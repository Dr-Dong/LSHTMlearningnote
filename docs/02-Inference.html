<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 9 章 統計推斷的概念 | 醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="第 9 章 統計推斷的概念 | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 9 章 統計推斷的概念 | 醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2019-11-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="01-Probability.html"/>
<link rel="next" href="03-Analytic-Technique.html"/>
<script src="assets/jquery/jquery.min.js"></script>
<link href="assets/gitbook/css/style.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/kePrint/kePrint.js"></script>
<script src="assets/htmlwidgets/htmlwidgets.js"></script>
<script src="assets/plotly-binding/plotly.js"></script>
<script src="assets/typedarray/typedarray.min.js"></script>
<link href="assets/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="assets/crosstalk/js/crosstalk.min.js"></script>
<link href="assets/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="assets/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="00-author.html"><a href="00-author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="01-Probability.html"><a href="01-Probability.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Probability.html"><a href="01-Probability.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="01-Probability.html"><a href="01-Probability.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="01-Probability.html"><a href="01-Probability.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="01-Probability.html"><a href="01-Probability.html#Bayes-Definition"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="01-Probability.html"><a href="01-Probability.html#期望-expectation-或均值-or-mean-和-方差-variance"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="01-Probability.html"><a href="01-Probability.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="01-Probability.html"><a href="01-Probability.html#bernoulli"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="01-Probability.html"><a href="01-Probability.html#binomial"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="01-Probability.html"><a href="01-Probability.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="01-Probability.html"><a href="01-Probability.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="01-Probability.html"><a href="01-Probability.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="01-Probability.html"><a href="01-Probability.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="01-Probability.html"><a href="01-Probability.html#poisson"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="01-Probability.html"><a href="01-Probability.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="01-Probability.html"><a href="01-Probability.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="01-Probability.html"><a href="01-Probability.html#CLT"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="01-Probability.html"><a href="01-Probability.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="01-Probability.html"><a href="01-Probability.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="01-Probability.html"><a href="01-Probability.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="01-Probability.html"><a href="01-Probability.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="01-Probability.html"><a href="01-Probability.html#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="01-Probability.html"><a href="01-Probability.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="01-Probability.html"><a href="01-Probability.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="01-Probability.html"><a href="01-Probability.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="02-Inference.html"><a href="02-Inference.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="02-Inference.html"><a href="02-Inference.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="02-Inference.html"><a href="02-Inference.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="02-Inference.html"><a href="02-Inference.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="02-Inference.html"><a href="02-Inference.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="02-Inference.html"><a href="02-Inference.html#估計和精確度-estimation-and-precision"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="02-Inference.html"><a href="02-Inference.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="02-Inference.html"><a href="02-Inference.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="02-Inference.html"><a href="02-Inference.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="02-Inference.html"><a href="02-Inference.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="02-Inference.html"><a href="02-Inference.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="02-Inference.html"><a href="02-Inference.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="02-Inference.html"><a href="02-Inference.html#chi-square-distribution"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="02-Inference.html"><a href="02-Inference.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="02-Inference.html"><a href="02-Inference.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-definition"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="02-Inference.html"><a href="02-Inference.html#概率-vs.推斷-probability-vs.inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="02-Inference.html"><a href="02-Inference.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="02-Inference.html"><a href="02-Inference.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="02-Inference.html"><a href="02-Inference.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="02-Inference.html"><a href="02-Inference.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="02-Inference.html"><a href="02-Inference.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="02-Inference.html"><a href="02-Inference.html#llr"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="02-Inference.html"><a href="02-Inference.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="02-Inference.html"><a href="02-Inference.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="02-Inference.html"><a href="02-Inference.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="02-Inference.html"><a href="02-Inference.html#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="02-Inference.html"><a href="02-Inference.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="02-Inference.html"><a href="02-Inference.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="02-Inference.html"><a href="02-Inference.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="02-Inference.html"><a href="02-Inference.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="02-Inference.html"><a href="02-Inference.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="02-Inference.html"><a href="02-Inference.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="02-Inference.html"><a href="02-Inference.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的構建-construction-of-a-hypothesis-test"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="02-Inference.html"><a href="02-Inference.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="02-Inference.html"><a href="02-Inference.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="02-Inference.html"><a href="02-Inference.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="02-Inference.html"><a href="02-Inference.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="02-Inference.html"><a href="02-Inference.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="02-Inference.html"><a href="02-Inference.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="02-Inference.html"><a href="02-Inference.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="02-Inference.html"><a href="02-Inference.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="02-Inference.html"><a href="02-Inference.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="02-Inference.html"><a href="02-Inference.html#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的近似方法"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="02-Inference.html"><a href="02-Inference.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="02-Inference.html"><a href="02-Inference.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="02-Inference.html"><a href="02-Inference.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="02-Inference.html"><a href="02-Inference.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="02-Inference.html"><a href="02-Inference.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="02-Inference.html"><a href="02-Inference.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="02-Inference.html"><a href="02-Inference.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="02-Inference.html"><a href="02-Inference.html#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="02-Inference.html"><a href="02-Inference.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="02-Inference.html"><a href="02-Inference.html#正態誤差模型-normal-error-models"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="02-Inference.html"><a href="02-Inference.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="02-Inference.html"><a href="02-Inference.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="02-Inference.html"><a href="02-Inference.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="02-Inference.html"><a href="02-Inference.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="02-Inference.html"><a href="02-Inference.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="02-Inference.html"><a href="02-Inference.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="02-Inference.html"><a href="02-Inference.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="02-Inference.html"><a href="02-Inference.html#多個參數時的統計推斷-inference-with-multiple-parameters-i"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="02-Inference.html"><a href="02-Inference.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="02-Inference.html"><a href="02-Inference.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="02-Inference.html"><a href="02-Inference.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="02-Inference.html"><a href="02-Inference.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="02-Inference.html"><a href="02-Inference.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="02-Inference.html"><a href="02-Inference.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="02-Inference.html"><a href="02-Inference.html#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="02-Inference.html"><a href="02-Inference.html#profile-log-likelihood"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="02-Inference.html"><a href="02-Inference.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="02-Inference.html"><a href="02-Inference.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="02-Inference.html"><a href="02-Inference.html#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path="02-Inference.html"><a href="02-Inference.html#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path="02-Inference.html"><a href="02-Inference.html#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path="02-Inference.html"><a href="02-Inference.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path="02-Inference.html"><a href="02-Inference.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間-confidence-intervals-1"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#假設檢驗"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關-association"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較-comparisons"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#前提和數據轉換-assumptions-and-transformations"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ANOVA"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析-multivariable-models"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析矩陣標記與其意義"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸的模型診斷"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#baseline-adjustment-using-ancova"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法-permutation-procedures"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#自助重抽法-the-bootstrap"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#the-sandwich-estimator"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯定理的應用單一參數模型"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path="09-GLM.html"><a href="09-GLM.html"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path="09-GLM.html"><a href="09-GLM.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path="09-GLM.html"><a href="09-GLM.html#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path="09-GLM.html"><a href="09-GLM.html#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path="09-GLM.html"><a href="09-GLM.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path="09-GLM.html"><a href="09-GLM.html#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path="09-GLM.html"><a href="09-GLM.html#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path="09-GLM.html"><a href="09-GLM.html#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path="09-GLM.html"><a href="09-GLM.html#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path="09-GLM.html"><a href="09-GLM.html#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path="09-GLM.html"><a href="09-GLM.html#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path="09-GLM.html"><a href="09-GLM.html#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path="09-GLM.html"><a href="09-GLM.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="09-GLM.html"><a href="09-GLM.html#廣義線性迴歸入門"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path="09-GLM.html"><a href="09-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="09-GLM.html"><a href="09-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path="09-GLM.html"><a href="09-GLM.html#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path="09-GLM.html"><a href="09-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path="09-GLM.html"><a href="09-GLM.html#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path="09-GLM.html"><a href="09-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = &quot;loess&quot;)</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path="09-GLM.html"><a href="09-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path="09-GLM.html"><a href="09-GLM.html#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型-logistic-regression-model"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path="09-GLM.html"><a href="09-GLM.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path="09-GLM.html"><a href="09-GLM.html#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="09-GLM.html"><a href="09-GLM.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path="09-GLM.html"><a href="09-GLM.html#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path="09-GLM.html"><a href="09-GLM.html#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path="09-GLM.html"><a href="09-GLM.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path="09-GLM.html"><a href="09-GLM.html#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="09-GLM.html"><a href="09-GLM.html#模型比較和擬合優度"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path="09-GLM.html"><a href="09-GLM.html#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path="09-GLM.html"><a href="09-GLM.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path="09-GLM.html"><a href="09-GLM.html#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path="09-GLM.html"><a href="09-GLM.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path="09-GLM.html"><a href="09-GLM.html#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="09-GLM.html"><a href="09-GLM.html#計數型因變量-poisson-regression"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path="09-GLM.html"><a href="09-GLM.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path="09-GLM.html"><a href="09-GLM.html#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path="09-GLM.html"><a href="09-GLM.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="09-GLM.html"><a href="09-GLM.html#率的廣義線性迴歸-poisson-glm-for-rates"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path="09-GLM.html"><a href="09-GLM.html#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path="09-GLM.html"><a href="09-GLM.html#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path="09-GLM.html"><a href="09-GLM.html#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path="09-GLM.html"><a href="09-GLM.html#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path="09-GLM.html"><a href="09-GLM.html#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="09-GLM.html"><a href="09-GLM.html#混雜的調整交互作用和模型的可壓縮性"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path="09-GLM.html"><a href="09-GLM.html#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path="09-GLM.html"><a href="09-GLM.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="09-GLM.html"><a href="09-GLM.html#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path="09-GLM.html"><a href="09-GLM.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path="09-GLM.html"><a href="09-GLM.html#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="09-GLM.html"><a href="09-GLM.html#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="09-GLM.html"><a href="09-GLM.html#流行病學中的邏輯迴歸"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path="09-GLM.html"><a href="09-GLM.html#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path="09-GLM.html"><a href="09-GLM.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="09-GLM.html"><a href="09-GLM.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path="09-GLM.html"><a href="09-GLM.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path="09-GLM.html"><a href="09-GLM.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path="09-GLM.html"><a href="09-GLM.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="09-GLM.html"><a href="09-GLM.html#分析策略"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path="09-GLM.html"><a href="09-GLM.html#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path="09-GLM.html"><a href="09-GLM.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path="09-GLM.html"><a href="09-GLM.html#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path="09-GLM.html"><a href="09-GLM.html#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="09-GLM.html"><a href="09-GLM.html#檢查你的模型-model-checking---glm"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path="09-GLM.html"><a href="09-GLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path="09-GLM.html"><a href="09-GLM.html#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path="09-GLM.html"><a href="09-GLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path="09-GLM.html"><a href="09-GLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="09-GLM.html"><a href="09-GLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path="09-GLM.html"><a href="09-GLM.html#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path="09-GLM.html"><a href="09-GLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path="09-GLM.html"><a href="09-GLM.html#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="09-GLM.html"><a href="09-GLM.html#評價模型的表現-assessing-model-performance"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path="09-GLM.html"><a href="09-GLM.html#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path="09-GLM.html"><a href="09-GLM.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path="09-GLM.html"><a href="09-GLM.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path="09-GLM.html"><a href="09-GLM.html#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗數據的分析法"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path="09-GLM.html"><a href="09-GLM.html#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path="09-GLM.html"><a href="09-GLM.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path="09-GLM.html"><a href="09-GLM.html#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="09-GLM.html"><a href="09-GLM.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path="09-GLM.html"><a href="09-GLM.html#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path="09-GLM.html"><a href="09-GLM.html#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="09-GLM.html"><a href="09-GLM.html#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path="09-GLM.html"><a href="09-GLM.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path="09-GLM.html"><a href="09-GLM.html#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path="09-GLM.html"><a href="09-GLM.html#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="09-GLM.html"><a href="09-GLM.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯迴歸-conditional-logistic-regression"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path="09-GLM.html"><a href="09-GLM.html#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path="09-GLM.html"><a href="09-GLM.html#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path="09-GLM.html"><a href="09-GLM.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path="09-GLM.html"><a href="09-GLM.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path="09-GLM.html"><a href="09-GLM.html#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="09-GLM.html"><a href="09-GLM.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path="09-GLM.html"><a href="09-GLM.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型-random-intercept-model"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = &quot;ML&quot;</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中加入共變量-random-intercept-model-with-covariates"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數模型-random-coefficient-model"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將數據導入軟件裏"><i class="fa fa-check"></i><b>61.7.1</b> 　將數據導入軟件裏，</a></li>
<li class="chapter" data-level="61.7.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.2</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.3</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.4</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.5</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.6</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.7</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.8</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.9</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.10</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.12" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.12</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-1"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-2"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-3"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#generalized-estimating-equation"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysisunsupervised-learning-聚類分析"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-1"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#principal-component-analysis-主成分分析"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-2"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#further-issues"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數分布"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#nonparametric"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據中的回歸模型"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布-1"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-比例風險模型"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分析策略和模型檢查-model-checking-survival-analysis"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#競爭風險模型-competing-risk"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的其他手段"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#加速失效模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.1</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量-time-dependent-variables-和脆弱模型-frailty-model"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間事件數據的高級分析法"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="80" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html"><i class="fa fa-check"></i><b>80</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="80.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>80.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="80.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>80.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="80.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#概率論者分析結果"><i class="fa fa-check"></i><b>80.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="80.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>80.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="80.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-the-great-trial"><i class="fa fa-check"></i><b>80.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="80.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#background-great-trial"><i class="fa fa-check"></i><b>80.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="80.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#試驗結果"><i class="fa fa-check"></i><b>80.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="80.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#經典統計學分析方法"><i class="fa fa-check"></i><b>80.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="80.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>80.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MC-estimation"><i class="fa fa-check"></i><b>81</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="81.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#起源"><i class="fa fa-check"></i><b>81.1</b> 起源</a><ul>
<li class="chapter" data-level="81.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#作出預測"><i class="fa fa-check"></i><b>81.1.1</b> 作出預測</a></li>
<li class="chapter" data-level="81.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-新藥表現預測"><i class="fa fa-check"></i><b>81.1.2</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>81.2</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="81.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>81.2.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="81.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>81.2.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="81.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅法分析軟件-openbugs"><i class="fa fa-check"></i><b>81.3</b> 蒙特卡羅法分析軟件 OpenBUGS</a><ul>
<li class="chapter" data-level="81.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>81.3.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="81.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>81.3.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="81.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>81.3.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>81.4</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="82" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率-conjugate-priors"><i class="fa fa-check"></i><b>82</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="82.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>82.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="82.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="82.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#事後概率分布預測"><i class="fa fa-check"></i><b>82.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="82.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>82.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="82.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesPrac03"><i class="fa fa-check"></i><b>82.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="83" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MCMC-methods"><i class="fa fa-check"></i><b>83</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="83.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>83.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="83.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>83.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="83.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Gibbs-sampling"><i class="fa fa-check"></i><b>83.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="83.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值-initial-values"><i class="fa fa-check"></i><b>83.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="83.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>83.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="83.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#收斂時間"><i class="fa fa-check"></i><b>83.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="83.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>83.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="83.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-軟件"><i class="fa fa-check"></i><b>83.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="83.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>83.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="83.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>83.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="83.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-language"><i class="fa fa-check"></i><b>83.5</b> BUGS language</a><ul>
<li class="chapter" data-level="83.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>83.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="83.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#分布的標記法"><i class="fa fa-check"></i><b>83.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="83.5.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#arrays-and-loops"><i class="fa fa-check"></i><b>83.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="83.5.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#常用的方程"><i class="fa fa-check"></i><b>83.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="83.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>83.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="83.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>83.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#建模和模型的檢查"><i class="fa fa-check"></i><b>84</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="84.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesianLM"><i class="fa fa-check"></i><b>84.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="84.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#children-in-the-gambia"><i class="fa fa-check"></i><b>84.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="84.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>84.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="84.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>84.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="84.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="84.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>84.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="84.2.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>84.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="84.2.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>84.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="84.2.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>84.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="84.2.8" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="84.2.9" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#tdreplacegaussian"><i class="fa fa-check"></i><b>84.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="84.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>84.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="84.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>84.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="84.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>84.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="84.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>84.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="84.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>84.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="84.4.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>84.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="85" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#不同實驗研究設計時適用的貝葉斯模型"><i class="fa fa-check"></i><b>85</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="85.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>85.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="85.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>85.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="85.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>85.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="85.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#the-great-trial"><i class="fa fa-check"></i><b>85.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="85.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#吸煙與癌症"><i class="fa fa-check"></i><b>85.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯廣義線性回歸"><i class="fa fa-check"></i><b>86</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="86.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>86.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="86.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>86.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="86.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>86.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="86.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>86.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="86.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#邏輯回歸模型中回歸系數的含義"><i class="fa fa-check"></i><b>86.2.1</b> 　邏輯回歸模型中回歸系數的含義</a></li>
<li class="chapter" data-level="86.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#低出生體重數據-1"><i class="fa fa-check"></i><b>86.2.2</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="86.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>86.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="86.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>86.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="86.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Bayesian-practical07"><i class="fa fa-check"></i><b>86.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="87" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級回歸模型"><i class="fa fa-check"></i><b>87</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="87.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>87.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="87.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>87.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="87.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>87.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="87.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>87.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="87.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>87.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="87.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>87.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="87.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#縱向數據"><i class="fa fa-check"></i><b>87.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="87.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-example"><i class="fa fa-check"></i><b>87.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="87.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>87.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="87.3.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>87.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="87.3.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>87.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="87.3.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>87.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="87.3.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>87.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="87.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>87.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#再訪-mcmc"><i class="fa fa-check"></i><b>88</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="88.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>88.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="88.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>88.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯和概率論的比較"><i class="fa fa-check"></i><b>89</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="89.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>89.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="89.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>89.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="89.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>89.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="90" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html"><i class="fa fa-check"></i><b>90</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="90.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>90.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="90.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>90.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="90.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步分析"><i class="fa fa-check"></i><b>90.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="90.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#混雜"><i class="fa fa-check"></i><b>90.2.2</b> 混雜</a></li>
<li class="chapter" data-level="90.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>90.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="90.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>90.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="90.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>90.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="90.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>90.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="90.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>90.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="90.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>90.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="91" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#graphical-models-因果推斷的圖形模型"><i class="fa fa-check"></i><b>91</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="91.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>91.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="91.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>91.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="91.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-圖的術語"><i class="fa fa-check"></i><b>91.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="91.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>91.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="91.1.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>91.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="91.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以非對撞銀子爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>91.2</b> 以非對撞銀子爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="91.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件的總結"><i class="fa fa-check"></i><b>91.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="91.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#d-分離-d-separation"><i class="fa fa-check"></i><b>91.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-continuous-outcomes-結果變量爲連續型變量"><i class="fa fa-check"></i><b>92</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="92.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>92.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="92.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>92.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="92.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>92.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="92.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>92.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="92.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>92.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="92.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>92.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="92.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均值差"><i class="fa fa-check"></i><b>92.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="92.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>92.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="92.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>92.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="92.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#positivity-非零性"><i class="fa fa-check"></i><b>92.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="92.3.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>92.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical03---causal-inference"><i class="fa fa-check"></i><b>92.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="93" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-binary-outcomes-結果變量爲二分類變量"><i class="fa fa-check"></i><b>93</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="93.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>93.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="93.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>93.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>93.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="93.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>93.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="93.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>93.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="93.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>93.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>93.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="93.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>93.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="93.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical04---causal-inference"><i class="fa fa-check"></i><b>93.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="93.6.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>93.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="93.6.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>93.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="93.6.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>93.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="93.6.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>93.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="93.6.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>93.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="93.6.7" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.8" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>93.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="93.6.9" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>93.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="93.6.10" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>93.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="93.6.11" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>93.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="93.6.12" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>93.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="94" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#prospensity-score-傾向性評分"><i class="fa fa-check"></i><b>94</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="94.0.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#關於條件可置換性"><i class="fa fa-check"></i><b>94.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="94.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>94.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="94.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分層法-stratification"><i class="fa fa-check"></i><b>94.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="94.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#配對法-matching"><i class="fa fa-check"></i><b>94.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="94.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>94.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical05---causal-inference"><i class="fa fa-check"></i><b>94.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="94.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>94.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="94.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>94.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="94.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>94.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="94.2.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>94.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="94.2.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用配對法計算-ace"><i class="fa fa-check"></i><b>94.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="94.2.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#模型校正-ps"><i class="fa fa-check"></i><b>94.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#inverse-probability-weighted-estimation-and-doubly-robust-methods"><i class="fa fa-check"></i><b>95</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="96" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#causal-mediation-analysis"><i class="fa fa-check"></i><b>96</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="97" data-path="29SME.html"><a href="29SME.html"><i class="fa fa-check"></i><b>97</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="30-references.html"><a href="30-references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="統計推斷的概念" class="section level1">
<h1><span class="header-section-number">第 9 章</span> 統計推斷的概念</h1>
<blockquote>
<dl>
<dt>If people do not believe that mathematics is simple, it is only because they do not realize how complicated life is.</dt>
<dd><a href="https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC">John von Neumann</a>
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Inference lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/altmann.daniel">Daniel Altmann</a>, Professor <a href="https://www.lshtm.ac.uk/aboutus/people/gregson.john">John Gregson</a>, and Dr. Katy Morgan.
</div>

<div id="人羣與樣本-population-and-sample" class="section level2">
<h2><span class="header-section-number">9.1</span> 人羣與樣本 (population and sample)</h2>
<p>討論樣本時，需考慮下面幾個問題：</p>
<ol style="list-style-type: decimal">
<li>樣本是否具有代表性？</li>
<li>人羣被準確定義了嗎？</li>
<li>我們感興趣的“人羣”是否可以是無限大 (多) 的？</li>
<li>我們研究的樣本，是僅僅用來觀察，亦或是計劃對之進行某種干預呢？</li>
<li>我們從所有可能的人羣中抽樣了嗎？</li>
</ol>
</div>
<div id="樣本和統計量-sample-and-statistic" class="section level2">
<h2><span class="header-section-number">9.2</span> 樣本和統計量 (sample and statistic)</h2>
<p>通常我們在進行實驗或觀察時只是獲得了樣本的數據。而希望從樣本數據去推斷 (inference) 總體 (或人羣) 的一些特徵。我們也許只是想用樣本的平均值來估計整體人羣的某個特徵的平均值。不管是何種估計和推斷，都是基於對樣本數據的計算，從樣本中獲得想要推斷總體的<strong>統計量 (statistics)</strong>。我們用已知樣本去推斷未知總體的過程就叫做<strong>估計 (estimate)</strong>。這個想要被推斷的總體或人羣的值，被叫做<strong>參數 (parameter)</strong>，常常使用希臘字母來標記。用來估計總體或人羣的，從樣本數據計算得來的統計量，叫做<strong>估計量 (estimator)</strong>。</p>
<p>所有的統計量，都有<strong>樣本分佈 (sampling distributions，意爲重複無限次取樣後獲得的無限次統計量的分佈)</strong>。推斷的過程歸納如下：</p>
<ol style="list-style-type: decimal">
<li>從總體或人羣中抽樣 (樣本量 <span class="math inline">\(n\)</span>)</li>
<li>計算這個樣本的合適統計量，從而用於估計它在整體或人羣中的值。</li>
<li>我們還需要決定計算獲得的統計量的樣本分佈 (假定會抽樣無數次) 。</li>
<li>一旦可以精確地確認樣本分佈，我們就可以定量地計算出使用步驟2中獲得的統計量估計總體或人羣的參數時的準確度。</li>
</ol>
</div>
<div id="估計-estimation" class="section level2">
<h2><span class="header-section-number">9.3</span> 估計 Estimation</h2>
<p>從樣本的均值，推斷總體或人羣的均值是一種估計。我們的目的是，從已知樣本中計算一個儘可能接近那個未知的總體或人羣參數的值。一個估計量有兩個與生俱來的性質 (properties)：1) 偏倚 (bias); 2) 精確度 (precision)。這兩個性質都可以從樣本分佈和估計量獲得。</p>
<ol style="list-style-type: decimal">
<li><p>偏倚： 偏倚簡單說就是樣本分佈的均值，也就是我們從樣本中計算獲得的估計量，和我們想要拿它來估計的總體或人羣的參數之間的差距。(The bias is the difference between the mean of the sampling distribution – the expected or average value of the estimator – and the population parameter being estimated.) 一個小的偏倚，確保了我們從樣本中計算獲得的估計值 (假設我們抽樣無數次，計算無數個樣本估計值) <strong>均勻地</strong>分佈在總體或人羣參數的左右兩邊。偏倚本身並不是太大的問題，但是假如樣本量增加，偏倚依然存在 (估計量不一致, inconsistent) ，那常常意味着是抽樣過程出現了問題。例如：<br>用簡單隨機抽樣法獲得的樣本均值，就是總體或人羣均值的無偏估計 (unbiased estimator)。如果抽樣時由於某些主觀客觀的原因導致較小的樣本很少被抽樣 (抽樣過程出了問題，脫離了簡單隨機抽樣原則) ，那麼此時得到的樣本均值就會是一個過高的估計值 (upward biased estimator)。</p></li>
<li><p>精確度：估計值的精確度可以通過樣本分佈的方差或標準差來評價 (簡單說是樣本分佈的方差越低，波動越小，精確度越高) 。樣本分佈的標準差被定義爲估計值的標準誤。假如估計量是樣本均值，那麼樣本分佈的標準差 (估計量的標準誤) 和樣本數據之間有如下的關係：</p></li>
</ol>
<p><span class="math display">\[\text{true standard error of the mean}  = \frac{\text{true standard deviation}}{\sqrt{\text{sample size}}}\]</span></p>
<p>在一些簡單的情況下，通常估計值的選用不言自明 (例如均值，或者百分比) 。但是在複雜的情況下，我們可能可以有多個不同類型的估計量可以選擇，他們也常常各有利弊，需要我們做出取捨。</p>
</div>
<div id="信賴區間-confidence-intervals" class="section level2">
<h2><span class="header-section-number">9.4</span> 信賴區間 confidence intervals</h2>
<p>從樣本中計算估計量獲得的一個估計值，只是一個<strong>點估計 (point estimate)</strong>。對比之下，信賴區間就是一個對這個點估計的精確度的體現。信賴區間越窄，說明我們對於總體或人羣的參數的可能取值的範圍估計越精確。</p>
<p>信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。<strong>每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平 (<span class="math inline">\(95\%\)</span>) 。</strong> 常用的這個概率值就是 <span class="math inline">\(95\%, 90\%, 99\%\)</span>。</p>
<p>當從樣本數據計算獲得的估計量的信賴區間很寬，說明了這個收集來的數據提供了很少的參數信息，導致估計變得很不精確。</p>
<p><del>看到這裏的都是好漢一條啊！ 我不知道你暈了麼有，反正我是已經暈了。。。</del></p>
</div>
</div>
<div id="估計和精確度-estimation-and-precision" class="section level1">
<h1><span class="header-section-number">第 10 章</span> 估計和精確度 Estimation and Precision</h1>
<div id="CI-for-sample-mean" class="section level2">
<h2><span class="header-section-number">10.1</span> 估計量和他們的樣本分佈</h2>
<p>例子： 最大呼氣量 (Forced Expoiratory Volume in one second, FEV1) 用於測量一個人的肺功能，它的測量值是連續的。我們從前來門診的人中隨機抽取 <span class="math inline">\(n\)</span> 人作爲樣本，用這個樣本的 FEV1 平均值來估計這個診所的患者的平均肺功能。</p>
<p><strong>模型假設：</strong> 在這個例子中，我們的假設有如下：每個隨機抽取的 FEV1 測量值都是從同一個總體 (人羣) 中抽取，每一個觀察值 <span class="math inline">\(Y_i\)</span> 都互相獨立互不影響。我們用縮寫 iid 表示這些隨機抽取的樣本是服從獨立同分佈 (independent and identically distributed)。另外，總體的分佈也假定爲正態分佈，且總體均值爲 <span class="math inline">\(\mu\)</span>，總體方差爲 <span class="math inline">\(\sigma^2\)</span>。那麼這個模型可以簡單的被寫成：</p>
<p><span class="math display">\[Y_i \stackrel{i.i.d}{\sim} N(\mu, \sigma^2), i=1,2,\dots,n\]</span></p>
<p><strong>總體均值 <span class="math inline">\(\mu\)</span> 的估計量：</strong> 顯然算術平均值: <span class="math inline">\(\bar{Y}=\frac{1}{n}\sum_{i=1}^ny_i\)</span> 是我們用於估計總體均值的估計量。</p>
<p><strong>估計量的樣本分佈：</strong> <span class="math display">\[\bar{Y}\stackrel{i.i.d}{\sim}N(\mu, \frac{\sigma^2}{n})\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
E(\bar{Y}) &amp;= E(\frac{1}{n}\sum Y_i) \\
           &amp;= \frac{1}{n}E(\sum Y_i) \\
           &amp;= \frac{1}{n}\sum E(Y_i) \\
           &amp;= \frac{1}{n}n\mu = \mu \\
Var(\bar{Y}) &amp;= Var(\frac{1}{n}\sum Y_i) \\
\because Y_i \;\text{are} &amp;\; \text{independent}   \\
            &amp;= \frac{1}{n^2}\sum Var(Y_i) \\
            &amp;= \frac{1}{n^2} n Var(Y_i) \\
            &amp;= \frac{\sigma^2}{n}
\end{aligned}
\]</span></p>
<p><strong>證明當 <span class="math inline">\(Z=\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}}\)</span> 時， <span class="math inline">\(Z\sim N(0,1)\)</span>:</strong></p>
<p>由式子可知， <span class="math inline">\(Z\)</span> 只是由一組服從正態分佈的數據 <span class="math inline">\(\bar{Y}\)</span> 線性轉換 (linear transformation) 而來，所以 <span class="math inline">\(Z\)</span> 本身也服從正態分佈</p>
<p><span class="math display">\[
\begin{aligned}
E(Z) &amp;= \frac{1}{\sqrt{Var(\bar{Y})}}E[\bar{Y}-\mu] \\
     &amp;= \frac{1}{\sqrt{Var(\bar{Y})}}[\mu-\mu] = 0 \\
Var(Z) &amp;= \frac{1}{Var(\bar{Y})}Var[\bar{Y}-\mu] \\
       &amp;= \frac{1}{Var(\bar{Y})}Var(\bar{Y}) =1 \\
\therefore Z \;&amp;\sim N(0,1)
\end{aligned}
\]</span></p>
<p><strong>均值 <span class="math inline">\(\mu\)</span> 的信賴區間：</strong> 上節說道，</p>
<blockquote>
<p>信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。<strong>每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平(<span class="math inline">\(95\%\)</span>) 。</strong> 常用的這個概率值就是 <span class="math inline">\(95\%, 90\%, 99\%\)</span>。</p>
</blockquote>
<p>假定我們用 <span class="math inline">\(95\%\)</span> 作爲信賴區間的水平。那麼下面我們嘗試推導一下信賴區間的計算公式。從長遠來說 (也就是假設我們從總體中抽樣無數次，每次都進行信賴區間的計算，也獲得無數個信賴區間) ，這些信賴區間中有 <span class="math inline">\(95\%\)</span> 是包含了總體的真實均值 (但是卻是未知) 的，而且這些信賴區間由於是從一個服從正態分佈的數據而來，它們也服從正態分佈 (對真實均值左右對稱) 。所以我們有理由相信，可以找到一個數值 <span class="math inline">\(c\)</span>：</p>
<p><span class="math display">\[Prob(\bar{Y} &gt; \mu+c) = 0.025 \\
  Prob(\bar{Y} &lt; \mu-c) = 0.025\]</span></p>
<p>因此，我們可以定義 <span class="math inline">\(95\%\)</span> 信賴區間的上限和下限分別是：</p>
<p><span class="math display">\[L=\bar{Y}-c \Rightarrow Prob(L&gt;\mu)=0.025 \\
  U=\bar{Y}+c \Rightarrow Prob(U&lt;\mu)=0.025\]</span></p>
<div class="figure">
<img src="img/Selection_082.png" />

</div>
<p>接下來就是推倒 (故意的) <span class="math inline">\(c\)</span> 的過程啦：</p>
<p><span class="math display">\[
\begin{aligned}
Prob(\bar{Y}&gt;\mu+c)=Prob(\bar{Y}-\mu&gt;c) \;&amp;= 0.025 \\
\Rightarrow Prob(\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}} &gt; \frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;= 0.025 \\
\Rightarrow Prob(Z&gt;\frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;= 0.025 \\
we\;have\;proved\; Z\sim N(0,1) \\
we\;also\;know\; Prob(Z&gt;1.96) \;&amp;= 0.025 \\
so\;let\; \frac{c}{\sqrt{Var(\bar{Y})}} =1.96 \\
\Rightarrow c=1.96\sqrt{Var(\bar{Y})} \\
the\;95\%\;confidence\;interval \;of\; &amp;the\;population\;mean\;is\\
\mu = \bar{Y}\pm1.96\sqrt{Var(\bar{Y})}=\bar{Y}\pm &amp; 1.96\frac{\sigma}{\sqrt{n}}
\end{aligned}
\]</span></p>
<p>其中，<span class="math inline">\(\sqrt{Var(\bar{Y})}\)</span> 就是我們熟知的估計量 <span class="math inline">\(\bar{Y}\)</span> 的標準誤。</p>
</div>
<div id="估計量的特質" class="section level2">
<h2><span class="header-section-number">10.2</span> 估計量的特質</h2>
<p>考慮以下的問題：</p>
<ol style="list-style-type: decimal">
<li>什麼因素決定了一個估計量 (estimator) 的好壞，是否實用？</li>
<li>如果有其他的可選擇估計量，該如何取捨呢？</li>
<li>當情況複雜的時候，我們該如何尋找合適的估計量？</li>
</ol>
<div id="bias" class="section level3">
<h3><span class="header-section-number">10.2.1</span> 偏倚</h3>
<p>假設 <span class="math inline">\(T\)</span> 是我們估計總體參數 <span class="math inline">\(\theta\)</span> 的一個估計量。一般來說我們希望估計量的樣本分佈可以在 <code>“正確的位置”</code> 左右均勻分佈。換句話說我們希望：</p>
<p><span class="math display">\[E(T)=\theta\]</span></p>
<p>如果實現了這個條件，我們說這樣的估計量是無偏的 (<code>unbiased</code>)。然而，天下哪有這等好事，我們叫真實值和估計量之間的差距爲偏倚：</p>
<p><span class="math display">\[bias(T) = E(T)-\theta\]</span></p>
<p>其實偏倚完全等於零並不是最重要，許多常見的估計量都是有偏倚的。重要的是，這個偏倚會隨着樣本量的增加而逐漸趨近於零。所以我們就可以認爲這樣的估計量是漸進無偏的 (asymptotically unbiased)：</p>
<p><span class="math display">\[T\;is\;an\;\textbf{unbiased}\;estimator\;for\;\theta\;if\;\\E(T)=\theta\\
T\;is\;an\;\textbf{asymptotically unbiased}\;estimator\;for\;\theta\;if\;\\lim_{n\rightarrow\infty}E(T)=\theta\]</span></p>
</div>
<div id="估計量的效能-efficiency" class="section level3">
<h3><span class="header-section-number">10.2.2</span> 估計量的效能 Efficiency</h3>
<p>通常，我們希望一個估計量 (estimator) 的偏倚要小，同時，它的樣本分佈也希望能儘可能的不要波動太大。換句話說，我們還希望估計量的方差越小越好。</p>
<p>如果說，兩個估計量有相同的偏倚，均可以選擇來推斷總體，我們說，其中樣本分佈的方差小的那個 (波動幅度小) 的那個估計量是相對更好的。因爲樣本分佈方差越小，說明可以<strong>更加精確的</strong>估計總體參數。這兩個估計量的方差之比：<span class="math inline">\(Var(S)/Var(T)\)</span> 被叫做這兩個估計量的<strong>相對效能 (relative efficiency)</strong>。所以我們用估計量去推斷總體時，需要選用效能最高，精確度最好的估計量 <strong>(the minimum variance unbiased estimator/an efficient estimator)</strong>。</p>
</div>
<div id="均值和中位數的相對效能" class="section level3">
<h3><span class="header-section-number">10.2.3</span> 均值和中位數的相對效能</h3>
<p>在一個服從 <span class="math inline">\(N(\mu,\sigma^2)\)</span> 正態分佈的數據中，中位數和均值是一樣的，也都同時等於總體均值參數 <span class="math inline">\(\mu\)</span>。而且，樣本均數 <span class="math inline">\(\bar{Y}\)</span> 和樣本中位數 <span class="math inline">\(\dot{Y}\)</span> 都是對總體均值的無偏估計量。那麼應該選用中位數還是平均值呢？</p>
<p>之前證明過當 <span class="math inline">\(Y_i \sim N(\mu,\sigma^2)\)</span> 時， <span class="math inline">\(Var(\bar{Y})=\sigma^2/n\)</span>。然而，當 <span class="math inline">\(n\)</span> 較大的時候，可以證明的是：</p>
<p><span class="math display">\[Var(\dot{Y})=\frac{\pi}{2}\frac{\sigma^2}{n}\approx1.571\frac{\sigma^2}{n}\]</span></p>
<p>因此，這兩個估計量的相對效能就是：</p>
<p><span class="math display">\[\frac{Var(\dot{Y})}{Var(\bar{Y})}\approx1.571\]</span></p>
<p>所以總體是正態分佈時，平均值就是較中位數更適合用來估計總體的估計量。</p>
</div>
<div id="均方差-mean-square-error-mse" class="section level3">
<h3><span class="header-section-number">10.2.4</span> 均方差 mean square error (MSE)</h3>
<p>兩個估計量的偏倚不同時，可以比較他們和總體參數之間的差距，這被叫做均方差, Mean Square Error (MSE)。</p>
<p><span class="math display">\[MSE(T)=E[(T-\theta)^2]\]</span></p>
<p>這裏用一個數學技巧，將式子中的估計量和總體參數之間的差，分成兩個部分：一是估計量本身的方差 (<span class="math inline">\(T-E(T)\)</span>)，一是估計量的偏倚 (<span class="math inline">\(E(T)-\theta\)</span>)。</p>
<p><span class="math display">\[
\begin{aligned}
MSE(T) &amp;= E[(T-\theta)^2] \\
       &amp;= E\{[T-E(T)+E(T)-\theta]^2\} \\
       &amp;= E\{[T-E(T)]^2+[E(T)-\theta]^2 \\
       &amp; \;\;\;\;\; \;\;+2[T-E(T)][E(T)-\theta]\} \\
       &amp;= E\{[T-E(T)]^2\}+E\{[E(T)-\theta]^2\} + 0\\
       &amp;= Var(T) + [bias(T)^2]
\end{aligned}
\]</span></p>
</div>
</div>
<div id="samplevarbias" class="section level2">
<h2><span class="header-section-number">10.3</span> 總體方差的估計，自由度</h2>
<p>如果 <span class="math inline">\(Y_i \sim (\mu, \sigma^2)\)</span>，並不需要默認或者假定它服從正態分佈或者任何分佈。那麼它的方差我們會用：</p>
<p><span class="math display">\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2\]</span></p>
<p><strong>證明 <span class="math inline">\(V_{\mu}\)</span> 是 <span class="math inline">\(\sigma^2\)</span> 的無偏估計：</strong></p>
<p><span class="math display">\[
\begin{aligned}
V_{\mu} &amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
 we\;need\;to\;prove &amp;E(V_{\mu}) = \sigma^2 \\
\Rightarrow E(V_{\mu}) &amp;= \frac{1}{n}\sum_{i=1}^nE(Y_i-\mu)^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^nVar(Y_i) \\
        &amp;= \frac{1}{n}\sum_{i=1}^n\sigma^2 \\
        &amp;= \sigma^2
\end{aligned}
\]</span></p>
<p>然而通常情況下，我們並不知道總體的均值 <span class="math inline">\(\mu\)</span>。因此，只好用樣本的均值 <span class="math inline">\(\bar{Y}\)</span> 來估計 <span class="math inline">\(\mu\)</span>。所以上面的方程就變成了：</p>
<p><span class="math display">\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span></p>
<p>你如果仔細觀察認真思考，就會發現，上面這個式子是<code>有問題的</code>。這個大問題就在於，<span class="math inline">\(Y_i-\bar{Y}\)</span> 中我們忽略掉了樣本均值 <span class="math inline">\(\bar{Y}\)</span> 和總體均值 <span class="math inline">\(\mu\)</span> 之間的差 (<span class="math inline">\(\bar{Y}-\mu\)</span>)。因此上面的計算式來估計總體方差時，很顯然是會低估平均平方差，從而低估了總體方差。</p>
<p>這裏需要引入<strong>自由度 (degree of freedom)</strong> 在參數估計中的概念。</p>
<p>字面上可以理解爲：自由度是估計過程中使用了多少互相獨立的信息。所以在上面第一個公式中：<span class="math inline">\(V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2\)</span>。所有的 <span class="math inline">\(n\)</span> 個觀察值互相獨立，不僅如此，他們還對總體均值獨立。然而在第二個我們用 <span class="math inline">\(\bar{Y}\)</span> 取代了 <span class="math inline">\(\mu\)</span> 的公式中，樣本均數則與觀察值不互相獨立。因爲<strong>樣本均數必然總是落在觀察值的中間</strong>。然而總體均數並不一定就會落在觀察值中間。總體均數，和觀察值之間是自由，獨立的。因此，當我們觀察到 <span class="math inline">\(n-1\)</span> 個觀察值時，剩下的最後一個觀察值，決定了樣本均值的大小。所以說，樣本均值的自由度，是 <span class="math inline">\(n-1\)</span>。</p>
<p>所以，加入了自由度的討論，我們可以相信，用樣本估計總體的方差時，使用下面的公式將會是總體方差的無偏估計：</p>
<p><span class="math display">\[V_{n-1}=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})=\frac{n}{n-1}V_n\]</span></p>
<p><strong>證明</strong></p>
<p>利用上面也用到過的證明方法 – 把樣本和總體均值之間的差分成兩部分：</p>
<p><span class="math display">\[
\begin{aligned}
V_{\mu} &amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})+(\bar{Y}-\mu)]^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})^2+(\bar{Y}-\mu)^2\\
        &amp;\;\;\;\;\;\;\;\;\;\;\;\;+2(Y_i-\bar{Y})(\bar{Y}-\mu)]\\
        &amp;=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2+\frac{1}{n}\sum_{i=1}^n(\bar{Y}-\mu)^2\\
        &amp;\;\;\;\;\;\;\;\;\;\;\;\;+\frac{2}{n}(\bar{Y}-\mu)\sum_{i=1}^n(Y_i-\bar{Y}) \\
        &amp;= V_n+(\bar{Y}-\mu)^2 \\ &amp;\;\;\;\;\;\;\;\;\;\;\;\;(\text{note that}\;\sum_{i=1}^n(Y_i-\bar{Y})=0) \\
\Rightarrow  V_n &amp;= V_{\mu}-(\bar{Y}-\mu)^2  \\
\therefore E(V_n)&amp;= E(V_{\mu}) - E[(\bar{Y}-\mu)^2] \\
                 &amp;= Var(Y)-Var(\bar{Y}) \\
                 &amp;= \sigma^2-\frac{\sigma^2}{n} \\
                 &amp;= \sigma^2(\frac{n-1}{n})
\end{aligned}
\]</span></p>
<p>因此，我們看見 <span class="math inline">\(V_n\)</span> 正如上面討論的那樣，是低估了總體方差的。雖然當 <span class="math inline">\(n\rightarrow\infty\)</span> 時無限接近 <span class="math inline">\(\sigma^2\)</span> 但是依然是低估了的。所以，我們可以對之進行修正：</p>
<p><span class="math display">\[
\begin{aligned}
E[\frac{n}{n-1}V_n]     &amp;= \frac{n}{n-1}E[V_n] =\sigma^2 \\
\Rightarrow E[V_{n-1}]  &amp;= \sigma^2
\end{aligned}
\]</span></p>
</div>
<div id="samplevar" class="section level2">
<h2><span class="header-section-number">10.4</span> 樣本方差的樣本分佈</h2>
<p><span class="math inline">\(S^2\)</span> 常用來標記樣本方差，取代上面我們用到的 <span class="math inline">\(V_{n-1}\)</span>：</p>
<p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span></p>
<p>而且上面也證明了，<span class="math inline">\(E(S^2)=\sigma^2\)</span> 是總體方差的無偏估計。然而，要注意的是，樣本標準差 <span class="math inline">\(\sqrt{S^2}\)</span> 卻不是總體標準差 <span class="math inline">\(\sigma\)</span> 的無偏估計(因爲並不是線性變換，而是開了根號) 。</p>
<p><strong>證明樣本標準差 <span class="math inline">\(S\)</span> 不是總體標準差 <span class="math inline">\(\sigma\)</span> 的無偏估計</strong></p>
<p><span class="math display">\[
\begin{aligned}
Var(S)               &amp;=E(S^2)-[E(S)]^2 \\
\Rightarrow [E(S)]^2 &amp;=E(S^2)-Var(S) \\
\because E(S^2)      &amp;=\sigma^2 \\
\therefore   [E(S)]^2 &amp;=\sigma^2-Var(S) \\
             E(S)     &amp;=\sqrt{\sigma^2-Var(S)} \\
\end{aligned}\]</span></p>
<p><strong>可見樣本標準差是低估了總體標準差的。</strong></p>
<p>另外可以被證明的是：</p>
<p><span class="math display">\[\frac{n-1}{\sigma^2}S^2\sim \mathcal{X}_{n-1}^2\\
Var(S^2)=\frac{2\sigma^4}{n-1}\]</span></p>
<p><span class="math inline">\(\mathcal{X}^2_m\)</span>： 自由度爲 <span class="math inline">\(m\)</span> 的卡方分佈 (Section <a href="02-Inference.html#chi-square-distribution">11</a>)。是在圖形上向右歪曲的分佈。當自由度增加時，會越來越接近正態分佈。</p>
</div>
</div>
<div id="chi-square-distribution" class="section level1">
<h1><span class="header-section-number">第 11 章</span> 卡方分佈 Chi-square distribution</h1>
<div id="卡方分佈的期望和方差的證明" class="section level2">
<h2><span class="header-section-number">11.1</span> 卡方分佈的期望和方差的證明</h2>
<p>當 <span class="math inline">\(X\sim N(0,1)\)</span> 時， <span class="math inline">\(X^2\sim \mathcal{X}_1^2\)</span></p>
<p>如果 <span class="math inline">\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)</span>， 那麼 <span class="math inline">\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)</span></p>
<p>其中： <span class="math inline">\(\mathcal{X}_n^2\)</span> 表示自由度爲 <span class="math inline">\(n\)</span> 的卡方分佈。</p>
<p>且 <span class="math inline">\(X_m^2+X_n^2=\mathcal{X}_{m+n}^2\)</span></p>
</div>
<div id="卡方分佈的期望" class="section level2">
<h2><span class="header-section-number">11.2</span> 卡方分佈的期望</h2>
<p><span class="math display">\[E(X_1^2)=Var(X)+[E(X)]^2=1+0=1\]</span></p>
<p><span class="math display">\[\Rightarrow E(X_n^2)=n\]</span></p>
</div>
<div id="卡方分佈的方差" class="section level2">
<h2><span class="header-section-number">11.3</span> 卡方分佈的方差</h2>
<p><span class="math display">\[
\begin{aligned}
Var(X_1^2) &amp;= E(X_1^{2^2}) - E(X_1^2)^2 \\
           &amp;= E(X_1^4)-1
\end{aligned}
\]</span></p>
<div id="下面來求-ex_14" class="section level3">
<h3><span class="header-section-number">11.3.1</span> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></h3>
<p><span class="math display">\[
\begin{aligned}
\because E(X_1) &amp;= \int_{-\infty}^{+\infty} xf(x)dx \\
\therefore E(X_1^4) &amp;= \int_{-\infty}^{+\infty} x^4f(x)dx
\end{aligned}\]</span></p>
<p>已知： <span class="math inline">\(f(x)=\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}\)</span> 代入上式：</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \int_{-\infty}^{+\infty} x^4f(x)dx \\
         &amp;= \int_{-\infty}^{+\infty} x^4\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}dx\\
         &amp;=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^4e^{(-\frac{x^2}{2})}dx\\
         &amp;=\frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^3(-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>令 <span class="math inline">\(u=x^3, v=e^{(-\frac{x^2}{2})},t=-\frac{x^2}{2}\)</span> 可以推導：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{dv}{dx} &amp;= \frac{dv}{dt}\frac{dt}{dx} \\
              &amp;= e^t(-\frac{1}{2}\times2x) \\
              &amp;= (-x)e^{(-\frac{x^2}{2})} \\
\Rightarrow dv &amp;= (-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>再代入上面的式子：</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u\:dv \\
integrate\; &amp;by\; parts:\\
E(X_1^4) &amp;= \frac{-1}{\sqrt{2\pi}}\{[u\:v] \rvert_{-\infty}^{+\infty}-\int_{-\infty}^{+\infty}v\:du\} \\
&amp;= \frac{-1}{\sqrt{2\pi}}\{[x^3e^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}v\:du\} \\
&amp;=\frac{-1}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx^3\} \\
&amp;=\frac{-1}{\sqrt{2\pi}}[-3\int_{-\infty}^{+\infty}x^2e^{(-\frac{x^2}{2})}dx] \\
&amp;=\frac{-3}{\sqrt{2\pi}}[\int_{-\infty}^{+\infty}x(-x)e^{(-\frac{x^2}{2})}dx] \\
\end{aligned}
\]</span></p>
<p>再來一次分部積分：</p>
<p>令 <span class="math inline">\(a=x,b=e^{(-\frac{x^2}{2})},d\:b = (-x)e^{(-\frac{x^2}{2})}dx\)</span></p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{-3}{\sqrt{2\pi}}\{[a\:b] \rvert_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty}b\:da\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}\{[xe^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}b\:da\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}[-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx] \\
&amp;=\frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>下面令 <span class="math inline">\(I=\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\\ \Rightarrow I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy\)</span></p>
<p>接下來需要用到 <a href="https://www.youtube.com/watch?v=r0fv9V9GHdo">座標轉換</a>的知識，將 <span class="math inline">\(x,y\)</span> 表示的笛卡爾座標，轉換爲用角度 <span class="math inline">\(\theta\)</span> 和半徑 <span class="math inline">\(r\)</span> 表示的形式。之後的證明可以在<a href="https://www.youtube.com/watch?v=fWOGfzC3IeY">油管</a>上看到，但是我還是繼續證明下去。</p>
<p>直角座標系 (cartesian coordinators) 和 極座標系 (polar coordinators) 之間轉換的關係如下：</p>
<p><span class="math display">\[
\begin{aligned}
x&amp;=r\:cos\theta\\
y&amp;=r\:sin\theta\\
r^2&amp;=x^2+y^2\\
\end{aligned}
\]</span></p>
<p>座標轉換以後可以繼續求 <span class="math inline">\(E(X_1^4)\)</span>。 在那之前我們先求 <span class="math inline">\(I^2\)</span>。 注意轉換座標系統以後，<span class="math inline">\(\theta\in[0,2\pi], r\in[0,+\infty]\)</span></p>
<p><span class="math display">\[
\begin{aligned}
I^2 &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy \\
&amp;= \int_{0}^{+\infty}\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta dr \\
\end{aligned}
\]</span></p>
<p>由於先從中間的 <span class="math inline">\(\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta\)</span> 開始積分，<span class="math inline">\(\theta\)</span> 以外都可以視爲常數，那麼這個 <span class="math inline">\([0,2\pi]\)</span> 上的積分就的等於 <span class="math inline">\(2\pi e^{(-\frac{r^2}{2})}r\)</span>。</p>
<p>因此上面的式子又變爲：</p>
<p><span class="math display">\[
\begin{aligned}
I^2 &amp;=  2\pi\int_{0}^{+\infty}e^{(-\frac{r^2}{2})}r\:dr \\
\because \frac{d(e^{\frac{-r^2}{2}})}{dr} &amp;= -e^{(-\frac{r^2}{2})}r \\
\therefore I^2 &amp;= 2\pi(-e^{\frac{-r^2}{2}})\rvert_0^{+\infty} \\
               &amp;= 0-(2\pi\times(-1)) \\
               &amp;= 2\pi\\
\Rightarrow I  &amp;= \sqrt{2\pi}
\end{aligned}
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx \\
&amp;= \frac{3}{\sqrt{2\pi}}\times I \\
&amp;= 3 \\
\Rightarrow Var(X_1^2) &amp;= E(X_1^4) - 1 \\
                       &amp;= 3-1 =2
\end{aligned}
\]</span></p>
</div>
</div>
<div id="把上面的推導擴展" class="section level2">
<h2><span class="header-section-number">11.4</span> 把上面的推導擴展</h2>
<p><span class="math display">\[
\text{Suppose } \mathcal{X}^2_1, \cdots \mathcal{X}^2_k \stackrel{i.i.d}{\sim} \mathcal{X}^2_1 \\
\Rightarrow \sum_{i=1}^k \mathcal{X}^2_i \sim \mathcal{X}^2_k \\
\Rightarrow \text{E}(\sum_{i=1}^n\mathcal{X}^2_i)=\sum_{i-1}^n\text{E}(\mathcal{X}^2_i)=n\times1=n\\
\text{Var}(\sum_{i=1}^n\mathcal{X}^2_i)=\sum_{i=1}^n\text{Var}(\mathcal{X}^2_i) = n\times2=2n
\]</span></p>
<p>結論：<span class="math inline">\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)</span> 時，<span class="math inline">\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)</span> 服從卡方分佈，其期望 <span class="math inline">\(E(X_n^2)=n\)</span>，方差 <span class="math inline">\(Var(X_n^2)=2n\)</span>。 根據<strong>中心極限定理</strong>(Section <a href="01-Probability.html#CLT">8</a>)</p>
<p><span class="math display">\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]</span></p>
</div>
</div>
<div id="likelihood-definition" class="section level1">
<h1><span class="header-section-number">第 12 章</span> 似然 Likelihood</h1>
<div id="概率-vs.推斷-probability-vs.inference" class="section level2">
<h2><span class="header-section-number">12.1</span> 概率 vs. 推斷 Probability vs. Inference</h2>
<p>在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 <span class="math inline">\(0.5\; Prob(coin\;landing\;heads)=0.5\)</span>。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率(例如，10次投擲硬幣以後4次正面朝上的概率是多少？) 。</p>
<p><span class="math display">\[
\binom{10}{4}\times(0.5^4)\times(0.5^{10-4}) = 0.205
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">4</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## [1] 0.2051</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># or you can calculate by hand:</span>
<span class="kw">factorial</span>(<span class="dv">10</span>)<span class="op">*</span>(<span class="fl">0.5</span><span class="op">^</span><span class="dv">10</span>)<span class="op">/</span>(<span class="kw">factorial</span>(<span class="dv">4</span>)<span class="op">*</span>(<span class="kw">factorial</span>(<span class="dv">6</span>)))</code></pre></div>
<pre><code>## [1] 0.2051</code></pre>
<p>在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少(神如果存在話，只有神知道) 。故這個 <span class="math inline">\(Prob(coin\;landing\;heads)\)</span> 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，<strong>似然法 (likelihood)</strong> 就是我們進行參數估計的最佳手段。</p>
</div>
<div id="似然和極大似然估計-likelihood-and-maximum-likelihood-estimators" class="section level2">
<h2><span class="header-section-number">12.2</span> 似然和極大似然估計 Likelihood and maximum likelihood estimators</h2>
<p>此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患<del>中二</del>病，我們假定這個患病的概率爲 <span class="math inline">\(\pi\)</span>。於是我們就有了下面的模型：</p>
<p><strong>模型：</strong> 我們假定患病與否是一個服從<strong>二項分佈的隨機變量</strong>，<span class="math inline">\(X\sim Bin(10,\pi)\)</span>。同時也默認每個人之間是否患病是相互獨立的。</p>
<p><strong>數據：</strong> 觀察到的數據是，10人中有4人患病。於是 <span class="math inline">\(x=4\)</span>。</p>
<p>現在按照觀察到的數據，參數 <span class="math inline">\(\pi\)</span> 變成了未知數：</p>
<p><span class="math display">\[Prob(X=4|\pi)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]</span></p>
<p>此時我們會很自然的考慮，當 <span class="math inline">\(\pi\)</span> 是未知數的時候，<strong>它取值爲多大的時候才能讓這個事件(即：10人中4人患病) 發生的概率最大？</strong> 所以我們可以將不同的數值代入 <span class="math inline">\(\pi\)</span> 來計算該事件在不同概率的情況下發生的可能性到底是多少：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Table 12.1: The probability of observing <span class="math inline">\(X=4\)</span>
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(\pi\)</span>
</th>
<th style="text-align:center;">
事件 <span class="math inline">\(X=4\)</span> 發生的概率
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.0
</td>
<td style="text-align:center;">
0.000
</td>
</tr>
<tr>
<td style="text-align:center;">
0.2
</td>
<td style="text-align:center;">
0.088
</td>
</tr>
<tr>
<td style="text-align:center;">
<strong>0.4</strong>
</td>
<td style="text-align:center;">
<strong>0.251</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.205
</td>
</tr>
<tr>
<td style="text-align:center;">
0.6
</td>
<td style="text-align:center;">
0.111
</td>
</tr>
<tr>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
0.006
</td>
</tr>
<tr>
<td style="text-align:center;">
1.0
</td>
<td style="text-align:center;">
0.000
</td>
</tr>
</tbody>
</table>
<p>很顯然，如果 <span class="math inline">\(\pi=0.4\)</span> 時，我們觀察到的事件發生的概率要比 <span class="math inline">\(\pi\)</span> 取其它值時更大。於是小總結一下目前爲止的步驟如下：</p>
<ul>
<li>觀察到實驗數據(10人中4個患病) ；</li>
<li>假定這數據服從二項分佈的概率模型，計算不同(<span class="math inline">\(\pi\)</span> 的取值不同的) 情況下，該事件按照假定模型發生的概率；</li>
<li>通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (<span class="math inline">\(\pi=0.4\)</span>)。</li>
</ul>
<p>至此，我們可以知道，似然方程，是一個關於未知參數 <span class="math inline">\(\pi\)</span> 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 <span class="math inline">\(\pi\)</span> ：</p>
<p><span class="math display">\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]</span></p>
<p>我們可以畫出這個似然方程的形狀， <span class="math inline">\(\pi\in[0,1]\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)
y &lt;-<span class="st"> </span>(<span class="kw">factorial</span>(<span class="dv">10</span>)<span class="op">/</span>(<span class="kw">factorial</span>(<span class="dv">4</span>)<span class="op">*</span>(<span class="kw">factorial</span>(<span class="dv">6</span>))))<span class="op">*</span>(x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>)
<span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.3</span>), <span class="dt">ylab =</span> <span class="st">&quot;L(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="co">#title(&quot;Figure 1. Binomial Likelihood&quot;)</span>
<span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">0.251</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="fl">0.4</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:binomial-likelihood"></span>
<img src="bookdown_files/figure-html/binomial-likelihood-1.png" alt="Binomial Likelihood" width="90%" />
<p class="caption">
圖 12.1: Binomial Likelihood
</p>
</div>
<p>從圖形上我們也能確認，<span class="math inline">\(\pi=0.4\)</span> 時能夠讓這個似然方程取得最大值。</p>
</div>
<div id="似然方程的一般化定義" class="section level2">
<h2><span class="header-section-number">12.3</span> 似然方程的一般化定義</h2>
<p>對於一個概率模型，如果其參數爲 <span class="math inline">\(\theta\)</span>，那麼在給定觀察數據 <span class="math inline">\(\underline{x}\)</span> 時，該參數的似然方程被定義爲：</p>
<p><span class="math inline">\(L(\theta|\underline{x})=P(\underline{x}|\theta)\)</span></p>
<p>注意：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(\underline{x}|\theta)\)</span> 可以是概率(離散分佈) 方程，也可以是概率密度(連續型變量) 方程。對於此方程，<span class="math inline">\(\theta\)</span> 是給定的，然後再計算某些事件發生的概率。</li>
<li><span class="math inline">\(L(\theta|\underline{x})\)</span> 是一個關於參數 <span class="math inline">\(\theta\)</span> 的方程，此時，<span class="math inline">\(\underline{x}\)</span> 是固定不變的(觀察值) 。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。</li>
<li>似然方程<strong>不是</strong>一個概率密度方程。</li>
</ol>
<p>另一個例子：</p>
<p>有一組觀察數據是離散型隨機變量 <span class="math inline">\(X\)</span>，它符合概率方程 <span class="math inline">\(f(x|\theta)\)</span>。下表羅列了當 <span class="math inline">\(\theta\)</span> 分別取值 <span class="math inline">\(1,2,3\)</span> 時的概率方程的值，試求每個觀察值 <span class="math inline">\(X = 0,1,2,3,4\)</span> 的最大似然參數估計：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Exercise 12.3
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(x\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|1)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|2)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|3)\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/6
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/2
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Exercise 12.3 answer
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(x\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|1)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|2)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|3)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\theta\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
<strong>1</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
<strong>1</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
<strong>2</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/2
</td>
<td style="text-align:center;">
<strong>3</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
<strong>3</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="對數似然方程-log-likelihood" class="section level2">
<h2><span class="header-section-number">12.4</span> 對數似然方程 log-likelihood</h2>
<p>似然方程的最大值，可通過求 <span class="math inline">\(L(\theta|data)\)</span> 的最大值獲得，也可以通過求該方程的對數方程 <span class="math inline">\(\ell(\theta|data)\)</span> 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”(因爲這是觀察獲得的數據告訴我們的參數) ： <span class="math inline">\(\hat{\theta}\)</span>。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=\ell^\prime(\theta)=0\\
AND\\
\frac{d^2\ell}{d\theta^2}&lt;0\]</span></p>
<p>要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="dt">by=</span><span class="fl">0.001</span>)
y &lt;-<span class="st"> </span>(x<span class="dv">-1</span>)<span class="op">^</span><span class="dv">2-5</span>
<span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">0-1</span>), <span class="dt">ylab =</span> <span class="st">&quot;L(\U03B8)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03B8&quot;</span>)
<span class="co">#title(&quot;Figure 2. Likelihood function with \n a limited domain&quot;)</span>
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:likelihood-limited"></span>
<img src="bookdown_files/figure-html/likelihood-limited-1.png" alt="Likelihood function with a limited domain" width="90%" />
<p class="caption">
圖 12.2: Likelihood function with a limited domain
</p>
</div>
<p><strong>證明：當 <span class="math inline">\(L(\theta|data)\)</span> 取最大值時，該方程的對數方程 <span class="math inline">\(\ell(\theta|data)\)</span> 也是最大值：</strong></p>
<p>如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 <span class="math inline">\(\hat{\theta}\)</span> 使該方程取最大值，那麼：</p>
<p><span class="math display">\[\frac{dL}{d\theta}=0, \frac{d^2L}{d\theta^2}&lt;0 \Rightarrow \theta=\hat{\theta}\]</span></p>
<p>令 <span class="math inline">\(\ell=\text{log}L\)</span> 那麼 <span class="math inline">\(\frac{d\ell}{dL}=\ell^\prime=\frac{1}{L}\)</span>：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=\frac{d\ell}{dL}\cdot\frac{dL}{d\theta}=\frac{1}{L}\cdot\frac{dL}{d\theta}\]</span></p>
<p>當 <span class="math inline">\(\ell(\theta|data)\)</span> 取最大值時：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=0\Leftrightarrow\frac{1}{L}\cdot\frac{dL}{d\theta}=0\\
\because \frac{1}{L}\neq0 \\
\therefore \frac{dL}{d\theta}=0\\
\Leftrightarrow \theta=\hat{\theta}\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{d^2\ell}{d\theta^2} &amp;= \frac{d}{d\theta}(\frac{d\ell}{dL}\cdot\frac{dL}{d\theta})\\
 &amp;= \frac{d\ell}{dL}\cdot\frac{d^2L}{d\theta^2} + \frac{dL}{d\theta}\cdot\frac{d}{d\theta}(\frac{d\ell}{dL})
\end{aligned}
\]</span></p>
<p>當 <span class="math inline">\(\theta=\hat{\theta}\)</span> 時，<span class="math inline">\(\frac{dL}{d\theta}=0\)</span> 且 <span class="math inline">\(\frac{d^2L}{d\theta^2}&lt;0 \Rightarrow \frac{d^2\ell}{d\theta^2}&lt;0\)</span></p>
<p>所以，求獲得 <span class="math inline">\(\ell(\theta|data)\)</span> 最大值的 <span class="math inline">\(\theta\)</span> 即可令 <span class="math inline">\(L(\theta|data)\)</span> 獲得最大值。</p>
</div>
<div id="極大似然估計-maximum-likelihood-estimator-mle-的性質" class="section level2">
<h2><span class="header-section-number">12.5</span> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</h2>
<ol style="list-style-type: decimal">
<li>漸進無偏 Asymptotically unbiased: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow E(\hat{\Theta}) \rightarrow \theta\)</span></li>
<li>漸進最高效能 Asymptotically efficient: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow Var(\hat{\Theta})\)</span> 是所有參數中方差最小的估計</li>
<li>漸進正態分佈 Asymptotically normal: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow \hat{\Theta} \sim N(\theta, Var(\hat{\Theta}))\)</span></li>
<li>變形後依然保持不變 Transformation invariant: <br> <span class="math inline">\(\hat{\Theta}\)</span> 是 <span class="math inline">\(\theta\)</span> 的MLE時 <span class="math inline">\(\Rightarrow g(\hat{\Theta})\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 MLE</li>
<li>信息足夠充分 Sufficient：<br> <span class="math inline">\(\hat{\Theta}\)</span> 包含了觀察數據中所有的能夠用於估計參數的信息</li>
<li>始終不變 consistent: <br> <span class="math inline">\(n\rightarrow\infty\Rightarrow\hat{\Theta}\rightarrow\theta\)</span> 或者可以寫成：<span class="math inline">\(\varepsilon&gt;0, lim_{n\rightarrow\infty}P(|\hat{\Theta}-\theta|&gt;\varepsilon)=0\)</span></li>
</ol>
</div>
<div id="likelihood-poi" class="section level2">
<h2><span class="header-section-number">12.6</span> 率的似然估計 Likelihood for a rate</h2>
<p>如果在一項研究中，參與者有各自不同的追蹤隨訪時間(長度) ，那麼我們應該把事件(疾病) 的發病率用率的形式(多少事件每單位人年, e.g. per person year of observation) 。如果這個發病率的參數用 <span class="math inline">\(\lambda\)</span> 來表示，所有參與對象的隨訪時間之和爲 <span class="math inline">\(p\)</span> 人年。那麼這段時間內的期望事件(疾病發病) 次數爲：<span class="math inline">\(\mu=\lambda p\)</span>。假設事件(疾病發病) 發生是相互獨立的，可以使用泊松分佈來模擬期望事件(疾病發病) 次數 <span class="math inline">\(D\)</span>：</p>
<p><span class="math display">\[D\sim Poi(\mu)\]</span></p>
<p>假設我們觀察到了 <span class="math inline">\(D=d\)</span> 個事件，我們獲得這個觀察值的概率應該用以下的模型：</p>
<p><span class="math display">\[Prob(D=d)=e^{-\mu}\frac{\mu^d}{d!}=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]</span></p>
<p>因此，<span class="math inline">\(\lambda\)</span> 的似然方程是：</p>
<p><span class="math display">\[L(\lambda|observed \;data)=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]</span></p>
<p>所以，<span class="math inline">\(\lambda\)</span> 的對數似然方程是：</p>
<p><span class="math display">\[
\begin{aligned}
\ell(\lambda|observed\;data) &amp;= \text{log}(e^{-\lambda p}\frac{\lambda^dp^d}{d!}) \\
  &amp;= -\lambda p+d\:\text{log}(\lambda)+d\:\text{log}(p)-\text{log}(d!) \\
\end{aligned}
\]</span></p>
<p>解 <span class="math inline">\(\ell^\prime(\lambda|data)=0\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\ell^\prime(\lambda|data) &amp;= -p+\frac{d}{\lambda}=0\\
\Rightarrow \hat{\lambda} &amp;= \frac{d}{p} \\
\end{aligned}
\]</span></p>
<p><strong>注意：</strong> 在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，<span class="math inline">\(d\:\text{log}(p)-\text{log}(d!)\)</span> 不包含參數 <span class="math inline">\(\lambda\)</span> 可以直接不寫出來。</p>
</div>
<div id="有-n-個獨立觀察時的似然方程和對數似然方程" class="section level2">
<h2><span class="header-section-number">12.7</span> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</h2>
<p>當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之<strong>乘積</strong>。如果 <span class="math inline">\(X_1,\dots,X_n\stackrel{i.i.d}{\sim}f(\cdot|\theta)\)</span></p>
<p><span class="math display">\[L(\theta|x_1,\cdots,x_n)=f(x_1,\cdots,x_n|\theta)=\prod_{i=1}^nf(x_i|\theta)\\
\Rightarrow \ell(\theta|x_1,\cdots,x_n)=\sum_{i=1}^n\text{log}(f(x_i|\theta))\]</span></p>
</div>
</div>
<div id="llr" class="section level1">
<h1><span class="header-section-number">第 13 章</span> 對數似然比 Log-likelihood ratio</h1>
<p>對數似然比的想法來自於將對數似然方程圖形的 <span class="math inline">\(y\)</span> 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的<strong>對數似然比 (log-likelihood ratio)</strong> 來獲得：</p>
<p><span class="math display">\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]</span></p>
<p>由於 <span class="math inline">\(\ell(\theta)\)</span> 的最大值在 <span class="math inline">\(\hat{\theta}\)</span> 時， 所以，<span class="math inline">\(llr(\theta)\)</span> 就是個當 <span class="math inline">\(\theta=\hat{\theta}\)</span> 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 <span class="math inline">\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)</span> 取對數而已。</p>
<p><a href="https://winterwang.github.io/post/likelihood/">之前</a>我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：</p>
<p><span class="math display">\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=\text{log}[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=\text{log}\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]</span></p>
<p>其實由上也可以看出 <span class="math inline">\(llr(\theta)\)</span> 只是將對應的似然方程的 <span class="math inline">\(y\)</span> 軸重新調節了一下而已。形狀是沒有改變的：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)
y &lt;-<span class="st"> </span>(x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>)<span class="op">/</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)
z &lt;-<span class="st"> </span><span class="kw">log</span>((x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>))<span class="op">-</span><span class="kw">log</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)
<span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.1</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;LR(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.2</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial likelihood ratio&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">1.0</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.4</span>, <span class="dt">y0=</span><span class="dv">0</span>, <span class="dt">x1=</span><span class="fl">0.4</span>, <span class="dt">y1=</span><span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">plot</span>(x, z, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">1</span>), <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;llr(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial log-likelihood ratio&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.4</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">10</span>, <span class="dt">x1=</span><span class="fl">0.4</span>, <span class="dt">y1=</span><span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:binomial-logornot"></span>
<img src="bookdown_files/figure-html/binomial-logornot-1.png" alt="Binomial likelihood ratio and log-likelihood ratio" width="90%" />
<p class="caption">
圖 13.1: Binomial likelihood ratio and log-likelihood ratio
</p>
</div>
<div id="正態分佈數據的極大似然和對數似然比" class="section level2">
<h2><span class="header-section-number">13.1</span> 正態分佈數據的極大似然和對數似然比</h2>
<p>假設單個樣本 <span class="math inline">\(y\)</span> 是來自一組服從正態分佈數據的觀察值：<span class="math inline">\(Y\sim N(\mu, \tau^2)\)</span></p>
<p>那麼有：</p>
<p><span class="math display">\[
\begin{aligned}
f(y|\mu) &amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;=\text{log}(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;=  \frac{-1}{\tau^2} &lt; 0 \\
\therefore \hat{\mu} &amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]</span></p>
</div>
<div id="llr-chi1" class="section level2">
<h2><span class="header-section-number">13.2</span> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</h2>
<p>假設一組觀察值來自正態分佈 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>，先假設 <span class="math inline">\(\sigma^2\)</span> 已知。將觀察數據 <span class="math inline">\(x_1,\cdots, x_n\)</span> 標記爲 <span class="math inline">\(\underline{x}\)</span>。 那麼：</p>
<p><span class="math display">\[
\begin{aligned}
L(\mu|\underline{x}) &amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;=\sum_{i=1}^n\text{log}f(x_i|\mu)\\
&amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;= 0 \\
\therefore llr(\mu) &amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]</span></p>
</div>
<div id="llr-chi" class="section level2">
<h2><span class="header-section-number">13.3</span> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</h2>
<p>假設我們用 <span class="math inline">\(\mu_0\)</span> 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。</p>
<p>考慮一個服從正態分佈的單樣本 <span class="math inline">\(Y\)</span>: <span class="math inline">\(Y\sim N(\mu_0,\tau^2)\)</span>。那麼它的對數似然比：</p>
<p><span class="math display">\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]</span></p>
<p>根據<strong>卡方分佈</strong> (Section <a href="02-Inference.html#chi-square-distribution">11</a>) 的定義：</p>
<p><span class="math display">\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]</span></p>
<p>所以，如果有一組服從正態分佈的觀察值：<span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)</span>，且 <span class="math inline">\(\sigma^2\)</span> 已知的話：</p>
<p><span class="math display">\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]</span></p>
<p>根據<strong>中心極限定理</strong> (Section <a href="01-Probability.html#CLT">8</a>)，可以將上面的結論一般化：</p>

<div class="theorem">
<span id="thm:inference04" class="theorem"><strong>Theorem 13.1  </strong></span>如果 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)</span>。 那麼當重複多次從參數爲 <span class="math inline">\(\theta_0\)</span> 的總體中取樣時，那麼統計量 <span class="math inline">\(-2llr(\theta_0)\)</span> 會漸進於自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈： <span class="math display">\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]</span>
</div>

</div>
<div id="似然比信賴區間" class="section level2">
<h2><span class="header-section-number">13.4</span> 似然比信賴區間</h2>
<p>如果樣本量 <span class="math inline">\(n\)</span> 足夠大 (通常應該大於 <span class="math inline">\(30\)</span>)，根據上面的定理：</p>
<p><span class="math display">\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]</span></p>
<p>所以：</p>
<p><span class="math display">\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]</span></p>
<p>故似然比的 <span class="math inline">\(95\%\)</span> 信賴區間就是能夠滿足 <span class="math inline">\(llr(\theta)=-1.92\)</span> 的兩個 <span class="math inline">\(\theta\)</span> 值。</p>
<div id="binomial-ex" class="section level3">
<h3><span class="header-section-number">13.4.1</span> 以二項分佈數據爲例</h3>
<p>繼續用本文開頭的例子：</p>
<p><span class="math display">\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=\text{log}\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]</span></p>
<p>如果令 <span class="math inline">\(llr(\pi)=-1.92\)</span> 在代數上可能較難獲得答案。然而從圖形上，如果我們在 <span class="math inline">\(y=-1.92\)</span> 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)
z &lt;-<span class="st"> </span><span class="kw">log</span>((x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>))<span class="op">-</span><span class="kw">log</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)
<span class="kw">plot</span>(x, z, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">1</span>), <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;llr(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.15</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">12</span>, <span class="dt">x1=</span><span class="fl">0.15</span>, <span class="dt">y1=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.7</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">12</span>, <span class="dt">x1=</span><span class="fl">0.7</span>, <span class="dt">y1=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">at=</span><span class="kw">c</span>(<span class="fl">0.15</span>,<span class="fl">0.7</span>))
<span class="kw">text</span>(<span class="fl">0.9</span>, <span class="dv">-1</span>, <span class="st">&quot;-1.92&quot;</span>)
<span class="kw">arrows</span>(<span class="fl">0.8</span>, <span class="fl">-1.92</span>, <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">length =</span> <span class="fl">0.08</span>)
<span class="kw">arrows</span>( <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="fl">0.8</span>, <span class="fl">-1.92</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">length =</span> <span class="fl">0.08</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin-llr-95"></span>
<img src="bookdown_files/figure-html/bin-llr-95-1.png" alt="Log-likelihood ratio for binomial example, with 95% confidence intervals shown" width="90%" />
<p class="caption">
圖 13.2: Log-likelihood ratio for binomial example, with 95% confidence intervals shown
</p>
</div>
<p>從上圖中可以讀出，<span class="math inline">\(95\%\)</span> 對數似然比信賴區間就是 <span class="math inline">\((0.15, 0.7)\)</span></p>
</div>
<div id="normal-ex" class="section level3">
<h3><span class="header-section-number">13.4.2</span> 以正態分佈數據爲例</h3>
<p>本文前半部分證明過， <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>，先假設 <span class="math inline">\(\sigma^2\)</span> 已知。將觀察數據 <span class="math inline">\(x_1,\cdots, x_n\)</span> 標記爲 <span class="math inline">\(\underline{x}\)</span>。 那麼：</p>
<p><span class="math display">\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]</span></p>
<p>很顯然，這是一個關於 <span class="math inline">\(\mu\)</span> 的二次方程，且最大值在 MLE <span class="math inline">\(\hat{\mu}=\bar{x}\)</span> 時取值 <span class="math inline">\(0\)</span>。所以可以通過對數似然比法求出均值的 <span class="math inline">\(95\%\)</span> 信賴區間公式：</p>
<p><span class="math display">\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]</span></p>
<p>注意到這和我們之前求的正態分佈均值的信賴區間公式 (Section <a href="02-Inference.html#CI-for-sample-mean">10.1</a>) 完全一致。</p>
</div>
</div>
<div id="練習題" class="section level2">
<h2><span class="header-section-number">13.5</span> 練習題</h2>
<div id="q1" class="section level3">
<h3><span class="header-section-number">13.5.1</span> Q1</h3>
<ol style="list-style-type: lower-alpha">
<li>假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 <span class="math inline">\(\pi\)</span> 的似然方程和圖形 (likelihood) ?</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[\begin{aligned}
 L(\pi|3) &amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\
 omitting\;&amp;terms\;not\;in\;\pi \\
 \Rightarrow \ell(\pi|3) &amp;= \text{log}[\pi^3(1-\pi)^7] \\
 &amp;= 3\text{log}\pi+7\text{log}(1-\pi)\\
 \Rightarrow \ell^\prime(\pi|3)&amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\
 let \; \ell^\prime&amp; =0\\
 &amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\
 &amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\
 \Rightarrow MLE &amp;= \hat\pi = 0.3
\end{aligned}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:bin3-10"></span>
<img src="bookdown_files/figure-html/bin3-10-1.png" alt="Binomial likelihood function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.3: Binomial likelihood function 3 out of 10 subjects
</p>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>計算似然比，並作圖，注意方程圖形未變，<span class="math inline">\(y\)</span> 軸的變化；取對數似然比，並作圖</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">LR &lt;-<span class="st"> </span>L<span class="op">/</span><span class="kw">max</span>(L) ; <span class="kw">head</span>(LR)</code></pre></div>
<pre><code>## [1] 0.0000000 0.0004192 0.0031234 0.0098111 0.0216286 0.0392577</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(pi, LR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;darkblue&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.2</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial likelihood ratio function</span><span class="ch">\n</span><span class="st"> 3 out of 10 subjects&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-ratio"></span>
<img src="bookdown_files/figure-html/bin3-10-ratio-1.png" alt="Binomial likelihood ratio function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.4: Binomial likelihood ratio function 3 out of 10 subjects
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">logLR &lt;-<span class="st"> </span><span class="kw">log</span>(L<span class="op">/</span><span class="kw">max</span>(L))
<span class="kw">plot</span>(pi, logLR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;darkblue&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="co">#title(main = &quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&quot;)</span>
<span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">0</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-logratio"></span>
<img src="bookdown_files/figure-html/bin3-10-logratio-1.png" alt="Binomial log-likelihood ratio function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.5: Binomial log-likelihood ratio function 3 out of 10 subjects
</p>
</div>
</div>
<div id="q2" class="section level3">
<h3><span class="header-section-number">13.5.2</span> Q2</h3>
<ol style="list-style-type: lower-alpha">
<li>與上面用同樣的模型，但是觀察人數變爲 <span class="math inline">\(100\)</span> 人 患病人數爲 <span class="math inline">\(30\)</span> 人，試作對數似然比方程之圖形，與上圖對比：</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-30-100-logllr"></span>
<img src="bookdown_files/figure-html/bin3-10-30-100-logllr-1.png" alt="Binomial log-likelihood ratio function 3 out of 10 and 30 out of 100 subjects" width="90%" />
<p class="caption">
圖 13.6: Binomial log-likelihood ratio function 3 out of 10 and 30 out of 100 subjects
</p>
</div>
<p>可以看出，兩組數據的 MLE 都是一致的， <span class="math inline">\(\hat\pi=0.3\)</span>，但是對數似然比方程圖形在 樣本量爲 <span class="math inline">\(n=100\)</span> 時比 <span class="math inline">\(n=10\)</span> 時窄很多，由此產生的似然比信賴區間也就窄很多(精確很多) 。所以對數似然比方程的曲率(二階導數) ，反映了觀察獲得數據提供的對總體參數 <span class="math inline">\(\pi\)</span> 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。</p>
</div>
<div id="q3" class="section level3">
<h3><span class="header-section-number">13.5.3</span> Q3</h3>
<p>在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 <span class="math inline">\(95\%\)</span> 信賴區間。</p>
<p><strong>解</strong></p>
<p><span class="math display">\[\begin{aligned}
 d = 8, \;p &amp;= 160\; person\cdot year \\
  \Rightarrow D\sim Poi(\mu &amp;=\lambda p) \\
 L(\lambda|data) &amp;= Prob(D=d=8) \\
   &amp;=  e^{-\mu}\frac{\mu^d}{d!} \\
   &amp;=   e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\
  omitting&amp;\;terms\;not\;in\;\lambda \\
   &amp;= e^{-\lambda p}\lambda^d \\
\Rightarrow \ell(\lambda|data)&amp;= \text{log}(e^{-\lambda p}\lambda^d) \\
     &amp;= d\cdot \text{log}(\lambda)-\lambda p \\
     &amp; = 8\times \text{log}(\lambda) - 160\times\lambda
\end{aligned}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:Poi-llr-8-160"></span>
<img src="bookdown_files/figure-html/Poi-llr-8-160-1.png" alt="Poisson log-likelihood ratio function
 8 events in 160 person-years" width="90%" />
<p class="caption">
圖 13.7: Poisson log-likelihood ratio function 8 events in 160 person-years
</p>
</div>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
lambda
</th>
<th style="text-align:right;">
LogLR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.010
</td>
<td style="text-align:right;">
-6.4755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-5.8730
</td>
</tr>
<tr>
<td style="text-align:right;">
0.012
</td>
<td style="text-align:right;">
-5.3369
</td>
</tr>
<tr>
<td style="text-align:right;">
0.013
</td>
<td style="text-align:right;">
-4.8566
</td>
</tr>
<tr>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
-4.4237
</td>
</tr>
<tr>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
-4.0318
</td>
</tr>
<tr>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
-3.6755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.017
</td>
<td style="text-align:right;">
-3.3505
</td>
</tr>
<tr>
<td style="text-align:right;">
0.018
</td>
<td style="text-align:right;">
-3.0532
</td>
</tr>
<tr>
<td style="text-align:right;">
0.019
</td>
<td style="text-align:right;">
-2.7807
</td>
</tr>
<tr>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
-2.5303
</td>
</tr>
<tr>
<td style="text-align:right;">
0.021
</td>
<td style="text-align:right;">
-2.3000
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.022
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-2.0878
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.023
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.8922
</td>
</tr>
<tr>
<td style="text-align:right;">
0.024
</td>
<td style="text-align:right;">
-1.7118
</td>
</tr>
<tr>
<td style="text-align:right;">
0.025
</td>
<td style="text-align:right;">
-1.5452
</td>
</tr>
<tr>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
-1.3914
</td>
</tr>
<tr>
<td style="text-align:right;">
0.027
</td>
<td style="text-align:right;">
-1.2495
</td>
</tr>
<tr>
<td style="text-align:right;">
0.028
</td>
<td style="text-align:right;">
-1.1185
</td>
</tr>
<tr>
<td style="text-align:right;">
0.029
</td>
<td style="text-align:right;">
-0.9978
</td>
</tr>
<tr>
<td style="text-align:right;">
0.030
</td>
<td style="text-align:right;">
-0.8866
</td>
</tr>
<tr>
<td style="text-align:right;">
0.031
</td>
<td style="text-align:right;">
-0.7843
</td>
</tr>
<tr>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
-0.6903
</td>
</tr>
<tr>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
-0.6041
</td>
</tr>
<tr>
<td style="text-align:right;">
0.034
</td>
<td style="text-align:right;">
-0.5253
</td>
</tr>
<tr>
<td style="text-align:right;">
0.035
</td>
<td style="text-align:right;">
-0.4534
</td>
</tr>
<tr>
<td style="text-align:right;">
0.036
</td>
<td style="text-align:right;">
-0.3880
</td>
</tr>
<tr>
<td style="text-align:right;">
0.037
</td>
<td style="text-align:right;">
-0.3288
</td>
</tr>
<tr>
<td style="text-align:right;">
0.038
</td>
<td style="text-align:right;">
-0.2755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.039
</td>
<td style="text-align:right;">
-0.2277
</td>
</tr>
<tr>
<td style="text-align:right;">
0.040
</td>
<td style="text-align:right;">
-0.1851
</td>
</tr>
<tr>
<td style="text-align:right;">
0.041
</td>
<td style="text-align:right;">
-0.1476
</td>
</tr>
<tr>
<td style="text-align:right;">
0.042
</td>
<td style="text-align:right;">
-0.1148
</td>
</tr>
<tr>
<td style="text-align:right;">
0.043
</td>
<td style="text-align:right;">
-0.0866
</td>
</tr>
<tr>
<td style="text-align:right;">
0.044
</td>
<td style="text-align:right;">
-0.0627
</td>
</tr>
<tr>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
-0.0429
</td>
</tr>
<tr>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
-0.0271
</td>
</tr>
<tr>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
-0.0150
</td>
</tr>
<tr>
<td style="text-align:right;">
0.048
</td>
<td style="text-align:right;">
-0.0066
</td>
</tr>
<tr>
<td style="text-align:right;">
0.049
</td>
<td style="text-align:right;">
-0.0016
</td>
</tr>
<tr>
<td style="text-align:right;">
0.050
</td>
<td style="text-align:right;">
0.0000
</td>
</tr>
<tr>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
-0.0016
</td>
</tr>
<tr>
<td style="text-align:right;">
0.052
</td>
<td style="text-align:right;">
-0.0062
</td>
</tr>
<tr>
<td style="text-align:right;">
0.053
</td>
<td style="text-align:right;">
-0.0138
</td>
</tr>
<tr>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
-0.0243
</td>
</tr>
<tr>
<td style="text-align:right;">
0.055
</td>
<td style="text-align:right;">
-0.0375
</td>
</tr>
<tr>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
-0.0534
</td>
</tr>
<tr>
<td style="text-align:right;">
0.057
</td>
<td style="text-align:right;">
-0.0718
</td>
</tr>
<tr>
<td style="text-align:right;">
0.058
</td>
<td style="text-align:right;">
-0.0926
</td>
</tr>
<tr>
<td style="text-align:right;">
0.059
</td>
<td style="text-align:right;">
-0.1159
</td>
</tr>
<tr>
<td style="text-align:right;">
0.060
</td>
<td style="text-align:right;">
-0.1414
</td>
</tr>
<tr>
<td style="text-align:right;">
0.061
</td>
<td style="text-align:right;">
-0.1692
</td>
</tr>
<tr>
<td style="text-align:right;">
0.062
</td>
<td style="text-align:right;">
-0.1991
</td>
</tr>
<tr>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
-0.2311
</td>
</tr>
<tr>
<td style="text-align:right;">
0.064
</td>
<td style="text-align:right;">
-0.2651
</td>
</tr>
<tr>
<td style="text-align:right;">
0.065
</td>
<td style="text-align:right;">
-0.3011
</td>
</tr>
<tr>
<td style="text-align:right;">
0.066
</td>
<td style="text-align:right;">
-0.3389
</td>
</tr>
<tr>
<td style="text-align:right;">
0.067
</td>
<td style="text-align:right;">
-0.3786
</td>
</tr>
<tr>
<td style="text-align:right;">
0.068
</td>
<td style="text-align:right;">
-0.4201
</td>
</tr>
<tr>
<td style="text-align:right;">
0.069
</td>
<td style="text-align:right;">
-0.4633
</td>
</tr>
<tr>
<td style="text-align:right;">
0.070
</td>
<td style="text-align:right;">
-0.5082
</td>
</tr>
<tr>
<td style="text-align:right;">
0.071
</td>
<td style="text-align:right;">
-0.5547
</td>
</tr>
<tr>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
-0.6029
</td>
</tr>
<tr>
<td style="text-align:right;">
0.073
</td>
<td style="text-align:right;">
-0.6525
</td>
</tr>
<tr>
<td style="text-align:right;">
0.074
</td>
<td style="text-align:right;">
-0.7037
</td>
</tr>
<tr>
<td style="text-align:right;">
0.075
</td>
<td style="text-align:right;">
-0.7563
</td>
</tr>
<tr>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
-0.8103
</td>
</tr>
<tr>
<td style="text-align:right;">
0.077
</td>
<td style="text-align:right;">
-0.8657
</td>
</tr>
<tr>
<td style="text-align:right;">
0.078
</td>
<td style="text-align:right;">
-0.9225
</td>
</tr>
<tr>
<td style="text-align:right;">
0.079
</td>
<td style="text-align:right;">
-0.9806
</td>
</tr>
<tr>
<td style="text-align:right;">
0.080
</td>
<td style="text-align:right;">
-1.0400
</td>
</tr>
<tr>
<td style="text-align:right;">
0.081
</td>
<td style="text-align:right;">
-1.1006
</td>
</tr>
<tr>
<td style="text-align:right;">
0.082
</td>
<td style="text-align:right;">
-1.1624
</td>
</tr>
<tr>
<td style="text-align:right;">
0.083
</td>
<td style="text-align:right;">
-1.2255
</td>
</tr>
<tr>
<td style="text-align:right;">
0.084
</td>
<td style="text-align:right;">
-1.2896
</td>
</tr>
<tr>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
-1.3550
</td>
</tr>
<tr>
<td style="text-align:right;">
0.086
</td>
<td style="text-align:right;">
-1.4214
</td>
</tr>
<tr>
<td style="text-align:right;">
0.087
</td>
<td style="text-align:right;">
-1.4889
</td>
</tr>
<tr>
<td style="text-align:right;">
0.088
</td>
<td style="text-align:right;">
-1.5575
</td>
</tr>
<tr>
<td style="text-align:right;">
0.089
</td>
<td style="text-align:right;">
-1.6271
</td>
</tr>
<tr>
<td style="text-align:right;">
0.090
</td>
<td style="text-align:right;">
-1.6977
</td>
</tr>
<tr>
<td style="text-align:right;">
0.091
</td>
<td style="text-align:right;">
-1.7693
</td>
</tr>
<tr>
<td style="text-align:right;">
0.092
</td>
<td style="text-align:right;">
-1.8419
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.093
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.9154
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.094
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.9898
</td>
</tr>
<tr>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
-2.0652
</td>
</tr>
<tr>
<td style="text-align:right;">
0.096
</td>
<td style="text-align:right;">
-2.1414
</td>
</tr>
<tr>
<td style="text-align:right;">
0.097
</td>
<td style="text-align:right;">
-2.2185
</td>
</tr>
<tr>
<td style="text-align:right;">
0.098
</td>
<td style="text-align:right;">
-2.2964
</td>
</tr>
<tr>
<td style="text-align:right;">
0.099
</td>
<td style="text-align:right;">
-2.3752
</td>
</tr>
<tr>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
-2.4548
</td>
</tr>
</tbody>
</table>
<p>所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。</p>
</div>
</div>
</div>
<div id="quadratic-llr" class="section level1">
<h1><span class="header-section-number">第 14 章</span> 二次方程近似法求對數似然比 approximate log-likelihood ratios</h1>
<p>爲什麼要用二次方程近似對數似然比方程？</p>
<ol style="list-style-type: decimal">
<li>上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (Section <a href="02-Inference.html#binomial-ex">13.4.1</a>: binomial example)。</li>
<li>我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。</li>
<li>所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。</li>
</ol>
<div id="quadratic-llr2" class="section level2">
<h2><span class="header-section-number">14.1</span> 正態近似法求對數似然 Normal approximation to the log-likelihood</h2>
<p>根據前一節 (Section <a href="02-Inference.html#normal-ex">13.4.2</a>)，如果樣本均數的分佈符合正態分佈：<span class="math inline">\(\bar{X}\sim N(\mu, \sigma^2/n)\)</span>。那麼樣本均數的對數似然比爲：</p>
<p><span class="math display">\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]</span></p>
<p>其中， <span class="math inline">\(\bar{x}\)</span> 是正態分佈總體均數 <span class="math inline">\(\mu\)</span> 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 <span class="math inline">\(\sigma/\sqrt{n}\)</span> 是 <span class="math inline">\(\bar{x}\)</span> 的標準誤 (standard error)。</p>
<p>因此，假設 <span class="math inline">\(\theta\)</span> 是我們想尋找的總體參數。有些人提議可以使用下面的關於 <span class="math inline">\(\theta\)</span> 的二次方程來做近似：</p>
<p><span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></p>
<p>上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， <span class="math inline">\(M\)</span> 的標準誤爲 <span class="math inline">\(S\)</span>。如果我們正確地選用 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>，那我們就可以用這樣的方程來近似求真實觀察數據的似然 <span class="math inline">\(\ell(\theta|data)\)</span>。</p>
<p>通過近似正態對數似然比，<span class="math inline">\(M\)</span> 應當選用使方程取最大值時，參數 <span class="math inline">\(\theta\)</span> 的極大似然估計 <span class="math inline">\(M=\hat{\Theta}\)</span>。</p>
<p>但是在選用標準誤 <span class="math inline">\(S\)</span> 上必須滿足下列條件：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(S\)</span> 是極大似然估計 <span class="math inline">\(\hat{\Theta}\)</span> 的標準誤。</li>
<li>被選擇的 <span class="math inline">\(S\)</span> 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率(二階導數) 。</li>
</ol>
<p>由於，一個方程的曲率是該方程的二階導數(斜線斜率變化的速度) 。所以對數似然比方程在 MLE 取最大值時的曲率(二階導數) 爲：</p>
<p><span class="math display">\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]</span></p>
<p>在正態分佈的例子下，<span class="math inline">\(M=\bar{x}, S=\sigma/\sqrt{n}\)</span>。對數似然比方程最大值時的曲率(二階導數) 恰好就爲標準誤的平方的負倒數：</p>
<p><span class="math inline">\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)</span> <span class="math inline">\(\Rightarrow\)</span> 被叫做 <strong>Fisher information</strong>。</p>
<p>稍微總結一下：</p>
<ol style="list-style-type: decimal">
<li>任意的對數似然比方程 <span class="math inline">\(llr(\theta)\)</span> 都可以考慮用一個二次方程來近似： <span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></li>
<li>其中<br> <span class="math inline">\(\begin{aligned} &amp;M=\hat\theta\\ &amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\ &amp;when \\  &amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases} \end{aligned}\)</span></li>
</ol>
<div id="近似法估算對數似然比的信賴區間" class="section level3">
<h3><span class="header-section-number">14.1.1</span> 近似法估算對數似然比的信賴區間</h3>
<p>一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：</p>
<p><span class="math display">\[-2f(\theta)&lt;\mathcal{X}_{1,(1-\alpha)}^2\]</span></p>
<p>故信賴區間爲： <span class="math inline">\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)</span>。求<span class="math inline">\(95\%\)</span> 水平的信賴區間時，<span class="math inline">\(\mathcal{X}_{1,0.95}^2=3.84\)</span>，所以就又看到了熟悉的 <span class="math inline">\(M\pm1.96S\)</span>。</p>
</div>
<div id="以泊松分佈爲例" class="section level3">
<h3><span class="header-section-number">14.1.2</span> 以泊松分佈爲例</h3>
<p>一個被追蹤的樣本，經過了 <span class="math inline">\(p\)</span> 人年的觀察，記錄到了 <span class="math inline">\(d\)</span> 個我們要研究的事件：</p>
<p><span class="math display">\[D\sim Poi(\mu), where \mu=\lambda p\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)，之前介紹似然方程時推導過的泊松分佈的似然方程 (Section <a href="02-Inference.html#likelihood-poi">12.6</a>)：</p>
<p><span class="math display">\[\begin{aligned}
P(D=d|\lambda) &amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;\Rightarrow \ell(\lambda) = d\text{log}\lambda - \lambda p \\
&amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]</span></p>
<p>Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]</span></p>
<p>Step 3. 把前兩部求得的 <span class="math inline">\(MLE\)</span> 和 <span class="math inline">\(S^2\)</span> 代入近似的二次方程：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp; using\;approximate\;quadratic\;llr \\
&amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp; let \; q(\lambda)=-1.92\\
&amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]</span></p>
<p>結論就是： 發病(死亡) 率 <span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間爲： <span class="math inline">\(M\pm1.96S\)</span>。所以我們不需要每次都代入對數似然比方程，只要算出 <span class="math inline">\(MLE = M\)</span> 和 <span class="math inline">\(S\)</span> 之後代入這個公式就可以用二次方程近似法算出信賴區間。</p>
</div>
<div id="quadratic-binomial-approx" class="section level3">
<h3><span class="header-section-number">14.1.3</span> 以二項分佈爲例</h3>
<p><span class="math display">\[K\sim Bin(n,\pi)\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;omitting\;terms\;not\;in\;\pi \\
&amp;\Rightarrow \ell(\pi) = k\:\text{log}\pi+(n-k)\text{log}(1-\pi) \\
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]</span></p>
<p>Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &lt;0 \\
&amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;=\frac{p(1-p)}{n}\\
&amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]</span></p>
<p>Step 3. 將求得的 MLE 和 <span class="math inline">\(S^2\)</span> 代入近似信賴區間：</p>
<p><span class="math display">\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]</span></p>
</div>
</div>
<div id="para-trans" class="section level2">
<h2><span class="header-section-number">14.2</span> 參數转换 parameter transformations</h2>
<p>如果將參數 <span class="math inline">\(\theta\)</span> 通過某種數學方程轉化成 <span class="math inline">\(g(\theta)\)</span>，那麼我們可以認爲，轉化後的方程的 MLE 爲 <span class="math inline">\(g(\hat\theta)\)</span>，其中 <span class="math inline">\(\hat\theta\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的 MLE。</p>
<p>類似地，如果 <span class="math inline">\(\theta_1 \sim \theta_2\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的似然比信賴區間，那麼 <span class="math inline">\(g(\theta_1)\sim g(\theta_2)\)</span> 就是 <span class="math inline">\(g(\theta)\)</span> 的似然比信賴區間。</p>
<p>以下爲轉換參數以後獲取信賴區間的步驟：</p>
<ol style="list-style-type: decimal">
<li>將參數通過某些數學方程(通常是取對數) 轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。<br> Transform parameter so that <span class="math inline">\(llr\)</span> is closer to a quadratic shape.</li>
<li>用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 <br> Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.</li>
<li>將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。<br> Transform the confidence intervals back, or to any scale we wish – they remain valid.</li>
</ol>
<div id="Possion-log-transform" class="section level3">
<h3><span class="header-section-number">14.2.1</span> 以泊松分佈爲例</h3>
<p>當我們用泊松分佈模擬事件在某段時間內發生率 <span class="math inline">\(\lambda\)</span> 時，注意到這個事件發生率必須滿足 <span class="math inline">\(\lambda&gt;0\)</span>。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 <span class="math inline">\(\lambda \rightarrow \text{log}(\lambda)\)</span> 此時 <span class="math inline">\(\text{log}(\lambda)\)</span> 就不再被限制與 <span class="math inline">\(&gt;0\)</span>。下面我們嘗試尋找對數轉換過後的 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>。</p>
<p>令 <span class="math inline">\(\beta=\text{log}(\lambda), \Rightarrow e^\beta=\lambda\)</span> 從本文上半部分中我們已知 <span class="math inline">\(\hat\lambda=\frac{d}{p}\)</span>。</p>
<ul>
<li>對數轉換以後的 <span class="math inline">\(M\)</span> 是什麼? <br>根據定義，<span class="math inline">\(MLE(\beta)=MLE[\text{log}(\lambda)]=\text{log}(\hat\lambda)\)</span> <span class="math inline">\(\Rightarrow M=\hat\beta=\text{log}(\frac{d}{p})\)</span></li>
<li><p>對數轉換以後的 <span class="math inline">\(S\)</span> 是什麼? <br> 泊松分佈的對數似然方程是：<span class="math inline">\(\ell(\lambda|d)=d \text{log}(\lambda) - \lambda p\)</span> 用 <span class="math inline">\(\beta\)</span> 替換掉 <span class="math inline">\(\lambda\)</span></p>
<span class="math inline">\(\begin{aligned} &amp; \ell(\beta|d)=d \beta - pe^\beta\\ &amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\ &amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{\text{log}(d/p)}}\\ &amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)</span></li>
<li><p>轉換後的近似二次方程：<br> <span class="math inline">\(\begin{aligned} &amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-\text{log}(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2 \end{aligned}\)</span></p></li>
<li><p><span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=\text{log}(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)</span></p></li>
<li><p><span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=exp(\text{log}(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)</span></p></li>
</ul>
</div>
<div id="以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">14.2.2</span> 以二項分佈爲例</h3>
<p>在研究對象 <span class="math inline">\(n\)</span> 人中觀察到 <span class="math inline">\(k\)</span> 個人患有某種<del>中二</del>疾病。</p>
<p>令 <span class="math inline">\(\beta=\text{log}(\pi) \Rightarrow \pi=e^\beta\)</span> 從上文的推倒也已知 <span class="math inline">\(\hat\pi=\frac{k}{n}=p\)</span></p>
<p><span class="math inline">\(\begin{aligned} &amp;\Rightarrow \ell(\beta)=k\text{log}\pi+(n-k)\text{log}(1-\pi)=k\beta+(n-k)\text{log}(1-e^\beta) \\ &amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;\because \hat\beta=\text{log}(\hat\pi) \\ &amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)</span></p>
</div>
</div>
<div id="練習題-1" class="section level2">
<h2><span class="header-section-number">14.3</span> 練習題</h2>
<div id="q1-1" class="section level3">
<h3><span class="header-section-number">14.3.1</span> Q1</h3>
<ol style="list-style-type: lower-alpha">
<li>在<span class="math inline">\(n=100\)</span>人中觀察到有<span class="math inline">\(k=40\)</span>人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，<span class="math inline">\(\pi\)</span> 爲患病的概率。下面是 <span class="math inline">\(\pi \in [0.2,0.6]\)</span> 區間的對數似然比方程曲線。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.2</span>, <span class="fl">0.6</span>, <span class="dt">by=</span><span class="fl">0.01</span>)
L &lt;-<span class="st"> </span>(pi<span class="op">^</span><span class="dv">40</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>pi)<span class="op">^</span><span class="dv">60</span>)
Lmax &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">max</span>(L), <span class="dv">41</span>)
LR &lt;-<span class="st"> </span>L<span class="op">/</span>Lmax
logLR &lt;-<span class="st"> </span><span class="kw">log</span>(LR)

<span class="kw">plot</span>(pi, logLR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;logLR(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">2</span>) <span class="co"># add some horizontal grid on the background</span>
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">12</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin-llr-40-100"></span>
<img src="bookdown_files/figure-html/bin-llr-40-100-1.png" alt="Binomial log-likelihood ratio between 0.2-0.6" width="90%" />
<p class="caption">
圖 14.1: Binomial log-likelihood ratio between 0.2-0.6
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#title(main = &quot;Figure 1. Binomial log-likelihood ratio&quot;)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>用一個二次方程來模擬上面的對數似然比曲線：<span class="math inline">\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)</span>，其中 <span class="math inline">\(M=\hat\pi=\frac{k}{n}=0.4\)</span>，<span class="math inline">\(S^2=\frac{p(1-p)}{n}=0.0024\)</span></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mai =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.7</span>))
quad &lt;-<span class="st"> </span><span class="op">-</span>(pi<span class="fl">-0.4</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.0024</span>)
<span class="kw">plot</span>(pi, quad, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">lines</span>(pi, logLR, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)
<span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">4</span>, <span class="dt">lwd =</span> <span class="dv">1</span>) <span class="co"># add some horizontal grid on the background</span>
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="co">#title(main = &quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&quot;)</span>
<span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="dt">x=</span><span class="fl">0.27</span>, <span class="dt">y=</span> <span class="fl">-5.5</span> ,<span class="dt">xpd =</span> <span class="ot">TRUE</span>,  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;logLR&quot;</span>,<span class="st">&quot;Quadratic&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,
       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>), <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">horiz =</span> <span class="ot">TRUE</span>) <span class="co">#the legend is below the graph</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin-1.png" alt="Quadratic approximation
 of binomial log-likelihood ratio 40 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.2: Quadratic approximation of binomial log-likelihood ratio 40 out of 100 subjects
</p>
</div>
</div>
<div id="q2-1" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Q2</h3>
<p>依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。</p>
<ol style="list-style-type: decimal">
<li>類比上面的問題，用同樣的 <span class="math inline">\(\hat\pi=0.4\)</span>，但是 <span class="math inline">\(n=10, k=4\)</span> 時的圖形：</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mai =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.7</span>))
pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.0</span>, <span class="fl">0.85</span>, <span class="dt">by=</span><span class="fl">0.01</span>)
L &lt;-<span class="st"> </span>(pi<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>pi)<span class="op">^</span><span class="dv">6</span>)
logLR &lt;-<span class="st"> </span><span class="kw">log</span>(L<span class="op">/</span><span class="kw">max</span>(L))

quad &lt;-<span class="st"> </span><span class="op">-</span>(pi<span class="fl">-0.4</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">/</span><span class="dv">10</span>)
<span class="kw">plot</span>(pi, quad, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,
     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)
<span class="kw">lines</span>(pi, logLR, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)
<span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">4</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)
<span class="co">#title(main = &quot;Figure 3. Quadratic approximation\n of binomial log-likelihood ratio\n 4 out of 10 subjects&quot;)</span>
<span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">2</span>)

<span class="kw">legend</span>(<span class="dt">x=</span><span class="fl">0.17</span>, <span class="dt">y=</span> <span class="fl">-6.5</span> ,<span class="dt">xpd =</span> <span class="ot">TRUE</span>,  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;logLR&quot;</span>,<span class="st">&quot;Quadratic&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,
       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>), <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">horiz =</span> <span class="ot">TRUE</span>) <span class="co">#the legend is below the graph</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin4-10"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin4-10-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 4 out of 10 subjects" width="90%" />
<p class="caption">
圖 14.3: Quadratic approximation of binomial log-likelihood ratio 4 out of 10 subjects
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.4, n=1000, k=400\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin400-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin400-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 400 out of 1000 subjects" width="90%" />
<p class="caption">
圖 14.4: Quadratic approximation of binomial log-likelihood ratio 400 out of 1000 subjects
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=100, k=1\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。</p>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin1-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin1-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 1 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.5: Quadratic approximation of binomial log-likelihood ratio 1 out of 100 subjects
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=1000, k=10\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin10-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin10-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 10 out of 1000 subjects" width="90%" />
<p class="caption">
圖 14.6: Quadratic approximation of binomial log-likelihood ratio 10 out of 1000 subjects
</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=10000, k=100\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin100-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin100-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 100 out of 10000 subjects" width="90%" />
<p class="caption">
圖 14.7: Quadratic approximation of binomial log-likelihood ratio 100 out of 10000 subjects
</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.99, n=100, k=99\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。</p>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin99-100"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin99-100-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 99 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.8: Quadratic approximation of binomial log-likelihood ratio 99 out of 100 subjects
</p>
</div>
<p>總結： 二次方程近似時，在二項分佈的情況下，隨着 <span class="math inline">\(n, k\)</span> 增加，近似越理想。</p>
</div>
</div>
</div>
<div id="假設檢驗的構建-construction-of-a-hypothesis-test" class="section level1">
<h1><span class="header-section-number">第 15 章</span> 假設檢驗的構建 Construction of a hypothesis test</h1>
<div id="null-and-alter" class="section level2">
<h2><span class="header-section-number">15.1</span> 什麼是假設檢驗 Hypothesis testing</h2>
<p>一般來說，我們的<strong>假設</strong>(或者叫<strong>假說</strong>) 是對與我們實驗觀察數據來自的總體(或人羣) 的<strong>概率分佈</strong>的描述。在參數檢驗的背景下，就是要檢驗描述這個總體(或人羣) 的<strong>概率分佈</strong>的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作<strong>零假設</strong>(或者叫<strong>原假設</strong>) ，null hypothesis (<span class="math inline">\(H_0\)</span>)；另一個是與之對應的(互補的) 替代假設，althernative hypothesis (<span class="math inline">\(H_1/H_A\)</span>)。</p>
<p>例如，若 <span class="math inline">\(X\)</span> 是一個服從二項分佈的隨機離散變量 <span class="math inline">\(X\sim Bin(5, \theta)\)</span>。可以考慮如下的零假設和替代假設：<span class="math inline">\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)</span>。</p>
<p>當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定：</p>
<ol style="list-style-type: decimal">
<li>從樣本中計算所得的參數估計值爲多少時，拒絕零假設。(接受替代假設爲“真”)</li>
<li>從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。(接受零假設爲“真”)</li>
</ol>
<p>注意：(這一段很繞)</p>
<p>上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的(不對稱的) 假設：即簡單的 <span class="math inline">\(H_0\)</span>，複雜的 <span class="math inline">\(H_1\)</span>。如此一來當零假設 <span class="math inline">\(H_0\)</span> 不被拒絕時，我們並不一定就接受之。因爲無證據證明 <span class="math inline">\(H_1\)</span> 不等於有證據證明 <span class="math inline">\(H_0\)</span>。<strong>(Absence of evidence is not evidence of absence).</strong> 換句話說，無證據讓我們拒絕 <span class="math inline">\(H_0\)</span> 本身並不成爲支持 <span class="math inline">\(H_0\)</span> 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。</p>
<p>在樣本空間 sample space 中，決定了零假設 <span class="math inline">\(H_0\)</span> 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 <span class="math inline">\(\mathfrak{R}\)</span> 來標記。</p>
</div>
<div id="錯誤概率和效能方程-error-probabilities-and-the-power-function" class="section level2">
<h2><span class="header-section-number">15.2</span> 錯誤概率和效能方程 error probabilities and the power function</h2>
<p>這一部分也可以參考本書臨牀試驗樣本量計算 (Section <a href="05-clinical-trials.html#sample-size">33</a>) 部分。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 15.1 : Definition of Type I and Type II error
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="2">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
SAMPLE
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(\underline{x} \notin \mathfrak{R}\)</span> Accept <span class="math inline">\(H_0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\underline{x} \in \mathfrak{R}\)</span> Reject <span class="math inline">\(H_0\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;vertical-align: middle !important;" rowspan="2">
TRUTH
</td>
<td style="text-align:center;">
<span class="math inline">\(H_0\)</span> is true
</td>
<td style="text-align:center;">
<span class="math inline">\(\checkmark\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\alpha\)</span> <br> Type I error
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(H_1\)</span> is true
</td>
<td style="text-align:center;">
<span class="math inline">\(\beta\)</span> <br> Type II error
</td>
<td style="text-align:center;">
<span class="math inline">\(\checkmark\)</span>
</td>
</tr>
</tbody>
</table>
<p>假如一個假設檢驗是關於總體參數 <span class="math inline">\(\theta\)</span> 的：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta=\theta_1 \]</span></p>
<p>這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率(該檢驗方法能夠檢驗出有真實差別的能力) ：</p>
<p><span class="math display">\[\text{Power}=\text{Prob}(\underline{x}\in\mathfrak{R}|H_1\text{ is true}) = 1-\text{Prob}(\text{Type II error})\]</span></p>
<p>觀察數據只有兩種可能：落在拒絕域內，或者落在拒絕域之外。第二類錯誤我們常常使用 <span class="math inline">\(\beta\)</span> 來表示，所以 <span class="math inline">\(\text{Power}=1-\beta\)</span>。</p>
<p>檢驗的顯著性水平用 <span class="math inline">\(\alpha\)</span> 來表示。<span class="math inline">\(\alpha\)</span> 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 <span class="math inline">\(H_0\)</span>，接受了替代假設 <span class="math inline">\(H_1\)</span>，即假陽性的概率。</p>
<p><span class="math display">\[\text{Prob}(\underline{x}\in \mathfrak{R} |H_0 \text{ is true})=\text{Prob(Type I error)}\]</span></p>
<div id="以二項分佈爲例-1" class="section level3">
<h3><span class="header-section-number">15.2.1</span> 以二項分佈爲例</h3>
<p>用本文開頭的例子： <span class="math inline">\(X\sim Bin(5,\theta)\)</span>。和我們建立的零假設和替代假設：<span class="math inline">\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)</span>：</p>
<p>考慮兩種檢驗方法：</p>
<ol style="list-style-type: decimal">
<li>A 方法：當且僅當5次觀察都爲“成功”時才拒絕 <span class="math inline">\(H_0 (\text{i.e.}\; X=5)\)</span>。所以此時判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲 <span class="math inline">\(5\)</span>。檢驗效能 <span class="math inline">\(\text{Power}=1-\beta\)</span> 爲：<span class="math inline">\(Prob(X=5|H_1 \text{ is true})=(\frac{2}{3})^5=0.1317\)</span>。顯著性水平 <span class="math inline">\(\alpha\)</span> 爲 <span class="math inline">\(Prob(X=5|H_0 \text{ is true})=(\frac{1}{2})^5=0.03125\)</span>。</li>
<li>B 方法：當觀察到3,4,5次“成功”時，拒絕 <span class="math inline">\(H_0 (\text{i.e.} X=3,4,5)\)</span>。此時判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲 <span class="math inline">\(3,4,5\)</span>。檢驗效能 <span class="math inline">\(Power\)</span> 爲：<span class="math inline">\(Prob(X=3,4,\text{ or }5|H_1 \text{ is ture})=\sum_{i=3}^5(\frac{2}{3})^i(\frac{1}{3})^{5-i}\approx0.7901\)</span>；顯著性水平 <span class="math inline">\(\alpha\)</span> 爲：<span class="math inline">\(Prob(X=3,4,5|H_0 \text{ is true})=\sum_{i=3}^5(\frac{1}{2})^i(\frac{1}{2})^{5-i}=0.5\)</span></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the power in test B</span>
<span class="kw">dbinom</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 0.7901</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the size in test B</span>
<span class="kw">dbinom</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)</code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果(犯第一類錯誤，錯誤地拒絕 <span class="math inline">\(H_0\)</span>，接受 <span class="math inline">\(H_1\)</span>)，但是也有更高的檢驗效能 <span class="math inline">\(1-\beta\)</span>(真陽性更高) 。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 <span class="math inline">\(\alpha=0.05\)</span>，然後儘可能選擇檢驗效能最高的檢驗方法。</p>
</div>
</div>
<div id="Neyman-Pearson" class="section level2">
<h2><span class="header-section-number">15.3</span> 如何選擇要檢驗的統計量</h2>
<p>在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。</p>
<p>幸運地是，當明確了零假設和替代假設後，我們可以利用 <a href="https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma">Neyman-Pearson lemma</a> 似然比公式<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>:</p>
<p>來決定使用哪個統計量做檢驗<strong>最有效</strong>：</p>
<p><span class="math display">\[\text{Neyman-Pearson lemma}=\frac{L_{H_0}}{L_{H_1}}\]</span></p>
<p>這公式很直觀，因爲當觀察數據更加支持 <span class="math inline">\(H_1\)</span> 時 (<span class="math inline">\(L_{H_1}\)</span> 更大)，<span class="math inline">\(H_0\)</span> 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，實際計算時我們常使用對數似然比：<span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span>。</p>
<p>問題來了，那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定：</p>
<ol style="list-style-type: decimal">
<li>被檢驗統計量的樣本分佈 (the sampling distribution of the test statistic)</li>
<li>第一類錯誤概率 <span class="math inline">\(\alpha\)</span> (the required value of <span class="math inline">\(\alpha\)</span>)</li>
</ol>
<div id="以已知方差的正態分佈爲例" class="section level3">
<h3><span class="header-section-number">15.3.1</span> 以已知方差的正態分佈爲例</h3>
<p>假如已知 <span class="math inline">\(X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span> 而且方差 <span class="math inline">\(\sigma^2\)</span> 也是已知的。如果令 <span class="math inline">\(H_0: \mu=5\; ;H_1: \mu=10\)</span> 可以通過如下的方法找到我們需要的最佳檢驗統計量 <u>best statistic</u> 根據之前的推導 (Section <a href="02-Inference.html#llr">13</a>) 可知正態分佈的似然方程如下：</p>
<p><span class="math display">\[\ell(\mu|\underline{x}) =-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\]</span></p>
<p>所以已知 <span class="math inline">\(\sigma^2\)</span> 時，我們的零假設和替代假設之間的對數似然比 <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> 爲:</p>
<p><span class="math display">\[\ell_{H_0}-\ell_{H_1}=-\frac{1}{2\sigma^2}(\sum_{i=1}^n(x_i-5)^2-\sum_{i=1}^n(x_i-10)^2)\]</span></p>
<p>然而，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>：</p>
<p><span class="math display">\[
\begin{aligned}
\ell_{H_0}-\ell_{H_1} &amp; = -(\sum_{i=1}^n(x_i-5)^2-\sum_{i=i}^n(x_i-10)^2)\\
                &amp; = 75n - 2\times(10-5)\sum_{i=1}^nx_i \\
\end{aligned}
\]</span></p>
<p>所以只要樣本和 (sum of sample) <span class="math inline">\(\sum_{i=1}^nx_i\)</span> <u>(最佳統計量 best statistic)</u> 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。爲了方便我們就用樣本均數 <span class="math inline">\(\frac{1}{n}\sum_{i=1}^nx_i\)</span> 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 (判別區域) 。</p>
</div>
</div>
<div id="複合假設-composite-hypotheses" class="section level2">
<h2><span class="header-section-number">15.4</span> 複合假設 composite hypotheses</h2>
<p>目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \theta=\theta_0 \;\text{v.s.}\; H_1: \theta&gt;\theta_0\)</span> [<strong>單側</strong>的替代假設]</li>
<li><span class="math inline">\(H_0: \theta=\theta_0 \;\text{v.s.}\; H_1: \theta\neq\theta_0\)</span> [<strong>雙側</strong>的替代假設]</li>
</ol>
<p>所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是始終如一地適用？我們一一來看：</p>
<div id="單側替代假設" class="section level3">
<h3><span class="header-section-number">15.4.1</span> 單側替代假設</h3>
<p>本章目前爲止的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 <span class="math inline">\(H_1: \mu=10\)</span> 擴展爲，任意大於 <span class="math inline">\(5\)</span> 的 <span class="math inline">\(\mu\)</span> ，即 <span class="math inline">\(\mu&gt;5\)</span> 。因爲大於 <span class="math inline">\(5\)</span> 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是<strong>樣本均值</strong>。</p>
</div>
<div id="雙側替代假設" class="section level3">
<h3><span class="header-section-number">15.4.2</span> 雙側替代假設</h3>
<p>雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：<span class="math inline">\(H_0: \mu=5 \;\text{v.s.}\; H_1: \mu&lt;5\)</span> 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。此處暫且先按下不表。</p>
</div>
</div>
<div id="爲反對零假設-h_0-的證據定量" class="section level2">
<h2><span class="header-section-number">15.5</span> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</h2>
<p>重新再考慮複合假設：<span class="math inline">\(H_0: \theta=\theta_0\;\text{v.s.}\;H_1: \theta&gt;\theta_0\)</span> 假如存在一個總是可用的最佳檢驗統計量，用 <span class="math inline">\(T\)</span> 來標記 (或 <span class="math inline">\(T(x)\)</span>)， 這個統計量足夠大時，我們拒絕 <span class="math inline">\(H_0\)</span>。 別忘了我們還要給事先固定好的顯著性水平 <span class="math inline">\(\alpha\)</span> 定義與之相關的判別區域：</p>
<p><span class="math display">\[\text{Prob}(\underline{x}\in\mathfrak{R}|H_0)=\alpha\]</span></p>
<p>如果我們知道 <span class="math inline">\(T\)</span> 的樣本分佈，我們就可以使用一個閾值 <span class="math inline">\(c\)</span> 來定義這個判別區域：</p>
<p><span class="math display">\[Prob(T\geqslant c|H_0)=\alpha\]</span></p>
<p>更加正式的，我們定義判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲：</p>
<p><span class="math display">\[\{\underline{x}:\text{Prob}(T(x)\geqslant c|H_0)=\alpha\}\]</span></p>
<p>換句話說，當統計量 <span class="math inline">\(T&gt;c\)</span> 時，我們拒絕 <span class="math inline">\(H_0\)</span> 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 <span class="math inline">\(H_0\)</span> 的證據。再考慮從觀察數據中獲得的 <span class="math inline">\(T\)</span> ，即數據告訴我們的 <span class="math inline">\(t\)</span> 。所以，當 <span class="math inline">\(t\)</span> 值越大，說明觀察值相對零假設 <span class="math inline">\(H_0\)</span> 越往極端的方向走。因此我們可以用 <span class="math inline">\(T\)</span> 的樣本分佈來計算觀察值大大於等於這個閾值(極端值) 時的概率：</p>
<p><span class="math display">\[p=\text{Prob}(T\geqslant t|H_0)\]</span></p>
<p>這個概率公式被稱爲是單側 <span class="math inline">\(p\)</span> 值 <strong>(one-side p-value)</strong>。單側 <span class="math inline">\(p\)</span> 值越小，統計量 <span class="math inline">\(T\)</span> 的樣本空間就有越小比例(越強) 的證據支持零假設 <span class="math inline">\(H_0\)</span>。</p>
<p>我們把這以思想用到假設檢驗中時，就可以認爲：</p>
<p><span class="math display">\[p&lt;\alpha \Leftrightarrow t&gt;c\]</span></p>
<p>所以用我們一貫的設定 <span class="math inline">\(\alpha=0.05\)</span>，所以如果計算獲得 <span class="math inline">\(p&lt;0.05\)</span> 我們就認爲獲得了足夠強的拒絕零假設 <span class="math inline">\(H_0\)</span> 的證據。</p>
<div id="normal-mean-compare" class="section level3">
<h3><span class="header-section-number">15.5.1</span> 回到正態分佈的均值比較問題上來(單側替代假設)</h3>
<p>繼續考慮 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span>，假設 <span class="math inline">\(\sigma^2=10\)</span>，我們要檢驗的是 <span class="math inline">\(H_0: \mu=5 \;\text{v.s}.\; H_1: \mu&gt;5\)</span></p>
<ol style="list-style-type: decimal">
<li>確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是<strong>樣本均值 <span class="math inline">\(\bar{x}\)</span></strong>。</li>
<li>確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 <span class="math inline">\(\bar{X}\sim N(\mu,\sigma^2/n)\)</span> 。<br><span class="math inline">\(\Rightarrow Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\)</span>，所以在 <span class="math inline">\(H_0\)</span> 條件下，<span class="math inline">\(\Rightarrow Z=\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}} \sim N(0,1)\)</span></li>
<li>所以當一個檢驗的顯著性水平設定爲 <span class="math inline">\(\alpha=0.05\)</span> 時，我們用判別區域 <span class="math inline">\(\mathfrak{R}\)</span>，使統計量據落在該判別區域內的概率爲 <span class="math inline">\(0.05\)</span>：<br> <span class="math inline">\(\text{Prob}(\bar{X}\geqslant c|H_0) = 0.05\)</span> <br> 已知在標準正態分佈時，<span class="math inline">\(\text{Prob}(Z\geqslant1.64)=0.05=\text{Prob}(\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}}\geqslant1.64)\)</span></li>
<li>假設樣本量是 <span class="math inline">\(10\)</span>，那麼數據的判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 就是 <span class="math inline">\(\bar{X}\geqslant6.64\)</span>。</li>
<li>假設觀察數據告訴我們，<span class="math inline">\(\bar{X}=7.76\)</span> 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，就提供了足夠的證據拒絕接受 <span class="math inline">\(H_0\)</span>。</li>
<li>我們可以給這個觀察數據計算相應的單側 <span class="math inline">\(p\)</span> 值：<br> <span class="math inline">\(p=\text{Prob}(\bar{X}\geqslant7.76|H_0)=\text{Prob}(Z+5\geqslant7.76)\\=\text{Prob}(Z\geqslant2.76)=0.003\)</span> <br> 所以，觀察數據告訴我們，在 <span class="math inline">\(H_0\)</span> 的前提下，觀察值出現的概率是 <span class="math inline">\(0.3\%\)</span> 。即，在無數次<strong>重複</strong>取樣實驗中，僅有 <span class="math inline">\(0.3\%\)</span> 的結果可以給出支持 <span class="math inline">\(H_0\)</span> 的證據。因此我們拒絕 <span class="math inline">\(H_0\)</span> 接受 <span class="math inline">\(H_1\)</span>。</li>
</ol>
</div>
</div>
<div id="雙側替代假設情況下雙側-p-值的定量方法" class="section level2">
<h2><span class="header-section-number">15.6</span> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</h2>
<div class="figure" style="text-align: center"><span id="fig:assymmetric"></span>
<img src="bookdown_files/figure-html/assymmetric-1.png" alt="Deliberately use an assymmetrical distribution to highlight the issues" width="90%" />
<p class="caption">
圖 15.1: Deliberately use an assymmetrical distribution to highlight the issues
</p>
</div>
<p>此處故意使用一個左右不對稱的概率密度分佈來解釋。</p>
<p>現在的替代假設是雙側的：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \;\text{v.s.}\; H_1:  \theta\neq\theta_0\]</span></p>
<p>正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_1: \theta&gt;\theta_0\)</span>;</li>
<li><span class="math inline">\(H_1: \theta&lt;\theta_0\)</span>.</li>
</ol>
<p>每個單側檢驗都有自己的最佳檢驗統計量。令 <span class="math inline">\(T\)</span> 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖 <a href="02-Inference.html#fig:assymmetric">15.1</a> 所示(左右不對稱) 。假如觀察數據給出的統計量爲 <span class="math inline">\(t_{\text{obs}}\)</span>，那麼在概率上反對零假設的情況可以有兩種：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(T\geqslant t_{\text{obs}}\)</span> 其中， <span class="math inline">\(\text{Prob}(T\geqslant t_{\text{obs}}|H_0)=\tilde p\)</span>;</li>
<li><span class="math inline">\(T\leqslant t^\prime\)</span> 其中，<span class="math inline">\(t^\prime\)</span> 滿足： <span class="math inline">\(\text{Prob}(T\leqslant t^\prime|H_0) =\tilde p\)</span>。(圖<a href="02-Inference.html#fig:assymmetric">15.1</a>)</li>
</ol>
<p>所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(<span class="math inline">\(=\tilde p\)</span>)相同，那麼就可以直接認爲，雙側 <span class="math inline">\(p\)</span> 值是兩側面積之和 (<span class="math inline">\(p=2\times \tilde p\)</span>)，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 <span class="math inline">\(H_0\)</span>。</p>
<p>注意：</p>
<ul>
<li>被選中的 <span class="math inline">\(t^\prime\)</span> 值大小不大可能滿足：<span class="math inline">\(|t^\prime - E(T|\theta_0)|=|t_{obs}-E(T|\theta_0)|\)</span>。因爲那只有在完全左右對稱的分佈中才會出現。但是，此處我們關心的是面積左右兩邊的尾部要相等即可，所以我們只需要知道右半邊，較大的那個 <span class="math inline">\(t_{obs}\)</span> 就完全足夠了。</li>
</ul>
<p>回到上面的均值比較問題 (Section <a href="02-Inference.html#normal-mean-compare">15.5.1</a>)。現在我們要進行雙側假設檢驗，即： <span class="math inline">\(H_0: \mu=5 \text{ v.s. } H_1: \mu\neq5\)</span>，最佳統計量依然還是樣本均數 <span class="math inline">\(\bar{X}\)</span>。數據告訴我們說 <span class="math inline">\(\bar{X}=7.76\)</span>，因此雙側 <span class="math inline">\(p\)</span> 值就是將已求得的單側 <span class="math inline">\(\tilde p\)</span> 值乘以 <span class="math inline">\(2\)</span>： <span class="math inline">\(\text{two-sided } p=2\tilde p= 0.006\)</span></p>
<p>當然，實際操作中我們很少進行這樣繁瑣的論證，多數情況下就直接報告雙側 <span class="math inline">\(p\)</span> 值。</p>
</div>
<div id="test-summary" class="section level2">
<h2><span class="header-section-number">15.7</span> 假設檢驗構建之總結</h2>
<p>按照如下的步驟一一構建我們的假設檢驗過程：</p>
<ol style="list-style-type: decimal">
<li>先建立<strong>零假設，和替代假設</strong> (Section <a href="02-Inference.html#null-and-alter">15.1</a>)；</li>
<li>定義<strong>最佳檢驗統計量</strong> (用 Neyman-Pearson lemma) (Section <a href="02-Inference.html#Neyman-Pearson">15.3</a>)；</li>
<li>取得零假設條件下，最佳統計量的樣本分佈(通常都較爲困難，有時候我們會傾向於使用“不太理想”，但是計算較爲簡便的過程。) ；</li>
<li>定義<strong>拒絕域(判別區域) </strong> (常用 <span class="math inline">\(\alpha=0.05\)</span>) ；</li>
<li>計算<strong>觀察數據</strong>的檢驗統計量；</li>
<li>如果觀察數據的檢驗統計量落在了提前定義好的拒絕域內，那麼我們的檢驗結論就是：觀察數據<strong>拒絕了零假設支持替代假設</strong>。然而在實際操作時，如果發現數據的檢驗統計量不在拒絕域內，我們僅僅只能下結論說：觀察數據<strong>無法拒絕零假設</strong>(<strong>而不是接受零假設！</strong>) ；</li>
<li>報告計算得到的反對零假設的定量 <span class="math inline">\(p\)</span> 值。</li>
</ol>
<p>作爲統計學家，我們的任務是評價數據提供的證據，而不是簡單的去接受或者拒絕一個假設。</p>
</div>
<div id="練習題-2" class="section level2">
<h2><span class="header-section-number">15.8</span> 練習題</h2>
<div id="q1-2" class="section level3">
<h3><span class="header-section-number">15.8.1</span> Q1</h3>
<p>某種藥物有兩種使用方法：可以口服，也可以注射。兩種方法都被認爲可以使血漿中藥物濃度在24小時候達到相似的平均水平，<span class="math inline">\(3 \mu \text{g/L}\)</span>。已知口服該藥物後，濃度的方差爲 <span class="math inline">\(1\)</span>，而如果是注射的話方差只有 <span class="math inline">\(1/4\)</span>。因此設計了一個口服臨牀實驗，觀察到24小時後血漿中藥物濃度數據爲：2.54, 0.93, 2.75, 4.51, 3.71, 1.62, 3.01, 4.13, 2.08, 3.33。假設這組觀察數據獨立同分佈 <span class="math inline">\(\stackrel{i.i.d}{\sim} N(3, \sigma^2)\)</span></p>
<ol style="list-style-type: decimal">
<li>證明以下的假設的最佳檢驗統計量是 <span class="math inline">\(\sum_{i=1}^{10}(x_i-3)^2\)</span>： <span class="math display">\[H_0: \sigma^2=1/4 \text{ v.s. } H_1: \sigma^2=1\]</span></li>
</ol>
<p><strong>解</strong></p>
<p>根據 Neyman-Pearson lemma (Section <a href="02-Inference.html#Neyman-Pearson">15.3</a>) 來判斷最佳檢驗統計量：</p>
<p>下面用 <span class="math inline">\(\sigma^2_0, \sigma^2_1\)</span> 分別標記零假設和替代假設時的方差。</p>
<p><span class="math display">\[
\begin{aligned}
L(\sigma^2|\underline{x},\mu=3) &amp;= \prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\text{exp}(-\frac{1}{2}(\frac{x_i-3}{\sigma})^2) \\
\Rightarrow \ell(\sigma^2) &amp;=-\frac{1}{2}\sum_{i=1}^n\text{log}\sigma^2-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-3)^2 \\
  &amp;= -\frac{n}{2}\text{log}\sigma^2-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-3)^2 \\
\Rightarrow \ell(\sigma_0^2)-\ell(\sigma_1^2)&amp;= \frac{n}{2}\text{log}\sigma_1^2+\frac{1}{2\sigma_1^2}\sum_{i=1}^n(x_i-3)^2\\
&amp;\;\;\;\;\;\;-\frac{n}{2}\text{log}\sigma_0^2-\frac{1}{2\sigma_0^2}\sum_{i=1}^n(x_i-3)^2\\
&amp;=\frac{n}{2}(\text{log}\sigma_1^2-\text{log}\sigma_0^2)+\frac{1}{2}(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})\sum_{i=1}^n(x_i-3)^2\\
&amp;=\frac{n}{2}\text{log}\frac{\sigma_1^2}{\sigma_0^2}+\frac{1}{2}(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})\sum_{i=1}^n(x_i-3)^2
\end{aligned}
\]</span></p>
<p>觀察上面的式子就會發現，當實驗重複後唯一會發生變化的就是後面的 <span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span>。 由於，<span class="math inline">\(\sigma_0^2=1/4, \; \sigma_1^2=1\)</span>，所以 <span class="math inline">\((\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})&lt;0\)</span>。那麼當 <span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span> 越大，<span class="math inline">\(\ell(\sigma_0^2)-\ell(\sigma_1^2)\)</span> 就越小。因此，這就是我們尋找的最佳檢驗統計量。</p>
<ol start="2" style="list-style-type: decimal">
<li>證明上面的檢驗統計量總是可以作爲最佳檢驗統計量，用於檢驗單側替代假設：<span class="math inline">\(H_1: \sigma^2&gt;1/4\)</span>。</li>
</ol>
<p>上面的替代假設中 <span class="math inline">\(\sigma_1^2=1\)</span>，如果將替代假設改成 <span class="math inline">\(\sigma_1^2&gt;1/4\)</span>，那麼 <span class="math inline">\((\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})&lt;0\)</span> 依然成立。所以，<span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span>，或者這部分乘以任何一個不變的常數依然是替代假設爲 <span class="math inline">\(H_1: \sigma^2&gt;1/4\)</span> 時的最佳檢驗統計量。</p>
<ol start="3" style="list-style-type: decimal">
<li>在 <span class="math inline">\(H_0\)</span> 條件下，樣本分佈 <span class="math inline">\(\sum_{i=1}^{10}(x_i-3)^2\)</span> 是怎樣的分佈？利用這個分佈來定義顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 時的拒絕域。</li>
</ol>
<p>在<span class="math inline">\(H_0\)</span> 條件下，有： <span class="math display">\[X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(3,1/4)\\
\Rightarrow \frac{X_i-3}{\sqrt{1/4}}\sim N(0,1)\\
\Rightarrow (\frac{X_i-3}{\sqrt{1/4}})^2 \sim \mathcal{X}_1^2\\
\Rightarrow \sum_{i=1}^{10}(\frac{X_i-3}{\sqrt{1/4}})^2 \sim \mathcal{X}_{10}^2\\
\Rightarrow 4\sum_{i=1}^{10}(X_i-3)^2\sim \mathcal{X}_{10}^2\\
\text{Let } T=\sum_{i=1}^{10}(X_i-3)^2\\
\Rightarrow 4T \sim \mathcal{X}_{10}^2\]</span></p>
<p>拒絕域被定義爲檢驗統計量取大於等於某個臨界值時概率爲 <span class="math inline">\(0.05\)</span>，即 <span class="math inline">\(\text{Prob}(T\geqslant t)=0.05\)</span></p>
<p><span class="math display">\[\text{Prob}(4T\geqslant \mathcal{X}^2_{10,0.95})=0.05\\
\Rightarrow \text{Prob}(T\geqslant 1/4\mathcal{X}^2_{10,0.95})=0.05\]</span></p>
<p>所以，此處當顯著性水平定爲 <span class="math inline">\(\alpha=0.05\)</span> 時，拒絕域就是要大於自由度爲 <span class="math inline">\(10\)</span> 的卡方分佈的 <span class="math inline">\(95\%\)</span> 分位點。</p>
<ol start="4" style="list-style-type: decimal">
<li>在 <span class="math inline">\(H_0\)</span> 條件下，該檢驗統計量的正態分佈模擬是怎樣的？</li>
</ol>
<p>根據<strong>中心極限定理</strong>(Section <a href="01-Probability.html#CLT">8</a>) 和 <strong>卡方分佈的性質</strong> (Section <a href="02-Inference.html#chi-square-distribution">11</a>)</p>
<p><span class="math display">\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]</span></p>
<p>所以近似地，</p>
<p><span class="math display">\[\mathcal{X}_{10}^2\sim N(\text{E}(\mathcal{X}_{10}^2)=10,\text{Var}(\mathcal{X}_{10}^2)=20)\\
\Rightarrow 4T\sim \text{approx} N(10,20)\\
\Rightarrow \frac{4T-10}{\sqrt{20}} \stackrel{\cdot}{\sim} N(0,1)\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>用上面的正態分佈模擬，和觀察嘗試對單側替代假設作統計檢驗並依據所得結果作出結論：<span class="math display">\[H_0: \sigma^2=1/4 \text{ v.s. } H_1: \sigma^2&gt;1/4\]</span></li>
</ol>
<p>用上面的正態分佈近似法，我們可以計算拒絕域：</p>
<p><span class="math display">\[\text{Prob}(\frac{4T-10}{\sqrt{20}}\geqslant Z_{0.95})=0.05\]</span></p>
<p>已知標準正態分佈的 <span class="math inline">\(95\%\)</span> 分位點取值 <span class="math inline">\(1.64\)</span>，所以拒絕域：</p>
<p><span class="math display">\[\frac{4T-10}{\sqrt{20}}\geqslant 1.64\\
\Rightarrow T\geqslant1/4(10+1.64\sqrt{20})=1/4\times17.33\]</span></p>
<p>由觀察數據可得：<span class="math inline">\(T=11.5\)</span> ，所以觀察數據的檢驗統計量落在了拒絕域內。我們的結論是：觀察數據提供了極強的證據證明在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，口服該藥物24小時後的血漿藥物濃度的方差大於 <span class="math inline">\(1/4\)</span>。</p>
</div>
</div>
</div>
<div id="假設檢驗的近似方法" class="section level1">
<h1><span class="header-section-number">第 16 章</span> 假設檢驗的近似方法</h1>
<p>本章教你怎麼徒手搞似然比檢驗 (likelihood ratio test)，Wald 檢驗 (Wald test)，和 Score 檢驗 (Score test)。</p>
<div id="近似和精確檢驗-approximate-and-exact-tests" class="section level2">
<h2><span class="header-section-number">16.1</span> 近似和精確檢驗 approximate and exact tests</h2>
<p>前一章描述了如何用對數似然比尋找最佳檢驗統計量 (Section <a href="02-Inference.html#Neyman-Pearson">15.3</a>)。一旦找到並確定了最佳檢驗統計量，接下去還需要確定這個最佳檢驗統計量的樣本分佈，用定好的顯著性水平(<span class="math inline">\(\alpha=0.05\)</span>)確定拒絕域，再使用觀察數據計算數據本身的統計量，然後對反對零假設的證據定量(計算 <span class="math inline">\(p\)</span> 值) 。前一章用的例子均來自於正態分佈，所以我們都能夠不太複雜地獲得樣本均值，樣本方差等較容易取得樣本分佈的檢驗統計量。正如我們在前一章最後部分 (Section <a href="02-Inference.html#test-summary">15.7</a>) 總結的那樣，<strong>大多數情況下我們沒有那麼幸運</strong>。最佳檢驗統計量的樣本分佈會很難確定。所以另一個進行假設檢驗的途徑就是近似檢驗法 (approximate tests)。</p>
</div>
<div id="LRT" class="section level2">
<h2><span class="header-section-number">16.2</span> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</h2>
<p>記得我們之前說到，簡單假設 <span class="math inline">\(H_0: \theta=\theta_0\text{ v.s. } H_1: \theta=\theta_1\)</span> 的檢驗的最佳檢驗統計量可以使用 Neyman-Pearson lemma (尼曼皮爾森輔助定理) (Section <a href="02-Inference.html#Neyman-Pearson">15.3</a>) 來確定：</p>
<p><span class="math display">\[\ell_{H_0}-\ell_{H_1} = \ell(\theta_0)-\ell(\theta_1)\]</span></p>
<p>如果假設變成了複合型假設：<span class="math inline">\(H_0: \theta\in\omega_0 \text{ v.s. } H_1: \theta\in\omega_1\)</span>。此時，<span class="math inline">\(\omega_0, \omega_1\)</span> 分別指兩種假設條件下我們關心的總體參數的可能取值範圍。那麼可以把上面的定理擴展成，在 <span class="math inline">\(\omega_0, \omega_1\)</span> 兩個取值範圍內，零假設和對立假設在給出的觀察數據條件下的極大似然之比：</p>
<p><span class="math display">\[\text{log}\frac{\text{max}_{H_0}[L(\theta|data)]}{\text{max}_{H_1}[L(\theta|data)]}=\text{max}_{H_0}[\ell(\theta|data)]-\text{max}_{H_1}[\ell(\theta|data)]\\
=\text{max}_{\theta\in\omega_0}[\ell(\theta|data)]-\text{max}_{\theta\in\omega_1}[\ell(\theta|data)]\]</span></p>
<p>典型的假設檢驗情況下，我們面對的是簡單的零假設和複合型的替代假設：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta\neq\theta_0\]</span></p>
<p>所以在這個情況下，套用擴展以後的 Neyman-Pearson lemma：</p>
<p><span class="math display">\[\text{max}_{H_0}[\ell(\theta)]-\text{max}_{H_1}[\ell(\theta)]=\ell(\theta_0) - \ell(\hat\theta)=llr(\theta_0)\]</span></p>
<p>之前討論對數似然比 (Section <a href="02-Inference.html#llr-chi">13.3</a>) 時我們已知：</p>
<p><span class="math display">\[\text{Under }H_0: \theta=\theta_0\Rightarrow -2llr(\theta_0)\stackrel{\cdot}{\sim}\mathcal{X}_1^2\]</span></p>
<p>於是利用自由度爲 <span class="math inline">\(1\)</span> 的卡方檢驗的特徵我們就可以爲反對零假設的證據定量，計算關鍵的拒絕域。如果說顯著性水平爲 <span class="math inline">\(\alpha\)</span> 那麼，我們拒絕零假設 <span class="math inline">\(H_0:\theta=\theta_0\)</span> 的拒絕域是：</p>
<p><span class="math display">\[-2llr(\theta_0)&gt;\mathcal{X}^2_{1,1-\alpha}\]</span></p>
<p>當使用 <span class="math inline">\(\alpha=0.05\)</span> 時，這個關鍵的拒絕域就是：<span class="math inline">\(-2llr(\theta_0)&gt;3.84\)</span>。</p>
<p>這就是傳說中的 (對數) 似然比檢驗，(log-)Likelihood ratio test (LRT)。</p>
<p>LRT 的優點：</p>
<ol style="list-style-type: decimal">
<li>簡單；</li>
<li><span class="math inline">\(p\)</span> 值不會被參數尺度 (parameter scale) 左右，也就是說如果我們對參數進行了數學轉換 (Section <a href="02-Inference.html#para-trans">14.2</a>) 也不會影響似然比檢驗計算得到的 <span class="math inline">\(p\)</span> 值大小。</li>
</ol>
<p>LRT 的缺點：</p>
<ol style="list-style-type: decimal">
<li>非正態分佈的數據時，LRT 只能算是漸進有效 (asymptotic valid)，即樣本量要足夠大時結果才能令人滿意；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>需要計算兩次對數似然 (MLE 和 零假設時)。</li>
</ol>
</div>
<div id="練習題-3" class="section level2">
<h2><span class="header-section-number">16.3</span> 練習題</h2>
<p>假設有在觀察對象 <span class="math inline">\(n=100\)</span> 人中發生了 <span class="math inline">\(k=40\)</span> 個事件。假定數據服從二項分佈，已知人羣中每個人發生該事件的概率爲 <span class="math inline">\(\pi_0=0.5\)</span>。嘗試計算似然比檢驗統計量：<span class="math inline">\(-2llr(\pi_0)\)</span>，並進行顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 的假設檢驗：<span class="math inline">\(H_0: \pi=\pi_0 \text{ v.s. }H_1: \pi\neq\pi_0\)</span></p>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\because f(k=40|\pi) = \binom{100}{40}\pi^{40}(1-\pi)^{100-40} \\
&amp;\text{Ignoring terms}  \text{ not with }  \pi \\
&amp;\therefore \ell(\pi|k=40) = 40\text{log}\pi+60\text{log}(1-\pi) \\
&amp;\Rightarrow \ell^\prime(\pi|k=40) = \frac{40}{\pi}-\frac{60}{1-\pi} \\
&amp;\text{Let }   \ell^\prime(\pi|k=40) = 0 \\
&amp;\Rightarrow   \frac{40}{\pi}-\frac{60}{1-\pi} =0 \\
&amp;\Rightarrow  \text{ MLE } \hat\pi=0.4 \\
&amp;\Rightarrow llr(\pi_0)=\ell(\pi_0)-\ell(\hat\pi) \\
&amp;\;\;\;\;\;\;\;\;\;=40\text{log}0.5+60\text{log}(1-0.5)-40\text{log}0.4-60\text{log}(1-0.4)\\
&amp;\;\;\;\;\;\;\;\;\;=-2.013\\
&amp;\Rightarrow -2llr=4.026 &gt; \text{Pr}(\mathcal{X}^2_{1,0.95})=3.84
\end{aligned}
\]</span></p>
<p>所以當顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 時，數據提供了足夠拒絕零假設的證據。該事件在此人羣中發生的概率要低於人羣的 <span class="math inline">\(0.5\)</span>。</p>
</div>
<div id="Wald" class="section level2">
<h2><span class="header-section-number">16.4</span> 近似檢驗法之 – Wald 檢驗</h2>
<p>和 LRT 一樣， Wald 檢驗也適用於檢驗 <span class="math inline">\(H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta\neq\theta_0\)</span>。但是本方法其實是使用對數似然比方程的近似二次方程 (Section <a href="02-Inference.html#quadratic-llr">14</a>)。相比之下，LRT 使用的是精確的對數似然比，只對檢驗統計量 <span class="math inline">\(-2llr\)</span> 進行了自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈 <span class="math inline">\(\mathcal{X}_1^2\)</span> 近似。本節介紹的 Wald 檢驗過程中使用了兩次近似，一次是計算對數似然比時使用了二次方程，一次則是和 LRT 一樣對檢驗統計量進行 <span class="math inline">\(\mathcal{X}_1^2\)</span> 近似。</p>
<p>根據之前的對數似然比近似結論 (Section <a href="02-Inference.html#quadratic-llr2">14.1</a>) ：</p>
<p><span class="math display">\[llr(\theta)\approx-\frac{1}{2}(\frac{M-\theta}{S})^2\text{ asymptotically}\]</span></p>
<p>其中，<span class="math inline">\(M\)</span> 是 <span class="math inline">\(\text{MLE }\hat\theta\)</span>，<span class="math inline">\(S=\sqrt{\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}}\)</span></p>
<p>而且前一節我們也看到，</p>
<p><span class="math display">\[
\text{Under }H_0: \theta=\theta_0\Rightarrow -2llr(\theta_0) \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
\Rightarrow -2\times-\frac{1}{2}(\frac{M-\theta_0}{S})^2 \stackrel{\cdot}{\sim}\mathcal{X}_1^2 \\
\Rightarrow (\frac{M-\theta_0}{S}) \stackrel{\cdot}{\sim} N(0,1)\\
\text{Let } W=(\frac{M-\theta_0}{S})
\]</span></p>
<p><span class="math inline">\(W\)</span> 就是我們在 Wald 檢驗中用到的檢驗統計量。接下來就可以計算給定顯著水平 <span class="math inline">\(\alpha\)</span> 時的拒絕域，給 <span class="math inline">\(p\)</span> 值定量：</p>
<p>當 <span class="math inline">\(W&gt;N(0,1)_{1-\alpha/2}\)</span> 或 <span class="math inline">\(W&lt;N(0,1)_{\alpha/2}\)</span>時，拒絕 <span class="math inline">\(H_0: \theta=\theta_0\)</span>；</p>
<p>或者，當 <span class="math inline">\(W^2&gt;\mathcal{X}^2_{1,1-\alpha}\)</span> 時，拒絕 <span class="math inline">\(H_0: \theta=\theta_0\)</span>。</p>
<p>這就是我們心心念念的 Wald 檢驗。</p>
<div class="figure" style="text-align: center"><span id="fig:llr-wald"></span>
<img src="img/Selection_083.png" alt="Likelihood ratio and Wald tests: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation" width="90%" />
<p class="caption">
圖 16.1: Likelihood ratio and Wald tests: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation
</p>
</div>
<p>上圖 <a href="02-Inference.html#fig:llr-wald">16.1</a> 解釋了 LRT 和 Wald 檢驗的不同之處。紅色虛線是二次方程，用於近似似然比方程(綠色實線) 。二者在 <span class="math inline">\(\text{MLE}=\hat\theta\)</span> 時同時取極大值。Wald 檢驗的是，數據提供的 <span class="math inline">\(\hat\theta\)</span> 和我們想要比較的零假設 <span class="math inline">\(\theta_0\)</span> 之間的橫軸差距。在檢驗量 <span class="math inline">\(W\)</span> 中我們還把這個差除以觀察數據均值的標準差(數據的標準誤) 。 如果數據本身波動大，<span class="math inline">\(W\)</span> 的分母(標準誤) 較大，那麼即使 <span class="math inline">\(\hat\theta - \theta_0\)</span> 保持不變，統計量變小，反對零假設的證據也就越小。反觀，LRT 檢驗的檢驗統計量就是上圖 <a href="02-Inference.html#fig:llr-wald">16.1</a> 顯示的縱軸差 <span class="math inline">\(\ell(\theta_0)-\ell(\hat\theta)\)</span> 的大小。二者之間的關係被直觀的顯示在圖中。</p>
<p>Wald 檢驗優點：</p>
<ol style="list-style-type: decimal">
<li>比 LRT 略簡單；</li>
<li>不必再計算零假設時的對數似然，只需要 <span class="math inline">\(MLE\)</span> 和它的標準誤。</li>
</ol>
<p>Wald 檢驗缺點：</p>
<ol style="list-style-type: decimal">
<li>兩次近似(LRT只用了一次近似) ；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>參數如果被數學轉換 (Section <a href="02-Inference.html#para-trans">14.2</a>)，<span class="math inline">\(p\)</span> 值會跟着變化。</li>
</ol>
<div id="再以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">16.4.1</span> 再以二項分佈爲例</h3>
<p>在 <span class="math inline">\(n\)</span> 個實驗對象中觀察到 <span class="math inline">\(k\)</span> 個事件，使用參數爲 <span class="math inline">\(\pi\)</span> 的二項分佈模型來模擬。使用 Wald 檢驗法對下列假設做出統計檢驗： <span class="math inline">\(H_0: \pi=\pi_0 \text{ v.s. } H1: \pi\neq\pi_0\)</span>。將參數 logit 轉換 (log-odds) 之後，對轉換後的新參數再做一次 Wald 檢驗。</p>
<p><strong>解</strong></p>
<p>根據之前的二次方程近似法推導 (Section <a href="02-Inference.html#quadratic-binomial-approx">14.1.3</a>)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; M=\text{MLE}=\hat\pi=\frac{k}{n}=p\\
&amp; S=se(\hat\pi)=\sqrt{\frac{p(1-p)}{n}}\\
&amp; \Rightarrow \text{Under } H_0: \pi=\pi_0\\
&amp; W=(\frac{p-\pi_0}{\sqrt{\frac{p(1-p)}{n}}})\stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>根據參數數學轉換的性質 (Section <a href="02-Inference.html#para-trans">14.2</a>)</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{New parameter } \beta=g(\pi)=\text{logit}(\pi)=\text{log}\frac{\pi}{1-\pi}\\
&amp; \text{MLE}=\text{logit}(\hat\pi)=\text{log}\frac{\hat\pi}{1-\hat\pi} \\
&amp; \text{Here we need to use delta-method to approximate standard error of } g(\pi)\\
&amp; S=se[g(\hat\pi)]\approx g^\prime(\pi)\times se(\hat\pi) \\
&amp; = \frac{1}{\hat\pi(1-\hat\pi)}\sqrt{\frac{p(1-p)}{n}}\\
&amp; =\sqrt{\frac{1}{k}+\frac{1}{n-k}} \\
&amp; \text{So the Wald test becomes}\\
&amp; H_0: \beta=\beta_0\\
&amp; \Rightarrow W=\frac{\text{log}(\frac{\hat\pi}{1-\hat\pi})-\text{log}(\frac{\pi_0}{1-\pi_0})}{\sqrt{\frac{1}{k}+\frac{1}{n-k}}}\stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>可見對參數進行了數學轉換之後，檢驗統計量的計算式發生了變化。因此 <span class="math inline">\(p\)</span> 值也會不同。</p>
</div>
</div>
<div id="Score" class="section level2">
<h2><span class="header-section-number">16.5</span> 近似檢驗法之 – Score 检验</h2>
<p>注意到 Wald 檢驗使用的近似二次方程是在 MLE， 也就是極大似然比時的點 <span class="math inline">\(\hat\theta\)</span> 和對數似然比方程取相同的值和相同曲率 (二次導數)。 可以類比的是，Score 检验是基于另一種二次方程模擬，Score 檢驗的近似二次方程和對數似然比方程在零假設 (<span class="math inline">\(\theta_0\)</span>) 時取相同的曲率。所以，Score 檢驗使用的近似方程在 <span class="math inline">\(\theta_0\)</span> 時和對數似然比方程在相同位置時的傾斜度 (一階導數)，和曲率 (坡度的變化程度，二階導數) 相同。所以令 <span class="math inline">\(U\)</span> 爲對數似然比方程在 <span class="math inline">\(\theta_0\)</span> 時的坡度，定義 <span class="math inline">\(V\)</span> 是對數似然比方程在 <span class="math inline">\(\theta_0\)</span> 時的曲率的負數：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; U=\ell^\prime(\theta)|_{\theta=\theta_0}=\ell^\prime(\theta_0)\\
&amp; V=-E[\ell^{\prime\prime}(\theta)]|_{\theta=\theta_0}=-E[\ell^{\prime\prime}(\theta_0)]
\end{aligned}
\]</span></p>
<p>注：此處的 <span class="math inline">\(V=-E[l^{\prime\prime}(\theta_0)]\)</span> 又常常被叫做 Expected Fisher information。</p>
<p>記得在 Wald 檢驗中使用的近似方程： <span class="math display">\[llr(\theta)\approx-\frac{1}{2}(\frac{M-\theta}{S})^2\text{ asymptotically}\]</span></p>
<p>令 <span class="math inline">\(q(\theta)=-\frac{1}{2}(\frac{M-\theta}{S})^2\)</span> 就有：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; q^\prime(\theta)                      =\frac{M-\theta}{S^2}\\
&amp; \Rightarrow q^\prime(\theta_0)        =\frac{M-\theta_0}{S^2}\\
&amp; q^{\prime\prime}(\theta)              =-\frac{1}{S^2}\\
&amp; \Rightarrow q^{\prime\prime}(\theta_0)=E[l^{\prime\prime}(\theta_0)]\\
&amp; \Rightarrow \frac{1}{S^2}             =-E[l^{\prime\prime}(\theta_0)]\\
&amp; q^\prime(\theta_0)                    = \frac{M-\theta_0}{S^2} = -E[l^{\prime\prime}(\theta_0)](M-\theta_0)\\
&amp;                                       = \ell^\prime(\theta_0)\\
&amp; \Rightarrow     M-\theta_0  = -\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}\\
&amp; \Rightarrow     M  =  -\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}+\theta_0\\
&amp; q(\theta)=-\frac{1}{2}(\frac{M-\theta}{S})^2=\frac{E[l^{\prime\prime}(\theta_0)]}{2}(-\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}+\theta_0-\theta)^2\\
&amp; q(\theta)=-\frac{V}{2}(\frac{U}{V}+\theta_0-\theta)^2\\
&amp; \Rightarrow \text{ Under } H_0: \theta=\theta_0\\
&amp; \Rightarrow q(\theta_0)=-\frac{V}{2}(\frac{U}{V})^2=-\frac{U^2}{2V}\\
&amp; \Rightarrow -2q(\theta_0)=\frac{U^2}{V} \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \text{Or equivalently} \frac{U}{\sqrt{V}} \stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>這就是 Score 檢驗時使用的檢驗統計量。相應的拒絕域就可以被定義爲： 當 <span class="math inline">\(\frac{U^2}{V}&gt;\mathcal{X}_{1,1-\alpha}^2\)</span> 時，拒絕 <span class="math inline">\(H_0\)</span></p>
<p>如下面的示意圖 <a href="02-Inference.html#fig:score-test">16.2</a> 所示，Score 檢驗，比較的是 <span class="math inline">\(\theta_0\)</span> 時的校正後似然方程的坡度 (一階導數/二階導數)，和極大似然時的坡度 (一階導數=0) 的差別。如果這個值越大，說明零假設時的似然和極大似然 (觀察數據的信息) 的距離越遠，拒絕零假設的證據就越有力。</p>
<div class="figure" style="text-align: center"><span id="fig:score-test"></span>
<img src="img/Selection_084.png" alt="Score test: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation" width="90%" />
<p class="caption">
圖 16.2: Score test: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation
</p>
</div>
<p>Score 檢驗優點：</p>
<ol style="list-style-type: decimal">
<li>比 LRT 簡單；</li>
<li>不需要計算 MLE，只需要計算零假設時的對數似然比方程之坡度和曲率；</li>
<li>在流行病學用到的檢驗方法中最常用，也最容易擴展 (Mantel-Haenszel test, log rank test, generalised linear models such as logistic, Poisson, Cox regressions)。</li>
</ol>
<p>Score 檢驗缺點：</p>
<ol style="list-style-type: decimal">
<li>和 Wald 檢驗一樣用到了兩次近似；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>參數如果被數學轉換 (Section <a href="02-Inference.html#para-trans">14.2</a>)，<span class="math inline">\(p\)</span> 值會跟着變化。</li>
</ol>
<div id="再再以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">16.5.1</span> 再再以二項分佈爲例</h3>
<p><span class="math inline">\(K\sim Bin(n, \pi)\)</span> 假如已知人羣中事件發生的概率是 <span class="math inline">\(\pi_0\)</span>。試推導此時的 Score 檢驗的檢驗統計量。</p>
<p><strong>解</strong></p>
<p>對二項分佈數據進行 Score 檢驗的時候我們需要計算 <span class="math inline">\(U, V\)</span>，然後計算統計量 <span class="math inline">\(\frac{U^2}{V}\)</span> 和 <span class="math inline">\(\mathcal{X}_1^2\)</span> 比較即可。</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Let } p=\frac{k}{n} \\
&amp; \ell(\pi|k) = k\text{log}(\pi)+(n-k)\text{log}(1-\pi)\\
&amp; \ell^\prime(\pi)=\frac{k}{\pi}-\frac{n-k}{1-\pi}=\frac{k-n\pi}{\pi(1-\pi)}\\
&amp; = \frac{p-\pi}{\pi(1-\pi)/n}\\
&amp; \Rightarrow U = \ell^\prime(\pi_0)=\frac{p-\pi_0}{\pi_0(1-\pi_0)/n}\\
&amp; \ell^{\prime\prime}(\pi|K)=-\frac{K}{\pi^2}-\frac{n-K}{(1-\pi)^2}\\
&amp; \Rightarrow -\ell^{\prime\prime}(\pi|K)=\frac{K}{\pi^2}+\frac{n-K}{(1-\pi)^2}\\
&amp; \because E(K)=n\pi\\
&amp; \therefore -E[\ell^{\prime\prime}(\pi|K)]=\frac{n\pi}{\pi^2}+\frac{n-n\pi}{(1-\pi)^2}\\
&amp; =\frac{n}{\pi}+\frac{n}{1-\pi}=\frac{n}{\pi(1-\pi)}\\
&amp; \text{ Under } H_0: \pi=\pi_0 \Rightarrow V=-E[\ell^{\prime\prime}(\pi_0)]=\frac{n}{\pi_0(1-\pi_0)}\\
&amp; \Rightarrow \frac{U^2}{V}=\frac{(p-\pi_0)^2}{\pi_0(1-\pi_0)/n} \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \text{OR } \frac{U}{\sqrt{V}} = \frac{p-\pi_0}{\sqrt{\pi_0(1-\pi_0)/n}} \stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
</div>
</div>
<div id="LRTwaldScore-Compare" class="section level2">
<h2><span class="header-section-number">16.6</span> LRT, Wald, Score 檢驗三者的比較</h2>
<ol style="list-style-type: decimal">
<li><p>LRT 比較的是對數似然方程在零假設 <span class="math inline">\(H_0\)</span> 和極大似然估計 (MLE) 時之間的縱軸差 (圖 <a href="02-Inference.html#fig:llr-wald">16.1</a>)；Wald 檢驗試圖直接比較 MLE 和 <span class="math inline">\(H_0\)</span> 的橫軸差 (二次方程近似法，並用標準誤校正) (圖 <a href="02-Inference.html#fig:llr-wald">16.1</a>)；Score 檢驗比較的是對數似然方程在 <span class="math inline">\(H_0\)</span> 時的切線斜率 (二次方程近似法，用曲率也就是二階導數校正) (圖 <a href="02-Inference.html#fig:score-test">16.2</a>)。三種檢驗比較的東西各不相同，但是這種差距大到進入拒絕域時，數據就會拒絕零假設。其中 Score 檢驗的計算過程最爲簡便，只需要計算 <span class="math inline">\(H_0\)</span> 時對數似然方程的一階和二階導數，而不用去計算 MLE，因此更多的被應用在流行病學數據計算中。</p></li>
<li><p>如果對數似然方程本身就是左右對稱的 (正態分佈的情況下)，這三個檢驗方法計算的所有結果都是完全一致的。如果對數似然方程只是近似左右對稱，那麼三者的計算結果會十分接近。可以說，三種檢驗方法是漸進等價的。</p></li>
<li><p>如果對觀測值進行了數學轉換，三者中只有 LRT 的計算結果保持不變。如果對參數的數學轉換使得對數似然方程更加接近左右對稱的二次方程，那麼 Wald 和 Score 檢驗的計算結果可以得到改善。</p></li>
<li><p>如果說，MLE 和 零假設之間的差距很大，那麼 Wald 或者 Score 檢驗所使用的二次方程近似法的誤差會增加，此時傾向於使用 LRT 來進行精確檢驗。當然如果當樣本量較大，要檢驗的差距也很大，三種檢驗方案都能夠提供證據拒絕零假設 (<span class="math inline">\(p\)</span> 值都會很小)。</p></li>
<li><p>如果三種檢驗方案給出的計算結果迥異，即使使用了數學轉換結果也沒有明顯改善的話，那麼最大的問題是樣本量太小。這時候還是老老實實用 LRT 吧。</p></li>
<li><p>幾乎所有的參數檢驗都歸類與這章節介紹的三種檢驗方法。比如說 <span class="math inline">\(Z\)</span> 檢驗， <span class="math inline">\(t\)</span> 檢驗， <span class="math inline">\(F\)</span> 檢驗都是 LRT。在流行病學研究中最常用的還是 Score 檢驗。</p></li>
</ol>
<p>我們的結論是，當條件允許的情況下，統計檢驗都推薦儘量使用精確檢驗 LRT。</p>
</div>
<div id="練習題-4" class="section level2">
<h2><span class="header-section-number">16.7</span> 練習題</h2>
<div id="q1-3" class="section level3">
<h3><span class="header-section-number">16.7.1</span> Q1</h3>
<p>在對數似然比章節 (Section <a href="02-Inference.html#llr-chi1">13.2</a>)，我們曾經證明過，已知方差時：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; llr(\mu|\underline{x})=\ell(\mu|\underline{x})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
&amp; \Rightarrow -2llr(\mu|\underline{x})=-2\ell(\mu|\underline{x})=(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2
\end{aligned}
\]</span></p>
<p>當觀察數據 <span class="math inline">\(X_1,\cdots,X_n\sim N(\mu,1^2)\)</span> ，求 LRT, Wald, Score 三種檢驗方法對下列假設進行檢驗時的檢驗統計量： <span class="math inline">\(H_0: \mu=\mu_0 \text{ v.s. } H_1: \mu\neq\mu_0\)</span></p>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Model: } X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, 1)\\
&amp; H_0: \mu=\mu_0 \text{ v.s. } H_1: \mu\neq\mu_0\\
&amp; \text{Model } \Rightarrow \bar{X} \sim N(\mu, \frac{1}{n}) \\
&amp; \text{If we observe } \bar{X} = \bar{x}\\
&amp; \ell(\mu|\bar{x})=-\frac{1}{2}(\frac{\bar{x}-\mu}{1/\sqrt{n}})^2\\
&amp; \textbf{For LRT, under } H_0: \mu=\mu_0 \Rightarrow -2llr(\mu_0) \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \Rightarrow \frac{\bar{x}-\mu}{1/\sqrt{n}} \sim N(0,1)\\
&amp; \textbf{For Wald test, under } H_0: \mu=\mu_0 \Rightarrow \frac{M-\mu_0}{S}\sim N(0,1) \\
&amp; \Rightarrow \frac{\bar{x}-\mu}{1/\sqrt{n}} \sim N(0,1)\\
&amp; \textbf{For Score test, under } H_0: \mu=\mu_0 \Rightarrow U=\ell^\prime(\mu_0), V=-E[\ell^{\prime\prime}(\mu_0)]\\
&amp; U=\ell^\prime(\mu_0)=(\frac{\bar{x}-\mu_0}{1/\sqrt{n}})\sqrt{n}=\frac{\bar{x}-\mu_0}{1/n}\\
&amp; \ell^{\prime\prime}(\mu_0)=-\frac{1}{1/n}=-n \Rightarrow V=-E[n]=n\\
&amp; \frac{U^2}{V}=(\frac{\bar{x}-\mu_0}{1/n})^2/n=(\frac{\bar{x}-\mu_0}{1/\sqrt{n}})^2\\
&amp; \Rightarrow \frac{U^2}{V} \sim \mathcal{X}_1^2 \Rightarrow \frac{U}{\sqrt{V}}=\frac{\bar{x}-\mu_0}{1/\sqrt{n}} \sim N(0,1)
\end{aligned}
\]</span></p>
<p><strong>本題證明了，當數據服從正態分佈時，三種檢驗方法使用的檢驗統計量，是完全一致的。</strong></p>
</div>
<div id="q2-2" class="section level3">
<h3><span class="header-section-number">16.7.2</span> Q2</h3>
<p>根據醫生的觀察，某種癌症患者的生存時間服從平均值爲 <span class="math inline">\(1/\beta_0\)</span> 的指數分佈 (exponentially distributed)。有一種新藥物可以改善平均生存時間 (仍然服從指數分佈)。已知指數分佈的密度方程是：<span class="math inline">\(f(x|\beta)=\beta \text{exp} (-\beta x), \text{ where } \beta, x&gt;0\)</span>。</p>
<ol style="list-style-type: decimal">
<li>證明指數分佈的均值是 <span class="math inline">\(1/\beta\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; X\sim f(x|\beta), x&gt;0 \Rightarrow E(X)=\int_0^\infty x\cdot f(x)\text{d} x = \int_0^\infty x\cdot \beta \cdot e^{-\beta x} \text{d}x\\
&amp; E(x)= - \int_0^\infty x\cdot \frac{\text{d}e^{-\beta x}}{\text{d}x} \cdot \text{d}x\\
&amp; \text{We can now integrate by parts, using } \int_a^b u \frac{\text{d}v}{\text{d}x} \text{d}x = [uv]_a^b-\int_a^b v \frac{\text{d}u}{\text{d}x} \text{d}x \\
&amp; E(X) = -[x\cdot e^{-\beta x}]_0^\infty + \int_0^\infty e^{-\beta x} \text{d} x \\
&amp; \;\;\;\; = -0+\int_0^\infty e^{-\beta x} \text{d} x\\
&amp; \;\;\;\; = \int_0^\infty\frac{\text{d}}{\text{d}x} \frac{e^{-\beta x}}{-\beta} \text{d} x\\
&amp; \;\;\;\; = [\frac{e^{-\beta x}}{-\beta}]_0^\infty = \frac{1}{-\beta}[0-1]=\frac{1}{\beta}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>請寫下本題設定條件下的數學模型，零假設和替代假設</li>
</ol>
<p><strong>解：</strong> 假設患者人數爲 <span class="math inline">\(n\)</span>，他們的生存時間爲相互獨立的隨機變量： <span class="math inline">\(X_1,\cdots,X_n\)</span>。那麼本例中的數學模型爲：<span class="math inline">\(\text{Model: } X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\beta)=\beta e^{-\beta x}\)</span>。我們可以提出如下的零假設和替代假設：<span class="math inline">\(H_0: \beta=\beta_0 \text{ v.s. } H_1: \beta\neq\beta_0\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>推導此模型參數 <span class="math inline">\(\beta\)</span> 的極大似然估計 (MLE)，試使用似然比檢驗法來推導進行假設檢驗時使用的檢驗統計量。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; L(\beta|\underline{x}) = \prod_{i=1}^n f(x_i|\beta)=\prod_{i=1}^n\beta e^{-\beta x_i} \\
&amp; \ell(\beta)=\sum_{i=1}^n\text{log}(\beta e^{-\beta x_i})=\sum\text{log}\beta-\sum\beta x_i=n\text{log}\beta-\beta\sum x_i \\
&amp; \;\;\;\; = n\text{log}\beta-\beta n \bar{x} \\
&amp; \Rightarrow \ell^\prime(\beta)=\frac{n}{\beta}-n\bar{x}\text{ MLE solves } \ell^\prime(\beta)=0 \text{ when }\ell^{\prime\prime}(\beta) &lt; 0 \\
&amp; \ell^\prime(\beta)=0 \Rightarrow \hat\beta=\frac{1}{\bar{x}}, \text{ and } \ell^{\prime\prime}(\beta)=-n\frac{1}{\beta^2} &lt; 0\\
&amp; \Rightarrow \text{ LRT test statistic: Under } H_0: \beta=\beta_0 \Rightarrow -2llr(\beta_0) \sim \mathcal{X}_1^2\\
&amp; llr(\beta_0)=\ell(\beta_0)-\ell(\hat\beta)=n\text{log}\beta_0-\beta_0n\bar{x}-n\text{log}\hat\beta+\hat\beta n \bar{x}\\
&amp; \text{ Substituting with MLE } \hat\beta=\frac{1}{\bar{x}}\\
&amp; \;\;\;\;\;\;\;\;\;\; = n\text{log}\beta_0-\beta_0n\bar{x}+n\text{log}\bar{x}+ n\\
&amp; \;\;\;\;\;\;\;\;\;\; = n(\text{log}\beta_0\bar{x}-\beta_0\bar{x}+1) \textbf{ this is the statistic for LRT}
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>推導 Score 和 Wald 檢驗法時的檢驗統計量</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \textbf{Score test: under } H_0 \Rightarrow \frac{U^2}{V}\sim \mathcal{X}_1^2 \text{ where } U=\ell^\prime(\beta_0), V=-E[\ell^{\prime\prime}(\beta_0)]\\
&amp; \Rightarrow U=\frac{n}{\beta_0}-n\bar{x}; V = -E[-n\frac{1}{\beta_0^2}] = n\frac{1}{\beta_0^2} \\
&amp; \Rightarrow \frac{U^2}{V}=(\frac{n}{\beta_0}-n\bar{x})^2\cdot\frac{\beta_0^2}{n} = (\frac{(\frac{n}{\beta_0}-n\bar{x})\beta_0}{\sqrt{n}})^2\\
&amp; \;\;\;\;\;\;\;\;\; = n(1-\bar{x}\beta_0)^2\\
&amp; \textbf{This is the statistic for Score test}\\
&amp; \textbf{Wald test: under } H_0: \beta=\beta_0 \Rightarrow W=(\frac{M-\beta_0}{S})^2 \sim \mathcal{X}_1^2, \\
&amp; \text{ where } M=\hat\beta=\frac{1}{\bar{x}}, \text{ and } S^2=-\frac{1}{\ell^{\prime\prime}(\hat\beta)}\\
&amp; \ell^{\prime\prime}(\beta)=-n\frac{1}{\beta^2}\Rightarrow \ell^{\prime\prime}(\hat\beta)=-n\bar{x}^2\Rightarrow S^2=\frac{1}{n\bar{x}^2}\\
&amp; \Rightarrow W=(\frac{M-\beta_0}{S})^2=\frac{(\frac{1}{\bar{x}}-\beta_0)^2}{\frac{1}{n\bar{x}^2}}=n(1-\beta_0\bar{x})^2\\
&amp; \textbf{This is the statistic for Wald test}
\end{aligned}
\]</span></p>
<p>注意到在這個特例中， Score 和 Wald 檢驗的統計量竟然不謀而合。</p>
<ol start="5" style="list-style-type: decimal">
<li>觀察5名患者，獲得診斷後的生存數據 (年)： <span class="math inline">\(0.5,1,1.25,1.5,0.75\)</span>。用上面推導的統計量對這個數據進行假設檢驗：<span class="math inline">\(H_0: \beta=0.5 \text{ v.s. } \beta\neq0.5\)</span>，你如何下結論？</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Data: } x_1,\cdots,x_n=0.5,1,1.25,1.5,0.75. \Rightarrow \bar{x}=1\\
&amp;H_0: \beta=0.5 \text{ v.s. } \beta\neq0.5\\
&amp;\textbf{LRT test: } \\
&amp; llr(\beta_0) = n(\text{log}\beta_0\bar{x}-\beta_0\bar{x}+1) = 5\times(\text{log}0.5-0.5\times1+1) = -0.966\\
&amp;\Rightarrow -2llr=1.93 &lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
&amp;\textbf{Score test: } \\
&amp; \frac{U^2}{V} = n(1-\bar{x}\beta_0)^2 = 5\times(1-1\times0.5)^2=1.25 &lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
&amp;\textbf{Wald test: } \\
&amp; W=n(1-\beta_0\bar{x})^2=5\times(1-0.5\times1)^2=1.25&lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
\end{aligned}
\]</span></p>
</div>
<div id="q3-1" class="section level3">
<h3><span class="header-section-number">16.7.3</span> Q3</h3>
<p>隨機變量 <span class="math inline">\(X_1,\cdots,X_n\)</span> 互相獨立且在區間 <span class="math inline">\([0,\alpha]\)</span> 內服從相同的恆定概率分佈 (identical uniform distribution)。 試着畫出參數 <span class="math inline">\(\alpha\)</span> 的似然方程示意圖。不進行任何數學計算，試着想象一下如果對 <span class="math inline">\(\alpha\)</span> 進行某種假設檢驗會出現什麼問題嗎？</p>
</div>
</div>
</div>
<div id="正態誤差模型-normal-error-models" class="section level1">
<h1><span class="header-section-number">第 17 章</span> 正態誤差模型 Normal error models</h1>
<p>正態誤差模型，其實沒有其名字那麼複雜，就是討論在正態分布條件下，<strong>均值和方差都需要被估計</strong> (都是未知狀態) 的模型。</p>
<p>本章還介紹</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈，試着闡述如何將 <span class="math inline">\(t\)</span> 分佈應用於兩個獨立樣本均值的比較；</li>
<li><span class="math inline">\(\chi^2\)</span> 分佈在統計學中各種常用分佈中的中心位置。</li>
</ol>
<div id="服從正態分佈的隨機變量" class="section level2">
<h2><span class="header-section-number">17.1</span> 服從正態分佈的隨機變量</h2>
<p><span class="math display">\[
X_1,\cdots,X_n \stackrel{i.i.d}{\sim} N(\mu,\sigma^2) \Leftrightarrow \bar{X} \sim N(\mu, \frac{\sigma^2}{n})
\]</span></p>
<p>如果總體方差 <span class="math inline">\(\sigma^2\)</span> 已知 (理想狀態，現實中不太可能)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1) \\
&amp; 95\% \text{CI for } \mu = \bar{X} \pm Z_{0.975}\frac{\sigma}{\sqrt{n}} \\
&amp; \text{H}_0: \mu=\mu_0 \Rightarrow \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \sim N(0,1)
\end{aligned}
\]</span></p>
<p>如果總體方差 <span class="math inline">\(\sigma^2\)</span> 是未知的，腫麼辦？ (模型中出現了兩個參數 <span class="math inline">\(\mu \;\&amp;\; \sigma^2\)</span>)</p>
<p><span class="math display">\[
T=\frac{\bar{X}-\mu_0}{\hat\sigma/\sqrt{n}} \sim ?????????
\]</span></p>
</div>
<div id="Fandtdistr" class="section level2">
<h2><span class="header-section-number">17.2</span> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</h2>
<p>如果 <span class="math inline">\(X\sim N(0,1)\)</span>，那麼 <span class="math inline">\(X^2 \sim \chi^2_1\)</span> (Section <a href="02-Inference.html#chi-square-distribution">11</a>)。類似地，如果 <span class="math inline">\(X_1,\cdots,X_n \stackrel{i.i.d}{\sim} N(0,1)\)</span> 那麼 <span class="math inline">\(\sum_{i=1}^n X^2_i \sim \chi^2_k\)</span>。</p>
<p><span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈是建立在 <span class="math inline">\(\chi^2\)</span> 分佈的基礎上的：</p>
<ul>
<li><span class="math inline">\(F\)</span> 分佈： <span class="math inline">\(Y_1, Y_2\)</span> 是獨立的兩個隨機變量，且 <span class="math inline">\(Y_1 \sim \chi^2_{k_1}; Y_2 \sim \chi^2_{k_2}\)</span>，那麼</li>
</ul>
<p><span class="math display">\[
F=\frac{Y_1/k_1}{Y_2/k_2} \sim F_{k_1, k_2}
\]</span></p>
<ul>
<li><span class="math inline">\(t\)</span> 分佈，是 <span class="math inline">\(F\)</span> 分佈的特殊情況 <span class="math inline">\((k_1=1)\)</span>：</li>
</ul>
<p><span class="math display">\[
T\sim t_{k_2} \Rightarrow T^2 = \frac{Y_1/1}{Y_2/k_2} \sim F_{1,k_2}
\]</span></p>
<p>此時我們再來考慮正態分佈模型中有兩個參數 <span class="math inline">\(\mu, \sigma^2\)</span> 需要被估計的模型：</p>
<p><span class="math display">\[
Y_i \stackrel{i.i.d}{\sim} N(\mu,\sigma^2) \text{ where } i = 1, \cdots, n
\]</span></p>
<p>其實可以改寫爲</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Y_i = \mu + \varepsilon_i \\
&amp; \text{Where } \varepsilon_i \stackrel{i.i.d}{\sim} N(0,\sigma^2)
\end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\varepsilon_i \stackrel{i.i.d}{\sim} N(0,\sigma^2)\)</span> 就是正態誤差 normal (random) error。<span class="math inline">\(Y_i = \mu + \varepsilon_i\)</span> 就是正態誤差模型 normal error model。誤差的含義就是統計模型中的隨機誤差 (模型不能解釋的部分)。如果一個正態誤差模型像前面的式子這樣沒有其他變量，那麼所有的觀察值 <span class="math inline">\(Y_i\)</span>，就是由總體均值 <span class="math inline">\(\mu\)</span> population mean，和隨機誤差 <span class="math inline">\(\varepsilon\)</span> random error 來說明 (就是這個式子 <span class="math inline">\(Y_i = \mu + \varepsilon_i\)</span>)。</p>
<p>如果觀察值 <span class="math inline">\(Y_i\)</span> 的一部分除了可以用均值解釋，還可以由某個變量 <span class="math inline">\(x\)</span> 來說明 (叫做解釋變量 explanatory variable 詳見線性迴歸部分 Section <a href="04-Linear-Regression.html#defLM">26.3.3</a>)，即：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;Y_i | x \stackrel{i.i.d}{\sim} N(\mu+\beta x_i, \sigma^2)\\
&amp; E(Y|x) = \mu+\beta x, \text{Var}(Y|x) = \sigma^2 \\
&amp; \text{ or } Y_i|x = \mu + \beta x_i + \varepsilon_i ; \text{ where }  \varepsilon_i \stackrel{i.i.d}{\sim} N(0, \sigma^2)
\end{aligned}
\]</span></p>
<p>上面的模型會在後面講線性迴歸的部分深入探討，此處簡單用下面的圖形來輔助理解。圖 <a href="02-Inference.html#fig:normal-error0">17.1</a> 中繪製的是 <span class="math inline">\(Y_i|x = \mu + \beta x_i + \varepsilon_i ; \text{ where } \varepsilon_i \stackrel{i.i.d}{\sim} N(0, \sigma^2)\)</span> 的示意圖，用 <span class="math inline">\(x_i\)</span> 標記兩個組，其中 <span class="math inline">\(x_i = 0\)</span> 時爲組 A 的人的觀察值，<span class="math inline">\(x_i=1\)</span> 時爲組 B 的人的觀察值。兩組的平均值如 Y 軸顯示的那樣，組 A 是 <span class="math inline">\(\mu\)</span>，組 B 是 <span class="math inline">\(\mu+\beta\)</span>。所以，這裏可以看到，正態誤差模型是假定兩組具有相同的方差的 common variance，如圖 <a href="02-Inference.html#fig:normal-error1">17.2</a>。如果解釋變量 (explanatory variable) 是一個連續型變量，則解釋爲在 X 軸上的任意一點對應的 Y 值的誤差都服從相同的方差，如圖 <a href="02-Inference.html#fig:normal-error2">17.3</a></p>
<div class="figure" style="text-align: center"><span id="fig:normal-error0"></span>
<img src="img/Selection_105.png" alt="Normal error models with categorical explanatory variable" width="90%" />
<p class="caption">
圖 17.1: Normal error models with categorical explanatory variable
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:normal-error1"></span>
<img src="img/Selection_106.png" alt="Normal error models shown with common error variance" width="90%" />
<p class="caption">
圖 17.2: Normal error models shown with common error variance
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:normal-error2"></span>
<img src="img/Selection_107.png" alt="Normal error models shown with continuous variable and common error variance" width="80%" />
<p class="caption">
圖 17.3: Normal error models shown with continuous variable and common error variance
</p>
</div>
</div>
<div id="兩個參數的模型" class="section level2">
<h2><span class="header-section-number">17.3</span> 兩個參數的模型</h2>
<div id="一組數據兩個參數" class="section level3">
<h3><span class="header-section-number">17.3.1</span> 一組數據兩個參數</h3>
<p>如果觀察數據 <span class="math inline">\(\underline{x} = x_1, \cdots, x_n\)</span> 是互相獨立的，該觀察數據的模型可以用一個包含兩個參數 <span class="math inline">\(\theta,\phi\)</span> 的概率方程 <span class="math inline">\(f\)</span> 來描述，那麼這個包含兩個參數的概率方程的似然和對數似然分別是：</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta, \phi | \underline{x}) &amp;=  \prod_{i=1}^nf(x_i | \theta, \phi) \\
\ell(\theta, \phi | \underline{x}) &amp;= \sum_{i=1}^n\text{log}f(x_i | \theta, \phi)
\end{aligned}
\]</span></p>
<p>兩個參數的 <span class="math inline">\(\text{MLE}\)</span> 可以通過對對數似然方程進行兩次偏微分，然後解連立方程組：</p>
<p><span class="math display">\[
\left\{
\begin{array}{ll}
\frac{\partial\ell}{\partial\theta} = 0\\
\frac{\partial\ell}{\partial\phi} = 0 \\
\end{array}
\right.
\]</span></p>
</div>
<div id="兩組數據各一個參數" class="section level3">
<h3><span class="header-section-number">17.3.2</span> 兩組數據各一個參數</h3>
<p>如果是兩組獨立數據，各由一個參數描述他們各自的概率方程：</p>
<p><span class="math display">\[
X_1, \cdots, X_n \stackrel{i.i.d}\sim f(\theta_1) \\
Y_1, \cdots, Y_m \stackrel{i.i.d}\sim f(\theta_2)
\]</span></p>
<p>那麼以兩組數據爲聯合條件 (應該可以理解爲同時觀察到時的) 的聯合似然 (joint likelihood)：</p>
<p>We describe the likelihood as the joint likelihood, conditional on jointly observing both datasets:</p>
<p><span class="math display">\[
L(\theta_1, \theta_2|\underline{x},\underline{y}) = \prod_{i=1}^nf_1(x_{1i}|\theta_1) \times \prod_{i=1}^mf_2(y_{i}|\theta_2)
\]</span></p>
<p>所以，聯合之後的對數似然方程就是兩個對數似然方程之和：</p>
<p><span class="math display">\[
\ell(\theta_1,\theta_2|\underline{x},\underline{y}) = \sum_{i=1}^n\text{log} f(x_i|\theta_1) + \sum_{i=1}^m\text{log} f(y_i|\theta_2)
\]</span></p>
<p>你會發現，分成兩組數據兩個獨立的概率方程之後的聯合對數似然方程求 <span class="math inline">\(\text{MLE}\)</span> 時需要用偏微分。可是偏微分之後的結果，和兩組數據合二爲一，用含有兩個參數的概率方程，計算其 <span class="math inline">\(\text{MLE}\)</span> 的結果會<strong>完全相同</strong>。</p>
</div>
</div>
<div id="正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導" class="section level2">
<h2><span class="header-section-number">17.4</span> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</h2>
<p>此時的情況如同前面的把兩組數據合二爲一的情況，用正態分佈的概率方程，然後有兩個參數 <span class="math inline">\(\mu, \sigma^2\)</span>。</p>
<p><span class="math display">\[
Y_1,\cdots,Y_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2) \\
\ell(\mu, \sigma^2 | \underline{y}) = -\frac{n}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}\sum^n_{i=1} (x_i - \mu)^2
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mu: \frac{\partial \ell}{\partial \mu} = \frac{\sum^n_{i=1}(y_i-\mu)}{2\sigma^2} = 0 \Rightarrow \hat\mu = \bar{y}\\
&amp; \sigma^2: \frac{\partial \ell}{\partial (\sigma^2)} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\mu)^2 \\
&amp; \text{ Substituting } \mu=\hat\mu = \bar{y} \text{ and set equal to } 0\\
&amp; \frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\bar{y})^2 = 0 \\
&amp; \Rightarrow \hat\sigma^2 = \frac{1}{n}\sum^n_{i=1}(y_i - \bar{y})^2
\end{aligned}
\]</span></p>
<p>有沒有覺得這裏的方差的極大似然估計似曾相識 (Section <a href="02-Inference.html#samplevarbias">10.3</a>)。在早期的章節中，我們學到了分部法 (“把樣本和總體均值之間的差的平方和分成兩部分”)：</p>
<p><span class="math display">\[
\begin{aligned}
\sum^n_{i=1}(y_i-\mu)^2 &amp; = \sum^n_{i=1}(y_i - \bar{y} + \bar{y} -\mu)^2  \\
                        &amp; = \sum^n_{i=1}(y_i - \bar{y})^2 + \sum^n_{i=1}(\bar{y}-\mu)^2 \\
\Rightarrow \sum^n_{i=1}(y_i - \bar{y})^2 &amp; = \sum^n_{i=1}(y_i-\mu)^2 - \sum^n_{i=1}(\bar{y}-\mu)^2
\end{aligned}
\]</span></p>
<p>當時分的是平方和，這裏再介紹一種把概率分部的方法 <strong>partition the probabilities</strong>。</p>
<p>We can “partition” the probability of observing the data, conditional on unknown <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>, into</p>
<ol style="list-style-type: decimal">
<li>the probability of observing the data conditional on the observed sample mean <span class="math inline">\(\bar{y}\)</span> and unknown <span class="math inline">\(\sigma^2\)</span> ;</li>
<li>the probability of observing the sample mean <span class="math inline">\(\bar{y}\)</span> conditional on the two unknown parameters.</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Prob}(\underline{y} | \mu, \sigma^2) = \text{Prob}(\underline{y}|\bar{y}, \sigma^2) \times \text{Prob}(\bar{y}|\mu, \sigma^2) \\
&amp;\Rightarrow \text{Prob}(\underline{y} | \bar{y}, \sigma^2) = \frac{\text{Prob}(\underline{y} | \mu, \sigma^2)}{\text{Prob}(\bar{y}|\mu, \sigma^2)}
\end{aligned}
\]</span></p>
<p>看到這裏你是否會想起概率論中討論的條件概率方程 (Section <a href="01-Probability.html#conditonalProb">1.2</a>)：</p>
<p><span class="math display">\[
f(x|Y=y) = \frac{f(x,y)}{f(y)}
\]</span></p>
<p>利用上述概率分佈的方法，我們可以進而推導方差 <span class="math inline">\(\sigma^2\)</span> 的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
f(\underline{y} | \bar{y}, \sigma^2) &amp;= \frac{
\color{red}{f(\underline{y} | \mu, \sigma^2)}
}{f(\bar{y}|\mu, \sigma^2)} \\
  &amp;=  \frac{
  \color{red}{(\frac{1}{\sqrt{2\pi\sigma^2}})^ne^{-\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \mu)^2}}
  }{(\frac{1}{\sqrt{2\pi\sigma^2/n}})e^{-\frac{1}{2\sigma^2/n}(\bar{y}-\mu)^2}} \\
\Rightarrow \ell(\sigma^2| \underline{y}, \bar{y}) &amp;=
\color{red}{-\frac{n}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}\sum^n_{i=1}(y_i-\mu)^2} \\ &amp; \;\;\;+\frac{1}{2}\text{log}\frac{\sigma^2}{n} + \frac{1}{2\sigma^2/n}(\bar{y}-\mu)^2 \\
&amp;= -\frac{n-1}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}(\sum^n_{i=1}(y_i-\mu)^2 - n(\bar{y}-\mu)^2) \\
 \text{Because }  &amp;\sum^n_{i=1}(y_i - \bar{y})^2  = \sum^n_{i=1}(y_i-\mu)^2 - \sum^n_{i=1}(\bar{y}-\mu)^2 \\
 \Rightarrow \ell(\sigma^2| \underline{y}, \bar{y}) &amp;= -\frac{n-1}{2}\text{log}\sigma^2 -\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \bar{y})^2 \\
 \text{Note that the } &amp;\text{above conditional log-likelihood is now free of } \mu \\
 \Rightarrow \ell^\prime(\sigma^2) &amp;= -\frac{n-1}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\bar{y})^2 \\
 \text{Set equal } &amp; \text{to zero and rearrange} \\
 \Rightarrow \hat\sigma^2 &amp;= \frac{1}{n-1}\sum^n_{i=1}(y_i-\bar{y})^2\\
 \text{This is the } &amp;\color{red}{\text{unbiased estimate of } \sigma^2}
\end{aligned}
\]</span></p>
<p>現在再重新考慮對數據 <span class="math inline">\(Y_1, \cdots, Y_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span> 進行均值的假設檢驗：</p>
<p><span class="math display">\[
\text{H}_0: \mu = \mu_0 \text{ v.s H}_1: \mu &gt; \mu_0
\]</span></p>
<p>當 <span class="math inline">\(\sigma^2\)</span> 是<strong>已知的</strong>，在零假設條件下的檢驗統計量是：</p>
<p><span class="math display" id="eq:infer8-1">\[
\begin{aligned}
&amp; \text{H}_0 \Rightarrow (\frac{\bar{Y}-\mu_0}{\sigma/\sqrt{n}}) \sim N(0,1) \\
&amp; \text{Or equivalently, } \\
&amp; (\frac{\bar{Y}-\mu_0}{\sigma/\sqrt{n}})^2 \sim \chi_1^2
\end{aligned}
\tag{17.1}
\]</span></p>
<p>當 <span class="math inline">\(\sigma^2\)</span> 是<strong>未知的</strong>，它需要通過樣本數據來估計時。我們就該使用前面從條件對數似然方程推導出的方差無偏估計：</p>
<p><span class="math display">\[
\hat\sigma^2 = S^2 = \frac{1}{n-1}\sum^n_{i=1}(y_i-\bar{y})^2
\]</span></p>
<p>但是，假如只把無偏估計的方差放到公式 <a href="02-Inference.html#eq:infer8-1">(17.1)</a> 裏去，可以當作新的檢驗統計量嗎？有這麼簡單嗎？</p>
<p><span class="math display">\[
(\frac{\bar{Y}-\mu_0}{s/\sqrt{n}})^2
\]</span></p>
<p>當然沒有這麼簡單！這種方式僅僅考慮了樣本的方差估計，卻忽略了這個估計是有不確定性的 (uncertainty)，它並不是真實的 <span class="math inline">\(\sigma^2\)</span>，只是個估計 (estimator)。我們需要找到一種方法把方差的不確定性也考慮進新的檢驗統計量裏去。利用章節 <a href="02-Inference.html#samplevar">10.4</a> 的結論：</p>
<p><span class="math display" id="eq:infer8-2">\[
\begin{equation}
\frac{n-1}{\sigma^2}S^2 \sim \chi^2_{n-1}\\
\Rightarrow \frac{S^2}{\sigma^2} = \frac{\chi^2_{n-1}}{n-1}
\end{equation}
\tag{17.2}
\]</span></p>
<p>把公式 <a href="02-Inference.html#eq:infer8-1">(17.1)</a> 除以 <a href="02-Inference.html#eq:infer8-2">(17.2)</a> 獲得：</p>
<p><span class="math display">\[
\frac{(\bar{Y}-\mu_0)^2}{S^2/n} \sim \frac{\chi^2_1/1}{\chi^2_{n-1}/n-1} = F_{1,n-1}
\]</span></p>
<p>這樣我們就同時考慮了方差估計本身，和它的不確定性了。這個新的統計量被定義爲 <span class="math inline">\(T\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; T=\frac{\bar{Y}-\mu_0}{S/\sqrt{n}} \\
&amp; \text{Then under H}_0: T^2 \sim F_{1,n-1} \text{ or equivalently } T \sim \sqrt{F_{1,n-1}}=t_{n-1}
\end{aligned}
\]</span></p>
<p>這個特殊的 <span class="math inline">\(F\)</span> 分佈，就是我們之前定義過的，這裏用手紮紮實實地推導出來的檢驗統計量 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(t\)</span> 分佈。利用這個方差未知時的分佈，均值的 <span class="math inline">\(95\%\)</span> 信賴區間的估計就是：</p>
<p><span class="math display">\[
95\% \text{ CI for } \mu: \bar{Y} \pm t_{n-1,0.975}\frac{S}{\sqrt{n}}
\]</span></p>
</div>
<div id="比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2" class="section level2">
<h2><span class="header-section-number">17.5</span> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></h2>
<p>本節要來推導<strong>方差齊時</strong>的兩個獨立樣本的均值比較 two sample <span class="math inline">\(t\)</span> test。兩個獨立樣本用下面的數學符號標記：</p>
<p><span class="math display">\[
X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu_1, \sigma^2); Y_1, \cdots, Y_m, \stackrel{i.i.d}{\sim} N(\mu_2, \sigma^2)
\]</span></p>
<p>要進行的假設檢驗是：</p>
<p><span class="math display">\[
\text{H}_0: \mu_1 = \mu_2 \text{ v.s. } \text{H}_1: \mu_1 &gt; \mu_2
\]</span></p>
<p>此時，兩組獨立樣本的共同方差 <span class="math inline">\(\hat\sigma^2\)</span> 需要被估計，利用上面相同的推導過程，可以獲得合併後的共同方差的無偏估計：</p>
<p><span class="math display" id="eq:infer8-3">\[
\begin{equation}
\hat\sigma^2 = S^2_p = \frac{\sum^n_{i=1}(X_i-\bar{X})^2 + \sum^m_{i=1}(Y_i-\bar{Y})^2}{n+m-2}\\
\end{equation}
\tag{17.3}
\]</span></p>
<p>因爲兩組數據互相獨立，所以有：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{1}{\sigma^2}\sum^n_{i=1}(X_i - \bar{X})^2 \sim \chi^2_{n-1} \\
&amp; \frac{1}{\sigma^2}\sum^m_{i=1}(Y_i - \bar{Y})^2 \sim \chi^2_{m-1} \\
\Rightarrow &amp;\frac{1}{\sigma^2}\{ \sum^n_{i=1}(X_i - \bar{X})^2 + \sum^m_{i=1}(Y_i - \bar{Y})^2 \} \sim \chi^2_{n+m-2}
\end{aligned}
\]</span></p>
<p>把公式 <a href="02-Inference.html#eq:infer8-3">(17.3)</a> 代入此式可得：</p>
<p><span class="math display" id="eq:infer8-4">\[
\begin{equation}
(n+m-2)\frac{S^2_p}{\sigma^2} \sim \chi^2_{n+m-2}
\end{equation}
\tag{17.4}
\]</span></p>
<p>由於 <span class="math inline">\(\bar{X} \sim N(\mu_1, \frac{\sigma^2}{n}); \bar{Y} \sim N(\mu_2, \frac{\sigma^2}{m})\)</span>，所以在零假設條件下 <span class="math inline">\(\text{H}_0: \mu_1=\mu_2\Rightarrow \bar{X}-\bar{Y} \sim N(0,\sigma^2(\frac{1}{n}+\frac{1}{m}))\)</span>。</p>
<p><span class="math display" id="eq:infer8-5">\[
\begin{equation}
\Rightarrow \frac{\bar{X}-\bar{Y}}{\sqrt{\sigma^2(\frac{1}{n}+\frac{1}{m})}} \sim N(0,1) \\
\Leftrightarrow \frac{(\bar{X}-\bar{Y})^2}{\sigma^2(\frac{1}{n}+\frac{1}{m})} \sim \chi^2_1
\end{equation}
\tag{17.5}
\]</span></p>
<p>現在把公式 <a href="02-Inference.html#eq:infer8-5">(17.5)</a> 除以 <a href="02-Inference.html#eq:infer8-4">(17.4)</a> 可得：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{(\bar{X}-\bar{Y})^2}{\sigma^2(\frac{1}{n}+\frac{1}{m})} \times \frac{\sigma^2}{S^2_p(n+m-2)} = \frac{\chi^2_1/1}{\chi^2_{n+m-2}} \\
&amp;\Rightarrow T^2 = \frac{(\bar{X}-\bar{Y})^2}{S^2_p(\frac{1}{n}+\frac{1}{m})} = \frac{\chi^2_1/1}{\chi^2_{n+m-2}/(n+m-2)} \sim F_{1,n+m-2} \\
&amp;\Rightarrow T = \frac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2}
\end{aligned}
\]</span></p>
<p>這就是標準的兩個齊方差的獨立樣本均值比較的 <span class="math inline">\(t\)</span> 檢驗，two-sample <span class="math inline">\(t\)</span> test with pooled variance。這裏推導的兩個 <span class="math inline">\(t\)</span> 檢驗，是都是精確的<strong>似然比檢驗 (likelihood ratio test)</strong> (Section <a href="02-Inference.html#LRT">16.2</a>)。壯士請自己跟着似然比檢驗的方法推導一次。</p>
</div>
<div id="各個統計分佈之間的關係" class="section level2">
<h2><span class="header-section-number">17.6</span> 各個統計分佈之間的關係</h2>
<p>卡方分佈 <span class="math inline">\(\chi^2\)</span> 是統計學常用分佈中極爲重要的分佈，其他的許多分佈都與之相關。</p>
<p><span class="math display">\[
\{N(0,1)\}^2 = \chi^2_1 \\
\chi^2_k = \sum_{i-1}^k \chi^2_1 \\
F_{k,n} = \frac{\chi^2_k/k}{\chi^2_n/n}\\
t^2_n = F_{1,n} =\frac{\chi^2_1/1}{\chi^2_n/n}
\]</span></p>
</div>
</div>
<div id="多個參數時的統計推斷-inference-with-multiple-parameters-i" class="section level1">
<h1><span class="header-section-number">第 18 章</span> 多個參數時的統計推斷 Inference with multiple parameters I</h1>
<p>前一章介紹單樣本和雙樣本 <span class="math inline">\(t\)</span> 檢驗時已經接觸到了 2 個未知參數情況下的檢驗統計量推導，本章把之前用到的方法擴展到 2 個以上參數的情況。帶你推導兩個以上參數的似然比檢驗 likelihood ratio test，Wald 檢驗，和 Score 檢驗推論。</p>
<div id="多參數-multiple-parameters---lrt" class="section level2">
<h2><span class="header-section-number">18.1</span> 多參數 multiple parameters - LRT</h2>
<div id="似然-likelihood" class="section level3">
<h3><span class="header-section-number">18.1.1</span> 似然 likelihood</h3>
<p>如果一個觀察數據 <span class="math inline">\(\underline{x} = (x_1, \cdots, x_n)\)</span> 相互獨立，可以用含有 <span class="math inline">\(k\)</span> 個參數 <span class="math inline">\(\theta_1,\cdots,\theta_k\)</span> 的數學模型 <span class="math inline">\(f\)</span> 來描述，那麼它的似然公式爲：</p>
<p><span class="math display">\[
L(\theta_1,\cdots,\theta_k | \underline{x}) = f(\underline{x} | \theta_1,\cdots,\theta_k) = \prod^n_{i=1}f(x_i|\theta_1,\cdots,\theta_k)
\]</span></p>
<p>它的對數似然公式爲：</p>
<p><span class="math display">\[
\ell(\theta_1,\cdots,\theta_k|\underline{x}) = \sum^n_{i=1}\text{log}f(x_1|\theta_1,\cdots,\theta_k)
\]</span></p>
<p>每個參數的 <span class="math inline">\(\text{MLE}\)</span> 通過解下面的 <span class="math inline">\(k\)</span> 個連立方程組獲得：</p>
<p><span class="math display">\[
\left\{
\begin{array}{c}
\frac{\partial \ell}{\partial \theta_1} = \ell^\prime(\theta_1) = 0 \\
\frac{\partial \ell}{\partial \theta_2} = \ell^\prime(\theta_k) = 0 \\
\vdots \\
\frac{\partial \ell}{\partial \theta_k} = \ell^\prime(\theta_k) = 0 \\
\end{array}
\right.
\]</span></p>
<ul>
<li>這些連立方程有時被叫做 <strong>score equations</strong>；</li>
<li><p><span class="math inline">\(\text{MLE}\)</span> 的恆定性，不變性 invariance 在多個參數時同樣適用。</p></li>
<li>當參數只有一個 <span class="math inline">\(\theta\)</span> 時，其 <span class="math inline">\(\text{MLE}\)</span> 的方差是 <span class="math inline">\(S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\)</span></li>
<li><p>當參數有多個時，<span class="math inline">\(k\)</span> 個 <span class="math inline">\(\text{MLE}\)</span> 的方差是一個 <span class="math inline">\(k\times k\)</span> 的對稱矩陣，其中二次微分矩陣 <a href="02-Inference.html#eq:hessian-matrix">(18.1)</a> 的昵稱是<strong>海森矩陣 Hessian matrix</strong>：</p></li>
</ul>
<p><span class="math display" id="eq:hessian-matrix">\[
\begin{equation}
\underline{\ell^{\prime\prime}(\theta)} = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)
\end{equation}
\tag{18.1}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \underline{\ell^{\prime\prime}(\theta)} |_{\color{red}{\theta=\hat\theta}} =  \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k} \\
\end{array}
\right)_{\color{red}{\theta=\hat\theta}}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \underline{\text{Var}(\hat\theta)} = - \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)^{\color{red}{-1}}_{\color{red}{\theta=\hat\theta}}
\]</span></p>
</div>
<div id="對數似然比檢驗" class="section level3">
<h3><span class="header-section-number">18.1.2</span> 對數似然比檢驗</h3>
<p>多個參數未知時的對數似然比檢驗可以被這樣拓展：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{H}_0: \underline{\theta} = \underline{\theta_0} \\
&amp; \Rightarrow -2llr(\underline{\theta_0}) = -2(\ell(\underline{\theta_0})- \ell(\hat{\underline{\theta}})) \stackrel{\cdot}{\sim} \chi^2_r \\
&amp; \text{Where } r \text{ is the number of parameters restricted under H}_0
\end{aligned}
\]</span></p>
</div>
</div>
<div id="多參數-wald-檢驗---wald-test" class="section level2">
<h2><span class="header-section-number">18.2</span> 多參數 Wald 檢驗 - Wald test</h2>
<p>單個參數時的 Wald 檢驗的檢驗統計量：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{H}_0: \theta=\theta_0 \Rightarrow W_\theta = (\frac{M-\theta_0}{S})^2 \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; \text{Where } M=\hat\theta, S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}} \\
&amp; \Rightarrow W=(\hat\theta-\theta_0)^2(-\ell^{\prime\prime}(\hat\theta)) \stackrel{\cdot}{\sim} \chi^2_1
\end{aligned}
\]</span></p>
<p>如果是兩個參數 <span class="math inline">\(\lambda, \psi\)</span> 的 Wald 檢驗： <span class="math inline">\(\text{H}_0: \lambda=\lambda_0, \psi=\psi_0 \text{ v.s. H}_1: \lambda \neq \lambda_0 \text{ or } \psi \neq \psi_0\)</span>。</p>
<ul>
<li>我們可以先一個一個考慮參數：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; W_\lambda  = (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; W_\psi     = (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; \Rightarrow W_\lambda + W_\psi \stackrel{\cdot}{\sim} \chi^2_2 \\
&amp; \Rightarrow W = (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) + (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_2
\end{aligned}
\]</span></p>
<ul>
<li>也可以一開始就兩個參數一起考慮：</li>
</ul>
<p><span class="math display">\[
\underline{\ell^\prime} = \left(
\begin{array}{c}
\frac{\partial\ell}{\partial\lambda}\\
\frac{\partial\ell}{\partial\psi}
\end{array}
\right)
\Rightarrow \underline{\ell^{\prime\prime}} = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)
\]</span></p>
<p>然後單參數時 <span class="math inline">\(W\)</span> 的分子 <span class="math inline">\((\theta_0-\hat\theta)^2\)</span> 此時變爲：</p>
<p><span class="math display">\[
(\hat\lambda-\lambda_0)^2+(\hat\psi-\psi_0)^2 = (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right)
\]</span></p>
<p>所以兩個參數時的 Wald 檢驗統計量爲：</p>
<p><span class="math display">\[
\begin{aligned}
W = &amp; (\hat\lambda-\lambda_0, \hat\psi-\psi_0)(-\underline{\ell^{\prime\prime}}(\hat\lambda,\hat\psi))\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right) \\
= &amp; - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)_{\hat\lambda,\hat\psi}
\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right)\\
 &amp; \text{ Because } \lambda \text{ and } \psi \text{ are independent,} \\
 &amp; \text{ so their covariance } \frac{\partial^2\ell}{\partial\lambda\partial\psi} = \frac{\partial^2\ell}{\partial\psi\partial\lambda} = 0\\
 \Rightarrow  = &amp; - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
 \begin{array}{c}
 \ell^{\prime\prime}(\hat\lambda)  &amp; 0 \\
 0 &amp; \ell^{\prime\prime}(\hat\psi)
 \end{array}
 \right)
 \left(
 \begin{array}{c}
 \hat\lambda-\lambda_0 \\
 \hat\psi-\psi_0
 \end{array}
 \right)\\
 = &amp;  - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
 \begin{array}{c}
 \ell^{\prime\prime}(\hat\lambda)(\hat\lambda-\lambda_0) \\
 \ell^{\prime\prime}(\hat\psi)(\hat\psi-\psi_0)
 \end{array}
 \right) \\
= &amp; (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) + (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_2
\end{aligned}
\]</span></p>
<p>由此可見，兩個參數分開來考慮之後把統計量相加，和一開始就把兩個參數放在一起，利用矩陣計算後獲得的檢驗統計量完全相同。用矩陣的好處是可以把上面的推導過程直接擴展成 <span class="math inline">\(k\)</span> 個參數的形式，且標記簡便：</p>
<p><span class="math display">\[
W = -(\hat{\underline{\theta}} - \underline{\theta_0})^T\underline{\ell^{\prime\prime}(\hat\theta)}(\underline{\hat\theta} - \underline{\theta_0})  \stackrel{\cdot}{\sim} \chi^2_k
\]</span></p>
</div>
<div id="多參數-score-檢驗---score-test" class="section level2">
<h2><span class="header-section-number">18.3</span> 多參數 Score 檢驗 - Score test</h2>
<p>單個參數時的 Score 檢驗的檢驗統計量：</p>
<p><span class="math display">\[
 \text{H}_0: \theta=\theta_0 \text{ v.s. H}_1: \theta \neq \theta_0 \\
 \frac{U^2}{V} \stackrel{\cdot}{\sim} \chi^2_1 \\
 \text{Where } U=\ell^\prime(\theta_0), V=E[-\ell^{\prime\prime}(\theta_0)]
\]</span></p>
<p>類似 Wald 檢驗法的矩陣推導過程和標記法，<span class="math inline">\(k\)</span> 個參數的 Score 檢驗的統計量可以標記爲：</p>
<p><span class="math display">\[
\underline{U}^T\underline{V}^{-1}\underline{U} \stackrel{\cdot}{\sim} \chi^2_k \\
\text{Where } \underline{U} = \left.\frac{\partial\ell}{\partial\underline{\theta}} \right\vert_{\underline{\theta}=\underline{\theta_0}},
\underline{V} = E[-\underline{\ell^{\prime\prime}(\theta)}]_{\underline{\theta}=\underline{\theta_0}}
\]</span></p>
<p>所以如果是兩個參數 <span class="math inline">\(\lambda, \psi\)</span> 那麼檢驗 <span class="math inline">\(\text{H}_0:\lambda = \lambda_0, \psi = \psi_0 \text{ v.s. H}_1: \lambda \neq \lambda_0 \text{ or } \psi\neq\psi_0\)</span> 的 Score 檢驗統計量是：</p>
<p><span class="math display">\[
(\frac{\partial\ell}{\partial\lambda}, \frac{\partial\ell}{\partial\psi})_{\lambda_0, \psi_0}\left(
E\left[
-\left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)_{\lambda_0,\psi_0}
\right]
\right)^{-1}\left(
\begin{array}{c}
\frac{\partial\ell}{\partial\lambda}\\
\frac{\partial\ell}{\partial\psi}
\end{array}
\right)_{\lambda_0,\psi_0} \stackrel{\cdot}{\sim} \chi^2_2
\]</span></p>
</div>
<div id="condilikeli" class="section level2">
<h2><span class="header-section-number">18.4</span> 條件似然 conditional likelihood</h2>
<p>現實的例子中，參數可能有非常多，但是我們可能只關心其中幾個。下章介紹的子集似然函數 (profile likelihood) 是可以在多種情況下應用的好方法。本節介紹的方法是<strong>條件似然法</strong>。簡單原理是，把模型中不能提供我們感興趣的參數的有效信息的那些參數 (“nuisance” parameters) 當作是固定的 (fixed)。由此可以定義一個新的概率模型 – <strong>條件概率模型 conditional probability model</strong>。</p>
<p>我們用泊松模型來解釋如何建立這樣的模型。</p>
<p>兩個獨立的人羣追蹤樣本，在 <span class="math inline">\(p_0, p_1\)</span> 人年的隨訪中發生事件 A 的次數分別是 <span class="math inline">\(k_0, k_1\)</span>。假設我們只關心兩組的事件 A 發生率的比 <span class="math inline">\(\text{Rate ratio:} \theta=\frac{\lambda_1}{\lambda_0}\)</span>。</p>
<p>合併兩個人羣，發生事件 A 的總次數爲 <span class="math inline">\(k=k_0+k_1\)</span>。只知道 <span class="math inline">\(k\)</span> 並不能讓我們推算兩個人羣中各發生了多少次事件 A，也無法用它來計算發生率的比 <span class="math inline">\(\theta\)</span>，而這個 <span class="math inline">\(k\)</span> 就是條件概率模型中的條件。</p>
<p><span class="math display">\[
K_0 \sim Po(\mu_0); K_1 \sim Po(\mu_1) ; \text{ where } \mu_0 = \lambda_0 p_0 \mu_1 = \lambda_1 p_1\\
k=k_0 + k_1 \Rightarrow K_0+K_1 \sim Po(\mu_0 + \mu_1)
\]</span></p>
<p><span class="math display" id="eq:infer9-1">\[
\begin{aligned}
  &amp; \text{Prob}(k_0 \text{events in group 0} | k \text{ events in total}) \\
= &amp; \frac{\text{Prob}(k_0 \text{ events in group }0 \text{ and } k-k_0 \text{ events in  group } 1)}
 {\text{Prob}(k \text{ events in total})} \\
\end{aligned}
\tag{18.2}
\]</span></p>
<p>由於兩個樣本是來自獨立的人羣，所以公式 <a href="02-Inference.html#eq:infer9-1">(18.2)</a> 的分母，和分子分別是</p>
<p><span class="math display">\[
\begin{aligned}
\text{Prob}(k &amp;\text{ events in total}) \\
 = &amp; \frac{(\lambda_0 p_0 + \lambda_1 p_1)^k e^{-(\lambda_0 p_0 + \lambda_1 p_1)}}{k!} \\
\text{Prob}(k_0 &amp;\text{ events in group }0 \text{ and } k-k_0 \text{ events in  group } 1) \\
 = &amp; \frac{(\lambda_0 p_0)^{k_0}e^{-\lambda_0 p_0}}{k_0!}\times\frac{(\lambda_1 p_1)^{k-k_0}e^{-\lambda_1 p_1}}{(k-k_0)!}
\end{aligned}
\]</span></p>
<p>所以公式 <a href="02-Inference.html#eq:infer9-1">(18.2)</a> 可以整理成：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\frac{(\lambda_0 p_0)^{k_0}e^{-\lambda_0 p_0}}{k_0!}\times\frac{(\lambda_1 p_1)^{k-k_0}e^{-\lambda_1 p_1}}{(k-k_0)!}}
{\frac{(\lambda_0 p_0 + \lambda_1 p_1)^k e^{-(\lambda_0 p_0 + \lambda_1 p_1)}}{k!}} \\
= &amp;  \frac{e^{-(\lambda_0 p_0 + \lambda_1 p_1)}(\lambda_0 p_0)^{k_0}(\lambda_1 p_1)^{k-k_0}\cdot k!}{e^{-(\lambda_0 p_0 + \lambda_1 p_1)}(\lambda_0p_0+\lambda_1p_1)^k\cdot k_0!\cdot (k-k_0)!}\\
= &amp; (\frac{\lambda_0 p_0}{\lambda_0 p_0+\lambda_1 p_1})^{k_0}(\frac{\lambda_1 p_1}{\lambda_0 p_0+\lambda_1 p_1})^{k-k_0}\cdot\frac{k!}{k_0!(k-k_0)!} \\
= &amp; (\pi)^{k_0}(1-\pi)^{k-k_0}\cdot\frac{k!}{k_0!(k-k_0)!} \\
\text{Where } &amp; \pi = \frac{\lambda_0 p_0}{\lambda_0 p_0 + \lambda_1 p_1} = \frac{p_0}{p_0+(\lambda_1/\lambda_0)p_1} = \frac{p_0}{p_0+\theta p_1}\\
\Rightarrow &amp;\text{ Given } K_0+K_1=K, K_0 \sim Bin(k, \pi=\frac{p_0}{p_0+\theta p_1})
\end{aligned}
\]</span></p>
<p>我們就把兩個泊松分佈的模型，變形成爲了一個條件二項分佈，而且只有一個未知參數 <span class="math inline">\(\theta\)</span>。之後就可以用二項分佈的對數似然方程進行下一步的假設檢驗的構建：</p>
<p><span class="math display" id="eq:inference9-2">\[
\begin{aligned}
               L(\pi) &amp; = (\pi)^{k_0}(1-\pi)^{k-k_0}  \\
\Rightarrow \ell(\pi) &amp; = k_0 \text{log}\pi + (k-k_0)\text{log} (1-\pi) \\
\text{Because }  \pi  &amp; = \frac{p_0}{p_0+\theta p_1} \\
        \ell_c(\theta)  &amp; = k_0 \text{log}(\frac{\pi}{1-\pi}) + k\text{log}(1-\pi) \\
                      &amp; = k_0 \text{log}(\frac{p_0}{\theta p_1}) + k\text{log}(\frac{\theta p_1}{p_0 + \theta p_1}) \\
\text{Ignoring} &amp; \text{ terms not involving } \theta \\
        \ell_c(\theta)&amp; = k_1 \text{log}\theta - k\text{log}(p_0 + \theta p_1)
\end{aligned}
\tag{18.3}
\]</span></p>
<p>至此，推導發生率比 <span class="math inline">\(\theta = \frac{\lambda_1}{\lambda_0}\)</span> 的條件對數似然就完成了。Elegant and Bravo!</p>
<p>關於條件對數似然：</p>
<ol style="list-style-type: decimal">
<li>推導出的條件對數似然是一個<strong>真實</strong>的以觀察數據爲條件的對數似然，可以用於假設檢驗；</li>
<li>條件似然過程依賴於我們能否找到這樣一個“條件似然”，使得模型的對數似然<strong>只取決於我們關心的參數</strong>，我們幸運地找到了發生率比的對數似然方程，<strong>但是至今沒有人找到發生率差 <span class="math inline">\(\lambda_1-\lambda_0\)</span> 的條件對數似然</strong>；</li>
<li>與此相對地是，下一章介紹的子集似然函數 (profile likelihood)，可以用於幾乎所有的多參數模型的假設檢驗之構建；</li>
<li>但是，條件對數似然相當之重要，特別是它作爲 Cox proportional hazard model 模型的基本模型構架在生存分析 (survival analysis) 中的應用，以及在配對病例對照分析 (matched case-control study) 中用於條件邏輯迴歸 (conditional logistic regression) 的理論基礎 (將會在第二學期的碩士課程中介紹，敬請期待)。</li>
</ol>
</div>
<div id="練習" class="section level2">
<h2><span class="header-section-number">18.5</span> 練習</h2>
<p>某項研究追蹤隨訪 50-69 歲男性的心臟病發病率。研究對象根據心臟病發病史的有無分成兩組。有心臟病史的對象被隨訪 512 人・年，觀察到 25 例新的心臟病發作病例；無心臟病史的對象被隨訪 4862 人・年，觀察到 52 例新的心臟病發作病例。</p>
<ol style="list-style-type: decimal">
<li>如果需要檢驗的零假設是 <span class="math inline">\(\text{H}_0:\)</span> 有心臟病史的男性<strong>發病率的對數</strong>等於 <span class="math inline">\(-3\)</span>，無心臟病史的男性發病率的對數等於 <span class="math inline">\(-4.5\)</span>。請推導該實驗的<strong>聯合</strong>對數似然比檢驗，Wald 檢驗兩種檢驗法的檢驗統計量，並進行假設檢驗。</li>
</ol>
<p><strong>解</strong></p>
<ul>
<li>模型：</li>
</ul>
<p>令隨機變量 <span class="math inline">\(K_i\)</span> 標記新發生的心臟病病例數，其中當 <span class="math inline">\(i=0\)</span> 時代表<strong>無心臟病史組</strong>；當 <span class="math inline">\(i=1\)</span> 時代表<strong>有心臟病史組</strong>。所以可以用下面的泊松模型來標記兩組的新發生心臟病病例數：</p>
<p><span class="math display">\[
K_i \sim \text{Poisson}(\mu_i); \mu_i = \lambda_i p_i\\
\text{Where } \lambda_i \text{ is the rate parameter in group } i, \\
p_i \text{ is the person-years at risk in group }i \\
\]</span></p>
<p>有無心臟病史組之間由於是相互獨立的，故兩組的對數似然相加之後就可得到合併後的對數似然。</p>
<ul>
<li>數據：</li>
</ul>
<p><span class="math display">\[
k_0 = 52, p_0 = 4862; k_1 = 25, p_1 = 512
\]</span></p>
<p>泊松模型的對數似然方程爲 (Section <a href="02-Inference.html#likelihood-poi">12.6</a>)：</p>
<p><span class="math display">\[
\ell(\lambda | \text{data}) = -\lambda p + k \text{log} \lambda
\]</span></p>
<p>令 <span class="math inline">\(\psi = \text{log} \lambda\)</span> 有：</p>
<p><span class="math display">\[
\ell(\psi) = k \psi - e^\psi p
\]</span></p>
<p>令 <span class="math inline">\(\psi_0 = \text{log}\lambda_0; \psi_1 = \text{log}\lambda_1\)</span>，那麼本題中的假設檢驗可以寫成是：</p>
<p><span class="math display">\[\text{H}_0: {\psi_0}_0 = -4.5, {\psi_1}_0 = -3 \text{ v.s. H}_1: {\psi_0}_0 \neq -4.5 \text{ or } {\psi_1}_0 \neq -3\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>對數似然比檢驗需要尋找的檢驗統計量是 <span class="math inline">\(-2llr({\psi_0}_0,{\psi_1}_0)\)</span>，其中：</li>
</ol>
<p><span class="math display">\[
llr({\psi_0}_0,{\psi_1}_0) = \ell({\psi_0}_0,{\psi_1}_0) - \ell(\hat\psi_0,\hat\psi_1)
\]</span></p>
<p>所以我們分別來計算 <span class="math inline">\(\ell({\psi_0}_0,{\psi_1}_0)\)</span> 和 <span class="math inline">\(\ell(\hat\psi_0,\hat\psi_1)\)</span>：</p>
<p><span class="math display" id="eq:infer9-prac-1">\[
\begin{equation}
\ell(\psi_0, \psi_1) = k_0 \psi_0 - e^{\psi_0} p_0 + k_1 \psi_1 - e^{\psi_1} p_1
\end{equation}
\tag{18.4}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \frac{\partial\ell}{\partial\psi_0} = k_0 - e^{\psi_0}p_0 \\
\text{and} \\
\frac{\partial\ell}{\partial\psi_1} = k_1 - e^{\psi_1}p_1
\]</span></p>
<p>然後我們把這兩個偏微分式子等於零時的解作爲 <span class="math inline">\(\psi_0, \psi_1\)</span> 的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial\ell}{\partial{\psi}_0} &amp; = 0 \\
\Rightarrow          e^{{\hat\psi}_0} &amp; = \frac{k_0}{p_0} \\
\Rightarrow             {\hat\psi}_0  &amp; = \text{log}(\frac{k_0}{p_0}) \\
\text{And similarly }   {\hat\psi}_1  &amp; = \text{log}(\frac{k_1}{p_1})
\end{aligned}
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[
\begin{aligned}
\ell({\psi_0}_0,{\psi_1}_0) &amp; = 52\times(-4.5) - e^{-4.5}\times4862+25\times(-3)-e^{-3}\times512 \\
                            &amp; = -388.5029 \\
\ell(\hat\psi_0,\hat\psi_1) &amp; = 52\times\text{log}\frac{52}{4862} - e^{\text{log}\frac{52}{4862}}\times4862 + 25\times\text{log}\frac{25}{512} - e^{\text{log}\frac{25}{512}}\times512 \\
                            &amp; = 52\times\text{log}\frac{52}{4862} - 52 + 25\times\text{log}\frac{25}{512} - 25 \\
                            &amp; = -388.4602 \\
\Rightarrow llr({\psi_0}_0,{\psi_1}_0)  &amp; =   -388.5029 - (-388.4602) = - 0.0427 \\
\Rightarrow -2llr({\psi_0}_0,{\psi_1}_0)  &amp; = 0.0854
\end{aligned}
\]</span></p>
<p>因爲在零假設條件下 <span class="math inline">\(-2llr \stackrel{\cdot}{\sim} \chi^2_2\)</span>，本次檢驗的拒絕域是 <span class="math inline">\(\mathfrak{R} &gt; \chi^2_{2,0.95} = 5.99\)</span>，所以，檢驗的結果 <span class="math inline">\(-2llr = 0.0854 &lt; 5.99\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Wald 檢驗時我們需要的檢驗統計量爲：</li>
</ol>
<p><span class="math display">\[
W = (\hat\psi_0-{\psi_0}_0, \hat\psi_1-{\psi_1}_0)(-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\left(
\begin{array}{c}
\hat\psi_0-{\psi_0}_0 \\
\hat\psi_1-{\psi_1}_0
\end{array}
\right)
\]</span></p>
<p>先處理中間那個看起來比較棘手的 <span class="math inline">\((-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\underline{\ell^\prime}(\psi_0, \psi_1) &amp; = \left(
\begin{array}{c}
k_0 - e^{\psi_0}p_0 \\
k_1 - e^{\psi_1}p_1
\end{array}
\right) \\
\Rightarrow \underline{\ell^{\prime\prime}}(\psi_0,\psi_1) &amp; = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\psi^2_0} &amp; \frac{\partial^2\ell}{\partial\psi_1\partial\psi_0} \\
\frac{\partial^2\ell}{\partial\psi_0\partial\psi_1} &amp; \frac{\partial^2\ell}{\partial\psi^2_1}
\end{array}
\right) = \left(
\begin{array}{c}
-e^{\psi_0}p_0  &amp; 0\\
0  &amp; -e^{\psi_1}p_1
\end{array}
\right) \\
\Rightarrow -\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1) &amp; = \left(
\begin{array}{c}
-e^{\hat\psi_0}p_0  &amp; 0\\
0  &amp; -e^{\hat\psi_1}p_1
\end{array}
\right) \\
 &amp; = \left(
\begin{array}{c}
-e^{\text{log}(\frac{52}{4862})}\times4862  &amp; 0\\
0  &amp; -e^{\text{log}(\frac{25}{512})}\times512
\end{array}
\right) \\
&amp; = \left(
\begin{array}{c}
52  &amp; 0\\
0  &amp; 25
\end{array}
\right)
\end{aligned}
\]</span></p>
<p>又有 <span class="math inline">\(\hat\psi_1-{\psi_1}_0 = \text{log}(\frac{25}{512})-(-3) = -0.0194\)</span></p>
<p>和 <span class="math inline">\(\hat\psi_0-{\psi_0}_0 = \text{log}(\frac{52}{4862})-(-4.5) = -0.0379\)</span></p>
<p>所以</p>
<p><span class="math display">\[
\begin{aligned}
W &amp; = (\hat\psi_0-{\psi_0}_0, \hat\psi_1-{\psi_1}_0)(-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\left(
\begin{array}{c}
\hat\psi_0-{\psi_0}_0 \\
\hat\psi_1-{\psi_1}_0
\end{array}
\right) \\
  &amp; = (-0.0379, -0.0194)\left(
  \begin{array}{c}
  52  &amp; 0\\
  0  &amp; 25
  \end{array}
  \right)\left(
  \begin{array}{c}
  -0.0379 \\
  -0.0194
  \end{array}
  \right) = 0.08439208
\end{aligned}
\]</span></p>
<p>Wald 檢驗的檢驗統計量也一樣服從 <span class="math inline">\(\chi^2_2\)</span>，所以拒絕域同對數似然比檢驗法的<span class="math inline">\(\mathfrak{R} &gt; \chi^2_{2,0.95} = 5.99\)</span>，所以，檢驗的結果 <span class="math inline">\(W = 0.08439208 &lt; 5.99\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
<ol start="2" style="list-style-type: decimal">
<li>利用本節推導出的發生率比的<strong>條件對數似然方程</strong>，請嘗試進行對數似然比檢驗：心臟病發作率在無病史男性中和有病史男性中的比例爲 <span class="math inline">\(0.2\)</span>。</li>
</ol>
<p>本章推導的發生率的比值的條件對數似然方程爲：</p>
<p><span class="math display">\[
\ell_c(\theta)  = k_1 \text{log}\theta - k\text{log}(p_0 + \theta p_1) \\
\text{Where } \theta = \frac{\lambda_1}{\lambda_0}
\]</span></p>
<p>題目要求比較的是 <span class="math inline">\(\frac{\lambda_0}{\lambda_1} = 0.2\)</span>，用本題中的 <span class="math inline">\(\lambda_0\)</span> 取代條件對數似然方程中的 <span class="math inline">\(\lambda_1\)</span> 則有：</p>
<p><span class="math display">\[
\ell_c{\theta} = k_0\text{log}\theta - k\text{log}(p_1 + \theta p_0) \\
\text{H}_0: \theta_0 = 0.2 \text{ v.s. H}_1: \theta_0 \neq 0.2
\]</span></p>
<p>對於條件對數似然比檢驗，需要的檢驗統計量是 <span class="math inline">\(-2llr_c(\theta_0)\)</span> 其中：</p>
<p><span class="math display">\[
llr_c(\theta_0) = \ell_c(\theta_0) - \ell_c(\hat\theta)
\]</span></p>
<p>先計算 <span class="math inline">\(\ell_c(\hat\theta)\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
      \text{Let }\ell_c^\prime &amp; = \frac{k_0}{\theta} - \frac{kp_0}{p_1+\theta p_0} = 0 \\
\Rightarrow \frac{k_0}{\theta} &amp; = \frac{kp_0}{p_1+\theta p_0} \\
\Rightarrow \hat\theta         &amp; = \frac{k_0p_1}{p_0k_1} = \frac{k_0/p_0}{k_1/p_1} \\
\Rightarrow \hat\theta         &amp; = \frac{52\times512}{4862\times25} = 0.219037 \\
\Rightarrow \ell_c(\theta_0)   &amp; = k_0\text{log}0.2 -  k\text{log}(p_1 + \theta p_0) \\
                               &amp; = 52\times\text{log}0.2 - 77\times\text{log}(512 + 0.2\times4862) \\
                               &amp; = -646.003 \\
          \ell_c{\hat\theta}   &amp; = 52\times\text{log}0.219037 - 77\times\text{log}(512 + 0.219037\times4862)\\
                               &amp; = -645.933 \\
\Rightarrow -2llr(\theta_0)    &amp; = -2\times(-646.003-(-645.933)) = 0.14
\end{aligned}
\]</span></p>
<p>因爲在零假設條件下 <span class="math inline">\(-2llr \stackrel{\cdot}{\sim} \chi^2_1\)</span>，本次檢驗的拒絕域是 <span class="math inline">\(\mathfrak{R} &gt; \chi^2_{1,0.95} = 3.84\)</span>，所以，檢驗的結果 <span class="math inline">\(-2llr = 0.14 &lt; 3.84\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
</div>
</div>
<div id="profile-log-likelihood" class="section level1">
<h1><span class="header-section-number">第 19 章</span> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</h1>
<p>本章介紹的子集似然法是處理多個參數模型的主要方法。前章介紹的<strong>條件似然法</strong>也是相當出色的方法，但是許多情況下我們無法找到合適的“條件”來輔助我們擺脫那些模型中不需要的，<strong>障礙 (或者叫噪音) 參數 nuisance parameters</strong>。</p>
<p>我們還是沿用上一節的例子。</p>
<p>兩個獨立的人羣追蹤樣本，在 <span class="math inline">\(p_0, p_1\)</span> 人年的隨訪中發生事件 A 的次數分別是 <span class="math inline">\(k_0, k_1\)</span>。我們只關心兩組的事件 A 發生率的比 <span class="math inline">\(\text{Rate ratio:} \theta=\frac{\lambda_1}{\lambda_0}\)</span>。兩個人羣的聯合對數似然函數如下：</p>
<p><span class="math display">\[
\ell(\lambda_0, \lambda_1) = k_0\text{log}\lambda_0 - \lambda_0p0 + k_1\text{log}\lambda_1 - \lambda_1p1
\]</span></p>
<ul>
<li>Step 1. 先用 <span class="math inline">\(\lambda_1 = \lambda_0\theta\)</span> 取代掉上面式子中的 <span class="math inline">\(\lambda_1\)</span>。</li>
</ul>
<p><span class="math display" id="eq:infer10-1">\[
\begin{aligned}
\Rightarrow \ell(\lambda_0, \theta) &amp; = k\text{log}\lambda_0 + k_1\text{log}\theta - \lambda_0(P_0 + \theta p_1) \\
\text{Where } k &amp; = k_0 + k_1
\end{aligned}
\tag{19.1}
\]</span></p>
<p>這一步先是消滅了一個障礙參數 <span class="math inline">\(\lambda_1\)</span>，獲得了一個我們關心的參數 <span class="math inline">\(\theta\)</span>，和 <span class="math inline">\(\lambda_0\)</span> 的對數似然方程。接下來，我們尋找用 <span class="math inline">\(\theta\)</span> 表示 <span class="math inline">\(\lambda_0\)</span> (用 <span class="math inline">\(\hat\lambda_0(\theta)\)</span> 標記) 的似然方程，使得只包含一個參數 <span class="math inline">\(\theta\)</span> 的對數似然方程可以在每個 <span class="math inline">\(\lambda_0\)</span> 時取得極大值。此時我們定義 <span class="math inline">\(\theta\)</span> 的子集對數似然方程 profile log-likelihood是：</p>
<p><span class="math display">\[
\ell_p(\theta) = \ell(\hat\lambda_0(\theta),\theta)
\]</span></p>
<ul>
<li>Step 2. 爲了求 <span class="math inline">\(\hat\lambda_0(\theta)\)</span>，先視 <span class="math inline">\(\theta\)</span> 爲不變的，對上式 <a href="02-Inference.html#eq:infer10-1">(19.1)</a> 求 <span class="math inline">\(\lambda_0\)</span> 的微分：</li>
</ul>
<p><span class="math display">\[
\frac{\partial\ell(\lambda_0,\theta)}{\partial\lambda_0}=\frac{k}{\lambda_0} - (p_0+\theta p_1)
\]</span></p>
<p>把該微分方程等於0，推導出 <span class="math inline">\(\hat\lambda_0=\frac{k}{p_0+\theta p_1}\)</span> 就是 <span class="math inline">\(\theta\)</span> 在取值範圍內所有能使對數似然方程 <a href="02-Inference.html#eq:infer10-1">(19.1)</a> 取極大值的對應 <span class="math inline">\(\lambda_0\)</span>。</p>
<ul>
<li>Step 3. 將這個 <span class="math inline">\(\theta\)</span> 表示的 <span class="math inline">\(\lambda_0\text{ MLE}\)</span> 代替 <span class="math inline">\(\lambda_0\)</span> 代入對數似然方程 <a href="02-Inference.html#eq:infer10-1">(19.1)</a> 中去：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\ell_p(\theta) &amp;= k\text{log}\frac{k}{p_0 + \theta p_1} + k_1 \text{log}\theta - k \\
\text{Ignoring} &amp;\text{ items not involving } \theta\\
\Rightarrow &amp;= k_1\text{log}\theta - k\text{log}(p_0+\theta p_1)
\end{aligned}
\]</span></p>
<p>這個用子集似然法推導的關於參數 <span class="math inline">\(\theta\)</span> 的似然方程和前一章用條件似然法 (Section <a href="02-Inference.html#condilikeli">18.4</a>) 推導的結果是完全一致的 <a href="02-Inference.html#eq:inference9-2">(18.3)</a>。</p>
<div id="子集似然法推導的過程總結" class="section level2">
<h2><span class="header-section-number">19.1</span> 子集似然法推導的過程總結</h2>
<ol style="list-style-type: decimal">
<li>多個參數中區分出我們感興趣的參數 <span class="math inline">\(\psi\)</span> 和其餘的障礙(噪音)參數 <span class="math inline">\(\lambda\)</span>；</li>
<li>爲了從對數似然方程中消除噪音參數，把它們一一通過微分求極值的辦法表達成用 <span class="math inline">\(\psi\)</span> 標記的表達式，用這些包含了 <span class="math inline">\(\psi\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 代替所有的噪音參數；</li>
<li>整理最終獲得的只有感興趣的參數的對數似然方程，記得把不包含參數的部分忽略掉。</li>
</ol>
<div id="子集對數似然方程的分佈" class="section level3">
<h3><span class="header-section-number">19.1.1</span> 子集對數似然方程的分佈</h3>
<p><span class="math display">\[
-2pllr(\psi) = -2\{ \ell_p(\psi) - \ell(\hat\psi)\} \stackrel{\cdot}{\sim} \chi^2_r
\]</span></p>
<p>其中自由度 <span class="math inline">\(r\)</span> 是想要檢驗的零假設中受限制的參數的個數。Degree of freedom <span class="math inline">\(r\)</span> is the number of parameters restricted under the null hypothesis. 所以，如果 <span class="math inline">\(\psi\)</span> 是一個維度 (dimension) 爲 <span class="math inline">\(p\)</span> 的向量，如果零假設是 <span class="math inline">\(\text{H}_0: \psi = \psi_0\)</span>，那麼自由度就是 <span class="math inline">\(p\)</span>。</p>
</div>
<div id="假設檢驗過程舉例" class="section level3">
<h3><span class="header-section-number">19.1.2</span> 假設檢驗過程舉例</h3>
<p>兩個獨立的二項分佈樣本：<span class="math inline">\(K_0 \sim \text{Bin}(n_0, \pi_0), K_1 \sim \text{Bin}(n_1, \pi_1)\)</span>。它們的聯合對數似然爲：</p>
<p><span class="math display">\[
\ell(\pi_0, \pi_1) = \ell(\pi_0) + \ell(\pi_1)
\]</span></p>
<p>如果要檢驗的零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \pi_0 = \pi_1 \text{ v.s. H}_1: \pi_0 \neq \pi_1\)</span>。</p>
<p>如果令 <span class="math inline">\(\theta=\frac{\pi_1}{\pi_0}\)</span>，那麼要檢驗的零假設和替代假設就變成了：</p>
<p><span class="math display">\[
\text{H}_0: \theta = 1 \text{ v.s. H}_1: \theta \neq 1 \\
\Rightarrow -2 pllr \stackrel{\cdot}{\sim} \chi^2_1
\]</span></p>
<p>而且在零假設條件下，<span class="math inline">\(\text{H}_0: K_0+K_1 \sim \text{Bin}(n_0+n_1, \pi)\)</span>，那麼自己對數似然比檢驗的統計量是：</p>
<p><span class="math display">\[
\begin{aligned}
-2 pllr &amp; = -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi_0,\theta\pi_0)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\theta\pi_0)}] \} \\
\Rightarrow -2 pllr &amp; =  -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi,\theta\pi)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\pi_1)}] \} \\
\Rightarrow -2 pllr &amp; = -2\{ \ell{(\hat\pi)} - \ell{(\hat\pi_0, \hat\pi_1)} \}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="子集對數似然比的近似" class="section level2">
<h2><span class="header-section-number">19.2</span> 子集對數似然比的近似</h2>
<p>假如有兩個獨立樣本數據，參數分別只有一個 <span class="math inline">\(\beta_0, \beta_1\)</span>，我們關心他們二者之間的差是否有意義 <span class="math inline">\(\gamma = \beta_1-\beta_0\)</span>。如果 <span class="math inline">\(\beta_0\)</span> 的對數似然比檢驗統計量的相應的 Wald 檢驗統計量 (二次方程近似法 Section <a href="02-Inference.html#Wald">16.4</a>) 可以用 <span class="math inline">\(\hat\beta_0, S_0\)</span> 定義，其中 <span class="math inline">\(\beta_0\)</span> 是 <span class="math inline">\(\text{MLE}\)</span>，<span class="math inline">\(S_0\)</span> 是標準誤差。類似的，<span class="math inline">\(\beta_1\)</span> 的 Wald 檢驗統計量可以用 <span class="math inline">\(\hat\beta_1, S_1\)</span> 定義。那麼，我們關心的參數，<span class="math inline">\(\gamma = \beta_1 - \beta_0\)</span> 的 Wald 檢驗統計量可以用 <span class="math inline">\(\hat\gamma = \hat\beta_1 - \hat\beta_1, S=\sqrt{S^2_1 + S^2_0}\)</span> 定義：</p>
<p><span class="math display">\[
\begin{aligned}
pllr(\gamma) &amp; = -\frac{1}{2}(\frac{\gamma-\hat\gamma}{\sqrt{S^2_1+S^2_0}})^2 \\
&amp; = -\frac{1}{2}(\frac{(\beta_1-\beta_0)-(\hat\beta_1-\hat\beta_0)}{\sqrt{S^2_1+S^2_0}})^2
\end{aligned}
\]</span></p>
<div id="子集對數似然比近似的一般化" class="section level3">
<h3><span class="header-section-number">19.2.1</span> 子集對數似然比近似的一般化</h3>
<p>如果我們關心的參數，和模型參數的關係可以用下面的表達式來表示：</p>
<p><span class="math display">\[
\gamma = W_0\beta_0 + W_1\beta_1 + \cdots \\
\text{ Where } W_i \text{ are arbitrary cosntants}
\]</span></p>
<p>如果，模型中的每個參數 <span class="math inline">\(\beta_0, \beta_1, \cdots\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\beta_0, \hat\beta_1, \cdots\)</span>，標準誤是 <span class="math inline">\(S=\sqrt{(W_0S_0)^2+(W_1S_2)^2+\cdots}\)</span></p>
</div>
<div id="事件發生率之比的-wald-檢驗統計量" class="section level3">
<h3><span class="header-section-number">19.2.2</span> 事件發生率之比的 Wald 檢驗統計量</h3>
<p>事件發生率 (Possion rate ratio) <span class="math inline">\(\theta = \frac{\lambda_1}{\lambda_0}\)</span></p>
<p>令 <span class="math inline">\(\beta_1 = \text{log}\lambda_1, \beta_0 = \text{log}\lambda_0, \gamma = \text{log}\theta\)</span>。</p>
<p>所以有 <span class="math inline">\(\gamma=\beta_1-\beta_0\)</span>。</p>
<p>由於</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta_0 &amp; = \text{log}(\frac{k_0}{p_0}), \\
\hat\beta_1 &amp; = \text{log}(\frac{k_1}{p_1}) \\
\end{aligned}
\]</span></p>
<p>因而</p>
<p><span class="math display">\[
\begin{aligned}
\hat\gamma &amp; = \text{log}\frac{k_1}{p_1} - \text{log}\frac{k_0}{p_0} \\
           &amp; = \text{log}\frac{k_1/p_1}{k_0/p_0}
\end{aligned}
\]</span></p>
<p>又由於 <span class="math inline">\(S_0 = \frac{1}{\sqrt{k_0}}, S_1 = \frac{1}{\sqrt{k_1}}\)</span> (Section <a href="02-Inference.html#Possion-log-transform">14.2.1</a>)。</p>
<p>所以 <span class="math inline">\(S=\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}\)</span>。</p>
<p>綜上，事件發生率之比的 Wald 檢驗統計量爲</p>
<p><span class="math display">\[
\begin{aligned}
pllr(\gamma) &amp; = -\frac{1}{2}(\frac{\gamma - \hat\gamma}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2 \\
             &amp; = -\frac{1}{2}(\frac{\text{log}\theta - \text{log}\frac{k_1/p_1}{k_0/p_0}}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2
\end{aligned}
\]</span></p>
</div>
</div>
<div id="練習-practical" class="section level2">
<h2><span class="header-section-number">19.3</span> 練習 Practical</h2>
<p><span class="math inline">\(n\)</span> 名肺癌 I 期患者的倖存時間 <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span> 被認爲服從指數分佈 (參數 <span class="math inline">\(\lambda_x\)</span>)，概率方程爲 <span class="math inline">\(\lambda_x e^{-x\lambda_x},\text{ where } x &gt; 0\)</span>。</p>
<ol style="list-style-type: decimal">
<li>證明 <span class="math inline">\(\lambda_x\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\lambda_x = \frac{1}{\bar{x}}\)</span>, 對數似然方程是 <span class="math display">\[\ell(\lambda_x | \underline{x}) = n\text{log}\lambda_x - \lambda_x n \bar{x}\]</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
f(\underline{x}|\lambda_x) &amp; = \lambda_x\cdot e^{-x\lambda_x} \\
F(\underline{x}|\lambda_x)  &amp; = \prod_{i=1}^n\lambda_{x}\cdot e^{-x_i\lambda_{x}} \\
\Rightarrow L(\lambda_x | \underline{x}) &amp; = \prod_{i=1}^n\lambda_xe^{-x_i\lambda_{x}} \\
\Rightarrow \ell(\lambda_x|\underline{x}) &amp; = \sum_{i=1}^n(\text{log}\lambda_x + \text{log}e^{-x_i\lambda_{x}}) \\
                                        &amp; = n\text{log}\lambda_x  + \sum_{i=1}^n(-x_i\lambda_{x}) \\
                                        &amp; = n\text{log}\lambda_x - n\bar{x}\lambda_x \\
\Rightarrow \ell^\prime(\lambda_x) &amp; = \frac{n}{\lambda_x} - n\bar{x}\lambda_x \\
\text{Let } \ell^\prime(\lambda_x) &amp; = 0 \Rightarrow \text{ MLE of } \lambda_x \text{ is } \hat\lambda_x = \frac{1}{\bar{x}} \\
\because \ell^{\prime\prime} = -\frac{n}{\lambda^2_x} &amp; &lt; 0 \therefore \frac{1}{\bar{x}} \text{ is the MLE}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>另一組獨立數據是樣本量爲 <span class="math inline">\(n\)</span> ，但是肺癌診斷爲 II 期的患者的倖存時間 <span class="math inline">\(Y_1, \cdots, Y_n\)</span>。這組數據也被認爲服從參數爲 <span class="math inline">\(\lambda_y\)</span> 的指數分佈。用 <span class="math inline">\(\theta=\frac{\lambda_x}{\lambda_y}\)</span> 標記兩組患者倖存時間之比，用 <span class="math inline">\(r=\frac{\bar{x}}{\bar{y}}\)</span> 標記樣本的倖存時間均值之比。證明使兩個樣本數據的聯合對數似然取極大值的 <span class="math inline">\(\hat\lambda_y(\theta) = \frac{2}{\bar{y}(\theta r+1)}\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\ell(\lambda_x|\underline{x}) &amp; = n\text{log}\lambda_x - n \bar{x} \lambda_x \\
\ell(\lambda_y|\underline{y}) &amp; = n\text{log}\lambda_y - n \bar{y} \lambda_y \\
\Rightarrow \text{ Joint log-likelihood: } &amp; \ell(\lambda_x, \lambda_y | \underline{x}, \underline{y}) = n\text{log}\lambda_x - n\bar{x}\lambda_x \\
&amp; \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+  n\text{log} \lambda_y - n\bar{y}\lambda_y \\
\text{Subsitute } \lambda_x &amp; =\theta\cdot\lambda_y \\
\Rightarrow \ell(\theta, \lambda_y) &amp;= n\text{log}\theta\lambda_y - n\bar{x}\theta\lambda_y + n\text{log} \lambda_y - n\bar{y}\lambda_y \\
\ell(\theta, \lambda_y) &amp; = n(\text{log}\theta + \text{log}\lambda_y - \bar{x}\theta\lambda_y + \text{log}\lambda_y - \bar{y}\lambda_y) \\
                        &amp; = n[\text{log}\theta + 2\text{log}\lambda_y - \lambda_y(\bar{x}\theta + \bar{y})] \\
\Rightarrow \frac{\partial\ell(\theta, \lambda_y)}{\partial \lambda_y} &amp; = n[\frac{2}{\lambda_y} - (\bar{x}\theta + \bar{y})] \\
\text{Let } \frac{\partial\ell(\theta, \lambda_y)}{\partial \lambda_y} &amp; = 0 \text{ and because } r = \frac{\bar{x}}{\bar{y}} \\
\hat\lambda_y(\theta) &amp; = \frac{2}{\bar{x}\theta + \bar{y}} = \frac{2}{\bar{y}(r\cdot\theta +1)}
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>證明參數 <span class="math inline">\(\theta\)</span> 的子集對數似然是 <span class="math inline">\(\ell_p(\theta|r) = n\text{log}\theta - 2n \text{log}(\theta\cdot r + 1)\)</span>，且 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\theta = \frac{1}{r}\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\ell_p (\theta) &amp; = n[\text{log}\theta + 2\cdot\text{log}\frac{2}{\bar{y}(r\cdot\theta +1)} - \text{log}\frac{2}{\bar{y}(r\cdot\theta +1)}(\bar{x}\theta+\bar{y})] \\
                &amp; = n\{\text{log}\theta + 2\cdot\text{log}2 - 2\cdot\text{log}[\bar{y}(r\theta+1)] -2 \} \\
\text{Ignoring } &amp; \text{ items not involving } \theta\\
                &amp; = n[\text{log}\theta - 2\text{log}(r\theta+1)] \\
\Rightarrow \ell_p^{\prime}(\theta) &amp; = n(\frac{1}{\theta} - \frac{2r}{r\theta+1}) \\
\text{Let } \ell_p^{\prime}(\theta) &amp; = 0 \Rightarrow  n(\frac{1}{\theta} - \frac{2r}{r\theta+1}) = 0 , \hat\theta=\frac{1}{r}\\
\because  \ell_p^{\prime\prime}(\theta) &amp; = -\frac{1}{\theta^2} - \frac{2r^2}{(r\theta^2+1)^2} &lt; 0 \\
\therefore \hat\theta &amp; =\frac{1}{r} \text{ is the MLE}
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>根據 <span class="math inline">\(\text{MLE}\)</span> 的恆定性，可以直接推導出 <span class="math inline">\(\theta\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 嗎?</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\because \hat\lambda_x = \frac{1}{x} , \hat\lambda_y = \frac{1}{y} \\
\therefore \theta = \frac{\lambda_x}{\lambda_y} \Rightarrow \hat\theta = \frac{\hat\lambda_x}{\hat\lambda_y} = \frac{1}{r}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>證明檢驗下列假設 <span class="math inline">\(\text{H}_0: \theta_0 = 1 \text{ v.s. H}_1: \theta_0 \neq 1\)</span> 的子集對數似然比檢驗統計量是 <span class="math inline">\(2n\text{log}\frac{(r+1)^2}{4r}\)</span>，並進行 <span class="math inline">\(n=16, r=2\)</span> 的假設檢驗。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\text{Under H}_0 &amp; \Rightarrow \text{ test statistic is } \\
-2llr(\theta_0)  &amp; = -2[\ell(\theta_0) - \ell(\hat\theta)] \stackrel{\cdot}{\sim} \chi^2_1 \\
\Rightarrow \ell_p(\theta_0) &amp; = n\text{log}1 - 2n \text{log}(r+1) = -2n\text{log}(r+1) \\
          \ell_p(\hat\theta) &amp; = n\text{log}\frac{1}{r} - 2n\text{log}(2) \\
                             &amp; = -n\text{log}r-2n\text{log}2 = -n\text{log}4r\\
\Rightarrow \ell_p(\theta_0) - \ell_p(\hat\theta) &amp; = -2n\text{log}(r+1) + n\text{log}4r = n\text{log}\frac{4r}{(r+1)^2} \\
\Rightarrow -2llr(\theta_0)  &amp; = -2n\text{log}\frac{4r}{(r+1)^2} = 2n\text{log}\frac{(r+1)^2}{4r} \\
\text{ When } n=16, r=2 -2llr(\theta_0) &amp; = 2\times16\times\text{log}(\frac{2+1}{4\times2})^2 = 3.769 &lt; \chi^2_{1,0.95} = 3.84\\
\text{ We do not reject }&amp;\text{ the null hypothesis at the } 5% \text{ level.}
\end{aligned}
\]</span></p>
<p>此時如果精確計算可以獲得 <span class="math inline">\(p=0.052\)</span>，從檢驗統計量的計算值我們也能看出距離拒絕零假設的拒絕域十分接近。此時可以認爲是一個臨界的 <span class="math inline">\(p\)</span> 值。所以數據提供了臨界 <span class="math inline">\(p=0.052\)</span> 的證據證明肺癌 II 期患者的倖存時間平均要少於 I 期患者。</p>
</div>
<div id="總結" class="section level2">
<h2><span class="header-section-number">19.4</span> 總結</h2>
<p>推斷是十分具有挑戰性的一個章節，我們在此做個簡單的複習和總結，用一些常見的問題來結束本章。</p>
<div id="快速複習" class="section level3">
<h3><span class="header-section-number">19.4.1</span> 快速複習</h3>
<p>對於收集到的<strong>樣本數據 data</strong>，我們需要提出一個所謂的“科學問題 scientific question”。</p>
<p>爲了回答這個“科學問題”，我們會設想，並提出一個合適的 <strong>統計學模型 statistical model</strong>，確認提出的統計學模型中的<strong>參數 parameters</strong>。通過樣本數據的信息對參數進行<strong>估計 estimation</strong>，或者進行<strong>假設檢驗 hypothesis tests</strong>。</p>
<p>統計學模型具有自己的概率分佈，通過相應的參數，和模型的分佈可以解釋觀察數據的分佈，並且利用這些信息進行我們需要的推斷。同時，我們還需要利用觀察數據對我們提出的模型是否擬合數據做出合適的<strong>診斷</strong>。</p>
<p>估計和假設檢驗，是以<strong>似然方程</strong>爲基礎的。通常我們會利用便於計算的對數似然(比)，進行假設檢驗。</p>
<p>獲得似然方程以後，我們可以用對數似然比，進一步進行推斷：</p>
<ol style="list-style-type: decimal">
<li>確認最佳估計 <span class="math inline">\(MLE\)</span>，和它的方差 (標準誤)；</li>
<li>計算參數的點估計量，和信賴區間；</li>
<li>爲感興趣的參數實施假設檢驗。</li>
</ol>
</div>
<div id="試爲下面的醫學研究問題提出合適的統計學模型" class="section level3">
<h3><span class="header-section-number">19.4.2</span> 試爲下面的醫學研究問題提出合適的統計學模型</h3>
<ol style="list-style-type: decimal">
<li>在一所醫院收集了 80 名患者的血壓和體重的數據，醫生想要分析血壓 (bp) 跟體重 (weight) 之間是否有相關性。</li>
</ol>
<p>答： 用簡單線性迴歸模型。(r.v. = random variable)</p>
<p><span class="math display">\[
Y \text{ r.v. for bp } Y_j | \text{weight}_j \stackrel{i}{\sim} N(\alpha + \beta \text{weight}, \sigma^2), j = 1,2,\cdots,80; \text{H}_0: \beta=0
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>爲了調查某市青光眼的患病率 (prevalence)，從一般人羣中隨機抽取了 100 人進行眼部檢查。</li>
</ol>
<p>答：用二項分佈模型。</p>
<p><span class="math display">\[
K \text{ r.v. for number of people found with glaucoma } \\
K \sim \text{Bin}(100, \pi); \text{ Estimate } \pi \text{ with CI.}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>另一個醫生拿到了 2. 的數據，打算分析這100人中青光眼的患病與否是否和血壓相關。</li>
</ol>
<p>答：用邏輯迴歸模型。 <span class="math inline">\(\text{logit}\pi = \text{log}\frac{\pi}{1-\pi}\)</span></p>
<p><span class="math display">\[
K_i | bp_i \sim \text{Bin}(100, \pi_i), \text{logit}(\pi_i) = \alpha + \beta bp_i; \text{H}_0: \beta = 0
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>有好事者打算調查 25 名研究對象的血清膽固醇水平是否在實驗前後 (實驗時間3個月) 發生有意義的改變。</li>
</ol>
<p>答：正態分佈模型，單樣本 <span class="math inline">\(t\)</span> 檢驗。</p>
<p><span class="math display">\[
D \text{ r.v. for cholesterol change; } D_j \stackrel{i.i.d}{\sim} N(\delta, \sigma^2), j= 1,\cdots,25; \text{H}_0: \delta = 0\\
\text{Where } D_j = \text{chol}_{j,3m} - \text{chol}_{j,entry}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>前一題的好事者，打算進一步分析膽固醇水平的變化在某些進行特殊飲食的觀察對象中是否更加顯著。</li>
</ol>
<p>答：簡單線性迴歸模型。</p>
<p><span class="math display">\[
D_j | \text{diet}_j \stackrel{i}{\sim} N(\alpha + \beta \text{diet}_j, \sigma^2), j=1,\cdots,25; \text{H}_0: \beta = 0
\]</span></p>
<ol start="6" style="list-style-type: decimal">
<li>某降壓藥物已知能有效地降低高血壓患者的血壓。某項實驗將收集來的高血壓患者分成 6 個小組，每組給予的藥物劑量不同，最低 1 毫克每次，最高 6 毫克每次，每組相差 1 毫克劑量。研究者希望通過實驗確定該藥物的降壓效果是否在某個劑量時達到最大，如果沒有，是否降壓藥物的效果隨着劑量增加而增加。</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; bp_j | \text{dose}_j \stackrel{\cdot}{\sim} N(\alpha + \beta\text{dose}_j + \gamma\text{dose}^2_j, \sigma^2), j=1,\cdots,n;\\
\text{1) test } &amp; \text{ H}_0: \gamma=0; \text{ if do not reject, then do next test } \\
&amp; bp_j | \text{dose}_j \stackrel{\cdot}{\sim} N(\alpha + \beta\text{dose}_j, \sigma^2)
\text{2) test } &amp; \text{ H}_0: \beta=0
\end{aligned}
\]</span></p>
</div>
<div id="醫生來找統計學家問問題" class="section level3">
<h3><span class="header-section-number">19.4.3</span> 醫生來找統計學家問問題</h3>
<ol start="7" style="list-style-type: decimal">
<li>一個<strong>“臨牀醫生”</strong>來找你問了這樣的一個常見的問題：當我們使用 <span class="math inline">\(t\)</span> 檢驗的時候，爲什麼前提假設是數據服從 <strong>正態分佈</strong>? 而不使用<strong>服從 <span class="math inline">\(t\)</span> 分佈</strong> 這樣的前提條件，因爲我們實施該檢驗的時候明明就在用 <span class="math inline">\(t\)</span> 分佈？</li>
</ol>
<p>答：我們從未假定<strong>觀察數據服從 <span class="math inline">\(t\)</span> 分佈</strong>，我們假定的前提是檢驗統計量，也就是樣本均值和標準誤服從 <span class="math inline">\(t\)</span> 分佈。因爲我們不知道收集獲得的數據來自的人羣的方差是多少，需要使用樣本數據對方差也進行估計的時候，不得已而必須使用 <span class="math inline">\(t\)</span> 分佈來獲得估計的樣本均值的標準誤差，用於計算信賴區間和實施假設檢驗。</p>
<ol start="8" style="list-style-type: decimal">
<li>還是那個有好奇心的<strong>“臨牀醫生”</strong>又來問一個弱智問題：當我們使用正態分佈近似法對一個服從二項分佈的比例的單樣本檢驗的時候，我們把計算的檢驗統計量拿去跟正態分佈的特徵值作比較。然而，不用正態分佈近似，直接對連續型變量實施單樣本 <span class="math inline">\(t\)</span> 檢驗的時候卻把計算的檢驗統計量拿去和 <span class="math inline">\(t\)</span> 分佈的特徵值作比較，這是爲什麼？</li>
</ol>
<p>答：對連續型變量實施單樣本 <span class="math inline">\(t\)</span> 檢驗的時候，我們需要用樣本數據同時估計均值和標準誤。但是對於二項分佈的數據來說，它的樣本比例的標準誤是總體比例的一個方程，所以只要用樣本比例估計總體比例以後，總體的標準誤就已經可以知道，不必再作估計。所以，二項分佈的正態近似法就真的使用標準正態分佈的特徵值，但是連續型變量的總體標準誤同時被估計，它的不確定性也要考慮進來，只能使用 <span class="math inline">\(t\)</span> 分佈。</p>
<ol start="9" style="list-style-type: decimal">
<li>某<strong>“臨牀醫生”</strong>假裝很熱心想學習統計跑來問問題：該醫生實施的臨牀試驗，比較病例和對照之間某指標是否不同。但是，病例組看上去的年齡似乎比對照組要高一些，該醫生記得自己統計課上聽老師說過混雜因素的知識。所以他跑回家自己實施了一下病例組和對照組之間年齡是否有差別的 <span class="math inline">\(t\)</span> 檢驗，結果顯示病例組對照組的年齡沒有顯著性差異。所以他認爲可以從線性模型中去掉年齡這一變量。但是身爲統計學家的你堅持必須要保留年齡在模型裏。所以醫生問你是否關心年齡有差別所以才堅持要調整年齡。你的回答是“對不起大哥，我對病例對照之間的年齡差是否有統計學意義完全沒有興趣。”醫生更加困惑了。<span class="math inline">\(\text{variable}_i = \alpha + \beta\text{patient}_i + \gamma\text{age}_i + \varepsilon_i\)</span></li>
</ol>
<p>答：年齡是否會混雜了病人分組和指標之間的關係，<strong>不是通過比較兩組來自的人羣的年齡是否有差別來判斷的</strong>。如果<strong>樣本的年齡有差別</strong>，就很有可能會對你想要分析的關係造成混淆。因爲你進行的年齡均值是否有差異的 <span class="math inline">\(t\)</span> 檢驗，比較的並不是樣本年齡的差別，而是用樣本估計來自的人羣的年齡之間的比較。</p>

</div>
</div>
</div>



<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>區分與之前討論的對數似然比 (Section <a href="02-Inference.html#llr">13</a>)，之前討論的對數似然比指的是<strong>所有的似然和極大似然</strong>之間的比，此處的似然比只是純粹在探討兩個假設之間的似然比，<strong>與極大似然無關</strong>。<a href="02-Inference.html#fnref1">↩</a></p></li>
<li id="fn2"><p>Rememer that <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> is a random variable: the data varies <strong>each time</strong> we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.<a href="02-Inference.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="01-Probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="03-Analytic-Technique.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook/js/app.min.js"></script>
<script src="assets/gitbook/js/lunr.js"></script>
<script src="assets/gitbook/js/clipboard.min.js"></script>
<script src="assets/gitbook/js/plugin-search.js"></script>
<script src="assets/gitbook/js/plugin-sharing.js"></script>
<script src="assets/gitbook/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook/js/plugin-bookdown.js"></script>
<script src="assets/gitbook/js/jquery.highlight.js"></script>
<script src="assets/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/02-Inference.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
