<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 26 章 簡單線性迴歸 Simple Linear Regression | 醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="第 26 章 簡單線性迴歸 Simple Linear Regression | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 26 章 簡單線性迴歸 Simple Linear Regression | 醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2019-10-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="03-Analytic-Technique.html"/>
<link rel="next" href="05-clinical-trials.html"/>
<script src="assets/jquery/jquery.min.js"></script>
<link href="assets/gitbook/css/style.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/kePrint/kePrint.js"></script>
<script src="assets/htmlwidgets/htmlwidgets.js"></script>
<script src="assets/plotly-binding/plotly.js"></script>
<script src="assets/typedarray/typedarray.min.js"></script>
<link href="assets/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="assets/crosstalk/js/crosstalk.min.js"></script>
<link href="assets/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="assets/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="00-author.html"><a href="00-author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="01-Probability.html"><a href="01-Probability.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Probability.html"><a href="01-Probability.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="01-Probability.html"><a href="01-Probability.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="01-Probability.html"><a href="01-Probability.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="01-Probability.html"><a href="01-Probability.html#Bayes-Definition"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="01-Probability.html"><a href="01-Probability.html#期望-expectation-或均值-or-mean-和-方差-variance"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="01-Probability.html"><a href="01-Probability.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="01-Probability.html"><a href="01-Probability.html#bernoulli"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="01-Probability.html"><a href="01-Probability.html#binomial"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="01-Probability.html"><a href="01-Probability.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="01-Probability.html"><a href="01-Probability.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="01-Probability.html"><a href="01-Probability.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="01-Probability.html"><a href="01-Probability.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="01-Probability.html"><a href="01-Probability.html#poisson"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="01-Probability.html"><a href="01-Probability.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="01-Probability.html"><a href="01-Probability.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="01-Probability.html"><a href="01-Probability.html#CLT"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="01-Probability.html"><a href="01-Probability.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="01-Probability.html"><a href="01-Probability.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="01-Probability.html"><a href="01-Probability.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="01-Probability.html"><a href="01-Probability.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="01-Probability.html"><a href="01-Probability.html#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="01-Probability.html"><a href="01-Probability.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="01-Probability.html"><a href="01-Probability.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="01-Probability.html"><a href="01-Probability.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="02-Inference.html"><a href="02-Inference.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="02-Inference.html"><a href="02-Inference.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="02-Inference.html"><a href="02-Inference.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="02-Inference.html"><a href="02-Inference.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="02-Inference.html"><a href="02-Inference.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="02-Inference.html"><a href="02-Inference.html#估計和精確度-estimation-and-precision"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="02-Inference.html"><a href="02-Inference.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="02-Inference.html"><a href="02-Inference.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="02-Inference.html"><a href="02-Inference.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="02-Inference.html"><a href="02-Inference.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="02-Inference.html"><a href="02-Inference.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="02-Inference.html"><a href="02-Inference.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="02-Inference.html"><a href="02-Inference.html#chi-square-distribution"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="02-Inference.html"><a href="02-Inference.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="02-Inference.html"><a href="02-Inference.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-definition"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="02-Inference.html"><a href="02-Inference.html#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="02-Inference.html"><a href="02-Inference.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="02-Inference.html"><a href="02-Inference.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="02-Inference.html"><a href="02-Inference.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="02-Inference.html"><a href="02-Inference.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="02-Inference.html"><a href="02-Inference.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="02-Inference.html"><a href="02-Inference.html#llr"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="02-Inference.html"><a href="02-Inference.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="02-Inference.html"><a href="02-Inference.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="02-Inference.html"><a href="02-Inference.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="02-Inference.html"><a href="02-Inference.html#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="02-Inference.html"><a href="02-Inference.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="02-Inference.html"><a href="02-Inference.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="02-Inference.html"><a href="02-Inference.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="02-Inference.html"><a href="02-Inference.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="02-Inference.html"><a href="02-Inference.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="02-Inference.html"><a href="02-Inference.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="02-Inference.html"><a href="02-Inference.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的構建-construction-of-a-hypothesis-test"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="02-Inference.html"><a href="02-Inference.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="02-Inference.html"><a href="02-Inference.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="02-Inference.html"><a href="02-Inference.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="02-Inference.html"><a href="02-Inference.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="02-Inference.html"><a href="02-Inference.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="02-Inference.html"><a href="02-Inference.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="02-Inference.html"><a href="02-Inference.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="02-Inference.html"><a href="02-Inference.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="02-Inference.html"><a href="02-Inference.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="02-Inference.html"><a href="02-Inference.html#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的近似方法"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="02-Inference.html"><a href="02-Inference.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="02-Inference.html"><a href="02-Inference.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="02-Inference.html"><a href="02-Inference.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="02-Inference.html"><a href="02-Inference.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="02-Inference.html"><a href="02-Inference.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="02-Inference.html"><a href="02-Inference.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="02-Inference.html"><a href="02-Inference.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="02-Inference.html"><a href="02-Inference.html#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="02-Inference.html"><a href="02-Inference.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="02-Inference.html"><a href="02-Inference.html#正態誤差模型-normal-error-models"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="02-Inference.html"><a href="02-Inference.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="02-Inference.html"><a href="02-Inference.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="02-Inference.html"><a href="02-Inference.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="02-Inference.html"><a href="02-Inference.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="02-Inference.html"><a href="02-Inference.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="02-Inference.html"><a href="02-Inference.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="02-Inference.html"><a href="02-Inference.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="02-Inference.html"><a href="02-Inference.html#多個參數時的統計推斷-inference-with-multiple-parameters-i"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="02-Inference.html"><a href="02-Inference.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="02-Inference.html"><a href="02-Inference.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="02-Inference.html"><a href="02-Inference.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="02-Inference.html"><a href="02-Inference.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="02-Inference.html"><a href="02-Inference.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="02-Inference.html"><a href="02-Inference.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="02-Inference.html"><a href="02-Inference.html#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="02-Inference.html"><a href="02-Inference.html#profile-log-likelihood"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="02-Inference.html"><a href="02-Inference.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="02-Inference.html"><a href="02-Inference.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="02-Inference.html"><a href="02-Inference.html#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path="02-Inference.html"><a href="02-Inference.html#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path="02-Inference.html"><a href="02-Inference.html#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path="02-Inference.html"><a href="02-Inference.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path="02-Inference.html"><a href="02-Inference.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間-confidence-intervals-1"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#假設檢驗"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關-association"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較-comparisons"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#前提和數據轉換-assumptions-and-transformations"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ANOVA"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析-multivariable-models"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析矩陣標記與其意義"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸的模型診斷"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#baseline-adjustment-using-ancova"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法-permutation-procedures"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#自助重抽法-the-bootstrap"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#the-sandwich-estimator"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯定理的應用單一參數模型"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path="09-GLM.html"><a href="09-GLM.html"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path="09-GLM.html"><a href="09-GLM.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path="09-GLM.html"><a href="09-GLM.html#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path="09-GLM.html"><a href="09-GLM.html#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path="09-GLM.html"><a href="09-GLM.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path="09-GLM.html"><a href="09-GLM.html#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path="09-GLM.html"><a href="09-GLM.html#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path="09-GLM.html"><a href="09-GLM.html#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path="09-GLM.html"><a href="09-GLM.html#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path="09-GLM.html"><a href="09-GLM.html#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path="09-GLM.html"><a href="09-GLM.html#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path="09-GLM.html"><a href="09-GLM.html#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path="09-GLM.html"><a href="09-GLM.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="09-GLM.html"><a href="09-GLM.html#廣義線性迴歸入門"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path="09-GLM.html"><a href="09-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="09-GLM.html"><a href="09-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path="09-GLM.html"><a href="09-GLM.html#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path="09-GLM.html"><a href="09-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path="09-GLM.html"><a href="09-GLM.html#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path="09-GLM.html"><a href="09-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path="09-GLM.html"><a href="09-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path="09-GLM.html"><a href="09-GLM.html#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型-logistic-regression-model"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path="09-GLM.html"><a href="09-GLM.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path="09-GLM.html"><a href="09-GLM.html#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="09-GLM.html"><a href="09-GLM.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path="09-GLM.html"><a href="09-GLM.html#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path="09-GLM.html"><a href="09-GLM.html#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path="09-GLM.html"><a href="09-GLM.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path="09-GLM.html"><a href="09-GLM.html#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="09-GLM.html"><a href="09-GLM.html#模型比較和擬合優度"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path="09-GLM.html"><a href="09-GLM.html#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path="09-GLM.html"><a href="09-GLM.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path="09-GLM.html"><a href="09-GLM.html#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path="09-GLM.html"><a href="09-GLM.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path="09-GLM.html"><a href="09-GLM.html#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="09-GLM.html"><a href="09-GLM.html#計數型因變量-poisson-regression"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path="09-GLM.html"><a href="09-GLM.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path="09-GLM.html"><a href="09-GLM.html#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path="09-GLM.html"><a href="09-GLM.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="09-GLM.html"><a href="09-GLM.html#率的廣義線性迴歸-poisson-glm-for-rates"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path="09-GLM.html"><a href="09-GLM.html#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path="09-GLM.html"><a href="09-GLM.html#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path="09-GLM.html"><a href="09-GLM.html#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path="09-GLM.html"><a href="09-GLM.html#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path="09-GLM.html"><a href="09-GLM.html#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="09-GLM.html"><a href="09-GLM.html#混雜的調整交互作用和模型的可壓縮性"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path="09-GLM.html"><a href="09-GLM.html#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path="09-GLM.html"><a href="09-GLM.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="09-GLM.html"><a href="09-GLM.html#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path="09-GLM.html"><a href="09-GLM.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path="09-GLM.html"><a href="09-GLM.html#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="09-GLM.html"><a href="09-GLM.html#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="09-GLM.html"><a href="09-GLM.html#流行病學中的邏輯迴歸"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path="09-GLM.html"><a href="09-GLM.html#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path="09-GLM.html"><a href="09-GLM.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="09-GLM.html"><a href="09-GLM.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path="09-GLM.html"><a href="09-GLM.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path="09-GLM.html"><a href="09-GLM.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path="09-GLM.html"><a href="09-GLM.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="09-GLM.html"><a href="09-GLM.html#分析策略"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path="09-GLM.html"><a href="09-GLM.html#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path="09-GLM.html"><a href="09-GLM.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path="09-GLM.html"><a href="09-GLM.html#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path="09-GLM.html"><a href="09-GLM.html#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="09-GLM.html"><a href="09-GLM.html#檢查你的模型-model-checking---glm"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path="09-GLM.html"><a href="09-GLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path="09-GLM.html"><a href="09-GLM.html#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path="09-GLM.html"><a href="09-GLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path="09-GLM.html"><a href="09-GLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="09-GLM.html"><a href="09-GLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path="09-GLM.html"><a href="09-GLM.html#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path="09-GLM.html"><a href="09-GLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path="09-GLM.html"><a href="09-GLM.html#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="09-GLM.html"><a href="09-GLM.html#評價模型的表現-assessing-model-performance"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path="09-GLM.html"><a href="09-GLM.html#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path="09-GLM.html"><a href="09-GLM.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path="09-GLM.html"><a href="09-GLM.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path="09-GLM.html"><a href="09-GLM.html#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗數據的分析法"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path="09-GLM.html"><a href="09-GLM.html#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path="09-GLM.html"><a href="09-GLM.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path="09-GLM.html"><a href="09-GLM.html#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="09-GLM.html"><a href="09-GLM.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path="09-GLM.html"><a href="09-GLM.html#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path="09-GLM.html"><a href="09-GLM.html#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="09-GLM.html"><a href="09-GLM.html#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path="09-GLM.html"><a href="09-GLM.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path="09-GLM.html"><a href="09-GLM.html#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path="09-GLM.html"><a href="09-GLM.html#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="09-GLM.html"><a href="09-GLM.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯迴歸-conditional-logistic-regression"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path="09-GLM.html"><a href="09-GLM.html#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path="09-GLM.html"><a href="09-GLM.html#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path="09-GLM.html"><a href="09-GLM.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path="09-GLM.html"><a href="09-GLM.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path="09-GLM.html"><a href="09-GLM.html#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="09-GLM.html"><a href="09-GLM.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path="09-GLM.html"><a href="09-GLM.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型-random-intercept-model"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中加入共變量-random-intercept-model-with-covariates"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數模型-random-coefficient-model"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-1"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-2"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-3"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#generalized-estimating-equation"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysisunsupervised-learning-聚類分析"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-1"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#principal-component-analysis-主成分分析"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-2"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#further-issues"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數分布"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#nonparametric"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據中的回歸模型"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布-1"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-比例風險模型"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分析策略和模型檢查-model-checking-survival-analysis"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#競爭風險模型-competing-risk"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的其他手段"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#加速失效模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.1</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量-time-dependent-variables-和脆弱模型-frailty-model"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間事件數據的高級分析法"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="80" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html"><i class="fa fa-check"></i><b>80</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="80.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>80.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="80.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>80.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="80.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#概率論者分析結果"><i class="fa fa-check"></i><b>80.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="80.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>80.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="80.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-the-great-trial"><i class="fa fa-check"></i><b>80.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="80.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#background-great-trial"><i class="fa fa-check"></i><b>80.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="80.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#試驗結果"><i class="fa fa-check"></i><b>80.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="80.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#經典統計學分析方法"><i class="fa fa-check"></i><b>80.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="80.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>80.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MC-estimation"><i class="fa fa-check"></i><b>81</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="81.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#起源"><i class="fa fa-check"></i><b>81.1</b> 起源</a><ul>
<li class="chapter" data-level="81.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#作出預測"><i class="fa fa-check"></i><b>81.1.1</b> 作出預測</a></li>
<li class="chapter" data-level="81.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-新藥表現預測"><i class="fa fa-check"></i><b>81.1.2</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>81.2</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="81.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>81.2.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="81.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>81.2.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="81.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅法分析軟件-openbugs"><i class="fa fa-check"></i><b>81.3</b> 蒙特卡羅法分析軟件 OpenBUGS</a><ul>
<li class="chapter" data-level="81.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>81.3.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="81.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>81.3.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="81.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>81.3.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>81.4</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="82" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率-conjugate-priors"><i class="fa fa-check"></i><b>82</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="82.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>82.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="82.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="82.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#事後概率分布預測"><i class="fa fa-check"></i><b>82.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="82.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>82.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="82.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesPrac03"><i class="fa fa-check"></i><b>82.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="83" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MCMC-methods"><i class="fa fa-check"></i><b>83</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="83.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>83.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="83.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>83.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="83.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Gibbs-sampling"><i class="fa fa-check"></i><b>83.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="83.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值-initial-values"><i class="fa fa-check"></i><b>83.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="83.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>83.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="83.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#收斂時間"><i class="fa fa-check"></i><b>83.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="83.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>83.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="83.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-軟件"><i class="fa fa-check"></i><b>83.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="83.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>83.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="83.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>83.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="83.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-language"><i class="fa fa-check"></i><b>83.5</b> BUGS language</a><ul>
<li class="chapter" data-level="83.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>83.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="83.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#分布的標記法"><i class="fa fa-check"></i><b>83.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="83.5.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#arrays-and-loops"><i class="fa fa-check"></i><b>83.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="83.5.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#常用的方程"><i class="fa fa-check"></i><b>83.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="83.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>83.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="83.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>83.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#建模和模型的檢查"><i class="fa fa-check"></i><b>84</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="84.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesianLM"><i class="fa fa-check"></i><b>84.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="84.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#children-in-the-gambia"><i class="fa fa-check"></i><b>84.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="84.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>84.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="84.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>84.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="84.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="84.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>84.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="84.2.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>84.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="84.2.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>84.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="84.2.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>84.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="84.2.8" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="84.2.9" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#tdreplacegaussian"><i class="fa fa-check"></i><b>84.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="84.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>84.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="84.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>84.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="84.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>84.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="84.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>84.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="84.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>84.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="84.4.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>84.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="85" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#不同實驗研究設計時適用的貝葉斯模型"><i class="fa fa-check"></i><b>85</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="85.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>85.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="85.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>85.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="85.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>85.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="85.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#the-great-trial"><i class="fa fa-check"></i><b>85.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="85.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#吸煙與癌症"><i class="fa fa-check"></i><b>85.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯廣義線性回歸"><i class="fa fa-check"></i><b>86</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="86.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>86.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="86.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>86.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="86.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>86.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="86.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>86.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="86.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#低出生體重數據-1"><i class="fa fa-check"></i><b>86.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="86.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>86.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="86.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>86.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="86.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Bayesian-practical07"><i class="fa fa-check"></i><b>86.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="87" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級回歸模型"><i class="fa fa-check"></i><b>87</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="87.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>87.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="87.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>87.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="87.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>87.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="87.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>87.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="87.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>87.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="87.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>87.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="87.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#縱向數據"><i class="fa fa-check"></i><b>87.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="87.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-example"><i class="fa fa-check"></i><b>87.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="87.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>87.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="87.3.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>87.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="87.3.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>87.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="87.3.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>87.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="87.3.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>87.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="87.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>87.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#再訪-mcmc"><i class="fa fa-check"></i><b>88</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="88.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>88.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="88.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>88.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯和概率論的比較"><i class="fa fa-check"></i><b>89</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="89.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>89.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="89.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>89.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="89.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>89.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="90" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html"><i class="fa fa-check"></i><b>90</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="90.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>90.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="90.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>90.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="90.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步分析"><i class="fa fa-check"></i><b>90.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="90.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#混雜"><i class="fa fa-check"></i><b>90.2.2</b> 混雜</a></li>
<li class="chapter" data-level="90.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>90.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="90.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>90.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="90.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>90.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="90.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>90.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="90.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>90.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="90.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>90.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="91" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#graphical-models-因果推斷的圖形模型"><i class="fa fa-check"></i><b>91</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="91.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>91.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="91.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>91.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="91.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-圖的術語"><i class="fa fa-check"></i><b>91.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="91.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>91.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="91.1.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>91.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="91.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以非對撞銀子爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>91.2</b> 以非對撞銀子爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="91.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件的總結"><i class="fa fa-check"></i><b>91.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="91.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#d-分離-d-separation"><i class="fa fa-check"></i><b>91.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-continuous-outcomes-結果變量爲連續型變量"><i class="fa fa-check"></i><b>92</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="92.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>92.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="92.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>92.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="92.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>92.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="92.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>92.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="92.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>92.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="92.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>92.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="92.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均值差"><i class="fa fa-check"></i><b>92.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="92.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>92.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="92.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>92.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="92.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#positivity-非零性"><i class="fa fa-check"></i><b>92.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="92.3.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>92.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical03---causal-inference"><i class="fa fa-check"></i><b>92.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="93" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-binary-outcomes-結果變量爲二分類變量"><i class="fa fa-check"></i><b>93</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="93.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>93.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="93.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>93.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>93.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="93.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>93.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="93.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>93.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="93.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>93.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>93.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="93.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>93.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="93.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical04---causal-inference"><i class="fa fa-check"></i><b>93.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="93.6.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>93.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="93.6.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>93.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="93.6.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>93.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="93.6.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>93.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="93.6.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>93.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="93.6.7" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.8" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>93.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="93.6.9" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>93.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="93.6.10" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>93.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="93.6.11" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>93.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="93.6.12" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>93.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="94" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#prospensity-score-傾向性評分"><i class="fa fa-check"></i><b>94</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="94.0.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#關於條件可置換性"><i class="fa fa-check"></i><b>94.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="94.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>94.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="94.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分層法-stratification"><i class="fa fa-check"></i><b>94.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="94.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#配對法-matching"><i class="fa fa-check"></i><b>94.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="94.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>94.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical05---causal-inference"><i class="fa fa-check"></i><b>94.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="94.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>94.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="94.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>94.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="94.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>94.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="94.2.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>94.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="94.2.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用配對法計算-ace"><i class="fa fa-check"></i><b>94.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="94.2.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#模型校正-ps"><i class="fa fa-check"></i><b>94.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#inverse-probability-weighted-estimation-and-doubly-robust-methods"><i class="fa fa-check"></i><b>95</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="96" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#causal-mediation-analysis"><i class="fa fa-check"></i><b>96</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="97" data-path="29SME.html"><a href="29SME.html"><i class="fa fa-check"></i><b>97</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="30-references.html"><a href="30-references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lm" class="section level1">
<h1><span class="header-section-number">第 26 章</span> 簡單線性迴歸 Simple Linear Regression</h1>
<blockquote>
<dl>
<dt>Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong questions, which can always be made precise.</dt>
<dd>John Tukey
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Linear Regression lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/nicholas.jennifer">Jennifer Nicholas</a>.
</div>

<div id="一些背景和術語" class="section level2">
<h2><span class="header-section-number">26.1</span> 一些背景和術語</h2>
<p>思考下面這些問題：</p>
<ol style="list-style-type: decimal">
<li>脂肪攝入量增加，會導致體重增加嗎？</li>
<li>兒童成年時的身高，可以用父母親的身高來預測嗎？</li>
<li>如果其他條件都沒有變化，飲食習慣的改變，是否能影響血清膽固醇的水平？</li>
</ol>
<p>上面的問題中，自變量 (預測變量)，和因變量 (反應量) 分別是什麼？</p>
<p>你可能還會碰到像下面這些稱呼，他們都是一個意思：</p>
<ul>
<li>因變量 Dependent variable = 反應量 response variable = 結果變量 outcome variable;</li>
<li>自變量 independent variable = 預測變量 predictor variable = 解釋變量 explanatory variable = 共變量 covariate.</li>
</ul>
<p>所有的非簡單統計模型 (non-trivial statistical models) 都包括以下三個部分：</p>
<ol style="list-style-type: decimal">
<li>隨機變量 random variables：
<ul>
<li>因變量永遠都是隨機變量；</li>
<li>預測變量不一定是隨機變量；</li>
<li>在相對簡單的模型中，我們討論的因變量和預測變量幾乎都來自於從人羣中抽取觀察樣本收集來的數據。</li>
</ul></li>
<li>人羣參數 population parameters：
<ul>
<li>人羣參數，是我們希望通過收集樣本獲得的數據來估計 (estimate) 的參數。</li>
</ul></li>
<li>對不確定性的描述 representation of uncertainty：
<ul>
<li>不確定性，意爲因變量的變動中，沒有被預測變量解釋的部分。</li>
</ul></li>
</ol>
<p>其他的術語問題：</p>
<ul>
<li><strong>單一因變量</strong>的統計模型：<strong>univariate model</strong>;</li>
<li><strong>多個因變量</strong>的統計模型： <strong>multivariate model</strong>;</li>
<li><strong>單一因變量</strong>，含有<strong>多個預測變量</strong>的統計模型：<strong>multivariable model</strong>；</li>
<li>在線性迴歸中，單一因變量，單一預測變量的統計模型：<strong>simple linear regression</strong> (簡單線性迴歸)；</li>
<li>在線性迴歸中，單一因變量，多個預測變量的統計模型：<strong>multiple linear regression</strong> (多重線性迴歸)；</li>
</ul>
<p>儘量避免將預測變量 (predictor variable) 寫作自變量 (independent variable)，因爲 “independent” 有自己的統計學含義 (獨立)。然而我們在線性迴歸中使用的預測變量，不一定都<strong>互相獨立</strong>，所以容易讓人混淆其意義。</p>
</div>
<div id="簡單線性迴歸模型-simple-linear-regression-model" class="section level2">
<h2><span class="header-section-number">26.2</span> 簡單線性迴歸模型 simple linear regression model</h2>
<p>即：<strong>單一因變量，單一預測變量</strong>的統計模型。</p>
<div id="數據-a" class="section level3">
<h3><span class="header-section-number">26.2.1</span> 數據 A</h3>
<p>下面的散點圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 展示的是一項橫斷面調查的結果，調查的是一些兒童的年齡 (月)，和他們的體重 (千克) 之間的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt"></span>
<img src="bookdown_files/figure-html/age-wt-1.png" alt="Age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.1: Age and weight of children in a cross-sectional survey
</p>
</div>
</div>
<div id="數據-b" class="section level3">
<h3><span class="header-section-number">26.2.2</span> 數據 B</h3>
<p>表 <a href="04-Linear-Regression.html#tab:walk">26.1</a> 羅列的是11名兒童能夠自己獨立行走時的年齡。這些兒童在剛出生時被隨機分配到兩個組中 (積極鍛鍊走路，和對照組)。如果你熟悉均數比較，這樣的數據可以通過簡單 <span class="math inline">\(t\)</span> 檢驗來分析其均值的不同。但是實際上後面你會看到簡單 <span class="math inline">\(t\)</span> 檢驗和簡單線性迴歸是同一回事。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:walk">表 26.1: </span>Childen’s ages at time of first walking aline by randomisation group
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Age in months for walking alone
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Active Exercise (n=6)
</th>
<th style="text-align:center;">
Eight Week Control (n=5)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
9.00
</td>
<td style="text-align:center;">
13.25
</td>
</tr>
<tr>
<td style="text-align:center;">
9.50
</td>
<td style="text-align:center;">
11.5
</td>
</tr>
<tr>
<td style="text-align:center;">
9.75
</td>
<td style="text-align:center;">
12
</td>
</tr>
<tr>
<td style="text-align:center;">
10.00
</td>
<td style="text-align:center;">
13.5
</td>
</tr>
<tr>
<td style="text-align:center;">
13.00
</td>
<td style="text-align:center;">
11.5
</td>
</tr>
<tr>
<td style="text-align:center;">
9.50
</td>
<td style="text-align:center;">
–
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="區分因變量和預測變量" class="section level2">
<h2><span class="header-section-number">26.3</span> 區分因變量和預測變量</h2>
<p>在簡單兩樣本 <span class="math inline">\(t\)</span> 檢驗中，我們不區分那兩個要比較的數據 <span class="math inline">\((X, Y)\)</span>。所以 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 的關係，同分析 <span class="math inline">\(Y\)</span> 和 <span class="math inline">\(X\)</span> 的關係是一樣的。表 <a href="04-Linear-Regression.html#tab:walk">26.1</a> 的例子中，視“直立行走的年齡”這一變量爲因變量十分直觀且自然。圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 的例子中我們顯然可以關心是否可以用兒童的年齡來推測他/她的體重。所以年齡被視爲預測變量 <span class="math inline">\((X)\)</span>，體重被視爲因變量或者叫結果變量 <span class="math inline">\((Y)\)</span>。</p>
<div id="meanfunction" class="section level3">
<h3><span class="header-section-number">26.3.1</span> 均值 (期待值) 公式</h3>
<p>圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 的例子中，當我們決定考察體重變化 <span class="math inline">\((Y)\)</span> 和年齡的關係 <span class="math inline">\((X)\)</span> 後，我們需要提出一個模型，來描述二者之間的關係。這個模型中，最重要的信息，是均值，或者叫期待值：</p>
<p><span class="math display">\[
E(Y|X=x), \text{ the expected value of } Y \text{ when } X \text{ takes the value } x
\]</span></p>
<p>在簡單線性迴歸模型中，我們認爲這個均值方程是線性關係：</p>
<p><span class="math display">\[
E(Y|X=x) = \alpha +\beta x
\]</span></p>
<p>所以這個線性關係中，有兩個參數 (parameters) 是我們關心的 <span class="math inline">\(\alpha, \beta\)</span>。</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距 intecept。意爲當 <span class="math inline">\(X\)</span> 取 <span class="math inline">\(0\)</span>時， <span class="math inline">\(Y\)</span> 的期待值大小；</li>
<li><span class="math inline">\(\beta\)</span> 是方程的斜率 slope。意爲當 <span class="math inline">\(X\)</span> 上升一個單位時，<span class="math inline">\(Y\)</span> 上升的期待值大小。</li>
</ul>
<p>需要強調的是，這樣的線性模型，是我們提出，用來模擬真實數據時使用的。<del>你如果作死</del>當然還可以提出更加複雜的模型。如下面圖 <a href="04-Linear-Regression.html#fig:age-wt-lm">26.2</a> 顯示的是線性迴歸直線， 而圖 <a href="04-Linear-Regression.html#fig:age-wt-loess">26.3</a> 顯示的是較爲複雜的迴歸曲線。曲線方程可能更加擬合我們收集到的數據，然而這樣的連續的斜率變化很可能僅僅只解釋了這個樣本量數據，而不能解釋在人羣中年齡和體重的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm"></span>
<img src="bookdown_files/figure-html/age-wt-lm-1.png" alt="Linear mean function for age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.2: Linear mean function for age and weight of children in a cross-sectional survey
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:age-wt-loess"></span>
<img src="bookdown_files/figure-html/age-wt-loess-1.png" alt="Non-linear mean function for age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.3: Non-linear mean function for age and weight of children in a cross-sectional survey
</p>
</div>
</div>
<div id="條件分佈和方差-the-conditional-distribution-and-the-variance-function" class="section level3">
<h3><span class="header-section-number">26.3.2</span> 條件分佈和方差 the conditional distribution and the variance function</h3>
<p>如果要完全明確一個統計模型，另一個重要的點在於，提出的模型能否準確描述因變量在預測變量的條件下的分佈 (conditional distribution) it is necessary to describe the distribution of the dependent variable conditional on the predictor variable。使用簡單線性迴歸模型有幾個前提假設：</p>
<ol style="list-style-type: decimal">
<li>因變量對預測變量的條件分佈的方差是保持不變的 the variance of the dependent variable (conditional on the predictor variable) is constant。</li>
<li>該條件分佈是一個正態分佈。</li>
</ol>
<p>有時候，這些假設條件並不能得到滿足。上面的散點圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a>看上去還算符合這兩個假設前提：在每一個年齡階段，體重的分佈沒有發生歪斜 (skew)，分散分佈 (方差) 也相對穩定。但是圖 <a href="04-Linear-Regression.html#fig:diamond">26.4</a> 中的價格-克拉數據很明顯無法滿足上面的前提假設。在線性迴歸模型中，我們使用 <span class="math inline">\(\sigma^2\)</span> 表示殘差的方差 (residual variance)。</p>
<div class="figure" style="text-align: center"><span id="fig:diamond"></span>
<img src="bookdown_files/figure-html/diamond-1.png" alt="Relationship between diamond carat and price" width="80%" />
<p class="caption">
圖 26.4: Relationship between diamond carat and price
</p>
</div>
</div>
<div id="defLM" class="section level3">
<h3><span class="header-section-number">26.3.3</span> 定義簡單線性迴歸模型</h3>
<p>用來描述一個隨機變量 <span class="math inline">\((Y)\)</span> 和另一個變量 <span class="math inline">\((X)\)</span> 之間關係的簡單線性迴歸模型，被定義爲：</p>
<p><span class="math display">\[
(Y|X=x) \sim N(\alpha+\beta x, \sigma^2)
\]</span></p>
<p>上面這個模型，同時還描述了我們對數據的分佈的假設。同樣的模型，你可能更多得看到被寫成如下的方式：</p>
<p><span class="math display">\[
y=\alpha+\beta x+ \varepsilon \text{, where } \varepsilon\sim N(0,\sigma^2)
\]</span></p>
<p>假如，我們有一組樣本量爲 <span class="math inline">\(n\)</span> 的數據 <span class="math inline">\(\underline{x}\)</span>。我們就可以把通過上面的迴歸模型實現的 <span class="math inline">\(Y_i\)</span> 和它對應的 <span class="math inline">\(X_i (i=1,\cdots, n)\)</span>。描述爲如下的形式：</p>
<p><span class="math display" id="eq:NID">\[
\begin{equation}
  (Y_i|X_i=x_i) \sim \text{NID}(\alpha+\beta x, \sigma^2) \text{ where } i=1,\cdots,n
\end{equation}
  \tag{26.1}
\]</span></p>
<p>此處的 <span class="math inline">\(\text{NID}\)</span> 意爲獨立且服從正態分佈 <strong>(normally and independently distributed)</strong>。這裏默認的一個重要前提是所有的觀察值 <span class="math inline">\(X_i\)</span> 是相互獨立互不影響的。例如上面圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 所示兒童的年齡和體重數據，就必須假設這些兒童都來自<strong>沒有血緣關係的獨立家庭</strong>。如果這以數據中的兒童，有些是兄弟姐妹的話，觀察數據互相獨立的前提就無法得到滿足。不滿足相互獨立前提的數據，其分析方法會在 “Analysis of hierarchical and other dependent data (Term 2)” 中詳盡介紹。</p>
<p>公式 <a href="04-Linear-Regression.html#eq:NID">(26.1)</a> 常被記爲：</p>
<p><span class="math display" id="eq:NID1">\[
\begin{equation}
(Y_i|X_i=x_i) = \alpha + \beta x_i + \varepsilon_i, \text{ where } \varepsilon_i\sim \text{NID}(0,\sigma^2)
\end{equation}
 \tag{26.2}
\]</span></p>
<p>或者爲了簡潔表述寫成：</p>
<p><span class="math display" id="eq:NID2">\[
\begin{equation}
y_i = \alpha + \beta x_i + \varepsilon_i, \text{ where } \varepsilon_i\sim \text{NID}(0,\sigma^2)
\end{equation}
 \tag{26.3}
\]</span></p>
</div>
<div id="殘差-residuals" class="section level3">
<h3><span class="header-section-number">26.3.4</span> 殘差 residuals</h3>
<p>公式 <a href="04-Linear-Regression.html#eq:NID1">(26.2)</a> 和 <a href="04-Linear-Regression.html#eq:NID2">(26.3)</a> 其實已經包含了殘差的表達式：</p>
<p><span class="math display">\[
\varepsilon_i = y_i - (\alpha + \beta x_i)
\]</span></p>
<p>所以 <span class="math inline">\(\varepsilon_i\)</span> 的意義是第 <span class="math inline">\(i\)</span> 個觀察對象的隨機(偶然)誤差 (random error)，或者叫真實殘差 (true residual)。其實就是從線性迴歸模型計算獲得的映射值 <span class="math inline">\(\alpha+\beta x_i\)</span>，和實際觀察值 <span class="math inline">\(y_i\)</span> 之間的差距。而且從其公式可見，殘差本身也是由人羣的參數 <span class="math inline">\((\alpha, \beta)\)</span> 決定的。殘差也被定義爲迴歸模型的偏差值。當我們用樣本數據獲得的參數估計 <span class="math inline">\((\hat\alpha, \hat\beta)\)</span> 來取代掉參數 <span class="math inline">\((\alpha, \beta)\)</span> 時，這時的模型變成了估計模型，殘差也成了估計殘差或者叫觀察模型和觀察殘差。須和真實殘差加以區分。</p>
</div>
</div>
<div id="參數的估計-estimation-of-parameters" class="section level2">
<h2><span class="header-section-number">26.4</span> 參數的估計 estimation of parameters</h2>
<p>簡單線性迴歸模型中有三個人羣參數 <span class="math inline">\((\alpha, \beta, \sigma^2)\)</span>。統計分析的目標，就是使用樣本數據 <span class="math inline">\(Y_i, X_i, (i=1, \cdots, n)\)</span> 來對總體參數做出推斷 (inference)。在線性迴歸中主要使用<strong>普通最小二乘法 (ordinary least squares, OLS)</strong> 作爲推斷的工具。在統計學中，我們習慣給希臘字母戴上“帽子”，作爲該參數的估計值，例如 <span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是參數 <span class="math inline">\(\alpha, \beta\)</span> 的估計值。通過線性迴歸模型，給第 <span class="math inline">\(i\)</span> 個觀察值擬合的預測值，被叫做因變量的估計期望值 (estimated expectation)。用下面的式子來表示:</p>
<p><span class="math display">\[
\hat{y}_i=\hat\alpha+\hat\beta x_i
\]</span></p>
<p>此時，第 <span class="math inline">\(i\)</span> 名對象的觀察殘差 (observed or fitted or estimated residuals) 用下面的式子來表示：</p>
<p><span class="math display">\[
\hat{\varepsilon}_i = y_i-\hat{y}_i=y_i-(\hat\alpha+\hat\beta x_i)
\]</span></p>
<div id="MLEalphabeta" class="section level3">
<h3><span class="header-section-number">26.4.1</span> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></h3>
<p>普通最小二乘法估計的 <span class="math inline">\(\alpha, \beta\)</span> 會最小化擬合迴歸直線的偏差 minimize the sum of squared deviations from the fitted regression line。其正式的定義爲：OLS估計值，指的是能夠使<strong>殘差平方和 (residual sum of squares, <span class="math inline">\(SS_{RES}\)</span>)</strong>取最小值的 <span class="math inline">\(\hat\alpha, \hat\beta\)</span>。</p>
<p><span class="math display" id="eq:ssres">\[
\begin{equation}
SS_{RES} = \sum_{i=1}^n \hat{\varepsilon}^2_i = \sum_{i=1}^n (y_i-\hat\alpha-\hat\beta x_i)^2
\end{equation}
\tag{26.4}
\]</span></p>
<p>可以證明的是，OLS的 <span class="math inline">\(\alpha, \beta\)</span> 估計值的計算公式爲：</p>
<p><span class="math display" id="eq:hatalpha">\[
\begin{equation}
\hat\alpha=\bar{y}-\hat\beta\bar{x}
\tag{26.5}
\end{equation}
\]</span></p>
<p><span class="math display" id="eq:hatbeta">\[
\begin{equation}
\hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}
\tag{26.6}
\end{equation}
\]</span></p>
<p>其中 <span class="math inline">\(\bar{y}=\frac{\sum_{i=1}^ny_i}{n}, \bar{x}=\frac{\sum_{i=1}^nx_i}{n}\)</span></p>
<p><strong>證明</strong></p>
<p>求能最小化 <span class="math inline">\(SS_{RES}\)</span> 的 <span class="math inline">\(\alpha\)</span>， 我們需要把公式 <a href="04-Linear-Regression.html#eq:ssres">(26.4)</a> 對 <span class="math inline">\(\hat\alpha\)</span> 求導，然後將求導之後的式子等於 <span class="math inline">\(0\)</span> 之後求根即可：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\text{d}SS_{RES}}{\text{d}\hat\alpha} =\sum_{i=1}^n -2(y_i-\hat\alpha-\hat\beta x_i) = 0\\
&amp; \text{Since } \sum_{i=1}^n(y_i) = n\bar{y}; \sum_{i=1}^n (x_i) =n\bar{x} \\
&amp; \Rightarrow -n\bar{y}+n\hat\alpha+n\hat\beta\bar{x} = 0 \\
&amp; \Rightarrow \hat\alpha = \bar{y}-\hat\beta\bar{x}
\end{aligned}
\]</span></p>
<p>求能最小化 <span class="math inline">\(SS_{RES}\)</span> 的 <span class="math inline">\(\beta\)</span>，求導之前我們先把公式 <a href="04-Linear-Regression.html#eq:ssres">(26.4)</a> 中含有 <span class="math inline">\(\hat\alpha\)</span> 的部分替換掉：</p>
<p><span class="math display" id="eq:ssres-rearrange">\[
\begin{equation}
\begin{split}
SS_{RES} &amp;= \sum_{i=1}^n\hat\varepsilon_i^2=\sum_{i=1}^n(y_i-(\bar{y}-\hat\beta\bar{x})-\hat\beta x_i)^2\\
         &amp;= \sum_{i=1}^n((y_i-\bar{y})-\hat\beta(x_i-\bar{x}))^2 \\
\end{split}
\tag{26.7}
\end{equation}
\]</span></p>
<p>接下來對上式 <a href="04-Linear-Regression.html#eq:ssres-rearrange">(26.7)</a> 求導之後，用相同辦法求根：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{\mathrm{d} SS_{RES}}{\mathrm{d} \hat\beta} = \sum_{i=1}^n -2(x_i-\bar{x})(y_i-\bar{y}) + 2\hat\beta(x_i-\bar{x})^2 = 0\\
&amp; \Rightarrow \hat\beta\sum_{i=1}^n(x_i-\bar{x})^2 = \sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y}) \\
&amp; \hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}
\end{aligned}
\]</span></p>
<p>這兩個式子 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> <a href="04-Linear-Regression.html#eq:hatbeta">(26.6)</a> 同時也是參數 <span class="math inline">\(\alpha, \beta\)</span> 的極大似然估計 (MLE)。</p>
</div>
</div>
<div id="ResidualVar" class="section level2">
<h2><span class="header-section-number">26.5</span> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></h2>
<p>殘差方差等於殘差平方和除以樣本量。所以我們會把殘差方差的估計用下面的式子表示：</p>
<p><span class="math display" id="eq:sigma2wrong">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n \frac{\hat\varepsilon^2}{n} = \sum_{i=1}^n \frac{(y_i-\hat\alpha-\hat\beta x_i)^2}{n}
\end{equation}
\tag{26.8}
\]</span></p>
<p>這的確是 <span class="math inline">\(\sigma^2\)</span> 的極大似然估計 (MLE)。然而我們知道，公式 <a href="04-Linear-Regression.html#eq:sigma2wrong">(26.8)</a> 並不是殘差方差的無偏估計。類似與樣本方差低估了總體方差 (Section <a href="02-Inference.html#samplevarbias">10.3</a>)，那樣，這裏殘差方差的觀察值也是低估了總體殘差方差的。所以，殘差方差的無偏估計需要用下面的式子來校正：</p>
<p><span class="math display" id="eq:sigma2right">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n \frac{\hat\varepsilon^2}{n-2} = \sum_{i=1}^n \frac{(y_i-\hat\alpha-\hat\beta x_i)^2}{n-2}
\end{equation}
\tag{26.9}
\]</span></p>
<p>公式 <a href="04-Linear-Regression.html#eq:sigma2right">(26.9)</a> 被叫做殘差均方 (Residual Mean Squares, RMS)，常常被標記爲 <span class="math inline">\(\text{MS}_{RES}\)</span>。分母的 <span class="math inline">\(n-2\)</span>，表示進行殘差方差估計時用掉了兩個信息量 <span class="math inline">\(\alpha, \beta\)</span> (自由度減少了 2)，</p>
</div>
<div id="growgam" class="section level2">
<h2><span class="header-section-number">26.6</span> R 演示 例 1： 圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 數據</h2>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb71-2" title="2">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb71-3" title="3"></a>
<a class="sourceLine" id="cb71-4" title="4">slm &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb71-5" title="5"></a>
<a class="sourceLine" id="cb71-6" title="6"><span class="kw">summary</span>(slm) <span class="co"># basic default output of the summary</span></a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.924 -0.785  0.007  0.797  4.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.8376     0.2101    32.5   &lt;2e-16 ***
## age           0.1653     0.0111    14.9   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.27 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(slm), <span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show the sum of squares for the fitted model and residuals</span></a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>也可以用 <code>stargazer</code> 包輸出很酷的表格報告：</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1"><span class="kw">library</span>(stargazer)</a>
<a class="sourceLine" id="cb75-2" title="2"><span class="kw">stargazer</span>(slm, <span class="dt">type =</span> <span class="st">&quot;html&quot;</span>)</a></code></pre></div>
<table style="text-align:center">
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
wt
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
0.165<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
6.838<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.210)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
190
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.541
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.538
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
1.274 (df = 188)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
221.400<sup>***</sup> (df = 1; 188)
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
<p>其實結果都一樣。我們這裏詳細來看 <span class="math inline">\(\alpha, \beta, \sigma^2\)</span>：</p>
<p><span class="math inline">\(\hat\alpha = 6.84\)</span>：當年齡爲 <span class="math inline">\(0\)</span> 時，體重爲 <span class="math inline">\(6.84 kg\)</span>。本數據 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 中並沒有 <span class="math inline">\(0\)</span> 歲的兒童，所以這裏的截距的解釋需要非常小心是否合理。</p>
<p><span class="math inline">\(\hat\beta = 0.165\)</span>：這數據中兒童的體重估計隨着年齡升高 <span class="math inline">\(1\)</span> 個月增長 <span class="math inline">\(0.165 kg\)</span>。所以使用這兩個估計值我們就可以來估計任意年齡時兒童的體重。圖 <a href="04-Linear-Regression.html#fig:age-wt-lm">26.2</a> 就是擬合數據以後的簡單線性迴歸曲線。</p>
<p><span class="math inline">\(\hat\sigma^2 = 1.62, \hat\sigma=1.27\)</span> 就是默認輸出中最下面的 <code>Residual standard error: 1.274</code> 和 ANOVA 表格中 Residuals 的 <code>Mean Sq=1.62184</code> 部分。含義是，沿着擬合的直線，在每一個給定的年齡上兒童體重的分佈的標準差是 <span class="math inline">\(1.27 kg\)</span>。</p>
</div>
<div id="binarylms" class="section level2">
<h2><span class="header-section-number">26.7</span> R 演示 例 2： 表<a href="04-Linear-Regression.html#tab:walk">26.1</a> 數據</h2>
<p>如果在 <code>Stata</code> 聽說你還需要自己生成啞變量 (dummy variables) (應該是計算時，在想要變成啞變量的變量名前面加上 <code>i.</code>)。在 <a href="https://www.r-project.org/">R</a> 裏面，分類變量被設置成因子 “factor” 時，你就完全可以忽略生成啞變量的過程。下圖 <a href="04-Linear-Regression.html#fig:age-walk">26.5</a> 顯示了兩組兒童直立行走時的年齡。</p>
<div class="figure" style="text-align: center"><span id="fig:age-walk"></span>
<img src="bookdown_files/figure-html/age-walk-1.png" alt="Age at walking by group" width="80%" />
<p class="caption">
圖 26.5: Age at walking by group
</p>
</div>
<p>擬合簡單線性迴歸也是小菜一碟：</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1">wk_age &lt;-<span class="st"> </span><span class="kw">lm</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>Walk)</a>
<a class="sourceLine" id="cb76-2" title="2"></a>
<a class="sourceLine" id="cb76-3" title="3"><span class="kw">summary</span>(wk_age)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Age ~ Group, data = Walk)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -1.125 -0.738 -0.375  0.388  2.875 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    10.125      0.512   19.77    1e-08 ***
## Groupcontrol    2.225      0.760    2.93    0.017 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.25 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.488,  Adjusted R-squared:  0.431 
## F-statistic: 8.58 on 1 and 9 DF,  p-value: 0.0168</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">anova</span>(wk_age)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Age
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Group      1   13.5   13.50    8.58  0.017 *
## Residuals  9   14.2    1.57                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>這裏的 <span class="math inline">\(\hat\alpha=10.125\)</span>，意爲參照組 (此處，“exercise” 被默認設定爲參照組，而 “control” 被默認拿來和參照組相比較) 的兒童也就是，積極練習走路的小朋友這組能夠獨立行走的平均年齡是 <span class="math inline">\(10.125\)</span> 個月。</p>
<p><span class="math inline">\(\hat\beta=2.225\)</span>，意爲和參照組 (積極練習組) 相比，對照組兒童能夠自己行走的年齡平均要晚 <span class="math inline">\(2.225\)</span> 個月。所以對照組兒童能夠直立行走的平均年齡就是 <span class="math inline">\(10.125+2.225=12.35\)</span> 個月。</p>
<p>上述結果，你如果拿來和下面的兩樣本 <span class="math inline">\(t\)</span> 檢驗的結果相比就知道，是完全一致的。其中統計量 <span class="math inline">\(t^2=2.9285^2=F_{1,9}=8.58\)</span>。</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="kw">t.test</span>(Age<span class="op">~</span>Group, <span class="dt">data=</span>Walk, <span class="dt">var.equal=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Age by Group
## t = -2.9, df = 9, p-value = 0.02
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.9437 -0.5063
## sample estimates:
## mean in group exercise  mean in group control 
##                  10.12                  12.35</code></pre>
</div>
<div id="exeChol" class="section level2">
<h2><span class="header-section-number">26.8</span> 練習</h2>
<p>使用的數據內容爲：兩次調查同一樣本，99 名健康男性的血清膽固醇水平，間隔一年。</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="co"># 數據讀入</span></a>
<a class="sourceLine" id="cb82-2" title="2">Chol &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/chol.dta&quot;</span>)</a>
<a class="sourceLine" id="cb82-3" title="3"><span class="kw">summary</span>(Chol)</a></code></pre></div>
<pre><code>##        id           chol1         chol2    
##  Min.   : 1.0   Min.   :152   Min.   :170  
##  1st Qu.:25.5   1st Qu.:235   1st Qu.:240  
##  Median :50.0   Median :265   Median :260  
##  Mean   :50.0   Mean   :265   Mean   :264  
##  3rd Qu.:74.5   3rd Qu.:290   3rd Qu.:290  
##  Max.   :99.0   Max.   :360   Max.   :355</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1"><span class="co"># Alternative Descriptive Statistics using psych package</span></a>
<a class="sourceLine" id="cb84-2" title="2"><span class="kw">describe</span>(Chol)</a></code></pre></div>
<pre><code>## Chol 
## 
##  3  Variables      99  Observations
## ----------------------------------------------------------------------------------------------------
## id  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       99        1       50    33.33      5.9     10.8     25.5     50.0     74.5 
##      .90      .95 
##     89.2     94.1 
## 
## lowest :  1  2  3  4  5, highest: 95 96 97 98 99
## ----------------------------------------------------------------------------------------------------
## chol1  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       51    0.999    264.6    46.11    204.5    210.0    235.0    265.0    290.0 
##      .90      .95 
##    320.0    330.3 
## 
## lowest : 152 170 190 200 205, highest: 333 340 350 355 360
## ----------------------------------------------------------------------------------------------------
## chol2  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       30    0.997    263.5    43.28      200      215      240      260      290 
##      .90      .95 
##      311      330 
## 
## lowest : 170 190 195 200 205, highest: 320 330 345 350 355
## ----------------------------------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="co"># 兩次膽固醇水平的直方圖 Distribution of the two measures</span></a>
<a class="sourceLine" id="cb86-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb86-3" title="3"><span class="kw">hist</span>(Chol<span class="op">$</span>chol1)</a>
<a class="sourceLine" id="cb86-4" title="4"><span class="kw">hist</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM04-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" title="1"><span class="co"># 對兩次膽固醇水平作散點圖</span></a>
<a class="sourceLine" id="cb87-2" title="2"><span class="kw">ggplot</span>(Chol, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-3" title="3"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb87-4" title="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-5" title="5"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM04-2.png" width="80%" style="display: block; margin: auto;" /></p>
<div id="兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些" class="section level3">
<h3><span class="header-section-number">26.8.1</span> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</h3>
<ul>
<li>每個觀察對象互相獨立。</li>
<li>前後兩次測量的膽固醇水平呈線性相關。</li>
<li>殘差值，在每一個給定的 <span class="math inline">\(C_1\)</span> 值處呈現正態分佈，且方差不變。</li>
</ul>
<p>從散點圖來看這些假設應該都能得到滿足。</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="co"># 計算兩次膽固醇水平的 均值，方差，以及二者的協方差</span></a>
<a class="sourceLine" id="cb88-2" title="2"><span class="kw">mean</span>(Chol<span class="op">$</span>chol1); <span class="kw">mean</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 264.6</code></pre>
<pre><code>## [1] 263.5</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">var</span>(Chol<span class="op">$</span>chol1); <span class="kw">var</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 1661</code></pre>
<pre><code>## [1] 1457</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1"><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 961.2</code></pre>
</div>
<div id="計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta" class="section level3">
<h3><span class="header-section-number">26.8.2</span> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></h3>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp;= \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}\\
&amp;=\frac{\text{Cov}(C_1,C_2)}{\text{Var}(C_1)}\\
&amp;=\frac{1661.061}{961.224}=0.578
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1"><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)<span class="op">/</span><span class="kw">var</span>(Chol<span class="op">$</span>chol1)</a></code></pre></div>
<pre><code>## [1] 0.5787</code></pre>
<p><span class="math display">\[\hat\alpha=\bar{y}-\hat\beta\bar{x}=263.54-0.578\times264.59=110.425\]</span></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" title="1"><span class="kw">mean</span>(Chol<span class="op">$</span>chol2)<span class="op">-</span><span class="kw">mean</span>(Chol<span class="op">$</span>chol1)<span class="op">*</span><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)<span class="op">/</span><span class="kw">var</span>(Chol<span class="op">$</span>chol1)</a></code></pre></div>
<pre><code>## [1] 110.4</code></pre>
</div>
<div id="和迴歸模型計算的結果作比較解釋這些估計值的含義" class="section level3">
<h3><span class="header-section-number">26.8.3</span> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</h3>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chol2 ~ chol1, data = Chol)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -56.88 -22.06   1.85  16.63  84.12 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 110.4247    20.0113    5.52  2.8e-07 ***
## chol1         0.5787     0.0748    7.74  9.5e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.2 on 97 degrees of freedom
## Multiple R-squared:  0.382,  Adjusted R-squared:  0.375 
## F-statistic: 59.9 on 1 and 97 DF,  p-value: 9.51e-12</code></pre>
<ul>
<li>截距的估計值是 110.4 mg/100ml: 意爲這組樣本，第一次採集數據時，膽固醇水平的平均值是 110.4。</li>
<li>斜率的估計值是 0.58：意爲第一次採集的膽固醇水平每高 1 mg/100ml，那麼第二次採集的膽固醇相應提高的值的期待量爲 0.58.</li>
</ul>
</div>
<div id="加上計算的估計值直線-即迴歸直線" class="section level3">
<h3><span class="header-section-number">26.8.4</span> 加上計算的估計值直線 (即迴歸直線)</h3>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1"><span class="kw">ggplot</span>(Chol, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-2" title="2"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-3" title="3"><span class="st">   </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb102-4" title="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-5" title="5"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM09-1.png" width="672" /></p>
<p>可以注意到，第一次訪問時膽固醇水平高的人，第二次被測量時膽固醇值高於平均值，但是卻沒有第一次高出平均值的部分多。
相似的，第一次膽固醇水平低的人，第二次膽固醇水平低於平均值，但是卻沒有第一次低於平均值的部分多。這一現象被叫做 “向均數迴歸-regression to the mean”</p>
</div>
<div id="diagnosis" class="section level3">
<h3><span class="header-section-number">26.8.5</span> 下面的代碼用於模型的假設診斷</h3>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1">M &lt;-<span class="st"> </span><span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol)</a>
<a class="sourceLine" id="cb103-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))  <span class="co"># Split the plotting panel into a 2 x 2 grid</span></a>
<a class="sourceLine" id="cb103-3" title="3"><span class="kw">plot</span>(M)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM10-1.png" width="672" /></p>
<p>好心人在 <a href="https://gist.github.com/atyre2/ff4e1ec24e42adda8dbd43cda99d6282">github</a> 上共享了 <code>Check_assumption.R</code> 的代碼，可以使用 ggplot2 來獲取高逼格的模型診斷圖：</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">source</span>(<span class="st">&quot;checkassumptions.R&quot;</span>)</a>
<a class="sourceLine" id="cb104-2" title="2"><span class="kw">check_assumptions</span>(M)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM11-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference" class="section level1">
<h1><span class="header-section-number">第 27 章</span> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</h1>
<p>前一章介紹了簡單線性迴歸模型中對總體參數 <span class="math inline">\(\alpha, \beta, \sigma^2\)</span> 的估計公式，分別是 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> <a href="04-Linear-Regression.html#eq:hatbeta">(26.6)</a> <a href="04-Linear-Regression.html#eq:sigma2right">(26.9)</a>。本章繼續介紹他們的統計學性質。下面的標記和統計量也會被用到：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\bar{y}=\frac{\sum_{i=1}^n y_i}{n}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本均值；</li>
<li><span class="math inline">\(\bar{x}=\frac{\sum_{i=1}^n x_i}{n}\)</span>，預測變量 <span class="math inline">\(x\)</span> 的樣本均值；</li>
<li><span class="math inline">\(SS_{yy}=\sum_{i=1}^n(y_i-\bar{y})^2\)</span>，因變量 <span class="math inline">\(y\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SS_{xx}=\sum_{i=1}^n(x_i-\bar{x})^2\)</span>，預測變量 <span class="math inline">\(x\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SD_y^2=\frac{\sum_{i=1}(y_i-\bar{y})^2}{n-1}=\frac{SS_{yy}}{n-1}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本方差；</li>
<li><span class="math inline">\(SD_x^2=\frac{\sum_{i=1}(x_i-\bar{x})^2}{n-1}=\frac{SS_{xx}}{n-1}\)</span>，預測變量 <span class="math inline">\(x\)</span> 的樣本方差；</li>
<li><span class="math inline">\(S_{xy}=\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})\)</span>，<span class="math inline">\(x,y\)</span> 的交叉乘積；</li>
<li><span class="math inline">\(CV_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}=\frac{S_{xy}}{n-1}\)</span>，樣本協方差；</li>
<li><span class="math inline">\(r_{xy}=\frac{CV_{xy}}{SD_xSD_y}\)</span>，<span class="math inline">\(x,y\)</span> 的樣本相關係數；</li>
<li><span class="math inline">\(SS_{RES}=\sum_{i=1}^n\hat\varepsilon^2=\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2\)</span>，殘差的估計平方和。</li>
</ol>
<div id="ols-估計量的性質" class="section level2">
<h2><span class="header-section-number">27.1</span> OLS 估計量的性質</h2>
<ol style="list-style-type: decimal">
<li>樣本估計的迴歸直線必定穿過數據的中心 <span class="math inline">\((\bar{x},\bar{y})\)</span>。</li>
</ol>
<p><strong>證明</strong></p>
<p>由於樣本估計的截距和斜率公式 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> <a href="04-Linear-Regression.html#eq:hatbeta">(26.6)</a> 可知：</p>
<p><span class="math display" id="eq:lmcenter">\[
\begin{aligned}
\hat\alpha &amp;= \bar{y} - \hat\beta\bar{x} \\
 \hat y_i  &amp;= \hat\alpha + \hat\beta x_i \\
 \Rightarrow \hat y_i &amp;= \bar{y}+\hat\beta(x_i-\bar{x})
\end{aligned}
\tag{27.1}
\]</span></p>
<p>所以，當 <span class="math inline">\(\hat x_i=\bar{x}\)</span> 時 <span class="math inline">\(\hat y_i=\bar{y}\)</span>。即迴歸直線必然穿過中心點。</p>
<ol start="2" style="list-style-type: decimal">
<li>如果擬合模型是正確無誤的， <span class="math inline">\(\hat\alpha,\hat\beta,\hat\sigma^2\)</span> 分別是各自的無偏估計。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是極大似然估計， <span class="math inline">\(\hat\sigma^2\)</span> 不是MLE。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是 <span class="math inline">\(\alpha, \beta\)</span> 最有效的估計量。</li>
</ol>
</div>
<div id="beta" class="section level2">
<h2><span class="header-section-number">27.2</span> <span class="math inline">\(\hat\beta\)</span> 的性質</h2>
<p><span class="math display" id="eq:hatbetaalt">\[
\begin{equation}
\hat\beta=\frac{S_{xy}}{SS_{xx}}=\frac{CV_{xy}}{SD_x^2}
\end{equation}
\tag{27.2}
\]</span></p>
<div id="randbeta" class="section level3">
<h3><span class="header-section-number">27.2.1</span> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</h3>
<p>如果我們使用 <span class="math inline">\(\hat\beta_{y|x}\)</span> 表示預測變量 <span class="math inline">\(x\)</span>，因變量 <span class="math inline">\(y\)</span> 的簡單線性迴歸係數，那麼我們就有：</p>
<p><span class="math display" id="eq:r2">\[
\begin{equation}
\hat\beta_{y|x} = \frac{CV_{xy}}{SD_x^2}  \text{ and } \hat\beta_{x|y} = \frac{CV_{xy}}{SD_y^2} \\
\text{Hence, } \hat\beta_{y|x}\hat\beta_{x|y} = r^2_{xy}
\end{equation}
\tag{27.3}
\]</span></p>
<p>公式 <a href="04-Linear-Regression.html#eq:r2">(27.3)</a> 也證明了：如果兩個變量相關係數爲 <span class="math inline">\(1\)</span> (100% 相關)， <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸的迴歸係數，是 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸的迴歸係數的倒數。</p>
</div>
<div id="例-1-還是圖-reffigage-wt-數據" class="section level3">
<h3><span class="header-section-number">27.2.2</span> 例 1： 還是圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 數據</h3>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb105-2" title="2">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb105-3" title="3"></a>
<a class="sourceLine" id="cb105-4" title="4"><span class="co"># regress wt on age</span></a>
<a class="sourceLine" id="cb105-5" title="5"><span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.924 -0.785  0.007  0.797  4.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.8376     0.2101    32.5   &lt;2e-16 ***
## age           0.1653     0.0111    14.9   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.27 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" title="1"><span class="co"># regress age on wt</span></a>
<a class="sourceLine" id="cb109-2" title="2"><span class="kw">summary</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = age ~ wt, data = growgam1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.010  -4.239   0.083   3.130  21.111 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -14.57       2.16   -6.75  1.8e-10 ***
## wt              3.27       0.22   14.88  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.66 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: age
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## wt          1 7103.6730 7103.6730 221.39203 &lt; 2.22e-16 ***
## Residuals 188 6032.2428   32.0864                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>可以看到二者的輸出結果中統計檢驗量一樣，但是一個是將體重針對年齡迴歸，另一個則是反過來，所以迴歸係數和截距都不同。迴歸方程的含義也就發生了變化。如果把兩條迴歸曲線同時作圖可以更加直觀：</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm1"></span>
<img src="bookdown_files/figure-html/age-wt-lm1-1.png" alt="Simple linear regression model line relating weight to age" width="80%" />
<p class="caption">
圖 27.1: Simple linear regression model line relating weight to age
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:wt-age-lm"></span>
<img src="bookdown_files/figure-html/wt-age-lm-1.png" alt="Simple linear regression model line relating age to weight" width="80%" />
<p class="caption">
圖 27.2: Simple linear regression model line relating age to weight
</p>
</div>
</div>
</div>
<div id="截距和迴歸係數的方差協方差" class="section level2">
<h2><span class="header-section-number">27.3</span> 截距和迴歸係數的方差，協方差</h2>
<p>假如簡單線性迴歸模型是正確的，那麼截距 <span class="math inline">\(\hat\alpha\)</span> 和迴歸係數 <span class="math inline">\(\hat\beta\)</span> 的方差分別是：</p>
<p><span class="math display" id="eq:varhatalpha">\[
\begin{equation}
V(\hat\alpha) = \sigma^2(\frac{1}{n}+\frac{\bar{x}^2}{SS_{xx}}) = \frac{\sigma^2}{(n-1)} (1-\frac{1}{n}+\frac{\bar{x}^2}{SD_x^2})
\end{equation}
\tag{27.4}
\]</span></p>
<p><span class="math display" id="eq:varhatbeta">\[
\begin{equation}
V(\hat\beta) = \frac{\sigma^2}{SS_{xx}}=\frac{\sigma^2}{(n-1)SD_x^2}
\end{equation}
\tag{27.5}
\]</span></p>
<p>從公式 <a href="04-Linear-Regression.html#eq:varhatalpha">(27.4)</a> 和 <a href="04-Linear-Regression.html#eq:varhatbeta">(27.5)</a> 也可以看出，兩個估計量的方差隨着殘差方差的增加而增加 (估計不精確)，隨着樣本量的增加而減少 (估計更精確)。截距 <span class="math inline">\(\hat\alpha\)</span> 的方差會隨着樣本均值的增加而增加。</p>
<p>通常來說，截距和迴歸係數二者之間並非相互獨立。他們的協方差爲：</p>
<p><span class="math display" id="eq:covaralphabeta">\[
\begin{equation}
Cov(\hat\alpha,\hat\beta) = -\frac{\sigma^2\bar{x}}{SS_{xx}}
\end{equation}
\tag{27.6}
\]</span></p>
<p>上面的公式 <a href="04-Linear-Regression.html#eq:varhatalpha">(27.4)</a> <a href="04-Linear-Regression.html#eq:varhatbeta">(27.5)</a> <a href="04-Linear-Regression.html#eq:covaralphabeta">(27.6)</a> 都包含了真實的殘差方差 <span class="math inline">\(\sigma^2\)</span>。這個量對於我們“人類”來說是未知的。</p>
<div id="centring" class="section level3">
<h3><span class="header-section-number">27.3.1</span> 中心化 centring</h3>
<p>簡單線性迴歸模型常用的一個技巧是將預測變量中心化。即，求預測變量的均值，然後將每個觀測值減去均值之後再用這個新的預測變量擬合簡單線性迴歸模型。這樣做其實完全不影響回顧係數，卻會影響截距的大小。此時新的迴歸直線的截距，就等於因變量 (體重) 的均值。</p>
<p>用圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 數據來解釋：</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" title="1"><span class="co"># mean value of age</span></a>
<a class="sourceLine" id="cb113-2" title="2"><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a></code></pre></div>
<pre><code>## [1] 16.98</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" title="1">growgam1<span class="op">$</span>age_cen &lt;-<span class="st"> </span>growgam1<span class="op">$</span>age<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb115-2" title="2"><span class="co"># regress wt on age</span></a>
<a class="sourceLine" id="cb115-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 6.837584   0.210070  32.549 &lt; 2.2e-16 ***
## age         0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" title="1"><span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age_cen, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age_cen, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 9.644737   0.092391 104.391 &lt; 2.2e-16 ***
## age_cen     0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>很明顯，結果顯示中心化不會改變迴歸係數，也不會改變它的方差。但是“新”的截距，其實就等於因變量 (體重) 的均值。而且很多數據都集中在這個均值附近，因而，截距的方差比沒有中心化的迴歸方程要小。</p>
</div>
</div>
<div id="alpha-beta-的推斷" class="section level2">
<h2><span class="header-section-number">27.4</span> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</h2>
<p><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 都可以被改寫成關於因變量 <span class="math inline">\(Y\)</span> 的方程，因此同時也是隨機誤差的方程式：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp;= \sum_{i=1}^n[\frac{(x_i-\bar{x})}{SS_{xx}}(y_i-\bar{y})] \\
\text{Substituting } &amp;(y_i-\bar{y}) = \beta(x_i-\bar{x})+(\varepsilon_i-\bar{\varepsilon}) \\
          &amp;= \beta + \sum_{i=1}^n[\frac{x_i-\bar{x}}{SS_{xx}}(\varepsilon_i-\bar{\varepsilon})]
\end{aligned}
\]</span></p>
<p>又因爲，<span class="math inline">\(\varepsilon_i \sim NID(0,\sigma^2)\)</span>，估計量 <span class="math inline">\(\hat\alpha, \hat\beta\)</span> 均爲 <span class="math inline">\(\varepsilon_i\)</span> 的線性轉換，所以他們也都是服從正態分佈的。</p>
<div id="對迴歸係數進行假設檢驗" class="section level3">
<h3><span class="header-section-number">27.4.1</span> 對迴歸係數進行假設檢驗</h3>
<p>對於迴歸係數 <span class="math inline">\(\beta\)</span>，我們可以使用 Wald statistic (Section <a href="02-Inference.html#Wald">16.4</a>) 進行零假設爲 <span class="math inline">\(\text{H}_0: \beta=0\)</span> 的假設檢驗。此時，替代假設爲 <span class="math inline">\(\text{H}_1: \beta\neq0\)</span>。最佳檢驗統計量爲：</p>
<p><span class="math display" id="eq:betattest">\[
\begin{equation}
t = \frac{\hat\beta-0}{SE(\hat\beta)} \\
\end{equation}
\tag{27.7}
\]</span></p>
<p>根據公式 <a href="04-Linear-Regression.html#eq:varhatbeta">(27.5)</a> <span class="math inline">\(SE(\hat\beta) = \sqrt{V(\hat\beta)} = \frac{\hat\sigma}{\sqrt{SS_{xx}}}\)</span>。用 <span class="math inline">\(\hat\sigma^2\)</span> 替換掉公式 <a href="04-Linear-Regression.html#eq:varhatbeta">(27.5)</a> 中的 <span class="math inline">\(\sigma^2\)</span>，意味着迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 服從自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈。之後就可以根據 <span class="math inline">\(t\)</span> 分佈的性質求相應的 <span class="math inline">\(p\)</span> 值了，對相關係數是否爲 <span class="math inline">\(0\)</span> 進行檢驗。之所以我們可以在這裏使用 Wald 檢驗，是因爲前提條件：隨機誤差服從正態分佈，於是 <span class="math inline">\(\beta\)</span> 的對數似然比也是左右對稱的，當對數似然比的圖形左右對稱時，就可以使用二次方程來近似 (Wald 檢驗的實質)。</p>
</div>
<div id="迴歸係數截距的信賴區間" class="section level3">
<h3><span class="header-section-number">27.4.2</span> 迴歸係數，截距的信賴區間</h3>
<p>估計量 <span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算公式如下：</p>
<p><span class="math display" id="eq:CIbeta">\[
\begin{equation}
\hat\beta \pm t_{n-2,0.975}SE(\hat\beta)
\end{equation}
\tag{27.8}
\]</span></p>
<p>其中，<span class="math inline">\(t_{n-2, 0.975}\)</span> 表示自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈的 <span class="math inline">\(97.5\%\)</span> 位點的值。繼續使用之前的實例，圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 中的數據。體重對年齡進行簡單線性迴歸之後，年齡的估計回顧係數 <span class="math inline">\(\hat\beta=0.165, SE(\hat\beta)=0.0111\)</span>, 此例中 <span class="math inline">\(n=190\)</span>，所以 <span class="math inline">\(t_{188, 0.975}=1.973\)</span>。所以迴歸係數的 <span class="math inline">\(95\%\)</span> 信賴區間可以如此計算：<span class="math inline">\(0.165\pm1.973\times0.0111=(0.143, 0.187)\)</span>。</p>
<p>類似的，估計截距 <span class="math inline">\(\hat\alpha\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算式便是： <span class="math inline">\(\hat\alpha \pm t_{n-2, 0.975}SE(\hat\alpha)\)</span>。同樣的例子裏，<span class="math inline">\(\hat\alpha=6.838, SE(\hat\beta) = 0.210, t_{188, 0.975}=1.973\)</span>。所以截距的 <span class="math inline">\(95\%\)</span> 信賴區間的計算方法就是： <span class="math inline">\(6.838\pm1.973\times0.210=(6.42, 7.25)\)</span></p>
<p>跟下面 R 計算的完全一樣：</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 6.4232 7.2520
## age         0.1434 0.1873</code></pre>
</div>
<div id="預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性" class="section level3">
<h3><span class="header-section-number">27.4.3</span> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</h3>
<p>這裏所謂的“預測值”其實並沒有拿來預測什麼新的數值，而是說我們希望通過線性迴歸找到因變量真實值的存在區間 (信賴區間)。所以這個預測值的真實含義其實應該是在預測變量取 <span class="math inline">\(X=x\)</span> 時，因變量的期待值，<span class="math inline">\(E(Y|X=x)\)</span>。</p>
<p>這個預測值的方差公式如下：</p>
<p><span class="math display" id="eq:predictvar">\[
\begin{equation}
V(\hat y_{x}) = \sigma^2[\frac{1}{n}+\frac{(x_i-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{27.9}
\]</span></p>
<p>於是可以計算它的 <span class="math inline">\(95\%\)</span> 信賴區間公式是：</p>
<p><span class="math display" id="eq:predictCI">\[
\begin{equation}
\hat y_x \pm t_{n-2, 0.975} \hat\sigma \sqrt{[\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]}
\end{equation}
\tag{27.10}
\]</span></p>
<p>其實在之前的圖 (圖 <a href="04-Linear-Regression.html#fig:age-wt-lm">26.2</a>) 我們也已經展示過這個信賴區間的範圍。</p>
</div>
<div id="預測帶-reference-range---包含了-95-觀察值的區間" class="section level3">
<h3><span class="header-section-number">27.4.4</span> 預測帶 Reference range - 包含了 95% 觀察值的區間</h3>
<p>此處的 <span class="math inline">\(95\%\)</span> 預測帶，其實是包含了 <span class="math inline">\(95\%\)</span> 觀察數據的區間。所以預測帶要比置信帶更寬。它的方差計算公式爲：</p>
<p><span class="math display" id="eq:refrangevar">\[
\begin{equation}
V(\hat y_x)+\sigma^2 = \sigma^2[1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{27.11}
\]</span></p>
<p>區間計算公式爲：</p>
<p><span class="math display" id="eq:refrangeCI">\[
\begin{equation}
\hat{y}_x \pm t_{n-2, 0.975} \sqrt{1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}}
\end{equation}
\tag{27.12}
\]</span></p>
<p>將置信帶和預測帶同時展現則如下圖：</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb121-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb121-2" title="2"></a>
<a class="sourceLine" id="cb121-3" title="3"></a>
<a class="sourceLine" id="cb121-4" title="4">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb121-5" title="5">temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a>
<a class="sourceLine" id="cb121-6" title="6"></a>
<a class="sourceLine" id="cb121-7" title="7">new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(growgam1, temp_var)</a>
<a class="sourceLine" id="cb121-8" title="8"></a>
<a class="sourceLine" id="cb121-9" title="9"></a>
<a class="sourceLine" id="cb121-10" title="10"><span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>wt)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-11" title="11"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">TRUE</span>, <span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-12" title="12"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb121-13" title="13"><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb121-14" title="14"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">38</span>, <span class="dv">4</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">36.5</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb121-15" title="15"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">5</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">20.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-16" title="16"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age (Months)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Weight (kg)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm-pred"></span>
<img src="bookdown_files/figure-html/age-wt-lm-pred-1.png" alt="Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range" width="80%" />
<p class="caption">
圖 27.3: Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range
</p>
</div>
</div>
</div>
<div id="rsquare" class="section level2">
<h2><span class="header-section-number">27.5</span> 線性迴歸模型和 Pearson 相關係數</h2>
<p>前面也推導過線性迴歸係數和 Pearson 相關係數之間的關係 (Section <a href="04-Linear-Regression.html#randbeta">27.2.1</a>)，這裏詳細再展開討論它們之間關係的另外兩個重要結論。</p>
<div id="r2-可以理解爲因變量平方和被模型解釋的比例" class="section level3">
<h3><span class="header-section-number">27.5.1</span> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</h3>
<p>Pearson 相關係數，因變量的平方和，模型的殘差平方和之間有如下的關係：</p>
<p><span class="math display" id="eq:rSSyySSres">\[
\begin{equation}
r^2 = \frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1-\frac{SS_{RES}}{SS_{yy}}
\end{equation}
\tag{27.13}
\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\frac{SS_{RES}}{SS_{yy}} = \frac{\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\]</span></p>
<p>因爲 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> : <span class="math inline">\(\hat\alpha=\bar{y}-\hat{\beta}\bar{x}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= \frac{\sum_{i=1}^n[(y_i-\bar{y})-\hat\beta(x_i-\bar{x})]^2}{\sum_{i=1}^n(y_i-\bar{y})^2} \\
                  &amp;=\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}-\frac{2\hat\beta\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(y_i-\bar{y})^2}+\frac{\hat\beta^2\sum_{i=1}^n(x_i-\bar{x})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}\\
                  &amp;=1-\frac{2\hat\beta S_{xy}}{SS_{yy}} + \frac{\hat\beta^2SS_{xx}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>又因爲 <span class="math inline">\(\hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{S_{xy}}{SS_{xx}}, r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= 1-\frac{2S_{xy}^2}{SS_{yy}SS_{xx}}+\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\
&amp;=1-2r^2+r^2\\
&amp;=1-r^2\\
\Rightarrow r^2&amp;=1-\frac{SS_{RES}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>因此，這裏就引出了非常重要的一個結論，<strong>Pearson 相關係數的平方 <span class="math inline">\(r^2\)</span> 的統計學含義是，因變量的平方和 <span class="math inline">\(SS_{yy}\)</span> 中，模型的預測變量能夠解釋的部分 <span class="math inline">\(1-SS_{RES}\)</span> 的百分比。</strong> 統計學結果的報告中，爲了和一般相關係數的意義區分，會用大寫的 <span class="math inline">\(R^2\)</span> 來表示這個模型解釋了因變量的百分比。(Section <a href="04-Linear-Regression.html#Rsquare">28.2.3</a>)</p>
</div>
</div>
<div id="t-r2-F" class="section level2">
<h2><span class="header-section-number">27.6</span> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</h2>
<p><span class="math display" id="eq:t-r2">\[
\begin{equation}
t=r\sqrt{\frac{n-2}{1-r^2}}
\end{equation}
\tag{27.14}
\]</span></p>
<p><strong>證明</strong></p>
<p>由於前面推導的 <span class="math inline">\(r^2\)</span> 公式 <a href="04-Linear-Regression.html#eq:rSSyySSres">(27.13)</a>，而且 <span class="math inline">\(r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{\frac{S_{xy}^2}{SS_{xx}SS_{yy}}}{\frac{SS_{RES}}{SS_{yy}}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}SS_{RES}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}(n-2)\hat\sigma^2}
\end{aligned}
\]</span></p>
<p>由於公式 <a href="04-Linear-Regression.html#eq:varhatbeta">(27.5)</a>，所以 <span class="math inline">\(\hat\sigma^2=V(\hat\beta)SS_{xx}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{S_{xy}^2}{SS^2_{xx}(n-2)V(\hat\beta)} \\
                  &amp; = \frac{\hat\beta^2}{(n-2)V(\hat\beta)} \\
\Rightarrow t=r\sqrt{\frac{n-2}{1-r^2}}
\end{aligned}
\]</span></p>
<p>這個結論也被用於相關係數的假設檢驗。而且也正如 Section <a href="04-Linear-Regression.html#randbeta">27.2.1</a> 證明過的那樣，在簡單線性迴歸裏因變量和預測變量的位置對調以後，對於回顧係數是否爲零的檢驗統計量不受影響。</p>
</div>
<div id="練習-2" class="section level2">
<h2><span class="header-section-number">27.7</span> 練習</h2>
<p>數據同前一章練習部分數據相同 <a href="04-Linear-Regression.html#exeChol">26.8</a>：</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1"><span class="co"># 數據讀入</span></a>
<a class="sourceLine" id="cb122-2" title="2">Chol &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/chol.dta&quot;</span>)</a>
<a class="sourceLine" id="cb122-3" title="3">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol)</a>
<a class="sourceLine" id="cb122-4" title="4"><span class="kw">print</span>(<span class="kw">summary</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chol2 ~ chol1, data = Chol)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -56.87654 -22.06181   1.84937  16.63107  84.11839 
## 
## Coefficients:
##                Estimate  Std. Error t value   Pr(&gt;|t|)    
## (Intercept) 110.4246582  20.0113279 5.51811 2.8499e-07 ***
## chol1         0.5786806   0.0747598 7.74053 9.5114e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.16 on 97 degrees of freedom
## Multiple R-squared:  0.381834,   Adjusted R-squared:  0.375462 
## F-statistic: 59.9159 on 1 and 97 DF,  p-value: 9.51139e-12</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: chol2
##           Df  Sum Sq Mean Sq F value     Pr(&gt;F)    
## chol1      1 54511.7 54511.7 59.9159 9.5114e-12 ***
## Residuals 97 88250.9   909.8                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1"><span class="co"># 計算截距和迴歸係數的 P 值 HAND CALCULATIONS twosided p-value in R can be obtained by pt(t, df) function</span></a>
<a class="sourceLine" id="cb126-2" title="2"></a>
<a class="sourceLine" id="cb126-3" title="3"><span class="co">## p value for intercept:</span></a>
<a class="sourceLine" id="cb126-4" title="4"></a>
<a class="sourceLine" id="cb126-5" title="5"><span class="fl">110.42466</span><span class="op">/</span><span class="fl">20.01133</span> <span class="co">#=5.518107</span></a></code></pre></div>
<pre><code>## [1] 5.518</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">5.518107</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 2.85e-07</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="co">## p value for beta:</span></a>
<a class="sourceLine" id="cb130-2" title="2"></a>
<a class="sourceLine" id="cb130-3" title="3"><span class="fl">0.57868</span><span class="op">/</span><span class="fl">0.07476</span> <span class="co">#= 7.740503</span></a></code></pre></div>
<pre><code>## [1] 7.741</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">7.740503</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 9.513e-12</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" title="1"><span class="co"># add fitted regression lines 95% CIs and reference range</span></a>
<a class="sourceLine" id="cb134-2" title="2">temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a>
<a class="sourceLine" id="cb134-3" title="3"></a>
<a class="sourceLine" id="cb134-4" title="4">new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(Chol, temp_var)</a>
<a class="sourceLine" id="cb134-5" title="5"></a>
<a class="sourceLine" id="cb134-6" title="6"><span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb134-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">TRUE</span>, <span class="dt">size=</span><span class="fl">0.5</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb134-8" title="8"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb134-9" title="9"><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb134-10" title="10"><span class="st">   </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb134-11" title="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb134-12" title="12"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>圖中可見，95% 置信帶變化顯著，距離均值越遠的地方，置信帶越寬。然而預測帶基本是平行的沒有變化。因爲預測帶的涵義是，95%的觀察數據都在這個區間範圍內。</p>
</div>
</div>
<div id="ANOVA" class="section level1">
<h1><span class="header-section-number">第 28 章</span> 方差分析 Introduction to Analysis of Variance</h1>
<div id="背景" class="section level2">
<h2><span class="header-section-number">28.1</span> 背景</h2>
<p>當我們用統計模型模擬真實數據的時候，我們常常會被問到這樣的問題：“兩個模型哪個能更好的擬合這個數據？”</p>
<p>本章我們先考慮簡單的情況，兩個模型互相比較時，其中一個稍微簡單些的模型使用的預測變量，同時也是另一個較複雜的模型的預測變量 (nested models)。所以，複雜模型的預測變量較多，而其中一個或者幾個預測變量又構成了新的較爲簡單的模型。這兩個模型之間的比較，就需要用到方差分析 Analysis of Variance (ANOVA)。</p>
<p>此處方差分析的原則是：如果複雜模型能夠更好的擬合真實實驗數據，那我們會認爲簡單模型無法解釋的大量殘差平方和，有效地被複雜模型解釋了。所以，這一原則下，可以推理，複雜模型計算獲得的殘差平方和，會顯著地小於簡單模型計算獲得的殘差平方和。ANOVA 就提供了這個殘差平方和變化的定量比較方法。</p>
</div>
<div id="簡單線性迴歸模型的方差分析" class="section level2">
<h2><span class="header-section-number">28.2</span> 簡單線性迴歸模型的方差分析</h2>
<p>其實從線性迴歸的第一章節開始，我們都在使用方差分析的思想。圖 <a href="04-Linear-Regression.html#fig:age-wt">26.1</a> 數據的迴歸模型中，我們其實比較了以下兩個模型：</p>
<ol style="list-style-type: decimal">
<li>零假設模型：null model, 即認爲年齡和體重之間沒有任何關係 (水平直線)；</li>
<li>替代模型： alternative model, 認爲年齡和體重之間有一定的線性關係 (擬合後的直線)。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm-anova"></span>
<img src="bookdown_files/figure-html/age-wt-lm-anova-1.png" alt="NULL (red) and Alternative models (blue) for the data" width="80%" />
<p class="caption">
圖 28.1: NULL (red) and Alternative models (blue) for the data
</p>
</div>
<div id="兩個模型的參數估計" class="section level3">
<h3><span class="header-section-number">28.2.1</span> 兩個模型的參數估計</h3>
<p>無論是零假設模型，還是替代假設模型，都需要通過最小化殘差來獲得其參數估計：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n \hat\varepsilon^2= \sum_{i=1}^n(y_i-\hat y_i)^2
\]</span></p>
<p>替代假設模型，在線性迴歸第一部分 (Section <a href="04-Linear-Regression.html#meanfunction">26.3.1</a>) 已經提到過，均值方程是 <span class="math inline">\(E(Y|X=x) = \alpha+\beta x\)</span>，且這個方程的參數 <span class="math inline">\(\alpha, \beta\)</span> 以及殘差方差 <span class="math inline">\(\sigma^2\)</span> 的估計值計算公式也已經推導完成 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> <a href="04-Linear-Regression.html#eq:hatbeta">(26.6)</a> <a href="04-Linear-Regression.html#eq:sigma2right">(26.9)</a>。</p>
<p>零假設模型，它的均值方程是 <span class="math inline">\(E(Y|X=x)=\alpha\)</span>。所以需要將它的殘差最小化：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n(y_i-\hat\alpha)^2
\]</span></p>
<p>由於 <a href="04-Linear-Regression.html#eq:hatalpha">(26.5)</a> ：<span class="math inline">\(\hat\alpha=\bar{y}-\hat\beta\)</span>，所以 <span class="math inline">\(\hat\alpha = \bar{y}\)</span>。</p>
<p>所以對於零假設模型來說：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n(y_i-\bar{y})^2 =SS_{yy}
\]</span></p>
<p>因此，沒有預測變量的零假設模型，它的殘差平方和，就等於因變量的平方和。</p>
</div>
<div id="分割零假設模型的殘差平方和" class="section level3">
<h3><span class="header-section-number">28.2.2</span> 分割零假設模型的殘差平方和</h3>
<p>ANOVA，方差分析的原則，其實就是將較簡單模型 (零假設模型) 的殘差平方和 <span class="math inline">\((SS_{RES_{NULL}})\)</span>，分割成下面兩個部分：</p>
<ol style="list-style-type: decimal">
<li>替代假設的複雜模型能夠說明的模型平方和 <span class="math inline">\((SS_{REG})\)</span>；</li>
<li>替代假設的複雜模型的殘差平方和 <span class="math inline">\((SS_{RES_{ALT}})\)</span>。</li>
</ol>
<p>用數學表達式表示爲：</p>
<p><span class="math display" id="eq:SSres-partition">\[
\begin{equation}
\sum_{i=1}^n(y_i-\bar{y})^2 = \sum_{i=1}^n(\hat{y}-\bar{y})^2 + \sum_{i=1}^n(y_i-\hat{y}_i)^2 \\
SS_{RES_{NULL}}(SS_{yy}) = SS_{REG} + SS_{RES_{ALT}}
\end{equation}
\tag{28.1}
\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^n(y_i-\bar{y})^2 &amp;= \sum_{i=1}^n[(\hat{y}-\bar{y})+(y_i-\hat{y})]^2\\
                            &amp;= \sum_{i=1}^n(\hat{y}-\bar{y})^2+\sum_{i=1}^n(y_i-\hat{y})^2+2\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y}) \\
                            &amp;= SS_{REG} + SS_{RES_{ALT}} + 2\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y})
\end{aligned}
\]</span></p>
<p>接下來就是要證明 <span class="math inline">\(\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y})=0\)</span></p>
<p>因爲公式 <a href="04-Linear-Regression.html#eq:lmcenter">(27.1)</a> <span class="math inline">\(\hat{y}_i=\bar{y}+\hat{\beta}(x_i-\bar{x})\)</span> 所以公式變形如下：</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y}) &amp;=  \sum_{i=1}^n(\bar{y}+\hat\beta(x_i-\bar{x})-\bar{y})(y_i-\bar{y}-\hat\beta(x_i-\bar{x})) \\
&amp;= \sum_{i=1}^n\hat\beta(x_i-\bar{x})[y_i-\bar{y}-\hat\beta(x_i-\bar{x})] \\
&amp;= \hat\beta\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) - \hat\beta^2\sum_{i=1}^n(x_i-\bar{x}) \\
&amp;= \frac{S_{xy}}{S_{xx}}S_{xy} - (\frac{S_{xy}}{S_{xx}})^2SS_{xx}\\
&amp;= 0 \\
\Rightarrow  SS_{RES_{NULL}}(SS_{yy}) &amp;= SS_{REG} + SS_{RES_{ALT}}
\end{aligned}
\]</span></p>
</div>
<div id="Rsquare" class="section level3">
<h3><span class="header-section-number">28.2.3</span> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</h3>
<p>在公式 <a href="04-Linear-Regression.html#eq:SSres-partition">(28.1)</a> 中，因變量的平方和被分割成了兩個部分：<span class="math inline">\(SS_{REG}\)</span> 迴歸模型能說明的部分，和 <span class="math inline">\(SS_{RES_{ALT}}\)</span> 迴歸模型的殘差平方和。所以，我們定義迴歸模型能說明的部分，佔因變量平方和的百分比 <span class="math inline">\(\frac{SS_{REG}}{SS_{yy}}\)</span>，爲決定係數 <span class="math inline">\(R^2\)</span>。</p>
<p>這個決定係數之前 (Section <a href="04-Linear-Regression.html#rsquare">27.5</a>) 也出現過：</p>
<p><span class="math display" id="eq:R-square">\[
\begin{equation}
R^2 = \frac{SS_{REG}}{SS_{yy}} = \frac{\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\end{equation}
\tag{28.2}
\]</span></p>
<p>再一次回到數據 (<a href="04-Linear-Regression.html#fig:age-wt">26.1</a>) 的線性迴歸來看：</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb135-2" title="2">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb135-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.924182 -0.784889  0.007099  0.797468  4.067806 
## 
## Coefficients:
##              Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept) 6.8375842  0.2100701 32.5491 &lt; 2.22e-16 ***
## age         0.1653314  0.0111115 14.8793 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.540782,   Adjusted R-squared:  0.53834 
## F-statistic: 221.392 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>R 輸出的結果中最下面的部分 <code>Multiple R-squared:  0.5408</code>。我們就可以用“人話”來解釋其意義：假定年齡和體重成直線關係，那麼年齡解釋了這組數據中兒童體重變化 (平方和) 的 54%。</p>
</div>
<div id="方差分析表格-the-anova-table" class="section level3">
<h3><span class="header-section-number">28.2.4</span> 方差分析表格 the ANOVA table</h3>
<p>一般情況下一個簡單線性迴歸，通過 ANOVA 對因變量平方和的分割，會被彙總成下面這樣的表格：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 28.1: Analysis of Variance table for a simple liear regression model
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Regression (model)
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{reg}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{reg} = \frac{SS_{reg}}{1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{res}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-2\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{res} = \frac{SS_{res}}{(n-2)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>表格中最右邊一列是平均平方和 (mean sum of squares)。它的定義是將平方和除以各自的自由度。其中殘差的平均平方和 <span class="math inline">\(MS_{RES}=\frac{SS_{RES}}{(n-2)}\)</span> 是替代模型下殘差方差的無偏估計。總體平均平方和 (total mean sum of squares)，則是零假設模型時的殘差方差估計。在 R 裏面也已經演示過多次 <code>anova(model)</code> 是調取方差分析表格的代碼：</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" title="1">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb137-2" title="2"><span class="kw">print</span>(<span class="kw">anova</span>(Model), <span class="dt">digit=</span><span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>注意到 R 省略掉第三行總體平方和的部分，不過其實也不太需要。檢驗統計量 F 的計算也很簡單，就是359.06320/1.62184=221.39。</p>
</div>
<div id="用-anova-進行假設檢驗" class="section level3">
<h3><span class="header-section-number">28.2.5</span> 用 ANOVA 進行假設檢驗</h3>
<p>在 ANOVA 中使用的檢驗手段是 <span class="math inline">\(F\)</span> 檢驗。這裏用 <span class="math inline">\(F\)</span> 檢驗來比較<strong>模型解釋的因變量平方和部分</strong> <span class="math inline">\((SS_{REG})\)</span> 和<strong>這個模型不能解釋的殘差平方和部分</strong> <span class="math inline">\(SS_{RES}\)</span> 經過自由度校正以後比值的大小。</p>
<p>此時我們需要知道零假設和替代假設 <span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span> 時，<span class="math inline">\(SS_{REG}, SS_{RES}\)</span> 的分佈。</p>
<ol style="list-style-type: decimal">
<li>零假設和替代假設時，<span class="math inline">\(SS_{RES}\)</span> 均服從自由度爲 <span class="math inline">\(n-2\)</span> 的卡方分佈：</li>
</ol>
<p><span class="math display" id="eq:distributionSSres">\[
\begin{equation}
\text{Because } SS_{RES} = \sum_{i=1}^n \varepsilon \sim N(0, \sigma^2)\\
\frac{SS_{RES}}{\sigma^2} \sim \chi^2_{n-2}
\end{equation}
\tag{28.3}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>零假設時， <span class="math inline">\(SS_{REG}\)</span> 服從自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈，且與 <span class="math inline">\(SS_{RES}\)</span> 相互獨立：</li>
</ol>
<p><span class="math display" id="eq:distributionSSreg">\[
\begin{equation}
\frac{SS_{REG}}{\sigma^2} \sim \chi^2_1
\end{equation}
\tag{28.4}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>替代假設時，<span class="math inline">\(SS_{REG}\)</span> 服從一個非中心化的卡方檢驗，且與 <span class="math inline">\(SS_{RES}\)</span> 相互獨立：</li>
</ol>
<p><span class="math display" id="eq:distributionSSregh1">\[
\begin{equation}
SS_{REG} = \beta^2 SS_{xx} + U \text{ where }\frac{U}{\sigma^2} \sim \chi_1^2
\end{equation}
\tag{28.5}
\]</span></p>
</div>
<div id="lm-Ftest" class="section level3">
<h3><span class="header-section-number">28.2.6</span> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</h3>
<p>如果兩個隨機變量各自服從相應自由度的卡方分佈，他們的每個元素的比值服從 <span class="math inline">\(F\)</span> 分佈：</p>
<p><span class="math display">\[
A\sim \chi_a^2 \text{ and } B\sim \chi_b^2\\
\Rightarrow \frac{A/a}{B/b} \sim F_{a,b}
\]</span></p>
<p>因此，目前爲止的推導過程我們也可以看到，在零假設條件下，<span class="math inline">\(MS_{REG}\)</span> 和 <span class="math inline">\(MS_{RES}\)</span> 的比值會服從 <span class="math inline">\(F\)</span> 分佈，自由度爲 <span class="math inline">\((1, n-2)\)</span>：</p>
<p><span class="math display" id="eq:Fdistri">\[
\begin{equation}
F=\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \frac{MS_{REG}}{MS_{RES}} \sim F_{1,n-2}
\end{equation}
\tag{28.6}
\]</span></p>
<p>在替代假設條件下 <span class="math inline">\((\text{H}_1: \beta\neq0)\)</span>，<span class="math inline">\(SS_{REG}\)</span> 的期望值是 <span class="math inline">\(\sigma^2+\beta^2SS_{xx}\)</span>，所以替代假設條件下的 <span class="math inline">\(F\)</span> 檢驗量總是會大於零假設時的 <span class="math inline">\(F\)</span>。因此你可以看到，這是一個雙側檢驗 (<span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span>)，但是由於替代假設的 <span class="math inline">\(F\)</span> 總是較大，所以只需要 <span class="math inline">\(F\)</span> 的右半部分的概率密度積分 (單側 <span class="math inline">\(p\)</span> 值)。</p>
</div>
<div id="F-t-same" class="section level3">
<h3><span class="header-section-number">28.2.7</span> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</h3>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;F=\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \frac{SS_{REG}}{(SS_{yy}-SS_{REG})/(n-2)} \\
&amp;\text{Since } r^2 = \frac{SS_{REG}}{SS_{yy}} \\
&amp;F=(n-2)\frac{SS_{yy}r^2}{SS_{yy}-SS_{yy}r^2}=(n-2)(\frac{r^2}{1-r^2})=t^2
\end{aligned}
\]</span></p>
<p>最後一步用到 (Section <a href="04-Linear-Regression.html#t-r2-F">27.6</a>) 證明過的，迴歸係數檢驗統計量 <span class="math inline">\(t\)</span>，和 Pearson 相關係數 <span class="math inline">\(r\)</span> 之間的關係。</p>
</div>
</div>
<div id="分類變量用作預測變量時的-anova" class="section level2">
<h2><span class="header-section-number">28.3</span> 分類變量用作預測變量時的 ANOVA</h2>
<p>方差分析的應用是如此的廣泛，你可以在多重迴歸中使用，也可以在模型中有分類變量時使用，甚至是同時有連續性變量和分類變量的迴歸模型中得到應用。</p>
<p>之前也遇到過二分類變量的簡單線性迴歸模型，當時我們的做法是使用一個啞變量來表示一個二分類變量。同樣的方法也可以用到多組分類變量上來，然後繼續使用線性迴歸。</p>
<div id="一個二分類預測變量" class="section level3">
<h3><span class="header-section-number">28.3.1</span> 一個二分類預測變量</h3>
<p>在前面的例子 (Section <a href="04-Linear-Regression.html#binarylms">26.7</a>) 中也已經展示過，可以通過線性迴歸來分析一個二分類變量 (實驗組對照組)，和一個連續型變量 (能直立行走時的兒童年齡)兩個變量之間的關係。而且其結果同兩樣本 <span class="math inline">\(t\)</span> 檢驗的結果完全一致。</p>
<p>繼續回到之前用過的這個兒童行走數據 (表 <a href="04-Linear-Regression.html#tab:walk">26.1</a>)：</p>
<pre><code>## 
## Call:
## lm(formula = Age ~ Group, data = Walk)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1250 -0.7375 -0.3750  0.3875  2.8750 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  10.12500    0.51223 19.7663 1.007e-08 ***
## Groupcontrol  2.22500    0.75977  2.9285    0.0168 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.255 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.48795,    Adjusted R-squared:  0.43105 
## F-statistic: 8.5763 on 1 and 9 DF,  p-value: 0.016797</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Age
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Group      1 13.502 13.5017  8.5763 0.0168 *
## Residuals  9 14.169  1.5743                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>之前分析這個數據的時候也說明過了，這裏的迴歸係數 <span class="math inline">\(2.225\)</span> 的含義是兩組之間均值的差異。而且注意看，這個迴歸係數是否爲零的檢驗統計量<span class="math inline">\((t-test)\)</span>獲得的 <span class="math inline">\(p\)</span> 值和 ANOVA 的檢驗結果 <span class="math inline">\((F-test)\)</span> 也是一致的。正驗證了我們前面證明的結果。(Section <a href="04-Linear-Regression.html#F-t-same">28.2.7</a>)</p>
</div>
<div id="一個模型兩種表述" class="section level3">
<h3><span class="header-section-number">28.3.2</span> 一個模型，兩種表述</h3>
<p>上面這個例子中，一個二分類的預測變量和一個因變量之間的關係，實際上可以用兩種數學模型來表達：</p>
<ol style="list-style-type: decimal">
<li>令 <span class="math inline">\(y_i, x_i\)</span> 分別是第 <span class="math inline">\(i\)</span> 名觀察對象的因變量 (“直立行走的年齡”)，和預測變量 (“實驗組或者對照組”) <span class="math inline">\((i=1,\cdots,n)\)</span>。那麼<strong>迴歸模型</strong>可以寫作：</li>
</ol>
<p><span class="math display" id="eq:regremodel">\[
\begin{equation}
y_i = \alpha+\beta x_i + \varepsilon_i, \text{ where } \varepsilon_i \sim NID(0, \sigma^2)
\end{equation}
\tag{28.7}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(x_i=0\)</span> 時，表示第 <span class="math inline">\(i\)</span> 名觀察對象在實驗組；</li>
<li><span class="math inline">\(x_i=1\)</span> 時，表示第 <span class="math inline">\(i\)</span> 名觀察對象在對照組。</li>
</ul>
<p>在這樣的迴歸模型標記下，零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>另一種模型的表達方式，被叫做 ANOVA 表達方式。是如此描述上面的關係的：令 <span class="math inline">\(y_{ki}\)</span> 表示第 <span class="math inline">\(i\)</span> 名觀察對象，他在第 <span class="math inline">\(k\)</span> 組 <span class="math inline">\((i=1,\cdots, n_k; k=1,2)\)</span>，此時的模型被寫作：</li>
</ol>
<p><span class="math display" id="eq:anovamodel">\[
\begin{equation}
y_{ki} = \mu_k + \varepsilon_{ki}, \text{ where } \varepsilon_{ki} \sim NID(0, \sigma^2)
\end{equation}
\tag{28.8}
\]</span></p>
<p>此時，<span class="math inline">\(\mu_k\)</span> 表示第 <span class="math inline">\(k\)</span> 組因變量的均值。零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \mu_k=\mu \text{ v.s. H}_1: \mu_k\neq\mu\)</span>。這裏的 <span class="math inline">\(\mu\)</span> 表示，每個組的平均值等於一個共同的均值 <span class="math inline">\(\mu\)</span>。</p>
</div>
<div id="分組變量的平方和" class="section level3">
<h3><span class="header-section-number">28.3.3</span> 分組變量的平方和</h3>
<p>對於預測變量只有一個分組變量的模型，擬合後的數值就是兩組的因變量均值 <span class="math inline">\((\bar{y}_k)\)</span>。在零假設條件下，兩組均值相等，均等於總體均值 <span class="math inline">\(\bar{y}\)</span>。這就導致了，殘差平方和，模型平方和在分組變量的 ANOVA 分析時要使用與連續型變量不同的術語。</p>
<ul>
<li>殘差平方和表示爲：</li>
</ul>
<p><span class="math display" id="eq:withingroupSS">\[
\begin{equation}
SS_{RES} = \sum_{k=1}^k\sum_{i=1}^{n_k} (y_{ki}-\bar{y}_k)^2
\end{equation}
\tag{28.9}
\]</span></p>
<p>其實這就是<strong>組內平方和</strong> (within group sum of squares)。</p>
<ul>
<li>模型平方和表示爲：</li>
</ul>
<p><span class="math display" id="eq:betweengroupSS">\[
\begin{equation}
SS_{REG} = \sum_{k=1}^k\sum_{i=1}^{n_k}(\bar{y}_k-\bar{y})^2=\sum_{k=1}^kn_k(\bar{y}_k-\bar{y})^2
\end{equation}
\tag{28.10}
\]</span></p>
<p>其實這就是<strong>組間平方和</strong> (between group sum of squares)</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" title="1">Mdl0 &lt;-<span class="st"> </span><span class="kw">aov</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data =</span> Walk) <span class="co"># fit a one-way ANOVA</span></a>
<a class="sourceLine" id="cb141-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Mdl0), <span class="dt">digits =</span> <span class="dv">6</span>)</a></code></pre></div>
<pre><code>##             Df  Sum Sq  Mean Sq F value   Pr(&gt;F)  
## Group        1 13.5017 13.50170 8.57629 0.016797 *
## Residuals    9 14.1687  1.57431                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 1 observation deleted due to missingness</code></pre>
<p>其實這跟之前的 <code>anova(Model)</code> 給出的結果完全一致。</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" title="1"><span class="kw">bartlett.test</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>Walk)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Age by Group
## Bartlett&#39;s K-squared = 0.63, df = 1, p-value = 0.4</code></pre>
<p>FYI. 上面的代碼 <code>bartlett.test()</code> 利用的是另外一個叫做 Bartlett 檢驗法的方差比較公式。(在 STATA 的 <code>oneway</code> 命令中也會默認給出 Bartlett 檢驗的方差是否一致的檢驗結果)</p>
</div>
<div id="簡單模型的分組變量大於兩組的情況" class="section level3">
<h3><span class="header-section-number">28.3.4</span> 簡單模型的分組變量大於兩組的情況</h3>
<p>公式 <a href="04-Linear-Regression.html#eq:anovamodel">(28.8)</a>, <a href="04-Linear-Regression.html#eq:withingroupSS">(28.9)</a>, 和 <a href="04-Linear-Regression.html#eq:betweengroupSS">(28.10)</a> 在兩組以上分組變量作預測變量時也是適用的。但是當組數爲 <span class="math inline">\(K\)</span> 時，組內平方和 (殘差平方和 <span class="math inline">\(SS_{RES}\)</span>) 的自由度需要修改成 <span class="math inline">\(n-K\)</span> (這是因爲模型中使用了 <span class="math inline">\(K\)</span> 個參數)。此時方差分析 ANOVA 的彙總表格就變爲了下面這樣：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 28.2: One-way ANOVA table
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br> variation
</th>
<th style="text-align:center;">
Sum of <br> Squares
</th>
<th style="text-align:center;">
Degrees of <br> Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br> Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Between groups
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{between}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(K-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{between}}{(K-1)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Within groups
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{within}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-K\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{within}}{(n-K)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>此時，檢驗統計量 <span class="math inline">\(F\)</span> 的計算公式爲：</p>
<p><span class="math display" id="eq:F1way-anova">\[
\begin{equation}
F=\frac{SS_{between}/(K-1)}{SS_{within}/(n-K)} \sim F_{(K-1),(n-K)}
\end{equation}
\tag{28.11}
\]</span></p>
<p>在解釋兩組以上分組變量的分析結果時，要注意的是如果 <span class="math inline">\(p\)</span> 值很小，檢驗結果告訴我們的是，各組中因變量的均值<strong>不全相等</strong>，而<strong>不是全部都不相等</strong>。其實就是，即使做了這個檢驗，我們也不知道到底那兩組之間是有差異的。如果此時我們發現結果提示均值不全相等，通常我們還會再作進一步的分析，使用類似成對比較法等等 (以後再繼續詳述)。不過提前要記住，如果使用成對比較法時 (pair-wise comparisons)，<strong>多重比較的問題 (multiple comparisons)</strong>會凸顯出來，主要的結果是增加統計檢驗的假陽性 (false-positive) 概率，此時再繼續使用 <span class="math inline">\(p&lt;0.05\)</span> 作爲統計學意義的標準則是不妥當的。</p>
</div>
</div>
</div>
<div id="多元模型分析-multivariable-models" class="section level1">
<h1><span class="header-section-number">第 29 章</span> 多元模型分析 Multivariable Models</h1>
<p>簡單線性迴歸描述的是一個連續型的因變量 <span class="math inline">\((y)\)</span>，和一個單一的預測變量 <span class="math inline">\((x)\)</span> 之間的關係。我們考慮把這個模型擴展成包含多個預測變量，單一因變量的模型。例如，我們可以考慮建立一個模型使用生活習慣 (包括“年齡，性別，運動，飲食習慣等”) 來預測收縮期血壓。此時多重迴歸的思想就可以幫我們理解一些我們<strong>更加關心的因子</strong>，與因變量之間的關係，同時控制或者叫調整了其他的<strong>混雜因子</strong> (control or adjust confounders)。有時候這樣的模型也可以直接應用到生活中去，比如上面的例子，我們可以通過瞭解一個人的生活習慣，用建立好的模型來估計這個人的收縮期血壓。</p>
<p>建立模型之前，必須明確研究的目的是什麼。例如我們關心一個<strong>新發現的因子</strong>可能與高血壓有關係，那麼模型中我們放進去調整的其他因子 (如年齡，性別，運動) 等和因變量 (血壓) 之間的關係就變得不那麼重要。</p>
<p>多重線性迴歸，或者叫多元模型分析 (multiple linear regression or multivariable linear regression) 是研究一個連續型因變量和多個預測變量之間關係的重要模型。本章還會着重討論<strong>混雜 (confounding)</strong>的概念。</p>
<div id="兩個預測變量的線性迴歸模型" class="section level2">
<h2><span class="header-section-number">29.1</span> 兩個預測變量的線性迴歸模型</h2>
<div id="數學標記法和解釋" class="section level3">
<h3><span class="header-section-number">29.1.1</span> 數學標記法和解釋</h3>
<p>這裏假設我們研究一個因變量 <span class="math inline">\(Y\)</span>，和兩個預測變量 <span class="math inline">\((X_1,X_2)\)</span> 的模型。那麼此時兩個預測變量的線性迴歸模型可以記爲：</p>
<p><span class="math display" id="eq:2varmultilm">\[
\begin{equation}
y_i = \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \varepsilon_i, \text{ where } \varepsilon_i \sim \text {NID}(0, \sigma^2)
\end{equation}
\tag{29.1}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(y_i\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的因變量數據 (例如體重)；
<ul>
<li><span class="math inline">\(x_{1i}\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的第一個預測變量數據 (例如年齡)， <span class="math inline">\(X_1\)</span>；</li>
<li><span class="math inline">\(x_{2i}\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的第二個預測變量數據 (例如身高)， <span class="math inline">\(X_1\)</span>；</li>
<li><span class="math inline">\(\alpha\)</span> 的涵義是，當兩個預測變量均爲 <span class="math inline">\(0\)</span> 時，因變量的期望值；</li>
<li><span class="math inline">\(\beta_1\)</span> 的涵義是，當 <span class="math inline">\(X_2\)</span> 不變時，<span class="math inline">\(X_1\)</span> 每升高一個單位，因變量的期望值；</li>
<li><span class="math inline">\(\beta_2\)</span> 的涵義是，當 <span class="math inline">\(X_1\)</span> 不變時，<span class="math inline">\(X_2\)</span> 每升高一個單位，因變量的期望值。</li>
</ul></li>
</ul>
<p><span class="math inline">\(\beta_1, \beta_2\)</span> 叫做偏迴歸係數 (partial regression coefficient)。它們測量的是兩個預測變量中，當一個被控制 (保持不變) 時，另一個對因變量的影響。</p>
<p>這個模型也可以用矩陣的形式來表示：</p>
<p><span class="math display" id="eq:matrixlm">\[
\begin{equation}
\textbf{Y} = \textbf{X}\beta+\varepsilon, \text{ where } \varepsilon \sim N(0, \textbf{I}\sigma^2) \\
\left(
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array}
\right) = \left(
\begin{array}{c}
1&amp;  x_{11} &amp; x_{21}  \\
1&amp;  x_{12} &amp; x_{22} \\
\vdots &amp;   \vdots&amp; \vdots \\
1&amp;   x_{1n}&amp; x_{2n} \\
\end{array}
\right)\left(
\begin{array}{c}
\alpha \\
\beta_1\\
\beta_2
\end{array}
\right)+\left(
\begin{array}{c}
\varepsilon_1\\
\varepsilon_2\\
\vdots\\
\varepsilon_n\\
\end{array}
\right)
\end{equation}
\tag{29.2}
\]</span></p>
<p>此時上面的表達式中，<span class="math inline">\(\textbf{X}\)</span> 是一個矩陣，<span class="math inline">\(\textbf{Y, \beta, \varepsilon}\)</span> 均為向量。殘差被認為服從多變量正態分佈 <strong>(Multivariate normal distribution)</strong> ，這個多變量正態分佈的協方差矩陣為 <span class="math inline">\(\sigma^2\)</span> 和單位矩陣 <span class="math inline">\(\textbf{I}\)</span> 的乘積來描述。這等價於假設殘差是獨立同分佈且方差 <span class="math inline">\(\sigma^2\)</span> 不變。</p>
</div>
<div id="最小平方和估計-least-squares-estimation" class="section level3">
<h3><span class="header-section-number">29.1.2</span> 最小平方和估計 Least Squares Estimation</h3>
<p>跟簡單線性回歸相似地，我們需要通過對殘差平方和最小化，來獲得此時多重線性回歸的各項參數估計：</p>
<p><span class="math display" id="eq:se">\[
\begin{equation}
SS_{RES} = \sum_{i=1}^n \hat\varepsilon_{i}^2 = \sum_{i=1}^n(y_i-\hat{y})^2=\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i})^2
\end{equation}
\tag{29.3}
\]</span></p>
<p>求能讓這個殘差平方和取最小值的參數估計 <span class="math inline">\(\hat\alpha,\hat\beta_1,\hat\beta_2\)</span> 我們會在下一章用矩陣標記法來解釋。此處要強調的是，這些估計量都是無偏估計量，且可以被證明的是殘差方差可以用下面的式子來定義：</p>
<p><span class="math display" id="eq:multivar">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n\frac{\hat\varepsilon_i^2}{(n-3)}=\frac{\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i})^2}{(n-3)}
\end{equation}
\tag{29.4}
\]</span></p>
</div>
</div>
<div id="線性回歸模型中使用分組變量" class="section level2">
<h2><span class="header-section-number">29.2</span> 線性回歸模型中使用分組變量</h2>
<p>之前我們已展示過，分組變量可以使用啞變量來表示。分組變量多於兩組時，可用多個啞變量來同時表示。現在假設變量 <span class="math inline">\(X\)</span> 有三個分組分別用 <span class="math inline">\(1,2,3\)</span> 來表示。那麼用啞變量來描述含有這個分組變量的數學方法可以標記為：</p>
<p><span class="math display" id="eq:dummy3">\[
\begin{equation}
y_i  = \alpha+\beta_1u_{1i}+\beta_2u_{2i}+\varepsilon_i, \text{ where } \varepsilon_i \sim \text{NID} (0,\sigma^2)
\end{equation}
\tag{29.5}
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
\begin{aligned}
u_{1i}=\left\{
 \begin{array}{ll}
 1 \text{ if } x_i=2 \\
 0 \text{ if } x_i\neq2 \\
 \end{array}
\right. ;
u_{2i}=\left\{
 \begin{array}{ll}
 1 \text{ if } x_i=3 \\
 0 \text{ if } x_i\neq3 \\
 \end{array}
\right.
\end{aligned}
\]</span></p>
<p>其實如果你願意，你也可以把公式 <a href="04-Linear-Regression.html#eq:dummy3">(29.5)</a> 寫成下面這樣：</p>
<p><span class="math display">\[
\begin{aligned}
\begin{array}{ll}
y_i = \alpha + \varepsilon_i   &amp; \text{if }  x_i=1 \\
y_i = \alpha +\beta_1+ \varepsilon_i   &amp; \text{if }  x_i=2 \\
y_i = \alpha +\beta_2+ \varepsilon_i   &amp; \text{if }  x_i=3 \\
\end{array}
\end{aligned}
\]</span>
所以，</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(X=1\)</span> 時因變量的期待值；</li>
<li><span class="math inline">\(\alpha+\beta_1\)</span> 是 <span class="math inline">\(X=2\)</span> 時因變量的期待值，所以 <span class="math inline">\(\beta_1\)</span> 是分組變量 <span class="math inline">\(X\)</span> 前兩組之間因變量的期待值的差；</li>
<li><span class="math inline">\(\alpha+\beta_2\)</span> 是 <span class="math inline">\(X=3\)</span> 時因變量的期待值，所以 <span class="math inline">\(\beta_2\)</span> 是分組變量 <span class="math inline">\(X\)</span> 前兩組之間因變量的期待值的差。</li>
</ul>
<p>此時的 <span class="math inline">\(X=1\)</span> 這個組通常被當作是分組變量中的基準組，也就是參照組 (reference group)。實際情況下你可能可以改變這個參照組為其他組的任意一個。</p>
</div>
<div id="協方差分析模型-the-analysis-of-covariance-ancova-model" class="section level2">
<h2><span class="header-section-number">29.3</span> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</h2>
<p>協方差分析模型用來分析一個連續型的因變量 <span class="math inline">\(Y\)</span> ，與一個連續型的預測變量 <span class="math inline">\((X_1)\)</span>和一個二分類的預測變量 <span class="math inline">\((X_2= 1,2)\)</span>，模型被標記為：</p>
<p><span class="math display" id="eq:ancova">\[
\begin{equation}
y_i=\alpha+\beta_1x_{1i}+\beta_2u_{2i}+\varepsilon_i, \text{ where } \varepsilon_i \sim \text{NID}(0,\sigma^2)
\end{equation}
\tag{29.6}
\]</span>
其中，</p>
<ul>
<li><span class="math inline">\(y_{i}\)</span> 為第 <span class="math inline">\(i\)</span> 名研究對象的因變量數據 (連續型)；</li>
<li><span class="math inline">\(x_{1i}\)</span> 為第 <span class="math inline">\(i\)</span> 名研究對象的第一個預測變量 (也是連續型)；</li>
<li><span class="math inline">\(u_i =\left\{ \begin{array}{ll} 1 \text{ if } x_{2i}=2 \\ 0 \text{ if } x_{2i}=1 \\ \end{array}\right.\)</span></li>
</ul>
<p>此模型中用到的參數有：</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距，意為當 <span class="math inline">\(X_1=0\)</span> 且 <span class="math inline">\(X_2=1 \; (u=0)\)</span> 時的因變量期待值；</li>
<li><span class="math inline">\(\beta_1\)</span> 是當 <span class="math inline">\(X_2\)</span> 保持不變時，<span class="math inline">\(X_1\)</span> 每升高一個單位時，因變量 <span class="math inline">\(Y\)</span> 的期待值；</li>
<li><span class="math inline">\(\beta_2\)</span> 是當 <span class="math inline">\(X_1\)</span> 保持不變時，分組變量 <span class="math inline">\(X_2\)</span> 的兩組之間因變量 <span class="math inline">\(Y\)</span> 的期待值差異大小。</li>
</ul>
<p>所以理解了上面的解釋之後，就可以將表達式 <a href="04-Linear-Regression.html#eq:ancova">(29.6)</a> 描述為：</p>
<p><span class="math display">\[
\begin{array}{ll}
y_i=\alpha+\beta_1x_{1i}+\varepsilon_i &amp; \text{ if } x_{2i}=1 \\
y_i=\alpha+\beta_2+\beta_1x_{1i}+\varepsilon_i &amp; \text{ if } x_{2i} = 2
\end{array}
\]</span></p>
<p>所以，在一個二維圖形中繪製這兩條回歸直線，你會發現他們之間是<strong>平行的</strong>。因為他們之間相差的只有截距，決定直線斜率的回歸係數，都是 <span class="math inline">\(\beta_1\)</span>。再用之前用過的數據，兒童的體重和年齡，如果此時考慮了性別因素的話，多重線性回歸的輸出結果和圖形分別應該是：</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb145-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb145-3" title="3"></a>
<a class="sourceLine" id="cb145-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb145-5" title="5"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + sex, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -4.19236 -0.76268 -0.00696  0.75675  3.79163 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  7.152414   0.234254 30.5327 &lt; 2.2e-16 ***
## age          0.163998   0.010919 15.0189 &lt; 2.2e-16 ***
## sex2        -0.518854   0.183053 -2.8344  0.005095 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.25 on 187 degrees of freedom
## Multiple R-squared:  0.5597, Adjusted R-squared:  0.55499 
## F-statistic: 118.85 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
## age         1 359.06  359.06 229.6755 &lt; 2.2e-16 ***
## sex         1  12.56   12.56   8.0341  0.005095 ** 
## Residuals 187 292.35    1.56                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:age-wt-mlm"></span>
<img src="bookdown_files/figure-html/age-wt-mlm-1.png" alt="Data and fitted values from a regression model relating age and gender to data from a cross-sectional survey. For male children data points shown as circles and fitted values linked by a solid line. For female children data points shown as triangles and fitted values linked by a dashed line." width="80%" />
<p class="caption">
圖 29.1: Data and fitted values from a regression model relating age and gender to data from a cross-sectional survey. For male children data points shown as circles and fitted values linked by a solid line. For female children data points shown as triangles and fitted values linked by a dashed line.
</p>
</div>
</div>
<div id="偏回歸係數的變化" class="section level2">
<h2><span class="header-section-number">29.4</span> 偏回歸係數的變化</h2>
<p>在增加不同的預測變量進入線性回歸模型中時，原先在方程中的預測變量的偏回歸係數發生了怎樣的變化？</p>
<p>我們先從最簡單的開始入手。先只考慮一個簡單先行回歸模型的情況。當我們新加入一個預測變量，模型發生了什麼變化？</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Model 1: } y_i = \alpha^*+\beta_1^*x_{1i}+\varepsilon^*_i \\
&amp; \text{Model 2: } y_i = \alpha + \beta_1x_{1i} + \beta_2 x_{2i}+\varepsilon_i
\end{aligned}
\]</span>
<span class="math inline">\(\beta_1, \beta_1^*\)</span> 表示的其實是完全不同的含義。<span class="math inline">\(\beta_1^*\)</span> 被稱為粗回歸係數 (crude coefficient)，或者叫做調整前回歸係數，<span class="math inline">\(\beta_1\)</span> 被稱為調整後回歸係數 (adjusted coefficient)。二者之間的差異，其實是可以通過對這兩個變量進行簡單線性回歸來度量的：</p>
<p><span class="math display">\[
\text{Model 3: } x_{2i} = \gamma+\delta_1x_{1i}+\omega_i
\]</span>
將 Model 2 中的 <span class="math inline">\(x_{2i}\)</span> 用 Model 3 來替換掉：
<span class="math display">\[
\begin{aligned}
\text{Model 2: }y_i  &amp;= \alpha + \beta_1 x_{1i} + \beta_2(\gamma + \delta_1x_{1i}+\omega_i) +\varepsilon_i \\
       &amp;= \alpha + \beta_2\gamma+(\beta_1+\beta_2\delta_1)x_{1i}+\beta_2\omega_i + \varepsilon_i
\end{aligned}
\]</span>
比較 Model 1 和變形過後的 Model 2 中 <span class="math inline">\(x_{1i}\)</span> 的係數就不難發現：</p>
<p><span class="math display">\[
\beta_1^* = \beta_1 + \beta_2\delta_1
\]</span>
由此可見，調整前後 <span class="math inline">\(x_{1i}\)</span> 的回歸係數的變化 <span class="math inline">\(\beta_1^*, \beta_1\)</span> 之間的差異，取決於兩個部分的大小：</p>
<ul>
<li><span class="math inline">\(\beta_2\)</span> 的大小和它的符號；</li>
<li><span class="math inline">\(X_1, X_2\)</span> 這兩個預測變量之間有多大關聯，用 Model 3 的 <span class="math inline">\(\delta_1\)</span> 來度量。</li>
</ul>
<p>所以，當調整後的 <span class="math inline">\(\beta_1 &gt; 0\)</span> 時，要分三種情況來討論</p>
<div id="情況1-beta_1-beta_1" class="section level3">
<h3><span class="header-section-number">29.4.1</span> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></h3>
<p>此時，<span class="math inline">\(\beta_2\delta_1&lt;0\)</span> 所以，二者之間一正一負。如下圖所示：</p>
<p><img src="img/lr4confounding1.png" width="50%" style="display: block; margin: auto;" />
按圖所示，當 <span class="math inline">\(X_2\)</span> 保持不變，<span class="math inline">\(X_1\)</span> 與因變量 <span class="math inline">\(Y\)</span> 正相關 (<span class="math inline">\(\beta_1&gt;0\)</span>)。但是，兩個預測變量之間 <span class="math inline">\(X_1, X_2\)</span> 也呈正相關關係 <span class="math inline">\(\delta_1 &gt;0\)</span>。而同時，<span class="math inline">\(X_2\)</span> 的升高會導致因變量 <span class="math inline">\(Y\)</span> 的下降 ($_2 &lt;0 $)。這種情況就意味著，如果，我們不調整 <span class="math inline">\(X_2\)</span> (使之保持不變)，那麼 <span class="math inline">\(X_1\)</span> 每升高一個單位，<span class="math inline">\(Y\)</span> 的變化會<strong>低於</strong>調整 <span class="math inline">\(X_2\)</span> 時，<span class="math inline">\(X_1\)</span> 的變化所引起的 <span class="math inline">\(Y\)</span> 的變化。如果這時候 <span class="math inline">\(\beta_2,\delta_1\)</span> 較大，那麼對於 <span class="math inline">\(X_1\)</span> 來說，調整 <span class="math inline">\(X_2\)</span> 前後，回歸係數的變化較大，如果大到一定程度，甚至調整前後的回歸係數的方向 (正負) 都會發生變化。</p>
</div>
<div id="情況2beta_1beta_1" class="section level3">
<h3><span class="header-section-number">29.4.2</span> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></h3>
<p>本情況下，<span class="math inline">\(\beta_2\delta_1&gt;0\)</span> 是正的。所以二者要麼同時爲正，要麼同時爲負。如下圖所示：</p>
<p><img src="img/lr4confounding2.png" width="50%" style="display: block; margin: auto;" /></p>
<p>當 <span class="math inline">\(X_2\)</span> 保持不變時， <span class="math inline">\(X_1\)</span> 同 <span class="math inline">\(Y\)</span> 呈正關係。但是，<span class="math inline">\(X_1\)</span> 的升高也會引起 <span class="math inline">\(X_2\)</span> 的升高，同時通過 <span class="math inline">\(X_2\)</span> 和 <span class="math inline">\(Y\)</span> 之間的正關係升高 <span class="math inline">\(Y\)</span>。所以假設在模型裏我們不對 <span class="math inline">\(X_2\)</span> 進行控制 (controld or adjust)，那麼 <span class="math inline">\(X_1\)</span> 和 <span class="math inline">\(Y\)</span> 之間的關係就被誇大了。</p>
<p>所以，當 <span class="math inline">\(X_1\rightarrow X_2\rightarrow Y\)</span> 的這條通路大大超過 <span class="math inline">\(X_1\rightarrow Y\)</span> 的話，調整後的迴歸係數 <span class="math inline">\(\beta_1\)</span> 就會變得很小。</p>
</div>
<div id="情況3-beta_1-beta_1" class="section level3">
<h3><span class="header-section-number">29.4.3</span> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></h3>
<p>這種情況只有當 <span class="math inline">\(\beta_2\delta_1=0\)</span> 時才會出現。所以，二者至少有一個是 <span class="math inline">\(0\)</span>。 如下圖所示：</p>
<p><img src="img/lr4confounding3.png" width="50%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(X_1\)</span> 與 <span class="math inline">\(Y\)</span> 呈正關係，<span class="math inline">\(X_1\)</span> 與 <span class="math inline">\(X_2\)</span> 呈正關係。但是 <span class="math inline">\(X_2\)</span> 與 <span class="math inline">\(Y\)</span> 無關聯。所以此時無論模型是否調整了 <span class="math inline">\(X_2\)</span> 都不會影響 <span class="math inline">\(X_1\)</span> 和 <span class="math inline">\(Y\)</span> 之間關係的計算。</p>
</div>
</div>
<div id="confounding" class="section level2">
<h2><span class="header-section-number">29.5</span> 混雜 confounding</h2>
<p>流行病學家最喜歡的詞彙恐怕要屬混雜 (confounding) 了 (interaction, 交互作用也要算一個 (Section <a href="04-Linear-Regression.html#interaction">32</a>，(笑))。他們常用混雜來解釋爲什麼調整其他因子前後迴歸係數發生了變化。當有其他因子 (測量了或者甚至是未知的) 對我們關心的預測變量和因變量之間的關係產生了影響 (加強或是減弱) 時，就叫做發生了混雜。</p>
<p>對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件：</p>
<ul>
<li>與關心的預測變量相關 (i.e. <span class="math inline">\(\delta_1 \neq 0\)</span>)；</li>
<li>與因變量相關 (當關心的預測變量不變時，<span class="math inline">\(\beta_2\neq0\)</span> )；</li>
<li>不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable.</li>
</ul>
<p>有時，判斷一個因子是否對我們關心的預測變量和因變量之間的關係構成了混雜並不容易，也不直觀。所以，有太多太多的情況下，我們無法準確地 100% 地確定我們關心的關係是否被別的因子混雜。所以，莫要用 “混雜” 一詞簡單糊弄人。</p>
<div id="作為媒介-mediation-effect" class="section level3">
<h3><span class="header-section-number">29.5.1</span> 作為媒介 mediation effect</h3>
<p>多數情況下，我們也無法從數據判斷一個變量是否在我們關心的預測變量和因變量之間關係的通路上。此時要做的是離開你的電腦，去學習他們之間的生物學知識，看是否真的有關係。</p>
<p>但是有些例子就很簡單啦。比如說，服用降血壓藥物可以預防發生中風。那麼此時血壓的降低，就處在了這二者因果關係的通路上。因爲藥物通過降低了血壓，從而預防了中風的發生。這一關係中，我們不能說血壓是混雜因子，它是一個媒介 (mediator)。但是多數的橫斷面研究 (cross-sectional study) 中我們無法是很難下結論的。</p>
</div>
<div id="兩個預測變量之間的關係" class="section level3">
<h3><span class="header-section-number">29.5.2</span> 兩個預測變量之間的關係</h3>
<p>如果另一個變量不是媒介，且它和我們關心的預測變量，因變量之間如果都有相關關係，那它的確有可能成為混雜因子。但是僅僅通過統計學模型來考察混雜是絕對不夠的。例如樣本量較小的數據中，我們可能無法檢驗出一個變量對模型的混雜影響是不是有統計學意義的，但是這不能提供證據否認它不是混雜因子。同樣的，更多的混雜因子是我們沒有測量沒有觀察到收集到的未知因素。<strong>所以，任何數據都無法提供完全去除混雜因子影響的模型。</strong></p>
</div>
<div id="rct臨床實驗是個特例" class="section level3">
<h3><span class="header-section-number">29.5.3</span> RCT臨床實驗是個特例</h3>
<p>因為隨機對照臨床實驗，在設計階段就已經把治療組對照組之間的差異最小化了，理想的隨機對照實驗，其治療組和對照組之間理論上除了治療藥物的差別之外完全相同。當然這是理想狀況，且所有的臨床實驗都必須向這個方向努力設計和實施。偶然出現的治療組和對照組在某些特徵上的不平衡，不能被認為是混雜因子。只能說這樣的臨床實驗是不理想的，提供的證據水平也就較弱。</p>
</div>
</div>
</div>
<div id="多元模型分析矩陣標記與其意義" class="section level1">
<h1><span class="header-section-number">第 30 章</span> 多元模型分析：矩陣標記與其意義</h1>
<p>在線性回歸目前為止介紹的內容中，我們最多只談到了預測變量為兩個的情況。本章，我們要把這些概念推廣到三個或者三個以上預測變量的情況。同時，多重線性回歸時採用的假設檢驗也會被談及。其實最常見的就是 <span class="math inline">\(F\)</span> 檢驗。而且我們也見識過了，當預測變量只有一個的時候，<span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗是等價的。</p>
<p>重要的概念我們都已經介紹完畢。前一章的多重回歸模型中也強調了，我們之所以希望把多個預測變量放進模型，最大的目的就是想了解這些預測變量之間的相互關係，當他們得到調整 (adjustment) 之後，彼此之間的關係是怎樣的。這樣的關係我們稱之為條件關係 (conditional relationships)。當我們使用條件關係的稱呼時，需要同時指明我們說的是哪個變量，在那個變量不變的條件下，與因變量的關係是如何如何。</p>
<p>本章節最後的部分將會著重關注共線性 (collinearity) 的問題。</p>
<div id="線性回歸模型的矩陣非矩陣標記法" class="section level2">
<h2><span class="header-section-number">30.1</span> 線性回歸模型的矩陣/非矩陣標記法</h2>
<div id="模型標記" class="section level3">
<h3><span class="header-section-number">30.1.1</span> 模型標記：</h3>
<p>假如，因變量用 <span class="math inline">\(Y\)</span> 表示，預測變量有 <span class="math inline">\(p\)</span> 個之多 <span class="math inline">\((X_1,\cdots, X_p)\)</span>。該模型的非矩陣標記法如下：
<span class="math display" id="eq:nonmatrixlm">\[
\begin{equation}
y_i  = \alpha + \beta_1 x_{1i}+ \beta_2 x_{2i} + \cdots +  \beta_p x_{pi} + \varepsilon_i \text{ with } \varepsilon_i \sim \text{NID}(0, \sigma^2)
\end{equation}
\tag{30.1}
\]</span>
其中，</p>
<ul>
<li><span class="math inline">\(y_i =\)</span> 第 <span class="math inline">\(i\)</span> 名觀察對象的因變量數據；</li>
<li><span class="math inline">\(x_{pi} =\)</span> 第 <span class="math inline">\(i\)</span> 名觀察對象的第 <span class="math inline">\(p\)</span> 個預測變量的觀察數據。</li>
</ul>
<p>上面的非矩陣標記法，等同於如下的矩陣標記法：
<span class="math display" id="eq:matrixlm2">\[
\begin{equation}
\textbf{Y} = \textbf{X}\beta+\varepsilon, \text{ where } \varepsilon \sim N(0, \textbf{I}\sigma^2) \\
\left(
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array}
\right) = \left(
\begin{array}{c}
1&amp;  x_{11} &amp; \cdots &amp; x_{p1}  \\
1&amp;  x_{12} &amp; \cdots &amp; x_{p2} \\
\vdots &amp;   \vdots&amp; \vdots &amp; \vdots \\
1&amp;   x_{1n}&amp; \cdots &amp;x_{pn} \\
\end{array}
\right)\left(
\begin{array}{c}
\alpha \\
\beta_1\\
\beta_2 \\
\vdots \\
\beta_p
\end{array}
\right)+\left(
\begin{array}{c}
\varepsilon_1\\
\varepsilon_2\\
\vdots\\
\varepsilon_n\\
\end{array}
\right)
\end{equation}
\tag{30.2}
\]</span>
此公式 <a href="04-Linear-Regression.html#eq:matrixlm2">(30.2)</a> 中</p>
<ul>
<li><span class="math inline">\(\textbf{X}\)</span> 是一個 <span class="math inline">\(n\times(p+1)\)</span> 的矩陣；</li>
<li><span class="math inline">\(\textbf{Y}\)</span> 和 <span class="math inline">\(\varepsilon\)</span> 分別是長度為 <span class="math inline">\(n\)</span> 的列向量；</li>
<li><span class="math inline">\(\beta\)</span> 是長度為 <span class="math inline">\(p+1\)</span> 的列向量，且第一個元素是 <span class="math inline">\(\alpha\)</span>，偶爾被人誤寫成 <span class="math inline">\(\beta_0\)</span>。</li>
</ul>
<p>殘差被認為服從<strong>多元正態分佈 (multivariate normal distribution)</strong>，這個多元正態分佈的方差協方差矩陣等於 <span class="math inline">\(\sigma^2\)</span> 與單位矩陣相乘獲得的矩陣。這其實等價於認為殘差服從獨立正態且方差為 <span class="math inline">\(\sigma^2\)</span> 的分佈，</p>
</div>
</div>
<div id="解讀參數" class="section level2">
<h2><span class="header-section-number">30.2</span> 解讀參數</h2>
<p>模型中的參數的涵義為：</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距，所有的預測變量都是零的時候，因變量 <span class="math inline">\(Y\)</span> 的期待值大小；</li>
<li><span class="math inline">\(\beta_j\)</span> 是預測變量 <span class="math inline">\(X_j\)</span> 升高一個單位，且其他變量保持不變的同時，因變量 <span class="math inline">\(Y\)</span> 的期待值的變化；</li>
<li><span class="math inline">\(\beta_j\)</span> 都是偏回歸係數，每個偏回歸係數，測量的都是該預測變量調整了其他預測變量之後對於因變量期待值的影響。</li>
</ul>
<div id="最小二乘估計" class="section level3">
<h3><span class="header-section-number">30.2.1</span> 最小二乘估計</h3>
<p>還是同之前一樣，我們對殘差的平方和最小化，來獲取我們關心的預測變量的回歸變量。</p>
<p><span class="math display" id="eq:lsemulti">\[
\begin{aligned}
SS_{RES} &amp; = \sum_{i=1}^n \hat\varepsilon_i^2 =  \sum_{i=1}^n(y_i-\hat{y})^2 \\
&amp; = \sum_{i=1}^n (y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i}-\cdots-\hat\beta_px_{pi})^2
\end{aligned}
\tag{30.3}
\]</span></p>
<p>下面用矩陣標記法計算 <span class="math inline">\(\hat\beta\)</span>：</p>
<p><span class="math display" id="eq:lm5-4">\[
\begin{aligned}
\text{Because } \mathbf{Y} &amp; = \mathbf{X\hat\beta + \varepsilon} \\
\Rightarrow \mathbf{\varepsilon} &amp; = \mathbf{Y - X\hat\beta}\\
\Rightarrow \mathbf{SS_{RES}} &amp; = \varepsilon_1\times \varepsilon_1 + \varepsilon_2\times \varepsilon_2 + \cdots + \varepsilon_n\times \varepsilon_n \\
                     &amp; = (\varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n)\left(
                     \begin{array}{c}
                     \varepsilon_1\\
                     \varepsilon_2\\
                     \vdots\\
                     \varepsilon_n
                     \end{array}
                     \right) \\
                     &amp; = \mathbf{\varepsilon^\prime} \mathbf{\varepsilon} \\
                     &amp; = \mathbf{(Y-X\hat\beta)^\prime(Y-X\hat\beta)} \\
                     &amp; = \mathbf{Y^\prime Y - X^\prime\hat\beta^\prime Y - Y^\prime X\hat\beta + X^\prime\hat\beta^\prime X \hat\beta} \\
\text{Because} &amp;\text{ transpose of a scalar is a scalar:} \\
 \mathbf{Y^\prime X\hat\beta} &amp; = \mathbf{(Y^\prime X\hat\beta)^\prime = X^\prime\hat\beta^\prime Y} \\
\Rightarrow  \mathbf{SS_{RES}} &amp; = \mathbf{Y^\prime Y - 2X^\prime\hat\beta^\prime Y + X^\prime\hat\beta^\prime X \hat\beta}\\
\Rightarrow \mathbf{\frac{\partial SS_{RES}}{\partial \hat\beta}} &amp; = \mathbf{-2X^\prime Y + 2 X^\prime X \hat\beta} = 0 \\
\Rightarrow \mathbf{\hat\beta} &amp; = \mathbf{(X^\prime X)^{-1}X^\prime Y}
\end{aligned}
\tag{30.4}
\]</span></p>
<p>公式 <a href="04-Linear-Regression.html#eq:lm5-4">(30.4)</a> 是參數矩陣 <span class="math inline">\(\mathbf{\beta}\)</span> 的無偏估計，且服從方差協方差矩陣爲 <span class="math inline">\(\mathbf{(X^\prime X)^{-1}\sigma^2}\)</span> 的多元正態分佈：</p>
<p><span class="math display" id="eq:lm5-5">\[
\begin{equation}
\mathbf{\hat\beta} \sim  N(\mathbf{\beta, (X^\prime X)^{-1}\sigma^2})
\end{equation}
\tag{30.5}
\]</span></p>
<p>另外可以被證明的是，多元線性迴歸模型的殘差方差的估計量計算公式爲：</p>
<p><span class="math display" id="eq:lm5-6">\[
\begin{aligned}
\hat\sigma^2 &amp; = \sum^n_{i=1}\frac{\hat\varepsilon^2_i}{[n-(p+1)]} \\
             &amp; = \sum^n_{i=1}\frac{\sum_{i=1}^n (y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i}-\cdots-\hat\beta_px_{pi})^2}{[n-(p+1)]} \\
\text{Where } &amp; p \text{ is the number of predictors}
\end{aligned}
\tag{30.6}
\]</span></p>
</div>
<div id="因變量的期待值-mathbfhat-y" class="section level3">
<h3><span class="header-section-number">30.2.2</span> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></h3>
<p>因變量的期待值矩陣 <span class="math inline">\(\mathbf{\hat Y}\)</span> 根據公式 <a href="04-Linear-Regression.html#eq:lm5-4">(30.4)</a> 推導：</p>
<p><span class="math display" id="eq:lm5-7">\[
\begin{aligned}
\mathbf{\hat Y} &amp; = \mathbf{X\hat\beta} \\
                &amp; = \mathbf{X(X^\prime X)^{-1}X^\prime Y}= \mathbf{PY} \\
\text{Where } \mathbf{P} &amp;= \mathbf{X(X^\prime X)^{-1}X^\prime}
\end{aligned}
\tag{30.7}
\]</span></p>
<p>這裏的 <span class="math inline">\(n\times n\)</span> 的正方形矩陣 <span class="math inline">\(\mathbf{P}\)</span> 在多元線性迴歸中是一個極爲重要的矩陣。</p>
<ul>
<li>它常被叫做“帽子/映射 (hat/projection)”矩陣，因爲它把觀察值 <span class="math inline">\(\mathbf{Y}\)</span> 和觀察值的擬合值一一映射；</li>
<li>帽子矩陣的第 <span class="math inline">\(i\)</span> 個對角元素，是第 <span class="math inline">\(i\)</span> 名觀察值的影響值 (leverage)，會用在下章節的模型診斷中；</li>
<li>擬合值矩陣的方差協方差矩陣被定義爲：</li>
</ul>
<p><span class="math display" id="eq:lm5-8">\[
\begin{equation}
\text{Var}(\mathbf{\hat Y}) = \mathbf{P}\sigma^2
\end{equation}
\tag{30.8}
\]</span></p>
</div>
<div id="殘差" class="section level3">
<h3><span class="header-section-number">30.2.3</span> 殘差</h3>
<p>殘差的觀察值 <span class="math inline">\(\mathbf{\hat\varepsilon}\)</span> 被定義爲觀察值和擬合值的差。根據前節 <a href="04-Linear-Regression.html#eq:lm5-8">(30.8)</a> 推導：</p>
<p><span class="math display" id="eq:lm5-9">\[
\begin{equation}
\mathbf{\hat\varepsilon} = \mathbf{Y - \hat Y} = \mathbf{Y - PY} = \mathbf{(I - P)Y}
\end{equation}
\tag{30.9}
\]</span></p>
<p>這個觀察殘差的方差被定義爲：</p>
<p><span class="math display" id="eq:lm5-10">\[
\begin{equation}
\text{Var}(\mathbf{\hat\varepsilon}) = \mathbf{(I - P)}\sigma^2
\end{equation}
\tag{30.10}
\]</span></p>
<ul>
<li>一般地，<span class="math inline">\(\mathbf{P}\)</span> 不是一個對角矩陣，意思是觀察殘差之間無法保證是獨立的；</li>
<li><span class="math inline">\(\mathbf{P}\)</span> 的對角元素也不全都相等，意思是觀察殘差的方差無法保證是恆定不變的。</li>
</ul>
</div>
</div>
<div id="方差分析一般化和-f-檢驗" class="section level2">
<h2><span class="header-section-number">30.3</span> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</h2>
<div id="多元線性迴歸時的決定係數和殘差方差" class="section level3">
<h3><span class="header-section-number">30.3.1</span> 多元線性迴歸時的決定係數和殘差方差</h3>
<p>和簡單線性迴歸一樣，因變量的校正平方和可以被分割成兩部分：迴歸模型能夠解釋的平方和；模型無法解釋的殘差平方和。類比方差分析章節 (Section <a href="04-Linear-Regression.html#ANOVA">28</a>) 的公式 <a href="04-Linear-Regression.html#eq:SSres-partition">(28.1)</a>：</p>
<p><span class="math display" id="eq:lm5-11">\[
\begin{aligned}
\sum_{i=1}^n(y_i-\bar{y})^2 &amp; = \sum_{i=1}^n(\hat{y}_i - \bar{y})^2 + \sum_{i=1}^n(y_i - \hat{y}_i)^2 \\
SS_{yy}  &amp; = SS_{REG} + SS_{RES}
\end{aligned}
\tag{30.11}
\]</span></p>
<p>和簡單線性迴歸也一樣，多元線性迴歸時的模型決定係數 (coefficient of determination) 的定義爲：</p>
<p><span class="math display" id="eq:lm5-12">\[
\begin{aligned}
R^2 &amp; = \frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1- \frac{SS_{RES}}{SS_{yy}} \\
    &amp; = 1 - \frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i - \bar{y})^2}
\end{aligned}
\tag{30.12}
\]</span></p>
<p>這裏的 <span class="math inline">\(R^2\)</span> 也一樣可以被解釋爲模型能夠解釋的因變量變動部分的百分比 (proportion of the variability in the dependent variable explained by the model)。值得注意的是，當模型中預測變量不減少，每加入一個新的預測變量，決定係數也會增加，相反殘差平方和卻絕不會增加。</p>
</div>
<div id="方差分析表格" class="section level3">
<h3><span class="header-section-number">30.3.2</span> 方差分析表格</h3>
<p>下表和簡單線性迴歸的方差分析表格很類似，也可以用來作假設檢驗 (迴歸方程的顯著性檢驗 Global <span class="math inline">\(F-\text{test}\)</span>，和偏 <span class="math inline">\(F\)</span> 檢驗 Partial <span class="math inline">\(F-\text{test}\)</span>)。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.1: Analysis of Variance table for a liear regression model with <span class="math inline">\(p\)</span> predictor variables
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Regression (model)
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{REG} = \frac{SS_{REG}}{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{RES}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-(p+1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{RES} = \frac{SS_{RES}}{[n-(p+1)]}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="globalsig" class="section level3">
<h3><span class="header-section-number">30.3.3</span> 迴歸方程的顯著性檢驗</h3>
<p>整個方程的顯著性檢驗，檢驗的是所有的迴歸係數都等於零的零假設，其對應的替代假設則是：“迴歸係數<strong>不全爲零</strong>”。就是至少有一個不等於零。</p>
<p>在零假設條件下，檢驗統計量的計算公式爲：</p>
<p><span class="math display" id="eq:lm5-13">\[
\begin{equation}
F = \frac{MS_{REG}}{MS_{RES}} \sim F_{p, [n-(p+1)]}
\end{equation}
\tag{30.13}
\]</span></p>
<p>在零假設條件下，<span class="math inline">\(F\)</span> 的期望值接近 <span class="math inline">\(1\)</span>，而替代假設條件下的 <span class="math inline">\(F\)</span> 總是會大於此，所以和 <span class="math inline">\(F\)</span> 分佈比較特徵值時只需要比較單側的 (右側的) 值，即可獲得雙側 <span class="math inline">\(p\)</span> 值。</p>
<p>在 R 裏面，迴歸方程的結果的最底下會出現統計量 <span class="math inline">\(F\)</span> 的大小，但是 <span class="math inline">\(MS_{REG}, MS_{RES}\)</span> 要用 <code>anova()</code> 代碼獲得：</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb149-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb149-3" title="3"></a>
<a class="sourceLine" id="cb149-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb149-5" title="5"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.20525 -0.64402 -0.00303  0.55967  2.86277 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.351244   1.259968 -6.6281 3.531e-10 ***
## age         -0.011260   0.016751 -0.6722    0.5023    
## len          0.237129   0.019516 12.1502 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9546 on 187 degrees of freedom
## Multiple R-squared:  0.74337,    Adjusted R-squared:  0.74063 
## F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## age         1 359.06  359.06  394.06 &lt; 2.2e-16 ***
## len         1 134.52  134.52  147.63 &lt; 2.2e-16 ***
## Residuals 187 170.39    0.91                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>可以看到 <code>summary()</code> 輸出結果的最後一行是關於迴歸方程整體的 <span class="math inline">\(F\)</span> 檢驗結果 <code>F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code>，從 <code>anova()</code> 結果中可以獲得 <span class="math inline">\(MS_{REG} = \frac{359.0632 + 134.5153}{2} = 246.7892\)</span>。<span class="math inline">\(F_{2,187} = \frac{246.7892}{0.9111833} = 270.84\)</span>。這個檢驗結果證明了，兩個預測變量 “體重” 和 “身長” 至少有一個的迴歸係數不等於零。</p>
</div>
<div id="partialF" class="section level3">
<h3><span class="header-section-number">30.3.4</span> <span class="math inline">\(\text{partial }F\)</span> 檢驗</h3>
<p>如果我們建立兩個模型，一個稍微複雜一些 <span class="math inline">\((B)\)</span>，比起略簡單的模型 <span class="math inline">\((A)\)</span>，增加了 <span class="math inline">\(k\)</span> 個預測變量。兩個模型放在一起的方差分析表格可以歸納成：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.2: Analysis of Variance table comparing the fit of a model <span class="math inline">\((B)\)</span> with <span class="math inline">\(p\)</span> predictor variables with that of one (model <span class="math inline">\(A\)</span>) with <span class="math inline">\(p-k\)</span> predictor variables
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Explained by <br> model <span class="math inline">\(A\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG_A}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(p-k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{REG_A} = \frac{SS_{REG_A}}{p-k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Extra Explained <br> by model <span class="math inline">\(B\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG_B}-SS_{REG_A}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{REG_B}-SS_{REG_A}}{k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual from <br> model <span class="math inline">\(B\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{RES_B}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-(p+1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{RES_B} = \frac{SS_{RES_B}}{[n-(p+1)]}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>那麼偏 <span class="math inline">\(F\)</span> 檢驗的零假設就是：<span class="math inline">\(B\)</span> 模型中包含，<span class="math inline">\(A\)</span> 模型中不包含的 <span class="math inline">\(k\)</span> 個預測變量的迴歸係數都等於零。</p>
<p><span class="math display" id="eq:lm5-14">\[
\begin{equation}
F=\frac{(SS_{REG-B}-SS_{REG-A})/k}{MS_{RES-B}} \sim F_{k, [n-(p+1)]}
\end{equation}
\tag{30.14}
\]</span></p>
<p>在 R 裏建立兩個模型：</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb153-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.155217 -0.629239  0.014555  0.544783  2.928738 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -7.6694406  0.7463556 -10.276 &lt; 2.2e-16 ***
## len          0.2257467  0.0096893  23.299 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9532 on 188 degrees of freedom
## Multiple R-squared:  0.74275,    Adjusted R-squared:  0.74139 
## F-statistic: 542.82 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## len         1 493.17  493.17  542.82 &lt; 2.2e-16 ***
## Residuals 188 170.80    0.91                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data =</span> growgam1)</a>
<a class="sourceLine" id="cb157-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len + age + sex, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.110422 -0.648401  0.026103  0.560621  2.768583 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -7.8906758  1.3003091 -6.0683 7.091e-09 ***
## len          0.2317997  0.0198470 11.6793 &lt; 2.2e-16 ***
## age         -0.0077959  0.0168974 -0.4614    0.6451    
## sex2        -0.1964758  0.1421171 -1.3825    0.1685    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9522 on 186 degrees of freedom
## Multiple R-squared:  0.74599,    Adjusted R-squared:  0.74189 
## F-statistic: 182.08 on 3 and 186 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq  F value Pr(&gt;F)    
## len         1 493.17  493.17 543.8753 &lt;2e-16 ***
## age         1   0.41    0.41   0.4540 0.5013    
## sex         1   1.73    1.73   1.9113 0.1685    
## Residuals 186 168.66    0.91                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>根據公式 <a href="04-Linear-Regression.html#eq:lm5-14">(30.14)</a>，<span class="math inline">\(F=\frac{0.4116944+1.7330862}{2\times0.9067645} = 1.18\)</span>。<span class="math inline">\(p\)</span> 值可以在 R 裏面這樣計算：</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" title="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(<span class="dt">df1 =</span> <span class="dv">2</span>,<span class="dt">df2 =</span> <span class="dv">186</span>,<span class="dt">q =</span> (<span class="fl">0.4116944+1.7330862</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.9067645</span>))</a></code></pre></div>
<pre><code>## [1] 0.3088</code></pre>
<p>更方便的是直接用 <code>anova()</code> 進行偏 <span class="math inline">\(F\)</span> 檢驗：</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1, Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wt ~ len
## Model 2: wt ~ len + age + sex
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    188 170.80                           
## 2    186 168.66  2    2.1448 1.1827 0.3088</code></pre>
</div>
</div>
<div id="添加新變量對迴歸模型的影響" class="section level2">
<h2><span class="header-section-number">30.4</span> 添加新變量對迴歸模型的影響</h2>
<p>當你決定給建立的模型 <span class="math inline">\(\mathbf{A}\)</span> 增加新的預測變量時，輸出的結果<strong>改變</strong>的有：</p>
<ol style="list-style-type: decimal">
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數的方差</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數的檢驗結果</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的 <strong>擬合值 (predicted values/fitted values)</strong>會改變；</li>
<li>決定係數 <span class="math inline">\(R^2\)</span> 會改變。</li>
</ol>
<div id="偏迴歸係數方差的改變" class="section level3">
<h3><span class="header-section-number">30.4.1</span> 偏迴歸係數方差的改變</h3>
<p>偏迴歸係數矩陣 <span class="math inline">\(\mathbf{\hat\beta}\)</span> 的方差 <span class="math inline">\(\mathbf{(X^\prime X)^{-1}\sigma^2}\)</span> <a href="04-Linear-Regression.html#eq:lm5-5">(30.5)</a>，取決於</p>
<ol style="list-style-type: decimal">
<li>殘差方差 (residual variance) <span class="math inline">\(\sigma^2\)</span>；</li>
<li>樣本量大小 (sample size) <span class="math inline">\(n\)</span>；</li>
<li>預測變量之間的協方差 (covariance between the predictor variable in question and the others)。</li>
</ol>
<p>在簡單線性迴歸中，預測變量的變化性 (variability，用方差或標準差衡量) 越大，迴歸係數的估計就越精確。類似地，多元線性迴歸中，預測變量之間的協方差之所以重要，因爲它決定了<strong>其他預測變量保持不變時</strong>，該預測變量的變化性。如果某兩個預測變量之間高度相關 (high covariance)，那麼當一個預測變量保持不變時，另一個的變化性就很小。</p>
<p>所以當給一個模型加入新的預測變量時，可能觀察的現象是原先模型中已有的預測變量的偏迴歸係數的方差<strong>可能升高，也可能降低</strong>。</p>
<ul>
<li>如果新加入的變量能解釋很大比例的殘差方差，那麼其他原有變量的偏迴歸係數會降低 (變精確)；</li>
<li>如果新加入的變量和原模型中的某個變量高度相關，那麼加入新變量後，原模型中與之高度相關的預測變量的方差會升高 (不精確)，這個現象會在共線性 (collinearity) 中繼續討論。</li>
</ul>
</div>
<div id="偏迴歸係數檢驗結果的改變" class="section level3">
<h3><span class="header-section-number">30.4.2</span> 偏迴歸係數檢驗結果的改變</h3>
<p>加入新預測變量時，原有的偏迴歸係數的檢驗結果發生的改變可以歸類成兩種情況：</p>
<ol style="list-style-type: decimal">
<li>估計的偏迴歸係數本身發生了改變；</li>
<li>偏迴歸係數的方差改變，導致了檢驗結果發生變化。</li>
</ol>
</div>
<div id="擬合值的改變" class="section level3">
<h3><span class="header-section-number">30.4.3</span> 擬合值的改變</h3>
<p>很明顯，當模型中加入新的變量，觀察對象的擬合值會發生改變，但是通常這樣的影響要遠遠小於對偏迴歸係數估計 (和其方差) 的影響。</p>
</div>
<div id="決定係數的改變" class="section level3">
<h3><span class="header-section-number">30.4.4</span> 決定係數的改變</h3>
<p>模型中增加新的預測變量，那麼模型的決定係數不會減少，只會增加。</p>
</div>
<div id="共線性-collinearity" class="section level3">
<h3><span class="header-section-number">30.4.5</span> 共線性 collinearity</h3>
<p>當預測變量 <span class="math inline">\(X_1\)</span> 和另一個預測變量 <span class="math inline">\(X_2\)</span> 之間呈高度線性關係時被定義爲共線性現象。如果這兩個變量的關係是<strong>完全線性 (exact linear)</strong>，那麼多元迴歸其實是無法進行的，因爲這兩個變量中的一個隨着另一個改變，無法像我們設想的那樣把其中一個變量保持不變，從而估計另一個變量的迴歸係數。用矩陣表示多元預測變量時 <span class="math inline">\(\mathbf{X}\)</span> 是<strong><a href="https://www.youtube.com/watch?v=UqyN7-tRS00">奇異矩陣 singular matrix</a></strong>，<span class="math inline">\(\mathbf{(X^\prime X)^{-1}}\)</span> 是不存在的。</p>
<p>完全線性的最佳例子是我們在對分類變量使用啞變量的情況下。每個啞變量之間都是完全線性的關係，因而我們只能用 <span class="math inline">\(0,1\)</span> 來編碼啞變量，當某個啞變量存在時，其餘的啞變量取 <span class="math inline">\(0\)</span> 從模型中消失。否則模型將無法擬合。</p>
<p>如果某兩個變量之間高度相關，那麼他們的預測變量矩陣接近 <strong>奇異矩陣</strong>，把這兩個變量同時作爲預測變量放入模型中會引起共線性現象，表現出來的形式有：</p>
<ol style="list-style-type: decimal">
<li>偏迴歸係數的方差變得很大；</li>
<li>偏迴歸係數本身的絕對值變得異常大；</li>
<li>某些已知的重要預測變量的偏迴歸係數變得過小且不再有意義；</li>
<li>雖然會有 1-3 描述的異常現象出現，但是擬合值的變化卻可能微不足道。</li>
</ol>
<p>所以擬合多元線性迴歸模型時，<strong>極爲重要的一點是要避免共線性</strong>。如果有些變量高度相關，必須考慮改變他們放入模型的形式：</p>
<ol style="list-style-type: decimal">
<li>收縮期血壓，舒張期血壓兩個變量是高度相關的，不能一起放入模型中。如果需要同時考慮兩個變量，可以用其中一個，另一個預測變量用二者之差；</li>
<li>身高，體重常常是高度相關的，儘量不要一起放入模型中，可以使用他們的結合形式體質指數 (BMI, <span class="math inline">\(\text{kg/m}^2\)</span>)；</li>
<li>當使用二次方程進行模型擬合的時候，用 <span class="math inline">\((x_i - \bar{x})^2\)</span> 取代 <span class="math inline">\(x_i^2\)</span>。</li>
</ol>
</div>
</div>
<div id="實戰演習" class="section level2">
<h2><span class="header-section-number">30.5</span> 實戰演習</h2>
<div id="血清維生素-c-濃度的預測變量" class="section level3">
<h3><span class="header-section-number">30.5.1</span> 血清維生素 C 濃度的預測變量</h3>
<p>數據來自與某個橫斷面研究，其目的是找出與血清維生素 C 濃度相關的預測變量。</p>
<p>數據中個變量含義如下表所示。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.3: Data set of serum vitamin C level explained
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable name
</th>
<th style="text-align:left;">
content
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<code>serial</code>
</td>
<td style="text-align:left;">
Patient identifier
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>age</code>
</td>
<td style="text-align:left;">
Age of subjects in years
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>height</code>
</td>
<td style="text-align:left;">
Height in metres
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>cigs</code>
</td>
<td style="text-align:left;">
Smoking status (0=non-smoker; 1=smoker)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>weight</code>
</td>
<td style="text-align:left;">
Weight in kg
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>sex</code>
</td>
<td style="text-align:left;">
Gender (0=men; 1=women)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>seruvitc</code>
</td>
<td style="text-align:left;">
Serum Vitamin C level (<span class="math inline">\(\mu\text{mol/L}\)</span>)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>ctakers</code>
</td>
<td style="text-align:left;">
Vitamin C supplements taken (1=yes, 0=no)
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>在 R 裏讀入數據，並對數據內容總結，對維生素C濃度和其他連續性變量作散點圖，對分類變量如性別，吸菸狀況，和維生素C補充劑服用與否之間的維生素 C 濃度作初步的分析表格。</li>
</ol>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb165-2" title="2">vitC &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/vitC.dta&quot;</span>)</a>
<a class="sourceLine" id="cb165-3" title="3"></a>
<a class="sourceLine" id="cb165-4" title="4"><span class="co">##########################################</span></a>
<a class="sourceLine" id="cb165-5" title="5"><span class="co"># Recoding the categorical variables     #</span></a>
<a class="sourceLine" id="cb165-6" title="6"><span class="co">##########################################</span></a>
<a class="sourceLine" id="cb165-7" title="7"></a>
<a class="sourceLine" id="cb165-8" title="8">vitC<span class="op">$</span>sex[vitC<span class="op">$</span>sex <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;Men&quot;</span></a>
<a class="sourceLine" id="cb165-9" title="9">vitC<span class="op">$</span>sex[vitC<span class="op">$</span>sex <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Women&quot;</span></a>
<a class="sourceLine" id="cb165-10" title="10">vitC<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb165-11" title="11">vitC<span class="op">$</span>cigs[vitC<span class="op">$</span>cigs <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;Non-smoker&quot;</span></a>
<a class="sourceLine" id="cb165-12" title="12">vitC<span class="op">$</span>cigs[vitC<span class="op">$</span>cigs <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Smoker&quot;</span></a>
<a class="sourceLine" id="cb165-13" title="13">vitC<span class="op">$</span>cigs &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>cigs)</a>
<a class="sourceLine" id="cb165-14" title="14">vitC<span class="op">$</span>ctakers[vitC<span class="op">$</span>ctakers <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;No&quot;</span></a>
<a class="sourceLine" id="cb165-15" title="15">vitC<span class="op">$</span>ctakers[vitC<span class="op">$</span>ctakers <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Yes&quot;</span></a>
<a class="sourceLine" id="cb165-16" title="16">vitC<span class="op">$</span>ctakers &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>ctakers)</a>
<a class="sourceLine" id="cb165-17" title="17"></a>
<a class="sourceLine" id="cb165-18" title="18"><span class="co">############################################</span></a>
<a class="sourceLine" id="cb165-19" title="19"><span class="co"># End of recoding the categorical variables#</span></a>
<a class="sourceLine" id="cb165-20" title="20"><span class="co">############################################</span></a>
<a class="sourceLine" id="cb165-21" title="21"></a>
<a class="sourceLine" id="cb165-22" title="22"><span class="kw">summary</span>(vitC) <span class="co">#Basic summary without any package</span></a></code></pre></div>
<pre><code>##      serial           age           height             cigs        weight         sex    
##  Min.   :  1.0   Min.   :65.0   Min.   :1.48   Non-smoker:80   Min.   : 44.0   Men  :44  
##  1st Qu.: 23.8   1st Qu.:67.0   1st Qu.:1.58   Smoker    :12   1st Qu.: 57.8   Women:48  
##  Median : 49.0   Median :69.0   Median :1.64                   Median : 67.0             
##  Mean   : 49.2   Mean   :69.3   Mean   :1.65                   Mean   : 68.6             
##  3rd Qu.: 73.2   3rd Qu.:71.0   3rd Qu.:1.72                   3rd Qu.: 76.5             
##  Max.   :100.0   Max.   :74.0   Max.   :1.89                   Max.   :103.0             
##                                 NA&#39;s   :1                      NA&#39;s   :1                 
##     seruvitc     ctakers 
##  Min.   :  8.0   No :73  
##  1st Qu.: 34.8   Yes:19  
##  Median : 58.0           
##  Mean   : 53.2           
##  3rd Qu.: 71.0           
##  Max.   :100.0           
## </code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1"><span class="kw">head</span>(vitC) <span class="co">#See the first 6 observations</span></a></code></pre></div>
<pre><code>## # A tibble: 6 x 8
##   serial   age height cigs       weight sex   seruvitc ctakers
##    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  
## 1      1    71   1.72 Smoker       68.8 Men          9 No     
## 2      2    70   1.63 Non-smoker   58.2 Women       19 No     
## 3      3    69   1.65 Non-smoker   94.3 Women       69 Yes    
## 4      4    67   1.62 Non-smoker   87.6 Women       71 No     
## 5      5    68   1.53 Non-smoker   66.3 Women       87 Yes    
## 6      6    71   1.64 Non-smoker   72.2 Women       96 Yes</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1"><span class="kw">library</span>(psych) <span class="co">#some detailed summary function from this package</span></a>
<a class="sourceLine" id="cb169-2" title="2"><span class="kw">describe</span>(vitC)</a></code></pre></div>
<pre><code>## vitC 
## 
##  8  Variables      92  Observations
## ----------------------------------------------------------------------------------------------------
## serial : subject number  Format:%3.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       92        1    49.25    33.74     5.55    10.10    23.75    49.00    73.25 
##      .90      .95 
##    88.90    95.45 
## 
## lowest :   1   2   3   4   5, highest:  96  97  98  99 100
## ----------------------------------------------------------------------------------------------------
## age : age on study entry  Format:%2.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       10    0.988    69.32    3.353     65.0     65.1     67.0     69.0     71.0 
##      .90      .95 
##     74.0     74.0 
##                                                                       
## Value         65    66    67    68    69    70    71    72    73    74
## Frequency     10     9    12     8    10    10    11     3     8    11
## Proportion 0.109 0.098 0.130 0.087 0.109 0.109 0.120 0.033 0.087 0.120
## ----------------------------------------------------------------------------------------------------
## height  Format:%4.1f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       91        1       34    0.999    1.647   0.1128     1.50     1.52     1.58     1.64     1.72 
##      .90      .95 
##     1.79     1.81 
## 
## lowest : 1.48 1.49 1.51 1.52 1.53, highest: 1.80 1.81 1.82 1.86 1.89
## ----------------------------------------------------------------------------------------------------
## cigs 
##        n  missing distinct 
##       92        0        2 
##                                 
## Value      Non-smoker     Smoker
## Frequency          80         12
## Proportion       0.87       0.13
## ----------------------------------------------------------------------------------------------------
## weight : Clothed weight  Format:%5.1f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       91        1       79        1    68.57    15.35    48.85    50.40    57.80    67.00    76.55 
##      .90      .95 
##    88.30    91.60 
## 
## lowest :  44.0  46.7  48.1  48.4  48.5, highest:  92.0  94.3  97.5 102.4 103.0
## ----------------------------------------------------------------------------------------------------
## sex 
##        n  missing distinct 
##       92        0        2 
##                       
## Value        Men Women
## Frequency     44    48
## Proportion 0.478 0.522
## ----------------------------------------------------------------------------------------------------
## seruvitc : Serum ascorbate  Format:%3.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       60        1    53.21    27.12    11.55    17.00    34.75    58.00    71.00 
##      .90      .95 
##    80.90    84.45 
## 
## lowest :   8   9  10  11  12, highest:  85  86  87  96 100
## ----------------------------------------------------------------------------------------------------
## ctakers 
##        n  missing distinct 
##       92        0        2 
##                       
## Value         No   Yes
## Frequency     73    19
## Proportion 0.793 0.207
## ----------------------------------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1"><span class="kw">library</span>(epiDisplay) <span class="co">#some STATA-like simple summary function</span></a>
<a class="sourceLine" id="cb171-2" title="2"><span class="kw">summ</span>(vitC)</a></code></pre></div>
<pre><code>## 
## No. of observations = 92
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 serial    92   49.25  49      29.07  1      100   
## 2 age       92   69.32  69      2.91   65     74    
## 3 height    91   1.65   1.64    0.1    1.48   1.89  
## 4 cigs                                              
## 5 weight    91   68.57  67      13.48  44     103   
## 6 sex                                               
## 7 seruvitc  92   53.21  58      23.83  8      100   
## 8 ctakers</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1">vitC<span class="op">$</span>serial[<span class="kw">which</span>(<span class="kw">is.na</span>(vitC<span class="op">$</span>height))]</a></code></pre></div>
<pre><code>## [1] 24</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1">vitC<span class="op">$</span>serial[<span class="kw">which</span>(<span class="kw">is.na</span>(vitC<span class="op">$</span>weight))]</a></code></pre></div>
<pre><code>## [1] 24</code></pre>
<p>從初步的熟悉數據結構和歸納結果可以看出，身高體重兩個數據有出現缺損值 (編號 24 的患者)。</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>sex, <span class="dt">graph =</span> <span class="ot">FALSE</span>) <span class="co"># From package &quot;epiDisplay&quot;</span></a></code></pre></div>
<pre><code>## For vitC$sex = Men 
##  obs. mean   median  s.d.   min.   max.  
##  44   46.091 52.5    24.877 8      100   
## 
## For vitC$sex = Women 
##  obs. mean   median  s.d.   min.   max.  
##  48   59.729 66.5    21.043 15     96</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>cigs, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## For vitC$cigs = Non-smoker 
##  obs. mean   median  s.d.   min.   max.  
##  80   55.138 58      23.323 8      100   
## 
## For vitC$cigs = Smoker 
##  obs. mean   median  s.d.   min.   max.  
##  12   40.333 49.5    24.186 9      68</code></pre>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>ctakers, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## For vitC$ctakers = No 
##  obs. mean   median  s.d.   min.   max.  
##  73   48.644 55      22.795 8      84    
## 
## For vitC$ctakers = Yes 
##  obs. mean   median  s.d.   min.   max.  
##  19   70.737 72      19.612 13     100</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" title="1"><span class="co"># You can also get similar detailed descriptive statistics by groups from package &quot;psych&quot;</span></a>
<a class="sourceLine" id="cb183-2" title="2"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>sex)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: Men
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 44 46.09 24.88   52.5   45.61 25.95   8 100    92 -0.06    -1.12 3.75
## --------------------------------------------------------------------------- 
## group: Women
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 48 59.73 21.04   66.5   61.15 15.57  15  96    81 -0.65    -0.62 3.04</code></pre>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" title="1"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>cigs)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: Non-smoker
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 80 55.14 23.32     58    56.3 22.24   8 100    92 -0.43    -0.85 2.61
## --------------------------------------------------------------------------- 
## group: Smoker
##    vars  n  mean    sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 12 40.33 24.19   49.5    40.7 25.2   9  68    59 -0.19    -1.93 6.98</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" title="1"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>ctakers)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: No
##    vars  n  mean    sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 73 48.64 22.79     55   49.47 25.2   8  84    76 -0.33    -1.24 2.67
## --------------------------------------------------------------------------- 
## group: Yes
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis  se
## X1    1 19 70.74 19.61     72   72.41 19.27  13 100    87 -1.07     1.52 4.5</code></pre>
<p>所以，血清維生素水平在女性，非吸菸者，和服用補充劑(廢話) 的人中較高。</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb189-2" title="2"><span class="kw">plot</span>(vitC<span class="op">$</span>age, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;age on study entry&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a>
<a class="sourceLine" id="cb189-3" title="3"><span class="kw">plot</span>(vitC<span class="op">$</span>weight, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;Clothed weight&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a>
<a class="sourceLine" id="cb189-4" title="4"><span class="kw">plot</span>(vitC<span class="op">$</span>height, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;Height&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:practicalfig1"></span>
<img src="bookdown_files/figure-html/practicalfig1-1.png" alt="Scatter plots between serum ascorbate and age/weight/height" width="80%" />
<p class="caption">
圖 30.1: Scatter plots between serum ascorbate and age/weight/height
</p>
</div>
<p>散點圖似乎沒有證據提示血清維生素 C 濃度和連續型變量，年齡，身高，體重之間有什麼相關性。</p>
<ol start="2" style="list-style-type: decimal">
<li>建立維生素 C 和其他預測變量的簡單線性迴歸模型，你有什麼結論？</li>
</ol>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>age, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ age, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.94 -18.98   5.82  16.67  46.52 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  113.104     59.511    1.90    0.061 .
## age           -0.864      0.858   -1.01    0.316  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.8 on 90 degrees of freedom
## Multiple R-squared:  0.0111, Adjusted R-squared:  0.000163 
## F-statistic: 1.01 on 1 and 90 DF,  p-value: 0.316</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>age, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 %   97.5 %
## (Intercept) -5.125 231.3335
## age         -2.568   0.8401</code></pre>
<p>血清維生素 C 濃度隨着年齡增加遞減，但是迴歸係數不具有統計學意義 (<span class="math inline">\(p=0.32\)</span>)。年齡每增加 1 歲，血清維生素平均下降 <span class="math inline">\(0.864 \:\mu\text{mol/L， 95% CI:} (-2.57, 0.840)\)</span>，</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>height, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ height, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.11 -19.81   5.76  17.94  48.29 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    115.9       41.2    2.81    0.006 **
## height         -37.8       25.0   -1.51    0.134   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.3 on 89 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.0251, Adjusted R-squared:  0.0141 
## F-statistic: 2.29 on 1 and 89 DF,  p-value: 0.134</code></pre>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>height, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 % 97.5 %
## (Intercept)  34.05 197.75
## height      -87.37  11.84</code></pre>
<p>血清維生素 C 濃度隨着身高增加遞減，但是迴歸係數不具有統計學意義 (<span class="math inline">\(p=0.134\)</span>)。身高每增加 1cm，血清維生素平均下降 <span class="math inline">\(0.378 \:\mu\text{mol/L， 95% CI:} (-0.874, 0.118)\)</span>，</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>cigs, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ cigs, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -47.14 -19.53   3.26  17.86  44.86 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    55.14       2.62   21.05   &lt;2e-16 ***
## cigsSmoker    -14.80       7.25   -2.04    0.044 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.4 on 90 degrees of freedom
## Multiple R-squared:  0.0442, Adjusted R-squared:  0.0336 
## F-statistic: 4.17 on 1 and 90 DF,  p-value: 0.0442</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>cigs, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 %  97.5 %
## (Intercept)  49.93 60.3417
## cigsSmoker  -29.21 -0.3945</code></pre>
<p>血清維生素 C 濃度與在吸菸人羣中較低，與不吸菸人羣相比，吸菸人羣的血清維生素 C 濃度平均低 <span class="math inline">\(14.8 \:\mu\text{mol/L， 95% CI:} (0.394, 29.2)\)</span>，這個濃度差具有臨界統計學意義 <span class="math inline">\((p=0.044)\)</span>。</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>weight, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ weight, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.71 -18.39   4.41  17.21  46.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 53.04017   12.90016    4.11  8.7e-05 ***
## weight       0.00967    0.18463    0.05     0.96    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.6 on 89 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  3.08e-05,   Adjusted R-squared:  -0.0112 
## F-statistic: 0.00274 on 1 and 89 DF,  p-value: 0.958</code></pre>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>weight, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##               2.5 %  97.5 %
## (Intercept) 27.4078 78.6725
## weight      -0.3572  0.3765</code></pre>
<p>維生素濃度和體重關係幾乎可以忽略 <span class="math inline">\((p=0.96)\)</span>。</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.73 -20.23   6.59  17.27  53.91 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    46.09       3.46   13.32   &lt;2e-16 ***
## sexWomen       13.64       4.79    2.85   0.0055 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23 on 90 degrees of freedom
## Multiple R-squared:  0.0826, Adjusted R-squared:  0.0724 
## F-statistic:  8.1 on 1 and 90 DF,  p-value: 0.00547</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##             2.5 % 97.5 %
## (Intercept) 39.22  52.97
## sexWomen     4.12  23.16</code></pre>
<p>血清維生素 C 濃度與在女性中較高，與男性相比，女性的血清維生素 C 濃度平均高 <span class="math inline">\(13.6 \:\mu\text{mol/L， 95% CI:} (4.12, 23.2)\)</span>，這個濃度差具有顯著統計學意義 <span class="math inline">\((p=0.005)\)</span>。</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ ctakers, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -57.74 -15.42   5.81  18.61  35.36 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    48.64       2.60   18.73  &lt; 2e-16 ***
## ctakersYes     22.09       5.72    3.87  0.00021 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.2 on 90 degrees of freedom
## Multiple R-squared:  0.142,  Adjusted R-squared:  0.133 
## F-statistic: 14.9 on 1 and 90 DF,  p-value: 0.000209</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##             2.5 % 97.5 %
## (Intercept) 43.48  53.80
## ctakersYes  10.74  33.45</code></pre>
<p>血清維生素 C 濃度與在服用補充劑的人中較高，與不服用補充劑的人相比，服用者的血清維生素 C 濃度平均高 <span class="math inline">\(22.1 \:\mu\text{mol/L， 95% CI:} (10.7, 33.4)\)</span>，這個濃度差具有顯著統計學意義 <span class="math inline">\((p=0.00021)\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>擬合一個多元線性迴歸模型，因變量爲血清維生素 C 濃度，預測變量使用 性別，吸菸狀態，和 是否服用維生素補充劑。解釋輸出結果的數字的含義。跟這些預測變量單獨和血清維生素 C 濃度建立的簡單線性迴歸模型作比較。說明哪些結果發生了改變，爲什麼。</li>
</ol>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.66 -19.07   2.24  17.62  38.03 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    44.97       3.55   12.69  &lt; 2e-16 ***
## sexWomen       10.66       4.51    2.36  0.02044 *  
## cigsSmoker    -11.57       6.66   -1.74  0.08586 .  
## ctakersYes     20.25       5.51    3.67  0.00041 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.3 on 88 degrees of freedom
## Multiple R-squared:  0.23,   Adjusted R-squared:  0.203 
## F-statistic: 8.74 on 3 and 88 DF,  p-value: 3.88e-05</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC)), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## sex        1   4270  4270.0  9.4354 0.0028320 ** 
## cigs       1   1497  1497.0  3.3080 0.0723454 .  
## ctakers    1   6102  6101.8 13.4831 0.0004125 ***
## Residuals 88  39824   452.5                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb218-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##               2.5 % 97.5 %
## (Intercept)  37.927 52.017
## sexWomen      1.687 19.630
## cigsSmoker  -24.799  1.666
## ctakersYes    9.291 31.211</code></pre>
<p>從這個多元線性迴歸的輸出報告來看，血清維生素 C 濃度</p>
<ul>
<li>在吸菸者中較低 <span class="math inline">\(-11.6 \:\mu\text{mol/L， 95% CI:} (-24.8, +1.67), p = 0.086\)</span>；</li>
<li>在女性中較高 <span class="math inline">\(+10.7 \:\mu\text{mol/L， 95% CI:} (1.69, 19.6), p = 0.020\)</span>；</li>
<li>在服用維生素補充劑的人中較高 <span class="math inline">\(+20.3 \:\mu\text{mol/L， 95% CI:} (9.29, 31.2), p = 0.0004\)</span>。</li>
</ul>
<p>故，本次數據告訴我們，服用維生素補充劑是最強的預測變量。在多元線性迴歸模型的結果中可以看到：</p>
<ul>
<li>性別之間維生素 C 濃度差變小了 (<span class="math inline">\(+13.6 \rightarrow +10.7\)</span>) <br> 這是因爲女性中有較多人服用維生素補充劑。即便如此，性別差在多元線性迴歸模型中仍然是有意義的。</li>
</ul>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Vitamin C taker&quot;</span>=ctakers, <span class="st">&quot;Gender&quot;</span> =<span class="st"> </span>sex), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(ctakers)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb220-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ---------------------------------- 
##           ---------Gender---------- 
##  Vitamin       Men   Women   Total  
##  C taker                            
##  ---------------------------------- 
##  No             37      36      73  
##              84.09   75.00   79.35  
##                                     
##  Yes             7      12      19  
##              15.91   25.00   20.65  
##                                     
##                                     
##  Total          44      48      92  
##             100.00  100.00  100.00  
##  ----------------------------------</code></pre>
<ul>
<li>吸菸與非吸菸者之間的維生素 C 濃度差也變小了 (<span class="math inline">\(-14.8 \rightarrow -11.6\)</span>)，因爲儘管吸菸與非吸菸者的維生素補充劑服用比例差不不大，但是吸菸者中大部分是男性。(詳見下表) <br> 吸菸者和非吸菸者之間維生素 C 濃度差經過多元線性迴歸調整後變得不再有統計學意義 <span class="math inline">\((p=0.086)\)</span>。</li>
</ul>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb222-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Vitamin C taker&quot;</span>=ctakers, <span class="st">&quot;Smoker&quot;</span> =<span class="st"> </span>cigs), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(ctakers)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb222-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ------------------------------------- 
##           -----------Smoker----------- 
##  Vitamin   Non-smoker  Smoker   Total  
##  C taker                               
##  ------------------------------------- 
##  No                63      10      73  
##                 78.75   83.33   79.35  
##                                        
##  Yes               17       2      19  
##                 21.25   16.67   20.65  
##                                        
##                                        
##  Total             80      12      92  
##                100.00  100.00  100.00  
##  -------------------------------------</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb224-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Gender&quot;</span> =<span class="st"> </span>sex, <span class="st">&quot;Smoker&quot;</span> =<span class="st"> </span>cigs), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(sex)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb224-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ------------------------------------ 
##          -----------Smoker----------- 
##  Gender   Non-smoker  Smoker   Total  
##  ------------------------------------ 
##  Men              36       8      44  
##                45.00   66.67   47.83  
##                                       
##  Women            44       4      48  
##                55.00   33.33   52.17  
##                                       
##                                       
##  Total            80      12      92  
##               100.00  100.00  100.00  
##  ------------------------------------</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>在前一個模型中加入年齡，身高，體重作爲新的預測變量。先解釋新的模型中報告的個數值的意義，利用方差分析表格比較兩個模型的差別 (先手計算，再用 R 計算確認你的答案)。</li>
</ol>
<p>由於身高體重有缺損值(serial=24)，所以要比較預測變量增加前後的模型，需要先把之前的模型中 serial=24 的觀察對象刪除掉才公平。</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC[<span class="op">-</span><span class="dv">24</span>,])</a>
<a class="sourceLine" id="cb226-2" title="2"><span class="kw">summary</span>(Model1);<span class="kw">anova</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC[-24, 
##     ])
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.79 -18.21   2.21  17.59  36.97 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    46.03       3.55   12.96  &lt; 2e-16 ***
## sexWomen        9.76       4.49    2.18  0.03228 *  
## cigsSmoker    -12.26       6.59   -1.86  0.06627 .  
## ctakersYes     19.83       5.45    3.64  0.00047 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21 on 87 degrees of freedom
## Multiple R-squared:  0.226,  Adjusted R-squared:  0.199 
## F-statistic: 8.46 on 3 and 87 DF,  p-value: 5.39e-05</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## sex        1   3689    3689    8.35 0.00486 ** 
## cigs       1   1679    1679    3.80 0.05440 .  
## ctakers    1   5841    5841   13.23 0.00047 ***
## Residuals 87  38418     442                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>weight <span class="op">+</span><span class="st"> </span>height, <span class="dt">data =</span> vitC[<span class="op">-</span><span class="dv">24</span>,])</a>
<a class="sourceLine" id="cb229-2" title="2"><span class="kw">summary</span>(Model2);<span class="kw">anova</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers + age + weight + 
##     height, data = vitC[-24, ])
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.56 -17.72   4.23  18.75  35.58 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   65.352     89.482    0.73  0.46722    
## sexWomen      10.367      7.285    1.42  0.15843    
## cigsSmoker   -11.800      6.757   -1.75  0.08444 .  
## ctakersYes    19.859      5.547    3.58  0.00057 ***
## age           -0.353      0.840   -0.42  0.67499    
## weight         0.107      0.223    0.48  0.63174    
## height        -1.573     42.259   -0.04  0.97040    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.3 on 84 degrees of freedom
## Multiple R-squared:  0.233,  Adjusted R-squared:  0.178 
## F-statistic: 4.25 on 6 and 84 DF,  p-value: 0.00088</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## sex        1   3689    3689    8.14 0.00546 ** 
## cigs       1   1679    1679    3.70 0.05767 .  
## ctakers    1   5841    5841   12.88 0.00056 ***
## age        1    205     205    0.45 0.50283    
## weight     1    133     133    0.29 0.58951    
## height     1      1       1    0.00 0.97040    
## Residuals 84  38079     453                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>利用偏 <span class="math inline">\(F\)</span> 檢驗的公式</p>
<p><span class="math display">\[
F=\frac{(205.2889295+132.9899543+0.6280691)/3}{38079.42/84} = 0.2492713
\]</span></p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb232-1" title="1"><span class="kw">anova</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: seruvitc ~ sex + cigs + ctakers
## Model 2: seruvitc ~ sex + cigs + ctakers + age + weight + height
##   Res.Df   RSS Df Sum of Sq    F Pr(&gt;F)
## 1     87 38418                         
## 2     84 38079  3       339 0.25   0.86</code></pre>
<p>所以檢驗統計量對應的 <span class="math inline">\(p=0.86\)</span> 告訴我們沒有證明據證明調整了性別，吸菸狀況，服用補充劑與否之後，增加的年齡，體重，身高作爲預測變量和觀察對象的血清維生素 C 濃度有關係。模型 2 比模型 1 不能解釋更多的模型殘差 (不比模型 1 更加擬合數據)。</p>
</div>
<div id="紅細胞容積與血紅蛋白" class="section level3">
<h3><span class="header-section-number">30.5.2</span> 紅細胞容積與血紅蛋白</h3>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.4: Data set of haemoglobin and PCV explained
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable name
</th>
<th style="text-align:left;">
content
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<code>hb</code>
</td>
<td style="text-align:left;">
Haemoglobin (gm/dl)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>pcv</code>
</td>
<td style="text-align:left;">
Pack cell volume %
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>age</code>
</td>
<td style="text-align:left;">
Age (years)
</td>
</tr>
<tr>
</tbody>
</table>
<ol start="5" style="list-style-type: decimal">
<li>把數據導入 R，並且建立因變量爲血紅蛋白，預測變量爲 PCV 和 年齡的多元線性迴歸模型</li>
</ol>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb234-2" title="2">haem &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/haem.dta&quot;</span>)</a>
<a class="sourceLine" id="cb234-3" title="3">psych<span class="op">::</span><span class="kw">describe</span>(haem)</a></code></pre></div>
<pre><code>##     vars  n  mean   sd median trimmed   mad  min  max range  skew kurtosis   se
## hb     1 12 12.53 1.70   12.8   12.56  1.70  9.6 15.1   5.5 -0.26    -1.39 0.49
## pcv    2 12 38.58 8.14   37.5   38.80 11.12 25.0 50.0  25.0 -0.10    -1.59 2.35
## age    3 12 32.75 8.98   31.5   32.40  9.64 20.0 49.0  29.0  0.31    -1.20 2.59</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(hb <span class="op">~</span><span class="st"> </span>pcv <span class="op">+</span><span class="st"> </span>age, <span class="dt">data =</span> haem)</a>
<a class="sourceLine" id="cb236-2" title="2"><span class="kw">summary</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = hb ~ pcv + age, data = haem)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -1.413 -1.002  0.302  0.662  1.867 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   5.0606     1.9680    2.57    0.030 *
## pcv           0.1056     0.0429    2.46    0.036 *
## age           0.1036     0.0389    2.66    0.026 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.15 on 9 degrees of freedom
## Multiple R-squared:  0.63,   Adjusted R-squared:  0.548 
## F-statistic: 7.65 on 2 and 9 DF,  p-value: 0.0114</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" title="1">haem<span class="op">$</span>e_hat &lt;-<span class="st"> </span>Model3<span class="op">$</span>residuals</a>
<a class="sourceLine" id="cb238-2" title="2">haem<span class="op">$</span>y_hat &lt;-<span class="st"> </span>Model3<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb238-3" title="3"><span class="kw">print</span>(haem)</a></code></pre></div>
<pre><code>## # A tibble: 12 x 5
##       hb   pcv   age  e_hat y_hat
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1  11.1    35    20  0.274  10.8
##  2  10.7    45    22 -1.39   12.1
##  3  12.4    47    25 -0.211  12.6
##  4  14      50    28  0.762  13.2
##  5  13.1    31    28  1.87   11.2
##  6  10.5    30    31 -0.938  11.4
##  7   9.6    25    32 -1.41   11.0
##  8  12.5    33    35  0.331  12.2
##  9  13.5    35    38  0.810  12.7
## 10  13.9    40    40  0.475  13.4
## 11  15.1    45    45  0.629  14.5
## 12  13.9    47    49 -1.20   15.1</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>利用 R 的矩陣計算重現迴歸模型的計算結果</li>
</ol>
<ul>
<li>計算因變量和兩個預測變量各自的和</li>
</ul>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" title="1">sumy &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb)</a>
<a class="sourceLine" id="cb240-2" title="2">sumx1 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>pcv)</a>
<a class="sourceLine" id="cb240-3" title="3">sumx2 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>age)</a></code></pre></div>
<ul>
<li>計算因變量和兩個預測變量各自的平方和</li>
</ul>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" title="1">sumy2 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>hb)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-2" title="2">sumx1y &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb<span class="op">*</span>haem<span class="op">$</span>pcv)</a>
<a class="sourceLine" id="cb241-3" title="3">sumx2y &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb<span class="op">*</span>haem<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb241-4" title="4">sumx12 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>pcv)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-5" title="5">sumx22 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>age)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-6" title="6">sumx1x2 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>pcv<span class="op">*</span>haem<span class="op">$</span>age)</a></code></pre></div>
<ul>
<li>生成一個數值爲 1 的變量，名爲 <code>one</code></li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" title="1">one &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">12</span>)</a></code></pre></div>
<ul>
<li>用 <code>matrix()</code> 命令生成矩陣</li>
</ul>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" title="1">Rownames &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb243-2" title="2"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>) {</a>
<a class="sourceLine" id="cb243-3" title="3">  a &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;row&quot;</span>, i, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb243-4" title="4">  Rownames &lt;-<span class="st"> </span><span class="kw">c</span>(Rownames,a); <span class="kw">rm</span>(a)</a>
<a class="sourceLine" id="cb243-5" title="5">  }</a>
<a class="sourceLine" id="cb243-6" title="6"></a>
<a class="sourceLine" id="cb243-7" title="7">Y &lt;-<span class="st"> </span><span class="kw">matrix</span>(haem<span class="op">$</span>hb ,<span class="dt">dimnames =</span> <span class="kw">list</span>(Rownames, <span class="st">&quot;hb&quot;</span>))</a>
<a class="sourceLine" id="cb243-8" title="8">Y</a></code></pre></div>
<pre><code>##         hb
## row1  11.1
## row2  10.7
## row3  12.4
## row4  14.0
## row5  13.1
## row6  10.5
## row7   9.6
## row8  12.5
## row9  13.5
## row10 13.9
## row11 15.1
## row12 13.9</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" title="1">X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(one, haem<span class="op">$</span>pcv, haem<span class="op">$</span>age), <span class="dt">nrow =</span> <span class="dv">12</span>, <span class="dt">dimnames =</span> <span class="kw">list</span>(Rownames, <span class="kw">c</span>(<span class="st">&quot;one&quot;</span>, <span class="st">&quot;pcv&quot;</span>, <span class="st">&quot;age&quot;</span>)))</a>
<a class="sourceLine" id="cb245-2" title="2">X</a></code></pre></div>
<pre><code>##       one pcv age
## row1    1  35  20
## row2    1  45  22
## row3    1  47  25
## row4    1  50  28
## row5    1  31  28
## row6    1  30  31
## row7    1  25  32
## row8    1  33  35
## row9    1  35  38
## row10   1  40  40
## row11   1  45  45
## row12   1  47  49</code></pre>
<ul>
<li>用公式 <a href="04-Linear-Regression.html#eq:lm5-4">(30.4)</a> 計算估計 <span class="math inline">\(\mathbf{\hat\beta}\)</span> 矩陣</li>
</ul>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb247-1" title="1">XX &lt;-<span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X <span class="co"># these are the sum of squares of each variable and the sum of the cross products of the pairs of variables</span></a>
<a class="sourceLine" id="cb247-2" title="2">XX</a></code></pre></div>
<pre><code>##     one   pcv   age
## one  12   463   393
## pcv 463 18593 15276
## age 393 15276 13757</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb249-1" title="1">(<span class="kw">data.frame</span>(sumx1,sumx12,sumx2,sumx22, sumx1x2))</a></code></pre></div>
<pre><code>##   sumx1 sumx12 sumx2 sumx22 sumx1x2
## 1   463  18593   393  13757   15276</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb251-1" title="1">XY &lt;-<span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y <span class="co"># this is the cross-product matrix of predictors against outcome</span></a>
<a class="sourceLine" id="cb251-2" title="2">XY</a></code></pre></div>
<pre><code>##         hb
## one  150.3
## pcv 5887.7
## age 5026.0</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" title="1">(<span class="kw">data.frame</span>(sumy, sumx1y, sumx2y))</a></code></pre></div>
<pre><code>##    sumy sumx1y sumx2y
## 1 150.3   5888   5026</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb255-1" title="1">betahat &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X ) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y</a>
<a class="sourceLine" id="cb255-2" title="2">betahat</a></code></pre></div>
<pre><code>##         hb
## one 5.0606
## pcv 0.1056
## age 0.1036</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" title="1"><span class="co">###or equivalently you can use</span></a>
<a class="sourceLine" id="cb257-2" title="2">betahat &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">crossprod</span>(X) ) <span class="op">%*%</span><span class="st"> </span><span class="kw">crossprod</span>( X, Y )</a>
<a class="sourceLine" id="cb257-3" title="3">betahat</a></code></pre></div>
<pre><code>##         hb
## one 5.0606
## pcv 0.1056
## age 0.1036</code></pre>
<p>可以看到 <code>betahat</code> 的結果和多元迴歸模型輸出的迴歸係數估計是一致的。</p>
<ul>
<li>計算擬合值</li>
</ul>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" title="1">Fitted &lt;-<span class="st"> </span>X<span class="op">%*%</span>betahat</a>
<a class="sourceLine" id="cb259-2" title="2">Fitted</a></code></pre></div>
<pre><code>##          hb
## row1  10.83
## row2  12.09
## row3  12.61
## row4  13.24
## row5  11.23
## row6  11.44
## row7  11.01
## row8  12.17
## row9  12.69
## row10 13.43
## row11 14.47
## row12 15.10</code></pre>
<ul>
<li>估計迴歸係數的方差協方差矩陣</li>
</ul>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb261-1" title="1">e_hat &lt;-<span class="st"> </span>Y<span class="op">-</span>Fitted <span class="co"># residuals</span></a>
<a class="sourceLine" id="cb261-2" title="2">e_hat</a></code></pre></div>
<pre><code>##            hb
## row1   0.2736
## row2  -1.3892
## row3  -0.2110
## row4   0.7616
## row5   1.8674
## row6  -0.9377
## row7  -1.4134
## row8   0.3314
## row9   0.8096
## row10  0.4747
## row11  0.6291
## row12 -1.1962</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb263-1" title="1">SSres &lt;-<span class="st"> </span><span class="kw">t</span>(e_hat) <span class="op">%*%</span><span class="st"> </span>e_hat <span class="co"># residual sum of squares</span></a>
<a class="sourceLine" id="cb263-2" title="2">SSres</a></code></pre></div>
<pre><code>##       hb
## hb 11.81</code></pre>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" title="1">Sigma2 &lt;-<span class="st"> </span>SSres <span class="op">%*%</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>(<span class="dv">12</span><span class="op">-</span>(<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>))) <span class="co"># residual variance</span></a>
<a class="sourceLine" id="cb265-2" title="2">Sigma2</a></code></pre></div>
<pre><code>##     [,1]
## hb 1.312</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" title="1"><span class="co"># multiply the inverse of the cross-product matrix for the predictors</span></a>
<a class="sourceLine" id="cb267-2" title="2"><span class="co"># by the residual variance to get the variance-covariance matrix of</span></a>
<a class="sourceLine" id="cb267-3" title="3"><span class="co"># the coefficients</span></a>
<a class="sourceLine" id="cb267-4" title="4">V &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">crossprod</span>(X) ) <span class="op">*</span><span class="st"> </span><span class="kw">as.numeric</span>(Sigma2)</a>
<a class="sourceLine" id="cb267-5" title="5">V</a></code></pre></div>
<pre><code>##          one        pcv        age
## one  3.87296 -0.0632072 -0.0404537
## pcv -0.06321  0.0018365 -0.0002336
## age -0.04045 -0.0002336  0.0015105</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" title="1"><span class="co"># the square root of the diagonal terms in the above matrix are the standard errors shown in the regression output</span></a>
<a class="sourceLine" id="cb269-2" title="2"><span class="kw">sqrt</span>(<span class="kw">diag</span>(V))</a></code></pre></div>
<pre><code>##     one     pcv     age 
## 1.96798 0.04285 0.03887</code></pre>
</div>
</div>
</div>
<div id="線性迴歸的模型診斷" class="section level1">
<h1><span class="header-section-number">第 31 章</span> 線性迴歸的模型診斷</h1>
<p>和其他的統計學模型一樣，線性迴歸也有自己的前提條件，而且從模型結果作出的各種推斷都依賴這些前提條件的成立。所以，我們需要有一些統計學的手段來檢查線性迴歸模型中這些前提是否得到滿足。然而理想總是很豐滿，現實通常又太骨感。你不大可能找到一組真實的數據能夠 100% 完美的滿足所需要的前提條件。當然不是說不能滿足模型的前提條件，我們就無法進行統計推斷了。而且我們也有不少結果穩健 (robust) 的統計學手段，讓我們可以不必考慮太多前提條件。檢查數據，瞭解數據內容，理解數據本身的結構永遠都是有助於數據分析的。</p>
<p>還要記得一點就是，根據中心極限定理，(即使有一些前提假設不能成立) 大型數據分析結果的穩健性/可靠性，要高於小型數據的分析。</p>
<div id="線性迴歸模型的前提條件" class="section level2">
<h2><span class="header-section-number">31.1</span> 線性迴歸模型的前提條件</h2>
<ol style="list-style-type: decimal">
<li>因變量和各個預測變量之間的關係都是線性 linear relationship 的；</li>
<li>因變量之間相互獨立；</li>
<li>真實 <strong>true</strong> 殘差的方差是恆定不變的 constant。這裏的含義是在真實迴歸直線上下散佈的因變量的點，在任意一個預測變量值的位置的方差 (分散) 要保持恆定不變。這個特性被描述成方差齊性 homoscedasticity (殘差方差的一致性 homogeneity of the residual variance)，與之相對的定義是異方差性 heteroscedasticity (殘差方差的不同質性，heterogeneity of the residual variance)。</li>
<li>真實殘差服從正態分佈。(儘管你發現統計忍者包裏丟入隨便什麼數據都能給你個線性迴歸的報告來，但是，如果你真想用其結果做統計推斷，p CI 的話，這條前提必須滿足。)</li>
</ol>
<p>本章着重討論第 1，3，4 前提條件的診斷法。因爲觀測數據之間是否獨立性 (第 2 條) 並不是你光盯着數據看就能知道的。你要去問給你數據的 (沒良心的) 人。</p>
</div>
<div id="用圖形來視覺診斷" class="section level2">
<h2><span class="header-section-number">31.2</span> 用圖形來視覺診斷</h2>
<div class="figure" style="text-align: center"><span id="fig:fig6-1"></span>
<img src="img/Selection_109.png" alt="Illustration the usefullness of scatter plots of the dependent variable against the predictor variable in simple linear regression" width="80%" />
<p class="caption">
圖 31.1: Illustration the usefullness of scatter plots of the dependent variable against the predictor variable in simple linear regression
</p>
</div>
<p>圖 <a href="04-Linear-Regression.html#fig:fig6-1">31.1</a> 中展示了四種實例。把預測變量和因變量做散點圖，這常常是甄別出異方差性 (Example C)，非線性 (Example A)，異常值 (Example D) 的最好方法。其中右上角的 Example B 是良好的迴歸模型的散點圖應該有的樣子。</p>
<p>建議進行視覺判斷的時候把擬合曲線去掉再作一次，看看有迴歸直線和沒有迴歸直線前後的散點圖差別，更容易看出數據的分佈特徵。但是光看散點圖作判斷的方法，在多元線性迴歸模型中只能看看能否找到一些異常值，對輔助判斷方差齊性和線性關係就沒有太大的用處。殘差點圖就更加實用。</p>
</div>
<div id="殘差圖" class="section level2">
<h2><span class="header-section-number">31.3</span> 殘差圖</h2>
<p>如果線性迴歸模型的前提條件能夠得到滿足，那麼擬合模型後的殘差，一定會服從正態分佈且方差均勻一致。所以另一個診斷異方差性的辦法可以通過作觀察殘差和擬合值之間的散點圖來輔助判斷。下圖 <a href="04-Linear-Regression.html#fig:fig6-2">31.2</a> 是各個簡單線性迴歸擬合後的<strong>殘差和擬合值</strong>之間的散點圖。可以看出左下角的 Example C 的異方差性展現得更加明顯了。同樣此圖也能幫助判斷線性關係，如左上角的 Example A 所示，如果預測變量和因變量之間不是線性關係，那麼殘差就不可能均勻的分佈在 <span class="math inline">\(0\)</span> 的兩側。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-2"></span>
<img src="img/Selection_111.png" alt="Plots of residuals agianst fitted values for the examples in the previous figure" width="80%" />
<p class="caption">
圖 31.2: Plots of residuals agianst fitted values for the examples in the previous figure
</p>
</div>
<p>對於一個簡單線性迴歸模型來說，擬合值僅僅只是預測變量的一個線性數學轉換，所以上面圖中的殘差和擬合值的散點圖，其實等價於殘差和預測變量的散點圖。所以圖 <a href="04-Linear-Regression.html#fig:fig6-1">31.1</a> 和圖 <a href="04-Linear-Regression.html#fig:fig6-2">31.2</a> 兩圖展現的信息量此時是一樣的。</p>
<p>但是，多元線性迴歸時，殘差和擬合值的散點圖會比殘差和預測變量散點圖更適合判斷異方差性，和線性關係的假設。</p>
</div>
<div id="殘差正態圖-normal-plot-of-residuals" class="section level2">
<h2><span class="header-section-number">31.4</span> 殘差正態圖 normal plot of residuals</h2>
<p>正態圖在分析技巧的章節也有介紹 (Section <a href="03-Analytic-Technique.html#normalplot">25.2.1</a>)。這是最佳的判斷數據是否服從正態分佈的視覺圖。所以用它來繪製線性迴歸擬合後的殘差，是個很好的辦法。可惜的是殘差正態圖無法用於判斷異方差性，和線性關係兩個假設。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-3"></span>
<img src="img/Selection_112.png" alt="Normal plots of residuals for the examples in the previous figure" width="80%" />
<p class="caption">
圖 31.3: Normal plots of residuals for the examples in the previous figure
</p>
</div>
<p>有時後觀察殘差 (observed residuals) 可能不能滿足齊方差性質而真實殘差 (true residuals) 反而滿足。所以一些統計學家建議把計算的殘差標準化 (standardised residuals) 以後再作正態圖。</p>
<div id="模型診斷實例" class="section level3">
<h3><span class="header-section-number">31.4.1</span> 模型診斷實例</h3>
<p>前面建立過的兒童體重和年齡，身長之間的多元迴歸模型的診斷 (Section <a href="04-Linear-Regression.html#globalsig">30.3.3</a>) 見下圖。所有四個圖都沒有證據證明非線性關係和異方差性。看不見顯著的異常值。正態圖看出殘差有那麼一點點不太正態分佈，但是不嚴重到讓人懷疑模型給出的推斷是否受到重大影響。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-4"></span>
<img src="bookdown_files/figure-html/fig6-4-1.png" alt="Residual plots for the linear regression relating a child's weight to their age and length" width="100%" />
<p class="caption">
圖 31.4: Residual plots for the linear regression relating a child’s weight to their age and length
</p>
</div>
</div>
</div>
<div id="前提條件的統計學檢驗" class="section level2">
<h2><span class="header-section-number">31.5</span> 前提條件的統計學檢驗</h2>
<div id="二次方程迴歸法檢驗非線性" class="section level3">
<h3><span class="header-section-number">31.5.1</span> 二次方程迴歸法檢驗非線性</h3>
<p>二次方程迴歸法是一種多元迴歸模型，它包含了兩個預測變量，一個是另一個的平方。數學模型可以標記成爲：</p>
<p><span class="math display" id="eq:lm6-1">\[
\begin{aligned}
y_i &amp; = \alpha + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i \\
\text{Where } &amp; \varepsilon_i \sim \text{NID}(0, \sigma^2)
\end{aligned}
\tag{31.1}
\]</span></p>
<p>儘管你看到了二次方程在這裏，但是這仍然是一個線性迴歸模型。但是二次方程的迴歸模型描述的是 <span class="math inline">\(Y, X\)</span> 兩個變量之間的非線性關係。如果你把方程 <span class="math inline">\(\hat{y}_i = \hat\alpha + \hat\beta_1x_i + \hat\beta_2x^2_i\)</span> 對 <span class="math inline">\(x_i\)</span> 求微分，你會得到 <span class="math inline">\(\hat\beta_1+2\hat\beta_2 x_i\)</span>。這是二次方程的曲率方程。所以如果結果中報告 <span class="math inline">\(\hat\beta_2\)</span> 是有統計學意義的，就等於是有證據證明這兩個變量之間的關係不是線性的。</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb271-1" title="1">growgam1<span class="op">$</span>age2 &lt;-<span class="st"> </span>(growgam1<span class="op">$</span>age)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb271-2" title="2">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb271-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.20525 -0.64402 -0.00303  0.55967  2.86277 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.351244   1.259968 -6.6281 3.531e-10 ***
## age         -0.011260   0.016751 -0.6722    0.5023    
## len          0.237129   0.019516 12.1502 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9546 on 187 degrees of freedom
## Multiple R-squared:  0.74337,    Adjusted R-squared:  0.74063 
## F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb273-1" title="1"><span class="kw">print</span>(<span class="kw">summary</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len + age + age2, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.30561 -0.64811 -0.01615  0.54829  2.74233 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.5918429  1.2537775 -6.8528 1.031e-10 ***
## len          0.2514685  0.0205039 12.2644 &lt; 2.2e-16 ***
## age         -0.1110198  0.0502050 -2.2113   0.02823 *  
## age2         0.0023351  0.0011091  2.1055   0.03659 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9459 on 186 degrees of freedom
## Multiple R-squared:  0.74935,    Adjusted R-squared:  0.74531 
## F-statistic: 185.36 on 3 and 186 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>正如上面的二次方程模型輸出結果所示，年齡和體重之間，當調整了身高以後，有證據 (但是較弱) 證明不呈現線性關係 <span class="math inline">\((p=0.037)\)</span>。</p>
</div>
<div id="非線性關係模型" class="section level3">
<h3><span class="header-section-number">31.5.2</span> 非線性關係模型</h3>
<p>二次方程的迴歸模型的應用在非線性模型中的應用其實有許許多多的缺陷。例如二次方程迴歸只能默認有一個極致點。也就是在二次方程模型中，預測變量和因變量的關係要麼是先下降後升高，要麼是先升高再下降。不光如此，二次方程迴歸還默認二者之間的關係在極致點是左右對稱的。這無論如何在現實中都很難有成這樣關係的兩個變量。所以，假如你使用二次方程模型迴歸之後發現非線性的證據是有意義的，那麼更好的辦法是接下來擬合一個更加符合實際情況的非線性模型-多項式曲線迴歸模型。</p>
<p>二次方程回顧模型是多項式曲線迴歸模型的最簡單形式，其次是三次方程模型 (其實就是在公式 <a href="04-Linear-Regression.html#eq:lm6-1">(31.1)</a> 裏面加一個 <span class="math inline">\(+\beta_3 x_i^3\)</span>)。另一種更加靈活的模型是擬合一個精確的分段式多項式模型，即允許在不同範圍 (被描述爲 “結點 knots”) 的預測變量 <span class="math inline">\(X\)</span> 內擬合不同的模型。其中一種叫做 <strong>限制性立方曲線模型</strong> restricted cubic spline model (<a href="http://wangcc.me/publication/hpylorimeta/">點這裏看我用了這種方法的論文</a>)：</p>
<ol style="list-style-type: decimal">
<li>默認第一個節點之前和最後一個節點以後爲直線模型；</li>
<li>其餘節點之間默認用三次方迴歸模型擬合數據；</li>
<li>在節點處的兩個方程之間用平滑的曲線連接 (強制兩個方程的一階二階導數相等即可 constraining the first and second derivatives of adjacent functions to agree when they meet at the knot point)</li>
</ol>
</div>
</div>
<div id="異常值槓桿值和庫克距離" class="section level2">
<h2><span class="header-section-number">31.6</span> 異常值，槓桿值，和庫克距離</h2>
<p>觀測值中的異常值很顯然對模型的擬合會有較大的影響。如果某個觀測值對應的擬合值是異常值的話，那麼這樣的值被認爲槓桿值很大。庫克距離 (Cook’s Distance) 是另一種用來衡量異常值的手段。</p>
<div id="standardres" class="section level3">
<h3><span class="header-section-number">31.6.1</span> 異常值和標準化殘差</h3>
<p>異常值指的是那些通過模型擬合過後，觀測值和擬合值差異很大的那些觀察對象。這些值需要被甄別出來因爲它們</p>
<ol style="list-style-type: decimal">
<li>可能是數據錄入階段造成的人爲失誤，或者是有什麼別的原因導致的系統性異常需要讓輸入數據的人員進行進一步的調查；</li>
<li>異常值可能較大的影響迴歸係數的方差估計，造成不精確甚至錯誤的結果；</li>
<li>異常值也會影響迴歸係數本身的估計。</li>
</ol>
<p>觀測值和擬合值之間的差，被命名爲觀測殘差 (observed residuals)。線性迴歸模型的前提之一是 <strong>真實殘差</strong> 獨立且方差維持恆定不變。但是<strong>觀測殘差卻無可能做到獨立且方差恆定不變</strong>。</p>
<p>之所以說觀測殘差不是獨立的，可以這樣來理解：假如擬合某個線性迴歸模型，預測變量是二分類的，且其中一個分類只有兩個觀測值，那麼擬合的直線會通過這兩個觀測值的中心點 (均值)，那麼這兩個觀測值的觀測殘差就恰好分佈在迴歸直線的兩側 (相加之和爲零，呈完美負相關)，它們是<strong>相關的</strong>！！！</p>
<p>觀測殘差的方差不可能恆定的理由，可以這樣來理解：同樣假如擬合某個預測變量是二分類的線性迴歸模型，其中一個分類只有一個觀測值，那麼迴歸直線在這個觀測值處的殘差方差是零。</p>
<p>標準化殘差 (standardized residuals) <span class="math inline">\((r_i)\)</span>，被定義爲每個觀測值的殘差和模型估計的殘差標準誤相除獲得的數據。所以符合前提條件的線性模型擬合後，計算的標準化殘差會服從標準正態分佈。從標準正態分佈的知識你也應該知道，<strong><span class="math inline">\(95\%\)</span> 的觀測值的標準化殘差必須分佈在數值 <span class="math inline">\(-2, 2\)</span> 範圍內</strong>。另外一種標準化殘差的方法叫做<strong>內學生化殘差 (studentised residual)</strong>。內學生化殘差是把觀測值的殘差除以每一個觀測值各自的估計標準誤。在 R 裏面可以通過 <code>rstandard()</code> 命令計算迴歸模型每個觀測值的內學生化殘差。<strong>內學生化殘差也是服從標準正態分佈的</strong>。</p>
</div>
<div id="槓桿值-leverage" class="section level3">
<h3><span class="header-section-number">31.6.2</span> 槓桿值 Leverage</h3>
<p>如果一個觀測值的擬合值十分極端，那麼該觀測值本身可能對迴歸模型的參數估計影響很大。這個影響程度大小用槓桿值衡量。簡單線性迴歸時，每個觀測值的槓桿值計算公式爲：</p>
<p><span class="math display" id="eq:lm6-4">\[
\begin{aligned}
l_i = \frac{1}{n} + \frac{x_i-\bar{x}}{SS_{xx}}
\end{aligned}
\tag{31.2}
\]</span></p>
<p>槓桿值的範圍是 <span class="math inline">\(\frac{1}{n}, 1\)</span> 之間。槓杆值方程提示這是一個單調函數，它是評價預測變量本身到該變量均值之間距離的指標。槓桿值越大，該觀測值就有越大的可能性對模型擬合造成影響。如果槓桿值大到等於 <span class="math inline">\(1\)</span>，那麼槓桿效應造成的影響極大，觀測值和擬合值就完全一致。意味着在這個觀測值附近，只有它自己，沒有其他觀測值。</p>
<p>(2018-05-14 嘗試過去試題 2014 Paper 2-Q2 時發現槓杆值的問題，在此繼續增加關於多元現行回歸中槓杆值的性質。)</p>
<p>多元線性迴歸時的槓桿值計算公式和 <a href="04-Linear-Regression.html#eq:lm5-7">(30.7)</a> 中的帽子矩陣 <span class="math inline">\(\mathbf{P}\)</span> 有關：</p>
<p><span class="math display" id="eq:lm6-5">\[
\begin{aligned}
 &amp; l_i = \mathbf{P}_{ii} \text{ The } i\text{ th diagonal element of } \\
 &amp; \mathbf{X(X^\prime X)^{-1}X^\prime}
\end{aligned}
\tag{31.3}
\]</span></p>
<p>In multiple regression, leverage measures “distance” from the centre of the joint distribution of the predecitor variables, but with distance scaled by the directional degree of dispersion. Notice that the point with largest leverage would not have particularly high leverage in either simple linear regression models including only one of the two (or more) predictor variables. Further this point would not be readily identified in plots of each of the predictor variables against the dependent variable. The value of measures such as the leverage is greatest in complex multiple regression models where it can be difficult to identify points with an atypical (非典型) combination of predictor variables using more simple graphical techniques.</p>
</div>
<div id="庫克距離-cooks-distance" class="section level3">
<h3><span class="header-section-number">31.6.3</span> 庫克距離 Cook’s Distance</h3>
<p>當通過計算觀測值的槓桿值之後，發現具有較大槓桿值的那些觀測點，應該被視爲對模型的穩定性有<strong>“潛在威脅”</strong>。此時就輪到庫克距離的登場。庫克距離可以用來衡量一個觀測值對模型的影響大小 (比較把觀測值移除出模型前後的模型變化)。</p>
<p>對於一個有 <span class="math inline">\(p\)</span> 個預測變量的迴歸模型來說，如果殘差方差的估計值爲 <span class="math inline">\(\hat\sigma^2\)</span>，那麼第 <span class="math inline">\(i\)</span> 個觀測值的庫克距離的計算過程就是把該觀測值移除，重新擬合相同的模型，計算獲得該點做的新的擬合值 <span class="math inline">\(\hat y_{j(i)}\)</span>：</p>
<p><span class="math display" id="eq:lm6-6">\[
\begin{aligned}
D_i = \frac{\sum^n_{j=1}(\hat y_{j(i)} - \hat y_j)^2}{(p+1)\hat\sigma^2}
\end{aligned}
\tag{31.4}
\]</span></p>
<p>可以被證明的是，庫克距離其實是結合標準化殘差值 <span class="math inline">\((r_i)\)</span>，和槓桿值 <span class="math inline">\((l_i)\)</span> 的一個綜合量：</p>
<p><span class="math display" id="eq:lm6-7">\[
\begin{aligned}
D_i &amp; = \frac{\sum^n_{j=1}(\hat y_{j(i)} - \hat y_j)^2}{(p+1)\hat\sigma^2} \\
    &amp; = \frac{r^2_il_i}{(p+1)(1-l_i)}
\end{aligned}
\tag{31.5}
\]</span></p>
<p>所以從庫克距離和標準化殘差，以及槓桿值之間的關係公式 <a href="04-Linear-Regression.html#eq:lm6-7">(31.5)</a> 也可以看出，當槓桿值大同時標準化殘差值的絕對值也大的觀測值，庫克距離就會很大。用線性迴歸時，把每個觀測值得庫克距離和擬合值作散點圖，或者把槓桿值和標準化殘差作散點圖是常用的判斷異常值的手段。</p>
</div>
</div>
<div id="在統計忍者包裏面對模型診斷作圖" class="section level2">
<h2><span class="header-section-number">31.7</span> 在統計忍者包裏面對模型診斷作圖</h2>
<p>擬合好了一個線性迴歸模型以後，<code>plot(Modelname)</code> 即可看到四個診斷圖 (Section <a href="04-Linear-Regression.html#diagnosis">26.8.5</a>)。</p>
</div>
</div>
<div id="interaction" class="section level1">
<h1><span class="header-section-number">第 32 章</span> 交互作用 Interactions</h1>
<p>線性迴歸部分目前爲止我們討論過如何用多元迴歸模型來控制 (或調整) 特定的預測變量 <span class="math inline">\((X)\)</span> 之外的變量。多元迴歸的目的之一是爲了估計預測變量和因變量之間的迴歸係數的同時，保持其他 (想要被調整的) 變量不變。如此一來，其實等於是假定了無論其餘的調整變量取值如何，<span class="math inline">\(X,Y\)</span> 之間的迴歸係數<strong>總是相同</strong> (繪製的迴歸線是一組平行線)。本章討論的交互作用，就是探討其中某個變量<strong>改變了 <span class="math inline">\(X,Y\)</span> 之間的關係 (modification effect)</strong> 的情況。放寬了之前強制所有直線都平行的限制，探討兩個變量之間的線性關係是否因爲某個變量而發生了質的改變。這樣的關係，在流行病學中被定義爲 <strong>交互作用 interaction</strong>。</p>
<p>本站會探討如何利用線性迴歸模型分析交互作用，如何理解並解釋統計忍者包輸出的報告結果的意義。具體涉及的例子爲：兩個連續型變量，兩個分類型變量，以及一個連續型，一個分類型變量之間的關係的交互作用。</p>
<div id="兩個預測變量之間的線性模型交互作用" class="section level2">
<h2><span class="header-section-number">32.1</span> 兩個預測變量之間的線性模型交互作用</h2>
<div id="交互作用線性模型的一般表達式" class="section level3">
<h3><span class="header-section-number">32.1.1</span> 交互作用線性模型的一般表達式</h3>
<p>假如準備擬合的模型是一個因變量 <span class="math inline">\(Y\)</span>，兩個預測變量 <span class="math inline">\(X_1, X_2\)</span>。同時模型考慮根據 <span class="math inline">\(X_2\)</span> 的值，<span class="math inline">\(X_1, Y\)</span> 之間關係的迴歸係數可以不相等 (直線的斜率不同，即會出現兩條相交的迴歸直線)。這樣的模型其實只要在原有的兩個預測變量的迴歸線性模型中增加一個新的預測變量，新的預測變量是 <span class="math inline">\(X_1, X_2\)</span> 的乘積即可。很簡單，不是麼？</p>
<p><span class="math display" id="eq:lm7-1">\[
\begin{aligned}
y_i  &amp; = \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i} + \varepsilon_i \\
\text{Where, } &amp; \varepsilon_i \sim \text{NID}(0,\sigma^2) \\
y_i  &amp; = \text{value of the dependent variable} \\
x_{1i} &amp; = \text{value of the first predictor variable} \\
x_{2i} &amp; = \text{value of the second predictor variable} \\
x_{3i} &amp; = x_{1i} \times x_{2i} \\
\end{aligned}
\tag{32.1}
\]</span></p>
<p>爲什麼增加一個 <span class="math inline">\(X_1\times X_2\)</span> 就能夠分析交互作用呢 (不同直線的斜率)？ 要理解其中的奧妙，我們可以這樣來理解：當像普通的線性迴歸模型那樣調整了 <span class="math inline">\(X_2\)</span> 之後，也就是當 <span class="math inline">\(X_2\)</span> 固定不變時 <span class="math inline">\((X_2=k)\)</span>，迴歸方程 <a href="04-Linear-Regression.html#eq:lm7-1">(32.1)</a>，就變成了：</p>
<p><span class="math display" id="eq:lm7-2">\[
\begin{equation}
y_i  = (\alpha + \beta_2 k) + (\beta_1 + \beta_3 k)x_{1i} + \varepsilon_i
\end{equation}
\tag{32.2}
\]</span></p>
<p>此時的 <span class="math inline">\(X_1\)</span> 的斜率從 <span class="math inline">\(\beta_1\)</span> 變成了 <span class="math inline">\((\beta_1 + \beta_3 k)\)</span>，截距從 <span class="math inline">\(\alpha\)</span> 變成了 <span class="math inline">\((\alpha + \beta_2 k)\)</span>。</p>
</div>
<div id="interaction-cont-bin" class="section level3">
<h3><span class="header-section-number">32.1.2</span> 連續型變量和二分類變量之間的交互作用</h3>
<p>一個連續型變臉一個二分類變量的交互作用迴歸方程十分容易理解 (利用啞變量建立模型)：</p>
<p><span class="math display" id="eq:lm7-4">\[
\begin{array}{ll}
y_i  = \alpha + \beta_1 x_1i + \varepsilon_i  &amp;   \text{ when } X_2 = 0 \\
y_i  = (\alpha + \beta_2) + (\beta_1+\beta_3)x_{1i} + \varepsilon_i &amp; \text{ when } X_2 =1
\end{array}
\tag{32.3}
\]</span></p>
<p>所以，<span class="math inline">\(X_2\)</span> 取零 或者 取 <span class="math inline">\(1\)</span> 代表了不同的分組，上面的迴歸方程就可以擬合 <span class="math inline">\(Y, X_1\)</span> 在 <span class="math inline">\(X_2\)</span> 的兩組中不同截距，不同斜率的兩條直線。其中各個參數估計，用人話來解釋就是：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\alpha\)</span> 是當 <span class="math inline">\(X_2 = 0\)</span> 時的<strong>截距</strong>；</li>
<li><span class="math inline">\(\alpha + \beta_2\)</span> 是當 <span class="math inline">\(X_2 = 1\)</span> 時的截距，所以 <span class="math inline">\(\beta_2\)</span> 就是二分類預測變量 <span class="math inline">\(X_2\)</span> 的兩組之間<strong>截距的差</strong>；</li>
<li><span class="math inline">\(\beta_1\)</span> 是當 <span class="math inline">\(X_2 = 0\)</span> 時的<strong>斜率</strong>；</li>
<li><span class="math inline">\((\beta_1+\beta_3)\)</span> 是當 <span class="math inline">\(X_2 = 1\)</span> 時的截距，所以 <span class="math inline">\(\beta_3\)</span> 就是二分類預測變量 <span class="math inline">\(X_2\)</span> 的兩組之間<strong>斜率的差</strong>。</li>
</ol>
</div>
<div id="兩個二分類變量之間的交互作用" class="section level3">
<h3><span class="header-section-number">32.1.3</span> 兩個二分類變量之間的交互作用</h3>
<p>當兩個預測變量都是二分類變量時，可以用兩個啞變量來編碼各自的分組，擬合下面的迴歸模型：</p>
<p><span class="math display" id="eq:lm7-5">\[
\begin{array}{lll}
y_i = \alpha + \varepsilon_i   &amp;  \text{ when } X_1 = 0 \&amp; X_2 = 0  &amp; \mu_{00} \\
y_i = \alpha + \beta_1 + \varepsilon_i &amp; \text{ when } X_1 = 1 \&amp; X_2 =0  &amp; \mu_{10} \\
y_i = \alpha + \beta_2 + \varepsilon_i &amp; \text{ when } X_1 = 0 \&amp; X_2 =1  &amp; \mu_{01} \\
y_i = \alpha + \beta_1 + \beta_2+ \beta_3 + \varepsilon_i &amp; \text{ when } X_1 = 1 \&amp; X_2 = 1 &amp; \mu_{11}
\end{array}
\tag{32.4}
\]</span></p>
<p>如果用 <span class="math inline">\(\mu_{ij}\)</span> 表示 <span class="math inline">\(X_1 = i, X_2 = j\)</span> 時的總體均值 (population mean)，那麼模型 <a href="04-Linear-Regression.html#eq:lm7-5">(32.4)</a> 各個參數估計及其意義爲：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\alpha\)</span> 是當 <span class="math inline">\(X_1 = 0, \&amp; X_2 = 0\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\((\mu_{00})\)</span>；</li>
<li><span class="math inline">\(\alpha+\beta_1\)</span> 是當 <span class="math inline">\(X_1 = 1 \&amp; X_2 = 0\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\(\mu_{10}\)</span>，所以 <span class="math inline">\(\beta_1\)</span> 是 <span class="math inline">\(X_2 = 0\)</span> 時 <span class="math inline">\(X_1\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差，<span class="math inline">\(\mu_{10}-\mu_{00}\)</span>；</li>
<li><span class="math inline">\(\alpha+\beta_2\)</span> 是當 <span class="math inline">\(X_1 = 0 \&amp; X_2 = 1\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\(\mu_{01}\)</span>，所以 <span class="math inline">\(\beta_2\)</span> 是 <span class="math inline">\(X_1 = 0\)</span> 時 <span class="math inline">\(X_2\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差，<span class="math inline">\(\mu_{01}-\mu_{00}\)</span>；</li>
<li><span class="math inline">\(\alpha + \beta_1 + \beta_2 + \beta_3\)</span> 是當 <span class="math inline">\(X_1 = 1 \&amp; X_2 = 1\)</span> 時的均值估計 <span class="math inline">\(\mu_{11}\)</span>，所以 <span class="math inline">\(\beta_3\)</span> 是 <span class="math inline">\(X_1 = 1\)</span> 時，<span class="math inline">\(X_2\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差 <span class="math inline">\(\mu_{11}-\mu_{10}\)</span> <strong>減去</strong> <span class="math inline">\(X_2 = 0\)</span> 時，<span class="math inline">\(X_1\)</span> 的兩組之間的均值差 <span class="math inline">\(\mu_{01}-\mu_{00}\)</span>：<span class="math inline">\((\mu_{11}-\mu_{10}) - (\mu_{01}-\mu_{00})\)</span>。</li>
</ol>
<p>當 <span class="math inline">\(X_1\)</span> 是連續型變量時，交互作用項的迴歸係數 <span class="math inline">\(\beta_3\)</span> 的幾何意義是兩個迴歸直線斜率的差。但是本例中，兩個預測變量都是二分類變量的情況下，<span class="math inline">\(\beta_3\)</span> 的實際意義就變成了，被 <span class="math inline">\(X_2\)</span> 定義的兩組 <span class="math inline">\(X_1\)</span> 之間因變量差的差，<span class="math inline">\((\mu_{11}-\mu_{10}) - (\mu_{01}-\mu_{00})\)</span>。</p>
</div>
<div id="兩個連續變量之間的交互作用" class="section level3">
<h3><span class="header-section-number">32.1.4</span> 兩個連續變量之間的交互作用</h3>
<p>前面 (Section <a href="04-Linear-Regression.html#interaction-cont-bin">32.1.2</a>) 已經討論過，一個是連續型變量 <span class="math inline">\(X_1\)</span>，另一個是分類變量時 <span class="math inline">\(X_2\)</span>，線性迴歸的交互作用項迴歸係數的含義是因變量 <span class="math inline">\(Y\)</span> 和連續性變量 <span class="math inline">\(X_1\)</span> 在不同的 <span class="math inline">\(X_2\)</span> 組中的迴歸係數之差(斜率之差)。但是，當兩個預測變量 <span class="math inline">\(X_1, X_2\)</span> 都是連續型變量時，交互作用項的迴歸係數該如何解釋呢？直觀的說，此時的交互作用項迴歸係數應該被理解爲：<strong>預測變量 <span class="math inline">\(X_2\)</span> 每增加一個單位時，<span class="math inline">\(Y, X_1\)</span> 之間關係的迴歸方程的斜率變化</strong>。爲了更好地解釋這個概念，我們沿用前面兒童年齡和身長預測其身高的模型 (Section <a href="04-Linear-Regression.html#globalsig">30.3.3</a>)，加入年齡和身高的交互作用項結果如下：</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb275-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb275-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb275-3" title="3"></a>
<a class="sourceLine" id="cb275-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age<span class="op">*</span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb275-5" title="5"><span class="co"># or equivalently use lm(wt ~  age*len, data=growgam1)</span></a>
<a class="sourceLine" id="cb275-6" title="6"></a>
<a class="sourceLine" id="cb275-7" title="7"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len + age * len, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.200 -0.651  0.003  0.522  2.895 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4.51956    1.90918   -2.37   0.0189 *  
## age         -0.28490    0.10496   -2.71   0.0073 ** 
## len          0.18777    0.02681    7.00  4.4e-11 ***
## age:len      0.00340    0.00129    2.64   0.0090 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.94 on 186 degrees of freedom
## Multiple R-squared:  0.753,  Adjusted R-squared:  0.749 
## F-statistic:  189 on 3 and 186 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" title="1"><span class="kw">confint</span>(Model1)</a></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -8.2859887 -0.753130
## age         -0.4919562 -0.077844
## len          0.1348837  0.240657
## age:len      0.0008588  0.005937</code></pre>
<p>這裏的模型中，兒童的身長和年齡相乘的部分構成了一個交互作用項。我們用這個擬合的迴歸方程寫出當兒童年齡爲 12 個月時，身長預測體重的方程：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=12) &amp; = (-4.5196 - 0.2849\times12) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times12)\times\text{Length} \\
                        &amp; = -7.9384 + 0.2286\times \text{Length}
\end{aligned}
\]</span></p>
<p>類似地，年齡 13 個月時， 預測體重的方程是：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=13) &amp; = (-4.5196 - 0.2849\times13) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times13)\times\text{Length} \\
                        &amp; = -8.2233 + 0.2320\times \text{Length}
\end{aligned}
\]</span></p>
<p>年齡 13 個月時， 預測體重的方程是：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=14) &amp; = (-4.5196 - 0.2849\times14) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times14)\times\text{Length} \\
                        &amp; = -8.5082 + 0.2354\times \text{Length}
\end{aligned}
\]</span></p>
<p>所以你會看到每個給定的兒童年齡時的方程身長預測體重的方程都是線性方程，截距和斜率都在變化。兒童的年齡每增加 <span class="math inline">\(1\)</span> 個月，身長和體重的相關係數增加 <span class="math inline">\(0.0034 \text{kg/cm}\)</span>。除了迴歸係數，其餘的數字都是不能用正常的數據來理解的 (沒有兒童身長 或者 體重會等於零)。如果非要解釋，那麼需要把數據全部中心化 (Section <a href="04-Linear-Regression.html#centring">27.3.1</a>)。</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb279-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(growgam1<span class="op">$</span>age, <span class="dt">graph=</span><span class="ot">FALSE</span>); epiDisplay<span class="op">::</span><span class="kw">summ</span>(growgam1<span class="op">$</span>len, <span class="dt">graph=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  190  16.979 16      8.337  5      36</code></pre>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  190  76.697 76.05   7.156  60.1   95.5</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" title="1">growgam1<span class="op">$</span>age_c &lt;-<span class="st"> </span>growgam1<span class="op">$</span>age<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb282-2" title="2">growgam1<span class="op">$</span>len_c &lt;-<span class="st"> </span>growgam1<span class="op">$</span>len<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>len)</a>
<a class="sourceLine" id="cb282-3" title="3"></a>
<a class="sourceLine" id="cb282-4" title="4">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age_c <span class="op">+</span><span class="st"> </span>len_c <span class="op">+</span><span class="st"> </span>age_c<span class="op">*</span>len_c, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb282-5" title="5"><span class="co"># or equivalently use lm(wt ~  age_c*len_c, data=growgam1)</span></a>
<a class="sourceLine" id="cb282-6" title="6"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age_c + len_c + age_c * len_c, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.200 -0.651  0.003  0.522  2.895 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  9.46978    0.09507   99.60   &lt;2e-16 ***
## age_c       -0.02427    0.01721   -1.41    0.160    
## len_c        0.24547    0.01947   12.61   &lt;2e-16 ***
## age_c:len_c  0.00340    0.00129    2.64    0.009 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.94 on 186 degrees of freedom
## Multiple R-squared:  0.753,  Adjusted R-squared:  0.749 
## F-statistic:  189 on 3 and 186 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" title="1"><span class="kw">confint</span>(Model2)</a></code></pre></div>
<pre><code>##                  2.5 %   97.5 %
## (Intercept)  9.2822177 9.657345
## age_c       -0.0582290 0.009680
## len_c        0.2070560 0.283877
## age_c:len_c  0.0008588 0.005937</code></pre>
<p>你會解釋上面中心化數據以後擬合的迴歸方程的結果，和各個參數估計的意義嗎？</p>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="03-Analytic-Technique.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="05-clinical-trials.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook/js/app.min.js"></script>
<script src="assets/gitbook/js/lunr.js"></script>
<script src="assets/gitbook/js/clipboard.min.js"></script>
<script src="assets/gitbook/js/plugin-search.js"></script>
<script src="assets/gitbook/js/plugin-sharing.js"></script>
<script src="assets/gitbook/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook/js/plugin-bookdown.js"></script>
<script src="assets/gitbook/js/jquery.highlight.js"></script>
<script src="assets/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/04-Linear-Regression.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
