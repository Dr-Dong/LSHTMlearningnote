<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 58 章 相互依賴數據及簡單的應對方案 | 醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="第 58 章 相互依賴數據及簡單的應對方案 | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 58 章 相互依賴數據及簡單的應對方案 | 醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2019-10-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="09-GLM.html"/>
<link rel="next" href="11-Survival-analysis.html"/>
<script src="assets/jquery/jquery.min.js"></script>
<link href="assets/gitbook/css/style.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/kePrint/kePrint.js"></script>
<script src="assets/htmlwidgets/htmlwidgets.js"></script>
<script src="assets/plotly-binding/plotly.js"></script>
<script src="assets/typedarray/typedarray.min.js"></script>
<link href="assets/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="assets/crosstalk/js/crosstalk.min.js"></script>
<link href="assets/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="assets/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="00-author.html"><a href="00-author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="01-Probability.html"><a href="01-Probability.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Probability.html"><a href="01-Probability.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="01-Probability.html"><a href="01-Probability.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="01-Probability.html"><a href="01-Probability.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="01-Probability.html"><a href="01-Probability.html#Bayes-Definition"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="01-Probability.html"><a href="01-Probability.html#期望-expectation-或均值-or-mean-和-方差-variance"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="01-Probability.html"><a href="01-Probability.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="01-Probability.html"><a href="01-Probability.html#bernoulli"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="01-Probability.html"><a href="01-Probability.html#binomial"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="01-Probability.html"><a href="01-Probability.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="01-Probability.html"><a href="01-Probability.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="01-Probability.html"><a href="01-Probability.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="01-Probability.html"><a href="01-Probability.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="01-Probability.html"><a href="01-Probability.html#poisson"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="01-Probability.html"><a href="01-Probability.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="01-Probability.html"><a href="01-Probability.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="01-Probability.html"><a href="01-Probability.html#CLT"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="01-Probability.html"><a href="01-Probability.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="01-Probability.html"><a href="01-Probability.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="01-Probability.html"><a href="01-Probability.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="01-Probability.html"><a href="01-Probability.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="01-Probability.html"><a href="01-Probability.html#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="01-Probability.html"><a href="01-Probability.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="01-Probability.html"><a href="01-Probability.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="01-Probability.html"><a href="01-Probability.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="02-Inference.html"><a href="02-Inference.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="02-Inference.html"><a href="02-Inference.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="02-Inference.html"><a href="02-Inference.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="02-Inference.html"><a href="02-Inference.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="02-Inference.html"><a href="02-Inference.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="02-Inference.html"><a href="02-Inference.html#估計和精確度-estimation-and-precision"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="02-Inference.html"><a href="02-Inference.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="02-Inference.html"><a href="02-Inference.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="02-Inference.html"><a href="02-Inference.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="02-Inference.html"><a href="02-Inference.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="02-Inference.html"><a href="02-Inference.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="02-Inference.html"><a href="02-Inference.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="02-Inference.html"><a href="02-Inference.html#chi-square-distribution"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="02-Inference.html"><a href="02-Inference.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="02-Inference.html"><a href="02-Inference.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-definition"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="02-Inference.html"><a href="02-Inference.html#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="02-Inference.html"><a href="02-Inference.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="02-Inference.html"><a href="02-Inference.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="02-Inference.html"><a href="02-Inference.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="02-Inference.html"><a href="02-Inference.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="02-Inference.html"><a href="02-Inference.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="02-Inference.html"><a href="02-Inference.html#llr"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="02-Inference.html"><a href="02-Inference.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="02-Inference.html"><a href="02-Inference.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="02-Inference.html"><a href="02-Inference.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="02-Inference.html"><a href="02-Inference.html#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="02-Inference.html"><a href="02-Inference.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="02-Inference.html"><a href="02-Inference.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="02-Inference.html"><a href="02-Inference.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="02-Inference.html"><a href="02-Inference.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="02-Inference.html"><a href="02-Inference.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="02-Inference.html"><a href="02-Inference.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="02-Inference.html"><a href="02-Inference.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的構建-construction-of-a-hypothesis-test"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="02-Inference.html"><a href="02-Inference.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="02-Inference.html"><a href="02-Inference.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="02-Inference.html"><a href="02-Inference.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="02-Inference.html"><a href="02-Inference.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="02-Inference.html"><a href="02-Inference.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="02-Inference.html"><a href="02-Inference.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="02-Inference.html"><a href="02-Inference.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="02-Inference.html"><a href="02-Inference.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="02-Inference.html"><a href="02-Inference.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="02-Inference.html"><a href="02-Inference.html#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的近似方法"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="02-Inference.html"><a href="02-Inference.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="02-Inference.html"><a href="02-Inference.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="02-Inference.html"><a href="02-Inference.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="02-Inference.html"><a href="02-Inference.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="02-Inference.html"><a href="02-Inference.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="02-Inference.html"><a href="02-Inference.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="02-Inference.html"><a href="02-Inference.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="02-Inference.html"><a href="02-Inference.html#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="02-Inference.html"><a href="02-Inference.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="02-Inference.html"><a href="02-Inference.html#正態誤差模型-normal-error-models"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="02-Inference.html"><a href="02-Inference.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="02-Inference.html"><a href="02-Inference.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="02-Inference.html"><a href="02-Inference.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="02-Inference.html"><a href="02-Inference.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="02-Inference.html"><a href="02-Inference.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="02-Inference.html"><a href="02-Inference.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="02-Inference.html"><a href="02-Inference.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="02-Inference.html"><a href="02-Inference.html#多個參數時的統計推斷-inference-with-multiple-parameters-i"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="02-Inference.html"><a href="02-Inference.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="02-Inference.html"><a href="02-Inference.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="02-Inference.html"><a href="02-Inference.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="02-Inference.html"><a href="02-Inference.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="02-Inference.html"><a href="02-Inference.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="02-Inference.html"><a href="02-Inference.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="02-Inference.html"><a href="02-Inference.html#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="02-Inference.html"><a href="02-Inference.html#profile-log-likelihood"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="02-Inference.html"><a href="02-Inference.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="02-Inference.html"><a href="02-Inference.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="02-Inference.html"><a href="02-Inference.html#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path="02-Inference.html"><a href="02-Inference.html#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path="02-Inference.html"><a href="02-Inference.html#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path="02-Inference.html"><a href="02-Inference.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path="02-Inference.html"><a href="02-Inference.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間-confidence-intervals-1"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#假設檢驗"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關-association"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較-comparisons"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#前提和數據轉換-assumptions-and-transformations"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ANOVA"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析-multivariable-models"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析矩陣標記與其意義"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸的模型診斷"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#baseline-adjustment-using-ancova"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法-permutation-procedures"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#自助重抽法-the-bootstrap"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#the-sandwich-estimator"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯定理的應用單一參數模型"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path="09-GLM.html"><a href="09-GLM.html"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path="09-GLM.html"><a href="09-GLM.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path="09-GLM.html"><a href="09-GLM.html#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path="09-GLM.html"><a href="09-GLM.html#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path="09-GLM.html"><a href="09-GLM.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path="09-GLM.html"><a href="09-GLM.html#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path="09-GLM.html"><a href="09-GLM.html#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path="09-GLM.html"><a href="09-GLM.html#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path="09-GLM.html"><a href="09-GLM.html#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path="09-GLM.html"><a href="09-GLM.html#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path="09-GLM.html"><a href="09-GLM.html#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path="09-GLM.html"><a href="09-GLM.html#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path="09-GLM.html"><a href="09-GLM.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="09-GLM.html"><a href="09-GLM.html#廣義線性迴歸入門"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path="09-GLM.html"><a href="09-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="09-GLM.html"><a href="09-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path="09-GLM.html"><a href="09-GLM.html#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path="09-GLM.html"><a href="09-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path="09-GLM.html"><a href="09-GLM.html#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path="09-GLM.html"><a href="09-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path="09-GLM.html"><a href="09-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path="09-GLM.html"><a href="09-GLM.html#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型-logistic-regression-model"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path="09-GLM.html"><a href="09-GLM.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path="09-GLM.html"><a href="09-GLM.html#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="09-GLM.html"><a href="09-GLM.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path="09-GLM.html"><a href="09-GLM.html#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path="09-GLM.html"><a href="09-GLM.html#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path="09-GLM.html"><a href="09-GLM.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path="09-GLM.html"><a href="09-GLM.html#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="09-GLM.html"><a href="09-GLM.html#模型比較和擬合優度"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path="09-GLM.html"><a href="09-GLM.html#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path="09-GLM.html"><a href="09-GLM.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path="09-GLM.html"><a href="09-GLM.html#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path="09-GLM.html"><a href="09-GLM.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path="09-GLM.html"><a href="09-GLM.html#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="09-GLM.html"><a href="09-GLM.html#計數型因變量-poisson-regression"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path="09-GLM.html"><a href="09-GLM.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path="09-GLM.html"><a href="09-GLM.html#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path="09-GLM.html"><a href="09-GLM.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="09-GLM.html"><a href="09-GLM.html#率的廣義線性迴歸-poisson-glm-for-rates"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path="09-GLM.html"><a href="09-GLM.html#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path="09-GLM.html"><a href="09-GLM.html#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path="09-GLM.html"><a href="09-GLM.html#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path="09-GLM.html"><a href="09-GLM.html#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path="09-GLM.html"><a href="09-GLM.html#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="09-GLM.html"><a href="09-GLM.html#混雜的調整交互作用和模型的可壓縮性"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path="09-GLM.html"><a href="09-GLM.html#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path="09-GLM.html"><a href="09-GLM.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="09-GLM.html"><a href="09-GLM.html#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path="09-GLM.html"><a href="09-GLM.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path="09-GLM.html"><a href="09-GLM.html#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="09-GLM.html"><a href="09-GLM.html#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="09-GLM.html"><a href="09-GLM.html#流行病學中的邏輯迴歸"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path="09-GLM.html"><a href="09-GLM.html#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path="09-GLM.html"><a href="09-GLM.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="09-GLM.html"><a href="09-GLM.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path="09-GLM.html"><a href="09-GLM.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path="09-GLM.html"><a href="09-GLM.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path="09-GLM.html"><a href="09-GLM.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="09-GLM.html"><a href="09-GLM.html#分析策略"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path="09-GLM.html"><a href="09-GLM.html#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path="09-GLM.html"><a href="09-GLM.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path="09-GLM.html"><a href="09-GLM.html#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path="09-GLM.html"><a href="09-GLM.html#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="09-GLM.html"><a href="09-GLM.html#檢查你的模型-model-checking---glm"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path="09-GLM.html"><a href="09-GLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path="09-GLM.html"><a href="09-GLM.html#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path="09-GLM.html"><a href="09-GLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path="09-GLM.html"><a href="09-GLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="09-GLM.html"><a href="09-GLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path="09-GLM.html"><a href="09-GLM.html#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path="09-GLM.html"><a href="09-GLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path="09-GLM.html"><a href="09-GLM.html#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="09-GLM.html"><a href="09-GLM.html#評價模型的表現-assessing-model-performance"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path="09-GLM.html"><a href="09-GLM.html#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path="09-GLM.html"><a href="09-GLM.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path="09-GLM.html"><a href="09-GLM.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path="09-GLM.html"><a href="09-GLM.html#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗數據的分析法"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path="09-GLM.html"><a href="09-GLM.html#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path="09-GLM.html"><a href="09-GLM.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path="09-GLM.html"><a href="09-GLM.html#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="09-GLM.html"><a href="09-GLM.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path="09-GLM.html"><a href="09-GLM.html#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path="09-GLM.html"><a href="09-GLM.html#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="09-GLM.html"><a href="09-GLM.html#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path="09-GLM.html"><a href="09-GLM.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path="09-GLM.html"><a href="09-GLM.html#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path="09-GLM.html"><a href="09-GLM.html#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="09-GLM.html"><a href="09-GLM.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯迴歸-conditional-logistic-regression"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path="09-GLM.html"><a href="09-GLM.html#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path="09-GLM.html"><a href="09-GLM.html#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path="09-GLM.html"><a href="09-GLM.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path="09-GLM.html"><a href="09-GLM.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path="09-GLM.html"><a href="09-GLM.html#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="09-GLM.html"><a href="09-GLM.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path="09-GLM.html"><a href="09-GLM.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型-random-intercept-model"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中加入共變量-random-intercept-model-with-covariates"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數模型-random-coefficient-model"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-1"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-2"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-3"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#generalized-estimating-equation"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysisunsupervised-learning-聚類分析"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-1"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#principal-component-analysis-主成分分析"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-2"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#further-issues"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數分布"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#nonparametric"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據中的回歸模型"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布-1"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-比例風險模型"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分析策略和模型檢查-model-checking-survival-analysis"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#競爭風險模型-competing-risk"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的其他手段"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#加速失效模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.1</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量-time-dependent-variables-和脆弱模型-frailty-model"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間事件數據的高級分析法"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="80" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html"><i class="fa fa-check"></i><b>80</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="80.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>80.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="80.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>80.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="80.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#概率論者分析結果"><i class="fa fa-check"></i><b>80.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="80.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>80.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="80.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-the-great-trial"><i class="fa fa-check"></i><b>80.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="80.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#background-great-trial"><i class="fa fa-check"></i><b>80.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="80.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#試驗結果"><i class="fa fa-check"></i><b>80.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="80.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#經典統計學分析方法"><i class="fa fa-check"></i><b>80.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="80.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>80.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MC-estimation"><i class="fa fa-check"></i><b>81</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="81.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#起源"><i class="fa fa-check"></i><b>81.1</b> 起源</a><ul>
<li class="chapter" data-level="81.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#作出預測"><i class="fa fa-check"></i><b>81.1.1</b> 作出預測</a></li>
<li class="chapter" data-level="81.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-新藥表現預測"><i class="fa fa-check"></i><b>81.1.2</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>81.2</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="81.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>81.2.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="81.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>81.2.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="81.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅法分析軟件-openbugs"><i class="fa fa-check"></i><b>81.3</b> 蒙特卡羅法分析軟件 OpenBUGS</a><ul>
<li class="chapter" data-level="81.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>81.3.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="81.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>81.3.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="81.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>81.3.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>81.4</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="82" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率-conjugate-priors"><i class="fa fa-check"></i><b>82</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="82.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>82.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="82.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="82.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#事後概率分布預測"><i class="fa fa-check"></i><b>82.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="82.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>82.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="82.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesPrac03"><i class="fa fa-check"></i><b>82.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="83" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MCMC-methods"><i class="fa fa-check"></i><b>83</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="83.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>83.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="83.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>83.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="83.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Gibbs-sampling"><i class="fa fa-check"></i><b>83.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="83.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值-initial-values"><i class="fa fa-check"></i><b>83.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="83.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>83.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="83.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#收斂時間"><i class="fa fa-check"></i><b>83.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="83.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>83.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="83.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-軟件"><i class="fa fa-check"></i><b>83.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="83.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>83.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="83.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>83.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="83.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-language"><i class="fa fa-check"></i><b>83.5</b> BUGS language</a><ul>
<li class="chapter" data-level="83.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>83.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="83.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#分布的標記法"><i class="fa fa-check"></i><b>83.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="83.5.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#arrays-and-loops"><i class="fa fa-check"></i><b>83.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="83.5.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#常用的方程"><i class="fa fa-check"></i><b>83.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="83.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>83.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="83.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>83.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#建模和模型的檢查"><i class="fa fa-check"></i><b>84</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="84.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesianLM"><i class="fa fa-check"></i><b>84.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="84.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#children-in-the-gambia"><i class="fa fa-check"></i><b>84.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="84.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>84.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="84.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>84.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="84.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="84.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>84.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="84.2.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>84.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="84.2.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>84.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="84.2.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>84.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="84.2.8" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="84.2.9" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#tdreplacegaussian"><i class="fa fa-check"></i><b>84.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="84.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>84.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="84.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>84.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="84.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>84.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="84.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>84.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="84.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>84.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="84.4.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>84.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="85" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#不同實驗研究設計時適用的貝葉斯模型"><i class="fa fa-check"></i><b>85</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="85.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>85.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="85.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>85.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="85.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>85.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="85.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#the-great-trial"><i class="fa fa-check"></i><b>85.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="85.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#吸煙與癌症"><i class="fa fa-check"></i><b>85.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯廣義線性回歸"><i class="fa fa-check"></i><b>86</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="86.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>86.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="86.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>86.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="86.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>86.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="86.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>86.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="86.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#低出生體重數據-1"><i class="fa fa-check"></i><b>86.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="86.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>86.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="86.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>86.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="86.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Bayesian-practical07"><i class="fa fa-check"></i><b>86.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="87" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級回歸模型"><i class="fa fa-check"></i><b>87</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="87.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>87.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="87.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>87.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="87.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>87.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="87.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>87.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="87.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>87.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="87.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>87.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="87.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#縱向數據"><i class="fa fa-check"></i><b>87.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="87.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-example"><i class="fa fa-check"></i><b>87.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="87.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>87.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="87.3.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>87.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="87.3.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>87.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="87.3.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>87.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="87.3.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>87.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="87.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>87.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#再訪-mcmc"><i class="fa fa-check"></i><b>88</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="88.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>88.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="88.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>88.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯和概率論的比較"><i class="fa fa-check"></i><b>89</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="89.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>89.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="89.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>89.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="89.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>89.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="90" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html"><i class="fa fa-check"></i><b>90</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="90.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>90.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="90.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>90.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="90.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步分析"><i class="fa fa-check"></i><b>90.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="90.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#混雜"><i class="fa fa-check"></i><b>90.2.2</b> 混雜</a></li>
<li class="chapter" data-level="90.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>90.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="90.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>90.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="90.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>90.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="90.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>90.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="90.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>90.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="90.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>90.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="91" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#graphical-models-因果推斷的圖形模型"><i class="fa fa-check"></i><b>91</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="91.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>91.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="91.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>91.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="91.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-圖的術語"><i class="fa fa-check"></i><b>91.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="91.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>91.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="91.1.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>91.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="91.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以非對撞銀子爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>91.2</b> 以非對撞銀子爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="91.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件的總結"><i class="fa fa-check"></i><b>91.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="91.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#d-分離-d-separation"><i class="fa fa-check"></i><b>91.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-continuous-outcomes-結果變量爲連續型變量"><i class="fa fa-check"></i><b>92</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="92.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>92.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="92.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>92.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="92.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>92.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="92.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>92.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="92.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>92.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="92.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>92.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="92.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均值差"><i class="fa fa-check"></i><b>92.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="92.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>92.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="92.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>92.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="92.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#positivity-非零性"><i class="fa fa-check"></i><b>92.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="92.3.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>92.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical03---causal-inference"><i class="fa fa-check"></i><b>92.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="93" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-binary-outcomes-結果變量爲二分類變量"><i class="fa fa-check"></i><b>93</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="93.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>93.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="93.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>93.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>93.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="93.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>93.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="93.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>93.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="93.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>93.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>93.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="93.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>93.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="93.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical04---causal-inference"><i class="fa fa-check"></i><b>93.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="93.6.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>93.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="93.6.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>93.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="93.6.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>93.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="93.6.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>93.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="93.6.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>93.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="93.6.7" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.8" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>93.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="93.6.9" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>93.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="93.6.10" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>93.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="93.6.11" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>93.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="93.6.12" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>93.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="94" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#prospensity-score-傾向性評分"><i class="fa fa-check"></i><b>94</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="94.0.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#關於條件可置換性"><i class="fa fa-check"></i><b>94.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="94.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>94.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="94.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分層法-stratification"><i class="fa fa-check"></i><b>94.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="94.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#配對法-matching"><i class="fa fa-check"></i><b>94.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="94.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>94.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical05---causal-inference"><i class="fa fa-check"></i><b>94.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="94.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>94.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="94.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>94.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="94.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>94.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="94.2.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>94.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="94.2.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用配對法計算-ace"><i class="fa fa-check"></i><b>94.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="94.2.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#模型校正-ps"><i class="fa fa-check"></i><b>94.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#inverse-probability-weighted-estimation-and-doubly-robust-methods"><i class="fa fa-check"></i><b>95</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="96" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#causal-mediation-analysis"><i class="fa fa-check"></i><b>96</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="97" data-path="29SME.html"><a href="29SME.html"><i class="fa fa-check"></i><b>97</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="30-references.html"><a href="30-references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Hierarchical" class="section level1">
<h1><span class="header-section-number">第 58 章</span> 相互依賴數據及簡單的應對方案</h1>
<blockquote>
<dl>
<dt>To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.</dt>
<dd><p>Sir Ronald Aylmer Fisher</p>
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Analysis of Hierarchical and Other Dependent Data lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/sharples.linda">Linda Sharples</a>, and Dr. <a href="https://www.lshtm.ac.uk/aboutus/people/njagi.edmund-njeru">Edmund Njeru Njagi</a>.
</div>

<div id="相互依賴的數據" class="section level2">
<h2><span class="header-section-number">58.1</span> 相互依賴的數據</h2>
<p>線性回歸模型，廣義線性回歸模型，他們背後都有一個十分十分<strong>十分重要的假設–數據的相互獨立性</strong>。這個前提假設常常會在現實數據中得不到滿足，因爲數據與數據之間在背後很可能會有有所關聯，也許是已知的，也許是未知的因素讓某些數據顯得更加接近彼此。這個章節，主要的內容就是舉例說明分層數據在日常生活中的常見性，以及處理這個非獨立性質的必要性。</p>
<ul>
<li>圖 <a href="10-Hierarchical-models.html#fig:Hier01-1">58.1</a> 展示的箱式圖顯示的是六個不同醫院對各自 12 名患者收縮期血壓測量的結果。如果把醫院看做一個單位，取院內患者的平均值，那麼六所醫院的血壓均值最大爲 135.7 mmHg，最小是 117.7 mmHg，六所醫院測量的血壓總體均值爲 125.6 mmHg。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-1"></span>
<img src="bookdown_files/figure-html/Hier01-1-1.png" alt="Box and whiskers plot of measured SBP in patients from six hospitals" width="90%" />
<p class="caption">
圖 58.1: Box and whiskers plot of measured SBP in patients from six hospitals
</p>
</div>
<ul>
<li>圖 <a href="10-Hierarchical-models.html#fig:Hier01-2">58.2</a> 展示的是對 17 名患者使用兩種不同的測量方法測量的最大呼吸速率 (peak-expiratory-flow rate, PEFR)。兩種方法又測量了兩次，途中展示的是其中一種測量方法前後兩次測量結果的散點圖。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-2"></span>
<img src="bookdown_files/figure-html/Hier01-2-1.png" alt="Two recordings of PEFR taken with the Mini Wright meter" width="80%" />
<p class="caption">
圖 58.2: Two recordings of PEFR taken with the Mini Wright meter
</p>
</div>
<ul>
<li>圖 <a href="10-Hierarchical-models.html#fig:Hier01-3">58.3</a> 展示的來自全英 65 所學校的 4059 名學生入學前閱讀水平測試成績 (LRT) 和畢業時 GCSE 考試成績之間的散點圖關系。值得注意的是該圖其實無視了學校這個變量，把每個學生看成相互獨立的個體。但是當我們隨機選取四所學校，看它們各自的學生的成績表現 (圖 <a href="10-Hierarchical-models.html#fig:Hier01-4">58.4</a>)。很顯然，之前忽視了學校這一層級的變量是不恰當的，因爲不同學校學生的入學前和畢業時成績之間的相關性很明顯存在不同的模式 (四所學校的回歸線各自的截距和斜率各不相同)。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-3"></span>
<img src="bookdown_files/figure-html/Hier01-3-1.png" alt="GCSE by LRT in all 65 schools" width="80%" />
<p class="caption">
圖 58.3: GCSE by LRT in all 65 schools
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:Hier01-4"></span>
<img src="bookdown_files/figure-html/Hier01-4-1.png" alt="GCSE by LRT in four randomly selected schools" width="80%" />
<p class="caption">
圖 58.4: GCSE by LRT in four randomly selected schools
</p>
</div>
<ul>
<li>另一個特別好的例子展示在圖 <a href="10-Hierarchical-models.html#fig:Hier01-5">58.5</a> 中，是關於同一個母親的不同孩子的出生體重的數據。一個母親可以有多個孩子，每個母親的孩子之間的出生體重很明顯無法看作相互獨立。圖中展示的是，3300 名生了兩個孩子的母親的孩子們出生體重的散點圖。同一個母親的小孩用線相連。顯然，同一個母親生的孩子，其出生體重比不同母親的孩子出生體重差距更小，更接近彼此，因爲他們來自同一個母親。可以想象，一個母親如果身材高大，那麼她的孩子們可能都傾向於有比較高的出生體重。所以同一個母親的孩子之間體重是有相關關系的 (within correlation)。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-5"></span>
<img src="bookdown_files/figure-html/Hier01-5-1.png" alt="Birthweight of siblings by maternal identifier" width="80%" />
<p class="caption">
圖 58.5: Birthweight of siblings by maternal identifier
</p>
</div>
<ul>
<li>最後一個用於本章節的實例是，一項研究亞洲兒童生長狀況的調查分別記錄了 198 個數據點，68 個兒童在 0 到 3 歲之間的四個年齡點的體重數據。圖 <a href="10-Hierarchical-models.html#fig:Hier01-6">58.6</a> 展示的就是這個典型的隨訪數據的個人生長曲線。且圖中每個人的生長軌跡提示，男孩子的生長過程可能相互之間體重差異顯得較女孩子來得大。如果，我們用每個兒童自己的數據，給每個兒童擬合各自的回歸線，數據顯然不足，但是如果我們決定忽略個體的生長的隨機效應 (不均一性)，又顯得十分不妥當。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-6"></span>
<img src="bookdown_files/figure-html/Hier01-6-1.png" alt="Growth profiles of boys and girls in the Asian growth data" width="80%" />
<p class="caption">
圖 58.6: Growth profiles of boys and girls in the Asian growth data
</p>
</div>
</div>
<div id="依賴性的來源在哪裏" class="section level2">
<h2><span class="header-section-number">58.2</span> 依賴性的來源在哪裏</h2>
<p>上述例子中的數據，均提示我們數據與數據之間獨立性的假設，常常會遇到尷尬的局面。因爲數據與數據之間本身就不可能完全獨立。</p>
<ol style="list-style-type: decimal">
<li>同一個診所或者醫院的患者，他們之間可能有着某些相似的因素從而導致他們的血壓相比其他醫院的人彼此更加接近。這個原因可能是有同一家醫院的患者可能有類似的疾病。</li>
<li>同一患者身上反復抽取樣本，也就是說一個對象貢獻了多個數據的時候，這些來自同一對象的數據當然具有相對不同對象數據更高的均質性。</li>
<li>同一所學校的學生的成績或內部的相關性，很可能大於不同學校兩個學生之間成績的相關性。因爲同一學校的孩子可能共享某些共同的特徵，比如說相似的家庭經濟背景，或者是同樣的教學內容教學老師等環境因素。這樣，來自同一所學校的孩子的成績很可能就會更加相似。</li>
<li>至於說家庭數據就更加典型了。來自同一家庭的兄弟姐妹，有着極強的相關性，因爲他們共享着遺傳因素，或者是相似的家庭教育/飲食/生活習慣等環境因素。</li>
<li>同一個體身上的縱向 (時間) 隨訪數據很顯然會比不同患者有更強的內部相關性。</li>
</ol>
<p>目前位置介紹的這些常見實例中，可以發現它們有一個共通點。就是這些數據其實內部是有分層結構的 (hierarchy)。這些數據中，都有一個最底層單元 (elementary units/level 1)，還有一個聚合單元 (aggregate units/level 2)，聚合單元常被命名爲層級 (cluster)。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Hier01tab00">表 58.1: </span>Hierarchy in the data (5 examples in Chapter 1)
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Level
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Aggregate
</th>
<th style="text-align:left;">
Elementary
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
hospitals
</td>
<td style="text-align:left;">
patients
</td>
</tr>
<tr>
<td style="text-align:left;">
individuals
</td>
<td style="text-align:left;">
PEFR measures
</td>
</tr>
<tr>
<td style="text-align:left;">
schools
</td>
<td style="text-align:left;">
pupils
</td>
</tr>
<tr>
<td style="text-align:left;">
mothers
</td>
<td style="text-align:left;">
children
</td>
</tr>
<tr>
<td style="text-align:left;">
children
</td>
<td style="text-align:left;">
visits
</td>
</tr>
</tbody>
</table>
<p>正如表格 <a href="10-Hierarchical-models.html#tab:Hier01tab00">58.1</a> 總結的那樣，這些數據中存在這層級結構，這種數據被稱爲分層數據 (hierarchical)，或者叫嵌套式數據 (nested data)。根據你所在的知識領域，它可能還被命名爲多層結構數據 (multilevel and clustered data)。在一些研究中，你可能會遇見從實驗設計階段就存在分層結構的數據，比如使用分層抽樣 (multistage sampling) 的設計的實驗等。這樣的實驗設計最常在人口學，社會學的研究中看到。在大多數醫學研究中，每個數據點 (observation point, level 1)，所屬的層 (cluster) 本身可能是我們感興趣的研究點 (例如同屬於一個家庭，相同母親的後代)，又或者是同一個人/患者的隨着時間推移的隨訪健康狀態 (如生長曲線，體重變化，疾病康復情況)。</p>
<p>如果用前面用過的 圖 <a href="10-Hierarchical-models.html#fig:Hier01-6">58.6</a> 的生長曲線做例子，那麼每個被調查的兒童，就是該數據的第二級層，每個隨訪時刻測量的體重數據，則是觀察的數據點。這個數據還有一個特點是，觀察數據點是有前後的 (時間) 順序的，這是一個典型的<strong>縱向研究數據 (longitudinal data)</strong>。</p>
</div>
<div id="數據有依賴性導致的結果" class="section level2">
<h2><span class="header-section-number">58.3</span> 數據有依賴性導致的結果</h2>
<p>如果你手頭的數據，結構上是一種嵌套式結構數據，那麼任何無視了這一點作出的統計學推斷都是有瑕疵的。相互之間互不獨立這一特質，需要通過一種新的手段，把嵌套式的數據結構考慮進統計學模型裏來。</p>
<p>在一些情況下，數據的嵌套式結構可能可以被忽略掉，但是其結果是導致統計學的估計變得十分低效 (inefficient procedure)。你可能會聽說過一般化估計公式 (generalized estimating equations)，是其中一種備擇手段，因爲在這一公式中，你需要人爲地指定數據與數據之間可能的依賴關系是怎樣的。</p>
<p>其實，即使有人真的在分析過程中忽略了數據本身的嵌套式結構，他會發現最終在描述分析結果的時候，還是無法避免這一嚴重的問題。另外一些統計學家可能記得在穩健統計學法中，三明治標準誤估計法也是可以供選擇的一種處理相關數據的手段。</p>
</div>
<div id="邊際模型和條件模型-marginal-and-conditional-models" class="section level2">
<h2><span class="header-section-number">58.4</span> 邊際模型和條件模型 marginal and conditional models</h2>
<p>邊際模型和條件模型的概念其實不是分層模型特有的，卻在分析分層數據模型時十分有用。假如，對於某個結果變量 <span class="math inline">\(Y\)</span> 有它如下的回歸模型，其中我們把某個單一的共變量 <span class="math inline">\(Z\)</span> 從模型中分離出來，加以特別關注:</p>
<p><span class="math display">\[
g\{ \text{E}(Y|\textbf{X},Z) \} = \beta\textbf{X} +\gamma Z
\]</span></p>
<p>這是一個典型的條件模型，它描述了結果變量 <span class="math inline">\(Y\)</span> 的期望是以怎樣的<strong>條件</strong>和解釋變量 <span class="math inline">\(\textbf{X},Z\)</span> 之間建立關系的。每個解釋變量的回歸系數，其含義都是<strong>以其他同一模型中的共變量不變的條件下</strong>，和結果變量之間的關系。經過這樣的解讀，你會知道，其實本統計學教程目前爲止遇見過的所有的回歸模型都是條件模型。如果此時我們反過來思考，把上述模型中單獨分離出來的單一共變量 <span class="math inline">\(Z\)</span> 對於結果變量 <span class="math inline">\(Y\)</span> 均值的影響合並起來 (對共變量 <span class="math inline">\(Z\)</span> 積分即可)，此時我們得到的就是共變量 <span class="math inline">\(\textbf{X}\)</span> 和結果變量 <span class="math inline">\(Y\)</span> 之間，關於 <span class="math inline">\(Z\)</span> 的邊際模型 (Marginal model):</p>
<p><span class="math display">\[
\text{E}_Z\{ \text{E}(Y|\textbf{X}, Z) \} = \text{E}_Z\{ g^{-1}(\beta\textbf{X} + \gamma Z) \} \\
\text{Where } \text{E}(Z) = 0
\]</span></p>
<p>用<strong>線性回歸</strong>來舉例:</p>
<p><span class="math display">\[
\text{E}(Y| \textbf{X}, Z) = \beta\textbf{X} + \gamma Z
\]</span></p>
<p>那麼此時共變量 <span class="math inline">\(\textbf{X}\)</span> 的邊際模型回歸系數 <span class="math inline">\(\beta\)</span> 的含義，和條件模型時的回歸系數其實是相同的含義:</p>
<p><span class="math display">\[
\text{E}_Z\{\text{E}(Y|\textbf{X},Z)\} = \text{E}_Z(\beta\textbf{X} + \gamma Z) = \beta\textbf{X} + \gamma\text{E}(Z) = \beta\textbf{X}
\]</span></p>
<p>爲什麼這裏的邊際模型對於分層數據來說很重要呢？答案在於，嵌套式數據中，我們常常關心那第二個階層 (重復測量某個指標的患者，學生成績數據中的學校層級，等) 在它所在的那個階層中和結果變量之間的平均關系。(In models for hierarchical data we often use level effects to represent what is common among observations from one “cluster” or “group”. We may then want marginal conclusions: we need to average over these effects).</p>
<div id="標記法-notation" class="section level3">
<h3><span class="header-section-number">58.4.1</span> 標記法 notation</h3>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span> 標記第 <span class="math inline">\(j\)</span> 層的第 <span class="math inline">\(i\)</span> 個個體;</li>
<li><span class="math inline">\(i = 1, \cdots, n_j\)</span> 表示第 <span class="math inline">\(j\)</span> 層中共有 <span class="math inline">\(n_j\)</span> 個個體 (elements);</li>
<li><span class="math inline">\(j = 1, \cdots, J\)</span> 表示數據共有 <span class="math inline">\(J\)</span> 個第二階層 (clusters);</li>
<li><span class="math inline">\(N = \sum_{j=1}^J n_j\)</span> 表示總體樣本量等於各個階層樣本量之和;</li>
<li>特殊情況: 如果每個階層的個體數相同 <span class="math inline">\(n\)</span>，<span class="math inline">\(N=nJ\)</span>，這樣的數據被叫做均衡數據 (balanced data)。</li>
</ul>
</div>
<div id="合並每個階層" class="section level3">
<h3><span class="header-section-number">58.4.2</span> 合並每個階層</h3>
<p>過去常見的總結嵌套式數據的手段只是把每層數據取平均值，這樣的方法簡單粗暴但是偶爾是可以接受的，只要你能夠接受如此處理數據可能帶來的如下後果:</p>
<ul>
<li>各層數據均值，其可靠程度 (方差) 隨着各層的樣本量不同而不同 (depends on the number of elementary units per cluster);</li>
<li>變量的含義發生改變。如果是使用層水平 (cluster level) 的數據，本來測量給個體的那些變量，就變成了<strong>層的變量</strong>，從此作出的任何統計學推斷，只能限制在層水平 (ecological fallacy, as correlations at the macro level cannot be used to make assertions at the micro level);</li>
<li>由於無視了層內個體數據，導致大量信息損失。</li>
</ul>
<p>此處我們借用 <span class="citation">(Snijders and Bosker <a href="#ref-Snijders1999" role="doc-biblioref">1999</a>)</span> 書中第 28 頁的人造數據，如下表</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Artificial data
</caption>
<thead>
<tr>
<th style="text-align:center;">
Cluster <span class="math inline">\((j)\)</span>
</th>
<th style="text-align:center;">
id <span class="math inline">\((i)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\bar{X}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\bar{Y}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
2
</td>
</tr>
</tbody>
</table>
<p>這個表中的人造數據，其結構是一目了然的，它的第二層級數量是 5，每層的個體數量是 2。這是一個平衡數據。由於這是個我們人爲模擬的數據，圖 <a href="10-Hierarchical-models.html#fig:artificialdata00">58.7</a> 也顯示它沒有隨機誤差，所有數據都在各自的直線上。</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb703-1" title="1">dt &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;backupfiles/hierexample.csv&quot;</span>, <span class="dt">header =</span> T)</a>
<a class="sourceLine" id="cb703-2" title="2"><span class="kw">names</span>(dt) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Cluster&quot;</span>, <span class="st">&quot;id&quot;</span>, <span class="st">&quot;X&quot;</span>, <span class="st">&quot;Y&quot;</span>, <span class="st">&quot;Xbar&quot;</span>, <span class="st">&quot;Ybar&quot;</span>)</a>
<a class="sourceLine" id="cb703-3" title="3">dt<span class="op">$</span>Cluster &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dt<span class="op">$</span>Cluster)</a>
<a class="sourceLine" id="cb703-4" title="4"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb703-5" title="5"></a>
<a class="sourceLine" id="cb703-6" title="6"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y, <span class="dt">shape =</span> Cluster, <span class="dt">colour =</span> Cluster)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb703-7" title="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb703-8" title="8">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb703-9" title="9">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb703-10" title="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb703-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb703-12" title="12"><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="dt">legend.direction =</span> <span class="st">&quot;horizontal&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata00"></span>
<img src="bookdown_files/figure-html/artificialdata00-1.png" alt="Artificial data: scatter of clustered data" width="80%" />
<p class="caption">
圖 58.7: Artificial data: scatter of clustered data
</p>
</div>
<ul>
<li>如果我們無視其分層數據的嵌套式結構，把每個數據都看作是獨立的樣本，擬合一個<strong>整體回歸 (total regression) 圖 <a href="10-Hierarchical-models.html#fig:artificialdata01">58.8</a></strong>:</li>
</ul>
<p><span class="math display">\[
\hat Y_{ij} = 5.33 - 0.33 X_{ij}
\]</span></p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb704-1" title="1"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb704-2" title="2"></a>
<a class="sourceLine" id="cb704-3" title="3"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">shape =</span> <span class="dv">23</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb704-4" title="4"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb704-5" title="5"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb704-6" title="6">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb704-7" title="7">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb704-8" title="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb704-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb704-10" title="10"><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="dt">legend.direction =</span> <span class="st">&quot;horizontal&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata01"></span>
<img src="bookdown_files/figure-html/artificialdata01-1.png" alt="Artificial data: Total regression" width="80%" />
<p class="caption">
圖 58.8: Artificial data: Total regression
</p>
</div>
<ul>
<li>如果我們只保留層級數據本身，求了變量 <span class="math inline">\(X,Y\)</span> 在每層的均值的話，就得到了<strong>層間回歸 (between regression) 圖 <a href="10-Hierarchical-models.html#fig:artificialdata02">58.9</a></strong> – 變量 <span class="math inline">\(X,Y\)</span> 之間的回歸直線的斜率變得更大了:</li>
</ul>
<p><span class="math display">\[
\hat{\bar{Y}}_j = 8.0 - 1.0 \bar{X}_j
\]</span></p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb705-1" title="1"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb705-2" title="2"></a>
<a class="sourceLine" id="cb705-3" title="3"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">23</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb705-4" title="4"><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-5" title="5"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">8</span>, <span class="dt">slope =</span> <span class="dv">-1</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb705-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Xbar, <span class="dt">y=</span>Ybar, <span class="dt">size =</span> <span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-7" title="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb705-8" title="8">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb705-9" title="9">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-10" title="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb705-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata02"></span>
<img src="bookdown_files/figure-html/artificialdata02-1.png" alt="Artificial data: scatter of clustered data" width="80%" />
<p class="caption">
圖 58.9: Artificial data: scatter of clustered data
</p>
</div>
</div>
<div id="生物學悖論-ecological-fallacy" class="section level3">
<h3><span class="header-section-number">58.4.3</span> 生物學悖論 ecological fallacy</h3>
<p>生物學悖論常見於我們認爲某分層數據中層級變量之間的關系，同樣適用與層級中的個體之間: 例如比較 A 國 和 B 國之間心血管疾病的發病率，發現 A 國國民食鹽平均攝入量高於 B 國，很多人可能就會下結論說食鹽攝入量高的個體，心血管疾病發病的危險度較高。然而，這樣的推論很多時候是錯誤的。</p>
<p>曾經在 <span class="citation">(Robinson <a href="#ref-Robinson1950" role="doc-biblioref">1950</a>)</span> 論文中舉過的著名例子: 該研究調查美國每個州的移民比例，和該州相應的識字率之間的關系。研究者發現，移民比例較高的州，其識字率也較高 (相關系數 0.53)。由此就有人下結論說移民越多，那個州的教育水平會比較高。但是實際情況是，把每個個體的受教育水平和該個體本身是不是移民做了相關系數分析之後發現，這個關系其實是負相關 (-0.11)。所以說在州的水平作出的統計學推斷-移民多的州受教育水平高-是不正確的。之所以在州水平發現移民比例和受教育水平之間的正關系，是因爲移民傾向於居住在教育水平本來就比較高的本土出生美國人的州。</p>
</div>
<div id="分解層級數據" class="section level3">
<h3><span class="header-section-number">58.4.4</span> 分解層級數據</h3>
<p>如果是分析最初層級數據 (level 1) 的話，我們還需要考慮下列一些問題:</p>
<ul>
<li>當心數據被多次利用</li>
</ul>
<p>如果我們關心的變量其實是在第二層級的 (level 2/cluster level)，但是你卻把它當作是第一層級的數據，就會引起<strong>數據很多</strong>的錯覺，因爲同一層的個體他們的層屬變量都是一樣的，你擁有的數據其實並沒有你想的那麼多。</p>
<p>前文中用過的 GCSE 數據其實是一個很好的例子，下表中歸納了調查的學校類型 (男校，女校或者混合校)，以及按照每個學生個人所屬學校類型的總結，可以看出，當你嘗試使用個人 (elementary level) 水平的數據分析實際上是第二層級數據的特性時，你會被誤導。因爲個人數據告訴你， 34% 的學生在女校學習，然而正確的分析法應該是，學校中有 31% 的學校是女校。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Aggregated and disaggregated
</caption>
<thead>
<tr>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
School type
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Cluster Level
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Elementary Level
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
N
</th>
<th style="text-align:center;">
%
</th>
<th style="text-align:center;">
N
</th>
<th style="text-align:center;">
%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
mixed
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
2169
</td>
<td style="text-align:center;">
53
</td>
</tr>
<tr>
<td style="text-align:center;">
boys only
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
513
</td>
<td style="text-align:center;">
13
</td>
</tr>
<tr>
<td style="text-align:center;">
girls only
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
1377
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
4059
</td>
<td style="text-align:center;">
100
</td>
</tr>
</tbody>
</table>
<ul>
<li>分層數據分析法</li>
</ul>
<p>有人會說，既然如此，那麼我們就把數據放在每層當中分析就好了 (stratified analyses)。還是用前文中用過的人造 5 層數據來說明這樣做的弊端。前面用了兩種方法 (total regression, between regression) 來總結這個 5 層的人造數據 <a href="10-Hierarchical-models.html#fig:artificialdata02">58.9</a>。最後一種分析此數據的方法是，把 5 層數據分開分別做回歸線如圖 <a href="10-Hierarchical-models.html#fig:artificialdata03">58.10</a>。等同於我們的對數據擬合五次下面的回歸方程:</p>
<p><span class="math display">\[
\hat Y_{ij} - \bar{Y}_j = \beta(X_{ij} - \bar{X}_j)
\]</span></p>
<p>這種模型被叫做<strong>層內回歸 (within regression)</strong>。這 5 個線性回歸的斜率都是 1，是五條不同截距的平行直線。因爲我們自己編造的數據的緣故，現實數據不太可能恰好所有層內回歸的斜率都是完全相同的。這其實也是曾內回歸法的一個默認前提 – 每層數據中解釋變量和結果變量之間的關系是相同的。</p>
<div class="figure" style="text-align: center"><span id="fig:artificialdata03"></span>
<img src="bookdown_files/figure-html/artificialdata03-1.png" alt="Artificial data: within cluster regressions" width="80%" />
<p class="caption">
圖 58.10: Artificial data: within cluster regressions
</p>
</div>
</div>
<div id="固定效應模型-fixed-effect-model" class="section level3">
<h3><span class="header-section-number">58.4.5</span> 固定效應模型 fixed effect model</h3>
<p>無論數據中的分層結構是否有現實意義 (如果說是五種不同的民族，那就有顯著的現實意義)，在回歸模型中都<strong>有必要考慮這個分層結構對數據的變異的貢獻</strong> (the contribution of the clusters to the data variation)。</p>
<p>線性回歸章節中我們使用的是五個啞變量來代表不同組別加以分析:</p>
<p><span class="math display">\[
Y_{ij} = \alpha_1 I_{i, j = 1} + \alpha_2 I_{i, j=2} + \cdots + \alpha_5 I_{i, j=5} + \beta_1X_{ij} + \varepsilon_{ij}
\]</span></p>
<p>其中 <span class="math inline">\(j\)</span> 是所屬層級編號。該模型中的 <span class="math inline">\(\varepsilon_{ij}\)</span> 被認爲服從均值爲零，方差爲 <span class="math inline">\(\sigma_{\varepsilon}^2\)</span> 的正態分布。該模型也可以簡寫爲:</p>
<p><span class="math display">\[
Y_{ij} = \alpha_j + \beta_1X_{ij} + \epsilon_{ij}
\]</span>
一樣一預案
這樣的模型在等級線性回歸模型中被認爲是<strong>固定效應模型 fixed effect model</strong>。它其實是默認給五個層級五個不同的截距，每層內部 <span class="math inline">\(X,Y\)</span> 之間的關系 (斜率) 則被認爲是完全相同的 (namely the within cluster models are the same)。</p>
<p>本課剛開始的例子中有個數據是來自 6 所不同醫院 72 名患者的收縮期血壓的數據。我們現在來分析這些人中血壓和年齡之間的關系。下面的散點圖重現了六所醫院的72名患者的血壓和年齡。</p>
<pre><code>## Warning: New theme missing the following elements: axis.ticks.length.x, axis.ticks.length.x.top,
## axis.ticks.length.x.bottom, axis.ticks.length.y, axis.ticks.length.y.left, axis.ticks.length.y.right</code></pre>
<div class="figure" style="text-align: center"><span id="fig:Hier01-7"></span>
<img src="bookdown_files/figure-html/Hier01-7-1.png" alt="SBP versus age: different symbols identify the six hospitals" width="90%" />
<p class="caption">
圖 58.11: SBP versus age: different symbols identify the six hospitals
</p>
</div>
<p>下面在 R 裏擬合這個固定效應模型:</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb707-1" title="1">Bp &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/bp.dta&quot;</span>)</a>
<a class="sourceLine" id="cb707-2" title="2"></a>
<a class="sourceLine" id="cb707-3" title="3">Bp<span class="op">$</span>hosp &lt;-<span class="st"> </span><span class="kw">as.factor</span>(Bp<span class="op">$</span>hosp)</a>
<a class="sourceLine" id="cb707-4" title="4">Bp &lt;-<span class="st"> </span>Bp <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb707-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_age =</span> age <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(age))</a>
<a class="sourceLine" id="cb707-6" title="6"><span class="co"># 通過指定截距爲零，獲取每個醫院的回歸線的截距</span></a>
<a class="sourceLine" id="cb707-7" title="7">Model0 &lt;-<span class="st"> </span><span class="kw">lm</span>(bp <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st">  </span>c_age <span class="op">+</span><span class="st"> </span>hosp, <span class="dt">data =</span> Bp) </a>
<a class="sourceLine" id="cb707-8" title="8"></a>
<a class="sourceLine" id="cb707-9" title="9"><span class="kw">summary</span>(Model0)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bp ~ 0 + c_age + hosp, data = Bp)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -34.7803  -9.8106  -0.5285   7.4000  55.5287 
## 
## Coefficients:
##        Estimate Std. Error t value Pr(&gt;|t|)    
## c_age   1.00223    0.43766   2.290  0.02528 *  
## hosp1 139.15421    5.73015  24.285  &lt; 2e-16 ***
## hosp2 130.21017    5.86957  22.184  &lt; 2e-16 ***
## hosp3 129.58146    5.66881  22.859  &lt; 2e-16 ***
## hosp4 124.00188    5.70326  21.742  &lt; 2e-16 ***
## hosp5 114.58859    5.70289  20.093  &lt; 2e-16 ***
## hosp6 115.79702    5.85632  19.773  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19.136 on 65 degrees of freedom
## Multiple R-squared:  0.97954,    Adjusted R-squared:  0.97733 
## F-statistic: 444.46 on 7 and 65 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb709-1" title="1"><span class="co"># 先生成一個新的醫院變量 hops1 = 1。然後使用偏 F 檢驗法</span></a>
<a class="sourceLine" id="cb709-2" title="2"><span class="co"># 檢驗控制了患者的年齡以後，這六所醫院的截距是否各自不相同。</span></a>
<a class="sourceLine" id="cb709-3" title="3">Bp<span class="op">$</span>hosp1 &lt;-<span class="st"> </span>Bp<span class="op">$</span>hosp[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb709-4" title="4">mod2 &lt;-<span class="st"> </span><span class="kw">lm</span>(bp <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st">  </span>c_age <span class="op">+</span><span class="st"> </span><span class="kw">as.numeric</span>(hosp1), <span class="dt">data =</span> Bp)</a>
<a class="sourceLine" id="cb709-5" title="5"><span class="kw">anova</span>(Model0, mod2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: bp ~ 0 + c_age + hosp
## Model 2: bp ~ 0 + c_age + as.numeric(hosp1)
##   Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)  
## 1     65 23801.9                                
## 2     70 27751.6 -5  -3949.73 2.15725 0.069638 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>偏 F 檢驗法給出的結果 <span class="math inline">\(F(5, 65) = 2.16, P = 0.07\)</span>，所以說，數據其實告訴我們，調整了年齡之後，這六所醫院患者中年齡和血壓之間關系的回歸線有不同的截距。</p>
</div>
</div>
<div id="簡單線性迴歸複習" class="section level2">
<h2><span class="header-section-number">58.5</span> 簡單線性迴歸複習</h2>
<p>滾回線性回歸章節 <a href="04-Linear-Regression.html#lm">26</a>。</p>
</div>
<div id="練習題-7" class="section level2">
<h2><span class="header-section-number">58.6</span> 練習題</h2>
<div id="數據" class="section level3">
<h3><span class="header-section-number">58.6.1</span> 數據</h3>
<ol style="list-style-type: decimal">
<li>High-School-and-Beyond 數據 <br> 本數據來自1982年美國國家教育統計中心 (National Center for Education Statistics, NCES) 對美國公立學校和天主教會學校的一項普查。曾經在 Hierarchical Linear Model <span class="citation">(Raudenbush and Bryk <a href="#ref-Raudenbush2002" role="doc-biblioref">2002</a>)</span> 一書中作爲範例使用。其數據的變量名和各自含義如下：</li>
</ol>
<pre><code>minority           indicatory of student ethinicity (1 = minority, 0 = other)
female             pupil&#39;s gender
ses                standardized socio-economic status score
mathach            measure of mathematics achievement
size               school&#39;s total number of pupils
sector             school&#39;s sector: 1 = catholic, 0 = not catholic
schoolid           school identifier</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>PEFR 數據 <br> 數據本身是 17 名研究對象用兩種不同的測量方法測量兩次每個人的最大呼氣流速 (peak-expiratory-flow rate, PEFR)。最早在1986年的柳葉刀雜誌發表 <span class="citation">(Bland and Altman <a href="#ref-Bland1986" role="doc-biblioref">1986</a>)</span>。兩種測量法的名稱分別是 “Standard Wright” 和 “Mini Wright” peak flow meter。變量名和個字含義如下：</li>
</ol>
<pre><code>id                 participant identifier
wp1                standard wright measure at 1st occasion
wp2                standard wright measure at 2nd occasion
wm1                mini wright measure at 1st occasion
wm2                mini wright measure at 2nd occasion</code></pre>
</div>
<div id="問題" class="section level3">
<h3><span class="header-section-number">58.6.2</span> 問題</h3>
</div>
<div id="將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵" class="section level3">
<h3><span class="header-section-number">58.6.3</span> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</h3>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb713-1" title="1">hsb_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/hsb_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb713-2" title="2"><span class="kw">length</span>(<span class="kw">unique</span>(hsb_selected<span class="op">$</span>schoolid)) <span class="co">## number of school = 160</span></a></code></pre></div>
<pre><code>## [1] 160</code></pre>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb715-1" title="1"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb715-2" title="2">hsb &lt;-<span class="st"> </span>hsb_selected[<span class="op">!</span><span class="kw">duplicated</span>(hsb_selected<span class="op">$</span>schoolid), ]</a>
<a class="sourceLine" id="cb715-3" title="3"></a>
<a class="sourceLine" id="cb715-4" title="4"><span class="co">## about 44 % of the schools are Catholic schools</span></a>
<a class="sourceLine" id="cb715-5" title="5"><span class="kw">with</span>(hsb, <span class="kw">tab1</span>(sector, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## sector : 
##         Frequency Percent Cum. percent
## 0              90   56.25        56.25
## 1              70   43.75       100.00
##   Total       160  100.00       100.00</code></pre>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb717-1" title="1"><span class="co">## among all the pupils, about 53% are females</span></a>
<a class="sourceLine" id="cb717-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(female, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## female : 
##         Frequency Percent Cum. percent
## 0            3390   47.18        47.18
## 1            3795   52.82       100.00
##   Total      7185  100.00       100.00</code></pre>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb719-1" title="1"><span class="co">## among all the pupils, about 27.5% are from ethnic minorities</span></a>
<a class="sourceLine" id="cb719-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## minority : 
##         Frequency Percent Cum. percent
## 0            5211   72.53        72.53
## 1            1974   27.47       100.00
##   Total      7185  100.00       100.00</code></pre>
</div>
<div id="爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值" class="section level3">
<h3><span class="header-section-number">58.6.4</span> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</h3>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb721-1" title="1">hsb5 &lt;-<span class="st"> </span><span class="kw">subset</span>(hsb_selected, schoolid <span class="op">&lt;</span><span class="st"> </span><span class="dv">1320</span>)</a>
<a class="sourceLine" id="cb721-2" title="2">Mean_ses_math &lt;-<span class="st"> </span><span class="kw">ddply</span>(hsb5,<span class="op">~</span>schoolid,summarise,<span class="dt">mean_ses=</span><span class="kw">mean</span>(ses),<span class="dt">mean_math=</span><span class="kw">mean</span>(mathach))</a>
<a class="sourceLine" id="cb721-3" title="3"><span class="co">## the mean SES score ranges from -0.4255 to +0.5280</span></a>
<a class="sourceLine" id="cb721-4" title="4"><span class="co">## the mean Maths score ranges from 7.636 to 16.255</span></a>
<a class="sourceLine" id="cb721-5" title="5">Mean_ses_math</a></code></pre></div>
<pre><code>##   schoolid    mean_ses  mean_math
## 1     1224 -0.43438298  9.7154468
## 2     1288  0.12159999 13.5108000
## 3     1296 -0.42550000  7.6359583
## 4     1308  0.52800000 16.2554999
## 5     1317  0.34533333 13.1776875</code></pre>
</div>
<div id="先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中" class="section level3">
<h3><span class="header-section-number">58.6.5</span> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</h3>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb723-1" title="1"><span class="co">## plot the scatter of mathach and ses among these 5 schools</span></a>
<a class="sourceLine" id="cb723-2" title="2"></a>
<a class="sourceLine" id="cb723-3" title="3"><span class="kw">ggplot</span>(hsb5, <span class="kw">aes</span>(<span class="dt">x =</span> ses, <span class="dt">y =</span> mathach)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb723-4" title="4"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb723-5" title="5"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb723-6" title="6">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb723-7" title="7">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb723-8" title="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;SES&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math achievement&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb723-9" title="9"><span class="st">  </span><span class="kw">xlim</span>(<span class="op">-</span><span class="fl">2.05</span>, <span class="fl">2.05</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb723-10" title="10"><span class="st">  </span><span class="kw">ylim</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">30</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb723-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mathses"></span>
<img src="bookdown_files/figure-html/mathses-1.png" alt="Scatter plot of SES and math achievements among all pupils from first 5 schools, assuming that they are all independent" width="80%" />
<p class="caption">
圖 58.12: Scatter plot of SES and math achievements among all pupils from first 5 schools, assuming that they are all independent
</p>
</div>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb724-1" title="1">Total_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5)</a>
<a class="sourceLine" id="cb724-2" title="2"><span class="co">## the total regression model gives an estimated regression coefficient for the SES</span></a>
<a class="sourceLine" id="cb724-3" title="3"><span class="co">## of each pupil equal to 3.31 (SE=0.66)</span></a>
<a class="sourceLine" id="cb724-4" title="4"><span class="kw">summary</span>(Total_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses, data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -15.23022  -5.08316  -0.68614   5.11170  14.68513 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 11.45652    0.47342 24.1997 &lt; 2.2e-16 ***
## ses          3.30696    0.66021  5.0089 1.267e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.4708 on 186 degrees of freedom
## Multiple R-squared:  0.11886,    Adjusted R-squared:  0.11412 
## F-statistic:  25.09 on 1 and 186 DF,  p-value: 1.2667e-06</code></pre>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb726-1" title="1">hsb5<span class="op">$</span>Pred_T &lt;-<span class="st"> </span>Total_reg<span class="op">$</span>fitted.values <span class="co"># save the fitted values to the dataset</span></a></code></pre></div>
</div>
<div id="用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model" class="section level3">
<h3><span class="header-section-number">58.6.6</span> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</h3>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb727-1" title="1">Btw_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mean_math <span class="op">~</span><span class="st"> </span>mean_ses, <span class="dt">data =</span> Mean_ses_math)</a>
<a class="sourceLine" id="cb727-2" title="2"><span class="co">## the regression model for the school level variables (between model) gives</span></a>
<a class="sourceLine" id="cb727-3" title="3"><span class="co">## an estimated regression coefficient of 7.29 (SE=1.41)</span></a>
<a class="sourceLine" id="cb727-4" title="4"><span class="kw">summary</span>(Btw_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mean_math ~ mean_ses, data = Mean_ses_math)
## 
## Residuals:
##        1        2        3        4        5 
##  1.02010  0.76212 -1.12415  0.54401 -1.20209 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 11.86216    0.55664 21.3102 0.0002261 ***
## mean_ses     7.29039    1.40703  5.1814 0.0139557 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.2418 on 3 degrees of freedom
## Multiple R-squared:  0.89949,    Adjusted R-squared:  0.86598 
## F-statistic: 26.847 on 1 and 3 DF,  p-value: 0.013956</code></pre>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb729-1" title="1">Mean_ses_math<span class="op">$</span>Pred_B &lt;-<span class="st"> </span>Btw_reg<span class="op">$</span>fitted.values <span class="co"># save the fitted values to the dataset</span></a></code></pre></div>
</div>
<div id="分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型" class="section level3">
<h3><span class="header-section-number">58.6.7</span> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</h3>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb730-1" title="1">Within_schl1 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1224</span>,])</a>
<a class="sourceLine" id="cb730-2" title="2">Within_schl2 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1288</span>,])</a>
<a class="sourceLine" id="cb730-3" title="3">Within_schl3 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1296</span>,])</a>
<a class="sourceLine" id="cb730-4" title="4">Within_schl4 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1308</span>,])</a>
<a class="sourceLine" id="cb730-5" title="5">Within_schl5 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1317</span>,])</a>
<a class="sourceLine" id="cb730-6" title="6"><span class="co"># the within school regressions gives estimated slopes which have a mean of 1.65</span></a>
<a class="sourceLine" id="cb730-7" title="7"><span class="co"># and which ranges between 0.126 and 3.255</span></a>
<a class="sourceLine" id="cb730-8" title="8"><span class="kw">summary</span>(<span class="kw">c</span>(Within_schl1<span class="op">$</span>coefficients[<span class="dv">2</span>], Within_schl2<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb730-9" title="9">      Within_schl3<span class="op">$</span>coefficients[<span class="dv">2</span>], Within_schl4<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb730-10" title="10">      Within_schl5<span class="op">$</span>coefficients[<span class="dv">2</span>]))</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.12602 1.07596 1.27391 1.64799 2.50858 3.25545</code></pre>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb732-1" title="1"><span class="co"># the SEs ranging between 1.21 and 3.00</span></a>
<a class="sourceLine" id="cb732-2" title="2"><span class="kw">summary</span>(<span class="kw">c</span>(<span class="kw">summary</span>(Within_schl1)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-3" title="3">          <span class="kw">summary</span>(Within_schl2)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-4" title="4">          <span class="kw">summary</span>(Within_schl3)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-5" title="5">          <span class="kw">summary</span>(Within_schl4)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-6" title="6">          <span class="kw">summary</span>(Within_schl5)<span class="op">$</span>coefficients[<span class="dv">4</span>]))</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  1.2090  1.4359  1.7652  1.8987  2.0797  3.0034</code></pre>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb734-1" title="1">hsb5<span class="op">$</span>Pred_W &lt;-<span class="st"> </span><span class="kw">c</span>(Within_schl1<span class="op">$</span>fitted.values, Within_schl2<span class="op">$</span>fitted.values,</a>
<a class="sourceLine" id="cb734-2" title="2">      Within_schl3<span class="op">$</span>fitted.values, Within_schl4<span class="op">$</span>fitted.values,</a>
<a class="sourceLine" id="cb734-3" title="3">      Within_schl5<span class="op">$</span>fitted.values) <span class="co">## save the predicted value into the dataset</span></a></code></pre></div>
</div>
<div id="比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同" class="section level3">
<h3><span class="header-section-number">58.6.8</span> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</h3>
<ul>
<li>總體模型 (Total regression model) 實際上無視了學生的性別，種族等可能帶來的混雜效果；</li>
<li>學校間模型 (Between model) 估計的實際上是<strong>SES均值</strong>每增加一個單位，與之對應的<strong>數學平均成績</strong>的改變量，<strong>這個模型絕對不可用與評估個人的 SES 與數學成績之間的關係</strong>；</li>
<li>學校內模型 (Within model) 擬合的 SES 與數學成績之間的關係變得十分地不精確 (SEs are fairly large)，變化幅度也很大。</li>
</ul>
</div>
<div id="把三種模型的數學成績擬合值散點圖繪製在同一張圖內" class="section level3">
<h3><span class="header-section-number">58.6.9</span> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</h3>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb735-1" title="1">Mean &lt;-<span class="st"> </span>Mean_ses_math[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]</a>
<a class="sourceLine" id="cb735-2" title="2"><span class="kw">names</span>(Mean) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;schoolid&quot;</span>, <span class="st">&quot;ses&quot;</span>, <span class="st">&quot;Pred_W&quot;</span>)</a>
<a class="sourceLine" id="cb735-3" title="3"></a>
<a class="sourceLine" id="cb735-4" title="4"></a>
<a class="sourceLine" id="cb735-5" title="5"><span class="kw">ggplot</span>(hsb5, <span class="kw">aes</span>(<span class="dt">x =</span> ses, <span class="dt">y =</span> Pred_W, <span class="dt">group =</span> schoolid)) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-6" title="6"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-7" title="7"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> Total_reg<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">slope =</span> Total_reg<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb735-8" title="8">               <span class="dt">colour =</span> <span class="st">&quot;dark blue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-9" title="9"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> Btw_reg<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">slope =</span> Btw_reg<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb735-10" title="10">               <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-11" title="11"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Mean, <span class="dt">shape =</span> <span class="dv">17</span>, <span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">colour =</span> <span class="st">&quot;Red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-12" title="12"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb735-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb735-14" title="14">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb735-15" title="15">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-16" title="16"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;SES&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Fitted regression lines (Maths achievement)&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb735-17" title="17"><span class="st">  </span><span class="kw">xlim</span>(<span class="op">-</span><span class="fl">2.05</span>, <span class="fl">2.05</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb735-18" title="18"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">5</span>, <span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-19" title="19"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb735-20" title="20"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>,</a>
<a class="sourceLine" id="cb735-21" title="21">  <span class="dt">hjust =</span> <span class="dv">0</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">caption =</span> <span class="st">&quot;Black dash line: Within regression model;</span></a>
<a class="sourceLine" id="cb735-22" title="22"><span class="st">Blue solid line: Total regression model;</span></a>
<a class="sourceLine" id="cb735-23" title="23"><span class="st">Red solid line: Between regression model;</span></a>
<a class="sourceLine" id="cb735-24" title="24"><span class="st">Red triangle: School mean values&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mathses-3models"></span>
<img src="bookdown_files/figure-html/mathses-3models-1.png" alt="High-school-and-beyond data: Predicted values by Total, Between, and Within regression models" width="80%" />
<p class="caption">
圖 58.13: High-school-and-beyond data: Predicted values by Total, Between, and Within regression models
</p>
</div>
</div>
<div id="用這-5-個學校的數據擬合一個固定效應線性迴歸模型" class="section level3">
<h3><span class="header-section-number">58.6.10</span> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</h3>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb736-1" title="1">Fixed_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(schoolid), <span class="dt">data =</span> hsb5)</a>
<a class="sourceLine" id="cb736-2" title="2"></a>
<a class="sourceLine" id="cb736-3" title="3"><span class="co">## Fitting a fixed effect model to these data is equivalent to forcing</span></a>
<a class="sourceLine" id="cb736-4" title="4"><span class="co">## a common slope onto the five within regression models. It gives an</span></a>
<a class="sourceLine" id="cb736-5" title="5"><span class="co">## estimated slope of 1.789 (SE=0.76), close to their average of 1.64799.</span></a>
<a class="sourceLine" id="cb736-6" title="6"><span class="co">## Note that controlling for female, minority, and sector but not for</span></a>
<a class="sourceLine" id="cb736-7" title="7"><span class="co">## schoolid leads to roughly the same estimate (slope = 1.68, SE=0.75)</span></a>
<a class="sourceLine" id="cb736-8" title="8"></a>
<a class="sourceLine" id="cb736-9" title="9"><span class="kw">summary</span>(Fixed_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses + factor(schoolid), data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -13.97593  -4.19683  -0.75189   5.22088  16.38133 
## 
## Coefficients:
##                      Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)          10.49254    0.96761 10.8438 &lt; 2.2e-16 ***
## ses                   1.78896    0.75939  2.3558  0.019548 *  
## factor(schoolid)1288  2.80072    1.60041  1.7500  0.081803 .  
## factor(schoolid)1296 -2.09538    1.27973 -1.6374  0.103283    
## factor(schoolid)1308  4.81839    1.81826  2.6500  0.008758 ** 
## factor(schoolid)1317  2.06736    1.41005  1.4662  0.144332    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.2362 on 182 degrees of freedom
## Multiple R-squared:  0.1992, Adjusted R-squared:  0.1772 
## F-statistic: 9.0544 on 5 and 182 DF,  p-value: 1.0512e-07</code></pre>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb738-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>minority <span class="op">+</span><span class="st"> </span>sector, <span class="dt">data =</span> hsb5))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses + female + minority + sector, data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -13.09128  -4.17332  -0.46306   4.50807  15.33205 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 12.54543    0.86027 14.5831 &lt; 2.2e-16 ***
## ses          1.68055    0.74489  2.2561 0.0252480 *  
## female      -1.54861    0.94857 -1.6326 0.1042780    
## minority    -3.19635    0.95450 -3.3487 0.0009857 ***
## sector       3.98121    1.11941  3.5565 0.0004785 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.1696 on 183 degrees of freedom
## Multiple R-squared:  0.2119, Adjusted R-squared:  0.19467 
## F-statistic: 12.301 on 4 and 183 DF,  p-value: 7.0265e-09</code></pre>
</div>
<div id="讀入-pefr-數據" class="section level3">
<h3><span class="header-section-number">58.6.11</span> 讀入 PEFR 數據。</h3>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb740-1" title="1">pefr &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pefr.dta&quot;</span>)</a>
<a class="sourceLine" id="cb740-2" title="2"><span class="co"># the data are in wide format</span></a>
<a class="sourceLine" id="cb740-3" title="3">pefr</a></code></pre></div>
<pre><code>## # A tibble: 17 x 5
##       id   wp1   wp2   wm1   wm2
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1   494   490   512   525
##  2     2   395   397   430   415
##  3     3   516   512   520   508
##  4     4   434   401   428   444
##  5     5   476   470   500   500
##  6     6   557   611   600   625
##  7     7   413   415   364   460
##  8     8   442   431   380   390
##  9     9   650   638   658   642
## 10    10   433   429   445   432
## 11    11   417   420   432   420
## 12    12   656   633   626   605
## 13    13   267   275   260   227
## 14    14   478   492   477   467
## 15    15   178   165   259   268
## 16    16   423   372   350   370
## 17    17   427   421   451   443</code></pre>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb742-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb742-2" title="2">pefr_long &lt;-<span class="st"> </span>pefr <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb742-7" title="7">pefr_long</a></code></pre></div>
<pre><code>## # A tibble: 34 x 4
##       id occasion    wm    wp
##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1 1          512   494
##  2     1 2          525   490
##  3     2 1          430   395
##  4     2 2          415   397
##  5     3 1          520   516
##  6     3 2          508   512
##  7     4 1          428   434
##  8     4 2          444   401
##  9     5 1          500   476
## 10     5 2          500   470
## # ... with 24 more rows</code></pre>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb744-1" title="1"><span class="co">## figure shows slightly closer agreement between the repeated measures of standard Wright,</span></a>
<a class="sourceLine" id="cb744-2" title="2"><span class="co">## than between those of Mini Wright</span></a>
<a class="sourceLine" id="cb744-3" title="3"></a>
<a class="sourceLine" id="cb744-4" title="4"><span class="kw">ggplot</span>(pefr_long, <span class="kw">aes</span>(<span class="dt">x =</span> id, <span class="dt">y =</span> wp, <span class="dt">fill =</span> occasion)) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-5" title="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-6" title="6"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">mean</span>(pefr_long<span class="op">$</span>wp), <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-7" title="7"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb744-8" title="8"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">17</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb744-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb744-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb744-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-12" title="12"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Subject ID&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;W Measurements&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb744-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb744-14" title="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), </a>
<a class="sourceLine" id="cb744-15" title="15">  <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tworecordings"></span>
<img src="bookdown_files/figure-html/tworecordings-1.png" alt="Two recordings of PEFR taken with the standard Wright meter" width="80%" />
<p class="caption">
圖 58.14: Two recordings of PEFR taken with the standard Wright meter
</p>
</div>
</div>
<div id="求每個患者的-wp-兩次測量平均值" class="section level3">
<h3><span class="header-section-number">58.6.12</span> 求每個患者的 <code>wp</code> 兩次測量平均值</h3>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb745-1" title="1"><span class="co"># the means range from 171.5 to 644.5</span></a>
<a class="sourceLine" id="cb745-2" title="2"></a>
<a class="sourceLine" id="cb745-3" title="3"><span class="kw">with</span>(pefr_long, <span class="kw">summ</span>(wp, <span class="dt">by =</span> id, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## For id = 1 
##  obs. mean   median  s.d.   min.   max.  
##  2    492    492     2.828  490    494   
## 
## For id = 2 
##  obs. mean   median  s.d.   min.   max.  
##  2    396    396     1.414  395    397   
## 
## For id = 3 
##  obs. mean   median  s.d.   min.   max.  
##  2    514    514     2.828  512    516   
## 
## For id = 4 
##  obs. mean   median  s.d.   min.   max.  
##  2    417.5  417.5   23.335 401    434   
## 
## For id = 5 
##  obs. mean   median  s.d.   min.   max.  
##  2    473    473     4.243  470    476   
## 
## For id = 6 
##  obs. mean   median  s.d.   min.   max.  
##  2    584    584     38.184 557    611   
## 
## For id = 7 
##  obs. mean   median  s.d.   min.   max.  
##  2    414    414     1.414  413    415   
## 
## For id = 8 
##  obs. mean   median  s.d.   min.   max.  
##  2    436.5  436.5   7.778  431    442   
## 
## For id = 9 
##  obs. mean   median  s.d.   min.   max.  
##  2    644    644     8.485  638    650   
## 
## For id = 10 
##  obs. mean   median  s.d.   min.   max.  
##  2    431    431     2.828  429    433   
## 
## For id = 11 
##  obs. mean   median  s.d.   min.   max.  
##  2    418.5  418.5   2.121  417    420   
## 
## For id = 12 
##  obs. mean   median  s.d.   min.   max.  
##  2    644.5  644.5   16.263 633    656   
## 
## For id = 13 
##  obs. mean   median  s.d.   min.   max.  
##  2    271    271     5.657  267    275   
## 
## For id = 14 
##  obs. mean   median  s.d.   min.   max.  
##  2    485    485     9.899  478    492   
## 
## For id = 15 
##  obs. mean   median  s.d.   min.   max.  
##  2    171.5  171.5   9.192  165    178   
## 
## For id = 16 
##  obs. mean   median  s.d.   min.   max.  
##  2    397.5  397.5   36.062 372    423   
## 
## For id = 17 
##  obs. mean   median  s.d.   min.   max.  
##  2    424    424     4.243  421    427</code></pre>
</div>
<div id="在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數" class="section level3">
<h3><span class="header-section-number">58.6.13</span> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</h3>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb747-1" title="1"><span class="kw">with</span>(pefr_long, <span class="kw">anova</span>(<span class="kw">lm</span>(wp<span class="op">~</span><span class="kw">factor</span>(id))))</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wp
##            Df Sum Sq  Mean Sq F value    Pr(&gt;F)    
## factor(id) 16 441599 27599.91   117.8 3.145e-14 ***
## Residuals  17   3983   234.29                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb749-1" title="1"><span class="co">#library(lme4)</span></a>
<a class="sourceLine" id="cb749-2" title="2">( fit &lt;-<span class="st"> </span><span class="kw">lmer</span>(wp <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data=</span>pefr_long) )</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerModLmerTest&#39;]
## Formula: wp ~ (1 | id)
##    Data: pefr_long
## REML criterion at convergence: 353.5472
## Random effects:
##  Groups   Name        Std.Dev.
##  id       (Intercept) 116.974 
##  Residual              15.307 
## Number of obs: 34, groups:  id, 17
## Fixed Effects:
## (Intercept)  
##      447.88</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb751-1" title="1"><span class="kw">sqrt</span>((<span class="dv">27600</span> <span class="op">-</span><span class="st"> </span><span class="dv">234</span>)<span class="op">/</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 116.97436</code></pre>
</div>
<div id="擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型" class="section level3">
<h3><span class="header-section-number">58.6.14</span> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</h3>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb753-1" title="1">Reg &lt;-<span class="st"> </span><span class="kw">lm</span>(wp <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb753-2" title="2"></a>
<a class="sourceLine" id="cb753-3" title="3"><span class="co"># The fixed effect regression model leads to the same ANOVA</span></a>
<a class="sourceLine" id="cb753-4" title="4"><span class="co"># table. To the same estimate of the residual SD = (15.307)</span></a>
<a class="sourceLine" id="cb753-5" title="5"><span class="co"># However, it does not give an estimate of the &quot;SD of id effect&quot;</span></a>
<a class="sourceLine" id="cb753-6" title="6"><span class="co"># Instead it gives estimates of mean PEFR for participant number 1</span></a>
<a class="sourceLine" id="cb753-7" title="7"><span class="co"># = 492 and estimates of the difference in means from him/her</span></a>
<a class="sourceLine" id="cb753-8" title="8"><span class="co"># for all the other 16 pariticipants</span></a>
<a class="sourceLine" id="cb753-9" title="9"><span class="kw">anova</span>(Reg)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wp
##            Df Sum Sq  Mean Sq F value    Pr(&gt;F)    
## factor(id) 16 441599 27599.91   117.8 3.145e-14 ***
## Residuals  17   3983   234.29                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb755-1" title="1"><span class="kw">summary</span>(Reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wp ~ factor(id), data = pefr_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -27.00  -3.75   0.00   3.75  27.00 
## 
## Coefficients:
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)   492.000     10.823  45.4569 &lt; 2.2e-16 ***
## factor(id)2   -96.000     15.307  -6.2718 8.435e-06 ***
## factor(id)3    22.000     15.307   1.4373 0.1687894    
## factor(id)4   -74.500     15.307  -4.8672 0.0001448 ***
## factor(id)5   -19.000     15.307  -1.2413 0.2313547    
## factor(id)6    92.000     15.307   6.0105 1.405e-05 ***
## factor(id)7   -78.000     15.307  -5.0958 8.972e-05 ***
## factor(id)8   -55.500     15.307  -3.6259 0.0020883 ** 
## factor(id)9   152.000     15.307   9.9303 1.715e-08 ***
## factor(id)10  -61.000     15.307  -3.9852 0.0009574 ***
## factor(id)11  -73.500     15.307  -4.8018 0.0001662 ***
## factor(id)12  152.500     15.307   9.9630 1.635e-08 ***
## factor(id)13 -221.000     15.307 -14.4382 5.665e-11 ***
## factor(id)14   -7.000     15.307  -0.4573 0.6532334    
## factor(id)15 -320.500     15.307 -20.9386 1.413e-13 ***
## factor(id)16  -94.500     15.307  -6.1738 1.020e-05 ***
## factor(id)17  -68.000     15.307  -4.4425 0.0003571 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.307 on 17 degrees of freedom
## Multiple R-squared:  0.99106,    Adjusted R-squared:  0.98265 
## F-statistic:  117.8 on 16 and 17 DF,  p-value: 3.145e-14</code></pre>
<p>上面的模型用數學表達式來描述就是：</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = \alpha_1 + \delta_i + \varepsilon_{ij} \\
\text{Where } \delta_j &amp; = \alpha_j - \alpha_1 \\
\text{and } \delta_1   &amp; = 0
\end{aligned}
\]</span></p>
</div>
<div id="將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式" class="section level3">
<h3><span class="header-section-number">58.6.15</span> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</h3>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb757-1" title="1">Reg1 &lt;-<span class="st"> </span><span class="kw">lm</span>((wp <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(wp)) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb757-2" title="2"></a>
<a class="sourceLine" id="cb757-3" title="3"><span class="co"># it leads to the same ANOVA table again, same residual SD</span></a>
<a class="sourceLine" id="cb757-4" title="4"><span class="kw">anova</span>(Reg1)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: (wp - mean(wp))
##            Df Sum Sq  Mean Sq F value     Pr(&gt;F)    
## factor(id) 17 441599 25976.38 110.871 4.5349e-14 ***
## Residuals  17   3983   234.29                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb759-1" title="1"><span class="kw">summary</span>(Reg1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = (wp - mean(wp)) ~ 0 + factor(id), data = pefr_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -27.00  -3.75   0.00   3.75  27.00 
## 
## Coefficients:
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## factor(id)1    44.118     10.823   4.0761 0.0007863 ***
## factor(id)2   -51.882     10.823  -4.7935 0.0001692 ***
## factor(id)3    66.118     10.823   6.1087 1.158e-05 ***
## factor(id)4   -30.382     10.823  -2.8071 0.0121232 *  
## factor(id)5    25.118     10.823   2.3207 0.0329951 *  
## factor(id)6   136.118     10.823  12.5762 4.894e-10 ***
## factor(id)7   -33.882     10.823  -3.1305 0.0060933 ** 
## factor(id)8   -11.382     10.823  -1.0516 0.3076854    
## factor(id)9   196.118     10.823  18.1197 1.493e-12 ***
## factor(id)10  -16.882     10.823  -1.5598 0.1372300    
## factor(id)11  -29.382     10.823  -2.7147 0.0147164 *  
## factor(id)12  196.618     10.823  18.1659 1.432e-12 ***
## factor(id)13 -176.882     10.823 -16.3425 7.887e-12 ***
## factor(id)14   37.118     10.823   3.4294 0.0031978 ** 
## factor(id)15 -276.382     10.823 -25.5355 5.342e-15 ***
## factor(id)16  -50.382     10.823  -4.6549 0.0002269 ***
## factor(id)17  -23.882     10.823  -2.2065 0.0413886 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.307 on 17 degrees of freedom
## Multiple R-squared:  0.99106,    Adjusted R-squared:  0.98212 
## F-statistic: 110.87 on 17 and 17 DF,  p-value: 4.5349e-14</code></pre>
<p>上面的模型用數學表達式來描述就是：</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} - \mu &amp; = \gamma_j + \varepsilon_{ij} \\
      Y_{ij} &amp; = \mu +  \gamma_j + \varepsilon_{ij} \\
\text{Where } \mu &amp; \text{ is the overall mean} \\
\text{and } \sum_{j=1}^J\gamma_j &amp; = 0\\
\end{aligned}
\]</span></p>
</div>
<div id="計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差" class="section level3">
<h3><span class="header-section-number">58.6.16</span> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</h3>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb761-1" title="1"><span class="co"># the individual level intercepts have mean zero and SD = 117.47, larger than the estimated</span></a>
<a class="sourceLine" id="cb761-2" title="2"><span class="co"># Std.Dev for id effect.</span></a>
<a class="sourceLine" id="cb761-3" title="3">Reg1<span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>##  factor(id)1  factor(id)2  factor(id)3  factor(id)4  factor(id)5  factor(id)6  factor(id)7 
##    44.117647   -51.882353    66.117647   -30.382353    25.117647   136.117647   -33.882353 
##  factor(id)8  factor(id)9 factor(id)10 factor(id)11 factor(id)12 factor(id)13 factor(id)14 
##   -11.382353   196.117647   -16.882353   -29.382353   196.617647  -176.882353    37.117647 
## factor(id)15 factor(id)16 factor(id)17 
##  -276.382353   -50.382353   -23.882353</code></pre>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb763-1" title="1"><span class="kw">summ</span>(Reg1<span class="op">$</span>coefficients, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.    min.     max.   
##  17   0      -16.882 117.473 -276.382 196.618</code></pre>
</div>
</div>
</div>
<div id="隨機截距模型-random-intercept-model" class="section level1">
<h1><span class="header-section-number">第 59 章</span> 隨機截距模型 random intercept model</h1>
<p>最簡單的隨機效應模型 – 隨機截距模型 random intercept model。</p>
<div id="隨機截距模型的定義" class="section level2">
<h2><span class="header-section-number">59.1</span> 隨機截距模型的定義</h2>
<p>有時，我們對每個分層各自的截距大小並不那麼感興趣，且如果只有固定效應的話，其實我們從某種程度上忽略掉了數據層與層之間變異的方差 (between cluster variation)。於是，在模型中考慮這些問題的解決方案就是 – 我們讓各層的截距呈現隨機效應 (treat the variation in cluster intercepts not as fixed)，<strong>把這些截距視爲來自與某種分布的隨機呈現 (randomly draws from some distribution)</strong>。於是原先的只有固定效應部分的模型，就增加了隨機截距部分:</p>
<p><span class="math display" id="eq:hier2-1">\[
\begin{aligned}
Y_{ij} &amp; = \mu + u_j + \varepsilon_{ij} \\
\text{where } u_j  &amp; \stackrel{N.I.D}{\sim} N(0, \sigma_u^2) \\
              \varepsilon_{ij} &amp; \stackrel{N.I.D}{\sim} N(0, \sigma_\varepsilon^2) \\
        u_j  &amp; \text{ are independent from } \varepsilon_{ij} \\
\end{aligned}
\tag{59.1}
\]</span></p>
<p>這個混合效應模型中，</p>
<ul>
<li><span class="math inline">\(\mu\)</span> 是總體均值;</li>
<li><span class="math inline">\(u_j\)</span> 是一個服從均值 0, 方差 (the population between cluster variance) 爲 <span class="math inline">\(\sigma_u^2\)</span> 的正態分布的隨機變量;</li>
<li><span class="math inline">\(\varepsilon_{ij}\)</span> 是隨機誤差，它也被認爲服從均值爲 0, 方差爲 <span class="math inline">\(\sigma_\varepsilon^2\)</span> 的正太分布，且這兩個隨機效應部分之間也是<strong>相互獨立的</strong>。</li>
<li>從該模型估算的結果變量 <span class="math inline">\(Y_{ij}\)</span> 的方差是 <span class="math inline">\(\sigma_u^2 + \sigma_\varepsilon^2\)</span>。</li>
<li>隨機截距模型又被叫做是 <strong>方差成分模型 (variance-component model)</strong>，或者是<strong>單向隨機效應方差模型 (one-way random effects ANOVA model)</strong>。</li>
</ul>
<p>這個模型和僅有固定效應的模型，有顯著的不同:</p>
<p><span class="math display">\[
Y_{ij} = \mu + \gamma_j + \varepsilon_{ij}
\]</span></p>
<p>固定效應模型裏，</p>
<ul>
<li><span class="math inline">\(\mu\)</span> 也是總體均值;</li>
<li><span class="math inline">\(\sum_{j=1}^J \gamma_j = 0\)</span> 是<strong>將各組不同截距之和強制爲零</strong>的過程;</li>
</ul>
<p>所以隨機截距模型打破了這個限制，使得隨機的截距 <span class="math inline">\(\mu_j\)</span> 成爲一個服從均值爲 0，方差爲 <span class="math inline">\(\sigma_u^2\)</span> 的 <strong>隨機變量</strong>。</p>
<p>隨機效應部分 <span class="math inline">\(u_j\)</span> 和隨機誤差 <span class="math inline">\(\varepsilon_{ij}\)</span> 之間相互獨立的前提，意味着兩個裏屬於不同層級的觀察之間是相互獨立的，但是反過來，同屬於一個層級的個體之間就變成了有相關性的了 (within cluster correlation):</p>
<p><span class="math display">\[
\begin{aligned}
\because Y_{1j} &amp; = \mu + u_j + \varepsilon_{1j} \\
         Y_{2j} &amp; = \mu + u_j + \varepsilon_{2j}  \\
\therefore \text{Cov}(Y_{1j}, Y_{2j}) &amp; =  \text{Cov}(u_j, u_j) + \text{Cov}(u_j, \varepsilon_{2j}) + \text{Cov}(\varepsilon_{1j}, u_j) + \text{Cov}(\varepsilon_{1j}, \varepsilon_{2j}) \\
                                      &amp; = \text{Cov}(u_j, u_j) = V(u_j, u_j)\\
                                      &amp; = \sigma_u^2
\end{aligned}
\]</span></p>
<p>由於 <span class="math inline">\(\text{Var}(Y_{1j}) = \text{Var}(Y_{2j}) = \sigma_u^2 + \sigma_\varepsilon^2\)</span>，所以，同屬一層的兩個個體之間的<strong>層內相關系數 (intra-class correlation)</strong>:</p>
<p><span class="math display">\[
\lambda = \frac{\text{Cov}(Y_{1j}, Y_{2j})}{\text{SD}(Y_{1j})\text{SD}(Y_{2j})} = \frac{\sigma_u^2}{\sigma_\varepsilon^2 + \sigma_u^2}
\]</span></p>
<p>從層內相關系數的公式也可看出，該相關系數可以同時被理解爲結果變量 <span class="math inline">\(Y_{ij}\)</span> 的方差中歸咎與層(cluster)結構的部分的百分比。</p>
<p>This is the within-cluster or intra-class correlation, that we will denote <span class="math inline">\(\lambda\)</span>. Note that it is also the proportion of total variance that is accounted for by the cluster.</p>
</div>
<div id="隨機截距模型的參數估計" class="section level2">
<h2><span class="header-section-number">59.2</span> 隨機截距模型的參數估計</h2>
<p>如此，我們就知道在隨機截距模型裏，有三個需要被估計的參數 <span class="math inline">\(\mu, \sigma_u^2, \sigma^2_\varepsilon\)</span>。我們可以利用熟悉的極大似然估計法估計這些參數 (Maximum Likelihood, ML)。當且進當嵌套式結構數據是<strong>平衡數據 (balanced)</strong>時 (即，每層中的個體數量相同)，這三個參數的 <span class="math inline">\(\text{MLE}\)</span> 分別是:</p>
<p><span class="math display" id="eq:hier02-2">\[
\begin{aligned}
\hat\mu &amp; = \bar{Y} \\
\hat\sigma_\varepsilon^2 &amp; = \text{Mean square error, MSE} \\ 
\hat\sigma_u^2 &amp; = \frac{\text{Model Sum of Squares, MSS}}{Jn} - \frac{\hat\sigma^2_\varepsilon}{n}
\end{aligned}
\tag{59.2}
\]</span></p>
<p>只要模型指定正確無誤，前兩個極大似然估計是他們各自的無偏估計。但第三個，也就是層內方差的估計量確實際上是低估了的 (downward biased)。這裏常用的另一種對層內方差參數的估計法被叫做<strong>矩估計量 (moment estimator, or ANOVA estimator)</strong>:</p>
<p><span class="math display">\[
\begin{aligned}
\widetilde{\sigma}_u^2 &amp; = \frac{\text{MSS}}{(J-1)n}- \frac{\hat\sigma_\varepsilon^2}{n} \\ 
                       &amp; = \frac{\text{MSS} - \text{MSE}(J-1)}{(J-1)n} \\
                       &amp; = \frac{\text{MMS}(J-1) - \text{MSE}(J-1)}{(J-1)n} \\
                       &amp; = \frac{\text{MMS} - \text{MSE}}{n}
\end{aligned}
\]</span></p>
<p>對於平衡數據 (balanced data)，這個矩估計量又被叫做<strong>限制性極大似然 (Restricted Maximum Likelihood, REML)</strong>。限制性極大似然法，是一個真極大似然過程 (genuine maximum likelihood procedure)，但是它每次進行估計的時候，會先“去除掉”固定效應部分，所以每次用於估計參數的數據其實是對數據的線性轉換後 <span class="math inline">\(Y_{ij} - \mu = u_j + \varepsilon_{ij}\)</span>，它使用的數據是這個等式右半部分的轉換後數據。在 REML 過程中，先估計層內方差 <span class="math inline">\(\sigma_u^2\)</span> 再對固定效應部分的總體均值估計，所以是個兩步走的過程。另外除了這裏討論的 ML, REML這兩種對層內方差進行參數估計的方法之外，在計量經濟學 (econometrics) 中常用的是 (本課不深入探討) <strong>廣義最小二乘法 (Generalized Least Squares, GLS)</strong>。GLS 使用的是一種加權的最小二乘法 (OLS)，該加權法根據層與隨機誤差的方差成分 (variance components) 不同而給不同的層以不同的截距權重。當數據本身是平衡數據時，GLS給出的估計結果等同於 REML法。當數據不是平衡數據的時候，ML/REML 其實背後使用的原理也是 GLS。</p>
</div>
<div id="如何在-r-中進行隨機截距模型的擬合" class="section level2">
<h2><span class="header-section-number">59.3</span> 如何在 R 中進行隨機截距模型的擬合</h2>
<p>在 R 或 STATA 中擬合隨機截距模型，需要數據爲“長 (long)” 數據，下面的代碼可以在 R 裏面把 “寬 (wide)” 的數據調整成爲 <strong>長</strong> 數據:</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb765-1" title="1">pefr &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pefr.dta&quot;</span>)</a>
<a class="sourceLine" id="cb765-2" title="2"><span class="co"># the data are in wide format</span></a>
<a class="sourceLine" id="cb765-3" title="3"><span class="kw">head</span>(pefr)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##      id   wp1   wp2   wm1   wm2
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1   494   490   512   525
## 2     2   395   397   430   415
## 3     3   516   512   520   508
## 4     4   434   401   428   444
## 5     5   476   470   500   500
## 6     6   557   611   600   625</code></pre>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb767-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb767-2" title="2">pefr_long &lt;-<span class="st"> </span>pefr <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb767-7" title="7">pefr_long</a></code></pre></div>
<pre><code>## # A tibble: 34 x 4
##       id occasion    wm    wp
##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1 1          512   494
##  2     1 2          525   490
##  3     2 1          430   395
##  4     2 2          415   397
##  5     3 1          520   516
##  6     3 2          508   512
##  7     4 1          428   434
##  8     4 2          444   401
##  9     5 1          500   476
## 10     5 2          500   470
## # ... with 24 more rows</code></pre>
<p>在 R 裏面，有兩個包 (<code>lme4::lmer</code> 或 <code>nlme::lme</code>) 的各自兩種代碼以供選用:</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb769-1" title="1">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> pefr_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb769-2" title="2"><span class="kw">summary</span>(M0)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: pefr_long 
##         AIC       BIC     logLik
##   366.75843 371.24795 -180.37921
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   110.39701 19.910835
## 
## Fixed effects: wm ~ 1 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 453.91176 26.992068 17 16.816487       0
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.444435579 -0.335076940  0.037044891  0.350983659  2.377059741 
## 
## Number of Observations: 34
## Number of Groups: 17</code></pre>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb771-1" title="1">M1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(wm <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data =</span> pefr_long, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb771-2" title="2"><span class="kw">summary</span>(M1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: wm ~ (1 | id)
##    Data: pefr_long
## 
## REML criterion at convergence: 360.8
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -2.444436 -0.335077  0.037045  0.350984  2.377060 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 12187.51 110.397 
##  Residual               396.44  19.911 
## Number of obs: 34, groups:  id, 17
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  453.912     26.992  16.000  16.817 1.36e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>不知道爲什麼在 R 裏有這兩種完全不同的方式來擬合混合效應模型。還好他們的結果基本完全一致。在這個極爲簡單的例子裏，我們可以利用模型擬合的結果中 <code>Random effects</code> 的部分來計算<strong>層內相關系數 (intra-class correlation)</strong>:</p>
<p><span class="math display">\[
\hat\lambda = \frac{\hat\sigma_u^2}{(\hat\sigma_u^2 + \hat\sigma_\varepsilon^2)} = \frac{110.40^2}{110.40^2 + 19.91^2} = 0.97
\]</span></p>
<p>這是對 Mini Wright meter 測量方法可靠性的一個評價指標。其中 <span class="math inline">\(\sigma_u^2\)</span> 是患者最大呼吸速率 (PEFR) 測量值的方差，<span class="math inline">\(\sigma_\varepsilon^2\)</span> 是測量的隨機誤差，所以這裏的測量方法的可靠度是 97%，是可信度十分高的測量準確度。</p>
</div>
<div id="隨機截距模型中的統計推斷" class="section level2">
<h2><span class="header-section-number">59.4</span> 隨機截距模型中的統計推斷</h2>
<div id="fixed-inference" class="section level3">
<h3><span class="header-section-number">59.4.1</span> 固定效應部分的推斷</h3>
<p>當數據是平衡數據時，固定效應的 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是總體的均值 (overall mean)。它的估計標準誤是:</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu) = \sqrt{\frac{n\hat\sigma_u^2 + \hat\sigma_\varepsilon^2}{Jn}}
\]</span></p>
<p>記得線性回歸中(固定效應模型中)，<span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 也還是總體的均值 (overall mean)。它的估計標準誤卻是:</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu^F) = \sqrt{\frac{\hat\sigma_\varepsilon^2}{Jn}}
\]</span></p>
<p>所以，僅有固定效應模型時的總體均值的標準誤總是要比混合效應模型下估計的總體均值標準誤要小</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu^F) &lt; \hat{\text{SE}}(\hat\mu)
\]</span></p>
<p>如果數據不是平衡數據，那麼隨機截距模型中 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是每層均值的加權均值 (a weighted mean of the cluster specific means):</p>
<p><span class="math display">\[
\begin{aligned}
\hat\mu &amp; = \frac{\sum_jw_j\bar{Y}_{\cdot j}}{\sum_j w_j} \\
\text{Where } w_j &amp; = \frac{1}{\sigma_u^2 + \sigma_\varepsilon^2/n_j}
\end{aligned}
\]</span></p>
<p>從加權的方式來看，如果樣本量少的層級數據本身的誤差方差 <span class="math inline">\(\sigma_\varepsilon^2\)</span> 也較小，那麼層樣本量較小的層也會和層樣本量較大的層獲得相似的均值權重。</p>
<p>零假設是 <span class="math inline">\(\mu = 0\)</span> 的檢驗，就計算 <span class="math inline">\(z\)</span> 檢驗統計量就可以 (或者 <span class="math inline">\(z^2\)</span> 的 Wald 檢驗):</p>
<p><span class="math display">\[
z = \frac{\hat\mu}{\hat{\text{SE}}(\hat\mu)}
\]</span>
總體均值的 95% 信賴區間的計算式就是:</p>
<p><span class="math display">\[
\hat\mu \pm z_{0.975}\hat{\text{SE}}(\hat\mu)
\]</span></p>
</div>
<div id="隨機效應部分的推斷" class="section level3">
<h3><span class="header-section-number">59.4.2</span> 隨機效應部分的推斷</h3>
<p>總體均值的假設檢驗搞定了之後，我們肯定還想對隨機截距模型擬合的隨機效應方差作出是否有意義的假設檢驗。也就是我們希望能檢驗零假設 <span class="math inline">\(\sigma_u^2 = 0\)</span>，和替代假設 <span class="math inline">\(\sigma_u^2 &gt; 0\)</span>。一般情況下大家肯定會想到對含有隨機效應的模型和只有固定效應的模型使用 LRT (似然比檢驗)，然後把檢驗統計量拿去和自由度爲 1 的卡方分布做比較。但是其實方差本身永遠都是大於等於零的，所以傳統的 LRT 在這個零假設時並不適用。</p>
<p>在零假設條件下 <span class="math inline">\(\sigma_u^2 = 0\)</span>，也就是說層內相關在一半的數據中是正相關，另一半數據中是正好相反的負相關，以此相互抵消，方差爲零。所以其實這裏的 LRT 檢驗統計量應該服從的不是自由度爲 1 的卡方分布那麼簡單，而是一種混合卡方分布 (自由度 1 和 自由度爲 0 的混合卡方分布 <span class="math inline">\(\chi_{0,1}^2\)</span>)。所以應該把模型比較之後計算獲得的 <span class="math inline">\(p\)</span> 值除以2，以獲得準確的對 <span class="math inline">\(\sigma_u^2 = 0\)</span> 檢驗的 <span class="math inline">\(p\)</span> 值。</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb773-1" title="1">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> pefr_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb773-2" title="2">M0_fixed&lt;-<span class="st"> </span><span class="kw">lm</span>(wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb773-3" title="3"><span class="kw">anova</span>(M0, M0_fixed)</a></code></pre></div>
<pre><code>##          Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M0           1  3 366.75843 371.24795 -180.37921                         
## M0_fixed     2  2 411.71916 414.71217 -203.85958 1 vs 2 46.960731  &lt;.0001</code></pre>
<p>回到本例中的混合效應模型和固定效應模型的比較來看，LRT本身的 P 值已經 <span class="math inline">\(&lt;0.0001\)</span>，所以除不除以二對推斷結果都沒有太大影響。也就是本例中的隨即截距模型是比固定效應的簡單線性回歸模型更加適合該數據的模型。</p>
<p>其他注意點:</p>
<ul>
<li>在坑爹的 STATA 裏面混合效應模型居然還會輸出隨機效應方差的 “標準誤”，該數字請你無視之。</li>
<li>當樣本擁有足夠多的樣本量 (其實是第二階層的層數)，極大似然法 (ML) 和限制性極大似然法 (REML) 給出的結果會相當接近。</li>
<li>當你比較兩個不是互爲嵌套 (nested) 的模型時，可以使用 AIC/BIC 指標。</li>
</ul>
</div>
</div>
<div id="練習題-8" class="section level2">
<h2><span class="header-section-number">59.5</span> 練習題</h2>
<div id="數據-1" class="section level3">
<h3><span class="header-section-number">59.5.1</span> 數據</h3>
<ol style="list-style-type: decimal">
<li>GHQ 數據 <br> 該數據包含 12 名學生前後兩次回答 General Health Questionnaire (GHQ) 問卷獲得的數據。該問卷用於測量學生的心理壓力，其變量名和含義如下：</li>
</ol>
<pre><code>id        Student identifier
GHQ1      General Health Questionnaire score- 1st occasion
GHQ2      General Health Questionnaire score- 2nd occasion</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Siblings 數據 <br> 該數據是來自一項對 3978 名媽媽關於她們 8604 名孩子的出生體重及健康狀況的問卷調查。該數據的變量名和含義如下：</li>
</ol>
<pre><code>momid     Mother identifier
idx       Baby identifier
mage      Maternal age (years)
meduc     Maternal education
gestat    gestational age (weeks)
birwt     Birth weight (g)
smoke     Maternal smoking (0 = no, 1 = yes)
male      Baby boy (0 = no, 1 = yes)
year      Year of birth
married   Maternal marital status (0 = no, 1 = yes)
hsgrad    Maternal high school education (0 = no, 1 = yes)
black     Maternal race (1 = black, 0 = other)</code></pre>
</div>
<div id="讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分" class="section level3">
<h3><span class="header-section-number">59.5.2</span> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</h3>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb777-1" title="1">ghq &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/ghq.dta&quot;</span>)</a>
<a class="sourceLine" id="cb777-2" title="2">ghq</a></code></pre></div>
<pre><code>## # A tibble: 12 x 3
##       id  GHQ1  GHQ2
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1    12    12
##  2     2     8     7
##  3     3    22    24
##  4     4    10    14
##  5     5    10     8
##  6     6     6     4
##  7     7     8     5
##  8     8     4     6
##  9     9    14    14
## 10    10     6     5
## 11    11     2     5
## 12    12    22    16</code></pre>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb779-1" title="1">ghq &lt;-<span class="st"> </span>ghq <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb779-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean =</span> (GHQ1 <span class="op">+</span><span class="st"> </span>GHQ2)<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb779-3" title="3"></a>
<a class="sourceLine" id="cb779-4" title="4"><span class="co"># each student has 2 observations (i.e. n_j = n = 2)</span></a>
<a class="sourceLine" id="cb779-5" title="5"><span class="co"># and therefore the data are balanced.</span></a>
<a class="sourceLine" id="cb779-6" title="6"><span class="co"># the overall mean is 10.167 and its SD is 6.073</span></a>
<a class="sourceLine" id="cb779-7" title="7"><span class="kw">with</span>(ghq, <span class="kw">summ</span>(mean, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   10.167 8.25    6.073  3.5    23</code></pre>
</div>
<div id="把數據從寬-wide-改變成長-long-的形式" class="section level3">
<h3><span class="header-section-number">59.5.3</span> 把數據從寬 (wide) 改變成長 (long) 的形式</h3>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb781-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb781-2" title="2">ghq_long &lt;-<span class="st"> </span>ghq <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id, <span class="op">-</span>mean) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">3</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb781-7" title="7">ghq_long</a></code></pre></div>
<pre><code>## # A tibble: 24 x 4
##       id  mean occasion   GHQ
##    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;
##  1     1  12   1           12
##  2     1  12   2           12
##  3     2   7.5 1            8
##  4     2   7.5 2            7
##  5     3  23   1           22
##  6     3  23   2           24
##  7     4  12   1           10
##  8     4  12   2           14
##  9     5   9   1           10
## 10     5   9   2            8
## # ... with 14 more rows</code></pre>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb783-1" title="1"><span class="co"># after reshaping there are 24 records. the summary statistics are</span></a>
<a class="sourceLine" id="cb783-2" title="2"><span class="co"># overall mean sd and min max</span></a>
<a class="sourceLine" id="cb783-3" title="3"><span class="kw">with</span>(ghq_long, <span class="kw">summ</span>(GHQ, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  24   10.167 8       6.098  2      24</code></pre>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb785-1" title="1"><span class="co"># between groups mean sd and min</span></a>
<a class="sourceLine" id="cb785-2" title="2"><span class="kw">summ</span>(ghq_long[<span class="op">!</span><span class="kw">duplicated</span>(ghq_long<span class="op">$</span>id), ]<span class="op">$</span>mean, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   10.167 8.25    6.073  3.5    23</code></pre>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb787-1" title="1"><span class="co"># within groups mean sd and min (came from the difference between</span></a>
<a class="sourceLine" id="cb787-2" title="2"><span class="co"># the overall mean and the within difference) observations for</span></a>
<a class="sourceLine" id="cb787-3" title="3"><span class="co"># each group = 2</span></a>
<a class="sourceLine" id="cb787-4" title="4">ghq_long &lt;-<span class="st"> </span>ghq_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb787-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif_GHQ =</span> <span class="kw">mean</span>(GHQ) <span class="op">-</span><span class="st"> </span>(GHQ <span class="op">-</span><span class="st"> </span>mean))</a>
<a class="sourceLine" id="cb787-6" title="6"><span class="kw">with</span>(ghq_long, <span class="kw">summ</span>(dif_GHQ, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  24   10.167 10.167  1.383  7.167  13.167</code></pre>
<p>GHQ 的分佈並不左右對稱。</p>
<div class="figure" style="text-align: center"><span id="fig:histGHQ"></span>
<img src="bookdown_files/figure-html/histGHQ-1.png" alt="Histogram of GHQ by occasion" width="80%" />
<p class="caption">
圖 59.1: Histogram of GHQ by occasion
</p>
</div>
</div>
<div id="對數據按照-id-分層進行-anova" class="section level3">
<h3><span class="header-section-number">59.5.4</span> 對數據按照 <code>id</code> 分層進行 ANOVA</h3>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb789-1" title="1"><span class="kw">with</span>(ghq_long, <span class="kw">anova</span>(<span class="kw">lm</span>(GHQ<span class="op">~</span><span class="kw">factor</span>(id))))</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: GHQ
##            Df  Sum Sq Mean Sq F value     Pr(&gt;F)    
## factor(id) 11 811.333 73.7576 20.1157 4.7782e-06 ***
## Residuals  12  44.000  3.6667                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb791-1" title="1"><span class="co">#library(lme4)</span></a>
<a class="sourceLine" id="cb791-2" title="2">( fit &lt;-<span class="st"> </span><span class="kw">lmer</span>(GHQ <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data=</span>ghq_long) )</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerModLmerTest&#39;]
## Formula: GHQ ~ (1 | id)
##    Data: ghq_long
## REML criterion at convergence: 131.3492
## Random effects:
##  Groups   Name        Std.Dev.
##  id       (Intercept) 5.9199  
##  Residual             1.9149  
## Number of obs: 24, groups:  id, 12
## Fixed Effects:
## (Intercept)  
##      10.167</code></pre>
<p><span class="math inline">\(\sigma_u, \sigma_e\)</span> 的估計值分別是 5.92 (between)， 1.91 (within)。可以計算層間相關係數 (intra-class correlation) <span class="math inline">\(\hat\lambda = \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_e} = 0.905\)</span>。且 <span class="math inline">\(\hat\sigma_u = \sqrt{\frac{73.8 - 3.7}{2}} = 5.92\)</span>，和前一次練習一樣地，這個隨機效應的方差，可以通過方差分析表格來直接手動計算 (當且僅當分層數據是<strong>平衡狀態</strong>的)。和前面計算的樣本數據比較，樣本層間標準差是高估了的 (sample between variance = 6.073 &gt; 5.92)，相反樣本層內標準差 (within sd) 則是低估了的 (sample within sd = 1.383 &lt; 1.91)。兩個層內標準差的關係是：</p>
<p><span class="math display">\[
\sqrt{1.383^2\times\frac{23}{12}} = 1.91
\]</span></p>
</div>
<div id="用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果" class="section level3">
<h3><span class="header-section-number">59.5.5</span> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</h3>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb793-1" title="1"><span class="kw">summary</span>(nlme<span class="op">::</span><span class="kw">lme</span>(<span class="dt">fixed =</span> GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> ghq_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>))</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: ghq_long 
##         AIC       BIC     logLik
##   137.34924 140.75573 -65.674622
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   5.9199181 1.9148548
## 
## Fixed effects: GHQ ~ 1 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 10.166667 1.7530632 12 5.7993727  0.0001
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -1.337372043 -0.578482697  0.073557531  0.414059981  1.796024881 
## 
## Number of Observations: 24
## Number of Groups: 12</code></pre>
<p>截距混合效應模型的參數估計和隨機效應 ANOVA 的參數估計是一樣的。</p>
</div>
<div id="用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同" class="section level3">
<h3><span class="header-section-number">59.5.6</span> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</h3>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb795-1" title="1"><span class="co">#( fit &lt;- lmer(GHQ ~ (1|id), data=ghq_long, REML = FALSE) ) # same but from `lme4` package</span></a>
<a class="sourceLine" id="cb795-2" title="2"></a>
<a class="sourceLine" id="cb795-3" title="3"><span class="kw">summary</span>(<span class="kw">lme</span>(<span class="dt">fixed =</span> GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> ghq_long, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>))</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: ghq_long 
##         AIC       BIC     logLik
##   140.26571 143.79987 -67.132857
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   5.6543976 1.9148545
## 
## Fixed effects: GHQ ~ 1 
##                 Value Std.Error DF  t-value p-value
## (Intercept) 10.166667 1.7145299 12 5.929711  0.0001
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.31652454 -0.58359637  0.08024454  0.40422622  1.81687284 
## 
## Number of Observations: 24
## Number of Groups: 12</code></pre>
<p>用極大似然法估計的隨機殘差標準差 <span class="math inline">\(\sigma_e\)</span> 和 REML/ANOVA 法估計的相同，但是隨機效應標準差 <span class="math inline">\(\sigma_u\)</span> 略小 5.65 &lt; 5.92。</p>
</div>
<div id="用簡單線性迴歸擬合一個固定效應模型" class="section level3">
<h3><span class="header-section-number">59.5.7</span> 用簡單線性迴歸擬合一個固定效應模型</h3>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb797-1" title="1">Fixed_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(GHQ<span class="op">-</span><span class="kw">mean</span>(GHQ) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> ghq_long)</a>
<a class="sourceLine" id="cb797-2" title="2"><span class="kw">summary</span>(Fixed_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = GHQ - mean(GHQ) ~ 0 + factor(id), data = ghq_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -3     -1      0      1      3 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## factor(id)1    1.8333     1.3540  1.3540 0.2006847    
## factor(id)2   -2.6667     1.3540 -1.9695 0.0724256 .  
## factor(id)3   12.8333     1.3540  9.4780 6.371e-07 ***
## factor(id)4    1.8333     1.3540  1.3540 0.2006847    
## factor(id)5   -1.1667     1.3540 -0.8616 0.4057744    
## factor(id)6   -5.1667     1.3540 -3.8158 0.0024580 ** 
## factor(id)7   -3.6667     1.3540 -2.7080 0.0190252 *  
## factor(id)8   -5.1667     1.3540 -3.8158 0.0024580 ** 
## factor(id)9    3.8333     1.3540  2.8311 0.0151447 *  
## factor(id)10  -4.6667     1.3540 -3.4466 0.0048356 ** 
## factor(id)11  -6.6667     1.3540 -4.9237 0.0003516 ***
## factor(id)12   8.8333     1.3540  6.5238 2.836e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.9149 on 12 degrees of freedom
## Multiple R-squared:  0.94856,    Adjusted R-squared:  0.89712 
## F-statistic: 18.439 on 12 and 12 DF,  p-value: 6.8362e-06</code></pre>
<p>可以看到輸出報告最底段部分 <code>Residual standard error: 1.91 on 12 degrees of freedom</code> 就是前文三種不同模型擬合的隨機殘差效應的標準差。在 STATA 裏被叫做 <code>Root MSE</code>。</p>
</div>
<div id="計算這些隨機截距的均值和標準差" class="section level3">
<h3><span class="header-section-number">59.5.8</span> 計算這些隨機截距的均值和標準差</h3>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb799-1" title="1"><span class="kw">summ</span>(Fixed_reg<span class="op">$</span>coefficients, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   0      -1.917  6.073  -6.667 12.833</code></pre>
<p>這裏僅僅用固定效應模型時，不同羣截距的均值雖然和用混合效應模型估計的一樣爲零，但是其估計的標準差要大於無論是 REML (5.92) 或者是 ML (5.65) 估計值的大小，其實這裏簡單線性迴歸給出的截距均值，就是本練習一開始讓你計算的樣本均值的標準差 (between group sd)。這是因爲<strong>簡單線性迴歸 (固定效應模型) 忽視了這些不同組的均值的不確定性</strong>。</p>
</div>
<div id="忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸" class="section level3">
<h3><span class="header-section-number">59.5.9</span> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</h3>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb801-1" title="1">Fixed_simple &lt;-<span class="st"> </span><span class="kw">lm</span>(GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> ghq_long)</a>
<a class="sourceLine" id="cb801-2" title="2"><span class="kw">summary</span>(Fixed_simple)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = GHQ ~ 1, data = ghq_long)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.1667 -4.4167 -2.1667  3.8333 13.8333 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  10.1667     1.2448  8.1673 3.001e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.0982 on 23 degrees of freedom</code></pre>
<p>此時的模型估計的 <code>Residual standard error: 6.09 on 23 degrees of freedom</code> 其實就是一開始讓你計算的樣本整體的標準差 (overall sd)</p>
</div>
<div id="用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較" class="section level3">
<h3><span class="header-section-number">59.5.10</span> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</h3>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb803-1" title="1"><span class="co"># sandwich robust method with cluster id</span></a>
<a class="sourceLine" id="cb803-2" title="2"></a>
<a class="sourceLine" id="cb803-3" title="3">robustReg &lt;-<span class="st"> </span>clubSandwich<span class="op">::</span><span class="kw">coef_test</span>(Fixed_simple, <span class="dt">vcov =</span> <span class="st">&quot;CR1&quot;</span>, <span class="dt">cluster =</span> ghq_long<span class="op">$</span>id)</a>
<a class="sourceLine" id="cb803-4" title="4"></a>
<a class="sourceLine" id="cb803-5" title="5">rob.std.err &lt;-<span class="st"> </span>robustReg<span class="op">$</span>SE</a>
<a class="sourceLine" id="cb803-6" title="6">naive.std.err&lt;-<span class="kw">summary</span>(Fixed_simple)<span class="op">$</span>coefficients[,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb803-7" title="7">better.table &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;Estimate&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple),</a>
<a class="sourceLine" id="cb803-8" title="8">                      <span class="st">&quot;Naive SE&quot;</span> =<span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-9" title="9">                      <span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(Fixed_simple)<span class="op">/</span>naive.std.err), <span class="dt">df=</span><span class="kw">nrow</span>(ghq_long)<span class="op">-</span><span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb803-10" title="10">                      <span class="st">&quot;LL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-11" title="11">                      <span class="st">&quot;UL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-12" title="12">                      <span class="st">&quot;Robust SE&quot;</span> =<span class="st"> </span>rob.std.err,</a>
<a class="sourceLine" id="cb803-13" title="13">                      <span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(Fixed_simple)<span class="op">/</span>rob.std.err), <span class="dt">df=</span><span class="kw">nrow</span>(ghq_long)<span class="op">-</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb803-14" title="14"><span class="dt">lower.tail =</span> <span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb803-15" title="15">                      <span class="st">&quot;LL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="dt">df=</span>robustReg<span class="op">$</span>df, <span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob.std.err,</a>
<a class="sourceLine" id="cb803-16" title="16">                      <span class="st">&quot;UL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="dt">df=</span>robustReg<span class="op">$</span>df, <span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob.std.err)</a>
<a class="sourceLine" id="cb803-17" title="17"><span class="kw">rownames</span>(better.table)&lt;-<span class="kw">c</span>(<span class="st">&quot;Constant&quot;</span>)</a>
<a class="sourceLine" id="cb803-18" title="18">better.table</a></code></pre></div>
<pre><code>##           Estimate  Naive SE      Pr(&gt;|z|)        LL        UL Robust SE      Pr(&gt;|z|)        LL
## Constant 10.166667 1.2447959 4.1792464e-08 7.7268666 12.606467 1.7530637 7.7968698e-06 6.3081995
##                 UL
## Constant 14.025134</code></pre>
</div>
<div id="讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量" class="section level3">
<h3><span class="header-section-number">59.5.11</span> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</h3>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb805-1" title="1">siblings &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/siblings.dta&quot;</span>)</a>
<a class="sourceLine" id="cb805-2" title="2">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>)</a>
<a class="sourceLine" id="cb805-3" title="3"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: siblings 
##         AIC       BIC     logLik
##   130956.97 130978.15 -65475.486
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.28656 377.65778
## 
## Fixed effects: birwt ~ 1 
##                Value Std.Error   DF   t-value p-value
## (Intercept) 3467.969 7.1380683 4626 485.84138       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2745852602 -0.4860398560  0.0036050084  0.5054348663  4.0506129253 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb807-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb807-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: siblings 
##        AIC       BIC     logLik
##   130951.2 130972.38 -65472.601
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.35596 377.65768
## 
## Fixed effects: birwt ~ 1 
##                 Value Std.Error   DF   t-value p-value
## (Intercept) 3467.9688 7.1385551 4626 485.80822       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2743063820 -0.4860194138  0.0035299824  0.5053550416  4.0503923643 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<p>由於該數據樣本量足夠大 (混合效應模型中等同於說數據的層數足夠多)，你可以看到其實 ML 法和 REML 法估計的參數結果十分地接近。</p>
</div>
</div>
</div>
<div id="隨機截距模型中加入共變量-random-intercept-model-with-covariates" class="section level1">
<h1><span class="header-section-number">第 60 章</span> 隨機截距模型中加入共變量 random intercept model with covariates</h1>
<p>這一章我們來把隨機截距模型加以擴展，在固定效應部分增加想要調整的共變量。</p>
<div id="多元線性回歸模型的延伸" class="section level2">
<h2><span class="header-section-number">60.1</span> 多元線性回歸模型的延伸</h2>
<p>如果有一個含有兩個預測變量的多元線性回歸模型:</p>
<p><span class="math display" id="eq:hier03-1">\[
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 X_{1ij} + \beta_2 X_{2ij} + \epsilon_{ij}
\end{equation}
\tag{60.1}
\]</span></p>
<p>如果觀測數據內部具有嵌套式結構，也就是有些對象之間有相關性，有些對象之間沒有，那麼上面這個多元線性回歸模型的誤差項 <span class="math inline">\(\epsilon_{ij}\)</span> 其實是不能被認爲相互獨立的，因爲數據中處以同一層的個體之間互相有關聯性 (屬於同一所學校的學生之間，同一所醫院的病人之間)。但是於此同時，我們不妨把最後的誤差項分成兩個部分</p>
<p><span class="math display">\[
\epsilon_{ij} = u_j + e_{ij}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(u_j\)</span>，是在隨機截距模型中用到的隨機截距部分，<span class="math inline">\(u_j \sim N(0, \sigma_u^2)\)</span>，它允許不同層的數據有自己的截距;</li>
<li><span class="math inline">\(e_{ij}\)</span>，是剝離掉層內相關 (等同於層間相異，intra-class correlation = between-class heterogeneity) 之後，剩餘的隨機殘差;</li>
</ul>
<p>之後把式子 <a href="10-Hierarchical-models.html#eq:hier03-1">(60.1)</a> 重新整理，就遇到了我們似曾相識的隨機截距模型:</p>
<p><span class="math display" id="eq:Hier03-01">\[
\begin{equation}
Y_{ij} = (\beta_0 + u_j) + \beta_1 X_{1ij} + \beta_2 X_{2ij} + e_{ij}
\end{equation}
\tag{60.2}
\]</span></p>
<p>這就是一個混合效應線性回歸模型 (linear mixed model)。其中，</p>
<ul>
<li>固定效應部分的參數有 fixed effect parameters: <span class="math inline">\(\beta_0, \beta_1, \beta_2\)</span>;</li>
<li>隨機效應部分的參數有 random effect parameters: <span class="math inline">\(u_j, e_{ij}\)</span>。</li>
</ul>
<p>但是和之前的隨機截距模型不同的是，這裏我們在固定效應部分增加了兩個共變量 <span class="math inline">\(X_1, X_2\)</span>，所以從該模型作出的所有統計推斷，都是建立在以這兩個共變量爲條件的基礎之上的 (conditionally on <span class="math inline">\(\mathbf{X} = \{ X_1, X_2\}\)</span>)。所以對於 <span class="math inline">\(u_j, e_{ij}\)</span>，他們的前提條件就變成了:</p>
<ul>
<li><span class="math inline">\(\text{E}(u_j|\mathbf{X} = \{ X_1, X_2\}) = 0\)</span>;</li>
<li><span class="math inline">\(\text{E}(e_{ij}|\mathbf{X} = \{ X_1, X_2, u_j\}) = 0\)</span>。</li>
</ul>
<p>根據這兩個條件，我們可以繼續得到:</p>
<ul>
<li><span class="math inline">\(\text{E}(e_{ij} | \mathbf{X} = \{ X_1, X_2\}) = 0\)</span>;</li>
<li><span class="math inline">\(\text{E}(Y_{ij} | \mathbf{X} = \{ X_1, X_2\}) = \beta_0 + \beta_1X_{1ij} + \beta_2X_{2ij}\)</span></li>
</ul>
<p>也就是說，這個包含了 <span class="math inline">\(u_j, e_{ij}\)</span> 的多元線性回歸模型，其邊際模型 (marginal regression over <span class="math inline">\(u_j, e_{ij}\)</span>) 還是一個線性回歸。</p>
<p><strong>注意</strong></p>
<ul>
<li>模型的固定效應部分加入了多個共變量 <span class="math inline">\(\mathbf{X} = \{ X_1, X_2\}\)</span> 之後，模型所估計的層內相關系數 (intra-class correlation, <span class="math inline">\(\lambda\)</span>) 也成了以這些共變量爲條件的層內相關系數。</li>
<li><span class="math inline">\(u_j\)</span> 這個層別隨機截距 (cluster-specific random intercept) 此時會囊括已知/未知的層水平的特徵 (class-level characteristics, i.e. unmeasured heterogeneity between clusters)。它會隨着你在模型中加入層水平的解釋變量而逐漸變小 (Its size will decrease as more explanatory variables for the <strong>cluster difference</strong> are included in the model)。</li>
</ul>
</div>
<div id="siblings-數據中新生兒體重的實例" class="section level2">
<h2><span class="header-section-number">60.2</span> <code>siblings</code> 數據中新生兒體重的實例</h2>
<p>在數據 <code>silblings</code> 中，研究者收集了來自 3978 名母親，8604 名新生兒出生體重 (g) 的數據。此外，該數據中還收集了這些新生兒的胎齡 (week)，新生兒的性別，母親孕期的吸煙狀況，以及懷孕時母親的年齡。在這個數據裏，每個母親是該數據的第二階層 (level 2)，每個母親的相關信息，就是屬於第二階層的層水平數據。每個新生兒的體重和相關數據，就是第一階層 (level 1) 數據，一個母親可能生 1-3 個嬰兒，這些來自同一個母親的新生兒之間很顯然不能視之爲相互獨立。研究者關心一個固定效應部分不包含其他共變量的隨機截距模型 (the Null Model)，和固定效應部分增加了其他共變量的隨機截距模型 (the Full Model) 哪個更能解釋這個數據或者更好的擬合這個數據 (better fitting the data)。</p>
<p>下面就先把數據讀入 R，然後建立一個零模型 (the Null Model):</p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb809-1" title="1">siblings &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/siblings.dta&quot;</span>)</a>
<a class="sourceLine" id="cb809-2" title="2">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb809-3" title="3"><span class="kw">summary</span>(M0)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: siblings 
##        AIC       BIC     logLik
##   130951.2 130972.38 -65472.601
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.35596 377.65768
## 
## Fixed effects: birwt ~ 1 
##                 Value Std.Error   DF   t-value p-value
## (Intercept) 3467.9688 7.1385551 4626 485.80822       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2743063820 -0.4860194138  0.0035299824  0.5053550416  4.0503923643 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb811-1" title="1">M0_fixed &lt;-<span class="st"> </span><span class="kw">lm</span>(birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> siblings)</a>
<a class="sourceLine" id="cb811-2" title="2"><span class="kw">anova</span>(M0, M0_fixed)</a></code></pre></div>
<pre><code>##          Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M0           1  3 130951.20 130972.38 -65472.601                         
## M0_fixed     2  2 132265.32 132279.44 -66130.660 1 vs 2 1316.1174  &lt;.0001</code></pre>
<p>下一步，我們來對該數據擬合一個全模型 (the Full Model)，我們可以先對兩個連續型變量 (胎齡，gestational age 和母親懷孕時年齡，maternal age) 進行適當的轉換，比方說把胎齡標準化成 38 周，懷孕時年齡標準化成 30 歲:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb813-1" title="1">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb813-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_gestat =</span> gestat <span class="op">-</span><span class="st"> </span><span class="dv">38</span>, <span class="co"># centering gestational age to 38 weeks</span></a>
<a class="sourceLine" id="cb813-3" title="3">         <span class="dt">c_mage =</span> mage <span class="op">-</span><span class="st"> </span><span class="dv">30</span>,  <span class="co"># centering maternal age to 30 years old</span></a>
<a class="sourceLine" id="cb813-4" title="4">         <span class="dt">male =</span> <span class="kw">factor</span>(male, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)), </a>
<a class="sourceLine" id="cb813-5" title="5">         <span class="dt">smoke =</span> <span class="kw">factor</span>(smoke, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Nonsmoker&quot;</span>, <span class="st">&quot;Smoker&quot;</span>)))</a>
<a class="sourceLine" id="cb813-6" title="6"><span class="co">#M_full &lt;- lme(fixed = birwt ~ c_gestat + male + smoke + c_mage, random  = ~ 1 | momid, data = siblings, method = &quot;REML&quot;)</span></a>
<a class="sourceLine" id="cb813-7" title="7">M_full &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb813-8" title="8"><span class="kw">library</span>(lmerTest)</a>
<a class="sourceLine" id="cb813-9" title="9"><span class="kw">summary</span>(M_full)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + male + smoke + c_mage + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 128984.9
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.14590 -0.52884 -0.00868  0.53594  3.63288 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept)  99784   315.89  
##  Residual             118012   343.53  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3341.0957     8.6642 7084.5208 385.620 &lt; 2.2e-16 ***
## c_gestat      85.4241     2.1607 7868.3663  39.535 &lt; 2.2e-16 ***
## malemale     133.9476     8.8694 7121.4202  15.102 &lt; 2.2e-16 ***
## smokeSmoker -239.9993    15.9794 7543.5486 -15.019 &lt; 2.2e-16 ***
## c_mage        13.1579     1.0903 5400.3042  12.068 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) c_gstt maleml smkSmk
## c_gestat    -0.347                     
## malemale    -0.535  0.038              
## smokeSmoker -0.244  0.017  0.006       
## c_mage       0.137  0.020 -0.001  0.145</code></pre>
<p>從全模型的結果報告中可以看出，固定效應部分加入的所有解釋變量都是有意義的。他們的含義如下:</p>
<ul>
<li><code>c_gestat 85.42</code>: 當模型中的其他變量保持不變時 (當模型中其他的變量被調整時)，胎齡每增加一周，<strong>無論是同一個媽媽還是不同媽媽 (either from the same or another mother, i.e. in any cluster)</strong> 生下的新生兒的出生體重增加的期待值是 85.42 g。</li>
<li><code>male 133.95</code>: 新生兒的性別如果是男孩，<strong>無論是同一個媽媽還是不同媽媽</strong>生下的新生兒，他的出生體重會比女孩增加 133.95 g。</li>
</ul>
<p>再看這兩個模型的隨機效應部分，無論是第二層級水平的層標準差 (cluster-level) 還是第一層級 (elementary-level) 的標準差都隨着固定效應部分加入新的解釋變量而變小。我們同樣可以用極大似然法 (ML) 擬合這兩個模型，其方差大小總結成下面的表格:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 60.1: Summary of estimates of the variation of the random effects of the null and full model using REML or ML
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
REML
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
ML
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Random Effect
</th>
<th style="text-align:center;">
Null Model
</th>
<th style="text-align:center;">
Full Model
</th>
<th style="text-align:center;">
Null Model
</th>
<th style="text-align:center;">
Full Model
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\hat\sigma_u\)</span>
</td>
<td style="text-align:center;">
368.3558
</td>
<td style="text-align:center;">
315.8853
</td>
<td style="text-align:center;">
368.2864
</td>
<td style="text-align:center;">
315.7320
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\hat\sigma_e\)</span>
</td>
<td style="text-align:center;">
377.6577
</td>
<td style="text-align:center;">
343.5296
</td>
<td style="text-align:center;">
377.6579
</td>
<td style="text-align:center;">
343.4581
</td>
</tr>
</tbody>
</table>
<p>表格的右半部分總結的是使用極大似然法 (會偏小估計隨機效應方差)，其實它們和 REML 法估計的結果相差不大。<strong>值得強調的是，由於 REML 法每次估計的數據是去除掉固定效應部分以後的隨機誤差部分的數據，所以當兩個用 REML 法估計的混合效應模型其固定效應部分不一致的時候，這兩個模型實際擬合了不同的數據，是不能使用 LRT 來比較兩個模型哪個更好的。</strong></p>
</div>
<div id="賦值予隨機效應成分" class="section level2">
<h2><span class="header-section-number">60.3</span> 賦值予隨機效應成分</h2>
<p>值得建議地，擬合了任何一個混合效應模型以後，需要盡量避免直接跳入結論陳述階段，而應當先對模型是否符合其假定的前提條件進行模型診斷。而且，對模型的擬合後截距及其層級隨機效應 (cluster random effect) 進行視覺化展現變得十分有用。</p>
<p>總體來說，有兩種方法可以用於估計並提取這些擬合值 – ML 和 Empirical Bayes (EB)。</p>
<div id="簡單預測-simple-prediction" class="section level3">
<h3><span class="header-section-number">60.3.1</span> 簡單預測 simple prediction</h3>
<p>和簡單線性回歸模型一樣，我們可以計_算模型的預測值和觀測值之間的差，獲得一個包含了兩個隨機效應成分的量:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = \beta_0 + \beta_1X_{1ij} + u_j + e_{ij} \\
\Rightarrow Y_{ij} &amp; =  \beta_0 + \beta_1X_{1ij} + \epsilon_{ij} \\
\Rightarrow \hat\epsilon_{ij} &amp; = Y_{ij} - (\hat\beta_0 + \beta_1X_{1ij})
\end{aligned}
\]</span></p>
<p>那麼最簡單的方法就是計算了這個隨機效應成分的混合體之後，對其取平均值，作爲 <span class="math inline">\(u_j\)</span> 的簡單估計:</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb815-1" title="1">M_full &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb815-2" title="2"></a>
<a class="sourceLine" id="cb815-3" title="3">siblings<span class="op">$</span>yhat &lt;-<span class="st"> </span>M_full<span class="op">$</span>fitted[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb815-4" title="4">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb815-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">res =</span> birwt<span class="op">-</span><span class="st"> </span>yhat)</a>
<a class="sourceLine" id="cb815-6" title="6">Mean_siblings &lt;-<span class="st"> </span><span class="kw">ddply</span>(siblings, <span class="op">~</span>momid, summarise, <span class="dt">uhat =</span> <span class="kw">mean</span>(res))</a>
<a class="sourceLine" id="cb815-7" title="7">Mean_siblings[Mean_siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,]</a></code></pre></div>
<pre><code>##   momid    uhat
## 1    14 105.124</code></pre>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb817-1" title="1">siblings[siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">15</span>,<span class="dv">16</span>)]</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   momid gestat birwt  yhat   res
##   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    14     24  2790 1961.  829.
## 2    14     42  2693 3512. -819.
## 3    14     39  3600 3295.  305.</code></pre>
<p>找到編號 14 號的母親，她有三個孩子被研究者記錄到，他們中有的孩子使用該模型計算的擬合值 (fitted value = <code>yhat</code>) 並不準確。在調整了胎齡，嬰兒性別，母親的吸煙狀況，和母親懷孕時年齡後，該母親生的孩子，和該隊列的總體平均值 (overall mean) 相比較，其偏差達到了 105.12 g。</p>
<p>我們可以對每個母親的擬合偏差做總結歸納:</p>
<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb819-1" title="1"><span class="kw">summ</span>(Mean_siblings<span class="op">$</span>uhat, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.    min.      max.    
##  3978 -0.512 -10.349 395.068 -1386.937 1772.721</code></pre>
<p>可見這 3978 名母親總體的擬合偏差的均值爲 -0.511，接近零。且它的標準差接近 400。這樣一種直接利用觀測值和擬合值之差做曾內平均的方法被叫做極大似然法 ML，這樣計算獲得的平均偏差被標記爲 <span class="math inline">\(\hat u_j^{\text{ML}}\)</span></p>
</div>
<div id="eb-預測值" class="section level3">
<h3><span class="header-section-number">60.3.2</span> EB 預測值</h3>
<p>EB 法 (經驗貝葉斯法) 也一樣要利用擬合模型後的 <span class="math inline">\(\beta\)</span> 來計算獲得層殘差 (cluster level residuals)。但是用 EB 法時我們還再使用層殘差的一個前提條件: <span class="math inline">\(u_j \sim N(0, \sigma_u^2)\)</span>。在線性隨機截距模型中，EB 法計算的層級殘差和簡單法計算的層殘差之間有如下的簡單轉換關系:</p>
<p><span class="math display">\[
\hat u_j^{\text{EB}} = \hat R_j\hat u_j^{\text{ML}}
\]</span></p>
<p>其中 <span class="math inline">\(\hat R_j\)</span> 被定義爲 ML 法計算層級殘差的可靠性 (reliability of <span class="math inline">\(\hat u_j^{\text{ML}}\)</span>)，它是一個包含了層級方差和個人水平方差的方程:</p>
<p><span class="math display">\[
\hat R_j = \frac{\hat\sigma_u^2}{\hat\sigma_u^2 + \sigma_e^2/n_j} = \hat w_j \hat \sigma_u^2
\]</span></p>
<p>其中 <span class="math inline">\(\hat w_j\)</span> 是之前在章節 <a href="10-Hierarchical-models.html#fixed-inference">59.4.1</a> 定義的權重。這個 <span class="math inline">\(\hat R_j\)</span> 又被叫做是<strong>收縮因子 (shrinkage factor)</strong>，因爲它取值是在 0 到 1 之間，所以它會把 ML 法計算獲得的層級誤差按照收縮銀子比例收縮變小。當 <span class="math inline">\(\sigma_u\)</span> 本身比較小，或者個體的隨機誤差大 <span class="math inline">\(\sigma_e\)</span>，或者層內樣本量小 <span class="math inline">\(n_j\)</span> 時收縮因子的作用更大。</p>
<p>此時，預測誤差 <span class="math inline">\((\hat u_j^{\text{EB}} - u_j)\)</span> 才是我們能夠從觀測數據以及模型中獲得的均值爲零方差又最小的殘差。所以 <span class="math inline">\(\hat u_j^{\text{EB}}\)</span> 又被稱爲 <span class="math inline">\(\text{Best linear unbiased predictors, BLUP}\)</span>。</p>
<p>第二層級殘差的方差是:</p>
<p><span class="math display">\[
R_j\hat \sigma_u^2
\]</span></p>
</div>
</div>
<div id="混合效應模型的診斷" class="section level2">
<h2><span class="header-section-number">60.4</span> 混合效應模型的診斷</h2>
<p>辛苦計算了 BLUP 之後，就可以拿它，和模型的標準化殘差來對模型作出一定的診斷。由於計算獲得的 BLUP 方差不齊，要先對其標準化之後再作正態圖:</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb821-1" title="1"><span class="co"># the standardized </span></a>
<a class="sourceLine" id="cb821-2" title="2"></a>
<a class="sourceLine" id="cb821-3" title="3">n_child &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(momid, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb821-4" title="4">Mean_siblings &lt;-<span class="st"> </span><span class="kw">merge</span>(Mean_siblings, n_child, <span class="dt">by =</span> <span class="st">&quot;momid&quot;</span>)  </a>
<a class="sourceLine" id="cb821-5" title="5"></a>
<a class="sourceLine" id="cb821-6" title="6">Mean_siblings &lt;-<span class="st"> </span>Mean_siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb821-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="co"># extract the random effect (EB) residuals at level 2</span></a>
<a class="sourceLine" id="cb821-8" title="8">         <span class="dt">uhat_eb =</span> <span class="kw">ranef</span>(M_full)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, </a>
<a class="sourceLine" id="cb821-9" title="9">         <span class="co"># shrinkage factor </span></a>
<a class="sourceLine" id="cb821-10" title="10">         <span class="dt">R =</span> <span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="fl">343.4572</span><span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n), </a>
<a class="sourceLine" id="cb821-11" title="11">         <span class="co"># Empirical Bayes prediction of variance of uhat</span></a>
<a class="sourceLine" id="cb821-12" title="12">         <span class="dt">var_eb =</span> R<span class="op">*</span>(<span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span>),</a>
<a class="sourceLine" id="cb821-13" title="13">         <span class="co"># standardize the EB uhat</span></a>
<a class="sourceLine" id="cb821-14" title="14">         <span class="dt">uhat_st =</span> uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb)</a>
<a class="sourceLine" id="cb821-15" title="15">  )</a>
<a class="sourceLine" id="cb821-16" title="16"></a>
<a class="sourceLine" id="cb821-17" title="17"><span class="co"># 計算每個個體的標準化殘差</span></a>
<a class="sourceLine" id="cb821-18" title="18"></a>
<a class="sourceLine" id="cb821-19" title="19">siblings<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(M_full, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals-unst"></span>
<img src="bookdown_files/figure-html/level2-residuals-unst-1.png" alt="Histogram and Q-Q plot of cluster (mother) level unstandardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.1: Histogram and Q-Q plot of cluster (mother) level unstandardized residuals for the intercept
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals-st"></span>
<img src="bookdown_files/figure-html/level2-residuals-st-1.png" alt="Histogram and Q-Q plot of cluster (mother) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.2: Histogram and Q-Q plot of cluster (mother) level standardized residuals for the intercept
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:level1-residuals-baby"></span>
<img src="bookdown_files/figure-html/level1-residuals-baby-1.png" alt="Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.3: Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept
</p>
</div>
<p>這些正態圖，主要用於輔助尋找看哪裏有異常值 (outliers)。</p>
</div>
<div id="第二層級-cluster-levellevel-2-的協方差" class="section level2">
<h2><span class="header-section-number">60.5</span> 第二層級 (cluster level/level 2) 的協方差</h2>
<p>還是這個 <code>siblings</code> 數據中，關於母親的數據在該母親生的孩子中是保持不變的，比如有人種 (<code>black</code>)，母親受教育情況 (<code>hsgrad</code>)，和母親的婚姻狀況 (<code>married</code>)。因爲這些變量屬於解釋第二層級 (level 2) 的變量，加入這些變量在固定效應部分只能解釋層間的方差 (between clusters variance):</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb822-1" title="1">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb822-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">black =</span> <span class="kw">factor</span>(black, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)), </a>
<a class="sourceLine" id="cb822-3" title="3">         <span class="dt">hsgrad =</span> <span class="kw">factor</span>(hsgrad, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)),</a>
<a class="sourceLine" id="cb822-4" title="4">         <span class="dt">married =</span> <span class="kw">factor</span>(married, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;yes&quot;</span>)))</a>
<a class="sourceLine" id="cb822-5" title="5"></a>
<a class="sourceLine" id="cb822-6" title="6">M_full1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage <span class="op">+</span><span class="st"> </span>black <span class="op">+</span><span class="st"> </span>married <span class="op">+</span><span class="st"> </span>hsgrad <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), </a>
<a class="sourceLine" id="cb822-7" title="7">                <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb822-8" title="8"><span class="kw">summary</span>(M_full1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + male + smoke + c_mage + black + married +      hsgrad + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 128884.7
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.19306 -0.53217 -0.01244  0.54116  3.65296 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept)  96846   311.20  
##  Residual             118053   343.59  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df  t value  Pr(&gt;|t|)    
## (Intercept) 3297.4611    23.3036 4601.1760 141.4998 &lt; 2.2e-16 ***
## c_gestat      84.4555     2.1584 7887.4033  39.1281 &lt; 2.2e-16 ***
## malemale     133.7891     8.8514 7160.4073  15.1150 &lt; 2.2e-16 ***
## smokeSmoker -227.9418    16.3323 7674.0013 -13.9565 &lt; 2.2e-16 ***
## c_mage        11.0375     1.1412 5488.4090   9.6716 &lt; 2.2e-16 ***
## blackYes    -177.8954    25.9709 3912.4116  -6.8498 8.554e-12 ***
## marriedyes    61.1716    22.2791 4164.2316   2.7457  0.006064 ** 
## hsgradYes     -4.2118    13.9792 3949.6037  -0.3013  0.763211    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) c_gstt maleml smkSmk c_mage blckYs mrrdys
## c_gestat    -0.111                                          
## malemale    -0.204  0.038                                   
## smokeSmoker -0.287  0.009  0.008                            
## c_mage       0.222  0.034 -0.004  0.071                     
## blackYes    -0.377  0.041  0.007  0.064  0.036              
## marriedyes  -0.914 -0.025  0.007  0.227 -0.230  0.348       
## hsgradYes   -0.165  0.011 -0.012 -0.044  0.172 -0.046  0.016</code></pre>
<p>加入了第二層級協變量之後， <span class="math inline">\(\sigma^2_u = 96845.79\)</span>，相比沒加之前的小了一些 <span class="math inline">\((\sigma^2_{u} = 99784)\)</span>。但是 <span class="math inline">\(\sigma^2_e\)</span> 幾乎保持不變。</p>
</div>
<div id="層內層間效應估計" class="section level2">
<h2><span class="header-section-number">60.6</span> 層內層間效應估計</h2>
<p>如有某個想加入模型的變量是屬於第一層級的，例如 <code>siblings</code> 數據中的胎齡，即使是同一個媽媽生的嬰兒，其出生時的胎齡也是各不相同。但是這樣在模型輸出的報告中，胎齡這一變量的估計量其實是其他變量保持不變時，<strong>每增加一周胎兒對不論是同一個母親還是不同母親生的嬰兒的出生體重的影響</strong>，怎樣才能把同一母親不同胎齡的影響 (within effect) 和不同母親不同胎齡的影響 (between effect) 給區分出來呢？</p>
<p>其實很簡單，我們來把胎齡這個變量做個分解:</p>
<p><span class="math display">\[
Y_{ij} = \beta_0 + \beta_{1B} \bar{X}_{\cdot j} + \beta_{1W} (X_{ij} - \bar{X}_{\cdot j}) + u_j + e_{ij}
\]</span></p>
<p>把胎齡這個變量分解成 <span class="math inline">\(\bar{X}_{\cdot j}\)</span> (每個母親生的嬰兒的平均胎齡)，和 <span class="math inline">\(X_{ij} - \bar{X}_{\cdot j}\)</span> (每個母親內，每個胎兒的胎齡和平均胎齡之差) 兩個部分，就解決了區分層間效應 <span class="math inline">\((\beta_{1B})\)</span> 和層內效應 <span class="math inline">\((\beta_{1W})\)</span>。 的方法。下面的模型在固定效應部分只使用了胎齡一個變量 (爲了這裏輸出報告簡潔明了):</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb824-1" title="1">M_gestat &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb824-2" title="2"><span class="kw">summary</span>(M_gestat)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 129638.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.95662 -0.52950  0.00662  0.52638  3.98718 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept) 113073   336.26  
##  Residual             124282   352.54  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3358.5435     7.1841 4956.3651 467.497 &lt; 2.2e-16 ***
## c_gestat      83.7325     2.2314 7785.2519  37.525 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr)
## c_gestat -0.406</code></pre>
<p>當把胎齡作爲一個變量放進模型的固定效應部分時，不論是不是同一個母親生下的胎兒，只要胎齡每增加一周，出生體重就增加 83.7 g。下一個模型中，我們來把胎齡這個變量分解成層間變量和層內變量:</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb826-1" title="1">Mean_gestat &lt;-<span class="st"> </span><span class="kw">ddply</span>(siblings, <span class="op">~</span><span class="st"> </span>momid, summarise, <span class="dt">mean_gestat =</span> <span class="kw">mean</span>(gestat))</a>
<a class="sourceLine" id="cb826-2" title="2"><span class="co"># 把每個母親的胎兒胎齡均值 (level 2 mean) 賦予原有的數據中</span></a>
<a class="sourceLine" id="cb826-3" title="3">avegest &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb826-4" title="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3978</span>){</a>
<a class="sourceLine" id="cb826-5" title="5">  avegest &lt;-<span class="st"> </span><span class="kw">c</span>(avegest, <span class="kw">rep</span>(Mean_gestat<span class="op">$</span>mean_gestat[i], <span class="kw">with</span>(siblings, <span class="kw">table</span>(momid))[i]))</a>
<a class="sourceLine" id="cb826-6" title="6">}</a>
<a class="sourceLine" id="cb826-7" title="7">siblings<span class="op">$</span>avegest &lt;-<span class="st"> </span>avegest</a>
<a class="sourceLine" id="cb826-8" title="8"><span class="kw">rm</span>(avegest)</a>
<a class="sourceLine" id="cb826-9" title="9"><span class="co"># 計算層內胎兒胎齡與其層均值的差異</span></a>
<a class="sourceLine" id="cb826-10" title="10">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb826-11" title="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_avegest =</span> avegest <span class="op">-</span><span class="st"> </span><span class="dv">38</span>, </a>
<a class="sourceLine" id="cb826-12" title="12">         <span class="dt">difgest =</span> gestat <span class="op">-</span><span class="st"> </span>avegest)</a>
<a class="sourceLine" id="cb826-13" title="13"></a>
<a class="sourceLine" id="cb826-14" title="14">siblings[siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">18</span><span class="op">:</span><span class="dv">20</span>)]</a></code></pre></div>
<pre><code>## # A tibble: 3 x 7
##   momid   idx gestat birwt avegest c_avegest difgest
##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1    14     1     24  2790      35        -3     -11
## 2    14     2     42  2693      35        -3       7
## 3    14     3     39  3600      35        -3       4</code></pre>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb828-1" title="1"><span class="co"># 下面用 c_avegest 和 difgest 代替 gestat 放入同樣模型的固定效應部分</span></a>
<a class="sourceLine" id="cb828-2" title="2"></a>
<a class="sourceLine" id="cb828-3" title="3">M_gestat_sep &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_avegest <span class="op">+</span><span class="st"> </span>difgest <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb828-4" title="4"><span class="kw">summary</span>(M_gestat_sep)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_avegest + difgest + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 129557.3
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.02183 -0.52451  0.00937  0.52315  3.98953 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept) 111117   333.34  
##  Residual             123670   351.67  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3320.0084     8.3833 3974.3077 396.026 &lt; 2.2e-16 ***
## c_avegest    113.2183     4.0294 3996.5078  28.098 &lt; 2.2e-16 ***
## difgest       70.9350     2.6655 4626.8919  26.613 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) c_vgst
## c_avegest -0.628       
## difgest    0.000  0.000</code></pre>
<p>把胎齡分解了以後，從模型的輸出結果可以看出，層間效應 113 g (不同的母親)，要大於層內效應 70.9 g (同一母親不同胎兒)。</p>
<p>比較分解胎齡以後的模型 <code>M_gestat_sep</code> 和把胎齡作爲一個變量的模型 <code>M_gestat</code> 哪個更優，可以有兩種檢驗法:</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb830-1" title="1"><span class="co"># 1. 用 ML 法重新擬合兩個模型後進行 LRT 檢驗比較 R 可以自動幫你</span></a>
<a class="sourceLine" id="cb830-2" title="2"><span class="kw">anova</span>(M_gestat_sep, M_gestat)</a></code></pre></div>
<pre><code>## Data: siblings
## Models:
## M_gestat: birwt ~ c_gestat + (1 | momid)
## M_gestat_sep: birwt ~ c_avegest + difgest + (1 | momid)
##              Df    AIC    BIC   logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    
## M_gestat      4 129656 129684 -64823.7   129648                             
## M_gestat_sep  5 129581 129617 -64785.6   129571 76.219      1 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb832-1" title="1"><span class="co"># 2. 用 Wald 檢驗比較 Beta_1W 和 Beta_1B 是不是不同</span></a>
<a class="sourceLine" id="cb832-2" title="2"><span class="kw">linearHypothesis</span>(M_gestat_sep, <span class="st">&quot;c_avegest = difgest&quot;</span>)</a></code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## c_avegest - difgest = 0
## 
## Model 1: restricted model
## Model 2: birwt ~ c_avegest + difgest + (1 | momid)
## 
##   Df   Chisq Pr(&gt;Chisq)    
## 1                          
## 2  1 76.5998 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>無論是哪種檢驗，都告訴我們把胎齡分解了的模型更好。了解更多層內層間回歸模型，參照 <span class="citation">(Mann, De Stavola, and Leon <a href="#ref-Mann2004" role="doc-biblioref">2004</a>)</span>。</p>
</div>
<div id="到底選擇固定還是混合模型" class="section level2">
<h2><span class="header-section-number">60.7</span> 到底選擇固定還是混合模型？</h2>
<p>目前爲止我們討論了嵌套式數據可以使用固定效應模型分析，也可以使用混合效應模型來擬合，那麼到底你該選擇哪個來解釋你的數據呢？ 選擇模型永遠是一個很難回答的問題。哪種模型更加恰當 (appropriate) 其實要取決於你的數據結構，分層的數據的話層的數量是不是足夠多？以及最重要的，你的**分析目的*。</p>
<ol style="list-style-type: decimal">
<li>如果模型中想分析的層/羣組，可以被視爲唯一的實體 (uniqe entity，例如不同的種族)，而且我們希望從模型來獲得對不同種羣或者不同個體中每一個個體的估計，那麼固定效應模型是合適的。</li>
<li>如果層/羣組其實是人羣中的樣本 (samples from a real population，如例題中的母親層級，人羣衆可以有許許多多的母親)，我們打算從這個模型的結果去推論整個人羣，那麼隨機效應模型才是最合適的。</li>
<li>如果說層級本身的樣本量 (n of clusters) 太小，那麼強行使用混合效應模型的話會導致隨機效應的估計結果十分地低效，甚至沒有意義; 當然如果你的混合效應模型關心的是固定效應部分，那麼增加一些層級隨機效應應該也能達到提升統計估計效率的目的。</li>
<li>如果我們關心的是層級協變量的效應，那麼隨機效應模型是唯一的選擇。</li>
</ol>
</div>
<div id="練習題目" class="section level2">
<h2><span class="header-section-number">60.8</span> 練習題目</h2>
<div id="把-high-school-and-beyond-數據讀入-r-中" class="section level3">
<h3><span class="header-section-number">60.8.1</span> 把 High-school-and-Beyond 數據讀入 R 中。</h3>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb834-1" title="1">hsb_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/hsb_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb834-2" title="2"><span class="kw">length</span>(<span class="kw">unique</span>(hsb_selected<span class="op">$</span>schoolid)) <span class="co">## number of school = 160</span></a></code></pre></div>
<pre><code>## [1] 160</code></pre>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb836-1" title="1"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb836-2" title="2">hsb &lt;-<span class="st"> </span>hsb_selected[<span class="op">!</span><span class="kw">duplicated</span>(hsb_selected<span class="op">$</span>schoolid), ]</a>
<a class="sourceLine" id="cb836-3" title="3"></a>
<a class="sourceLine" id="cb836-4" title="4"><span class="co">## about 44 % of the schools are Catholic schools</span></a>
<a class="sourceLine" id="cb836-5" title="5"><span class="kw">with</span>(hsb, <span class="kw">tab1</span>(sector, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## sector : 
##         Frequency Percent Cum. percent
## 0              90   56.25        56.25
## 1              70   43.75       100.00
##   Total       160  100.00       100.00</code></pre>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb838-1" title="1"><span class="co">## among all the schools, average school size is 1098</span></a>
<a class="sourceLine" id="cb838-2" title="2"><span class="kw">with</span>(hsb, <span class="kw">summ</span>(size, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  obs. mean     median  s.d.    min.   max.  
##  160  1097.825 1061    629.506 100    2713</code></pre>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb840-1" title="1"><span class="co">## among all the pupils, about 53% are females</span></a>
<a class="sourceLine" id="cb840-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(female, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## female : 
##         Frequency Percent Cum. percent
## 0            3390   47.18        47.18
## 1            3795   52.82       100.00
##   Total      7185  100.00       100.00</code></pre>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" title="1"><span class="co">## among all the pupils, about 27.5% are from ethnic minorities</span></a>
<a class="sourceLine" id="cb842-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## minority : 
##         Frequency Percent Cum. percent
## 0            5211   72.53        72.53
## 1            1974   27.47       100.00
##   Total      7185  100.00       100.00</code></pre>
</div>
<div id="擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同" class="section level3">
<h3><span class="header-section-number">60.8.2</span> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</h3>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb844-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb844-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46645.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.126073 -0.727203  0.021883  0.757717  2.919116 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7682  2.1836  
##  Residual             37.0344  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65748    0.18799  148.30225  67.332 &lt; 2.2e-16 ***
## ses            2.39020    0.10572 6838.07757  22.609 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb846-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb846-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46649.0  46676.5 -23320.5  46641.0     7181 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.12631 -0.72766  0.02200  0.75781  2.91860 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7285  2.1745  
##  Residual             37.0298  6.0852  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65762    0.18732  149.17601  67.572 &lt; 2.2e-16 ***
## ses            2.39150    0.10569 6837.30521  22.627 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<p>其實由於樣本量 (層數) 足夠多，兩個隨機截距模型給出的參數估計十分接近。</p>
</div>
<div id="觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎" class="section level3">
<h3><span class="header-section-number">60.8.3</span> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</h3>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb848-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb848-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46611.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.148567 -0.731004  0.019288  0.753657  2.926345 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.685   1.9196  
##  Residual             37.037   6.0858  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                   Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)       11.71891    0.22806  153.58417 51.3855 &lt; 2.2e-16 ***
## ses                2.37471    0.10549 6738.85825 22.5110 &lt; 2.2e-16 ***
## factor(sector)1    2.10084    0.34112  147.35739  6.1586 6.638e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses   
## ses          0.063       
## fctr(sctr)1 -0.672 -0.091</code></pre>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb850-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb850-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46616.4  46650.8 -23303.2  46606.4     7180 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.149152 -0.730912  0.019585  0.754184  2.925231 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.6219  1.9031  
##  Residual             37.0328  6.0855  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                   Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)       11.71927    0.22651  155.49785 51.7396 &lt; 2.2e-16 ***
## ses                2.37710    0.10544 6735.02962 22.5440 &lt; 2.2e-16 ***
## factor(sector)1    2.10005    0.33875  149.11328  6.1994 5.285e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses   
## ses          0.064       
## fctr(sctr)1 -0.672 -0.092</code></pre>
<p>可以看出，<code>sector</code> 變量在學校層面上都是沒有變化的，所以加它進入混合效應的固定部分，只會對隨機效應標準差 (within level/cluster/group error) <span class="math inline">\(\hat\sigma_u\)</span> 的估計造成影響，隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span> 則幾乎不受影響。同樣的 “ML, REML” 兩種方法對結果的影響微乎其微。</p>
</div>
<div id="現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化" class="section level3">
<h3><span class="header-section-number">60.8.4</span> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</h3>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" title="1">hsb_selected &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb852-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_size =</span> (size <span class="op">-</span><span class="st"> </span><span class="kw">with</span>(hsb, <span class="kw">mean</span>(size)))<span class="op">/</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb852-3" title="3"></a>
<a class="sourceLine" id="cb852-4" title="4">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb852-5" title="5"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + c_size + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46613.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.142084 -0.732778  0.018257  0.755374  2.922664 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.6367  1.9070  
##  Residual             37.0345  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                    Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)       11.588378    0.238560  151.299117 48.5764 &lt; 2.2e-16 ***
## ses                2.374876    0.105459 6721.908756 22.5194 &lt; 2.2e-16 ***
## factor(sector)1    2.401175    0.379378  145.265476  6.3292 2.885e-09 ***
## c_size             0.053553    0.030198  148.968765  1.7734   0.07821 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1
## ses          0.063              
## fctr(sctr)1 -0.710 -0.086       
## c_size      -0.309 -0.009  0.447</code></pre>
<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb854-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + c_size + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46615.3  46656.5 -23301.6  46603.3     7179 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.142725 -0.733277  0.018426  0.756191  2.920849 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.5444  1.8827  
##  Residual             37.0307  6.0853  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                    Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)       11.589234    0.236144  154.101375 49.0769 &lt; 2.2e-16 ***
## ses                2.378431    0.105389 6715.629474 22.5680 &lt; 2.2e-16 ***
## factor(sector)1    2.399344    0.375458  147.837153  6.3904 2.035e-09 ***
## c_size             0.053456    0.029890  151.673272  1.7884    0.0757 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1
## ses          0.064              
## fctr(sctr)1 -0.710 -0.087       
## c_size      -0.309 -0.009  0.447</code></pre>
<p>增加了 <code>size</code> 進入混合效應模型的固定效應部分，對兩種參數估計方法輸出的結果 <span class="math inline">\((\hat\sigma_u, \hat\sigma_e)\)</span> 並沒有太大的影響。</p>
</div>
<div id="在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據" class="section level3">
<h3><span class="header-section-number">60.8.5</span> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</h3>
<div class="sourceCode" id="cb856"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb856-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb856-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * c_size + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46613.5
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.130458 -0.730487  0.018183  0.753342  2.922402 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.5594  1.8866  
##  Residual             37.0370  6.0858  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                           Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)              11.665327    0.240290  149.376496 48.5469 &lt; 2.2e-16 ***
## ses                       2.377719    0.105409 6689.156858 22.5572 &lt; 2.2e-16 ***
## factor(sector)1           2.618912    0.395270  140.853920  6.6256 6.788e-10 ***
## c_size                    0.022185    0.034603  151.266433  0.6411   0.52241    
## factor(sector)1:c_size    0.124462    0.069016  139.397371  1.8034   0.07349 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1 c_size
## ses          0.063                     
## fctr(sctr)1 -0.611 -0.083              
## c_size      -0.351 -0.007  0.214       
## fctr(sc)1:_  0.176 -0.001  0.308 -0.501</code></pre>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb858-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb858-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) * c_size + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46614.0  46662.1 -23300.0  46600.0     7178 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.130886 -0.730494  0.017706  0.753635  2.919879 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.4378  1.8541  
##  Residual             37.0338  6.0855  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                           Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)              11.666606    0.237019  153.063389 49.2222 &lt; 2.2e-16 ***
## ses                       2.382601    0.105316 6679.214135 22.6234 &lt; 2.2e-16 ***
## factor(sector)1           2.616394    0.389730  144.122856  6.7134 4.063e-10 ***
## c_size                    0.021983    0.034135  155.039559  0.6440   0.52052    
## factor(sector)1:c_size    0.124598    0.068044  142.600213  1.8311   0.06917 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1 c_size
## ses          0.064                     
## fctr(sctr)1 -0.611 -0.084              
## c_size      -0.351 -0.007  0.214       
## fctr(sc)1:_  0.176 -0.001  0.307 -0.502</code></pre>
<p>在兩個估計方法的報告中，交互作用項均不具有統計學意義。</p>
</div>
<div id="把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎" class="section level3">
<h3><span class="header-section-number">60.8.6</span> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</h3>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Random effect sd and random residual sd from previous 8 mixed effect models
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
REML
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
ML
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Model with
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_u\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_e\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_u\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_e\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
ses
</td>
<td style="text-align:center;">
2.184
</td>
<td style="text-align:center;">
6.085
</td>
<td style="text-align:center;">
2.175
</td>
<td style="text-align:center;">
6.085
</td>
</tr>
<tr>
<td style="text-align:center;">
ses &amp; sector
</td>
<td style="text-align:center;">
1.920
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.903
</td>
<td style="text-align:center;">
6.086
</td>
</tr>
<tr>
<td style="text-align:center;">
ses, size &amp; sector
</td>
<td style="text-align:center;">
1.907
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.883
</td>
<td style="text-align:center;">
6.085
</td>
</tr>
<tr>
<td style="text-align:center;">
ses, size &amp; sector <br> &amp; size*sector
</td>
<td style="text-align:center;">
1.887
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.854
</td>
<td style="text-align:center;">
6.086
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\hat\sigma_e\)</span> 幾乎在所有模型的估計中都保持不變。因爲我們在固定效應中增加的共變量在學校層面 (level 2) 都是一樣的。也就是說對於同一學校的學生，新增的共變量是一模一樣沒有變化的，所以在個人水平 (level 1) 的隨機效應幾乎不會發生變化。且注意到 “ML” 極大似然法估計的隨機效應標準差比 “REML” 限制性極大似然估計法給出的結果略小 1% 左右。</p>
</div>
<div id="在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化" class="section level3">
<h3><span class="header-section-number">60.8.7</span> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</h3>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb860-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb860-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46336.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.28599 -0.71963  0.03760  0.75553  2.88323 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1693  1.4728  
##  Residual             35.9184  5.9932  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)         12.944772    0.217832  217.525947  59.4254 &lt; 2.2e-16 ***
## ses                  2.059675    0.105073 6543.507619  19.6024 &lt; 2.2e-16 ***
## factor(sector)1      2.731292    0.310817  143.786789   8.7875 4.206e-15 ***
## c_size               0.076372    0.024802  148.489526   3.0793  0.002472 ** 
## factor(female)1     -1.252053    0.160241 5716.967171  -7.8135 6.572e-15 ***
## factor(minority)1   -3.098421    0.200627 3527.352578 -15.4437 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 c_size fctr(f)1
## ses          0.000                                
## fctr(sctr)1 -0.624 -0.116                         
## c_size      -0.265 -0.025  0.448                  
## factr(fml)1 -0.390  0.060  0.005    0.018         
## fctr(mnrt)1 -0.206  0.212 -0.080   -0.074  0.011</code></pre>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb862-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb862-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##    46338    46393   -23161    46322     7177 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.28718 -0.71993  0.03838  0.75632  2.88308 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1013  1.4496  
##  Residual             35.9062  5.9922  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)         12.947113    0.215801  222.800978  59.9956 &lt; 2.2e-16 ***
## ses                  2.062690    0.104976 6533.709343  19.6491 &lt; 2.2e-16 ***
## factor(sector)1      2.729839    0.307263  146.376477   8.8844 2.149e-15 ***
## c_size               0.076268    0.024522  151.247816   3.1102  0.002235 ** 
## factor(female)1     -1.253783    0.160045 5688.833343  -7.8339 5.602e-15 ***
## factor(minority)1   -3.101155    0.200217 3493.548744 -15.4890 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 c_size fctr(f)1
## ses          0.000                                
## fctr(sctr)1 -0.623 -0.117                         
## c_size      -0.264 -0.025  0.448                  
## factr(fml)1 -0.393  0.060  0.005    0.018         
## fctr(mnrt)1 -0.208  0.213 -0.080   -0.075  0.011</code></pre>
<p>混合效應模型的固定效應部分增加了學生性別，以及是否是少數族裔以後，“ML/REML” 估計的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 均發生了顯著變化。因爲它們在個人水平都不一樣 (level 1, within group random residuals)。</p>
</div>
<div id="檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e" class="section level3">
<h3><span class="header-section-number">60.8.8</span> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></h3>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb864-1" title="1"><span class="co"># Only minority is associated with sector. There are more pupils from</span></a>
<a class="sourceLine" id="cb864-2" title="2"><span class="co"># ethnic minorities attending catholic schools</span></a>
<a class="sourceLine" id="cb864-3" title="3"><span class="kw">with</span>(hsb_selected, <span class="kw">tabpct</span>( sector, minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        minority
## sector      0     1  Total
##   0      2721   921   3642
##   1      2490  1053   3543
##   Total  5211  1974   7185
## 
## Row percent 
##       minority
## sector       0       1  Total
##      0    2721     921   3642
##         (74.7)  (25.3)  (100)
##      1    2490    1053   3543
##         (70.3)  (29.7)  (100)
## 
## Column percent 
##        minority
## sector      0       %     1       %
##   0      2721  (52.2)   921  (46.7)
##   1      2490  (47.8)  1053  (53.3)
##   Total  5211   (100)  1974   (100)</code></pre>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb866-1" title="1"><span class="kw">with</span>(hsb_selected, <span class="kw">tabpct</span>( sector, female, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        female
## sector      0     1  Total
##   0      1730  1912   3642
##   1      1660  1883   3543
##   Total  3390  3795   7185
## 
## Row percent 
##       female
## sector       0       1  Total
##      0    1730    1912   3642
##         (47.5)  (52.5)  (100)
##      1    1660    1883   3543
##         (46.9)  (53.1)  (100)
## 
## Column percent 
##        female
## sector      0      %     1       %
##   0      1730   (51)  1912  (50.4)
##   1      1660   (49)  1883  (49.6)
##   Total  3390  (100)  3795   (100)</code></pre>
<div class="sourceCode" id="cb868"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb868-1" title="1"><span class="co">## there was no significant interaction between female sex and sector so</span></a>
<a class="sourceLine" id="cb868-2" title="2"><span class="co">## this is deleted from the final model</span></a>
<a class="sourceLine" id="cb868-3" title="3">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(female)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb868-4" title="4"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * factor(female) + c_size + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46336.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.27886 -0.72057  0.03699  0.75622  2.87920 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1834  1.4776  
##  Residual             35.9191  5.9933  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                                    Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)                       12.966256    0.226778  258.535057  57.1761 &lt; 2.2e-16 ***
## ses                                2.058832    0.105092 6543.813324  19.5908 &lt; 2.2e-16 ***
## factor(sector)1                    2.671501    0.354202  219.966839   7.5423 1.203e-12 ***
## factor(female)1                   -1.294931    0.200965 7102.454639  -6.4436 1.243e-10 ***
## c_size                             0.076686    0.024873  147.469390   3.0831  0.002446 ** 
## factor(minority)1                 -3.097826    0.200706 3526.876210 -15.4347 &lt; 2.2e-16 ***
## factor(sector)1:factor(female)1    0.118573    0.332499 3731.139999   0.3566  0.721402    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 fctr(f)1 c_size fctr(m)1
## ses         -0.001                                         
## fctr(sctr)1 -0.658 -0.099                                  
## factr(fml)1 -0.463  0.051  0.291                           
## c_size      -0.246 -0.025  0.378   -0.006                  
## fctr(mnrt)1 -0.198  0.212 -0.070    0.009   -0.074         
## fctr()1:()1  0.272 -0.006 -0.476   -0.603    0.033  0.000</code></pre>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb870-1" title="1"><span class="co">## There is an interaction between minority and sector</span></a>
<a class="sourceLine" id="cb870-2" title="2">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(minority)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb870-3" title="3"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * factor(minority) + c_size +  
##     factor(female) + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46306.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.25845 -0.71873  0.03640  0.76239  2.93045 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1745  1.4746  
##  Residual             35.7700  5.9808  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)                         13.183015    0.222112  230.832589  59.3529 &lt; 2.2e-16 ***
## ses                                  2.006866    0.105303 6576.742333  19.0580 &lt; 2.2e-16 ***
## factor(sector)1                      2.249566    0.323107  163.059561   6.9623 7.782e-11 ***
## factor(minority)1                   -4.226834    0.287298 3674.763010 -14.7123 &lt; 2.2e-16 ***
## c_size                               0.094335    0.025023  153.264958   3.7699 0.0002326 ***
## factor(female)1                     -1.250756    0.159945 5731.205525  -7.8199 6.248e-15 ***
## factor(sector)1:factor(minority)1    2.167447    0.395431 3399.174556   5.4812 4.532e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 fctr(m)1 c_size fctr(f)1
## ses         -0.017                                         
## fctr(sctr)1 -0.642 -0.086                                  
## fctr(mnrt)1 -0.281  0.212  0.142                           
## c_size      -0.232 -0.036  0.392   -0.145                  
## factr(fml)1 -0.382  0.059  0.005    0.007    0.018         
## fctr()1:()1  0.196 -0.090 -0.272   -0.717    0.131  0.001</code></pre>
<p>數據顯示，少數族裔更多地選擇天主教會學校學習。學生性別則與是否是天主教會學校之間沒有顯著的關係。少數族裔和教會學校之間的交互作用同時也被發現具有統計學意義。</p>
</div>
<div id="對上面最後一個模型進行殘差分析和模型的診斷" class="section level3">
<h3><span class="header-section-number">60.8.9</span> 對上面最後一個模型進行殘差分析和模型的診斷。</h3>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb872-1" title="1"><span class="co">#fit &lt;- lmer(mathach ~ ses + factor(sector)*factor(minority) + c_size + </span></a>
<a class="sourceLine" id="cb872-2" title="2"><span class="co">#              factor(female) + (1| schoolid), data=hsb_selected)</span></a>
<a class="sourceLine" id="cb872-3" title="3"><span class="co">#summary(fit)</span></a>
<a class="sourceLine" id="cb872-4" title="4">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(minority)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female),  <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid, <span class="dt">data =</span> hsb_selected, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb872-5" title="5"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: hsb_selected 
##         AIC       BIC     logLik
##   46324.414 46386.323 -23153.207
## 
## Random effects:
##  Formula: ~1 | schoolid
##         (Intercept)  Residual
## StdDev:   1.4746055 5.9807998
## 
## Fixed effects: mathach ~ ses + factor(sector) * factor(minority) + c_size +      factor(female) 
##                                        Value  Std.Error   DF    t-value p-value
## (Intercept)                       13.1830150 0.22211246 7021  59.352884  0.0000
## ses                                2.0068664 0.10530291 7021  19.058033  0.0000
## factor(sector)1                    2.2495661 0.32310709  157   6.962293  0.0000
## factor(minority)1                 -4.2268343 0.28729849 7021 -14.712344  0.0000
## c_size                             0.0943352 0.02502303  157   3.769937  0.0002
## factor(female)1                   -1.2507559 0.15994509 7021  -7.819908  0.0000
## factor(sector)1:factor(minority)1  2.1674475 0.39543102 7021   5.481228  0.0000
##  Correlation: 
##                                   (Intr) ses    fctr(s)1 fctr(m)1 c_size fctr(f)1
## ses                               -0.017                                         
## factor(sector)1                   -0.642 -0.086                                  
## factor(minority)1                 -0.281  0.212  0.142                           
## c_size                            -0.232 -0.036  0.392   -0.145                  
## factor(female)1                   -0.382  0.059  0.005    0.007    0.018         
## factor(sector)1:factor(minority)1  0.196 -0.090 -0.272   -0.717    0.131  0.001  
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -3.258450948 -0.718733897  0.036399219  0.762392656  2.930454863 
## 
## Number of Observations: 7185
## Number of Groups: 160</code></pre>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" title="1"><span class="co"># number of students in each school</span></a>
<a class="sourceLine" id="cb874-2" title="2">n_pupil &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(schoolid, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb874-3" title="3">hsb &lt;-<span class="st"> </span><span class="kw">merge</span>(hsb, n_pupil, <span class="dt">by =</span> <span class="st">&quot;schoolid&quot;</span>)  </a>
<a class="sourceLine" id="cb874-4" title="4"></a>
<a class="sourceLine" id="cb874-5" title="5"></a>
<a class="sourceLine" id="cb874-6" title="6">hsb &lt;-<span class="st"> </span>hsb <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb874-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="co"># extract the random effect (EB) residuals (at school level)</span></a>
<a class="sourceLine" id="cb874-8" title="8">         <span class="dt">uhat_eb =</span> <span class="kw">ranef</span>(Fixed_reml)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, </a>
<a class="sourceLine" id="cb874-9" title="9">         <span class="co"># number of students in each school</span></a>
<a class="sourceLine" id="cb874-10" title="10">         <span class="co"># npupil = count(hsb_selected$schoolid)[2]$freq, </span></a>
<a class="sourceLine" id="cb874-11" title="11">         <span class="co"># shrinkage factor = sigma_u^2/(sigma_u^2+sigma_e^2/n_j)</span></a>
<a class="sourceLine" id="cb874-12" title="12">         <span class="dt">R =</span> <span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="fl">5.981</span><span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n),</a>
<a class="sourceLine" id="cb874-13" title="13">         <span class="co"># Empirical Bayes prediction of variance of uhat</span></a>
<a class="sourceLine" id="cb874-14" title="14">         <span class="dt">var_eb =</span> R<span class="op">*</span><span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span>, </a>
<a class="sourceLine" id="cb874-15" title="15">         <span class="co"># standardize the uhat</span></a>
<a class="sourceLine" id="cb874-16" title="16">         <span class="dt">uhat_st =</span> uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb))</a>
<a class="sourceLine" id="cb874-17" title="17"></a>
<a class="sourceLine" id="cb874-18" title="18"><span class="co"># extract the standardized random residuals (at pupil level)</span></a>
<a class="sourceLine" id="cb874-19" title="19">hsb_selected<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(Fixed_reml, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb875-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb875-2" title="2"><span class="kw">hist</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">breaks =</span> <span class="dv">12</span>, <span class="dt">col=</span><span class="st">&#39;lightblue&#39;</span>)</a>
<a class="sourceLine" id="cb875-3" title="3"><span class="kw">qqnorm</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">ylab =</span> <span class="st">&quot;Standardized level 2 (school) residuals&quot;</span>); <span class="kw">qqline</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">col=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals"></span>
<img src="bookdown_files/figure-html/level2-residuals-1.png" alt="Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.4: Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept
</p>
</div>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb876-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb876-2" title="2"><span class="kw">hist</span>(hsb_selected<span class="op">$</span>ehat, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">breaks =</span> <span class="dv">38</span>, <span class="dt">col=</span><span class="st">&#39;lightblue&#39;</span>)</a>
<a class="sourceLine" id="cb876-3" title="3"><span class="kw">qqnorm</span>(hsb_selected<span class="op">$</span>ehat,  <span class="dt">ylab =</span> <span class="st">&quot;Standardized level 1 (pupil) residuals&quot;</span>); <span class="kw">qqline</span>(hsb_selected<span class="op">$</span>ehat, <span class="dt">col=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level1-residuals"></span>
<img src="bookdown_files/figure-html/level1-residuals-1.png" alt="Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.5: Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept
</p>
</div>
</div>
<div id="通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值" class="section level3">
<h3><span class="header-section-number">60.8.10</span> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</h3>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb877-1" title="1"><span class="kw">summ</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  160  -0.001 -0.004  1.007  -3.107 2.71</code></pre>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb879-1" title="1">hsb[<span class="kw">with</span>(hsb, <span class="kw">which</span>(uhat_st <span class="op">&gt;</span><span class="st"> </span><span class="fl">2.5</span>)),  <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">12</span>)]</a></code></pre></div>
<pre><code>##    sector mathach size   uhat_st
## 48      1  13.874  687 2.7097312</code></pre>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb881-1" title="1">hsb[<span class="kw">with</span>(hsb, <span class="kw">which</span>(uhat_st <span class="op">&lt;</span><span class="st"> </span><span class="fl">-2.5</span>)), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">12</span>)]</a></code></pre></div>
<pre><code>##     sector    mathach size    uhat_st
## 135      0 15.9359999  153 -3.0189027
## 143      0 -2.0810001  745 -3.1071846</code></pre>
<p>所以，此處可以看出，隨機效應殘差下提示的隨機效應標準差可能比較極端的有上面這三所規模較小的學校。其中一所是天主教會學校，另外兩所是非天主教會學校。</p>
</div>
<div id="計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差" class="section level3">
<h3><span class="header-section-number">60.8.11</span> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</h3>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb883-1" title="1">Mean_ses_math &lt;-<span class="st"> </span><span class="kw">ddply</span>(hsb_selected,<span class="op">~</span>schoolid,summarise,<span class="dt">mean_ses=</span><span class="kw">mean</span>(ses),<span class="dt">mean_math=</span><span class="kw">mean</span>(mathach))</a>
<a class="sourceLine" id="cb883-2" title="2"></a>
<a class="sourceLine" id="cb883-3" title="3"></a>
<a class="sourceLine" id="cb883-4" title="4">hsb_selected<span class="op">$</span>dif_ses &lt;-<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb883-5" title="5"><span class="cf">for</span> (i <span class="cf">in</span> Mean_ses_math<span class="op">$</span>schoolid) {</a>
<a class="sourceLine" id="cb883-6" title="6">hsb_selected<span class="op">$</span>dif_ses[<span class="kw">which</span>(hsb_selected<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)] &lt;-<span class="st">  </span>hsb_selected<span class="op">$</span>ses[<span class="kw">which</span>(hsb_selected<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)] <span class="op">-</span><span class="st"> </span></a>
<a class="sourceLine" id="cb883-7" title="7"><span class="st">  </span>Mean_ses_math<span class="op">$</span>mean_ses[<span class="kw">which</span>(Mean_ses_math<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)]</a>
<a class="sourceLine" id="cb883-8" title="8">}</a>
<a class="sourceLine" id="cb883-9" title="9"></a>
<a class="sourceLine" id="cb883-10" title="10">hsb_selected &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb883-11" title="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean_ses =</span> ses <span class="op">-</span><span class="st"> </span>dif_ses)</a>
<a class="sourceLine" id="cb883-12" title="12"></a>
<a class="sourceLine" id="cb883-13" title="13"><span class="co">## total simple model with ses only </span></a>
<a class="sourceLine" id="cb883-14" title="14">Simple_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb883-15" title="15"><span class="kw">summary</span>(Simple_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46645.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.126073 -0.727203  0.021883  0.757717  2.919116 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7682  2.1836  
##  Residual             37.0344  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65748    0.18799  148.30225  67.332 &lt; 2.2e-16 ***
## ses            2.39020    0.10572 6838.07757  22.609 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb885-1" title="1"><span class="co">## fit the extended model within and between effect separated</span></a>
<a class="sourceLine" id="cb885-2" title="2">Extend_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>dif_ses <span class="op">+</span><span class="st"> </span>mean_ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb885-3" title="3"><span class="co">## the between schools effect (5.87) seems much larger than the within school effect (2.19) </span></a>
<a class="sourceLine" id="cb885-4" title="4"><span class="kw">summary</span>(Extend_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ dif_ses + mean_ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46568.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.16665 -0.72543  0.01744  0.75578  2.94540 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.6925  1.6409  
##  Residual             37.0191  6.0843  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.68331    0.14938  153.65182  84.906 &lt; 2.2e-16 ***
## dif_ses        2.19117    0.10867 7021.50918  20.164 &lt; 2.2e-16 ***
## mean_ses       5.86617    0.36170  153.36659  16.218 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) dif_ss
## dif_ses  0.000        
## mean_ses 0.010  0.000</code></pre>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb887-1" title="1"><span class="co">## We find strong evidence to support that the second model gives a better fit to the data</span></a>
<a class="sourceLine" id="cb887-2" title="2">mod2&lt;-<span class="st"> </span><span class="kw">update</span>(Extend_reml, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>dif_ses <span class="op">-</span><span class="st"> </span>mean_ses)</a>
<a class="sourceLine" id="cb887-3" title="3"><span class="kw">anova</span>(Extend_reml, mod2)</a></code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: hsb_selected
## Models:
## mod2: mathach ~ (1 | schoolid)
## Extend_reml: mathach ~ dif_ses + mean_ses + (1 | schoolid)
##             Df     AIC     BIC   logLik deviance   Chisq Chi Df Pr(&gt;Chisq)    
## mod2         3 47121.8 47142.4 -23557.9  47115.8                              
## Extend_reml  5 46573.8 46608.2 -23281.9  46563.8 552.001      2 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
</div>
<div id="隨機回歸系數模型-random-coefficient-model" class="section level1">
<h1><span class="header-section-number">第 61 章</span> 隨機回歸系數模型 random coefficient model</h1>
<p>這一章節我們把隨機截距模型進一步擴展，在隨機效應部分增加隨機斜率成分 (random slope)。這樣的模型又稱隨機系數模型 (random coefficient model) 或 隨機斜率模型 (random slope model)。</p>
<div id="gcse-scores-實例" class="section level2">
<h2><span class="header-section-number">61.1</span> GCSE scores 實例</h2>
<p>第一章介紹過的 65 所中學學生在入學前的閱讀水平成績和畢業時的考試成績的 GCSE 數據，用來作爲本章介紹概念的實例。我們先對其中學校編號爲 1 的學生做兩個成績的線性回歸:</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb890-1" title="1">gcse_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/gcse_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb890-2" title="2">M_sch1 &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ])</a>
<a class="sourceLine" id="cb890-3" title="3"></a>
<a class="sourceLine" id="cb890-4" title="4"><span class="kw">summary</span>(M_sch1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt, data = gcse_selected[gcse_selected$school == 
##     1, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -22.4876  -5.4427  -1.0177   6.1932  15.4687 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 3.833302   0.982238  3.9026 0.0002141 ***
## lrt         0.709341   0.092006  7.7097 5.771e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.29 on 71 degrees of freedom
## Multiple R-squared:  0.45569,    Adjusted R-squared:  0.44802 
## F-statistic:  59.44 on 1 and 71 DF,  p-value: 5.7708e-11</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig1"></span>
<img src="bookdown_files/figure-html/hier04-fig1-1.png" alt="GCSE versus LRT in school 1" width="80%" />
<p class="caption">
圖 61.1: GCSE versus LRT in school 1
</p>
</div>
<p>當我們重復同樣的實驗，給 65 所學校 (48號學校除外，它只有兩個學生) 一一繪制回歸直線的時候，你得到的一簇直線是這樣紙的:</p>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig2"></span>
<img src="bookdown_files/figure-html/hier04-fig2-1.png" alt="Predicted regression lines of GCSE versus LRT scores: separate estimates from each school" width="80%" />
<p class="caption">
圖 61.2: Predicted regression lines of GCSE versus LRT scores: separate estimates from each school
</p>
</div>
<p>實際上這麼多學校學生的成績前後回歸線，其截距和斜率各不相同 (圖<a href="10-Hierarchical-models.html#fig:hier04-fig2">61.2</a>)。這些斜率和截距的總結歸納如下:</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb892-1" title="1"><span class="kw">summ</span>(Coefs[<span class="op">-</span><span class="dv">48</span>,])</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   -0.18  -0.33   3.29   -8.52  6.84  
## 2 lrt         64   0.54   0.54    0.18   0.04   1.08</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig3"></span>
<img src="bookdown_files/figure-html/hier04-fig3-1.png" alt="School specific slopes and intercepts" width="80%" />
<p class="caption">
圖 61.3: School specific slopes and intercepts
</p>
</div>
<p>圖 <a href="10-Hierarchical-models.html#fig:hier04-fig3">61.3</a> 展示的是這些回歸直線各自的截距 (x 軸) 和斜率 (y 軸) 的散點圖。縱橫添加的兩條直線分別是截距和斜率的均值的位置。很明顯，截距和斜率之間本身是呈現正相關的 (相關系數 0.36): <strong>如果一個學校學生入學時成績一般，但是畢業時 GCSE 成績較高，說明那所學校本身對學生成績的提升作用明顯</strong>。</p>
<p>經過擬合64個線性回歸模型，獲得 <span class="math inline">\(64\times3\)</span> 個不同的回歸線的參數 (截距，斜率，和殘差方差)。所以我們可以提出的關於 “學校” 這個個體，它們各自的入學前後成績作出的回歸線獲得的三個參數，在它的 <strong>“人羣 (可以是英國國內的中學，全歐洲的中學，或者是全世界的中學)”</strong> 中是隨機分布在一些 “均值” 附近的。</p>
</div>
<div id="隨機回歸系數的實質" class="section level2">
<h2><span class="header-section-number">61.2</span> 隨機回歸系數的實質</h2>
<p>在隨機截距模型中，截距可以隨機分布在某個均值周圍，但是每條回歸直線我們默認其解釋變量和結果變量之間的關系是一樣的 (相同斜率的一簇直線)。現在，我們來把這個模型擴展，放寬它對斜率的限制，允許不同的層與層之間不僅僅可以有不同的截距，還可以有不同的斜率:</p>
<p><span class="math display" id="eq:hier04-1">\[
\begin{equation}
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})X_{1ij} + e_{ij}
\end{equation}
\tag{61.1}
\]</span></p>
<p>其中:</p>
<ul>
<li><span class="math inline">\(u_{0j}:\)</span> 是隨機截距成分 (第 <span class="math inline">\(j\)</span> 層數據和總體均值 <span class="math inline">\(\beta_0\)</span> 之間的差異)</li>
<li><span class="math inline">\(u_{1j}:\)</span> 是隨機斜率成分 (第 <span class="math inline">\(j\)</span> 層數據和總體寫率 <span class="math inline">\(\beta_1\)</span> 之間的差異)</li>
<li><span class="math inline">\(\text{E}(u_{0j}|X_{1ij}) = 0\)</span></li>
<li><span class="math inline">\(\text{E}(u_{1j}|X_{1ij}) = 0\)</span></li>
<li><span class="math inline">\(\text{E}(e_{ij}|X_{1ij},u_{0j}, u_{1j}) = 0\)</span></li>
<li><span class="math inline">\(u_0, u_1 \perp X_{1ij}\)</span> (兩個隨機部分和解釋變量之間獨立不相關)</li>
<li><span class="math inline">\(u_0, u_1 \perp e_{ij}\)</span> (兩個隨機部分和總體的隨機誤差獨立不相關)</li>
</ul>
<p>另外，<span class="math inline">\(\mathbf{u}_j = \{u_0, u_1\}\)</span> 服從分布:</p>
<p><span class="math display">\[
\mathbf{u}_j | X_{1ij} \sim N(\mathbf{0}, \mathbf{\sum}_{\mathbf{u}})
\]</span></p>
<p>其中的 <span class="math inline">\(\mathbf{\sum}_{\mathbf{u}}\)</span> 是一個 <span class="math inline">\(2\times2\)</span> 的方差協方差矩陣:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Where } \mathbf{u}_j &amp; = (u_{0j}, u_{1j})^T \\ 
              \mathbf{0}   &amp; = (0, 0)^T \\ 
              \mathbf{\sum}_{\mathbf{u}} &amp; =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} &amp; \sigma_{u_{01}} \\
              \sigma_{u_{01}}   &amp; \sigma^2_{u_{11}} \\
              \end{array} \right)
\end{aligned}
\]</span></p>
<p><span class="math inline">\(e_{ij}\)</span> 則服從下列分布:</p>
<p><span class="math display">\[
e_{ij} | X_{1ij}, u_{0j}, u_{1j} \sim N(0, \sigma^2_e)
\]</span></p>
</div>
<div id="繼續-gcse-scores-實例" class="section level2">
<h2><span class="header-section-number">61.3</span> 繼續 GCSE scores 實例</h2>
<p>繼續用 GCSE 數據，去除掉 48 號學校以後，擬合一個固定效應模型 (相同斜率，但是不同的固定截距):</p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb894-1" title="1">FIX_inter &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ])</a></code></pre></div>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb895-1" title="1"><span class="kw">summary</span>(FIX_inter)</a></code></pre></div>
<pre><code>Call:
lm(formula = gcse ~ 0 + lrt + factor(school), data = gcse_selected[gcse_selected$school != 
    48, ])

Residuals:
   Min     1Q Median     3Q    Max 
-28.32  -4.77   0.22   5.08  24.41 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
lrt                0.5595     0.0125   44.63  &lt; 2e-16 ***
factor(school)1    4.0823     0.8806    4.64  3.7e-06 ***
factor(school)2    5.6202     1.0154    5.53  3.3e-08 ***
   ...................                  ............
   ................... &lt;Output ommited&gt; ............
   ...................                  ............
factor(school)62  -0.5566     0.8929   -0.62  0.53306    
factor(school)63   6.4827     1.3734    4.72  2.4e-06 ***
factor(school)64   1.0089     0.9808    1.03  0.30368    
factor(school)65  -1.7701     0.8415   -2.10  0.03547 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.52 on 3992 degrees of freedom
Multiple R-squared:  0.442, Adjusted R-squared:  0.433 
F-statistic: 48.7 on 65 and 3992 DF,  p-value: &lt;2e-16</code></pre>
<p>該固定效應模型 (簡單線性回歸模型) 估計的共同斜率是 0.56 (se = 0.01)，和 64 個不同的固定斜率。這些固定斜率的範圍是 -9,63 到 7.91，均值是 0.03，標準差是 3.38。估計的殘差標準差是 <code>Residual standard error: 7.52</code>。</p>
<p>如果用相同的數據，我們允許截距發生隨機變動的話 (隨機截距模型):</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb897-1" title="1">MIX_inter &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb897-2" title="2"><span class="kw">summary</span>(MIX_inter)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28044.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71619 -0.63094  0.02920  0.68478  3.26661 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  9.4273  3.0704  
##  Residual             56.6047  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                Estimate  Std. Error          df t value Pr(&gt;|t|)    
## (Intercept)    0.031006    0.405263   59.922917  0.0765   0.9393    
## lrt            0.563268    0.012471 4048.045047 45.1676   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.007</code></pre>
<p>隨機截距模型估計的共同斜率還是不變 (0.56, se = 0.01)，總體平均截距是 0.03 (無統計學意義)。截距的 (正態) 分布的標準差是 3.07。殘差標準差，和剛才簡單現行回歸計算的殘差標準差是一樣的 (=7.52)。幾乎所有我們關心的參數估計，都接近簡單線性回歸的結果，但是隨機截距模型使用的參數個數只有 4 個，固定效應模型則用到了 66 個 (很顯然隨機截距模型更加高效)。</p>
<p>接下來，我們進一步擬合本章的重點模型 – 隨機參數模型:</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb899-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb899-2" title="2"><span class="kw">summary</span>(MIX_coef)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28003
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83179 -0.63196  0.03373  0.68330  3.45517 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  school   (Intercept)  9.24988 3.04136       
##           lrt          0.01496 0.12231  0.493
##  Residual             55.38239 7.44193       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept) -0.109181   0.402637 59.913249 -0.2712   0.7872    
## lrt          0.556600   0.020114 56.334162 27.6722   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.365 
## convergence code: 0
## Model failed to converge with max|grad| = 0.00928374 (tol = 0.002, component 1)</code></pre>
<p>這個模型，不僅允許了隨機的截距，還允許每個直線的斜率成爲隨機的斜率。此時的總體平均截距被估計爲 -0.11 (依然沒有統計學意義)，標準差略微變小 (3.07 變成了 3.04)。總體平均斜率是 0.56，現在也被允許有變動，其標準差是 0.12。此時這些許許多多的估計回歸方程中，斜率和截距的相關系數是 0.49，這十分接近我們在一開始的簡單回歸64次計算獲得的斜率和截距的相關系數 (0.36)。此隨機系數模型的殘差標準差變成了 7.44，略微小於之前的 7.52。這三個模型的結果總結如下表:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 61.1: Comparison of fixed, random intercept, and random coefficient models: school data
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="6">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Model
</div>
</th>
</tr>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Fixed effect
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Random intercept
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Random coeff.
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Parameter
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(Fixed\; part\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\beta_0\)</span>
</td>
<td style="text-align:left;">
-0.03
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.031
</td>
<td style="text-align:left;">
0.405
</td>
<td style="text-align:left;">
-0.109
</td>
<td style="text-align:left;">
0.403
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\beta_1\)</span>
</td>
<td style="text-align:left;">
0.56
</td>
<td style="text-align:left;">
0.013
</td>
<td style="text-align:left;">
0.563
</td>
<td style="text-align:left;">
0.013
</td>
<td style="text-align:left;">
0.557
</td>
<td style="text-align:left;">
0.020
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(Random\; part\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_{u_{00}}\)</span>
</td>
<td style="text-align:left;">
3.38
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
3.07
</td>
<td style="text-align:left;">
0.312
</td>
<td style="text-align:left;">
3.041
</td>
<td style="text-align:left;">
0.311
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_{u_{11}}\)</span>
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.122
</td>
<td style="text-align:left;">
0.019
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\text{Corr}(0,1)\)</span>
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.494
</td>
<td style="text-align:left;">
0.149
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_e\)</span>
</td>
<td style="text-align:left;">
7.522
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
7.524
</td>
<td style="text-align:left;">
0.084
</td>
<td style="text-align:left;">
7.442
</td>
<td style="text-align:left;">
0.084
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="使用模型結果推斷" class="section level2">
<h2><span class="header-section-number">61.4</span> 使用模型結果推斷</h2>
<p>接下來，我們討論如何比較隨機系數模型，隨機截距模型，也就是如何選擇一個更優的模型。如果只是比較相同數據下，隨機系數模型和隨機截距模型的優劣，那麼只需要同時檢驗 <span class="math inline">\(u_{1j} = 0; \text{Cov}(u_{0j}, u_{1j}) = 0\)</span>。</p>
<p>就用剛剛擬合好的 <code>MIX_inter</code> 和 <code>MIX_coef</code> 來比較:</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb901-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">random =</span>  <span class="op">~</span><span class="st"> </span>lrt <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb901-2" title="2">MIX_inter &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb901-3" title="3"></a>
<a class="sourceLine" id="cb901-4" title="4"><span class="kw">anova</span>(MIX_inter, MIX_coef)</a></code></pre></div>
<pre><code>##           Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## MIX_inter     1  4 28052.050 28077.281 -14022.025                         
## MIX_coef      2  6 28014.963 28052.809 -14001.482 1 vs 2 41.087068  &lt;.0001</code></pre>
<p>值得注意的是，這裏計算的 似然比的檢驗統計量服從的是一個 自由度爲 2 的卡方分布和一個 自由度爲 1 的卡方分布的混合分布。所以報告中給出的 p 值是一個保守估計，正確的 p 值可以這樣計算:</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb903-1" title="1">likelihood &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">logLik</span>(MIX_inter) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(MIX_coef)))</a>
<a class="sourceLine" id="cb903-2" title="2"><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 6.7124634e-10</code></pre>
<p>另一個重要的問題是該如何去真正理解這裏隨機系數模型給出的結果呢？</p>
<p>該模型的結果說，“人羣”中的總體均值是 -0.11，總體斜率是 0.56 (se = 0.02, 95%CI: 0.52, 0.60)。這裏的“人羣”指的是全英國/或者全世界這樣的學校。學校水平的截距和斜率服從以這兩個數字爲均值，標準差分別是 3.04 和 0.12 的正態分布。且截距和斜率之間的相關系數接近 0.50。第一層級 (學生的) 個體隨機誤差的標準差爲 7.44。這些結果可以拿來估計“學校人羣”的 95% 截距/斜率: <span class="math inline">\(-0.11 \pm 1.96 \times3.04\)</span> 和 <span class="math inline">\(0.56 \pm 1.96\times0.12\)</span>，所以人羣的截距的 95% 信賴區間是: <span class="math inline">\(-6.07, 5.85\)</span>，斜率的 95% 信賴區間是: <span class="math inline">\(0.33, 0.80\)</span>。與此形成對比的是，我們開頭給 64 所學校建立的 64 個模型的 截距和斜率拿來估計的 95% 截距信賴區間是 <span class="math inline">\(-0.18 \pm 1.96\times3.29: -6.63, 6.27\)</span>，95% 斜率信賴區間是 <span class="math inline">\(0.54 \pm 1.96 \times 0.18: 0.19, 0.89\)</span>。所以，隨機系數模型對截距和斜率的人羣估計及推斷更加精準。</p>
</div>
<div id="random-var" class="section level2">
<h2><span class="header-section-number">61.5</span> 隨機效應的方差</h2>
<p>在解釋混合效應模型的隨機效應部分的時候，有幾點需要注意。首先，隨機截距的方差，和隨機斜率的方差，是具有不同單位的。<strong>隨機截距的方差的單位是結果變量 <span class="math inline">\(Y\)</span> 的單位的平方</strong>。<strong>隨機斜率的方差，是結果變量和解釋變量的單位的商的平方</strong>。</p>
<p>另一個要注意的點是，<span class="math inline">\(Y_{ij}\)</span> 在 <span class="math inline">\(X_{1ij}\)</span> 的條件下的殘差的標準差，不是恆定不變的 (隨着 <span class="math inline">\(X_1\)</span> 的變化而變化):</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j}) X_{1ij} + e_{ij}  \\ 
       &amp; = (\beta_0 + \beta_1X_{1ij}) + (u_{0j} + u_{1j}X_{1ij} + e_{ij}) \\ 
       &amp; = (\beta_0 + \beta_1X_{1ij}) + \epsilon_{ij}
\end{aligned}
\]</span></p>
<p>所以從上面的式子可看出，隨機參數模型的<strong>總體殘差 (total residuals)</strong>，<span class="math inline">\(\epsilon_{ij} = u_{0j} + u_{1j}X_{1ij} + e_{ij}\)</span>，是隨着你想給斜率隨機性的那個解釋變量的變化而變化的。也正因爲如此，總體殘差的方差，也是隨着解釋變量變化而變化的 (和解釋變量成二次方程關系，如果繪制總體慘差的方差和解釋變量之間的關系會是一個拋物線):</p>
<p><span class="math display" id="eq:hier04-3">\[
\begin{aligned}
\text{Var}(Y_{ij} | X_{1ij}) &amp; = \text{Var}( u_{0j} + u_{1j}X_{1ij} + e_{ij}) \\ 
                             &amp; = \sigma^2_{u_{00}} + X_{1ij}^2\sigma^2_{u_{11}} + 2X_{1ij}\sigma_{u_{01}} + \sigma^2_e
\end{aligned}
\tag{61.2}
\]</span></p>
</div>
<div id="模型效果評估" class="section level2">
<h2><span class="header-section-number">61.6</span> 模型效果評估</h2>
<p>擬合模型的評估中，另一個重要的事是分析第一階層殘差和第二階層殘差是不是符合其前提條件 (正態分布)。記得第二階層殘差獲取之後需要被標準化。</p>
<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb905-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.00928374 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb907-1" title="1">School_res0 &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(MIX_coef, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;EB&quot;</span>, <span class="dt">standardize =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb907-2" title="2"><span class="kw">summ</span>(School_res0)</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   0      -0.11   2.87   -7.19  6.45  
## 2 lrt         64   0      0       0.1    -0.19  0.35</code></pre>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb909-1" title="1">School_res1 &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(MIX_coef, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;EB&quot;</span>, <span class="dt">standardize =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in ranef.merMod(object, postVar = TRUE): &#39;postVar&#39; is deprecated: please use &#39;condVar&#39;
## instead</code></pre>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb911-1" title="1"><span class="kw">summ</span>(School_res1)</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   0.04   -0.14   3      -6.74  7.53  
## 2 lrt         64   0.04   -0.03   1.31   -2.35  5.07</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier4-level2-residuals"></span>
<img src="bookdown_files/figure-html/hier4-level2-residuals-1.png" alt="Q-Q plots of school level intercept and slope residuals (unstandardized)" width="80%" />
<p class="caption">
圖 61.4: Q-Q plots of school level intercept and slope residuals (unstandardized)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:4-level2sta-residuals"></span>
<img src="bookdown_files/figure-html/4-level2sta-residuals-1.png" alt="Q-Q plots of school level intercept and slope residuals (standardized)" width="80%" />
<p class="caption">
圖 61.5: Q-Q plots of school level intercept and slope residuals (standardized)
</p>
</div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  4057 0      0.034   0.989  -3.832 3.455</code></pre>
<div class="figure" style="text-align: center"><span id="fig:4-level1sta-residuals"></span>
<img src="bookdown_files/figure-html/4-level1sta-residuals-1.png" alt="Histogram and Q-Qf plots of elementary level (pupil) standardized residuals" width="80%" />
<p class="caption">
圖 61.6: Histogram and Q-Qf plots of elementary level (pupil) standardized residuals
</p>
</div>
</div>
<div id="練習題-9" class="section level2">
<h2><span class="header-section-number">61.7</span> 練習題</h2>
<ol style="list-style-type: decimal">
<li>GCSE data: 數據來自65所中學的學生畢業成績 “the Graduate Certificate of Secondary Education (GCSE) score”，和這些學生在剛剛入學時接受閱讀能力水平測試 (LRT score) 的成績。其變量和各自含義爲：</li>
</ol>
<pre><code>school          school identifier
student         student identifier
gcse            GCSE score (multiplied by 10)
lrt             LRT score (multiplied by 10)
girl            Student female gender (1 = yes, 0 = no)
schgend         type of school (1: mixed gender; 2: boys only; 3: girls only)</code></pre>
<p>###　將數據導入軟件裏，</p>
<div class="sourceCode" id="cb915"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb915-1" title="1">gcse_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/gcse_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb915-2" title="2"></a>
<a class="sourceLine" id="cb915-3" title="3"><span class="kw">length</span>(<span class="kw">unique</span>(gcse_selected<span class="op">$</span>school)) <span class="co">## number of school = 65</span></a></code></pre></div>
<pre><code>## [1] 65</code></pre>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb917-1" title="1">gcse_selected &lt;-<span class="st"> </span>gcse_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb917-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">schgend =</span> <span class="kw">factor</span>(schgend, <span class="dt">labels  =</span> <span class="kw">c</span>(<span class="st">&quot;mixed geder&quot;</span>, <span class="st">&quot;boys only&quot;</span>, <span class="st">&quot;girls only&quot;</span>)))</a>
<a class="sourceLine" id="cb917-3" title="3"></a>
<a class="sourceLine" id="cb917-4" title="4"></a>
<a class="sourceLine" id="cb917-5" title="5"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb917-6" title="6">gcse &lt;-<span class="st"> </span>gcse_selected[<span class="op">!</span><span class="kw">duplicated</span>(gcse_selected<span class="op">$</span>school), ]</a>
<a class="sourceLine" id="cb917-7" title="7"></a>
<a class="sourceLine" id="cb917-8" title="8"><span class="co"># 一共有 65 所學校，54% 是混合校，15% 是男校，31% 是女校</span></a>
<a class="sourceLine" id="cb917-9" title="9"><span class="kw">with</span>(gcse, <span class="kw">tab1</span>(schgend, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## schgend : 
##             Frequency Percent Cum. percent
## mixed geder        35    53.8         53.8
## boys only          10    15.4         69.2
## girls only         20    30.8        100.0
##   Total            65   100.0        100.0</code></pre>
<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb919-1" title="1"><span class="co"># 計算每所學校兩種成績的平均分，計算一個包含每所學校的平均女生人數的變量</span></a>
<a class="sourceLine" id="cb919-2" title="2">Mean_gcse_lrt &lt;-<span class="st"> </span><span class="kw">ddply</span>(gcse_selected,<span class="op">~</span>school,summarise,<span class="dt">mean_gcse=</span><span class="kw">mean</span>(gcse),<span class="dt">mean_lrt=</span><span class="kw">mean</span>(lrt), <span class="dt">mean_girl=</span><span class="kw">mean</span>(girl)) </a>
<a class="sourceLine" id="cb919-3" title="3"></a>
<a class="sourceLine" id="cb919-4" title="4"><span class="co"># 整體來說，GCSE 分數的分布比起入學前 LRT 分數的分布更加寬泛，標準差更大。</span></a>
<a class="sourceLine" id="cb919-5" title="5"><span class="co"># 意味着入學時學生閱讀成績的差異，比起畢業時成績的差異要小。</span></a>
<a class="sourceLine" id="cb919-6" title="6"><span class="co"># 或者反過來說，畢業時成績差異，比起入學時閱讀成績的差異要大。</span></a>
<a class="sourceLine" id="cb919-7" title="7"><span class="kw">summ</span>(Mean_gcse_lrt[,<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>])</a></code></pre></div>
<pre><code>## 
## No. of observations = 65
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 mean_gcse 65   -0.23  -0.34   4.39   -10.49 10.04 
## 2 mean_lrt  65   -0.31  -0.41   3.44   -7.56  6.38  
## 3 mean_girl 65   0.57   0.5     0.36   0      1</code></pre>
<div id="先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校" class="section level3">
<h3><span class="header-section-number">61.7.1</span> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</h3>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb921-1" title="1">Fix &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb921-2" title="2"><span class="kw">anova</span>(Fix)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: gcse
##                  Df   Sum Sq  Mean Sq  F value     Pr(&gt;F)    
## lrt               1 141723.2 141723.2 2505.000 &lt; 2.22e-16 ***
## factor(school)   63  37314.7    592.3   10.469 &lt; 2.22e-16 ***
## Residuals      3992 225851.9     56.6                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb923-1" title="1"><span class="kw">summary</span>(Fix) <span class="co"># 輸出結果太長，中間被省略掉</span></a></code></pre></div>
<p>LRT 的回歸系數 (直線斜率 = 0.56, se = 0.01)，殘差的標準差 <span class="math inline">\(\hat\sigma_e =\)</span> 7.52。</p>
<pre><code>Call:
lm(formula = gcse ~ lrt + factor(school), data = gcse_selected[gcse_selected$school != 
    48, ])

Residuals:
   Min     1Q Median     3Q    Max 
-28.32  -4.77   0.22   5.08  24.41 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        4.08232    0.88060    4.64  3.7e-06 ***
lrt                0.55948    0.01253   44.63  &lt; 2e-16 ***
factor(school)2    1.53785    1.34332    1.14  0.25235    
                         ...
                         ...&lt;OMITTED OUTPUT&gt;
                         ...
                         ...
factor(school)65  -5.85245    1.21850   -4.80  1.6e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.52 on 3992 degrees of freedom
Multiple R-squared:  0.442, Adjusted R-squared:  0.433 
F-statistic: 49.4 on 64 and 3992 DF,  p-value: &lt;2e-16</code></pre>
</div>
<div id="僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化" class="section level3">
<h3><span class="header-section-number">61.7.2</span> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</h3>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb925-1" title="1">Fix1 &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb925-2" title="2"><span class="kw">anova</span>(Fix1)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: gcse
##             Df   Sum Sq  Mean Sq   F value     Pr(&gt;F)    
## lrt          1 141723.2 141723.2 2222.6017 &lt; 2.22e-16 ***
## schgend      2   4728.9   2364.4   37.0807 &lt; 2.22e-16 ***
## Residuals 4053 258437.7     63.8                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb927-1" title="1"><span class="kw">summary</span>(Fix1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt + schgend, data = gcse_selected[gcse_selected$school != 
##     48, ])
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -26.17545  -5.12410   0.19171   5.35399  28.32233 
## 
## Coefficients:
##                    Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       -0.960872   0.171460 -5.6041 2.233e-08 ***
## lrt                0.594272   0.012622 47.0836 &lt; 2.2e-16 ***
## schgendboys only   1.177713   0.392041  3.0041   0.00268 ** 
## schgendgirls only  2.362920   0.275274  8.5839 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.9853 on 4053 degrees of freedom
## Multiple R-squared:  0.36171,    Adjusted R-squared:  0.36124 
## F-statistic: 765.59 on 3 and 4053 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>新的模型 <code>Fix1</code> 參數明顯減少很多，殘差標準差估計 <span class="math inline">\(\hat\sigma_u =\)</span> 7.99。LRT 的回歸系數估計僅發生了不太明顯的變化 0.59 (0.01)</p>
</div>
<div id="使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義" class="section level3">
<h3><span class="header-section-number">61.7.3</span> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</h3>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb929-1" title="1"><span class="kw">library</span>(lmerTest)</a>
<a class="sourceLine" id="cb929-2" title="2">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb929-3" title="3"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28044.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71619 -0.63094  0.02920  0.68478  3.26661 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  9.4273  3.0704  
##  Residual             56.6047  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                Estimate  Std. Error          df t value Pr(&gt;|t|)    
## (Intercept)    0.031006    0.405263   59.922917  0.0765   0.9393    
## lrt            0.563268    0.012471 4048.045047 45.1676   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.007</code></pre>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb931-1" title="1"><span class="kw">ranova</span>(Fixed_reml) <span class="co">## random effect test</span></a></code></pre></div>
<pre><code>## ANOVA-like table for random-effects: Single term deletions
## 
## Model:
## gcse ~ lrt + (1 | school)
##              npar   logLik     AIC     LRT Df Pr(&gt;Chisq)    
## &lt;none&gt;          4 -14022.0 28052.0                          
## (1 | school)    3 -14224.8 28455.7 405.601  1 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>隨機截距模型的輸出結果可以看出，這裏的混合模型估計的 LRT 的回歸系數跟僅有固定效應的簡單線性回歸模型估計的值完全一樣 (0.56, se=0.01)。隨機效應部分 <span class="math inline">\(\hat\sigma_e = 7.524, \hat\sigma_u = 3.07\)</span>，此時的限制性似然 (restricted log-likelihood) 是 -14022。最晚部分的隨機效應檢驗的零假設是 <span class="math inline">\(\sigma_u = 0\)</span>，且值得注意的是，由於方差本身不可能小於零，故本次檢驗只用到自由度爲 1 的卡方分布的右半側(單側)。也就是說，其替代假設有且只有 <span class="math inline">\(\sigma_u &gt; 0\)</span> 的單側假設。這裏的檢驗結果提示高度有意義 (highly significant)。</p>
</div>
<div id="在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然" class="section level3">
<h3><span class="header-section-number">61.7.4</span> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</h3>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb933-1" title="1">Fixed_reml1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb933-2" title="2"><span class="co">#Fixed_reml1 &lt;- lme(fixed = gcse ~ lrt + schgend , random =  ~ 1 | school, data = gcse_selected[gcse_selected$school !=48, ], method = &quot;REML&quot;) </span></a>
<a class="sourceLine" id="cb933-3" title="3"></a>
<a class="sourceLine" id="cb933-4" title="4"><span class="kw">summary</span>(Fixed_reml1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28032.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71222 -0.63023  0.02647  0.68064  3.24445 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  8.4961  2.9148  
##  Residual             56.6045  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                      Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)         -0.872660    0.524979   58.504248 -1.6623  0.101807    
## lrt                  0.563512    0.012465 4049.316274 45.2087 &lt; 2.2e-16 ***
## schgendboys only     0.968683    1.118170   59.752787  0.8663  0.389785    
## schgendgirls only    2.497825    0.876614   56.676553  2.8494  0.006096 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.006                
## schgndbyson -0.469  0.006         
## schgndgrlso -0.599 -0.004  0.281</code></pre>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb935-1" title="1"><span class="co">## 檢驗新增的學校種類 schgend 是否對應該加入模型。</span></a>
<a class="sourceLine" id="cb935-2" title="2"></a>
<a class="sourceLine" id="cb935-3" title="3">mod2&lt;-<span class="st"> </span><span class="kw">update</span>(Fixed_reml1, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>schgend)</a>
<a class="sourceLine" id="cb935-4" title="4"><span class="kw">anova</span>(Fixed_reml1, mod2)</a></code></pre></div>
<pre><code>## Data: gcse_selected[gcse_selected$school != 48, ]
## Models:
## mod2: gcse ~ lrt + (1 | school)
## Fixed_reml1: gcse ~ lrt + schgend + (1 | school)
##             Df     AIC     BIC   logLik deviance   Chisq Chi Df Pr(&gt;Chisq)  
## mod2         4 28045.1 28070.4 -14018.6  28037.1                            
## Fixed_reml1  6 28041.1 28079.0 -14014.6  28029.1 8.01852      2   0.018147 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb937-1" title="1"><span class="co">## 求 Fixed_reml1 的似然</span></a>
<a class="sourceLine" id="cb937-2" title="2"></a>
<a class="sourceLine" id="cb937-3" title="3"><span class="kw">logLik</span>(Fixed_reml1)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -14016.32 (df=6)</code></pre>
<p>增加了學校類型在固定效應部分時，隨機效應的標準差從錢一個模型的 3.07 降低到這裏的 2.92。這個變量本身，從最後的模型比較也能看出，對模型的貢獻是有意義的 (p=0.018)。當然從隨機截距模型的輸出結果可以看出，學校類型的這一變量中，可能只有“女校”這一細分部分提供了足夠的效應。這裏的隨機截距模型的REML似然是 (restricted log-likelihood = -14016)</p>
</div>
<div id="擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分" class="section level3">
<h3><span class="header-section-number">61.7.5</span> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</h3>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb939-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb939-2" title="2"><span class="kw">summary</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 27988.8
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83073 -0.63015  0.03252  0.68505  3.41664 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.273191 2.87632       
##           lrt          0.014941 0.12223  0.582
##  Residual             55.394026 7.44272       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                    Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept)       -1.097818   0.497543 63.009861 -2.2065  0.031003 *  
## lrt                0.558197   0.020074 56.238393 27.8070 &lt; 2.2e-16 ***
## schgendboys only   1.041523   0.998851 57.084009  1.0427  0.301473    
## schgendgirls only  2.712024   0.783490 53.763667  3.4615  0.001061 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.321                
## schgndbyson -0.443  0.011         
## schgndgrlso -0.566  0.011  0.284</code></pre>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb941-1" title="1"><span class="kw">logLik</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -13994.393 (df=8)</code></pre>
<p>當截距 (不同學校之間， gcse 的起點)，斜率 (不同學校之間 lrt 和 gcse 之間的關系的斜率) 均可以有隨機性以後，<code>lrt</code> 的斜率雖然仍然保持不變 <span class="math inline">\(=0.56\)</span>，但是它的隨機效應標準差變成了 <span class="math inline">\(=0.12\)</span>，隨機截距的標準差也保持不變 <span class="math inline">\(=2.88\)</span>，這二者之間的相關系數是 <span class="math inline">\(=0.58\)</span>。第一階層隨機殘差標準也有了微妙的變化 <span class="math inline">\(7.52 \rightarrow 7.44\)</span>，此模型的限制性對數似然 (restricted log-likelihood) 是 <code>-13994.393 (df=8)</code>。</p>
</div>
<div id="通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義" class="section level3">
<h3><span class="header-section-number">61.7.6</span> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</h3>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb943-1" title="1"><span class="kw">ranova</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## ANOVA-like table for random-effects: Single term deletions
## 
## Model:
## gcse ~ lrt + schgend + (lrt | school)
##                       npar   logLik     AIC     LRT Df Pr(&gt;Chisq)    
## &lt;none&gt;                   8 -13994.4 28004.8                          
## lrt in (lrt | school)    6 -14016.3 28044.6 43.8549  2 2.9994e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb945-1" title="1"><span class="co"># 手算的方法是這樣的</span></a>
<a class="sourceLine" id="cb945-2" title="2">likelihood &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">logLik</span>(Fixed_reml1) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(Fixed_reml2)))</a>
<a class="sourceLine" id="cb945-3" title="3"><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 1.6765206e-10</code></pre>
<p>似然比檢驗的統計量是 43.8，不用檢驗也知道肯定是有意義的。手算也是可以達到相同的效果。值得注意的是，R計算給出的基於自由度爲 2 的卡方分布，其實是偏保守的。注意看手算部分，其實用到了自由度爲 1 自由度爲 2 兩個卡方分布換算獲得的 p 值。</p>
</div>
<div id="模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢" class="section level3">
<h3><span class="header-section-number">61.7.7</span> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</h3>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb947-1" title="1"><span class="co">## 把女生平均值放回整體數據中去</span></a>
<a class="sourceLine" id="cb947-2" title="2">Mean_girl &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb947-3" title="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">65</span>) {</a>
<a class="sourceLine" id="cb947-4" title="4">  Mean_girl &lt;-<span class="st"> </span><span class="kw">c</span>(Mean_girl, <span class="kw">rep</span>(Mean_gcse_lrt<span class="op">$</span>mean_girl[i], <span class="kw">with</span>(gcse_selected, <span class="kw">table</span>(school))[i]))</a>
<a class="sourceLine" id="cb947-5" title="5">  }</a>
<a class="sourceLine" id="cb947-6" title="6">gcse_selected<span class="op">$</span>mean_girl &lt;-<span class="st"> </span>Mean_girl</a>
<a class="sourceLine" id="cb947-7" title="7">  <span class="kw">rm</span>(Mean_girl)</a>
<a class="sourceLine" id="cb947-8" title="8"></a>
<a class="sourceLine" id="cb947-9" title="9"></a>
<a class="sourceLine" id="cb947-10" title="10">Fixed_reml3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>mean_girl <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.0133708 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb949-1" title="1"><span class="kw">summary</span>(Fixed_reml3)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + mean_girl + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 27997.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.81956 -0.63168  0.02994  0.68439  3.43510 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.910687 2.98508       
##           lrt          0.014913 0.12212  0.524
##  Residual             55.388585 7.44235       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept) -1.280012   0.705470 63.122621 -1.8144  0.07437 .  
## lrt          0.556711   0.020084 56.134006 27.7190  &lt; 2e-16 ***
## mean_girl    2.066161   1.031544 56.693987  2.0030  0.04997 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) lrt   
## lrt        0.220       
## mean_girl -0.828 -0.004
## convergence code: 0
## Model failed to converge with max|grad| = 0.0133708 (tol = 0.002, component 1)</code></pre>
<p>由於 <code>mean_girl</code> 其實是和 <code>schgend</code> 非常相似的表示學校層面的男女生性別比例的變量，所以這個模型的結果其實和前一個給出的隨機效應標準差的估計都很接近。</p>
</div>
<div id="現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt" class="section level3">
<h3><span class="header-section-number">61.7.8</span> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</h3>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb951-1" title="1">gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="dv">48</span>, ]</a></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   school student  gcse   lrt  girl schgend    mean_girl
##    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt;
## 1     48       1 -7.00 -3.73     1 girls only         1
## 2     48       2 -1.29 -4.55     1 girls only         1</code></pre>
<div class="sourceCode" id="cb953"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb953-1" title="1">school48lm &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb953-2" title="2"><span class="kw">summary</span>(school48lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt, data = gcse_selected[gcse_selected$school == 
##     48, ])
## 
## Residuals:
## ALL 2 residuals are 0: no residual degrees of freedom!
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -32.7221         NA      NA       NA
## lrt          -6.9018         NA      NA       NA
## 
## Residual standard error: NaN on 0 degrees of freedom
## Multiple R-squared:       1, Adjusted R-squared:     NaN 
## F-statistic:    NaN on 1 and 0 DF,  p-value: NA</code></pre>
<p>由於 48 號學校只有兩個數據點，所以強行進行簡單線性回歸的結果，就是擬合了一條通過這兩個點的直線，截距是-32.7，斜率是 -6.9，且沒有任何估計的誤差。</p>
</div>
<div id="這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎" class="section level3">
<h3><span class="header-section-number">61.7.9</span> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</h3>
<div class="sourceCode" id="cb955"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb955-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.00818763 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb957-1" title="1"><span class="kw">summary</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (lrt | school)
##    Data: gcse_selected
## 
## REML criterion at convergence: 28001.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83122 -0.63095  0.03275  0.68533  3.41855 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.248850 2.87208       
##           lrt          0.014968 0.12234  0.581
##  Residual             55.376791 7.44156       
## Number of obs: 4059, groups:  school, 65
## 
## Fixed effects:
##                    Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept)       -1.099128   0.496903 63.306305 -2.2120  0.030586 *  
## lrt                0.558013   0.020081 56.230723 27.7876 &lt; 2.2e-16 ***
## schgendboys only   1.041049   0.997646 57.338679  1.0435  0.301094    
## schgendgirls only  2.672800   0.779708 54.625681  3.4280  0.001163 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.321                
## schgndbyson -0.443  0.011         
## schgndgrlso -0.569  0.010  0.285  
## convergence code: 0
## Model failed to converge with max|grad| = 0.00818763 (tol = 0.002, component 1)</code></pre>
<p>可以看到，即使我們加入這個數據量極少的一個學校的數據，對結果也沒有太大的影響。</p>
</div>
<div id="計算這個模型的第二階級level-2-school-level的殘差" class="section level3">
<h3><span class="header-section-number">61.7.10</span> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</h3>
<div class="sourceCode" id="cb959"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb959-1" title="1">School_res &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(Fixed_reml2, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>)</a>
<a class="sourceLine" id="cb959-2" title="2"><span class="kw">summ</span>(School_res)</a></code></pre></div>
<pre><code>## 
## No. of observations = 65
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 65   0      0.11    2.65   -6.25  5.83  
## 2 lrt         65   0      0       0.1    -0.19  0.33</code></pre>
<div class="sourceCode" id="cb961"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb961-1" title="1">School_res[<span class="dv">48</span>, ] </a></code></pre></div>
<pre><code>##    (Intercept)          lrt
## 48 -0.73877885 -0.014709819</code></pre>
<p>隨機截距的殘差估計範圍在 -6.25 和 5.83 之間，隨機斜率殘差估計範圍在 -0.19 和 0.33 之間。其中 48 號學校的擬合後截距和斜率分別是 -0.74 和 -0.02。48 號學校在這個模型中估計的截距和斜率，與我們單獨對它一所學校擬合模型時的結果大相徑庭。這是因爲在總體的混合效應模型中，該學校的數據被拉近與總體的平均水平。</p>
<div class="figure" style="text-align: center"><span id="fig:4-level2-residuals"></span>
<img src="bookdown_files/figure-html/4-level2-residuals-1.png" alt="Q-Q plots of school level intercept and slope (unstandardized) residuals" width="80%" />
<p class="caption">
圖 61.7: Q-Q plots of school level intercept and slope (unstandardized) residuals
</p>
</div>
<p>圖 <a href="10-Hierarchical-models.html#fig:4-level2-residuals">61.7</a> 顯示標準化前的隨機效應部分的殘差表現尚可接受。</p>
</div>
<div id="計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何" class="section level3">
<h3><span class="header-section-number">61.7.11</span> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</h3>
<div class="sourceCode" id="cb963"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb963-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend, <span class="dt">random =</span> <span class="op">~</span><span class="st">  </span>lrt <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected, <span class="dt">method=</span><span class="st">&quot;REML&quot;</span>) <span class="co"># for extracting standardized level 2 error</span></a>
<a class="sourceLine" id="cb963-2" title="2"></a>
<a class="sourceLine" id="cb963-3" title="3">gcse_selected<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(Fixed_reml2, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a>
<a class="sourceLine" id="cb963-4" title="4"><span class="kw">with</span>(gcse_selected, <span class="kw">summ</span>(ehat, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  4059 0      0.033   0.989  -3.831 3.419</code></pre>
<div class="sourceCode" id="cb965"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb965-1" title="1"><span class="co">#  48 號學校的標準化殘差並不顯得異常</span></a>
<a class="sourceLine" id="cb965-2" title="2">gcse_selected<span class="op">$</span>ehat[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="st"> </span><span class="dv">48</span>]</a></code></pre></div>
<pre><code>## [1] -0.780061331  0.046827706</code></pre>
<div class="figure" style="text-align: center"><span id="fig:4-level1-residuals"></span>
<img src="bookdown_files/figure-html/4-level1-residuals-1.png" alt="Histogram and Q-Q plots of elementary level (pupil) standardized residuals" width="80%" />
<p class="caption">
圖 61.8: Histogram and Q-Q plots of elementary level (pupil) standardized residuals
</p>
</div>
</div>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-1" class="section level1">
<h1><span class="header-section-number">第 62 章</span> 縱向研究數據 longitudinal data 1</h1>
<p>本章我們來把目前爲止了解的混合效應 (截距/斜率) 模型應用到一種特殊形態的數據 – 縱向研究數據 – 中去。</p>
<p>縱向數據，是一種前瞻性收集的來的數據，它隨着時間的推移，在不同的時間點對相同的觀察對象進行數據的採集。每個研究對象被收集數據時的時間點，可以是相同的，也可以是不同的。在很多臨牀實驗中，患者被觀察隨訪，並且常常在同樣的時間點收集數據，所以在臨牀實驗的特殊形態下，每個患者收集數據的時間點可以做到統一，這樣的縱向研究數據是屬於<strong>固定測量時刻的類型 (fixed occasions)</strong>。但是在流行病學等觀察性研究中獲得的數據，就沒有這麼幸運，他們通常測量收集數據的時間點就不太可能保持一致，收集時間點不一致的縱向數據屬於<strong>不固定測量時刻的類型 (variable occasions)</strong>。</p>
<p>縱向數據英文名是 longitudinal data，它的常見別的名稱是 重復測量數據 (repeated measures data)，計量經濟學中叫做面板型數據 (panel data)，或者是時間序列橫斷面研究數據 (cross sectional time series data)。所以在縱向數據這種特殊形態的的嵌套式數據結構中，第二層級結構就是一個個的個體，第一層級結構，就是每個個體在不同的時間點獲得的測量值。除了和前面幾章討論過的嵌套式數據結構相似可以應用混合效應模型，縱向數據還有一些自己獨特的性質需要加以考量:</p>
<ul>
<li>層內數據的相關性結構是有測量時間的先後順序的;</li>
<li>之前討論的嵌套式結構數據在層內的觀察值則沒有嚴格的時間或者大小的排序 (例如同一所學校的不同學生);</li>
<li>換句話說，層內相關系數 (intra-class correlation) 很難被認爲是相似或者相同的。</li>
</ul>
<div id="固定測量時刻-fixed-occasions" class="section level2">
<h2><span class="header-section-number">62.1</span> 固定測量時刻 fixed occasions</h2>
<p>對於臨牀試驗中固定時刻隨訪收集到的病人數據，理想狀態下應該是一種平衡數據 (balanced data)。也就是在不同時間 <span class="math inline">\(t_i , i = 1, \cdots, n\)</span> 我們成功收集到所有患者的所有數據，所以每層 (名患者) 擁有的時間序列數據的樣本量是相同的 <span class="math inline">\(n_j = n, \forall j\)</span>。</p>
<p>如同分析其他類型的數據一樣，分析縱向數據也要從描述數據開始。如果是平衡數據，描述性分析就很容易，當有缺失值時，分析就變得有些棘手。例如，我們可以計算每個時間點的平均值作爲所有患者的 “平均特質 average profiles”。或者也可以用每個人的時間序列數據對時間做簡單線性回歸模型，從而獲取每個個體的截距和斜率。</p>
<div id="缺失值-missing-data" class="section level3">
<h3><span class="header-section-number">62.1.1</span> 缺失值 Missing data</h3>
<p>當縱向數據中存在一些缺失值，即使你在計算一些簡單的歸納性分析，也要<strong>特別特別特別</strong>地小心。如果不是所有人都有全部測量時間點的數據的話，總體的平均特徵數據分析了也沒有太大的卵用，因爲缺失值導致這樣計算獲得的並不是真實的平均值 (也因爲不同的患者，貢獻了不同時間點的數據，沒辦法平均)。</p>
<p>如果存在缺失值，那麼當且僅當這些缺失值和觀測值 <span class="math inline">\(Y\)</span> 之間沒有關系時，才能認爲這些簡單計算和簡單模型的建立是不帶有偏倚的。如果說，有些缺失值確實是根據觀測數據有選擇性地缺失 (the mechanism driving the selection depends on measured data)，隨機效應模型的建立可以自動化校正這樣的缺失，從而保證估計無偏。</p>
<p>根據觀測數據選擇性地出現缺失值的機制被叫做隨機缺失 (Missing at random, MAR)。</p>
<div id="隨機截距模型-random-intercept-model-1" class="section level4">
<h4><span class="header-section-number">62.1.1.1</span> 隨機截距模型 random intercept model</h4>
<p><strong>復合對稱模型 compound symmetry model</strong>， 是常見的一種用於重復測量數據的模型，它是基於隨機截距模型的一種擴展模型。</p>
<p>當模型中沒有解釋變量時，</p>
<p><span class="math display" id="eq:hier05-1">\[
\begin{equation}
Y_{ij} = \mu_i + u_{0j} + e_{ij}
\end{equation}
\tag{62.1}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(i\)</span> 是測量時刻;</li>
<li><span class="math inline">\(j\)</span> 是實驗的個體;</li>
<li><span class="math inline">\(\mu_i\)</span> 是測量時刻 <span class="math inline">\(i\)</span> 時的平均截距 – 這是一個固定效應。</li>
</ul>
<p>爲了擬合這個模型，我們需要先生成一系列的啞變量用來表示不同的測量時刻:</p>
<p><span class="math display">\[
Y_{ij} = \sum_{h=1}^n\beta_{0h} I_{i = h,j} + u_{0j} + e_{ij}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(I_{i = h,j}\)</span> 是用於表示第 <span class="math inline">\(j\)</span> 名患者的 <span class="math inline">\(i\)</span> 次觀測值，在第 <span class="math inline">\(h\)</span> 次測量時是否被測量到的啞變量。</li>
<li>該模型暗示同一個患者收集到的不同時刻的觀察數據是可以互換的，有相同的協方差
<span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j} , Y_{2j}) &amp; = \text{Cov}(u_{0j} + e_{1j}, u_{0j} + e_{2j}) \\ 
                          &amp; = \sigma^2_{u_{00}}
\end{aligned}
\]</span></li>
<li>該模型還有另一個暗示是，不同患者之間任意時間點的兩個觀察數據之間是相互獨立的
<span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j*}) &amp; = \text{Cov}(u_{0j} + e_{1j}, u_{0j*} + e_{2j*}) \\ 
                          &amp; = 0
\end{aligned}
\]</span></li>
</ul>
<p>所以當沒有缺失值時，數據是固定測量時刻 (fixed occation) 的數據也是是平衡數據，那麼每一個患者 (第二層級數據) 的觀察值可以寫作是一個向量 <span class="math inline">\(\{ \mathbf{Y}_{ij} \}\)</span>，每名患者的觀察值向量的長度都是相同的 <span class="math inline">\(n\)</span>。所以，它們的 <span class="math inline">\(n\times n\)</span> 協方差矩陣就是:</p>
<p><span class="math display">\[
\Omega_y = \left( \begin{array}{cccc} 
 \sigma^2_{u_{00}} + \sigma^2_e &amp; \sigma^2_{u_{00}}  &amp; \cdots &amp; \sigma^2_{u_{00}} \\
 \sigma_{u_{00}}   &amp; \sigma^2_{u_{00}} + \sigma^2_e    &amp; \cdots &amp; \sigma^2_{u_{00}} \\
 \vdots            &amp; \vdots                            &amp; \vdots &amp; \vdots \\
 \sigma^2_{u_{00}} &amp; \sigma^2_{u_{00}}                &amp;  \cdots &amp; \sigma^2_{u_{00}} + \sigma^2_e\\
\end{array} \right)
\]</span></p>
<p>也正是由於觀測值的協方差矩陣是如此地對稱，該模型被命名爲復合對稱模型 compound symmetric model。</p>
<p><strong>Adult height measures 數據</strong></p>
<p>有(閒人)花了數十年時間追蹤隨訪了近2000名女性在 26 歲，36歲，43歲，53歲時的身高。忽略掉可能存在的測量誤差，研究者想知道是否隨着年齡增加，女性的身高會縮水。這些女性在這些年齡時的身高數據總結如下:</p>
<div class="sourceCode" id="cb967"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb967-1" title="1">height &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/height.dta&quot;</span>)</a>
<a class="sourceLine" id="cb967-2" title="2"><span class="kw">summ</span>(height[, <span class="dv">2</span><span class="op">:</span><span class="dv">5</span>])</a></code></pre></div>
<pre><code>## 
## No. of observations = 2187
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 ht26      1758 162.33 162.6   6.36   142.2  180.3 
## 2 ht36      1610 162.26 162.2   6.05   135.2  180   
## 3 ht43      1567 162.28 162.1   5.96   140    180   
## 4 ht53      1462 161.56 161.5   5.96   134.3  179.6</code></pre>
<p>原則上每個女性在所有的時間應該都有身高測量值才對，我們暫且認爲擁有缺失測量值的時間點是完全隨機的。先計算樣本中數據完整部分的女性身高在四個時間點時的方差協方差矩陣:</p>
<div class="sourceCode" id="cb969"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb969-1" title="1"><span class="kw">var</span>(height[, <span class="dv">2</span><span class="op">:</span><span class="dv">5</span>], <span class="dt">use =</span> <span class="st">&quot;complete.obs&quot;</span>)</a></code></pre></div>
<pre><code>##           ht26      ht36      ht43      ht53
## ht26 39.813400 34.758457 34.478981 34.128167
## ht36 34.758457 34.455060 33.360413 33.086680
## ht43 34.478981 33.360413 34.331501 32.948850
## ht53 34.128167 33.086680 32.948850 34.215187</code></pre>
<p>要給這個數據擬合混合對稱模型 (compound symmetry model)，需要先把數據從寬變長，之後爲每個測量身高的時間點生成一個啞變量，然後擬合無截距式的隨機截距模型:</p>
<div class="sourceCode" id="cb971"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb971-1" title="1"><span class="co"># 把數據格式從寬變長</span></a>
<a class="sourceLine" id="cb971-2" title="2">hei_long &lt;-<span class="st"> </span>height <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id, <span class="op">-</span>bw, <span class="op">-</span>mht) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-4" title="4"><span class="st">    </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;Height&quot;</span>, <span class="st">&quot;H_Age&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-5" title="5"><span class="st">      </span><span class="kw">arrange</span>(id, H_Age, bw, mht) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-6" title="6"><span class="st">        </span><span class="kw">spread</span>(Height, value)</a>
<a class="sourceLine" id="cb971-7" title="7"></a>
<a class="sourceLine" id="cb971-8" title="8"><span class="co"># 生成四個年齡時間點數據的啞變量</span></a>
<a class="sourceLine" id="cb971-9" title="9">hei_long &lt;-<span class="st"> </span>hei_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-10" title="10"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Age_1 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">26</span>, <span class="dv">1</span>, <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb971-11" title="11">         <span class="dt">Age_2 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">36</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb971-12" title="12">         <span class="dt">Age_3 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">43</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb971-13" title="13">         <span class="dt">Age_4 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">53</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb971-14" title="14">M_hei &lt;-<span class="st"> </span><span class="kw">lmer</span>(ht <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">3</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">4</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> hei_long, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb971-15" title="15"><span class="kw">summary</span>(M_hei)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: ht ~ 0 + Age_1 + Age_2 + Age_3 + Age_4 + (1 | id)
##    Data: hei_long
## 
## REML criterion at convergence: 30475.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.69990 -0.46089 -0.00475  0.45917  8.26749 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 35.9056  5.9921  
##  Residual              1.9862  1.4093  
## Number of obs: 6397, groups:  id, 1980
## 
## Fixed effects:
##         Estimate Std. Error         df t value  Pr(&gt;|t|)    
## Age_1  162.34141    0.13903 2151.19114  1167.7 &lt; 2.2e-16 ***
## Age_2  162.31738    0.13977 2195.10608  1161.3 &lt; 2.2e-16 ***
## Age_3  162.19431    0.13997 2207.43550  1158.8 &lt; 2.2e-16 ***
## Age_4  161.45320    0.14041 2234.23204  1149.9 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##       Age_1 Age_2 Age_3
## Age_2 0.933            
## Age_3 0.931 0.933      
## Age_4 0.928 0.930 0.931</code></pre>
<div class="sourceCode" id="cb973"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb973-1" title="1"><span class="co"># 檢驗三個年齡點的身高均值是否相同用下面的方法: </span></a>
<a class="sourceLine" id="cb973-2" title="2"><span class="kw">linearHypothesis</span>(M_hei, <span class="kw">c</span>(<span class="st">&quot;Age_1 - Age_2 = 0&quot;</span>, </a>
<a class="sourceLine" id="cb973-3" title="3">                          <span class="st">&quot;Age_1 - Age_3 = 0&quot;</span>, </a>
<a class="sourceLine" id="cb973-4" title="4">                          <span class="st">&quot;Age_1 - Age_4 = 0&quot;</span>))</a></code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## Age_1 - Age_2 = 0
## Age_1 - Age_3 = 0
## Age_1 - Age_4 = 0
## 
## Model 1: restricted model
## Model 2: ht ~ 0 + Age_1 + Age_2 + Age_3 + Age_4 + (1 | id)
## 
##   Df   Chisq Pr(&gt;Chisq)    
## 1                          
## 2  3 374.564 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>所以，用這個模型 (符合對稱模型 compound symmetry model)，其實我是在告訴 R 軟件說，我認爲，這個數據中的女性四次測量的身高之間的方差協方差矩陣是這樣紙的 (因爲 <span class="math inline">\(5.992^2 = 35.91; 1.409^2 = 1.99\)</span>):</p>
<p><span class="math display">\[
\Omega_y = \left( \begin{array}{cccc} 
 37.90 &amp; 35.91  &amp; 35.91 &amp; 35.91 \\
 35.91 &amp; 37.90  &amp; 35.91 &amp; 35.91 \\
 35.91 &amp; 35.91  &amp; 37.90 &amp; 35.91 \\
 35.91 &amp; 35.91  &amp; 35.91 &amp; 37.90\\
\end{array} \right)
\]</span></p>
<p>分析這個模型第二層階級殘差，和第一層階級殘差可以計算並做圖 <a href="10-Hierarchical-models.html#fig:5-level2-res">62.1</a> <a href="10-Hierarchical-models.html#fig:5-level1-res">62.2</a> 如下:</p>
<div class="sourceCode" id="cb975"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb975-1" title="1"><span class="co"># refit the model with lme</span></a>
<a class="sourceLine" id="cb975-2" title="2">M_hei &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> ht <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">3</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">4</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, </a>
<a class="sourceLine" id="cb975-3" title="3">             <span class="dt">data =</span> hei_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action=</span>na.omit)</a>
<a class="sourceLine" id="cb975-4" title="4"><span class="co"># individual level standardized residuals</span></a>
<a class="sourceLine" id="cb975-5" title="5">ehat_st &lt;-<span class="st"> </span><span class="kw">residuals</span>(M_hei, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>, <span class="dt">level =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb975-6" title="6"></a>
<a class="sourceLine" id="cb975-7" title="7"><span class="co"># extract the EB uhat (level 2 EB residual)</span></a>
<a class="sourceLine" id="cb975-8" title="8">uhat_eb &lt;-<span class="st"> </span><span class="kw">ranef</span>(M_hei)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span></a>
<a class="sourceLine" id="cb975-9" title="9"></a>
<a class="sourceLine" id="cb975-10" title="10"><span class="co"># standardized level 2 residuals</span></a>
<a class="sourceLine" id="cb975-11" title="11"><span class="co">### count number of measures for each women</span></a>
<a class="sourceLine" id="cb975-12" title="12">Nmeas &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb975-13" title="13"><span class="co">### shrinkage factor </span></a>
<a class="sourceLine" id="cb975-14" title="14">R =<span class="st"> </span><span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">1.409</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>Nmeas)</a>
<a class="sourceLine" id="cb975-15" title="15"><span class="co">### use shrinkage factor calculate variance of uhat_eb</span></a>
<a class="sourceLine" id="cb975-16" title="16">var_eb &lt;-<span class="st"> </span>R <span class="op">*</span><span class="st"> </span><span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb975-17" title="17"><span class="co">### standardize uhat</span></a>
<a class="sourceLine" id="cb975-18" title="18">uhat_st &lt;-<span class="st"> </span>uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:5-level2-res"></span>
<img src="bookdown_files/figure-html/5-level2-res-1.png" alt="Standardized cluster level residuals (intercept) from the compound symmetry model" width="80%" />
<p class="caption">
圖 62.1: Standardized cluster level residuals (intercept) from the compound symmetry model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:5-level1-res"></span>
<img src="bookdown_files/figure-html/5-level1-res-1.png" alt="Standardized elementary level residuals from the compound symmetry model" width="80%" />
<p class="caption">
圖 62.2: Standardized elementary level residuals from the compound symmetry model
</p>
</div>
<p>混合對稱模型的前提假設實在是太強了 (它假定個體內的方差保持不變，且個體間的協方差也保持不變)。你我都清楚，當考慮了時間以後，同一個體在時間上比較接近的點測量之間會更相似，也更相關。</p>
</div>
<div id="隨機參數模型-random-intercept-and-slope-model" class="section level4">
<h4><span class="header-section-number">62.1.1.2</span> 隨機參數模型 random intercept and slope model</h4>
<p>實際上有多種方法可以放鬆混合對稱模型對方差和協方差的約束性前提，其中之一是在隨機截距模型中允許有隨機斜率成分。</p>
<p>使用隨機參數模型擬合縱向數據時的簡單模型如下:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})t_i +e_{ij}
\]</span></p>
<p>前一章討論過 (滾回 <a href="10-Hierarchical-models.html#random-var">61.5</a>)，這裏隨機參數模型的解釋變量是時間 <span class="math inline">\(t_i\)</span>，導致的結果之一是觀測值的方差其實是隨着時間變化而變化的 (拋物線關系):</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(Y_{ij}) &amp; = \text{Cov}(u_{0j} + u_{ij}t_i + e_{ij}, u_{0j} + u_{ij}t_i + e_{ij})  \\ 
                   &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_i^2 + 2t_i\sigma_{u_{01}} + \sigma^2_e
\end{aligned}
\]</span></p>
<p>同時，同一患者不同時間測量的觀測值之間的協方差是:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_1 + e_{1j}, u_{0j} + u_{2j}t_2 + e_{2j}) \\ 
&amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1t_2 + \sigma_{u_{01}}(t_1 + t_2)
\end{aligned}
\]</span></p>
<p>不同患者任意測量時刻之間的協方差是:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j*}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_1 + e_{1j}, u_{0j*} + u_{2j*}t_2 + e_{2j*}) \\ 
&amp; = 0
\end{aligned}
\]</span></p>
<p><strong>Adult height measures 數據</strong></p>
<p>利用上面的理論，來對身高數據擬合另一個混合效應模型:</p>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb976-1" title="1"><span class="co"># 對年齡中心化到以 26 歲爲起點</span></a>
<a class="sourceLine" id="cb976-2" title="2">hei_long &lt;-<span class="st"> </span>hei_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb976-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age =</span> <span class="kw">as.numeric</span>(H_Age) <span class="op">-</span><span class="st"> </span><span class="dv">26</span>)</a>
<a class="sourceLine" id="cb976-4" title="4">M_hei_ran &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> ht <span class="op">~</span><span class="st"> </span>age, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> hei_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb976-5" title="5"><span class="co">#M_hei_ran &lt;- lmer(ht ~ age + (age | id), data = hei_long, REML = TRUE)</span></a>
<a class="sourceLine" id="cb976-6" title="6"><span class="kw">summary</span>(M_hei_ran)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: hei_long 
##         AIC       BIC     logLik
##   30382.427 30423.006 -15185.213
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev      Corr  
## (Intercept) 6.158844448 (Intr)
## age         0.059929578 -0.281
## Residual    1.259210714       
## 
## Fixed effects: ht ~ age 
##                 Value   Std.Error   DF    t-value p-value
## (Intercept) 162.49616 0.141129788 4416 1151.39521       0
## age          -0.03158 0.002273653 4416  -13.88951       0
##  Correlation: 
##     (Intr)
## age -0.279
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -3.9386996996 -0.4542383385 -0.0066047392  0.4297466638  5.5051618893 
## 
## Number of Observations: 6397
## Number of Groups: 1980</code></pre>
<p>這個混合效應模型同時包含了隨機截距和隨機斜率兩個部分。你可以用 LRT 比較它和一個只有隨機截距的模型哪個更好，但是我們沒有辦法比較它和混合對稱模型哪個更優於擬合這個數據 (因爲他們的固定效應部分不同，在 REML 方法下實際二者擬合的數據是不同的)。這個隨機系數模型和前一個混合對稱模型都給出了身高隨着年齡增加而減少的相同結論。不同的是，隨機系數模型把同一對象內不同時間觀測值之間的等協方差的約束條件給放開了，因爲用腳趾頭想也知道<strong>同一個人不同時間測量的數據之間的協方差會隨着時間跨度不同而發生改變</strong>。</p>
<p>根據隨機系數模型給出的報告，計算模型估計的觀測值 (身高的4個時間點) 的方差協方差矩陣:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\text{Cov}}(Y_{1j}, Y_{2j}) &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1t_2 +\sigma_{u_{01}} (t_1 + t_2) \\
 &amp; = 6.1588^2 + 0.0599^2t_1t_2 + (-0.28)\times6.1588\times0.0599 (t_1 + t_2)\\ 
 &amp; = 37.93 + 0.004\times t_2 \times t_2 - 0.104 \times(t_1 + t_2) \\
\hat{\text{Var}} (Y_1j) &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1^2 - 2\sigma_{u_{01}}t_1 + \sigma_e^2 \\ 
&amp; = 37.93 + 0.004 \times t_1^2 - 0.104\times2\times t_1 + 1.59
\end{aligned}
\]</span></p>
<p>所以，當 <span class="math inline">\(t_1 = 0, t_2 = 10, t_3 = 17, t_4 = 27\)</span> 時，</p>
<p><span class="math display">\[
\mathbf{\hat{\Sigma}_u} =  \left( \begin{array}{cccc} 
 39.52 &amp; 36.90  &amp; 36.17 &amp; 35.14 \\
 36.90 &amp; 37.81  &amp; 35.75 &amp; 35.07 \\
 36.17 &amp; 35.75  &amp; 37.03 &amp; 35.03 \\
 35.14 &amp; 35.07  &amp; 35.03 &amp; 36.54 \\
\end{array} \right)
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:5-level2-ress"></span>
<img src="bookdown_files/figure-html/5-level2-ress-1.png" alt="UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.3: UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:5-level1-res0"></span>
<img src="bookdown_files/figure-html/5-level1-res0-1.png" alt="Standardized elementary level residuals from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.4: Standardized elementary level residuals from the random intercept and slope model
</p>
</div>
</div>
</div>
</div>
<div id="不固定測量時刻-variable-occasions" class="section level2">
<h2><span class="header-section-number">62.2</span> 不固定測量時刻 variable occasions</h2>
<p>當重復收集的數據不是平衡數據時，意味着不同的人數據的收集時間點不一樣，我們就無法像前面那樣用協方差矩陣的方式來描述不同人不同時間點之間測量值可能存在的相關性，也沒有辦法給每個時間點所有人的數據做平均值作爲全部人的平均特質。</p>
<p>但是我們可以把不固定測量時刻的不平衡數據看作是受缺失值數據影響的平衡數據 (unbalanced data can be thought of as balanced data affected by missingness)。所以需要特別小心謹慎，因爲用線性混合效應模型擬合這樣的數據，其實是在含蓄地假設那些應該出現但是沒有出現的測量值的缺失是隨機的。</p>
<p><strong>Asian growth data 實例</strong></p>
<p>在本部分開頭的章節介紹過，這是一個收集了亞洲兒童在 6 周，8 個月，12 個月，和 27 個月大時的體重數據。</p>
<div class="figure" style="text-align: center"><span id="fig:Hier05-07"></span>
<img src="bookdown_files/figure-html/Hier05-07-1.png" alt="Growth profiles of boys and girls in the Asian growth data" width="80%" />
<p class="caption">
圖 62.5: Growth profiles of boys and girls in the Asian growth data
</p>
</div>
<p>如圖 <a href="10-Hierarchical-models.html#fig:Hier05-07">62.5</a> 所示，觀察男孩女孩的體重隨着時間的變化，似乎暗示男孩子體重增加的速度較高，且男孩中體重增加的差異 (方差) 似乎也較女孩子的體重增加曲線來得大。另外，體重和年齡的關系並不是線性的，而且，這些數據中有缺失值。</p>
<p><strong>隨機截距模型</strong></p>
<p>第一個想到的合適模型應該包括一個隨機截距，一個固定效應的線性和拋物線性的年齡項，還有最後一個啞變量用以區分男孩和女孩:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + \beta_1t_{ij} + \beta_2 t_{ij}^2 + \beta_3 \text{girl}_j + e_{ij}
\]</span></p>
<p>在 R 裏擬合這個模型:</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb978-1" title="1">growth &lt;-<span class="st"> </span>growth <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb978-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age2 =</span> age<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb978-3" title="3"></a>
<a class="sourceLine" id="cb978-4" title="4">M_growth &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb978-5" title="5"><span class="kw">summary</span>(M_growth)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   565.93442 585.54157 -276.96721
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)   Residual
## StdDev:  0.85945071 0.73940625
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value  Std.Error  DF     t-value p-value
## (Intercept)  3.7992533 0.21210411 128  17.9122095  0.0000
## age          7.8173952 0.29051698 128  26.9085652  0.0000
## age2        -1.7054785 0.10891077 128 -15.6594104  0.0000
## genderGirls -0.7341374 0.23590992  66  -3.1119397  0.0027
##  Correlation: 
##             (Intr) age    age2  
## age         -0.579              
## age2         0.509 -0.970       
## genderGirls -0.549 -0.009  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.320321237 -0.444855166  0.024075779  0.446113187  3.991809168 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb980"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb980-1" title="1"><span class="co">## 由於樣本量較小，這裏如果使用極大似然法估計 ML，結果就和 REML 估計的隨機效應的方差部分不太相同</span></a>
<a class="sourceLine" id="cb980-2" title="2">M_growthml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb980-3" title="3"><span class="kw">summary</span>(M_growthml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: growth 
##         AIC       BIC     logLik
##   556.32603 576.05563 -272.16301
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)   Residual
## StdDev:  0.84433851 0.73390172
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value  Std.Error  DF     t-value p-value
## (Intercept)  3.7997442 0.21160249 128  17.9569922  0.0000
## age          7.8161949 0.29116479 128  26.8445748  0.0000
## age2        -1.7050759 0.10915202 128 -15.6211122  0.0000
## genderGirls -0.7340920 0.23465616  66  -3.1283729  0.0026
##  Correlation: 
##             (Intr) age    age2  
## age         -0.582              
## age2         0.511 -0.970       
## genderGirls -0.548 -0.009  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.340993892 -0.446771161  0.028578899  0.450565995  4.026706851 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<p><strong>隨機截距和斜率模型</strong></p>
<p>此時我們再來用相同的數據擬合混合效應模型，現在允許線性年齡的斜率有隨機變化:</p>
<div class="sourceCode" id="cb982"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb982-1" title="1">M_growth_mix &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb982-2" title="2"><span class="kw">summary</span>(M_growth_mix)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC      BIC     logLik
##   533.95003 560.0929 -258.97502
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 0.61487769 (Intr)
## age         0.51776878 0.135 
## Residual    0.57411956       
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.7954977 0.168145176 128  22.572742  0.0000
## age          7.6984362 0.239853311 128  32.096435  0.0000
## age2        -1.6577339 0.088594491 128 -18.711478  0.0000
## genderGirls -0.5983844 0.199974765  66  -2.992300  0.0039
##  Correlation: 
##             (Intr) age    age2  
## age         -0.543              
## age2         0.502 -0.929       
## genderGirls -0.588 -0.008  0.007
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.041884180 -0.442600563 -0.032412546  0.419399620  2.669681965 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<p>這裏可以看到隨機殘差 (residuals) 的標準差 (<code>StdDev</code>) 部分在後者(混合系數模型)中明顯變小了 <span class="math inline">\((0.74\rightarrow 0.54)\)</span>。另外，第二層級殘差和第一層級殘差 (未標準化) 如圖 <a href="10-Hierarchical-models.html#fig:hier05-10">62.6</a> 和 <a href="10-Hierarchical-models.html#fig:hier05-11">62.7</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:hier05-10"></span>
<img src="bookdown_files/figure-html/hier05-10-1.png" alt="UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.6: UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:hier05-11"></span>
<img src="bookdown_files/figure-html/hier05-11-1.png" alt="Standardized elementary level residuals from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.7: Standardized elementary level residuals from the random intercept and slope model
</p>
</div>
</div>
<div id="預測軌跡-predicting-trajectories" class="section level2">
<h2><span class="header-section-number">62.3</span> 預測軌跡 predicting trajectories</h2>
<p>比較只有隨機截距模型，和隨機系數模型給出的擬合曲線是否有差異 如圖<a href="10-Hierarchical-models.html#fig:hier05-12">62.8</a>，其實差異十分微小。可以用下面的 R 代碼:</p>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb984-1" title="1">growth<span class="op">$</span>traj2 &lt;-<span class="st"> </span><span class="kw">fitted</span>(M_growth_mix) </a>
<a class="sourceLine" id="cb984-2" title="2">growth<span class="op">$</span>traj1 &lt;-<span class="st"> </span><span class="kw">fitted</span>(M_growth) </a>
<a class="sourceLine" id="cb984-3" title="3"></a>
<a class="sourceLine" id="cb984-4" title="4">G &lt;-<span class="st"> </span><span class="kw">ggplot</span>(growth[growth<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">258</span>,<span class="dv">1141</span>,<span class="dv">3148</span>,<span class="dv">287</span>),], <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">19</span>, <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-5" title="5"><span class="st"> </span><span class="co"># geom_line(aes(y = traj1)) + </span></a>
<a class="sourceLine" id="cb984-6" title="6"><span class="co">#  geom_line(aes(y = traj2), linetype = 2) +</span></a>
<a class="sourceLine" id="cb984-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="kw">aes</span>(<span class="dt">y =</span> traj1), <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), <span class="dt">se =</span> F, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-8" title="8"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="kw">aes</span>(<span class="dt">y =</span> traj2), <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), <span class="dt">se =</span> F)  <span class="op">+</span></a>
<a class="sourceLine" id="cb984-9" title="9"><span class="st">   </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb984-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb984-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb984-12" title="12"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))</a>
<a class="sourceLine" id="cb984-13" title="13"></a>
<a class="sourceLine" id="cb984-14" title="14"></a>
<a class="sourceLine" id="cb984-15" title="15">G <span class="op">+</span><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>id, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-16" title="16"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">face =</span> <span class="st">&quot;bold&quot;</span>, <span class="dt">size =</span> <span class="kw">rel</span>(<span class="fl">1.5</span>)))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:hier05-12"></span>
<img src="bookdown_files/figure-html/hier05-12-1.png" alt="Observed weight and predicted growth profiles of four babies in the Asian growth data" width="80%" />
<p class="caption">
圖 62.8: Observed weight and predicted growth profiles of four babies in the Asian growth data
</p>
</div>
</div>
<div id="practical-05-hier" class="section level2">
<h2><span class="header-section-number">62.4</span> Practical 05-Hier</h2>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-2" class="section level1">
<h1><span class="header-section-number">第 63 章</span> 縱向研究數據 longitudinal data 2</h1>
<p>本章沒有代碼，學會如何用矩陣標記法寫下你的多元混合效應模型。</p>
<div id="邊際結構-marginal-structures" class="section level2">
<h2><span class="header-section-number">63.1</span> 邊際結構 marginal structures</h2>
<p>至此，我們接觸過的各種混合效應模型其實代表的是數據不同的邊際結構關系 (marginal relations)。</p>
<div id="隨機截距模型" class="section level3">
<h3><span class="header-section-number">63.1.1</span> 隨機截距模型</h3>
<p>縱向數據中，數據可能是平衡或不平衡數據，簡單的隨機截距模型可以標記如下:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + \beta_1 t_{ij} + e_{ij}
\]</span></p>
<p>這個模型隱含着如下的條件關系 (conditional relation):</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} | t_{ij}, u_{0j} &amp; \sim N(\beta_0 + \beta_1t_{ij} + u_{0j}, \sigma^2_e)\\ 
 u_{0j}|t_{ij} &amp; \sim N(0, \sigma^2_u) \\
 \text{Var}(Y_{ij} | t_{ij}, u_{0j})  &amp; = \sigma^2_e
\end{aligned}
\]</span></p>
<p>也就是說，觀測值 <span class="math inline">\(Y_{ij}\)</span> 以時間 <span class="math inline">\(t\)</span>，和隨機截距 <span class="math inline">\(u_0\)</span> 爲條件的方差，只取決於 <span class="math inline">\(\sigma^2_e\)</span>。所以，屬於同一層 (同一患者不同測量時間) 的測量值，以該層 (患者) 的截距爲條件 (conditional on <span class="math inline">\(u_j\)</span>) 的協方差是 <span class="math inline">\(\text{Cov} (Y_{ij}, Y_{i*j}|t_{ij}, t_{i*j}, u_j) = 0\)</span>。</p>
<p><span class="math inline">\(Y_{ij}\)</span> 針對 <span class="math inline">\(u_j\)</span> 的邊際期望 (marginal espectation with respect to <span class="math inline">\(u_j\)</span>):</p>
<p><span class="math display">\[
E(Y_{ij}|t_{ij}) = \beta_0 + \beta_1 t_{ij}
\]</span></p>
<p>其方差爲 <span class="math inline">\(\text{Var}(Y_{ij}|t_{ij}) = \sigma^2_u + \sigma^2_e\)</span>，同一層 (同一患者) 的兩個不同時刻測量值之間的邊際協方差就是 <span class="math inline">\(\text{Cov}(Y_{ij}, Y_{i*j}|t_{ij},t_{i*j}) = \sigma^2_u\)</span>。</p>
</div>
<div id="隨機系數模型" class="section level3">
<h3><span class="header-section-number">63.1.2</span> 隨機系數模型</h3>
<p>模型的數學標記是</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})t_{ij} + e_{ij}
\]</span></p>
<p>等同於</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + \beta_1t_{ij}) + (u_{0j} + u_{1j}t_{ij}) + e_{ij}
\]</span></p>
<p>其<strong>條件關系</strong>是</p>
<p><span class="math display">\[
Y_{ij}|t_{ij},u_{0j},u_{1j} \sim N( \beta_0 + \beta_1t_{ij} + u_{0j} + u_{1j}t_{ij}, \sigma^2_e)
\]</span></p>
<p>其中， <span class="math inline">\(\mathbf{u}_j|t_{ij} \sim N(0, \mathbf{\Sigma}_u)\)</span>，且</p>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} &amp; \sigma_{u_{01}} \\
              \sigma_{u_{01}}   &amp; \sigma^2_{u_{11}} \\
              \end{array} \right)
\\
\text{Cov} (Y_{ij}, Y_{i*j}|t_{ij}, t_{i*j}, u_{oj}, u_{1j}) = 0
\]</span></p>
<p>其所指的<span class="math inline">\(Y_{ij}\)</span>的邊際分布:</p>
<p><span class="math display">\[
\begin{aligned}
E(Y_{ij}|t_{ij})   &amp; = \beta_0 + \beta_1t_{ij} \\
\text{Var}(Y_{ij}) &amp; = \sigma^2_{u_{00}}  +2\sigma_{u_{01}}t_{ij} + \sigma^2_{u_{11}}t_{ij}^2 + \sigma^2_e \\
\text{Cov}(Y_{ij}, Y_{i*j}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_{ij} + e_{ij}, u_{0j} + u_{1j}t_{i*j} + e_{i*j}) \\
                   &amp; = \sigma^2_{u_{00}} + \sigma_{u_{01}}(t_{ij} + t_{i*j}) + \sigma^2_{u_{11}}t_{ij}t_{i*j} \text{ (for } i \neq i*) \\
\text{Cov}(Y_{ij}, Y_{i*j*}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_{ij} + e_{ij}, u_{0j*} + u_{1j*}t_{i*j*} + e_{i*j*}) \\ 
&amp; = 0 \text{ (for } j \neq j*) 
\end{aligned}
\]</span></p>
<p>也就是說<strong>同一層 (同一患者) 的不同測量值之間的協方差不爲零，是時間的函數</strong>。</p>
</div>
</div>
<div id="矩陣記法" class="section level2">
<h2><span class="header-section-number">63.2</span> 矩陣記法</h2>
<p>如果數據本身是<strong>平衡數據</strong>，可以用如下的矩陣標記混合效應模型，</p>
<ul>
<li><span class="math inline">\(j\)</span> 是每個患者 (第二層級)，<span class="math inline">\(\mathbf{Y}_j, \mathbf{e}_j\)</span> 向量被定義爲:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_j &amp; =  \left( \begin{array}{c}
Y_{1j} \\
Y_{2j} \\
\cdots \\
\cdots \\
Y_{nj}
\end{array}
\right) \\
\mathbf{e}_j &amp; =  \left( \begin{array}{c}
e_{1j} \\
e_{2j} \\
\cdots \\
\cdots \\
e_{nj}
\end{array}
\right) \\
\end{aligned}
\]</span></p>
<p>用三次測量時間 <span class="math inline">\(t_1, t_2, t_3\)</span> (以簡便標記) 來繼續接下來的推導，定義矩陣 <span class="math inline">\(\mathbf{T}, \mathbf{\beta}, \mathbf{u}_j\)</span>:</p>
<p><span class="math display">\[
\mathbf{T} = \left(\begin{array}{c}
1 &amp; t_1 \\
1 &amp; t_2 \\
1 &amp; t_3 
\end{array}
\right) \\
\mathbf{\beta} = \left( \begin{array}{c}
\beta_0 \\
\beta_1 
\end{array}
\right) \\
\mathbf{u}_j = \left(\begin{array}{c}
u_{0j} \\
u_{1j} 
\end{array}
\right)
\]</span></p>
<p>如此經過利用定義好的向量，我們就可以把模型用矩陣標記來記錄，從無窮無盡的下標中解放出來:</p>
<p><span class="math display">\[
\mathbf{Y = T\beta + Tu + e} \\ 
\text{Where } \mathbf{u} \sim N(0, \mathbf{\Sigma}_u) \\ 
              \mathbf{e} \sim N(0, \sigma^2_e\mathbf{I})
\]</span></p>
<p>那麼</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Y}) = \mathbf{T\Sigma}_u\mathbf{T}^T + \sigma^2_e \mathbf{I}
\]</span></p>
</div>
<div id="混合效應模型的一般化公式" class="section level2">
<h2><span class="header-section-number">63.3</span> 混合效應模型的一般化公式</h2>
<p>前面的例子用的雖然是時間做解釋變量 (縱向數據)，但是也可以推廣到一般的混合效應模型:</p>
<p><span class="math display">\[
\mathbf{Y = T\beta + Zu + e}
\]</span></p>
<p>其中 <span class="math inline">\(\mathbf{Z}\)</span> 是類似 <span class="math inline">\(\mathbf{T}\)</span> 的共變量矩陣。類似地，<span class="math inline">\(\mathbf{Y}\)</span> 的方差是:</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Y}) = \mathbf{Z\Sigma}_u\mathbf{Z}^T + \mathbf{\Sigma}_e \\
\mathbf{Y} \sim N(\mathbf{T\beta}, \mathbf{Z\Sigma}_u\mathbf{Z}^T + \mathbf{\Sigma}_e )
\]</span></p>
<p>這就是一個多元線性混合效應回歸模型，大多數情況下，<span class="math inline">\(\mathbf{\Sigma}_e = \sigma^2_e\mathbf{I}\)</span>。</p>
</div>
<div id="其他可選擇的方差協方差矩陣特徵" class="section level2">
<h2><span class="header-section-number">63.4</span> 其他可選擇的方差協方差矩陣特徵</h2>
<p>學會了上面的矩陣標記以後，就應該了解在這樣的多元混合效應模型中，對於層內方差，協方差矩陣的 <span class="math inline">\(\mathbf{\Sigma_u}\)</span> 結構初步假設是相當重要的。目前爲止我們接觸過的模型的方差協方差矩陣結構列舉如下 (爲了簡便標記都用<span class="math inline">\(3\times3\)</span> 的矩陣來表示):</p>
<ul>
<li>復合對稱結構 (compound symmetry structure - compound symmetry model) 又名爲可交換結構 (exchangeable structure)</li>
</ul>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u} + \sigma^2_e &amp; \sigma^2_{u}             &amp;  \sigma^2_{u} \\
              \sigma^2_{u}              &amp; \sigma^2_{u} + \sigma^2_e&amp; \sigma^2_{u}  \\
              \sigma^2_{u}              &amp; \sigma^2_{u} &amp; \sigma^2_{u} + \sigma^2_e \\
              \end{array} \right)
\]</span></p>
<ul>
<li>隨機系數結構 random coefficient (RC) structure</li>
</ul>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} + \sigma^2_e       &amp; \sigma^2_{u_{00}} + \sigma_{u_{01}} &amp;  \sigma^2_{u_{00}} + 2\sigma_{u_{01}} \\
              \sigma^2_{u_{00}} + \sigma_{u_{01}}  &amp; \sigma^2_{u_{00}} + 2\sigma_{u_{01}} + \sigma^2_{u_{11}} + \sigma^2_e&amp; \sigma^2_{u_{00}} + 3\sigma_{u_{01}} + 2\sigma^2_{u_{11}}  \\
              \sigma^2_{u_{00}} + 2\sigma_{u_{01}} &amp; \sigma^2_{u_{00}} + 3\sigma_{u_{01}} + 2\sigma^2_{u_{11}} &amp; \sigma^2_{u_{00}} + 4\sigma_{u_{01}} + 4\sigma^2_{u_{11}}+\sigma^2_e \\
              \end{array} \right)
\]</span></p>
<p>除了這兩個結構以外其他常見方差寫方差結構還有:</p>
<ul>
<li>自回歸結構 (autoregressive structure):</li>
</ul>
<p><span class="math display">\[
\frac{\phi}{1-\alpha^2} \left(\begin{array}{ccc}
1 &amp; \alpha &amp; \alpha^2 \\
\alpha &amp; 1  &amp; \alpha \\
\alpha^2 &amp; \alpha  &amp; 1
\end{array}
\right)
\]</span></p>
<ul>
<li>無固定結構 (unstructure):</li>
</ul>
<p><span class="math display">\[
\left(\begin{array}{ccc}
\sigma_{11} &amp; \sigma_{12}  &amp;\sigma_{13} \\
\sigma_{21} &amp; \sigma_{22}  &amp;\sigma_{23} \\
\sigma_{31} &amp; \sigma_{32}  &amp;\sigma_{33}
\end{array}
\right)
\]</span></p>
<p>最後不要忘記了還有完全獨立結構 (不需要任何復雜模型或校正其數據間的依賴性):</p>
<p><span class="math display">\[
\sigma^2\left(\begin{array}{ccc}
1 &amp; 0  &amp; 0 \\
0 &amp; 1  &amp; 0 \\
0 &amp; 0  &amp; 1
\end{array}
\right)
\]</span></p>
</div>
<div id="其他要點評論" class="section level2">
<h2><span class="header-section-number">63.5</span> 其他要點評論</h2>
<ul>
<li><p>各種結構模型之間的相互比較</p>
<ul>
<li>似然比檢驗法 the likelihood ratio test (LRT) <br> 前提是模型的固定結構不發生改變，兩個嵌套式模型之間的比較是可以使用死然比檢驗的。缺點是統計學效能可能不太理想 (low power)</li>
<li>模型的比較指標 information criteria <br> 就算是同一個數據，如果不同的協方差結構矩陣模型的固定效應部分也不同，似然比檢驗也不使用，這時候應該求助於赤池信息量 (Akaike’s Information Criterion, AIC)，或者貝葉斯信息量 (Bayesian Criterion, BIC) 的比較。這兩個信息量都是使用的模型的似然減去相應模型的參數數量作爲評判標準。差別是 BIC 對參數的調整更加大些。但是，沒人可以保證這些信息會永遠相互認證，他們可能出現互相矛盾，也沒人可以保證使用這些信息的比較可以證明你的模型是“最佳”模型。</li>
</ul></li>
</ul>
</div>
<div id="不平衡數據" class="section level2">
<h2><span class="header-section-number">63.6</span> 不平衡數據</h2>
<ul>
<li>有缺失值的數據，我們無法使用已知的協方差結構矩陣;</li>
<li>隨機效應模型，隨機系數模型可以用於不平衡數據，所以即使有缺失值，我們可以從混合效應模型的結果來推測數據暗示我們數據中存在着怎樣的協方差結構;</li>
</ul>
</div>
<div id="practical-06-hier" class="section level2">
<h2><span class="header-section-number">63.7</span> Practical 06-Hier</h2>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-3" class="section level1">
<h1><span class="header-section-number">第 64 章</span> 縱向研究數據 longitudinal data 3</h1>
<div id="第一層級的異質性-level-1-heterogeneity" class="section level2">
<h2><span class="header-section-number">64.1</span> 第一層級的異質性 level 1 heterogeneity</h2>
<p>目前爲止，我們使用討論過的模型，其實還默認另一個前提條件: 第一層級和第二層級的隨機誤差的方差是固定不變的 (level 1 and level 2 error variance are constant)。但是實際上我們可以把這個條件放寬，讓模型允許第一層級隨機誤差的方差根據某個解釋變量而不同，使得模型更加接近數據，這種模型被命名爲 <strong>復雜第一層級方差模型 (complex level 1 variation)</strong>。下面繼續使用 Asian growth data 來做說明。該數據測量了幾百名亞洲兒童在0-3歲之間幾個時間點的體重。現在我們來允許其第一層級 (每一個兒童在不同時間點測量的體重) 誤差方差隨着性別的不同而變化: <span class="math inline">\(\sigma_e = f(\text{gender})\)</span>。這裏的方程爲了防止標準差變成負的而使用對數函數:</p>
<p><span class="math display">\[
\text{log} (\sigma_e) = \delta_1I_{\text{gender = boy}} + \delta_2I_{\text{gender=girl}}
\]</span></p>
<p>這個加入了第一層級方差隨機性的模型在 R 裏可以這樣擬合:</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb985-1" title="1">M_growth_l1 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">weights =</span> <span class="kw">varIdent</span>(<span class="dt">form=</span><span class="op">~</span><span class="dv">1</span><span class="op">|</span>gender), <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb985-2" title="2"><span class="kw">summary</span>(M_growth_l1)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   533.06033 562.47105 -257.53016
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 0.64492252 (Intr)
## age         0.49336369 0.129 
## Residual    0.64221188       
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | gender 
##  Parameter estimates:
##       Boys      Girls 
## 1.00000000 0.77212879 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.8294125 0.175581146 128  21.809930  0.0000
## age          7.6297282 0.234375558 128  32.553429  0.0000
## age2        -1.6350689 0.086535221 128 -18.894837  0.0000
## genderGirls -0.6043805 0.204516567  66  -2.955166  0.0043
##  Correlation: 
##             (Intr) age    age2  
## age         -0.523              
## age2         0.471 -0.930       
## genderGirls -0.630  0.011  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -1.972411175 -0.451503129 -0.063192138  0.468697082  2.959946133 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb987"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb987-1" title="1"><span class="co"># 和之間默認男女兒童的誤差方差相等時的模型做比較</span></a>
<a class="sourceLine" id="cb987-2" title="2"><span class="co"># 沒有顯著差異 (p = 0.09)</span></a>
<a class="sourceLine" id="cb987-3" title="3"><span class="kw">anova</span>(M_growth_l1, M_growth_mix)</a></code></pre></div>
<pre><code>##              Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M_growth_l1      1  9 533.06033 562.47105 -257.53017                         
## M_growth_mix     2  8 533.95003 560.09290 -258.97501 1 vs 2 2.8897013  0.0891</code></pre>
</div>
<div id="第二層級異質性-level-2-heterogeneity" class="section level2">
<h2><span class="header-section-number">64.2</span> 第二層級異質性 level 2 heterogeneity</h2>
<p>我們還可以在模型中允許第二層級的結構不一樣，這等同於認爲這是一個三個層級的模型，其中第二層級分裂成男孩和女孩。</p>
<div class="sourceCode" id="cb989"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb989-1" title="1">M_growth_l2 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, </a>
<a class="sourceLine" id="cb989-2" title="2">                   <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age<span class="op">*</span>gender <span class="op">|</span><span class="st"> </span>id,</a>
<a class="sourceLine" id="cb989-3" title="3">                   <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb989-4" title="4"><span class="kw">summary</span>(M_growth_l2)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   539.92465 588.94252 -254.96233
## 
## Random effects:
##  Formula: ~age * gender | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##                 StdDev     Corr                
## (Intercept)     0.55670427 (Intr) age    gndrGr
## age             0.69451364  0.037              
## genderGirls     0.85251527 -0.550 -0.002       
## age:genderGirls 0.72515659 -0.095 -0.948  0.130
## Residual        0.56947533                     
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.8204364 0.160115147 128  23.860556  0.0000
## age          7.6149745 0.235176590 128  32.379815  0.0000
## age2        -1.6464243 0.087451604 128 -18.826691  0.0000
## genderGirls -0.6088237 0.203186658  66  -2.996376  0.0038
##  Correlation: 
##             (Intr) age    age2  
## age         -0.543              
## age2         0.520 -0.945       
## genderGirls -0.531 -0.048  0.011
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -2.0240475942 -0.4399956901 -0.0095445889  0.4564973181  2.7439585111 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb991-1" title="1">growth &lt;-<span class="st"> </span>growth <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb991-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boy =</span> <span class="kw">as.numeric</span>(gender <span class="op">==</span><span class="st"> &quot;Boys&quot;</span>), </a>
<a class="sourceLine" id="cb991-3" title="3">         <span class="dt">girl =</span> <span class="kw">as.numeric</span>(gender <span class="op">==</span><span class="st"> &quot;Girls&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb991-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age_boy =</span> age<span class="op">*</span>boy, </a>
<a class="sourceLine" id="cb991-5" title="5">         <span class="dt">age_girl =</span> age<span class="op">*</span>girl)         </a>
<a class="sourceLine" id="cb991-6" title="6"></a>
<a class="sourceLine" id="cb991-7" title="7"><span class="co">#M &lt;- lmer(weight ~ age + age2 + girl + (age_boy |id) + (age_girl| id), data = growth, REML = TRUE)</span></a>
<a class="sourceLine" id="cb991-8" title="8"></a>
<a class="sourceLine" id="cb991-9" title="9"><span class="co">#growth &lt;- growth %&gt;%</span></a>
<a class="sourceLine" id="cb991-10" title="10"><span class="co">#  mutate(boy = ifelse(gender == &quot;Boys&quot;, 1, 0), </span></a>
<a class="sourceLine" id="cb991-11" title="11"><span class="co">#         girl = ifelse(gender == &quot;Girls&quot;, 1, 0), </span></a>
<a class="sourceLine" id="cb991-12" title="12"><span class="co">#         age_boy = age*boy, </span></a>
<a class="sourceLine" id="cb991-13" title="13"><span class="co">#         age_girl = age*girl)</span></a>
<a class="sourceLine" id="cb991-14" title="14"><span class="co">#M_growth_l22 &lt;- lme(fixed = weight ~ age + age2 + girl, </span></a>
<a class="sourceLine" id="cb991-15" title="15"><span class="co">#                    random = list( ~ girl + age_girl | id, </span></a>
<a class="sourceLine" id="cb991-16" title="16"><span class="co">#                                   ~ boy + age_boy | id),</span></a>
<a class="sourceLine" id="cb991-17" title="17"><span class="co">#                   data = growth, method = &quot;REML&quot;, na.action = na.omit)</span></a>
<a class="sourceLine" id="cb991-18" title="18"><span class="co">#summary(M_growth_l22)</span></a>
<a class="sourceLine" id="cb991-19" title="19">M_growth &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age<span class="op">|</span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>,<span class="dt">na.action =</span> na.omit) </a>
<a class="sourceLine" id="cb991-20" title="20"><span class="kw">anova</span>(M_growth_l2, M_growth)</a></code></pre></div>
<pre><code>##             Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M_growth_l2     1 15 539.92465 588.94252 -254.96233                         
## M_growth        2  8 533.95003 560.09290 -258.97501 1 vs 2 8.0253784  0.3304</code></pre>
</div>
<div id="分析策略-1" class="section level2">
<h2><span class="header-section-number">64.3</span> 分析策略</h2>
<p>進行統計建模之前，請思考你想從數據中探尋什麼問題的答案?</p>
<ol style="list-style-type: decimal">
<li>是想了解某一個共變量在層內 (同一個體不同時間，或者統一學校不同學生之間) 的條件效應 (conditional effect)?</li>
<li>是想探索層內和層間數據的變化程度?</li>
<li>是想了解一個共變量的邊際效應 (marginal effect) 嗎?</li>
</ol>
<p>如果是 1 或 2 兩個問題的話，請使用混合效應模型。如果是 1，但是那個共變量卻不是定義於層水平的，那就只好放棄回到簡單的固定效應模型。如果是 3，需要考慮使用 GEE。</p>
<div id="模型選擇和建模步驟" class="section level3">
<h3><span class="header-section-number">64.3.1</span> 模型選擇和建模步驟</h3>
<p>詳細請參考 <span class="citation">(Verbeke <a href="#ref-Verbeke1997" role="doc-biblioref">1997</a>)</span>。</p>
<p>當擬合一個混合效應模型時，意味着均值的結構和協方差的結構可以被確定 (an appropriate mean structure as well as covariance structure is specified)。協方差結構，解釋了均值結構無法解釋的數據隨機變化，所以二者之間彼此高度互相依賴。另外，適當的協方差模型對於用數據進行人羣參數的有效統計推斷過程是必不可少的。</p>
<ul>
<li>第一步:</li>
</ul>
<p>由於固定效應部分不能完美解釋數據的變異，所以協方差結構就是用來輔助解釋這部分數據變異的輔助工具。建模的起點就應該是，先建立一個飽和 (甚至是過飽和 overelaborated) 的模型給均值結構 (固定效應部分)，從而確保之後要增加的隨機效應部分不受固定效應部分的擬合錯誤影響。所以，開始建模時，要先把所有可能考慮到的固定效應全部加入模型中去 (包括連續變量的二次方形式/或其他非線性關系，包括所有變量之間的交互作用)。這樣做其實是使用過度飽和的參數使得均值結構在模型中盡量在後面加入隨機效應之前保持不變。在可選的那些數據結構中，我們也應當考慮到數據中不同層級結構可能存在的異質性。要注意的是，隨機效應部分，不能也不應該在沒有把所有可能的一次方程結構都考慮進去之後 (a random effect for the linear effect of time)，就上馬二次方程/或更高次方程的隨機效應(a random effect for the quadratic effect of time)。
然後我們把飽和模型的殘差 (residuals)，異常值 (outliers)，擬合值 (fitted values)，和可能的 (potential) 隨機效應模型作出的這些殘差，異常值，擬合值之間進行比較。</p>
<ul>
<li>第二步:</li>
</ul>
<p>一旦你在飽和模型的條件下，確認好了隨機效應應該有的形式，接下來就是逐步精簡模型固定效應部分的過程:</p>
<ol style="list-style-type: decimal">
<li>用 Wald 檢驗 (當使用 REML 時)，或者 LRT (使用 ML 時) 來精簡化固定效應部分。</li>
<li>反復檢查殘差，異常值，以及擬合值跟觀測值</li>
<li>使用模型的預測軌跡和觀測值的點做視覺比較</li>
<li>用人話把你的模型解釋給老奶奶聽懂</li>
</ol>
</div>
</div>
</div>
<div id="generalized-estimating-equation" class="section level1">
<h1><span class="header-section-number">第 65 章</span> Generalized Estimating Equation</h1>
</div>
<div id="cluster-analysisunsupervised-learning-聚類分析" class="section level1">
<h1><span class="header-section-number">第 66 章</span> Cluster analysis/unsupervised learning 聚類分析</h1>
<p>目前爲止，在等級回歸模型部分中，我們接觸到的回歸模型和可能存在相互依賴性的數據，都是建立在我們能夠觀察到或者實驗設計上已知的數據層級結構的前提下的。這樣的層級可以是空間上的，或者時間上的。處在相同層級的研究對象之間存在相關性，換句話說就是：層級內部的對象之間，比起層級之間的對象具有更多的相似性。</p>
<p>但是，在許多情況下，我們其實是無法事先知道數據的內部層級（聚類）結構的。而且我們可能需要儘可能多的獲取數據，並且從測量的數據中學習。學習數據變量與變量之間的相關性(correlation)，變量與變量之間的協方差(covariance)，個體與個體之間的相似性，從而根據獲取的數據來判斷數據內部是否存在不同的層級結構。這樣的一種對數據結構進行探索的過程，在機器學習(maching learning)中也是常常使用的，它又被叫做<strong>非監督學習 (unsupervised learning)</strong>。</p>
<p>之所以把這類尋找數據分類分層結構的過程叫做非監督學習，其實，是爲了和現在越來越豐富，多到令人髮指的那些被歸類於<strong>監督學習(supervised learning)</strong>的方法作爲相互對照。在監督學習中，數據內部的分層，聚類結構是事先知道的，也就是事先能夠測量或者被定義好的。事先被定義好了的數據層級結構中，我們可以使用多元變量分析，來對某些個體的特徵加以分類，也就是給數據中的未知成員分配<strong>已知的分組</strong>的過程。</p>
<p>在醫學中常見的非監督學習過程實例之一是，對於一個（全部相同疾病的）隊列研究中的受試者進行了大量的生物標幟物(biomarker)的測量與收集，可以是血液樣本的 biomarker 的測量，也可以是每名受試者的全部DNA信息。研究者希望通過這些患者的信息對他們進行同一疾病不同等級（類別，或者進程）的分類。那麼研究者需要利用這些收集來的患者信息，建立一套儘可能完善的分類的系統。</p>
<p>另外一個例子是，我們收集了前列腺癌患者的前列腺組織，利用基因轉錄組學 (transcriptomics) 的方法測量了每名患者成千上萬的組織內基因表達。研究者希望通過這些數據來分析，提取，並且分辨這些前列腺癌患者中可能存在的分類，或者亞型。研究者也希望知道這些分析獲得的亞型，是否會和某些已知的癌症的亞型相似或者相重合。</p>
<p>在商業領域中，聚類分析也是不罕見的。例如你爲某商業公司工作，那麼食品供應商可能會上門來要求你把購買食物的顧客進行類別區分，從而提供給食物供應商們一些線索，讓他們能夠更加精準的定位廣告投放人羣。</p>
<p>在統計學，和機器學習領域中，有許多不同的手法，可以用來輔助建立這種分類的規則，它們通常又被叫做判別分析法(discriminant analysis methods)。我們這一章和下一章着重討論</p>
<ol style="list-style-type: decimal">
<li>聚類分析法 (cluster analysis)</li>
<li>主成分分析法 (principal component analysis)</li>
</ol>
<div id="聚類分析過程" class="section level2">
<h2><span class="header-section-number">66.1</span> 聚類分析過程</h2>
<p>聚類分析法是一種分析不同統計測量值之間相似/差異程度的描述性分析過程。</p>
<p>爲什麼我們總是想對具有相似性質的事物進行歸類？其實，對事物進行區分和歸類，或者打上一些標籤，是人類文明在學習並且理解周圍的世界，從而促進科學發展的核心問題之一。在原始社會，對相似事物進行歸類有時候甚至事關生死。例如人類最初需要判定某些食物的共同特徵，區分哪些是含有毒性的，哪類動物可能是兇猛殘忍的。我們從嬰兒時期開始學習語言，學習事物/事件/人物的名稱，這其實也是一個學習對周圍的世界進行區分的學習過程。古代希臘文明的先賢哲學家亞里士多德曾經主張，人類的本能之一，就是不停地想對這個我們生活的世界發生的事情看到的事物進行類別的區分，尋找相似的特徵，區別不一樣的性質。在生物學中，甚至有由亞里士多德的學生<a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%A5%A7%E5%BC%97%E6%8B%89%E6%96%AF%E6%89%98%E6%96%AF">泰奧夫拉斯托斯(Theophrastos)</a>創立的專門對生物進行分類的學科，生物分類學 (taxonomy)，後被瑞典人生物學家<a href="https://en.wikipedia.org/wiki/Carl_Linnaeus">卡爾林納斯 (Carl Linnaeus)</a>進一步發揚光大。18世紀末，<a href="https://en.wikipedia.org/wiki/Michel_Adanson">Michel Adanson</a>又爲人類引入了多元分析(polythetic)的分類系統概念，取代了之前使用單一因素(monothetic)對事物進行簡單分類的思想。很顯然，生物分類學在人類文明史中扮演了重要的角色。你應該很容易能想到達爾文提出的進化論，就是建立在前人對動植物進行了事無鉅細的分類和整理的基礎之上建立起來的重大理論突破。俄國科學家<a href="https://zh.wikipedia.org/wiki/%E5%BE%B7%E7%B1%B3%E7%89%B9%E9%87%8C%C2%B7%E4%BC%8A%E4%B8%87%E8%AF%BA%E7%BB%B4%E5%A5%87%C2%B7%E9%97%A8%E6%8D%B7%E5%88%97%E5%A4%AB">門捷列夫</a>發現化學元素週期性，並且製作出了世界上第一章元素週期表，也爲人類理解原子世界奠定了基石。</p>
<p>在對事物進行分類這個任務上，聚類分析(cluster analysis)，和判別分析是相同的。有時候在已知對象的分類情況時我們仍然傾向於使用聚類分析的方法，用它來描述數據的一些特徵。同時也能有助於判定之後可能進行的判別分析是否準確。</p>
<p>簡單歸納，對分類描述過程進行量化的主要步驟有以下幾個：</p>
<ol style="list-style-type: decimal">
<li><p>對於採集來的樣本數據 (statistical sample)，我們儘可能多的對它們的特徵變量進行測量。</p></li>
<li><p>根據第一步獲得的變量信息，定義一個能夠幫助我們判定對象與對象之間相似點或者不同程度的測量指標。</p></li>
<li><p>對這個測量指標制定一個區分的規則，或者叫做歸類的標準。</p></li>
<li><p>對樣本進行分類。</p></li>
<li><p>採集更多的樣本，對分類規則進行調整和完善。</p></li>
</ol>
<div id="連續型變量-continuous-variables-in-cluster-analysis" class="section level3">
<h3><span class="header-section-number">66.1.1</span> 連續型變量 continuous variables in cluster analysis</h3>
<p>我們想象手裏的數據是一個矩陣 <span class="math inline">\(X\)</span>，它的維度是 <span class="math inline">\(n \times p\)</span>，用 <span class="math inline">\(x_{ik}\)</span>，來表示第 <span class="math inline">\(i\)</span> 名觀察對象 <span class="math inline">\((i = 1, \dots, n)\)</span> 的第 <span class="math inline">\(k\)</span> 個變量 <span class="math inline">\((k = 1, \dots, p)\)</span> 的值。如果這些被測量的變量全部都是連續型變量的話，每個變量可以被使用幾何學的形式表達的 <span class="math inline">\(p\)</span> 個維度的其中一個平面上。當然，當維度超過3時，人類的無知大腦常常就無法進行有效的想象和推理，我們這裏使用簡單的三個變量，也就是三維空間來表示三個測量獲得的連續型變量：</p>
<p>例如我們測量了三名學生的身高，體重，以及前臂長。數據分別是：Angelo (190, 75, 30)；Dimitris (170, 75, 25)；Soren (170, 65, 30)。</p>
<div class="figure" style="text-align: center"><span id="fig:cluster00"></span>
<div id="htmlwidget-2f81be8bd94dc946f0a7" style="width:80%;height:403.2px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2f81be8bd94dc946f0a7">{"x":{"visdat":{"1a8820e56056":["function () ","plotlyVisDat"]},"cur_data":"1a8820e56056","attrs":{"1a8820e56056":{"x":{},"y":{},"z":{},"color":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"xaxis":{"range":[0,200]},"scene":{"xaxis":{"title":"Height (cm)"},"yaxis":{"title":"Weight (cm)"},"zaxis":{"title":"Forearm (cm)"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[190],"y":[75],"z":[30],"type":"scatter3d","mode":"markers","name":"Angelo","marker":{"color":"rgba(102,194,165,1)","line":{"color":"rgba(102,194,165,1)"}},"textfont":{"color":"rgba(102,194,165,1)"},"error_y":{"color":"rgba(102,194,165,1)"},"error_x":{"color":"rgba(102,194,165,1)"},"line":{"color":"rgba(102,194,165,1)"},"frame":null},{"x":[175],"y":[75],"z":[25],"type":"scatter3d","mode":"markers","name":"Dimitris","marker":{"color":"rgba(252,141,98,1)","line":{"color":"rgba(252,141,98,1)"}},"textfont":{"color":"rgba(252,141,98,1)"},"error_y":{"color":"rgba(252,141,98,1)"},"error_x":{"color":"rgba(252,141,98,1)"},"line":{"color":"rgba(252,141,98,1)"},"frame":null},{"x":[170],"y":[65],"z":[30],"type":"scatter3d","mode":"markers","name":"Soren","marker":{"color":"rgba(141,160,203,1)","line":{"color":"rgba(141,160,203,1)"}},"textfont":{"color":"rgba(141,160,203,1)"},"error_y":{"color":"rgba(141,160,203,1)"},"error_x":{"color":"rgba(141,160,203,1)"},"line":{"color":"rgba(141,160,203,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
圖 66.1: A physical 3D space showing measurements of three variables.
</p>
</div>
<p>在這個三維立體空間，我們需要定義一個變量用於丈量點與點之間的距離。其中最自然的就是歐幾里德(Euclidean)幾何距離:</p>
<p><span class="math display">\[
d_{ij} = \{\sum_{k = 1}^p(x_{ik} - x_{jk})^2\}^{\frac{1}{2}} 
\]</span></p>
<ul>
<li>歐幾里德幾何距離又被稱爲 <strong>L2 度量衡 (L2 metric)</strong>。按照這個距離的定義，那麼 Angelo 和 Dimitris 之間的歐幾里德幾何距離就是：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \{(190 - 175)^2 + (75 - 75)^2 + (30 - 25)^2 \}^{\frac{1}{2}} \\
= &amp; \sqrt{15^2 + 0^2 + 5^2} \\ 
= &amp; \sqrt{240} = 15.5
\end{aligned}
\]</span></p>
<ul>
<li>曼哈頓距離 (Manhattan distance)：別名城市區塊度量衡 (cityblock metric)，或者<strong>L1 度量衡</strong></li>
</ul>
<p><span class="math display">\[
d_{ij} = \sum_{k = 1}^p |x_{ik} - x_{jk}|
\]</span></p>
<p>按照曼哈頓距離來定義的話，Angelo 和 Dimitris 之間的距離就是：</p>
<p><span class="math display">\[
|190 - 175| + |75 - 75| + |30 - 25| = 15 + 0 + 5 = 20
\]</span></p>
<p>後來人們發現上面提到的這兩種幾何學距離其實是閔科夫斯基度量衡 (Minkowski metric) 在 L=1 和 L=2 時的特殊情況。</p>
<p>閔科夫斯基度量衡的一般形式表達爲:</p>
<p><span class="math display">\[
d_{ij} = \{ \sum_{k = 1}^p |x_{ik} - x_{jk}|^\ell \}^\frac{1}{\ell}
\]</span></p>
<p>閔科夫斯基度量衡試圖給差距較大的測量值之間增加權重用於區分彼此。不論是使用那種距離定義，這些測量距離的度量衡都具有如下的數學性質 (mathematical properties)：</p>
<ol style="list-style-type: decimal">
<li>兩點之間的距離大於等於零, positivity <br> <span class="math inline">\(d_{ij} \geqslant 0\)</span>，如果 <span class="math inline">\(d_{ij} = 0\)</span>，那麼對於任何一個 <span class="math inline">\(k = 1, \dots, p\)</span>，它們都是相等的 <span class="math inline">\(x_{ik} = x_{jk}\)</span>。</li>
<li>對稱性, symmetry <br> <span class="math inline">\(d_{ij} = d_{ji}\)</span></li>
<li>三角形不等性, triangle inequality <br> <span class="math inline">\(d_{ij} \leqslant d_{ih} + d_{hj}\)</span></li>
</ol>
</div>
<div id="二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables" class="section level3">
<h3><span class="header-section-number">66.1.2</span> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</h3>
<p>假如變量本身並不是連續型的，那麼閔科夫斯基度量衡並不適用，因爲二分量只能取0或者1。如下表所表示的，我們把 <strong>i,j</strong> 兩名對象的所有二分類變量進行下面的歸納總結：</p>
<table>
<thead>
<tr class="header">
<th align="center">i/j</th>
<th align="center">1</th>
<th align="center">0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">a</td>
<td align="center">b</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">c</td>
<td align="center">d</td>
</tr>
</tbody>
</table>
<p>其中，</p>
<ul>
<li>a 表示 i, j 兩名研究對象的二分類變量中，同時取 1 的變量的個數，</li>
<li>b 表示 i, j 兩名研究對象的二分類變量中，i 取 1 但是 j 取 0 的變量的個數，</li>
<li>c 表示 i, j 兩名研究對象的二分類變量中，j 取 1 但是 i 取 0 的變量的個數，</li>
<li>d 表示 i, j 兩名研究對象的二分類變量中，同時取 0 的變量的個數。</li>
</ul>
<p>根據這個總結表格，常用的表示兩個對象之間距離的數學度量是：</p>
<ol style="list-style-type: decimal">
<li><p>簡單匹配係數 (simple matching coefficient, SMC)，單純地計算所有的變量之中互相不一致的變量所佔的百分比： <span class="math display">\[d_{ij} = \frac{b + c}{a+b+c+d}\]</span></p></li>
<li><p>亞卡爾距離係數 (Jaccard coefficient)，則是把簡單匹配係數的分母中，d 的部分拿掉：<span class="math display">\[d_{ij} = \frac{b + c}{a + b + c}\]</span></p></li>
</ol>
<p><a href="https://en.wikipedia.org/wiki/Jaccard_index">其中亞卡爾距離係數更適合用於測量一些表達某些特質存在/不存在時兩名對象之間的距離測量 (see the “Difference with the simple matching coefficient (SMC)” session in the Wikipedia)</a>。</p>
<p>另外值得注意的是，在測量二分類變量距離的時候，三角形不等性的特質不一定會得到滿足。 (Please note that in general for dichotomous variables, the triangle inequality does not hold.)</p>
<p>用來計算測量對象之間距離的方法，和度量衡其實層出不窮，這裏只是簡單介紹了幾種。其餘的還有比如說由 <span class="citation">(Gower <a href="#ref-Gower1971" role="doc-biblioref">1971</a>)</span> 提出的 <a href="https://cran.r-project.org/web/packages/gower/vignettes/intro.html">Gower Index</a>，該指標可以同時把測量有連續型變量和分類型變量，二分類變量等都包含進來。值得提醒的是，如果是討論非連續型測量值的對象距離，我們常常用它們之間的相似性(similarities) <span class="math inline">\(s_{ij}\)</span>，而不太關注異質性 (dissimilarities) <span class="math inline">\(d_{ij}\)</span>，但其是它們之間的簡單轉換關係就是 <span class="math inline">\(d_{ij} = 1 - s_{ij}\)</span>。</p>
</div>
<div id="定義分類方法" class="section level3">
<h3><span class="header-section-number">66.1.3</span> 定義分類方法</h3>
<p>確定了用於衡量異質性 (dissimilarity) 距離的指標之後，我們就需要來定義分類的方法。首先把這個事先定下來的距離指標應用到我們的多元變量數據矩陣 (multivariate data matrix <span class="math inline">\(\mathbf{X}\)</span>) (dimension: <span class="math inline">\(n\times p\)</span>, where n indicates number of people, p indicates number of observed variables). 獲得一個形狀爲 <span class="math inline">\(n\times n\)</span> 的距離矩陣 <span class="math inline">\(\mathbf{D}\)</span> (對應上面三條數學性質中的第二條，對稱性 <span class="math inline">\(d_{ij} = d_{ji}\)</span>)。獲得觀察對象的距離矩陣 <span class="math inline">\(\mathbf{D}\)</span> 之後需要決定的就是如何給對象進行分組的策略。該分組策略需要能使觀察對象被分組後，組內的對象相對組外對象更加相似，或者組外對象相對組內對象更加不同 (a sensible strategy would be to look for sets of units such that all units in that set are relatively similar to each other but relatively different from all units outside that set)。所以，用於分組策略的算法要有一定的可行性，它還要能夠量化對象之間的相對相似性 (relative similarity) 從而能夠完成以下任務：</p>
<ol style="list-style-type: decimal">
<li><p>決定哪些人/對象被聚類到同一組中 (which pairs of units to join together into a cluster)</p></li>
<li><p>每次聚類過程完成以後，重複相同的策略和算法，也就是重新計算新組成的聚類和剩餘的對象之間的距離。</p></li>
<li><p>循環往復前兩個步驟直至全部的對象/個體都被分到各自的聚類 (cluster)。</p></li>
</ol>
<p>事實上重複上述步驟，最終會把每個個體都分配到一個單獨的聚類中，也就是每個個體本身，那其實就跟沒有做聚類分析沒有區別，也沒有意義了。於是我們需要把聚類分析的過程通過圖形的方式展示出來。這樣的圖形被叫做<strong>樹狀圖 (dendrogram)</strong>，可以在視覺上輔助我們做出要給對象分成多少個聚類的決定。在希臘語中(Greek)，dendron 是樹的意思，樹狀圖的形狀常見的如下圖 (<a href="10-Hierarchical-models.html#fig:cluster01">66.2</a>) 所示，座標軸之一是所有的觀測對象的編號，另一個座標軸則是度量每個聚類或者觀測對象個體之間的距離。</p>
<div class="figure" style="text-align: center"><span id="fig:cluster01"></span>
<img src="bookdown_files/figure-html/cluster01-1.png" alt="Example of dendrogram vertically oriented, with 50 statistical units (average linkage method and Euclidean distance measure)." width="80%" />
<p class="caption">
圖 66.2: Example of dendrogram vertically oriented, with 50 statistical units (average linkage method and Euclidean distance measure).
</p>
</div>
<p>那麼回到之前如何決定聚類數量的問題上來，我們有兩種手段來輔助：</p>
<ol style="list-style-type: decimal">
<li>層級法 (hierarchical methods)：聚合法，agglomerative； 或者分裂法， divisive。</li>
<li>分區算法 (partitioning methods)。</li>
</ol>
<p>層級法中的<strong>聚合法 (agglomerative)</strong>是指，從聚類分析的開始階段，每個獨立的對象自成一個聚類 (cluster)，所以起步於 n 個統計單位 (n statistical units)，之後的每一步聚類過程則是將度量距離相近的對象合併成爲一個聚類，直至最終所有個體歸爲唯一一個聚類。所以可以想象爲從各個枝葉彙總到一個樹幹走向各個枝葉的過程。</p>
<p>層級法中的<strong>分裂法 (divisive)</strong>則是和聚合法的聚類方向反過來，它起始於將所有觀察對象視爲唯一一個聚類，之後每一步聚類過程是將和大部分對象不太相似的個體從聚類中分裂出去，直至最終每個獨立的對象自成一個聚類。所以可以想象成從一個樹幹走向枝葉的過程。</p>
<p>分裂法其實十分消耗計算機的運算能力，因爲當樣本量較大時，一個 <span class="math inline">\(k\)</span> 種聚類的步驟就需要比較 <span class="math inline">\(2^{k-1} -1\)</span> 種不同的分區之間的距離。</p>
</div>
</div>
</div>
<div id="missing-data-1" class="section level1">
<h1><span class="header-section-number">第 67 章</span> Missing data 1</h1>
</div>
<div id="principal-component-analysis-主成分分析" class="section level1">
<h1><span class="header-section-number">第 68 章</span> Principal Component Analysis 主成分分析</h1>
<blockquote>
<dl>
<dt>A big computer, a complex algorithm and a long time does not equal science.</dt>
<dd>Robert Gentleman
</dd>
</dl>
</blockquote>

<div class="rmdnote">
PCA lecture was taught by Professor <a href="https://scholar.google.co.uk/citations?hl=en&amp;user=p-cHaf0AAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Luigi Palla</a>.
</div>

<div id="數據有相關性時產生的問題" class="section level2">
<h2><span class="header-section-number">68.1</span> 數據有相關性時產生的問題</h2>
<p>假設我們有 <span class="math inline">\(n\)</span> 個研究對象作爲樣本，我們從這些對象身上採集儘可能多的數據，假設我們一共收集了 <span class="math inline">\(p\)</span> 個不同的變量。那麼這個數據的維度 (dimension) 是 <span class="math inline">\(n \times p\)</span>。</p>
<p>如果說，我們在這個樣本中獲取到的 <span class="math inline">\(p\)</span> 個變量中，有一些是相互有依存性的，或者說相關的 (correlated)。我們有沒有辦法描述並展示這些具有相關性的變量在這個數據中扮演的角色，並且保留整個數據本身的變化特徵 (variability)？</p>
<p>Edgeworth (1891) 最早試圖用下面的方程來歸納一組從男性樣本身上測量獲得的存在相關性的變量：身高(H)，前臂長(F)，腿長(L)：</p>
<p><span class="math display">\[
\begin{aligned}
Y_1 &amp; = 0.16H + 0.51F + 0.39L \\ 
Y_2 &amp; = -0.17H + 0.69F + 0.09L \\
Y_3 &amp; = -0.15H + 0.25F + 0.52L
\end{aligned}
\]</span></p>
<p>這恐怕是最早嘗試將一組有相關性的身體測量數據整理成“不相關”的三個新變量，作爲男性身體測量指標，用於描述樣本個體的身體結構的過程。</p>
<p>下圖 <a href="10-Hierarchical-models.html#fig:PCA00">68.1</a> 中展示的兩個變量，<span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(x_2\)</span> 分別是身高和體重。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA00"></span>
<img src="img/PCA00.png" alt="Standardised data of height and weight" width="70%" />
<p class="caption">
圖 68.1: Standardised data of height and weight
</p>
</div>
<p>變量經過標準化處理之後，均值 <span class="math inline">\(\mu = 0\)</span>，方差 <span class="math inline">\(\sigma^2 =1\)</span>。如果此時已知身高和體重之間的協方差 (covariance, 概念參考 Section <a href="01-Probability.html#covariance">8.1</a>) 是 <span class="math inline">\(0.3\)</span>。</p>
<p>那麼，可以推導證明的是，他們的相關係數 (correlation, 概念參考 Section <a href="01-Probability.html#correlation">8.2</a>) 是：</p>
<p><span class="math display">\[
\begin{aligned}
Corr(X_1,X_2) &amp; = \frac{Cov(X_1,X_2)}{SD(X_1)SD(X_2)} \\
          &amp; =\frac{Cov(X_1,X_2)}{\sqrt{Var(X_1)Var(X_2)}}\\ 
          &amp; = Cov(X_1,X_2) \\
          &amp; = 0.3
\end{aligned}          
\]</span></p>
<p>以 <span class="math inline">\(x_2\)</span> (體重) 爲結果變量，<span class="math inline">\(X_1\)</span> (身高) 爲單一解釋變量的線性回歸模型的回歸係數 (regression coefficient <span class="math inline">\(\hat\beta\)</span>, 概念參考 Section <a href="04-Linear-Regression.html#beta">27.2</a>) 是：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp; = \frac{S_{x_1x_2}}{SS_{x_1x_2}} \\ 
          &amp; = \frac{CV_{x_1x_2}}{SD_{x_1}^2} \\ 
          &amp; = 0.3
\end{aligned}
\]</span></p>
<p>如果我們有另外一個座標系如下圖 <a href="10-Hierarchical-models.html#fig:PCA01">68.2</a>，從原先的座標系進行了一定角度的旋轉獲得 <span class="math inline">\(y_1, y_2\)</span>。你會認爲哪個座標系更適合這個標準化之後身高體重的數據呢？</p>
<div class="figure" style="text-align: center"><span id="fig:PCA01"></span>
<img src="img/PCA01.png" alt="Standardised data of height and weight, with a new reference system (y_1, y_2)" width="70%" />
<p class="caption">
圖 68.2: Standardised data of height and weight, with a new reference system (y_1, y_2)
</p>
</div>
<p>其實原先 <span class="math inline">\(x_1, x_2\)</span> 座標系之間存在一定的相關性，我們希望經過旋轉之後的新座標系 <span class="math inline">\(y_1, y_2\)</span> 之間是垂直的 (orthogonal)，這一數學上的概念被翻譯成爲統計學的語言就是，希望旋轉之後的新座標(變量)之間沒有相關性 (uncorrelated)。爲了消滅變量之間的相關性，我們要尋找到一個旋轉的角度 <span class="math inline">\(\theta\)</span>，使得所有數據的點 <span class="math inline">\(P_j\)</span> 到新的座標軸 <span class="math inline">\(y_1\)</span> 之間的<strong>垂直距離(perpendicualr)</strong> <span class="math inline">\(P_jP_j^\prime\)</span> <strong>之和最小</strong> (minimise the distances between points and the reference axes)。如圖 <a href="10-Hierarchical-models.html#fig:PCA02">68.3</a> 顯示的那樣，從原點到每個數據點 <span class="math inline">\(P_j\)</span> 之間的距離 <span class="math inline">\(OP_j\)</span> 其實是固定不變的。我們希望找到新的座標使得 <span class="math inline">\(P_jP_j^\prime\)</span> 的距離最短。其中 <span class="math inline">\(OP_j^\prime\)</span> 就是數據點在新座標軸上投影的長度。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA02"></span>
<img src="img/PCA02.png" alt="Minimise the distance between the points and the reference axes." width="70%" />
<p class="caption">
圖 68.3: Minimise the distance between the points and the reference axes.
</p>
</div>
<p>根據<a href="https://en.wikipedia.org/wiki/Pythagorean_theorem">勾股定理 (Pythagorean theorem)</a>。圖 <a href="10-Hierarchical-models.html#fig:PCA02">68.3</a> 中直角三角形的三邊的長度關係可以描述爲：</p>
<p><span class="math display">\[
(OP_j)^2 = (P_jP_j^\prime)^2 + (OP_j^\prime)^2
\]</span></p>
<p>把勾股定理應用到全部的數據點上的話，我們會得到一個關於所有數據點到新的座標軸距離，以及原點之間距離的方程：</p>
<p><span class="math display" id="eq:PCAeq1">\[
\begin{equation}
\sum_j (OP_j)^2 = \sum_j(P_jP_j^\prime)^2 + \sum_j(OP_j^\prime)^2
\end{equation}
\tag{68.1}
\]</span></p>
</div>
<div id="最大化方差等價於最大化數據點到新座標軸投影projection的長度" class="section level2">
<h2><span class="header-section-number">68.2</span> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</h2>
<p>把等式 <a href="10-Hierarchical-models.html#eq:PCAeq1">(68.1)</a> 兩邊同時除以數據樣本量，我們獲得等式 <a href="10-Hierarchical-models.html#eq:PCAeq2">(68.2)</a>：</p>
<p><span class="math display" id="eq:PCAeq2">\[
\begin{equation}
\sum_j (OP_j)^2/n = \sum_j(P_jP_j^\prime)^2/n + \sum_j(OP_j^\prime)^2/n
\end{equation}
\tag{68.2}
\]</span></p>
<p>其中值得注意的是，等式 <a href="10-Hierarchical-models.html#eq:PCAeq2">(68.2)</a> 左邊的部分 <span class="math inline">\(\sum_j (OP_j)^2/n\)</span> 對於一個樣本來說是固定不變的 (constant)。於是，等式右邊的部分，當我們的目標是最小化 <span class="math inline">\(\sum_j(P_jP_j^\prime)^2/n\)</span> 垂線 (perpendicular) 長度之和時，就等價於把數據點在新座標軸上的投影之和 <span class="math inline">\(\sum_j(OP_j^\prime)^2/n\)</span> 最大化。說白了，數據點在新座標軸上的投影，就是新座標軸上的變量大小。所以，旋轉座標軸之後，我們希望產生的新變量 <span class="math inline">\(y_1,y_2\)</span> 的方差取最大值(maximising the variance of the new data <span class="math inline">\(\sum_j(OP_j^\prime)^2/n\)</span>)。利用三角函數(假設座標軸的旋轉角度是<span class="math inline">\(\theta\)</span>)，你很容易就能得到新座標軸上新變量的值：</p>
<p><span class="math display" id="eq:PCAeq3">\[
\begin{equation}
\begin{aligned}
y_1  &amp; = x_1\cos\theta + x_2\sin\theta \\ 
y_2  &amp; = -x_1\sin\theta  + x_2\cos\theta
\end{aligned}
\end{equation}
\tag{68.3}
\]</span></p>
<p><strong>證明</strong></p>
<p>如圖 <a href="10-Hierarchical-models.html#fig:PCA03">68.4</a> 所示，設座標軸 <span class="math inline">\(X_1,X_2\)</span> 逆時針旋轉角度爲 <span class="math inline">\(\theta\)</span>，設新座標爲 <span class="math inline">\((y_1, y_2)\)</span>，且原點於點 <span class="math inline">\(P_j (x_1, x_2)\)</span> 之間的連線 <span class="math inline">\(OP_j\)</span> 長度爲 <span class="math inline">\(r\)</span>，<span class="math inline">\(OP_j\)</span> 和新座標軸 <span class="math inline">\(y_1\)</span> 之間的角度爲 <span class="math inline">\(\alpha\)</span>。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA03"></span>
<img src="img/PCA03.png" alt="Rotation of the coordinates, and the new variables calculation." width="70%" />
<p class="caption">
圖 68.4: Rotation of the coordinates, and the new variables calculation.
</p>
</div>
<p><span class="math display">\[
\begin{aligned}
(OP_j)^2 &amp; = x_1^2 + x_2^2 = y_1^2 + y_2^2 \\
         &amp; = r^2 \\ 
\because  x_1 &amp; = r\times\cos(\alpha +\theta) \\ 
          x_2 &amp; = r\times\sin(\alpha + \theta) \\
          y_1 &amp; = r\times\cos(\alpha) \\
          y_2 &amp; = r\times\sin(\alpha) \\ 
\therefore x_1 &amp; = r[\cos\alpha\cos\theta - \sin\alpha\sin\theta] \\
               &amp; = y_1\cos\theta - y_2\sin\theta \\ 
           x_2 &amp; = r[\sin\alpha\cos\theta + \cos\alpha\sin\theta] \\
               &amp; = y_2\cos\theta+y_1\sin\theta \\
\Rightarrow x_1\cos\theta &amp; = y_1\cos^2\theta -y_2 \sin\theta\cos\theta \\ 
            x_2\sin\theta &amp; = y_2\cos\theta\sin\theta + y_1\sin^2\theta \\ 
\textbf{Sum the}&amp; \textbf{ above two equations} \\
\Rightarrow y_1 &amp; = \frac{x_1\cos\theta + x_2 \sin\theta}{(\cos^2\theta + \sin^2\theta)} \\ 
            y_1 &amp; = x_1\cos\theta + x_2 \sin\theta \\ 
\textbf{Similarly}&amp; \\
\Rightarrow x_1\sin\theta &amp; = y_1\cos\theta\sin\theta -y_2 \sin^2\theta \\ 
            x_2\cos\theta &amp; = y_2\cos^2\theta + y_1\sin\theta\cos\theta \\ 
\textbf{Take substraction}&amp; \textbf{ between the above two equations} \\
\Rightarrow y_2 &amp; = \frac{-x_1\sin\theta + x_2\cos\theta}{(\cos^2\theta + \sin^2\theta)} \\
            y_2 &amp; = -x_1\sin\theta + x_2\cos\theta
\end{aligned}
\]</span></p>
<p><span class="math inline">\(y_1, y_2\)</span>就是旋轉後新的座標軸的變量。在這個簡單實例中，我們從原始數據 <span class="math inline">\(x_1, x_2\)</span> 經過旋轉，獲得新的數據 <span class="math inline">\(y_1, y_2\)</span>，他們二者之間其實只是經過了線性轉換 (linear transformation)。一般地，我們如果要給原始數據矩陣 (維度 <span class="math inline">\(n\times p\)</span>)進行座標軸的數據轉換，只需要給原始數據矩陣乘以一個正方形的投影矩陣 <span class="math inline">\(\mathbf{P}\)</span> (projection matrix) (維度 <span class="math inline">\(p\times p\)</span>) (<span class="math inline">\(p\)</span> 是變量的個數)即可。</p>
<p>當變量只有兩個 <span class="math inline">\((p =2)\)</span> 時，我們很容易使用一個平面圖來理解這個轉換過程其實就是對座標軸進行幾何旋轉的過程，這時候的投影矩陣是：</p>
<p><span class="math display" id="eq:PCAeq4">\[
\left[
\begin{array}
\cos\cos\theta &amp; \sin\theta \\
-\sin\theta &amp; \cos\theta
\end{array}
\right]
\tag{68.4}
\]</span></p>
<p>經過旋轉之後獲得的新變量 <span class="math inline">\(y_1, y_2\)</span> 被叫做主成分 (principal components)。主成分有什麼特徵呢？如圖 <a href="10-Hierarchical-models.html#fig:PCA04">68.5</a> 所表示的那樣，當兩個原始變量 <span class="math inline">\(x_1, x_2\)</span> 之間相關係數很高，由於已知方差總和不變 <span class="math inline">\(\text{Var}(x_1)+\text{Var}(x_2) = \text{Var}(y_1) + \text{Var}(y_2)\)</span>，座標旋轉之後的第一個主成分 <span class="math inline">\(y_1\)</span>，將會擁有原始數據 <span class="math inline">\(x_1, x_2\)</span> 的方差 (variance) 中的絕大部分。那麼理論上，我們就完成了保留數據本身的整體方差，但是把大部分方差歸納到第一個主成分中去的過程。所以，當對樣本測量了很多很多的變量的時候，我們會發現很多變量之間存在內部相關性，於是我們可以通過主成分分析來留下幾個能解釋整體數據的最主要的成分，並且保留數據的整體信息，也就是整體的方差，這是一個把數據降維 (dimension reduction) 的過程，去除掉那些冗餘的不需要的變量 (redundancy removed)。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA04"></span>
<img src="img/PCA04.png" alt="Variance of the new axis/prin" width="70%" />
<p class="caption">
圖 68.5: Variance of the new axis/prin
</p>
</div>
<p>所以，PCA的過程可以描述如下：</p>
<p>數據如果有 <span class="math inline">\(p\)</span> 個存在內部相關性的連續型變量 <span class="math inline">\(x_1, x_2, \dots, x_p\)</span>，那麼一定存在 <span class="math inline">\(p\)</span> 個相互獨立的變量 (principal components)，滿足下面的條件：</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(p\)</span> 個相互獨立的變量分別都是原始變量 <span class="math inline">\(x_1, x_2, \dots, x_p\)</span> 的線性轉換：
<span class="math display">\[
\begin{aligned}
y_1 &amp; = a_{11}x_1 + a_{12}x_2 + \cdots + a_{1p}x_p \\
y_2 &amp; = a_{21}x_1 + a_{22}x_2 + \cdots + a_{2p}x_p \\
\vdots &amp; \\
y_p &amp; = a_{p1}x_1 + a_{p2}x_2 + \cdots + a_{pp}x_p \\
\end{aligned}
\]</span></p></li>
<li><p>這 <span class="math inline">\(p\)</span> 個相互獨立的變量通過最大化它們對數據整體方差的貢獻獲得。</p></li>
<li><p>這 <span class="math inline">\(p\)</span> 個相互獨立的變量被叫做這個數據的主成分變量。</p></li>
<li><p>這些主成分變量之間相互獨立 (uncorrelated)，並且按照他們各自對數據總體方差的貢獻度從大到小排列 (the principal components are uncorrelated and are ordered by the amount of the total system variability that they explain)：</p></li>
</ol>
<p><span class="math display">\[
\text{Cov}(y_j, y_k) = 0 \text{ for any } j, k \in [1, p] \\
\text{Var}(y_1) \geqslant \text{Var}(y_2) \geqslant \text{Var}(y_3) \geqslant \dots \geqslant \text{Var}(y_p)
\]</span></p>
</div>
<div id="數學推導" class="section level2">
<h2><span class="header-section-number">68.3</span> 數學推導</h2>
<p>如果，</p>
<ul>
<li><span class="math inline">\(\textbf{S}\)</span> 是數據的<strong>方差協方差矩陣 (variance, covriance matrix)</strong>；</li>
<li><span class="math inline">\(\textbf{P}\)</span> 是<strong>直角投影矩陣 (orthogonal projection matrix)</strong>，該矩陣的每一列，是旋轉之後的新變量的座標，也就是主成分變量，它們又被叫做<strong>特徵向量 (eigenvectors)</strong>；</li>
<li><span class="math inline">\(\bf{\Lambda}\)</span> 是一個<strong>對角矩陣 (diagonal matrix)</strong>，它的對角線上是每個主成分變量的方差，它們又被叫做<strong>特徵值 (eigenvalues)</strong>。特徵值常常又被叫做慣性 (inertia)，特徵值從對角線左上角起往右下角是從大到小排列，每一個特徵值是每個特徵向量的方差，也就是數據整體方差投射在這個主成分變量上的慣性，可以理解爲該主成分能夠解釋多少整個數據的方差 (explained variance)。</li>
</ul>

<div class="theorem">
<span id="thm:unnamed-chunk-1" class="theorem"><strong>Theorem 68.1  (Spectral decomposition)  </strong></span>根據<strong>譜定理 Spectral decomposition</strong>：如果矩陣 <span class="math inline">\(\textbf{S}\)</span> 是對稱的，它總是可以被分解爲：
<span class="math display">\[
\textbf{S} = \textbf{P}\bf{\Lambda}\textbf{P}^t
\]</span>
</div>

<p>值得注意的是，首先，分解方差協方差矩陣的時候，並沒有任何統計學或者概率論上的前提條件；其次，這樣的矩陣分解不一定只用於方差協方差矩陣，你可以對任何對稱矩陣 (symmetrix matrix) 進行分解，它被叫做矩陣縮放 (matrix scaling)；最後，其實數據矩陣本身不一定非要是連續型變量，也不一定要有相似的刻度/取值範圍 (same scale)，如果你願意，對二分類變量或者是計數型變量，均可以進行主成分分析。但是，當變量之間的刻度相差巨大時，可能會產生一些意想不到的假象。所以，在實施主成分分析之前，通常的建議是對原始數據的變量進行標準化，或者直接用其相關係數矩陣 (correlation matrix)。</p>
<div id="超越對稱矩陣奇異值分解-singular-value-decomposition-svd" class="section level3">
<h3><span class="header-section-number">68.3.1</span> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</h3>
<p>主成分分析使用的矩陣分解方法，只能應用在方差協方差矩陣或者相關係數矩陣這樣的對稱的正方形矩陣。假如矩陣並非對稱，另一種矩陣分解方法叫做奇異值分解法 (singular value decomposition, SVD)。此時就可以直接應用在原始數據矩陣 <span class="math inline">\(\mathbf{X}_{n\times p}\)</span> 本身，而不需要侷限於數據的方差協方差矩陣/相關係數矩陣：</p>
<p><span class="math display">\[
\mathbf{X}_{n\times p} = \mathbf{U}_{n\times n}\bf{\Sigma}_{n \times p} \mathbf{W}_{p\times p}^t
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(\mathbf{U}_{n\times n}\)</span> 是含有<strong>左奇異向量 (left singular vectors)</strong> 的矩陣；</li>
<li><span class="math inline">\(\Sigma_{n \times p}\)</span> 是含有<strong>奇異值 (singular values)</strong>的矩陣；</li>
<li><span class="math inline">\(\mathbf{W}_{p\times p}\)</span> 則是含有<strong>右奇異向量 (right singular vectors)</strong> 的矩陣。</li>
</ul>
<p>所以你看到任意的形狀都可以被分解，此時分解出來的 <span class="math inline">\(\mathbf{U}_{n\times n}\)</span> 和 <span class="math inline">\(\mathbf{W}_{p\times p}\)</span> 是形狀維度不同的正方形矩陣。</p>
<p>另外，根據這樣的分解我們可以推導：</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{X}^t \mathbf{X} &amp; = \mathbf{W}\bf{\Sigma}\mathbf{U}^t\times\mathbf{U}\bf{\Sigma}\mathbf{W}^t \\
                        &amp; = \mathbf{W}\bf{\Sigma}^2\mathbf{W}^t \\ 
\Rightarrow \bf{\Sigma}^2 &amp; = \bf{\Lambda}                      
\end{aligned}
\]</span></p>
<p>所以，<span class="math inline">\(\bf{\Sigma}^2 = \bf{\Lambda}\)</span> ，也就是說在奇異值分解中獲得的中間矩陣 <span class="math inline">\(\bf{\Sigma}_{n \times p}\)</span>，它對角線上的數值的平方，就是每個原始變量的方差，或者說它們本身是原始數據的標準差。奇異值分解矩陣的方法最常見被用於實施對應分析 (Correspondence Analysis)。</p>
</div>
</div>
<div id="主成分分析數據實例" class="section level2">
<h2><span class="header-section-number">68.4</span> 主成分分析數據實例</h2>
<p><a href="http://factominer.free.fr/bookV2/orange.csv">橙汁數據</a>，是邀請美食家對產自世界各地的六種品牌的橙汁進行一個一個的味道/品質描述，並給每個項目打分後彙總獲得的評價數據。你可以用下面的代碼下載這個數據並觀察每個描述的變量，且很容易觀察的到的是，這些變量之間並不完全獨立，有些變量可能和另一些變量相關：</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Odour.intensity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Odour.typicality
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Pulpiness
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Intensity.of.taste
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Acidity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Bitterness
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Sweetness
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pampryl amb.
</td>
<td style="text-align:right;">
2.82
</td>
<td style="text-align:right;">
2.53
</td>
<td style="text-align:right;">
1.66
</td>
<td style="text-align:right;">
3.46
</td>
<td style="text-align:right;">
3.15
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
2.60
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana amb.
</td>
<td style="text-align:right;">
2.76
</td>
<td style="text-align:right;">
2.82
</td>
<td style="text-align:right;">
1.91
</td>
<td style="text-align:right;">
3.23
</td>
<td style="text-align:right;">
2.55
</td>
<td style="text-align:right;">
2.08
</td>
<td style="text-align:right;">
3.32
</td>
</tr>
<tr>
<td style="text-align:left;">
Fruvita fr.
</td>
<td style="text-align:right;">
2.83
</td>
<td style="text-align:right;">
2.88
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
3.45
</td>
<td style="text-align:right;">
2.42
</td>
<td style="text-align:right;">
1.76
</td>
<td style="text-align:right;">
3.38
</td>
</tr>
<tr>
<td style="text-align:left;">
Joker amb.
</td>
<td style="text-align:right;">
2.76
</td>
<td style="text-align:right;">
2.59
</td>
<td style="text-align:right;">
1.66
</td>
<td style="text-align:right;">
3.37
</td>
<td style="text-align:right;">
3.05
</td>
<td style="text-align:right;">
2.56
</td>
<td style="text-align:right;">
2.80
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana fr.
</td>
<td style="text-align:right;">
3.20
</td>
<td style="text-align:right;">
3.02
</td>
<td style="text-align:right;">
3.69
</td>
<td style="text-align:right;">
3.12
</td>
<td style="text-align:right;">
2.33
</td>
<td style="text-align:right;">
1.97
</td>
<td style="text-align:right;">
3.34
</td>
</tr>
<tr>
<td style="text-align:left;">
Pampryl fr.
</td>
<td style="text-align:right;">
3.07
</td>
<td style="text-align:right;">
2.73
</td>
<td style="text-align:right;">
3.34
</td>
<td style="text-align:right;">
3.54
</td>
<td style="text-align:right;">
3.31
</td>
<td style="text-align:right;">
2.63
</td>
<td style="text-align:right;">
2.90
</td>
</tr>
</tbody>
</table>
</div>
<p>進行主成分分析在Stata只需要這樣一行代碼：</p>
<pre><code>insheet using &quot;http://factominer.free.fr/bookV2/orange.csv&quot; , delimiter(&quot;;&quot;) clear
pca odour* pulp* intens* acid* bitter* sweetness, cor</code></pre>
<p>你就會獲得十分直觀的結果：</p>
<pre><code>
Principal components/correlation                 Number of obs    =          6
                                                 Number of comp.  =          5
                                                 Trace            =          7
    Rotation: (unrotated = principal)            Rho              =     1.0000

    --------------------------------------------------------------------------
       Component |   Eigenvalue   Difference         Proportion   Cumulative
    -------------+------------------------------------------------------------
           Comp1 |      4.74369       3.4104             0.6777       0.6777
           Comp2 |      1.33329      .513448             0.1905       0.8681
           Comp3 |      .819842      .735818             0.1171       0.9853
           Comp4 |     .0840232     .0648702             0.0120       0.9973
           Comp5 |      .019153      .019153             0.0027       1.0000
           Comp6 |            0            0             0.0000       1.0000
           Comp7 |            0            .             0.0000       1.0000
    --------------------------------------------------------------------------

Principal components (eigenvectors) 

    ------------------------------------------------------------------------------
        Variable |    Comp1     Comp2     Comp3     Comp4     Comp5 | Unexplained 
    -------------+--------------------------------------------------+-------------
    odourinten~y |   0.2110    0.6534   -0.5174    0.0286    0.0310 |           0 
    odourtypic~y |   0.4524    0.1162   -0.0646    0.2668    0.2952 |           0 
       pulpiness |   0.3313    0.5340    0.3290   -0.3327   -0.2250 |           0 
    intensityo~e |  -0.2984    0.3714    0.6910    0.0189    0.3456 |           0 
         acidity |  -0.4191    0.3017   -0.0237    0.7065   -0.4106 |           0 
      bitterness |  -0.4292    0.1628   -0.3152   -0.0974    0.6712 |           0 
       sweetness |   0.4384   -0.1374    0.2061    0.5553    0.3503 |           0 
    ------------------------------------------------------------------------------</code></pre>
<p>根據方差協方差矩陣進行的主成分分析結果，我們發現主成分 6 和 7 可以忽略不計。相同的計算結果可以在R裏面通過方便的計算包 <a href="http://factominer.free.fr/"><code>FactoMineR</code></a> 來計算並用 <a href="http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization"><code>factoextra</code></a> 來實現其分析圖形的美觀展示：</p>
<div class="sourceCode" id="cb995"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb995-1" title="1"><span class="co"># library(FactoMineR)</span></a>
<a class="sourceLine" id="cb995-2" title="2">org.pca &lt;-<span class="st"> </span><span class="kw">PCA</span>(orange[, <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>], <span class="dt">ncp =</span> <span class="dv">7</span>, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb995-3" title="3"></a>
<a class="sourceLine" id="cb995-4" title="4"><span class="co"># library(factoextra)</span></a>
<a class="sourceLine" id="cb995-5" title="5">eig.val &lt;-<span class="st"> </span><span class="kw">get_eigenvalue</span>(org.pca)</a>
<a class="sourceLine" id="cb995-6" title="6">eig.val <span class="co"># eigenvalue (variances of each principal components)</span></a></code></pre></div>
<pre><code>##        eigenvalue variance.percent cumulative.variance.percent
## Dim.1 4.743692688      67.76703840                   67.767038
## Dim.2 1.333289855      19.04699793                   86.814036
## Dim.3 0.819841150      11.71201643                   98.526053
## Dim.4 0.084023297       1.20033282                   99.726386
## Dim.5 0.019153009       0.27361442                  100.000000</code></pre>
<div class="sourceCode" id="cb997"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb997-1" title="1"><span class="co"># eigen vectors:</span></a>
<a class="sourceLine" id="cb997-2" title="2">org.pca<span class="op">$</span>svd<span class="op">$</span>V</a></code></pre></div>
<pre><code>##             [,1]        [,2]         [,3]         [,4]         [,5]
## [1,]  0.21100074  0.65340689 -0.517409852  0.028573070  0.030958154
## [2,]  0.45241413  0.11618305 -0.064606287  0.266760192  0.295222955
## [3,]  0.33132165  0.53403262  0.329025446 -0.332685134 -0.225026986
## [4,] -0.29836065  0.37144476  0.690990232  0.018942515  0.345597119
## [5,] -0.41905731  0.30166462 -0.023688451  0.706533003 -0.410644925
## [6,] -0.42917948  0.16282112 -0.315220908 -0.097425116  0.671196644
## [7,]  0.43840960 -0.13742859  0.206064224  0.555251136  0.350251763</code></pre>
<p>於是根據計算獲得的特徵值向量，我們可以寫下這5個主成分變量和原始變量之間的轉換關係方程：</p>
<p><span class="math display">\[
\begin{aligned}
y_1 &amp; = 0.2110x_1 + 0.4524x_2 + 0.3313x_3 - 0.2984x_4 - 0.4191x_5 - 0.4292x_6 + 0.4384x_7 \\
y_2 &amp; = 0.6534x_1 + 0.1162x_2 + 0.5340x_3 + 0.3714x_4 + 0.3017x_5 + 0.1628x_6 - 0.1374x_7 \\
y_3 &amp; =-0.5174x_1 - 0.0646x_2 + 0.3290x_3 + 0.6910x_4 - 0.0237x_5 - 0.3152x_6 + 0.2061x_7 \\
y_4 &amp; = 0.0286x_1 + 0.2668x_2 - 0.3327x_3 + 0.0189x_4 + 0.7065x_5 - 0.0974x_6 + 0.5553x_7 \\
y_5 &amp; = 0.0310x_1 + 0.2952x_2 - 0.2250x_3 + 0.3456x_4 - 0.4106x_5 + 0.6712x_6 + 0.3503x_7 \\
\end{aligned}
\]</span></p>
<p>於是，解釋完了如何從原始數據變量根據計算獲得的特徵值向量轉換成爲新的變量之後，要面對的問題是，我們要保留多少主成分？
我們通常會使用圖 <a href="10-Hierarchical-models.html#fig:PCAorangeScreeplot">68.6</a> 那樣的碎石圖 (Scree plot) 來輔助判斷。碎石圖通常縱軸是每個主成分能夠解釋的數據總體方差的百分比，然後橫軸是主成分的個數。所以我們會期待出現一個像手肘一樣的形狀提示應該在第幾個主成分的地方停下。通常在統計分析中，我們默認的準則是，至少保留的主成分個數要能夠解釋總體方差的 70%/80% 以上才較爲理想。<a href="https://en.wikipedia.org/wiki/Exploratory_factor_analysis#Kaiser&#39;s_(1960)_eigenvalue-greater-than-one_rule_(K1_or_Kaiser_criterion)">Kaiser 準則</a> 建議的是，最好保留下特徵值大於等於1(也就是標準化數據之後獲得的主成分變量方差大於等於1)的主成分變量。在我們的橙汁數據實例中，顯然保留前兩個主成分就已經能夠解釋 86.81% 的總體方差，我們認爲這是理想的主成分個數。</p>
<div class="figure" style="text-align: center"><span id="fig:PCAorangeScreeplot"></span>
<img src="bookdown_files/figure-html/PCAorangeScreeplot-1.png" alt="Orange data: eigenvalues among all variances (varaince explained) by each dimension (principle component) provided by PCA" width="70%" />
<p class="caption">
圖 68.6: Orange data: eigenvalues among all variances (varaince explained) by each dimension (principle component) provided by PCA
</p>
</div>
<p>另外一種輔助的圖形是叫做分數圖 (score plot)，又名個人圖 (graph of individuals)，如果個體的變量特徵相近，他們會在圖中聚在較爲靠近的地方：</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb999-1" title="1"><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">pointsize =</span> <span class="st">&quot;cos2&quot;</span>, <span class="dt">pointshape =</span> <span class="dv">21</span>, </a>
<a class="sourceLine" id="cb999-2" title="2">             <span class="dt">fill =</span> <span class="st">&quot;#E7B800&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangeScoreplot"></span>
<img src="bookdown_files/figure-html/PCAorangeScoreplot-1.png" alt="Score plot/individual plot of the orange data." width="70%" />
<p class="caption">
圖 68.7: Score plot/individual plot of the orange data.
</p>
</div>
<p>細心觀察的話，你會發現圖 <a href="10-Hierarchical-models.html#fig:PCAorangeScoreplot">68.7</a> 中各個橙汁 (個體,individual) 的座標其實是來自於PCA分析結果中第一和第二主成分變量的結果，展示在第一和第二主成分變量構成的平面。該平面解釋了總體數據慣性 (inertia) 的 86.82% (= 67.77% + 19.05%)。其中第一個主成分 <code>Dim.1</code> 把 <code>Tropicana fr.</code> 和 <code>Pampryl amb.</code> 兩種橙汁分別歸類在最右邊和最左邊。這是因爲原始數據中 <code>Tropicana fr.</code> 是 <code>Odour.typicality</code> 得分最高 <code>Bitternes</code> 得分倒數第二低，同時 <code>Pampryl amb.</code> 則是在這兩個項目上得分分別是最低和最高。也就是說這兩種橙汁在這兩個項目上得分分別是左右兩種極端，所以首先在第一主成分中把這兩中橙汁分離開來。接下來，第二主成分變量 <code>Dim.2</code> 則是將第一主成分成功分離開的兩個個體(橙汁)從數據中拿掉以後，剩下的四種橙汁的分類。可以看到第二個主成分軸，把 <code>Pampryl fr.</code> 和 <code>Tropicana amb.</code> 兩種橙汁放在了該軸的兩個極端，這是因爲 <code>Pampryl fr.</code> 在 <code>Intensity.of.taste</code> 項目上得分最高，而 <code>Tropicana amb.</code> 在拿掉了第一主成分分離的兩種橙汁之後，在 <code>Odour.intensity</code> 項目上得分最低。</p>
<p>回到 R 幫忙分析的主成分結果報告來：</p>
<div class="sourceCode" id="cb1000"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1000-1" title="1"><span class="kw">summary</span>(org.pca)</a></code></pre></div>
<pre><code>## 
## Call:
## PCA(X = orange[, 1:7], ncp = 7, graph = FALSE) 
## 
## 
## Eigenvalues
##                        Dim.1   Dim.2   Dim.3   Dim.4   Dim.5
## Variance               4.744   1.333   0.820   0.084   0.019
## % of var.             67.767  19.047  11.712   1.200   0.274
## Cumulative % of var.  67.767  86.814  98.526  99.726 100.000
## 
## Individuals
##                        Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
## Pampryl amb.       |  3.029 | -2.984 31.288  0.970 | -0.082  0.085  0.001 | -0.333  2.254  0.012 |
## Tropicana amb.     |  1.976 |  0.886  2.761  0.201 | -1.715 36.771  0.753 | -0.087  0.154  0.002 |
## Fruvita fr.        |  2.595 |  1.937 13.182  0.557 |  0.040  0.020  0.000 |  1.710 59.450  0.434 |
## Joker amb.         |  2.094 | -1.896 12.631  0.820 | -0.834  8.686  0.158 | -0.154  0.481  0.005 |
## Tropicana fr.      |  3.512 |  3.186 35.660  0.823 |  0.589  4.335  0.028 | -1.345 36.774  0.147 |
## Pampryl fr.        |  2.338 | -1.129  4.479  0.233 |  2.002 50.102  0.733 |  0.209  0.887  0.008 |
## 
## Variables
##                       Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
## Odour.intensity    |  0.460  4.452  0.211 |  0.754 42.694  0.569 | -0.468 26.771  0.219 |
## Odour.typicality   |  0.985 20.468  0.971 |  0.134  1.350  0.018 | -0.058  0.417  0.003 |
## Pulpiness          |  0.722 10.977  0.521 |  0.617 28.519  0.380 |  0.298 10.826  0.089 |
## Intensity.of.taste | -0.650  8.902  0.422 |  0.429 13.797  0.184 |  0.626 47.747  0.391 |
## Acidity            | -0.913 17.561  0.833 |  0.348  9.100  0.121 | -0.021  0.056  0.000 |
## Bitterness         | -0.935 18.420  0.874 |  0.188  2.651  0.035 | -0.285  9.936  0.081 |
## Sweetness          |  0.955 19.220  0.912 | -0.159  1.889  0.025 |  0.187  4.246  0.035 |</code></pre>
<p>可以看到第一部分是特徵值(eigenvalue)的結果描述，第二部分是個人 (individual) 的分析報告：</p>
<pre><code>...{omitted}...
Individuals
                       Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2 
Pampryl amb.       |  3.029 | -2.984 31.288  0.970 | -0.082  0.085  0.001
Tropicana amb.     |  1.976 |  0.886  2.761  0.201 | -1.715 36.771  0.753 
Fruvita fr.        |  2.595 |  1.937 13.182  0.557 |  0.040  0.020  0.000 
Joker amb.         |  2.094 | -1.896 12.631  0.820 | -0.834  8.686  0.158 
Tropicana fr.      |  3.512 |  3.186 35.660  0.823 |  0.589  4.335  0.028 
Pampryl fr.        |  2.338 | -1.129  4.479  0.233 |  2.002 50.102  0.733 
...{omitted}...</code></pre>
<p>其中，</p>
<ul>
<li><code>Dist</code> 是每個個體(行數據)，到座標軸原點 (平均重心位置) 的距離。此數據中距離原點最遠的兩種橙汁是 <code>Pampryl amb.</code> (最左邊) 和 <code>Tropicana fr.</code> (最右邊)。</li>
<li><code>Dim.1</code> 是該個體，在第一個主成分變量座標軸上的座標。</li>
<li><code>ctr</code> 是該個體在第一個主成分變量提取時貢獻的百分比。</li>
<li><code>cos2</code> 是該個體在該主成分變量上投影的慣性除以該個體本身的慣性所佔的比例，又叫做該個體對相應主成分變量的代表性評價 (the quality of representation of an individual <span class="math inline">\(i\)</span> on the principle component <span class="math inline">\(s\)</span> is measured by the distance between the point within the space <span class="math inline">\(u_s\)</span> and the projection on the component)。</li>
</ul>
<p><span class="math display">\[
\text{quality of representation}_s(i) = \frac{\text{Projected inertia of }i \text{ on } u_s}{\text{Total inertia of }i} = \cos^2\theta_i^s 
\]</span></p>
<p>PCA報告的下半部分，是關於數據中變量與變量之間關係的分析結果。</p>
<pre><code>Variables
                      Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
Odour.intensity    |  0.460  4.452  0.211 |  0.754 42.694  0.569 | -0.468 26.771  0.219 |
Odour.typicality   |  0.985 20.468  0.971 |  0.134  1.350  0.018 | -0.058  0.417  0.003 |
Pulpiness          |  0.722 10.977  0.521 |  0.617 28.519  0.380 |  0.298 10.826  0.089 |
Intensity.of.taste | -0.650  8.902  0.422 |  0.429 13.797  0.184 |  0.626 47.747  0.391 |
Acidity            | -0.913 17.561  0.833 |  0.348  9.100  0.121 | -0.021  0.056  0.000 |
Bitterness         | -0.935 18.420  0.874 |  0.188  2.651  0.035 | -0.285  9.936  0.081 |
Sweetness          |  0.955 19.220  0.912 | -0.159  1.889  0.025 |  0.187  4.246  0.035 |</code></pre>
<p>根據這個結果繪製的變量相關關係圖如下：</p>
<div class="sourceCode" id="cb1004"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1004-1" title="1"><span class="kw">fviz_pca_var</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangevariableplot"></span>
<img src="bookdown_files/figure-html/PCAorangevariableplot-1.png" alt="Variable plot of the orange data." width="70%" />
<p class="caption">
圖 68.8: Variable plot of the orange data.
</p>
</div>
<ul>
<li>在第一個主成分軸上 (<code>Dim.1</code>)，正相關的變量 <code>Odour.intensity, Odour.typicality, Pulpiness, Sweetness</code> 被歸類在右半球，而負相關的變量 <code>Intensity.of.taste, Acidity, Bitterness</code> 則被歸類在第一主成分軸的左半球。</li>
<li>相似地，在第二個主成分軸上 (<code>Dim.2</code>)，只有負相關的 <code>Sweetness</code> 被歸類在下半球。</li>
<li>每個變量從原點出發時的箭頭長度越長 <code>cos2</code>，代表它在該主成分軸上代表質量更好 (the quality of representation of the variable on the component)</li>
</ul>
<p>如果你願意，且數據和變量不至於多到眼花繚亂，我們還可以把個體圖和變量圖結合起來觀察：</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1005-1" title="1"><span class="kw">fviz_pca_biplot</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">pointsize =</span> <span class="st">&quot;cos2&quot;</span>, <span class="dt">pointshape =</span> <span class="dv">21</span>, </a>
<a class="sourceLine" id="cb1005-2" title="2">             <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangebiplot"></span>
<img src="bookdown_files/figure-html/PCAorangebiplot-1.png" alt="Biplot of the orange data." width="70%" />
<p class="caption">
圖 68.9: Biplot of the orange data.
</p>
</div>
</div>
<div id="在pca圖形中加入補充變量和補充個體-supplementary-elements" class="section level2">
<h2><span class="header-section-number">68.5</span> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</h2>
<p>在橙汁數據中，除了有美食家給出的各個味道項目的評分之外，其實還有各個橙汁的物理化學特性數據。</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Glucose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Fructose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Saccharose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Sweetening.power
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
pH
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Citric.acid
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Vitamin.C
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Way.of.preserving
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Origin
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pampryl amb.
</td>
<td style="text-align:right;">
25.32
</td>
<td style="text-align:right;">
27.36
</td>
<td style="text-align:right;">
36.45
</td>
<td style="text-align:right;">
89.95
</td>
<td style="text-align:right;">
3.59
</td>
<td style="text-align:right;">
0.84
</td>
<td style="text-align:right;">
43.44
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Other
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana amb.
</td>
<td style="text-align:right;">
17.33
</td>
<td style="text-align:right;">
20.00
</td>
<td style="text-align:right;">
44.15
</td>
<td style="text-align:right;">
82.55
</td>
<td style="text-align:right;">
3.89
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:right;">
32.70
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Fruvita fr.
</td>
<td style="text-align:right;">
23.65
</td>
<td style="text-align:right;">
25.65
</td>
<td style="text-align:right;">
52.12
</td>
<td style="text-align:right;">
102.22
</td>
<td style="text-align:right;">
3.85
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
37.00
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Joker amb.
</td>
<td style="text-align:right;">
32.42
</td>
<td style="text-align:right;">
34.54
</td>
<td style="text-align:right;">
22.92
</td>
<td style="text-align:right;">
90.71
</td>
<td style="text-align:right;">
3.60
</td>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
36.60
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Other
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana fr.
</td>
<td style="text-align:right;">
22.70
</td>
<td style="text-align:right;">
25.32
</td>
<td style="text-align:right;">
45.80
</td>
<td style="text-align:right;">
94.87
</td>
<td style="text-align:right;">
3.82
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
39.50
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Pampryl fr.
</td>
<td style="text-align:right;">
27.16
</td>
<td style="text-align:right;">
29.48
</td>
<td style="text-align:right;">
38.94
</td>
<td style="text-align:right;">
96.51
</td>
<td style="text-align:right;">
3.68
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
27.00
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Other
</td>
</tr>
</tbody>
</table>
</div>
<p>我們可以把這些沒有用於計算主成分分析的變量 (active variables)，和其餘的輔助性變量 (supplementary variables) 同時繪製在變量相關係數圓盤圖中。此時我們只需要在進行PCA運算的時候告訴R這些變量是輔助性的連續/分類變量即可：</p>
<div class="sourceCode" id="cb1006"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1006-1" title="1">org.pca &lt;-<span class="st"> </span><span class="kw">PCA</span>(orange, <span class="dt">quanti.sup =</span> <span class="dv">8</span><span class="op">:</span><span class="dv">14</span>, <span class="dt">quali.sup =</span> <span class="dv">15</span><span class="op">:</span><span class="dv">16</span>,</a>
<a class="sourceLine" id="cb1006-2" title="2">               <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1006-3" title="3">org.pca<span class="op">$</span>quanti.sup</a></code></pre></div>
<pre><code>## $coord
##                         Dim.1       Dim.2         Dim.3        Dim.4       Dim.5
## Glucose          -0.572454497  0.31123036  0.0263849025 -0.208332016 -0.72892600
## Fructose         -0.561054870  0.31451133 -0.0084203081 -0.181973281 -0.74371694
## Saccharose        0.750440168  0.14492075  0.3246761207 -0.075192796  0.55205886
## Sweetening.power  0.300767457  0.67471255  0.4895557731 -0.389880490 -0.25026037
## pH                0.879663611 -0.23629707  0.1935892274  0.245926101  0.26907097
## Citric.acid      -0.739370266 -0.12160048 -0.1957416737 -0.278669842 -0.56795532
## Vitamin.C        -0.044575912 -0.31698263 -0.2545161911 -0.905066399  0.11666756
## 
## $cor
##                         Dim.1       Dim.2         Dim.3        Dim.4       Dim.5
## Glucose          -0.572454497  0.31123036  0.0263849025 -0.208332016 -0.72892600
## Fructose         -0.561054870  0.31451133 -0.0084203081 -0.181973281 -0.74371694
## Saccharose        0.750440168  0.14492075  0.3246761207 -0.075192796  0.55205886
## Sweetening.power  0.300767457  0.67471255  0.4895557731 -0.389880490 -0.25026037
## pH                0.879663611 -0.23629707  0.1935892274  0.245926101  0.26907097
## Citric.acid      -0.739370266 -0.12160048 -0.1957416737 -0.278669842 -0.56795532
## Vitamin.C        -0.044575912 -0.31698263 -0.2545161911 -0.905066399  0.11666756
## 
## $cos2
##                         Dim.1       Dim.2          Dim.3        Dim.4       Dim.5
## Glucose          0.3277041510 0.096864337 0.000696163079 0.0434022288 0.531333120
## Fructose         0.3147825674 0.098917374 0.000070901589 0.0331142749 0.553114882
## Saccharose       0.5631604458 0.021002025 0.105414583332 0.0056539566 0.304768989
## Sweetening.power 0.0904610632 0.455237031 0.239664854983 0.1520067964 0.062630255
## pH               0.7738080690 0.055836307 0.037476788962 0.0604796473 0.072399188
## Citric.acid      0.5466683910 0.014786677 0.038314802810 0.0776568810 0.322573248
## Vitamin.C        0.0019870119 0.100477991 0.064778491512 0.8191451868 0.013611319</code></pre>
<p>然後用下面的代碼繪製包含了輔助性變量的變量相關圓盤圖：</p>
<div class="sourceCode" id="cb1008"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1008-1" title="1"><span class="kw">fviz_pca_var</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAvarsuppplot"></span>
<img src="bookdown_files/figure-html/PCAvarsuppplot-1.png" alt="Orange juice data: representation of the active and supplementary variables (in blue)." width="90%" />
<p class="caption">
圖 68.10: Orange juice data: representation of the active and supplementary variables (in blue).
</p>
</div>
<p>如圖 <a href="10-Hierarchical-models.html#fig:PCAvarsuppplot">68.10</a> 所示，第一個主成分變量分離的左右半球的橙汁味道特徵，和他們的物理特性其實是相呼應的。例如，<code>pH</code> 值出現在了圓盤的右半邊，靠近 <code>Sweetness</code> 這一變量。因爲 <code>pH</code> 越高，酸度越低，那麼味道也就越甜，這是合理的。另外一個有趣的現象是，蔗糖 <code>saccharose</code> 含量高的橙汁，<code>pH</code> 越高，味道越甜。在圓盤的左邊，是蔗糖在酸環境下分解之後產生的果糖和葡萄糖，所以果糖葡萄糖反而和酸度 <code>Acidity</code> 相關性高，因爲橙汁中果糖葡萄糖含量高意味着蔗糖被酸分解。</p>
<p>由此可見，PCA是一個對數據進行初步描述和探索時十分有力的工具。所以，在回歸模型選擇變量之前，建議可以對數據先進行主成分分析，並且把預備考慮放在回歸模型的解釋變量部分的變量用於PCA主成分分析，把想要做預測的變量作爲輔助性變量投射到主成分分析的變量相關圖中，觀察解釋變量之間可能存在的相關性，有助於選取合適的解釋變量。</p>
<div id="展示分類輔助性變量和個體的關係" class="section level3">
<h3><span class="header-section-number">68.5.1</span> 展示分類輔助性變量和個體的關係</h3>
<p>根據不同的儲存方式，兩類的橙汁區別很清楚。</p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1009-1" title="1">p &lt;-<span class="st"> </span><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">habillage =</span> <span class="dv">15</span>, </a>
<a class="sourceLine" id="cb1009-2" title="2">             <span class="dt">palette =</span> <span class="st">&quot;jco&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1009-3" title="3">p</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAindplotsupp"></span>
<img src="bookdown_files/figure-html/PCAindplotsupp-1.png" alt="Plane representation of the scatterplot of individuals with a supplementary categorical variable (way of preserving)." width="70%" />
<p class="caption">
圖 68.11: Plane representation of the scatterplot of individuals with a supplementary categorical variable (way of preserving).
</p>
</div>
<p>根據橙子的產地區分繪製的個人圖：</p>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1010-1" title="1">p &lt;-<span class="st"> </span><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">habillage =</span> <span class="dv">16</span>, </a>
<a class="sourceLine" id="cb1010-2" title="2">             <span class="dt">palette =</span> <span class="st">&quot;jco&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1010-3" title="3">p</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAindplotsupp2"></span>
<img src="bookdown_files/figure-html/PCAindplotsupp2-1.png" alt="Plane representation of the scatterplot of individuals with a supplementary categorical variable (origin)." width="70%" />
<p class="caption">
圖 68.12: Plane representation of the scatterplot of individuals with a supplementary categorical variable (origin).
</p>
</div>
</div>
</div>
<div id="cluster-analysispca-practical" class="section level2">
<h2><span class="header-section-number">68.6</span> Cluster analysis/PCA practical</h2>
<p>本次練習完成時，你將學會：</p>
<ol style="list-style-type: decimal">
<li>如何使用聚類分析，和主成分分析法來探索一組多變量數據之間的關係；</li>
<li>理解並懂得如何選取合適的距離測量尺度，和聚類分析方法；</li>
<li>繪製並能夠解釋由多層聚類分析算法 (hierarchical clustering algorithm) 獲得的樹狀圖；</li>
<li>使用主成分分析法對數據進行座標轉換，計算多個變量之間的方差，協方差矩陣，懂得如何判斷保留主成分的個數；</li>
<li>通過把數據繪製在較低維度的主成分座標軸上來判斷數據中可能存在的潛在分層/分組。</li>
</ol>
<div id="使用的數據和簡單背景知識" class="section level3">
<h3><span class="header-section-number">68.6.1</span> 使用的數據和簡單背景知識</h3>
<p>假設你是一名生物測量技術公司的統計師，現在有這樣一組數據，包含了對某植物測量的4種生物標幟物(biomarkers)。據報道，這四種成分或許能減少你公司生產的某藥物引起的副作用。爲了嘗試分析該植物的生物特性，從該植物的50個不同樣本中，測量了這4種生物標幟物的濃度。你的任務之一是對數據進行初步分析，彙報任何你找到的可能存在的顯著特徵差異。</p>
<ol style="list-style-type: decimal">
<li>在R裏讀入你的數據，看看這4種生物標幟物的簡單統計量和分佈，它們用的是相同的測量單位嗎？</li>
</ol>
<div class="sourceCode" id="cb1011"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1011-1" title="1">plant &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/plant.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1011-2" title="2">plant &lt;-<span class="st"> </span>plant[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]</a>
<a class="sourceLine" id="cb1011-3" title="3"><span class="kw">head</span>(plant)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##       bm1     bm2     bm3     bm4
##     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1  17.4    78.6   101.    109.   
## 2  87      30.1    79.1     6.60 
## 3   0.100   0.600   0.900   0.200
## 4 106      10      44.6    57.6  
## 5 141.    122     115.    123.   
## 6   0.5     0.800   0.200   0.5</code></pre>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1013-1" title="1"><span class="kw">summ</span>(plant)</a></code></pre></div>
<pre><code>## 
## No. of observations = 50
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 bm1       50   56.6   47.55   48.05  0      143   
## 2 bm2       50   53.21  52.7    45.13  0      143.6 
## 3 bm3       50   61.43  55.25   51.47  0.2    147.9 
## 4 bm4       50   57.43  56.75   45.45  0.1    146.1</code></pre>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1015-1" title="1">psych<span class="op">::</span><span class="kw">describe</span>(plant)</a></code></pre></div>
<pre><code>##     vars  n  mean    sd median trimmed   mad min   max range skew kurtosis   se
## bm1    1 50 56.60 48.05  47.55   53.36 66.05 0.0 143.0 143.0 0.27    -1.38 6.80
## bm2    2 50 53.21 45.13  52.70   49.62 59.45 0.0 143.6 143.6 0.43    -1.07 6.38
## bm3    3 50 61.43 51.47  55.25   58.86 69.76 0.2 147.9 147.7 0.27    -1.47 7.28
## bm4    4 50 57.43 45.45  56.75   54.71 52.41 0.1 146.1 146.0 0.32    -1.12 6.43</code></pre>
<p>觀察這四個生物標幟物的簡單統計量，似乎可以認爲它們使用的應該是相似或者相同的測量單位。它們的均值在53至61之間，標準差分佈在45-51之間，而且最大值最小值之間的範圍也十分接近。</p>
<ol start="2" style="list-style-type: decimal">
<li>這些生物標幟物能否單獨提供關於該植物的某部分特徵信息呢？思考我們該如何回答這個問題（提示：計算這些指標直接的相關係數）</li>
</ol>
<p>我們可以通過計算這四個生物標幟物濃度測量值之間的相關係數，來觀察它們之間是否具有相似性或者是否提供了部分相似的信息。</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1017-1" title="1"><span class="kw">cor</span>(plant)</a></code></pre></div>
<pre><code>##            bm1        bm2        bm3        bm4
## bm1 1.00000000 0.49826220 0.59414820 0.26769269
## bm2 0.49826220 1.00000000 0.50574946 0.33347350
## bm3 0.59414820 0.50574946 1.00000000 0.32094816
## bm4 0.26769269 0.33347350 0.32094816 1.00000000</code></pre>
<p>從相關係數矩陣的計算結果來看，平均地，這四個生物標幟物濃度之間具有一定程度的相關性。其中，生物標幟物1和3之間呈現了四者之間最高的樣本相關係數 <span class="math inline">\((r_{13} = 0.5941)\)</span>，生物標幟物1和4之間的相關係數則最小 <span class="math inline">\((r_{14} = 0.2677)\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>請描述前一步中我們計算的相關係數矩陣的維度(dimension)。</li>
</ol>
<p>該相關係數矩陣的維度是 <span class="math inline">\(4\times4\)</span>，事實上，這個矩陣的維度是由我們想要觀察分析的樣本中測量變量的個數決定的（在這裏就是四個生物標幟物）。但是這個相關係數的矩陣並不適合用於做聚類分析 (cluster analysis)，因爲相關係數本身反映的是變量之間的關係 (between variables)，並非觀察對象 (between subjects) 之間的距離(即，不是我們關心的用來把50個樣本進行分組歸類的距離變量)。</p>
<ol start="4" style="list-style-type: decimal">
<li>再次思考問題1.的答案，思考並選擇合適的測量不同樣本個體之間距離 (distance) 的度量衡。嘗試使用簡單的聚類分析命令對樣本進行分類。</li>
</ol>
<p>由於每個生物標記物在所有樣本中的數值基本在相似的比例或者刻度，每個標幟物在這個樣本中的標準差/方差數值也較爲相近。我們嘗試用連續變量最常見的均值測量距離指標:</p>
<div class="sourceCode" id="cb1019"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1019-1" title="1"><span class="co"># prepare hierarchical cluster</span></a>
<a class="sourceLine" id="cb1019-2" title="2">hc &lt;-<span class="st">  </span><span class="kw">hclust</span>(<span class="kw">dist</span>(plant), <span class="st">&quot;ave&quot;</span>)</a>
<a class="sourceLine" id="cb1019-3" title="3"></a>
<a class="sourceLine" id="cb1019-4" title="4"></a>
<a class="sourceLine" id="cb1019-5" title="5"><span class="kw">plot</span>(hc, <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1019-6" title="6">     <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L2 dissimilarity measure&quot;</span>, </a>
<a class="sourceLine" id="cb1019-7" title="7">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-3"></span>
<img src="bookdown_files/figure-html/pca-3-1.png" alt="Dendrogram for L2_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.13: Dendrogram for L2_avlink cluster analysis
</p>
</div>
<p>可以觀察到，樣本編號 31, 27, 17, 48, 8, 30, 3, 14, 6, 42 很快就聚合成爲一組。且這些樣本和其他樣本被聚類在不同組的過程一直維持到差異性達到100以上。我們還可以注意到，聚類過程中其他的分支呈現相對對稱的形狀。</p>
<ol start="5" style="list-style-type: decimal">
<li>從簡單的歐幾里得距離改成歐幾里得距離平方來測量樣本之間的距離的話，圖形會變成什麼樣？</li>
</ol>
<div class="sourceCode" id="cb1020"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1020-1" title="1">hc &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">dist</span>(plant)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1020-2" title="2"></a>
<a class="sourceLine" id="cb1020-3" title="3"><span class="kw">plot</span>(hc, <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1020-4" title="4">     <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L2squared dissimilarity measure&quot;</span>, </a>
<a class="sourceLine" id="cb1020-5" title="5">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>, <span class="dt">sub =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-4"></span>
<img src="bookdown_files/figure-html/pca-4-1.png" alt="Dendrogram for L2sq_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.14: Dendrogram for L2sq_avlink cluster analysis
</p>
</div>
<p>當使用歐幾里得距離的平方作爲樣本間隔的度量衡時，我們發現聚類的過程其實總體來說和使用歐幾里得距離本身並無本質上的區別。只是在差異性較低的地方聚類加速 (squeeze the dissimilarities at the lower end)，並且在較大的聚類區分之間變得更加明顯，視覺效果上更容易區分。</p>
<p>如果說，不用歐幾里得平方，而是使用簡單的曼哈頓距離 (L1 度量衡)，那麼圖形則又會呈現爲:</p>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1021-1" title="1"><span class="kw">plot</span>(cluster<span class="op">::</span><span class="kw">agnes</span>(plant, <span class="dt">metric =</span> <span class="st">&quot;manhattan&quot;</span>, <span class="dt">stand =</span> F), <span class="dt">which.plots =</span> <span class="dv">2</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1021-2" title="2">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L1 dissimilarity measure&quot;</span>, <span class="dt">sub =</span> <span class="st">&quot;&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-5"></span>
<img src="bookdown_files/figure-html/pca-5-1.png" alt="Dendrogram for L1_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.15: Dendrogram for L1_avlink cluster analysis
</p>
</div>
<p>可以看出，當使用曼哈頓距離做度量衡時，聚類的過程和之前的沒有本質上的區別，但是圖形的樹狀分支上似乎不再左右對稱。</p>
<ol start="6" style="list-style-type: decimal">
<li>接下來使用歐幾里得距離做度量衡，與上面的嘗試不同，這裏我們嘗試用完全連接，和單連接</li>
</ol>
</div>
</div>
</div>
<div id="missing-data-2" class="section level1">
<h1><span class="header-section-number">第 69 章</span> Missing data 2</h1>
</div>
<div id="further-issues" class="section level1">
<h1><span class="header-section-number">第 70 章</span> Further issues</h1>

</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Bland1986">
<p>Bland, J Martin, and DouglasG Altman. 1986. “Statistical Methods for Assessing Agreement Between Two Methods of Clinical Measurement.” <em>The Lancet</em> 327 (8476): 307–10.</p>
</div>
<div id="ref-Gower1971">
<p>Gower, John C. 1971. “A General Coefficient of Similarity and Some of Its Properties.” <em>Biometrics</em>, 857–71.</p>
</div>
<div id="ref-Mann2004">
<p>Mann, Vera, Bianca L De Stavola, and David A Leon. 2004. “Separating Within and Between Effects in Family Studies: An Application to the Study of Blood Pressure in Children.” <em>Statistics in Medicine</em> 23 (17): 2745–56.</p>
</div>
<div id="ref-Raudenbush2002">
<p>Raudenbush, Stephen W, and Anthony S Bryk. 2002. <em>Hierarchical Linear Models: Applications and Data Analysis Methods</em>. Vol. 1. Sage.</p>
</div>
<div id="ref-Robinson1950">
<p>Robinson, W. S. 1950. “Ecological Correlations and the Behavior of Individuals.” <em>American Sociological Review</em> 15 (3): 351–57. <a href="http://www.jstor.org/stable/2087176">http://www.jstor.org/stable/2087176</a>.</p>
</div>
<div id="ref-Snijders1999">
<p>Snijders, Tom, and Roel Bosker. 1999. “Multilevel Analysis: An Introduction to Basic and Applied Multilevel Analysis.” London: Sage.</p>
</div>
<div id="ref-Verbeke1997">
<p>Verbeke, Geert. 1997. <em>Linear Mixed Models for Longitudinal Data</em>. Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="09-GLM.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-Survival-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook/js/app.min.js"></script>
<script src="assets/gitbook/js/lunr.js"></script>
<script src="assets/gitbook/js/clipboard.min.js"></script>
<script src="assets/gitbook/js/plugin-search.js"></script>
<script src="assets/gitbook/js/plugin-sharing.js"></script>
<script src="assets/gitbook/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook/js/plugin-bookdown.js"></script>
<script src="assets/gitbook/js/jquery.highlight.js"></script>
<script src="assets/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/10-Hierarchical-models.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
