<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2019-10-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint/kePrint.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path=""><a href="#前言"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path=""><a href="#author"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path=""><a href="#intro"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path=""><a href="#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path=""><a href="#Bayes-Definition"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path=""><a href="#期望-expectation-或均值-or-mean-和-方差-variance"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path=""><a href="#bernoulli"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path=""><a href="#binomial"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path=""><a href="#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path=""><a href="#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path=""><a href="#poisson"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path=""><a href="#正態分佈"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path=""><a href="#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path=""><a href="#正態分佈-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path=""><a href="#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path=""><a href="#CLT"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path=""><a href="#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path=""><a href="#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path=""><a href="#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path=""><a href="#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path=""><a href="#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path=""><a href="#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path=""><a href="#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path=""><a href="#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path=""><a href="#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path=""><a href="#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path=""><a href="#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path=""><a href="#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path=""><a href="#統計推斷的概念"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path=""><a href="#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path=""><a href="#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path=""><a href="#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path=""><a href="#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path=""><a href="#估計和精確度-estimation-and-precision"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path=""><a href="#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path=""><a href="#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path=""><a href="#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path=""><a href="#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path=""><a href="#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path=""><a href="#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path=""><a href="#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path=""><a href="#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path=""><a href="#chi-square-distribution"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path=""><a href="#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path=""><a href="#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path=""><a href="#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path=""><a href="#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path=""><a href="#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path=""><a href="#likelihood-definition"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path=""><a href="#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path=""><a href="#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path=""><a href="#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path=""><a href="#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path=""><a href="#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path=""><a href="#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path=""><a href="#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path=""><a href="#llr"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path=""><a href="#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path=""><a href="#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path=""><a href="#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path=""><a href="#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path=""><a href="#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path=""><a href="#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path=""><a href="#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path=""><a href="#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path=""><a href="#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path=""><a href="#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path=""><a href="#quadratic-llr"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path=""><a href="#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path=""><a href="#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path=""><a href="#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path=""><a href="#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path=""><a href="#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path=""><a href="#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path=""><a href="#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path=""><a href="#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path=""><a href="#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path=""><a href="#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path=""><a href="#假設檢驗的構建-construction-of-a-hypothesis-test"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path=""><a href="#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path=""><a href="#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path=""><a href="#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path=""><a href="#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path=""><a href="#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path=""><a href="#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path=""><a href="#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path=""><a href="#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path=""><a href="#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path=""><a href="#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path=""><a href="#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path=""><a href="#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path=""><a href="#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path=""><a href="#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path=""><a href="#假設檢驗的近似方法"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path=""><a href="#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path=""><a href="#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path=""><a href="#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path=""><a href="#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path=""><a href="#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path=""><a href="#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path=""><a href="#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path=""><a href="#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path=""><a href="#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path=""><a href="#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path=""><a href="#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path=""><a href="#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path=""><a href="#正態誤差模型-normal-error-models"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path=""><a href="#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path=""><a href="#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path=""><a href="#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path=""><a href="#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path=""><a href="#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path=""><a href="#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path=""><a href="#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path=""><a href="#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path=""><a href="#多個參數時的統計推斷-inference-with-multiple-parameters-i"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path=""><a href="#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path=""><a href="#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path=""><a href="#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path=""><a href="#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path=""><a href="#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path=""><a href="#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path=""><a href="#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path=""><a href="#profile-log-likelihood"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path=""><a href="#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path=""><a href="#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path=""><a href="#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path=""><a href="#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path=""><a href="#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path=""><a href="#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path=""><a href="#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path=""><a href="#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path=""><a href="#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path=""><a href="#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path=""><a href="#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path=""><a href="#探索數據和簡單描述"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path=""><a href="#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path=""><a href="#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path=""><a href="#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path=""><a href="#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path=""><a href="#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path=""><a href="#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path=""><a href="#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path=""><a href="#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path=""><a href="#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path=""><a href="#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path=""><a href="#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path=""><a href="#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path=""><a href="#信賴區間-confidence-intervals-1"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path=""><a href="#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path=""><a href="#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path=""><a href="#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path=""><a href="#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path=""><a href="#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path=""><a href="#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path=""><a href="#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path=""><a href="#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path=""><a href="#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path=""><a href="#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path=""><a href="#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path=""><a href="#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path=""><a href="#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path=""><a href="#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path=""><a href="#假設檢驗"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path=""><a href="#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path=""><a href="#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path=""><a href="#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path=""><a href="#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path=""><a href="#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path=""><a href="#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path=""><a href="#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path=""><a href="#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path=""><a href="#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path=""><a href="#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path=""><a href="#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path=""><a href="#相關-association"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path=""><a href="#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path=""><a href="#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path=""><a href="#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path=""><a href="#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path=""><a href="#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path=""><a href="#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path=""><a href="#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path=""><a href="#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path=""><a href="#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path=""><a href="#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path=""><a href="#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path=""><a href="#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path=""><a href="#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path=""><a href="#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path=""><a href="#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path=""><a href="#比較-comparisons"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path=""><a href="#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path=""><a href="#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path=""><a href="#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path=""><a href="#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path=""><a href="#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path=""><a href="#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path=""><a href="#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path=""><a href="#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path=""><a href="#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path=""><a href="#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path=""><a href="#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path=""><a href="#前提和數據轉換-assumptions-and-transformations"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path=""><a href="#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path=""><a href="#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path=""><a href="#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path=""><a href="#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path=""><a href="#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path=""><a href="#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path=""><a href="#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path=""><a href="#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path=""><a href="#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path=""><a href="#lm"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path=""><a href="#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path=""><a href="#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path=""><a href="#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path=""><a href="#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path=""><a href="#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path=""><a href="#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path=""><a href="#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path=""><a href="#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path=""><a href="#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path=""><a href="#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path=""><a href="#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path=""><a href="#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path=""><a href="#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path=""><a href="#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path=""><a href="#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path=""><a href="#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path=""><a href="#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path=""><a href="#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path=""><a href="#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path=""><a href="#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path=""><a href="#最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path=""><a href="#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path=""><a href="#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path=""><a href="#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path=""><a href="#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path=""><a href="#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path=""><a href="#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path=""><a href="#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path=""><a href="#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path=""><a href="#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path=""><a href="#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path=""><a href="#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path=""><a href="#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path=""><a href="#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path=""><a href="#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path=""><a href="#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path=""><a href="#ANOVA"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path=""><a href="#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path=""><a href="#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path=""><a href="#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path=""><a href="#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path=""><a href="#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path=""><a href="#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path=""><a href="#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path=""><a href="#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path=""><a href="#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path=""><a href="#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path=""><a href="#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path=""><a href="#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path=""><a href="#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path=""><a href="#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path=""><a href="#多元模型分析-multivariable-models"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path=""><a href="#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path=""><a href="#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path=""><a href="#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path=""><a href="#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path=""><a href="#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path=""><a href="#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path=""><a href="#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path=""><a href="#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path=""><a href="#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path=""><a href="#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path=""><a href="#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path=""><a href="#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path=""><a href="#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path=""><a href="#多元模型分析矩陣標記與其意義"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path=""><a href="#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path=""><a href="#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path=""><a href="#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path=""><a href="#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path=""><a href="#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path=""><a href="#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path=""><a href="#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path=""><a href="#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path=""><a href="#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path=""><a href="#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path=""><a href="#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path=""><a href="#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path=""><a href="#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path=""><a href="#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path=""><a href="#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path=""><a href="#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path=""><a href="#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path=""><a href="#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path=""><a href="#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path=""><a href="#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path=""><a href="#線性迴歸的模型診斷"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path=""><a href="#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path=""><a href="#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path=""><a href="#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path=""><a href="#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path=""><a href="#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path=""><a href="#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path=""><a href="#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path=""><a href="#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path=""><a href="#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path=""><a href="#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path=""><a href="#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path=""><a href="#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path=""><a href="#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path=""><a href="#interaction"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path=""><a href="#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path=""><a href="#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path=""><a href="#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path=""><a href="#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path=""><a href="#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path=""><a href="#sample-size"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path=""><a href="#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path=""><a href="#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path=""><a href="#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path=""><a href="#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path=""><a href="#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path=""><a href="#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path=""><a href="#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path=""><a href="#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path=""><a href="#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path=""><a href="#baseline-adjustment-using-ancova"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path=""><a href="#穩健統計方法入門"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path=""><a href="#基於秩次的非參數檢驗"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path=""><a href="#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path=""><a href="#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path=""><a href="#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path=""><a href="#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path=""><a href="#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path=""><a href="#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path=""><a href="#排列置換法-permutation-procedures"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path=""><a href="#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path=""><a href="#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path=""><a href="#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path=""><a href="#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path=""><a href="#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path=""><a href="#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path=""><a href="#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path=""><a href="#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path=""><a href="#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path=""><a href="#自助重抽法-the-bootstrap"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path=""><a href="#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path=""><a href="#the-sandwich-estimator"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path=""><a href="#intro-Bayes"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path=""><a href="#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path=""><a href="#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path=""><a href="#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path=""><a href="#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path=""><a href="#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path=""><a href="#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path=""><a href="#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path=""><a href="#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path=""><a href="#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path=""><a href="#貝葉斯定理的應用單一參數模型"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path=""><a href="#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path=""><a href="#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path=""><a href="#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path=""><a href="#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path=""><a href="#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path=""><a href="#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path=""><a href="#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path=""><a href="#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path=""><a href="#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path=""><a href="#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path=""><a href="#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path=""><a href="#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path=""><a href="#貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path=""><a href="#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path=""><a href="#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path=""><a href="#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path=""><a href="#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path=""><a href="#重要概念複習"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path=""><a href="#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path=""><a href="#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path=""><a href="#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path=""><a href="#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path=""><a href="#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path=""><a href="#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path=""><a href="#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path=""><a href="#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path=""><a href="#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path=""><a href="#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path=""><a href="#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path=""><a href="#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path=""><a href="#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path=""><a href="#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path=""><a href="#廣義線性迴歸入門"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path=""><a href="#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path=""><a href="#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path=""><a href="#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path=""><a href="#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path=""><a href="#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path=""><a href="#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path=""><a href="#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path=""><a href="#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path=""><a href="#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path=""><a href="#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path=""><a href="#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path=""><a href="#二項分佈數據的廣義線性迴歸模型-logistic-regression-model"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path=""><a href="#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path=""><a href="#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path=""><a href="#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path=""><a href="#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path=""><a href="#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path=""><a href="#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path=""><a href="#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path=""><a href="#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path=""><a href="#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path=""><a href="#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path=""><a href="#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path=""><a href="#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path=""><a href="#模型比較和擬合優度"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path=""><a href="#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path=""><a href="#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path=""><a href="#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path=""><a href="#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path=""><a href="#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path=""><a href="#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path=""><a href="#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path=""><a href="#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path=""><a href="#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path=""><a href="#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path=""><a href="#計數型因變量-poisson-regression"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path=""><a href="#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path=""><a href="#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path=""><a href="#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path=""><a href="#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path=""><a href="#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path=""><a href="#率的廣義線性迴歸-poisson-glm-for-rates"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path=""><a href="#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path=""><a href="#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path=""><a href="#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path=""><a href="#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path=""><a href="#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path=""><a href="#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path=""><a href="#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path=""><a href="#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path=""><a href="#混雜的調整交互作用和模型的可壓縮性"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path=""><a href="#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path=""><a href="#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path=""><a href="#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path=""><a href="#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path=""><a href="#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path=""><a href="#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path=""><a href="#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path=""><a href="#流行病學中的邏輯迴歸"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path=""><a href="#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path=""><a href="#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path=""><a href="#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path=""><a href="#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path=""><a href="#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path=""><a href="#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path=""><a href="#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path=""><a href="#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path=""><a href="#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path=""><a href="#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path=""><a href="#分析策略"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path=""><a href="#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path=""><a href="#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path=""><a href="#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path=""><a href="#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path=""><a href="#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path=""><a href="#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path=""><a href="#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path=""><a href="#檢查你的模型-model-checking---glm"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path=""><a href="#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path=""><a href="#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path=""><a href="#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path=""><a href="#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path=""><a href="#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path=""><a href="#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path=""><a href="#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path=""><a href="#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path=""><a href="#評價模型的表現-assessing-model-performance"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path=""><a href="#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path=""><a href="#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path=""><a href="#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path=""><a href="#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path=""><a href="#配對實驗數據的分析法"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path=""><a href="#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path=""><a href="#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path=""><a href="#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path=""><a href="#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path=""><a href="#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path=""><a href="#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path=""><a href="#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path=""><a href="#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path=""><a href="#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path=""><a href="#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path=""><a href="#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path=""><a href="#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path=""><a href="#條件邏輯迴歸-conditional-logistic-regression"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path=""><a href="#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path=""><a href="#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path=""><a href="#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path=""><a href="#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path=""><a href="#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path=""><a href="#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path=""><a href="#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path=""><a href="#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path=""><a href="#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path=""><a href="#multinomial-logistic-regression"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path=""><a href="#ordinal-logistic-regression"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path=""><a href="#Hierarchical"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path=""><a href="#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path=""><a href="#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path=""><a href="#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path=""><a href="#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path=""><a href="#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path=""><a href="#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path=""><a href="#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path=""><a href="#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path=""><a href="#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path=""><a href="#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path=""><a href="#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path=""><a href="#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path=""><a href="#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path=""><a href="#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path=""><a href="#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path=""><a href="#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path=""><a href="#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path=""><a href="#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path=""><a href="#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path=""><a href="#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path=""><a href="#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path=""><a href="#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path=""><a href="#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path=""><a href="#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path=""><a href="#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path=""><a href="#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path=""><a href="#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path=""><a href="#隨機截距模型-random-intercept-model"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path=""><a href="#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path=""><a href="#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path=""><a href="#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path=""><a href="#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path=""><a href="#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path=""><a href="#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path=""><a href="#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path=""><a href="#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path=""><a href="#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path=""><a href="#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path=""><a href="#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path=""><a href="#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path=""><a href="#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path=""><a href="#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path=""><a href="#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path=""><a href="#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path=""><a href="#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path=""><a href="#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path=""><a href="#隨機截距模型中加入共變量-random-intercept-model-with-covariates"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path=""><a href="#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path=""><a href="#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path=""><a href="#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path=""><a href="#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path=""><a href="#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path=""><a href="#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path=""><a href="#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path=""><a href="#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path=""><a href="#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path=""><a href="#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path=""><a href="#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path=""><a href="#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path=""><a href="#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path=""><a href="#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path=""><a href="#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path=""><a href="#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path=""><a href="#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path=""><a href="#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path=""><a href="#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path=""><a href="#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path=""><a href="#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path=""><a href="#隨機回歸系數模型-random-coefficient-model"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path=""><a href="#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path=""><a href="#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path=""><a href="#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path=""><a href="#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path=""><a href="#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path=""><a href="#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path=""><a href="#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path=""><a href="#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.2" data-path=""><a href="#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.3" data-path=""><a href="#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.4" data-path=""><a href="#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.5" data-path=""><a href="#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.6" data-path=""><a href="#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.7" data-path=""><a href="#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.8" data-path=""><a href="#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.9" data-path=""><a href="#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.10" data-path=""><a href="#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.11" data-path=""><a href="#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path=""><a href="#縱向研究數據-longitudinal-data-1"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path=""><a href="#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path=""><a href="#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path=""><a href="#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path=""><a href="#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path=""><a href="#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path=""><a href="#縱向研究數據-longitudinal-data-2"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path=""><a href="#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path=""><a href="#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path=""><a href="#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path=""><a href="#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path=""><a href="#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path=""><a href="#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path=""><a href="#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path=""><a href="#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path=""><a href="#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path=""><a href="#縱向研究數據-longitudinal-data-3"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path=""><a href="#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path=""><a href="#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path=""><a href="#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path=""><a href="#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path=""><a href="#generalized-estimating-equation"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path=""><a href="#cluster-analysisunsupervised-learning-聚類分析"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path=""><a href="#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path=""><a href="#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path=""><a href="#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path=""><a href="#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path=""><a href="#missing-data-1"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path=""><a href="#principal-component-analysis-主成分分析"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path=""><a href="#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path=""><a href="#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path=""><a href="#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path=""><a href="#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path=""><a href="#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path=""><a href="#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path=""><a href="#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path=""><a href="#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path=""><a href="#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path=""><a href="#missing-data-2"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path=""><a href="#further-issues"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path=""><a href="#生存分析入門"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path=""><a href="#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path=""><a href="#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path=""><a href="#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path=""><a href="#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path=""><a href="#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path=""><a href="#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path=""><a href="#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path=""><a href="#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path=""><a href="#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path=""><a href="#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path=""><a href="#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path=""><a href="#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path=""><a href="#指數分布"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path=""><a href="#weibull-分布"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path=""><a href="#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path=""><a href="#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path=""><a href="#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path=""><a href="#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path=""><a href="#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path=""><a href="#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path=""><a href="#nonparametric"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path=""><a href="#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path=""><a href="#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path=""><a href="#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path=""><a href="#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path=""><a href="#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path=""><a href="#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path=""><a href="#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path=""><a href="#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path=""><a href="#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path=""><a href="#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path=""><a href="#生存數據中的回歸模型"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path=""><a href="#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path=""><a href="#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path=""><a href="#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path=""><a href="#weibull-分布-1"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path=""><a href="#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path=""><a href="#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path=""><a href="#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path=""><a href="#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path=""><a href="#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path=""><a href="#cox-比例風險模型"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path=""><a href="#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path=""><a href="#分析策略和模型檢查-model-checking-survival-analysis"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path=""><a href="#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path=""><a href="#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path=""><a href="#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path=""><a href="#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path=""><a href="#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path=""><a href="#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path=""><a href="#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path=""><a href="#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path=""><a href="#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path=""><a href="#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path=""><a href="#競爭風險模型-competing-risk"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path=""><a href="#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path=""><a href="#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path=""><a href="#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path=""><a href="#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path=""><a href="#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path=""><a href="#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path=""><a href="#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path=""><a href="#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path=""><a href="#生存分析的其他手段"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path=""><a href="#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path=""><a href="#加速失效模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path=""><a href="#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.1</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path=""><a href="#時間依存變量-time-dependent-variables-和脆弱模型-frailty-model"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path=""><a href="#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path=""><a href="#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path=""><a href="#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path=""><a href="#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path=""><a href="#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path=""><a href="#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path=""><a href="#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path=""><a href="#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path=""><a href="#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path=""><a href="#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path=""><a href="#時間事件數據的高級分析法"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="80" data-path=""><a href="#爲什麼我們要用貝葉斯統計學方法"><i class="fa fa-check"></i><b>80</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="80.1" data-path=""><a href="#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>80.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="80.1.1" data-path=""><a href="#背景資料-ssc-trial"><i class="fa fa-check"></i><b>80.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="80.1.2" data-path=""><a href="#概率論者分析結果"><i class="fa fa-check"></i><b>80.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="80.1.3" data-path=""><a href="#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>80.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="80.2" data-path=""><a href="#example-the-great-trial"><i class="fa fa-check"></i><b>80.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="80.2.1" data-path=""><a href="#background-great-trial"><i class="fa fa-check"></i><b>80.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="80.2.2" data-path=""><a href="#試驗結果"><i class="fa fa-check"></i><b>80.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="80.2.3" data-path=""><a href="#經典統計學分析方法"><i class="fa fa-check"></i><b>80.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="80.2.4" data-path=""><a href="#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>80.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path=""><a href="#MC-estimation"><i class="fa fa-check"></i><b>81</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="81.1" data-path=""><a href="#起源"><i class="fa fa-check"></i><b>81.1</b> 起源</a><ul>
<li class="chapter" data-level="81.1.1" data-path=""><a href="#作出預測"><i class="fa fa-check"></i><b>81.1.1</b> 作出預測</a></li>
<li class="chapter" data-level="81.1.2" data-path=""><a href="#example-新藥表現預測"><i class="fa fa-check"></i><b>81.1.2</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path=""><a href="#蒙特卡羅估計"><i class="fa fa-check"></i><b>81.2</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="81.2.1" data-path=""><a href="#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>81.2.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="81.2.2" data-path=""><a href="#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>81.2.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="81.3" data-path=""><a href="#蒙特卡羅法分析軟件-openbugs"><i class="fa fa-check"></i><b>81.3</b> 蒙特卡羅法分析軟件 OpenBUGS</a><ul>
<li class="chapter" data-level="81.3.1" data-path=""><a href="#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>81.3.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="81.3.2" data-path=""><a href="#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>81.3.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="81.3.3" data-path=""><a href="#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>81.3.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path=""><a href="#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>81.4</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="82" data-path=""><a href="#共軛先驗概率-conjugate-priors"><i class="fa fa-check"></i><b>82</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="82.1" data-path=""><a href="#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>82.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="82.2" data-path=""><a href="#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="82.2.1" data-path=""><a href="#事後概率分布預測"><i class="fa fa-check"></i><b>82.2.1</b> 事後概率分布預測</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="83" data-path=""><a href="#step-1-check-model"><i class="fa fa-check"></i><b>83</b> Step 1 check model</a><ul>
<li class="chapter" data-level="83.1" data-path=""><a href="#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>83.1</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="83.2" data-path=""><a href="#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>83.2</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="83.3" data-path=""><a href="#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>83.3</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="83.4" data-path=""><a href="#BayesPrac03"><i class="fa fa-check"></i><b>83.4</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path=""><a href="#step-1-check-model-1"><i class="fa fa-check"></i><b>84</b> Step 1 check model</a></li>
<li class="chapter" data-level="85" data-path=""><a href="#generate-10000-iterations"><i class="fa fa-check"></i><b>85</b> Generate 10000 iterations</a></li>
<li class="chapter" data-level="86" data-path=""><a href="#step-1-check-model-2"><i class="fa fa-check"></i><b>86</b> Step 1 check model</a></li>
<li class="chapter" data-level="87" data-path=""><a href="#generate-10000-iterations-1"><i class="fa fa-check"></i><b>87</b> Generate 10000 iterations</a></li>
<li class="chapter" data-level="88" data-path=""><a href="#thm-model"><i class="fa fa-check"></i><b>88</b> THM model:</a></li>
<li class="chapter" data-level="89" data-path=""><a href="#informative-prior"><i class="fa fa-check"></i><b>89</b> informative prior</a></li>
<li class="chapter" data-level="90" data-path=""><a href="#vague-prior"><i class="fa fa-check"></i><b>90</b> vague prior</a></li>
<li class="chapter" data-level="91" data-path=""><a href="#theta-dnorm0-0.000001"><i class="fa fa-check"></i><b>91</b> theta ~ dnorm(0, 0.000001)</a></li>
<li class="chapter" data-level="92" data-path=""><a href="#or"><i class="fa fa-check"></i><b>92</b> OR</a></li>
<li class="chapter" data-level="93" data-path=""><a href="#theta-dunif-10000-10000"><i class="fa fa-check"></i><b>93</b> theta ~ dunif(-10000, 10000)</a></li>
<li class="chapter" data-level="94" data-path=""><a href="#step-1-check-model-3"><i class="fa fa-check"></i><b>94</b> Step 1 check model</a></li>
<li class="chapter" data-level="95" data-path=""><a href="#compile-the-model"><i class="fa fa-check"></i><b>95</b> compile the model</a></li>
<li class="chapter" data-level="96" data-path=""><a href="#generate-10000-iterations-2"><i class="fa fa-check"></i><b>96</b> Generate 10000 iterations</a></li>
<li class="chapter" data-level="97" data-path=""><a href="#is-relative-risk-1"><i class="fa fa-check"></i><b>97</b> Is relative risk &gt; 1</a></li>
<li class="chapter" data-level="98" data-path=""><a href="#step-1-check-model-4"><i class="fa fa-check"></i><b>98</b> Step 1 check model</a></li>
<li class="chapter" data-level="99" data-path=""><a href="#compile-the-model-1"><i class="fa fa-check"></i><b>99</b> compile the model</a></li>
<li class="chapter" data-level="100" data-path=""><a href="#generate-10000-iterations-3"><i class="fa fa-check"></i><b>100</b> Generate 10000 iterations</a></li>
<li class="chapter" data-level="101" data-path=""><a href="#step-1-check-model-5"><i class="fa fa-check"></i><b>101</b> Step 1 check model</a></li>
<li class="chapter" data-level="102" data-path=""><a href="#compile-the-model-2"><i class="fa fa-check"></i><b>102</b> compile the model</a></li>
<li class="chapter" data-level="103" data-path=""><a href="#generate-100000-iterations"><i class="fa fa-check"></i><b>103</b> Generate 100000 iterations</a></li>
<li class="chapter" data-level="104" data-path=""><a href="#original-conjugate-drug-model-with-uniform-beta01-prior-on-theta"><i class="fa fa-check"></i><b>104</b> original conjugate drug model with uniform beta(0,1) prior on theta</a></li>
<li class="chapter" data-level="105" data-path=""><a href="#建模和模型的檢查"><i class="fa fa-check"></i><b>105</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="105.1" data-path=""><a href="#BayesianLM"><i class="fa fa-check"></i><b>105.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="105.2" data-path=""><a href="#children-in-the-gambia"><i class="fa fa-check"></i><b>105.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="105.2.1" data-path=""><a href="#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>105.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="105.2.2" data-path=""><a href="#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>105.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="105.2.3" data-path=""><a href="#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>105.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="105.2.4" data-path=""><a href="#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>105.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="105.2.5" data-path=""><a href="#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>105.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="105.2.6" data-path=""><a href="#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>105.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="105.2.7" data-path=""><a href="#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>105.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="105.2.8" data-path=""><a href="#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>105.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="105.2.9" data-path=""><a href="#tdreplacegaussian"><i class="fa fa-check"></i><b>105.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="105.3" data-path=""><a href="#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>105.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="105.3.1" data-path=""><a href="#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>105.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="105.3.2" data-path=""><a href="#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>105.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="105.4" data-path=""><a href="#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>105.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="105.4.1" data-path=""><a href="#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>105.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="105.4.2" data-path=""><a href="#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>105.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="106" data-path=""><a href="#不同實驗研究設計時適用的貝葉斯模型"><i class="fa fa-check"></i><b>106</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="106.1" data-path=""><a href="#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>106.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="106.2" data-path=""><a href="#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>106.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="106.3" data-path=""><a href="#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>106.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="106.4" data-path=""><a href="#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>106.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="106.4.1" data-path=""><a href="#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>106.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="106.5" data-path=""><a href="#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>106.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="106.5.1" data-path=""><a href="#the-great-trial"><i class="fa fa-check"></i><b>106.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="106.5.2" data-path=""><a href="#吸煙與癌症"><i class="fa fa-check"></i><b>106.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="107" data-path=""><a href="#貝葉斯廣義線性回歸"><i class="fa fa-check"></i><b>107</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="107.1" data-path=""><a href="#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>107.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="107.1.1" data-path=""><a href="#啞變量的數據矩陣"><i class="fa fa-check"></i><b>107.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="107.1.2" data-path=""><a href="#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>107.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="107.2" data-path=""><a href="#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>107.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="107.2.1" data-path=""><a href="#低出生體重數據-1"><i class="fa fa-check"></i><b>107.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="107.3" data-path=""><a href="#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>107.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="107.4" data-path=""><a href="#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>107.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="107.5" data-path=""><a href="#Bayesian-practical07"><i class="fa fa-check"></i><b>107.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="108" data-path=""><a href="#貝葉斯等級回歸模型"><i class="fa fa-check"></i><b>108</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="108.1" data-path=""><a href="#關於等級迴歸模型"><i class="fa fa-check"></i><b>108.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="108.2" data-path=""><a href="#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>108.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="108.2.1" data-path=""><a href="#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>108.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="108.2.2" data-path=""><a href="#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>108.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="108.2.3" data-path=""><a href="#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>108.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="108.3" data-path=""><a href="#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>108.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="108.3.1" data-path=""><a href="#縱向數據"><i class="fa fa-check"></i><b>108.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="108.3.2" data-path=""><a href="#hamd-example"><i class="fa fa-check"></i><b>108.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="108.3.3" data-path=""><a href="#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>108.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="108.3.4" data-path=""><a href="#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>108.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="108.3.5" data-path=""><a href="#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>108.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="108.3.6" data-path=""><a href="#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>108.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="108.3.7" data-path=""><a href="#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>108.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="108.4" data-path=""><a href="#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>108.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="109" data-path=""><a href="#再訪-mcmc"><i class="fa fa-check"></i><b>109</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="109.1" data-path=""><a href="#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>109.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="109.2" data-path=""><a href="#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>109.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="110" data-path=""><a href="#貝葉斯和概率論的比較"><i class="fa fa-check"></i><b>110</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="110.1" data-path=""><a href="#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>110.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="110.2" data-path=""><a href="#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>110.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="110.3" data-path=""><a href="#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>110.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="111" data-path=""><a href="#causal-languages-因果推斷的語法"><i class="fa fa-check"></i><b>111</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="111.1" data-path=""><a href="#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>111.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="111.2" data-path=""><a href="#傳統的統計學方法"><i class="fa fa-check"></i><b>111.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="111.2.1" data-path=""><a href="#初步分析"><i class="fa fa-check"></i><b>111.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="111.2.2" data-path=""><a href="#混雜"><i class="fa fa-check"></i><b>111.2.2</b> 混雜</a></li>
<li class="chapter" data-level="111.2.3" data-path=""><a href="#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>111.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="111.3" data-path=""><a href="#更加正規的方法"><i class="fa fa-check"></i><b>111.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="111.3.1" data-path=""><a href="#因果推斷使用的語言"><i class="fa fa-check"></i><b>111.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="111.3.2" data-path=""><a href="#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>111.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="111.3.3" data-path=""><a href="#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>111.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="111.3.4" data-path=""><a href="#鑑定-identification"><i class="fa fa-check"></i><b>111.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="112" data-path=""><a href="#graphical-models-因果推斷的圖形模型"><i class="fa fa-check"></i><b>112</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="112.1" data-path=""><a href="#統計學中的有向無環圖"><i class="fa fa-check"></i><b>112.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="112.1.1" data-path=""><a href="#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>112.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="112.1.2" data-path=""><a href="#dag-圖的術語"><i class="fa fa-check"></i><b>112.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="112.1.3" data-path=""><a href="#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>112.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="112.1.4" data-path=""><a href="#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>112.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="112.2" data-path=""><a href="#以非對撞銀子爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>112.2</b> 以非對撞銀子爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="112.2.1" data-path=""><a href="#條件的總結"><i class="fa fa-check"></i><b>112.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="112.2.2" data-path=""><a href="#d-分離-d-separation"><i class="fa fa-check"></i><b>112.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="113" data-path=""><a href="#regression-methods-with-continuous-outcomes-結果變量爲連續型變量"><i class="fa fa-check"></i><b>113</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="113.1" data-path=""><a href="#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>113.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="113.2" data-path=""><a href="#鑑定-identification---revision"><i class="fa fa-check"></i><b>113.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="113.2.1" data-path=""><a href="#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>113.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="113.2.2" data-path=""><a href="#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>113.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="113.2.3" data-path=""><a href="#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>113.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="113.3" data-path=""><a href="#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>113.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="113.3.1" data-path=""><a href="#條件因果均值差"><i class="fa fa-check"></i><b>113.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="113.3.2" data-path=""><a href="#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>113.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="113.3.3" data-path=""><a href="#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>113.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="113.3.4" data-path=""><a href="#positivity-非零性"><i class="fa fa-check"></i><b>113.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="113.3.5" data-path=""><a href="#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>113.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="113.4" data-path=""><a href="#practical03---causal-inference"><i class="fa fa-check"></i><b>113.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="114" data-path=""><a href="#regression-methods-with-binary-outcomes-結果變量爲二分類變量"><i class="fa fa-check"></i><b>114</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="114.1" data-path=""><a href="#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>114.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="114.1.1" data-path=""><a href="#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>114.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="114.2" data-path=""><a href="#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>114.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="114.3" data-path=""><a href="#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>114.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="114.3.1" data-path=""><a href="#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>114.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="114.3.2" data-path=""><a href="#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>114.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="114.4" data-path=""><a href="#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>114.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="114.5" data-path=""><a href="#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>114.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="114.6" data-path=""><a href="#practical04---causal-inference"><i class="fa fa-check"></i><b>114.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="114.6.1" data-path=""><a href="#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>114.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="114.6.2" data-path=""><a href="#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>114.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="114.6.3" data-path=""><a href="#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>114.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="114.6.4" data-path=""><a href="#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>114.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="114.6.5" data-path=""><a href="#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>114.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="114.6.6" data-path=""><a href="#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>114.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="114.6.7" data-path=""><a href="#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>114.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="114.6.8" data-path=""><a href="#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>114.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="114.6.9" data-path=""><a href="#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>114.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="114.6.10" data-path=""><a href="#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>114.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="114.6.11" data-path=""><a href="#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>114.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="114.6.12" data-path=""><a href="#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>114.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="115" data-path=""><a href="#prospensity-score-傾向性評分"><i class="fa fa-check"></i><b>115</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="115.0.1" data-path=""><a href="#關於條件可置換性"><i class="fa fa-check"></i><b>115.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="115.1" data-path=""><a href="#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>115.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="115.1.1" data-path=""><a href="#分層法-stratification"><i class="fa fa-check"></i><b>115.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="115.1.2" data-path=""><a href="#配對法-matching"><i class="fa fa-check"></i><b>115.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="115.1.3" data-path=""><a href="#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>115.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="115.2" data-path=""><a href="#practical05---causal-inference"><i class="fa fa-check"></i><b>115.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="115.2.1" data-path=""><a href="#初步熟悉數據內容"><i class="fa fa-check"></i><b>115.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="115.2.2" data-path=""><a href="#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>115.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="115.2.3" data-path=""><a href="#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>115.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="115.2.4" data-path=""><a href="#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>115.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="115.2.5" data-path=""><a href="#用配對法計算-ace"><i class="fa fa-check"></i><b>115.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="115.2.6" data-path=""><a href="#模型校正-ps"><i class="fa fa-check"></i><b>115.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="116" data-path=""><a href="#inverse-probability-weighted-estimation-and-doubly-robust-methods"><i class="fa fa-check"></i><b>116</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="117" data-path=""><a href="#causal-mediation-analysis"><i class="fa fa-check"></i><b>117</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="118" data-path=""><a href="#crude-and-stratified-rate-ratios"><i class="fa fa-check"></i><b>118</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path=""><a href="#references"><i class="fa fa-check"></i>&lt;U+53C2&gt;&lt;U+8003&gt;&lt;U+6587&gt;&lt;U+732E&gt;</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">醫學統計學</h1>
<p class="author"><em>王 超辰 Chaochen Wang</em></p>
<p class="date"><em>2019-10-24</em></p>
</div>
<p><img src="img/cover.jpg" width="100%" /></p>
<div id="前言" class="section level1 unnumbered">
<h1>前言</h1>
<blockquote>
<p>We are drowning in information and starving for knowledge.</p>
<p>— Rutherford D. Roger</p>
</blockquote>
<p><del>尚未想好寫什麼作前言。</del>我只是默默地想留下一些筆記和思考。本書用了兩個 R 包編譯，分別是 <strong>knitr</strong> <span class="citation">(Xie <a href="#ref-xie2015" role="doc-biblioref">2015</a>)</span> 和 <strong>bookdown</strong> <span class="citation">(Xie <a href="#ref-R-bookdown" role="doc-biblioref">2018</a>)</span>。</p>
<p>在開始倒計時離開倫敦的時刻，我再次翻閱這些思考過的，痛苦過的，糾結過的，忐忑過的，這一年的學習筆記，感慨良多。<a href="https://lshtm.ac.uk/">倫敦衛生與熱帶醫學院</a> 曾經是，現在依然還是我魂牽夢繞的學院，它的歷史積澱，它的小巧精緻，在它的樓道里度過的每一天都是那麼的充實而值得感動。這本書不僅僅是我的統計學學習的心路歷程，還傾注了這裡每一位老師，每一個一起奮鬥過的同學，我們的歡聲笑語，我們的喜怒哀樂。如果你的電腦/手機/iPad屏幕上打開了這本書，說明你將要或者已經是我的同仁，如果此生有幸相聚，我一定會敬你一杯。祝你學業有成，和我一起用數據科學解開這個世界的奧秘。為更平等的醫療，為了更自由的人類社會，奮鬥永不停止。</p>

<p class="flushright">
王超辰<br>
2017年9月於倫敦<br>
2018年7月於倫敦衛生與熱帶醫學院
</p>


</div>
<div id="author" class="section level1 unnumbered">
<h1>我是誰</h1>
<p>歡迎參觀我的<a href="https://winterwang.github.io">個人主頁</a>。</p>


</div>



<div id="intro" class="section level1">
<h1><span class="header-section-number">第 1 章</span> 概率論入門：定義與公理</h1>
<blockquote>
<dl>
<dt>Statistics - A subject which most statisticians find difficult but which many physicians are experts on.</dt>
<dd>Stephen S. Senn
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Probability lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/williamson.elizabeth">Elizabeth Williamson</a>.
</div>

<div id="三個概率公理" class="section level2">
<h2><span class="header-section-number">1.1</span> 三個概率公理：</h2>
<ol style="list-style-type: decimal">
<li>對於任意事件 <span class="math inline">\(A\)</span>，它發生的概率 <span class="math inline">\(P(A)\)</span> 滿足這樣的不等式： <span class="math inline">\(0 \leqslant P(A) \leqslant 1\)</span></li>
<li><span class="math inline">\(P(\Omega)=1\)</span> , <span class="math inline">\(\Omega\)</span> 是全樣本空間 (total sample space)</li>
<li>對於互斥（相互獨立）的事件 <span class="math inline">\(A_1, A_2, \dots, A_n\)</span> 有如下的等式關係： <span class="math inline">\(P(A_1\cup A_2 \cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots+P(A_n)\)</span></li>
</ol>
<p>你是不是覺得上面三條公理都是<strong>廢話</strong>。
不用擔心，我也是這麼覺得的。因爲所有人都認同的道理，才能成爲公理 (axiom)，因爲它們是不需要證明的自然而然形成的人人都接受的觀念。<code>(axiom: a saying that is widely accepted on its own merits; its truth is assumed to be self-evident)</code></p>
<p>然而，正是這樣顯而易見的道理，確是拿來建築理論的基石，千萬不能小看了他們。例如，我們看下面這個看似也應該成爲公理的公式，你能證明嗎：</p>
<p><span class="math inline">\(P(A_1\cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)\)</span></p>
<p><img src="img/venngram.png" width="90%" style="display: block; margin: auto;" /></p>
<p><strong>證明：</strong></p>
<p>先考慮 <span class="math inline">\(A_1 \cup A_2\)</span> 是什麼（拆分成三個互斥事件）</p>
<p><span class="math inline">\(A_1 \cup A_2 = (A_1\cap \bar{A_2})\cup(\bar{A_1}\cap A_2)\cup(A_1\cap A_2)\)</span></p>
<p>運用上面的公理<del>2</del> 3</p>
<p><span class="math inline">\(\therefore P(A_1 \cup A_2) = P(A_1\cap \bar{A_2}) + P(\bar{A_1}\cap A_2) + P(A_1\cap A_2) \;\;\;\;\;\;(1)\)</span></p>
<p>再考慮 <span class="math inline">\(A_1=(A_1\cap A_2)\cup(A_1\cap\bar{A_2})\)</span> 繼續拆分成兩個互斥事件</p>
<p><span class="math inline">\(\therefore P(A_1)=P(A_1\cap A_2)+P(A_1\cap\bar{A_2})\)</span> 整理一下：</p>
<p><span class="math inline">\(P(A_1\cap\bar{A_2})=P(A_1)-P(A_1\cap A_2)\)</span></p>
<p>同理可得: <span class="math inline">\(P(\bar{A_1}\cap A_2)=P(A_2)-P(A_1\cap A_2)\)</span></p>
<p>代入上面第(1)式可得：</p>
<p><span class="math display">\[
\begin{aligned}
P(A_1 \cup A_2) &amp;= P(A_1)-P(A_1\cap A_2)\\
                &amp;\;\;+ P(A_2)-P(A_1\cap A_2)\\
                &amp;\;\;+P(A_1\cap A_2)\\
                &amp;=P(A_1) + P(A_2) - P(A_1 \cap A_2)
\end{aligned}
\]</span></p>
</div>
<div id="conditonalProb" class="section level2">
<h2><span class="header-section-number">1.2</span> 條件概率 Conditional probability</h2>
<ul>
<li><span class="math inline">\(P(A|S)=\frac{P(A\cap S)}{P(S)}\)</span></li>
<li><span class="math inline">\(P(A\cap S) = P(A|S)P(S)\)</span></li>
</ul>
</div>
<div id="獨立-independence-的定義" class="section level2">
<h2><span class="header-section-number">1.3</span> 獨立 (independence) 的定義</h2>
<ul>
<li>兩個事件定義爲互爲獨立時 (<span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be independent <strong>if and only if</strong>)
<span class="math display">\[P(A\cap B)=P(A)P(B)\]</span></li>
<li>因爲從條件概率的概念我們已知<br> <span class="math inline">\(P(A\cap B) = P(A|B)P(B)\)</span> <br>所以<span class="math inline">\(P(A|B)=P(A)\)</span> 即：事件 <span class="math inline">\(B\)</span> 無法提供事件 <span class="math inline">\(A\)</span> 的任何有效訊息 (<strong><span class="math inline">\(A, B\)</span> 互相獨立</strong>)</li>
</ul>
</div>
<div id="賭博問題" class="section level2">
<h2><span class="header-section-number">1.4</span> 賭博問題</h2>
<p>終於來到本次話題的“重點”了。</p>
<p><img src="img/Selection_071.png" width="90%" style="display: block; margin: auto;" /></p>
<p>假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是<a href="https://winterwang.github.io/post/black-meal/">(味道奇特的)山羊</a>。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。
請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？</p>
</div>
<div id="賭博問題的答案" class="section level2">
<h2><span class="header-section-number">1.5</span> 賭博問題的答案</h2>
<p><strong>答案是：必須改變主意才能提高中獎概率。</strong></p>
<p>上述情況下，最簡單的是用概率樹 (probability tree) 來做決定：</p>
<p><img src="img/Selection_072.png" width="90%" style="display: block; margin: auto;" /></p>
<p>解說一下：</p>
<ul>
<li>假定保時捷在1號門後，你第一次選擇了1號門，那麼此時主持人可以任意打開2號或者三號門（因爲他們後面都沒有保時捷）。</li>
<li>假定保時捷在1號門後，你第一次選了2號門，那麼此時主持人只能打開3號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。</li>
<li>假定保時捷在1號門後，你第一次選了3號門，那麼此時主持人只能打開2號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。</li>
</ul>
<p>所以按照圖中給出的計算概率樹的過程可以得到:</p>
<p><span class="math display">\[P[change]=\frac{1}{3}+\frac{1}{3}=\frac{2}{3}\\
P[not\; change]=\frac{1}{6}+\frac{1}{6}=\frac{1}{3}\]</span></p>
<p>你是否選擇了改變主意了呢？</p>
</div>
</div>
<div id="Bayes-Definition" class="section level1">
<h1><span class="header-section-number">第 2 章</span> Bayes 貝葉斯理論的概念</h1>
<p>許多時候，我們需要將概率中的條件相互對調。
例如：
在已知該人羣中有20%的人有吸菸習慣(<span class="math inline">\(P(S)\)</span>)，吸菸的人有9%的概率有哮喘(<span class="math inline">\(P(A|S)\)</span>)，不吸菸的人有7%的概率有哮喘(<span class="math inline">\(P(A|\bar{S})\)</span>)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有多大的概率是一個菸民？也就是要求 <span class="math inline">\(P(S|A)\)</span></p>
<p>這裏先引入貝葉斯的概念：</p>
<p>我們可以將 <span class="math inline">\(P(A\cap S)\)</span> 寫成：
<span class="math display">\[P(A\cap S)=P(A|S)P(S)\\or\\
P(A\cap S)=P(S|A)P(A)\]</span>
這兩個等式是完全等價的。我們將他們連起來：</p>
<p><span class="math display">\[P(S|A)P(A)=P(A|S)P(S)\\
\Rightarrow P(S|A)=\frac{P(A|S)P(S)}{P(A)}\]</span></p>
<p>是不是看起來又像是寫了一堆<strong>廢話</strong>？
沒錯，你看出來是一堆廢話的時候，證明你也同意這背後的簡單邏輯。</p>
<p>再繼續，我們可以利用另外一個<strong>廢話</strong>：</p>
<p><span class="math display">\[
\because S+\bar{S}=1\\ 
\therefore P(A)=P(A\cap S)+P(A\cap\bar{S})
\]</span></p>
<p>用上面的公式替換掉</p>
<p><span class="math display">\[
P(A\cap S)+P(A\cap\bar{S}） \\
\therefore P(A)=P(A|S)P(S)+P(A|\bar{S})P(\bar{S})
\]</span></p>
<p>可以得到<strong>貝葉斯理論公式</strong>：</p>
<p><span class="math display">\[P(S|A)=\frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})}\]</span></p>
<p>回到上面說到的哮喘人中有多少比例吸菸的問題。可以繼續使用概率樹來方便的計算：</p>
<p><img src="img/Selection_073.png" width="90%" style="display: block; margin: auto;" /></p>
<p><span class="math display">\[\begin{align}
P(S|A) &amp;= \frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\bar{S})P(\bar{S})} \\
        &amp;= \frac{0.09\times0.2}{0.09\times0.2+0.07\times0.8} \\
        &amp;= 0.24
\end{align}\]</span></p>
<p>所以我們的結論就是，在已知該人羣中有20%的人有吸菸習慣(<span class="math inline">\(P(S)\)</span>)，吸菸的人有9%的概率有哮喘(<span class="math inline">\(P(A|S)\)</span>)，不吸菸的人有7%的概率有哮喘(<span class="math inline">\(P(A|\bar{S})\)</span>)的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有24% 的概率是一個菸民(<span class="math inline">\(P(S|A)\)</span>)。</p>
</div>
<div id="期望-expectation-或均值-or-mean-和-方差-variance" class="section level1">
<h1><span class="header-section-number">第 3 章</span> 期望 Expectation (或均值 or mean) 和 方差 Variance</h1>
<p>期望（或均值）是用來描述一組數據中心位置的指標（另一個是中位數 Median）。
對於離散型隨機變量 <span class="math inline">\(X\)</span> (discrete random variables)，它的期望被定義爲：</p>
<p><span class="math display">\[E(X)=\sum_x xP(X=x)\]</span></p>
<p>所以就是將所有 <span class="math inline">\(X\)</span> 可能取到的值乘以相應的概率後求和。這個期望（或均值）常常用希臘字母 <span class="math inline">\(\mu\)</span> 來標記。</p>
<p>方差 Variance 是衡量一組數據變化幅度(dispersion/variability)的指標之一。 方差的定義是：</p>
<p><span class="math display">\[Var(X)=E((X-\mu)^2)\\\text{Where, }\mu=E(x)\]</span></p>
<p>實際上我們更加常用的是它的另外一個公式：</p>
<p><span class="math display">\[Var(X)=E(X^2)-E(X)^2\]</span></p>
<p><strong>證明 上面兩個方差公式相等</strong></p>
<p><span class="math display">\[
\begin{align}
Var(x)  &amp;= E((X-\mu)^2) \\
        &amp;= E(X^2-2X\mu+\mu^2)\\
        &amp;= E(X^2) - 2\mu E(X) + \mu^2\\
        &amp;= E(X^2) - 2\mu^2 + \mu^2 \\
        &amp;= E(X^2) - \mu^2 \\
        &amp;= E(X^2) - E(X)^2
\end{align}
\]</span></p>
<div id="方差的性質" class="section level2">
<h2><span class="header-section-number">3.1</span> 方差的性質：</h2>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Var(X+b)=Var(X)\)</span></li>
<li><span class="math inline">\(Var(aX)=a^2Var(X)\)</span></li>
<li><span class="math inline">\(Var(aX+b)=a^2Var(X)\)</span></li>
</ol>
</div>
</div>
<div id="bernoulli" class="section level1">
<h1><span class="header-section-number">第 4 章</span> 伯努利分佈 Bernoulli distribution</h1>
<p>伯努利分佈，說的就是一個簡單的二分變量 (1, 0)，它取1時的概率如果是 <span class="math inline">\(\pi\)</span>。那麼我們可以計算這個分佈的期望值:</p>
<p><span class="math display">\[
\begin{align}
E(X) &amp;=\sum_x xP(X=x) \\
     &amp;=1\times\pi + 0\times(1-\pi)\\
     &amp;=\pi
\end{align}
\]</span></p>
<p>由於 <span class="math inline">\(x=x^2\)</span>，因爲 <span class="math inline">\(x=0,1\)</span>, 所以 <span class="math inline">\(E[X^2]=E[X]\)</span>，那麼方差爲：</p>
<p><span class="math display">\[
\begin{align}
Var(X) &amp;=E[X^2]-E[X]^2 \\
       &amp;=E[X]-E[X]^2 \\
       &amp;=\pi - \pi^2 \\
       &amp;=\pi(1-\pi)
\end{align}
\]</span></p>
<p><strong>證明，<span class="math inline">\(X,Y\)</span> 爲互爲獨立的隨機離散變量時，<br>a) <span class="math inline">\(E(XY)=E(X)E(Y)\)</span> ; <br>b) <span class="math inline">\(Var(X+Y)=Var(X)+Var(Y)\)</span></strong></p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li><strong>證明</strong></li>
</ol></li>
</ul>
<p><span class="math display">\[
\begin{align}
E(XY) &amp;= \sum_x\sum_y xyP(X=x, Y=y) \\
\because &amp;\; X,Y are\;independent\;to\;each\;other \\
\therefore &amp;= \sum_x\sum_y xyP(X=x)P(Y=y)\\
      &amp;=\sum_x xP(X=x)\sum_y yP(Y=y)\\
      &amp;=E(X)E(Y)
\end{align}
\]</span></p>
<ul>
<li><ol start="2" style="list-style-type: lower-alpha">
<li><strong>證明</strong>
根據方差的定義：</li>
</ol></li>
</ul>
<p><span class="math display">\[
\begin{align}
Var(X+Y) &amp;= E((X+Y)^2)-E(X+Y)^2 \\
         &amp; \; Expand \\
         &amp;=E(X^2+2XY+Y^2)-(E(X)+E(Y))^2\\
         &amp;=E(X^2)+E(Y^2)+2E(XY)\\
         &amp;\;\;\; - E(X)^2-E(Y)^2-2E(X)E(Y)\\
         &amp;\; We\;just\;showed\; E(XY)=E(X)E(Y)\\
         &amp;=E(X^2)-E(X)^2+E(Y^2)-E(Y)^2 \\
         &amp;=Var(X)+Var(Y)
\end{align}
\]</span></p>
</div>
<div id="binomial" class="section level1">
<h1><span class="header-section-number">第 5 章</span> 二項分佈的概念 Binomial distribution</h1>
<p>二項分佈在醫學研究中至關重要，一組二項分佈的數據，指的通常是 <span class="math inline">\(n\)</span> 次相互獨立的<a href="https://winterwang.github.io/post/probability2-4/">成功率爲 <span class="math inline">\(\pi\)</span> 的伯努利實驗</a> (<span class="math inline">\(n\)</span> independent Bernoulli trials) 中成功的次數。</p>
<p>當 <span class="math inline">\(X\)</span> 服從二項分佈，記爲 <span class="math inline">\(X \sim binomial(n, \pi)\)</span> 或<span class="math inline">\(X \sim bin(n, \pi)\)</span>。它的(第 <span class="math inline">\(x\)</span> 次實驗的)概率被定義爲：</p>
<p><span class="math display">\[
\begin{align}
P(X=x) &amp;= ^nC_x\pi^x(1-\pi)^{n-x} \\
       &amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
       &amp; for\;\; x = 0,1,2,\dots,n
\end{align}
\]</span></p>
<div id="二項分佈的期望和方差" class="section level2">
<h2><span class="header-section-number">5.1</span> 二項分佈的期望和方差</h2>
<ul>
<li>期望 <span class="math inline">\(E(X)\)</span>
<ul>
<li>若 <span class="math inline">\(X \sim bin(n,\pi)\)</span>，那麼 <span class="math inline">\(X\)</span> 就是這一系列獨立伯努利實驗中成功的次數。</li>
<li>用 <span class="math inline">\(X_i, i =1,\dots, n\)</span> 標記每個相互獨立的伯努利實驗。</li>
<li>那麼我們可以知道 <span class="math inline">\(X=\sum_{i=1}^nX_i\)</span>。</li>
</ul></li>
</ul>
<p><span class="math display">\[
      \begin{align} E(X) &amp;= E(\sum_{i=1}^nX_i)\\
                         &amp;= E(X_1+X_2+\cdots+X_n) \\
                         &amp;= E(X_1)+E(X_2)+\cdots+E(X_n)\\
                         &amp;= \sum_{i=1}^nE(X_i)\\
                         &amp;= \sum_{i=1}^n\pi \\
                         &amp;= n\pi
      \end{align}
\]</span></p>
<ul>
<li>方差 <span class="math inline">\(Var(X)\)</span></li>
</ul>
<p><span class="math display">\[
\begin{align}
Var(X) &amp;= Var(\sum_{i=1}^nX_i) \\
        &amp;= Var(X_i+X_2+\cdots+X_n) \\
        &amp;= Var(X_i)+Var(X_2)+\cdots+Var(X_n) \\
        &amp;= \sum_{i=1}^nVar(X_i) \\
        &amp;= n\pi(1-\pi) \\
\end{align}
\]</span></p>
</div>
<div id="hyperdist" class="section level2">
<h2><span class="header-section-number">5.2</span> 超幾何分佈 hypergeometric distribution</h2>
<p>假設我們從總人數爲 <span class="math inline">\(N\)</span> 的人羣中，採集一個樣本 <span class="math inline">\(n\)</span>。假如已知在總體人羣中(<span class="math inline">\(N\)</span>)有 <span class="math inline">\(M\)</span> 人患有某種疾病。請問採集的樣本 <span class="math inline">\(X=n\)</span> 中患有這種疾病的人，服從怎樣的分佈？</p>
<ul>
<li>從人羣(<span class="math inline">\(N\)</span>)中取出樣本(<span class="math inline">\(n\)</span>)，有 <span class="math inline">\(^NC_n\)</span> 種方法。</li>
<li>從患病人羣(<span class="math inline">\(M\)</span>)中取出患有該病的人(<span class="math inline">\(x\)</span>)有 <span class="math inline">\(^MC_x\)</span> 種方法。</li>
<li>樣本中不患病的人(<span class="math inline">\(n-x\)</span>)被採樣的方法有 <span class="math inline">\(^{N-M}C_{n-x}\)</span> 種。</li>
<li>採集一次 <span class="math inline">\(n\)</span> 人作爲樣本的概率都一樣。因此：</li>
</ul>
<p><span class="math display">\[P(X=x)=\frac{\binom{M}{x}\binom{N-M}{n-x}}{\binom{N}{n}}\]</span></p>
</div>
<div id="樂透中獎概率問題" class="section level2">
<h2><span class="header-section-number">5.3</span> 樂透中獎概率問題：</h2>
<ul>
<li>從數字 <span class="math inline">\(1\sim59\)</span> 中選取 <span class="math inline">\(6\)</span> 個任意號碼</li>
<li>開獎時從 <span class="math inline">\(59\)</span> 個號碼球中隨機抽取 <span class="math inline">\(6\)</span> 個</li>
<li>如果六個號碼全部猜中(不分順序)，你可以成爲百萬富翁。請問一次猜中全部 <span class="math inline">\(6\)</span> 個號碼的概率是多少？</li>
</ul>
<p>從 <span class="math inline">\(59\)</span> 個號碼中隨機取出任意 <span class="math inline">\(6\)</span> 個號碼的方法有 <span class="math inline">\(^{59}C_6\)</span> 種。
<span class="math display">\[^{59}C_6=\frac{59!}{6!(59-6)!}=45,057,474\]</span></p>
<p>每次選取六個號碼做爲一組的可能性相同，所以，你買了一組樂透號碼，能中獎的概率就是 <span class="math inline">\(1/45,057,474 = 0.00000002219\)</span>。你還會再去買彩票麼？</p>
<div id="如果我只想中其中的-3-個號碼概率有多大" class="section level3">
<h3><span class="header-section-number">5.3.1</span> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</h3>
<p>用超幾何分佈的概率公式：</p>
<p><span class="math display">\[
\begin{align}
P(X=3) &amp;= \frac{^6C_3\times ^{53}C_3}{^{59}C_6} \\
       &amp;= 0.010
\end{align}
\]</span></p>
<p>你有 <span class="math inline">\(1\%\)</span> 的可能中獎。換句話說，如果中三個以上的數字算中獎的話，你買的彩票中獎的概率低於 <span class="math inline">\(1\%\)</span>。是不是覺得下次送錢給博彩公司的時候還不如跟我一起喝一杯咖啡划算？</p>
</div>
</div>
</div>
<div id="poisson" class="section level1">
<h1><span class="header-section-number">第 6 章</span> 泊松分佈 Poisson Distribution</h1>
<ul>
<li>當一個事件，在一段時間 (<span class="math inline">\(T\)</span>) 中可能發生的次數是 <span class="math inline">\(\lambda\)</span> 。那麼我們可以認爲，經過時間 <span class="math inline">\(T\)</span>，該事件發生的期望次數是 <span class="math inline">\(E(X)=\lambda T\)</span>。</li>
<li>利用微分思想，將這段時間 <span class="math inline">\(T\)</span> 等分成 <span class="math inline">\(n\)</span> 個時間段，當 <span class="math inline">\(n\rightarrow\infty\)</span> 直到每個微小的時間段內最多發生一次該事件。</li>
</ul>
<p>那麼</p>
<ul>
<li>每個微小的時間段，可以視爲是一個伯努利實驗（有事件發生或者沒有）</li>
<li>那麼這整段時間 <span class="math inline">\(T\)</span> 內發生的事件可以視爲是一個二項分佈實驗。</li>
</ul>
<p>令 <span class="math inline">\(X=\)</span> 一次事件發生時所經過的所有時間段。</p>
<ul>
<li><span class="math inline">\(X \sim Bin(n, \pi)\)</span>，其中 <span class="math inline">\(n\rightarrow\infty\)</span>，<span class="math inline">\(n\)</span> 爲時間段。</li>
<li>在每個分割好的時間段內，事件發生的概率都是：<span class="math inline">\(\pi=\frac{\lambda T}{n}\)</span></li>
<li>期望 <span class="math inline">\(\mu=\lambda T \Rightarrow \pi=\mu/n\)</span></li>
<li>所以 <span class="math inline">\(X\)</span> 的概率方程就是：</li>
</ul>
<p><span class="math display">\[
\begin{align}
P(X=x) &amp;= \binom{n}{x}\pi^x(1-\pi)^{n-x} \\
       &amp;= \binom{n}{x}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
       &amp;= \frac{n!}{x!(n-x)!}(\frac{\mu}{n})^x(1-\frac{\mu}{n})^{n-x} \\
       &amp;=\frac{n!}{n^x(n-x)!}\frac{\mu^x}{x!}(1-\frac{\mu}{n})^{n-x}\\
\text{when}\; n\rightarrow\infty   &amp;\; x \ll n\\
\frac{n!}{n^x(n-x)!} &amp;=\frac{n(n-1)\dots(n-x+1)}{n^x} \rightarrow 1\\
(1-\frac{\mu}{n})^{n-x} &amp;\approx  (1-\frac{\mu}{n})^n \rightarrow e^{-\mu}\\
\text{the probability function } &amp; \text{ of a Poisson distribution}   \\
P(X=x) &amp;\rightarrow \frac{\mu^x}{x!}e^{-\mu}
\end{align}
\]</span></p>
<p>當數據服從泊松分佈時，記爲 <span class="math inline">\(X\sim Poisson(\mu=\lambda T)\;\; or\;\; X\sim Poi(\mu)\)</span></p>
<p><strong>證明泊松分佈的參數特徵：</strong></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E(X)=\mu\)</span></li>
</ol>
<p><span class="math display">\[
\begin{align}
E(X)  &amp;=  \sum_{x=0}^\infty xP(X=x) \\
      &amp;=  \sum_{x=0}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;= 0+ \sum_{x=1}^\infty x\frac{\mu^x}{x!}e^{-\mu} \\
      &amp;=  \sum_{x=1}^\infty \frac{\mu^x}{(x-1)!}e^{-\mu} \\
      &amp;=  \mu\sum_{x=1}^\infty \frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
replace\; &amp;x\; with\; all\; i=x-1 \\
      &amp;=  \mu\sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu} \\
notice\; that\; &amp;the\; right\; side \sum_{i=0}^\infty \frac{\mu^{i}}{i!}e^{-\mu}=1 is \\
the\;sum\;of\;all\;&amp;probability\;of\;a\;Poisson\;distribution\\
      &amp;= \mu
\end{align}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(Var(x)=\mu\)</span>
爲了找到 <span class="math inline">\(Var(X)\)</span>，我們用公式 <span class="math inline">\(Var(X)=E(X^2)-E(X)^2\)</span></li>
</ol>
<p>我們需要找到 <span class="math inline">\(E(X^2)\)</span></p>
<p><span class="math display">\[
\begin{align}
E(X^2) &amp;= \sum_{x=0}^\infty x^2\frac{\mu^x}{x!}e^{-\mu} \\
       &amp;= \mu \sum_{x=1}^\infty x\frac{\mu^{x-1}}{(x-1)!}e^{-\mu} \\
replace\; &amp;x\; with\; all\; i=x-1 \\
       &amp;= \mu \sum_{i=0}^\infty (i+1)\frac{\mu^{i}}{i!}e^{-\mu} \\
       &amp;= \mu(\sum_{i=0}^\infty i\frac{\mu^i}{i!}e^{-\mu} + \sum_{i=0}^\infty \frac{\mu^i}{i!}e^{-\mu}) \\
       &amp;= \mu(E(X)+1) \\
       &amp;= \mu^2+\mu \\
Var(X) &amp;= E(X^2) - E(X)^2 \\
       &amp;= \mu^2 + \mu -\mu^2 \\
       &amp;= \mu
\end{align}
\]</span></p>
</div>
<div id="正態分佈" class="section level1">
<h1><span class="header-section-number">第 7 章</span> 正態分佈</h1>
<div id="概率密度曲線-probability-density-function-pdf" class="section level2">
<h2><span class="header-section-number">7.1</span> 概率密度曲線 probability density function， PDF</h2>
<ul>
<li><p>一個隨機連續型變量 <span class="math inline">\(X\)</span> 它的性質由一個對應的<strong>概率密度方程 (probability density function, PDF)</strong> 決定。</p></li>
<li><p>在給定的範圍區間內，如 <span class="math inline">\(a\sim b, (a &lt; b)\)</span>，它的概率滿足:</p></li>
</ul>
<p><span class="math display">\[P(a\leqslant X \leqslant b) = \int_a^bf(x)dx\]</span></p>
<ul>
<li>這個相關的方程，在 <span class="math inline">\(a\sim b\)</span> 區間內的積分，就是這個連續變量在這個區間內取值的概率。</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="co"># R codes for drawing a standard normal distribution by using ggplot2</span></a>
<a class="sourceLine" id="cb1-2" title="2">p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>)), <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm)</a>
<a class="sourceLine" id="cb1-4" title="4">p <span class="op">+</span><span class="st"> </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">2</span>, <span class="dt">y=</span><span class="fl">0.3</span>, <span class="dt">parse=</span><span class="ot">TRUE</span>, <span class="dt">label=</span><span class="st">&quot;frac(1, sqrt(2*pi)) * e ^(-z^2/2)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1-5" title="5"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">vjust =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb1-6" title="6">        <span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">vjust =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb1-7" title="7">        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>),</a>
<a class="sourceLine" id="cb1-8" title="8">        <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>),</a>
<a class="sourceLine" id="cb1-9" title="9">        <span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">face =</span> <span class="st">&quot;bold&quot;</span>, <span class="dt">hjust =</span> <span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb1-10" title="10">        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;ivory&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1-11" title="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Probability density functions </span><span class="ch">\n</span><span class="st"> for standard normal distribution&quot;</span>,</a>
<a class="sourceLine" id="cb1-12" title="12">       <span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1-13" title="13"><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm,</a>
<a class="sourceLine" id="cb1-14" title="14">                <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">1.3</span>,<span class="fl">0.4</span>),</a>
<a class="sourceLine" id="cb1-15" title="15">                <span class="dt">geom =</span> <span class="st">&quot;area&quot;</span>,<span class="dt">fill=</span><span class="st">&quot;#00688B&quot;</span>, <span class="dt">alpha=</span> <span class="fl">0.2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PDF-standard"></span>
<img src="bookdown_files/figure-html/PDF-standard-1.png" alt="Probability Density Function of a Standard Normal Distribution" width="90%" />
<p class="caption">
圖 7.1: Probability Density Function of a Standard Normal Distribution
</p>
</div>
<p>注意：整個方程的曲線下面積等於 <span class="math inline">\(1\)</span>：
<span class="math display">\[\int_{-\infty}^\infty f(x)dx=1\]</span></p>
<ul>
<li>期望 <span class="math inline">\(E(X)=\int_{-\infty}^\infty xf(x)dx\)</span></li>
<li>方差 <span class="math inline">\(Var(X)=\int_{-\infty}^\infty (x-\mu)^2f(x)dx\)</span></li>
</ul>
</div>
<div id="正態分佈-1" class="section level2">
<h2><span class="header-section-number">7.2</span> 正態分佈</h2>
<p>如果一組數據服從正態分佈，我們通常用它的期望（或者叫平均值）<span class="math inline">\(\mu\)</span>，和它的方差 <span class="math inline">\(\sigma^2\)</span>，來描述這組數據。記爲：</p>
<p><span class="math display">\[X \sim N(\mu, \sigma^2)\]</span></p>
<ul>
<li>它的概率密度方程可以表述爲：</li>
</ul>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\]</span></p>
<ul>
<li><span class="math inline">\(E(x) =\mu\)</span></li>
<li><span class="math inline">\(Var(x)=\sigma^2\)</span></li>
</ul>
</div>
<div id="standardNormal" class="section level2">
<h2><span class="header-section-number">7.3</span> 標準正態分佈</h2>
<p>標準正態分佈的期望（或者均值）爲 <span class="math inline">\(0\)</span>，方差爲 <span class="math inline">\(1\)</span></p>
<ul>
<li>記爲：<span class="math inline">\(Z \sim N(0,1)\)</span></li>
<li>它的概率密度方程表述爲：</li>
</ul>
<p><span class="math display">\[\frac{1}{\sqrt{2\pi}}exp(-\frac{z^2}{2})\]</span></p>
<ul>
<li>它的累積分佈方程 (cumulative distribution function， CDF)，是將概率密度方程 (PDF) 積分以後獲得的方程。通常我們記爲 <span class="math inline">\(\Phi(z)\)</span></li>
</ul>
<p>再看一下標準正態分佈的概率密度方程曲線：</p>
<div class="figure" style="text-align: center"><span id="fig:PDF-standard2"></span>
<img src="bookdown_files/figure-html/PDF-standard2-1.png" alt="Probability Density function of a Standard Normal Distribution" width="90%" />
<p class="caption">
圖 7.2: Probability Density function of a Standard Normal Distribution
</p>
</div>
<ul>
<li>95% 的曲線下面積在標準差 standard deviation <span class="math inline">\(-1.96\sim1.96\)</span> 之間的區域。</li>
<li>而且，<span class="math inline">\(\phi(-x)=1-\phi(x)\)</span></li>
<li>任何一個正態分佈都可以通過下面的公式，標準化成爲標準正態分佈：</li>
</ul>
<p><span class="math display">\[Z=\frac{X-\mu}{\sigma}\]</span></p>
</div>
</div>
<div id="CLT" class="section level1">
<h1><span class="header-section-number">第 8 章</span> 中心極限定理 the Central Limit Theorem</h1>
<p>最近明顯可以感覺到課程的步驟開始加速。看我的課表：</p>
<p><img src="img/IMG_0522.png" width="90%" style="display: block; margin: auto;" /></p>
<p>手機畫面太小了。早上都是9點半開始，下午基本都是到5點。週一更慘，到7點。週二-週五中午都被統計中心的講座佔據。簡直是非人的生活。</p>
<p>這周概率論基礎結束。中心極限定理講完以後我們正式進入了 Inference 統計推斷的課程。我們花了一天時間講什麼是樣本估計 (Estimation)，什麼是參數精確度 (Precision)，什麼是自由度 (degree of freedom)，怎樣進行不偏的估計 (unbiased inference)。然後還有似然方程 (likelihood function)。</p>
<p>今天的更新還是簡單的把概率論掃尾一下。感受一下中心極限定理的偉大。</p>
<div id="covariance" class="section level2">
<h2><span class="header-section-number">8.1</span> 協方差 Covariance</h2>
<p><a href="https://winterwang.github.io/post/probability2-4/">之前我們定義過</a>，兩個獨立連續隨機變量 <span class="math inline">\(X,Y\)</span> 之和的方差 Variance ：</p>
<p><span class="math display">\[Var(X+Y)=Var(X)+Var(Y)\]</span></p>
<p>然而如果他們並不相互獨立的話：</p>
<p><span class="math display">\[
\begin{aligned}
Var(X+Y) &amp;= E[((X+Y)-E(X+Y))^2] \\
         &amp;= E[(X+Y)-(E(X)+E(Y))^2] \\
         &amp;= E[(X-E(X)) - (Y-E(Y))^2] \\
         &amp;= E[(X-E(X))^2+(Y-E(Y))^2 \\
         &amp; \;\;\; +2(X-E(X))(Y-E(Y))] \\
         &amp;= Var(X)+Var(Y)+2E[(X-E(X))(Y-E(Y))]
\end{aligned}
\]</span></p>
<p>可以發現在兩者和的方差公式展開之後多了一部分 <span class="math inline">\(E[(X-E(X))(Y-E(Y))]\)</span>。 這個多出來的一部分就說明了二者 <span class="math inline">\((X, Y)\)</span> 之間的關係。它被定義爲協方差 (Covariance):
<span class="math display">\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))]\]</span></p>
<p>所以：</p>
<p><span class="math display">\[Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\]</span></p>
<p><u>要記住，協方差只能用於評價<span class="math inline">\(X,Y\)</span>之間的線性關係 (Linear Association)。</u></p>
<p>以下是協方差 (Covariance) 的一些特殊性質：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{Cov}(X,X)=\text{Var}(X)\)</span></li>
<li><span class="math inline">\(\text{Cov}(X,Y)=\text{Cov}(Y,X)\)</span></li>
<li><span class="math inline">\(\text{Cov}(aX,bY)=ab\:\text{Cov}(X,Y)\)</span></li>
<li><span class="math display">\[\text{Cov}(aR+bS,cX+dY)=ac\:\text{Cov}(R,X)+ad\:\text{Cov}(R,Y)\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+bc\:\text{Cov}(S,X)+bd\:\text{Cov}(S,Y)\]</span></li>
<li><span class="math display">\[\text{Cov}(aX+bY,cX+dY)=ac\:\text{Var}(X)+ad\:\text{Var}(Y)\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+(ad+bc)\text{Cov}(X,Y)\]</span></li>
<li><span class="math inline">\(\text{Cov}(X+Y,X-Y)=\text{Var}(X)-\text{Var}(Y)\)</span></li>
<li>If <span class="math inline">\(X, Y\)</span> are independent. <span class="math inline">\(\text{Cov}(X,Y)=0\)</span> <span class="diff_alert">But not vise-versa !</span></li>
</ol>
</div>
<div id="correlation" class="section level2">
<h2><span class="header-section-number">8.2</span> 相關 Correlation</h2>
<ul>
<li>協方差雖然<span class="math inline">\(Cov(X,Y)\)</span> 的大小很大程度上會被他們各自的單位和波動大小左右。</li>
<li>我們將協方差標準化(除以各自的標準差 s.d.) (standardization) 之後，就可以得到相關係數 Corr (<span class="math inline">\(-1\sim1\)</span>):
<span class="math display">\[Corr(X,Y)=\frac{Cov(X,Y)}{SD(X)SD(Y)}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}\]</span></li>
</ul>
</div>
<div id="中心極限定理-the-central-limit-theorem" class="section level2">
<h2><span class="header-section-number">8.3</span> 中心極限定理 the Central Limit Theorem</h2>
<p><strong>如果從人羣中多次選出樣本量爲 <span class="math inline">\(n\)</span> 的樣本，並計算樣本均值, <span class="math inline">\(\bar{X}_n\)</span>。那麼這個樣本均值 <span class="math inline">\(\bar{X}_n\)</span> 的分佈，會隨着樣本量增加 <span class="math inline">\(n\rightarrow\infty\)</span>，而接近正態分佈。</strong></p>
<p>偉大的中心極限定理告訴我們：</p>
<p><strong>當樣本量足夠大時，樣本均值 <span class="math inline">\(\bar{X}_n\)</span> 的分佈爲正態分佈，這個特性與樣本來自的人羣的分佈 <span class="math inline">\(X_i\)</span> 無關。</strong></p>
<p><strong>再說一遍：</strong></p>
<p>如果對象是獨立同分佈 i.i.d (identically and independently distributed)。那麼它的總體期望和方差分別是: <span class="math inline">\(E(X)=\mu;\;Var(X)=\sigma^2\)</span>。
根據中心極限定理，可以得到：</p>
<ul>
<li>當樣本量增加，樣本均值的分佈服從正態分佈：
<span class="math display">\[\bar{X}_n\sim N(\mu, \frac{\sigma^2}{n})\]</span></li>
<li>也可以寫作，當樣本量增加：
<span class="math display">\[\sum_{i=1}^nX_i \sim N(n\mu,n\sigma^2)\]</span></li>
<li>有了這個定理，我們可以拋開樣本空間(<span class="math inline">\(X\)</span>)的分佈，也不用假定它服從正態分佈。</li>
<li>但是樣本的均值，卻總是服從正態分佈的。簡直是太完美了！！！！！！</li>
</ul>
</div>
<div id="binomial-normal-approx" class="section level2">
<h2><span class="header-section-number">8.4</span> 二項分佈的正態分佈近似</h2>
<ul>
<li><p>假設我們有大量(<span class="math inline">\(n\rightarrow\infty\)</span>)的二項分佈實驗 <span class="math inline">\(X\sim Bin(n, \pi)\)</span></p></li>
<li><p>根據<a href="https://winterwang.github.io/post/probability3/">二項分佈的概率公式</a>，計算將會變得很繁瑣複雜。</p></li>
<li><p>解決辦法：應用中心極限定理。</p></li>
<li><p><a href="https://winterwang.github.io/post/probability3/">中心極限定理</a>告訴我們，當樣本量足夠大時:
<span class="math display">\[X\sim N(n\pi, n\pi(1-\pi))\]</span></p></li>
<li><p>問題在於，多大的 <span class="math inline">\(n\)</span> 才能算大樣本呢？</p>
<ul>
<li>當且僅當 (only and if only) <span class="math inline">\(n&gt;20\)</span> AND <span class="math inline">\(n\pi&gt;5\)</span> AND <span class="math inline">\(n(1-\pi)&gt;5\)</span></li>
</ul></li>
</ul>
</div>
<div id="泊松分佈的正態分佈近似" class="section level2">
<h2><span class="header-section-number">8.5</span> 泊松分佈的正態分佈近似</h2>
<ul>
<li><p>假設時間 <span class="math inline">\(t\)</span> 內某事件的發生次數服從泊松分佈 <span class="math inline">\(X\sim Po(\mu)\)</span>。</p></li>
<li><p>考慮將這段時間 <span class="math inline">\(t\)</span> 等分成 <span class="math inline">\(n\)</span> 個時間段。那麼第 <span class="math inline">\(i\)</span> 時間段內事件發生次數依舊服從泊松分佈 <span class="math inline">\(X_i\sim Po(\frac{\mu}{n})\)</span>。且 <span class="math inline">\(E(X_i)=\mu/n, Var(X_i)=\mu/n\)</span>。</p></li>
<li><p>那麼原先的 <span class="math inline">\(X\)</span> 可以被視爲是將這無數的小時間段的 <span class="math inline">\(X_i\)</span> 相加。應用中心極限定理：
<span class="math display">\[X=\sum_{i=1}^nX_i\sim N(\frac{n\mu}{n}, \frac{n\mu}{n})\]</span></p></li>
<li><p>需要注意的是，這段時間 (<span class="math inline">\(t\)</span>) 內發生的事件次數 (<span class="math inline">\(\lambda\)</span>) : <span class="math inline">\(\lambda t =\mu&gt;10\)</span> ，這樣的正態分佈模擬才能成立。</p></li>
</ul>
</div>
<div id="continuity-correction" class="section level2">
<h2><span class="header-section-number">8.6</span> 正態分佈模擬的校正：continuity corrections</h2>
<ul>
<li>如果我們使用正態分佈來模擬離散變量的分佈，常常需要用到正態分佈模擬的矯正。</li>
<li>例如：我們如果用正態分佈模擬來計算 <span class="math inline">\(P(X=15)\)</span>，那麼實際上我們應該計算的是 <span class="math inline">\(P(14.5&lt;X&lt;15.5)\)</span>。</li>
</ul>
<div id="例題" class="section level3">
<h3><span class="header-section-number">8.6.1</span> 例題</h3>
<ol style="list-style-type: decimal">
<li>已知 <span class="math inline">\(X\sim Bin(100,0.5)\)</span>，求 <span class="math inline">\(P(X&gt;60)\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\because X&amp;\sim Bin(100, 0.5) \\ \therefore E(X) &amp;=n\pi=50 \\
Var(X) &amp;= n\pi(1-\pi) =25=5^2\\
P(X&gt;60)  &amp;= 1-P(X\leqslant60) \\
         &amp;= 1-P(Z\leqslant\frac{60.5-50}{\sqrt{25}}) \\
         &amp;= 1-P(Z\leqslant2.1) \\
         &amp;= 1-\Phi(2.1) \\
         &amp;= 1-0.982 = 0.018
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># 快來看實際用傻瓜算法計算獲得的概率：</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="dv">1</span><span class="op">-</span><span class="kw">pbinom</span>(<span class="dv">60</span>, <span class="dt">size=</span><span class="dv">100</span>, <span class="dt">prob=</span><span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.0176</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="co"># 快來看用中心極限定理模擬正態分佈獲得的概率：</span></a>
<a class="sourceLine" id="cb4-2" title="2"><span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>((<span class="fl">60.5</span><span class="dv">-50</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">25</span>))</a></code></pre></div>
<pre><code>## [1] 0.01786</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bin-normal-approx"></span>
<img src="bookdown_files/figure-html/bin-normal-approx-1.png" alt="Probability of 60 successes out of 100 Binomial trials, probability of success = 0.75" width="90%" />
<p class="caption">
圖 8.1: Probability of 60 successes out of 100 Binomial trials, probability of success = 0.75
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>已知 <span class="math inline">\(X\sim Bin(48, 0.75)\)</span>, 求 <span class="math inline">\(P(30&lt;X&lt;39)\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\because B &amp;\; \sim Bin(48, 0.75) \\
\therefore E(X) &amp;\; =n\pi=36 \\
           Var(X) &amp;\; =n\pi(1-\pi)=9=3^2 \\
P(30&lt;X&lt;39) &amp;\; = P(31\leqslant X\leqslant 38)\\
     &amp;\; = P(30.5\leqslant Y \leqslant 38.5) \\
     Y\;is\;the&amp;\;normal\;approximation \\
     &amp;\;= P(Y&lt;38.5) - P(Y&lt;30.5) \\
     &amp;\;= P(Z\leqslant\frac{38.5-36}{3})-
          P(Z\leqslant\frac{30.5-36}{3}) \\
     &amp;\;= P(Z\leqslant0.833) - P(Z\leqslant-1.833) \\
     &amp;\;= \Phi(0.833)-\Phi(-1.833) \\
     &amp;\;= 0.798-0.033 = 0.764
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># 快來看實際用傻瓜算法計算獲得的概率：</span></a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw">pbinom</span>(<span class="dv">38</span>, <span class="dt">size=</span><span class="dv">48</span>, <span class="dt">prob=</span><span class="fl">0.75</span>)<span class="op">-</span><span class="kw">pbinom</span>(<span class="dv">30</span>, <span class="dt">size=</span><span class="dv">48</span>, <span class="dt">prob=</span><span class="fl">0.75</span>)</a></code></pre></div>
<pre><code>## [1] 0.7578</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="co"># 快來看用中心極限定理模擬正態分佈獲得的概率：</span></a>
<a class="sourceLine" id="cb8-2" title="2"><span class="kw">pnorm</span>((<span class="fl">38.5</span><span class="dv">-36</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">9</span>)) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>((<span class="fl">30.5</span><span class="dv">-36</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">9</span>))</a></code></pre></div>
<pre><code>## [1] 0.7643</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bin-normal-approx2"></span>
<img src="bookdown_files/figure-html/bin-normal-approx2-1.png" alt="Probability of 30-39 successes out of 48 Binomial trials, probability of success = 0.75" width="90%" />
<p class="caption">
圖 8.2: Probability of 30-39 successes out of 48 Binomial trials, probability of success = 0.75
</p>
</div>
<p>從上面兩個例題也能看出，<span class="math inline">\(n\)</span> 越小，正態分佈模擬的誤差就越大。</p>
<ol start="3" style="list-style-type: decimal">
<li>已知 <span class="math inline">\(X \sim Poisson(30)\)</span> 求 <span class="math inline">\(P(X\leqslant20)\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
 \because E(X)=\mu=30, \;Var(X)=\mu=30=(\sqrt{30})^2 \\
 \begin{aligned}
 Pr(X\leqslant20) &amp;= P(Z\leqslant\frac{20.5-30}{\sqrt{30}}) \\
                  &amp;= P(Z\leqslant-1.734) \\
                  &amp;= \Phi(-1.734) \\
                  &amp;= 0.0414
 \end{aligned}
 \]</span></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="co"># 快來看實際用傻瓜算法計算獲得的概率：</span></a>
<a class="sourceLine" id="cb10-2" title="2"><span class="kw">ppois</span>(<span class="dv">20</span>, <span class="dt">lambda=</span><span class="dv">30</span>)</a></code></pre></div>
<pre><code>## [1] 0.03528</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="co"># 快來看用中心極限定理模擬正態分佈獲得的概率：</span></a>
<a class="sourceLine" id="cb12-2" title="2"><span class="kw">pnorm</span>((<span class="fl">20.5</span><span class="dv">-30</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">30</span>))</a></code></pre></div>
<pre><code>## [1] 0.04142</code></pre>
<p>這兩個其實有些小差距。不過看下圖，其模擬還是很到位的。只是正態分佈的面積明顯確實比泊松分佈的小柱子面積要大一些。</p>
<div class="figure" style="text-align: center"><span id="fig:bin-poi-approx"></span>
<img src="bookdown_files/figure-html/bin-poi-approx-1.png" alt="Probability of less than 20 events happen when the expectation is 30" width="90%" />
<p class="caption">
圖 8.3: Probability of less than 20 events happen when the expectation is 30
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>已知 <span class="math inline">\(X_1, X_2 \stackrel{i.i.d}{\sim} Poi(30)\)</span> 求 <span class="math inline">\(P(X_1+X_2\leqslant40)\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
E(X_1+X_2) &amp;\;= E(X_1)+E(X_2) = 30+30 = 60\\
Var(X_1+X_2) &amp;\;= Var(X_1)+Var(X_2) = 30+30 \\
             &amp;\;= (\sqrt{60})^2 \\
P(X_1+X_2\leqslant 40) &amp;\;= P(Z \leqslant \frac{40.5-60}{\sqrt{60}}) \\
           &amp;\;= P(Z\leqslant-2.517) \\
           &amp;\;= \Phi(-2.517) \\
           &amp;\;= 0.006
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="co"># 快來看實際用傻瓜算法計算獲得的概率：</span></a>
<a class="sourceLine" id="cb14-2" title="2"><span class="kw">ppois</span>(<span class="dv">40</span>, <span class="dt">lambda=</span><span class="dv">60</span>)</a></code></pre></div>
<pre><code>## [1] 0.003983</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="co"># 快來看用中心極限定理模擬正態分佈獲得的概率：</span></a>
<a class="sourceLine" id="cb16-2" title="2"><span class="kw">pnorm</span>((<span class="fl">40.5</span><span class="dv">-60</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">60</span>))</a></code></pre></div>
<pre><code>## [1] 0.005911</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bin-poi-approx2"></span>
<img src="bookdown_files/figure-html/bin-poi-approx2-1.png" alt="Probability of 2 identically and independently observed results of less or equal to 40 events happen in total when the expectation of each observation is 30" width="90%" />
<p class="caption">
圖 8.4: Probability of 2 identically and independently observed results of less or equal to 40 events happen in total when the expectation of each observation is 30
</p>
</div>
<p>又一次，正態分佈的面積比泊松分佈的小柱子面積要大一些。</p>
</div>
</div>
<div id="兩個連續隨機變量" class="section level2">
<h2><span class="header-section-number">8.7</span> 兩個連續隨機變量</h2>
<ul>
<li><p>假定 <span class="math inline">\(X_1, X_2\)</span> 是兩個連續隨機變量：
<span class="math display">\[
E(X_1)=\mu_1, Var(X_1)=\sigma_1^2 \\
E(X_2)=\mu_2, Var(X_2)=\sigma_2^2 \\
Corr(X_1, X_2)=\rho \Rightarrow Cov(X_1, X_2)=\rho\sigma_1\sigma_2=\sigma_{12}
\]</span></p></li>
<li><p>利用矩陣的標記法，可以將 <span class="math inline">\(X_1, X_2\)</span> 標記爲 <span class="math inline">\(\textbf{X}=(X_1, X_2)^T\)</span>, 即：</p></li>
</ul>
<p><span class="math display">\[
\textbf{X}=\left(
\begin{array}{c}
X_1\\
X_2\\
\end{array}
\right)
\]</span></p>
<ul>
<li>上面的所有內容都可以標記爲：
<span class="math display">\[
E(\textbf{X})=\mathbf{\mu}=\left(
\begin{array}{c}
\mu_1\\
\mu_2\\
\end{array}
\right)\\
Covariance \;matrix: \\
Var(\textbf{X})=\mathbf{\Sigma}=\left(
\begin{array}{c}
\sigma_1^2 &amp; \sigma_{12}\\
\sigma_{12} &amp; \sigma_1^2\\
\end{array}
\right)
\]</span></li>
</ul>
</div>
<div id="兩個連續隨機變量-例子" class="section level2">
<h2><span class="header-section-number">8.8</span> 兩個連續隨機變量 例子：</h2>
<p>假如要看收縮期血壓 (<span class="math inline">\(SBP\)</span>) 和舒張期血壓 (<span class="math inline">\(DBP\)</span>) 之間的關係：</p>
<p>下列爲已知條件：</p>
<ul>
<li><span class="math inline">\(SBP\)</span> 的均值爲 <span class="math inline">\(130\)</span>， 標準差爲 <span class="math inline">\(15\)</span>;</li>
<li><span class="math inline">\(DBP\)</span> 的均值爲 <span class="math inline">\(90\)</span>, 標準差爲 <span class="math inline">\(10\)</span>;</li>
<li><span class="math inline">\(SBP\)</span> 和 <span class="math inline">\(DBP\)</span> 之間的相關係數爲 <span class="math inline">\(0.75\)</span>。</li>
</ul>
<p>那麼， 我們可以把這些信息用下面的方法來標記：</p>
<p><span class="math display">\[
E(\textbf{X})=\mathbf{\mu}=\left(
\begin{array}{c}
130\\
90\\
\end{array}
\right)\\
Var(\textbf{X})=\mathbf{\Sigma}=\left(
\begin{array}{c}
225 &amp; 112.5\\
112.5 &amp; 225\\
\end{array}
\right)
\]</span></p>
</div>
<div id="條件分佈和邊緣分佈的概念" class="section level2">
<h2><span class="header-section-number">8.9</span> 條件分佈和邊緣分佈的概念</h2>
<ul>
<li><p>如果 <span class="math inline">\(\textbf{X}=(X_1, X_2)^T\)</span> 的兩個變量都服從正態分佈；</p></li>
<li><p>那麼這兩個變量的邊緣分佈 (marginal distribution) 也服從正態分佈:
<span class="math display">\[X_1\sim N(\mu_1,\sigma_1^2), X_2\sim N(\mu, \sigma_2^2)\]</span></p></li>
<li><p>同樣的，<span class="math inline">\(X_1\)</span> 的給出 <span class="math inline">\(X_2\)</span> 的條件分佈 (condition distribution) 也服從正態分佈：
<span class="math display">\[E(X_1|X_2)=\mu_1+\frac{\rho\sigma_1}{\sigma_2}(X_2-\mu_2) \\
 Var(X_1|X_2)=\sigma_1^2(1-\rho^2)\]</span></p></li>
<li><p>反之亦然。</p></li>
</ul>
</div>
<div id="條件分佈和邊緣分佈的例子" class="section level2">
<h2><span class="header-section-number">8.10</span> 條件分佈和邊緣分佈的例子</h2>
<p>上面的概念過於抽象，用血壓的例子：</p>
<p>收縮期血壓和舒張期血壓各自服從正態分佈。那麼可以用上面的概念來寫出已知舒張期血壓時，收縮期血壓的分佈。</p>
<ul>
<li><p>條件期望:
<span class="math display">\[E(\text{SBP|DBP})=130+\frac{0.75\times15}{10}(\text{DBP}-90)\]</span></p></li>
<li><p>實際如果來了一個病人，他說他只記得自己測的舒張期血壓是95：<br>
他的收縮期血壓的期望值就可以用上面的式子計算：
<span class="math display">\[E(\text{SBP|DBP}=95)=136\]</span></p></li>
<li><p>條件方差爲：
<span class="math display">\[Var(\text{SBP|DBP})=15^2(1-0.75^2)=98.4\approx9.92^2&lt;15^2\]</span></p></li>
<li><p>所以當我們知道了這個人的一部分信息以後，推測他的另一個相關連的變量變得更加準確(<strong>方差變小</strong>)了。</p></li>
</ul>
<div id="例題-1" class="section level3">
<h3><span class="header-section-number">8.10.1</span> 例題</h3>
<p>有 (閒) 人記錄了 <span class="math inline">\(1494\)</span> 名兒童在 <span class="math inline">\(2, 4, 6\)</span> 歲時的腿長度。已知在記錄的這三個年齡時的平均腿長度分別爲 <span class="math inline">\(85 \text{ cm}, 103 { cm}, 114 { cm}\)</span>。協方差矩陣如下:</p>
<p><span class="math display">\[
\left(
\begin{array}{c}
22.2 &amp; 11.8 &amp; 13.7\\
11.8 &amp; 26.3 &amp; 21.5\\
13.7 &amp; 21.5 &amp; 29.0
\end{array}
\right)
\]</span></p>
<p>假定，這三個年齡記錄的這些兒童的腿長度數據（聯合分佈, joint distribution）服從三個變量正態分佈。</p>
<ol style="list-style-type: decimal">
<li>求 <span class="math inline">\(2\)</span> 歲時這些兒童的腿長度的邊緣分佈 (marginal distribution)</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[X_{\text{age}=2} \sim N(85, \sigma_{\text{age}=2}^2=22.2)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>求他們 <span class="math inline">\(6\)</span> 歲時腿長度的 <span class="math inline">\(2\)</span> 歲時的條件分佈。(Find the distribution of leg length age 6 conditional on leg length at age 2.)</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math inline">\(6\)</span> 歲時和 <span class="math inline">\(2\)</span> 歲時腿長的相關係數 (correlation, <span class="math inline">\(\rho_{6,2}\)</span>) 爲：</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{6,2} &amp;= \frac{Cov_{6,2}}{\sqrt{Var(\text{length}_6)}\sqrt{Var(\text{length}_2)}}\\
&amp;= \frac{13.7}{\sqrt{22.2}\sqrt{29}}=0.54
\end{aligned}
\]</span></p>
<p>條件分佈套用上面提到的公式：</p>
<p><span class="math display">\[
\begin{aligned}
E({\text{length}_6 | \text{length}_2}) &amp;= \mu_6+\frac{\rho_{6,2}\sigma_6}{\sigma_2}(\text{length}_2-\mu_2) \\
&amp;= 114+\frac{0.54\times\sqrt{29.0}}{\sqrt{22.2}}(\text{length}_2-85)\\
Var(\text{length}_6 | \text{length}_2) &amp;= \sigma_6^2(1-\rho_{6,2}^2) \\
                         &amp;= 29.0\times(1-0.54^2) =20.5
\end{aligned}
\]</span></p>

</div>
</div>
</div>



<div id="統計推斷的概念" class="section level1">
<h1><span class="header-section-number">第 9 章</span> 統計推斷的概念</h1>
<blockquote>
<dl>
<dt>If people do not believe that mathematics is simple, it is only because they do not realize how complicated life is.</dt>
<dd><a href="https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC">John von Neumann</a>
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Inference lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/altmann.daniel">Daniel Altmann</a>, Professor <a href="https://www.lshtm.ac.uk/aboutus/people/gregson.john">John Gregson</a>, and Dr. Katy Morgan.
</div>

<div id="人羣與樣本-population-and-sample" class="section level2">
<h2><span class="header-section-number">9.1</span> 人羣與樣本 (population and sample)</h2>
<p>討論樣本時，需考慮下面幾個問題：</p>
<ol style="list-style-type: decimal">
<li>樣本是否具有代表性？</li>
<li>人羣被準確定義了嗎？</li>
<li>我們感興趣的“人羣”是否可以是無限大 (多) 的？</li>
<li>我們研究的樣本，是僅僅用來觀察，亦或是計劃對之進行某種干預呢？</li>
<li>我們從所有可能的人羣中抽樣了嗎？</li>
</ol>
</div>
<div id="樣本和統計量-sample-and-statistic" class="section level2">
<h2><span class="header-section-number">9.2</span> 樣本和統計量 (sample and statistic)</h2>
<p>通常我們在進行實驗或觀察時只是獲得了樣本的數據。而希望從樣本數據去推斷 (inference) 總體 (或人羣) 的一些特徵。我們也許只是想用樣本的平均值來估計整體人羣的某個特徵的平均值。不管是何種估計和推斷，都是基於對樣本數據的計算，從樣本中獲得想要推斷總體的<strong>統計量 (statistics)</strong>。我們用已知樣本去推斷未知總體的過程就叫做<strong>估計 (estimate)</strong>。這個想要被推斷的總體或人羣的值，被叫做<strong>參數 (parameter)</strong>，常常使用希臘字母來標記。用來估計總體或人羣的，從樣本數據計算得來的統計量，叫做<strong>估計量 (estimator)</strong>。</p>
<p>所有的統計量，都有<strong>樣本分佈 (sampling distributions，意爲重複無限次取樣後獲得的無限次統計量的分佈)</strong>。推斷的過程歸納如下：</p>
<ol style="list-style-type: decimal">
<li>從總體或人羣中抽樣 (樣本量 <span class="math inline">\(n\)</span>)</li>
<li>計算這個樣本的合適統計量，從而用於估計它在整體或人羣中的值。</li>
<li>我們還需要決定計算獲得的統計量的樣本分佈 (假定會抽樣無數次) 。</li>
<li>一旦可以精確地確認樣本分佈，我們就可以定量地計算出使用步驟2中獲得的統計量估計總體或人羣的參數時的準確度。</li>
</ol>
</div>
<div id="估計-estimation" class="section level2">
<h2><span class="header-section-number">9.3</span> 估計 Estimation</h2>
<p>從樣本的均值，推斷總體或人羣的均值是一種估計。我們的目的是，從已知樣本中計算一個儘可能接近那個未知的總體或人羣參數的值。一個估計量有兩個與生俱來的性質 (properties)：1) 偏倚 (bias); 2) 精確度 (precision)。這兩個性質都可以從樣本分佈和估計量獲得。</p>
<ol style="list-style-type: decimal">
<li><p>偏倚： 偏倚簡單說就是樣本分佈的均值，也就是我們從樣本中計算獲得的估計量，和我們想要拿它來估計的總體或人羣的參數之間的差距。(The bias is the difference between the mean of the sampling distribution – the expected or average value of the estimator – and the population parameter being estimated.) 一個小的偏倚，確保了我們從樣本中計算獲得的估計值 (假設我們抽樣無數次，計算無數個樣本估計值) <strong>均勻地</strong>分佈在總體或人羣參數的左右兩邊。偏倚本身並不是太大的問題，但是假如樣本量增加，偏倚依然存在 (估計量不一致, inconsistent) ，那常常意味着是抽樣過程出現了問題。例如：<br>用簡單隨機抽樣法獲得的樣本均值，就是總體或人羣均值的無偏估計 (unbiased estimator)。如果抽樣時由於某些主觀客觀的原因導致較小的樣本很少被抽樣 (抽樣過程出了問題，脫離了簡單隨機抽樣原則) ，那麼此時得到的樣本均值就會是一個過高的估計值 (upward biased estimator)。</p></li>
<li><p>精確度：估計值的精確度可以通過樣本分佈的方差或標準差來評價 (簡單說是樣本分佈的方差越低，波動越小，精確度越高) 。樣本分佈的標準差被定義爲估計值的標準誤。假如估計量是樣本均值，那麼樣本分佈的標準差 (估計量的標準誤) 和樣本數據之間有如下的關係：</p></li>
</ol>
<p><span class="math display">\[\text{true standard error of the mean}  = \frac{\text{true standard deviation}}{\sqrt{\text{sample size}}}\]</span></p>
<p>在一些簡單的情況下，通常估計值的選用不言自明 (例如均值，或者百分比) 。但是在複雜的情況下，我們可能可以有多個不同類型的估計量可以選擇，他們也常常各有利弊，需要我們做出取捨。</p>
</div>
<div id="信賴區間-confidence-intervals" class="section level2">
<h2><span class="header-section-number">9.4</span> 信賴區間 confidence intervals</h2>
<p>從樣本中計算估計量獲得的一個估計值，只是一個<strong>點估計 (point estimate)</strong>。對比之下，信賴區間就是一個對這個點估計的精確度的體現。信賴區間越窄，說明我們對於總體或人羣的參數的可能取值的範圍估計越精確。</p>
<p>信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。<strong>每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平 (<span class="math inline">\(95\%\)</span>) 。</strong> 常用的這個概率值就是 <span class="math inline">\(95\%, 90\%, 99\%\)</span>。</p>
<p>當從樣本數據計算獲得的估計量的信賴區間很寬，說明了這個收集來的數據提供了很少的參數信息，導致估計變得很不精確。</p>
<p><del>看到這裏的都是好漢一條啊！ 我不知道你暈了麼有，反正我是已經暈了。。。</del></p>
</div>
</div>
<div id="估計和精確度-estimation-and-precision" class="section level1">
<h1><span class="header-section-number">第 10 章</span> 估計和精確度 Estimation and Precision</h1>
<div id="CI-for-sample-mean" class="section level2">
<h2><span class="header-section-number">10.1</span> 估計量和他們的樣本分佈</h2>
<p>例子： 最大呼氣量 (Forced Expoiratory Volume in one second, FEV1) 用於測量一個人的肺功能，它的測量值是連續的。我們從前來門診的人中隨機抽取 <span class="math inline">\(n\)</span> 人作爲樣本，用這個樣本的 FEV1 平均值來估計這個診所的患者的平均肺功能。</p>
<p><strong>模型假設：</strong> 在這個例子中，我們的假設有如下：每個隨機抽取的 FEV1 測量值都是從同一個總體 (人羣) 中抽取，每一個觀察值 <span class="math inline">\(Y_i\)</span> 都互相獨立互不影響。我們用縮寫 iid 表示這些隨機抽取的樣本是服從獨立同分佈 (independent and identically distributed)。另外，總體的分佈也假定爲正態分佈，且總體均值爲 <span class="math inline">\(\mu\)</span>，總體方差爲 <span class="math inline">\(\sigma^2\)</span>。那麼這個模型可以簡單的被寫成：</p>
<p><span class="math display">\[Y_i \stackrel{i.i.d}{\sim} N(\mu, \sigma^2), i=1,2,\dots,n\]</span></p>
<p><strong>總體均值 <span class="math inline">\(\mu\)</span> 的估計量：</strong> 顯然算術平均值: <span class="math inline">\(\bar{Y}=\frac{1}{n}\sum_{i=1}^ny_i\)</span> 是我們用於估計總體均值的估計量。</p>
<p><strong>估計量的樣本分佈：</strong>
<span class="math display">\[\bar{Y}\stackrel{i.i.d}{\sim}N(\mu, \frac{\sigma^2}{n})\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
E(\bar{Y}) &amp;= E(\frac{1}{n}\sum Y_i) \\
           &amp;= \frac{1}{n}E(\sum Y_i) \\
           &amp;= \frac{1}{n}\sum E(Y_i) \\
           &amp;= \frac{1}{n}n\mu = \mu \\
Var(\bar{Y}) &amp;= Var(\frac{1}{n}\sum Y_i) \\
\because Y_i \;\text{are} &amp;\; \text{independent}   \\
            &amp;= \frac{1}{n^2}\sum Var(Y_i) \\
            &amp;= \frac{1}{n^2} n Var(Y_i) \\
            &amp;= \frac{\sigma^2}{n}
\end{aligned}
\]</span></p>
<p><strong>證明當 <span class="math inline">\(Z=\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}}\)</span> 時， <span class="math inline">\(Z\sim N(0,1)\)</span>:</strong></p>
<p>由式子可知， <span class="math inline">\(Z\)</span> 只是由一組服從正態分佈的數據 <span class="math inline">\(\bar{Y}\)</span> 線性轉換 (linear transformation) 而來，所以 <span class="math inline">\(Z\)</span> 本身也服從正態分佈</p>
<p><span class="math display">\[
\begin{aligned}
E(Z) &amp;= \frac{1}{\sqrt{Var(\bar{Y})}}E[\bar{Y}-\mu] \\
     &amp;= \frac{1}{\sqrt{Var(\bar{Y})}}[\mu-\mu] = 0 \\
Var(Z) &amp;= \frac{1}{Var(\bar{Y})}Var[\bar{Y}-\mu] \\
       &amp;= \frac{1}{Var(\bar{Y})}Var(\bar{Y}) =1 \\
\therefore Z \;&amp;\sim N(0,1)
\end{aligned}
\]</span></p>
<p><strong>均值 <span class="math inline">\(\mu\)</span> 的信賴區間：</strong> 上節說道，</p>
<blockquote>
<p>信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。<strong>每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平(<span class="math inline">\(95\%\)</span>) 。</strong> 常用的這個概率值就是 <span class="math inline">\(95\%, 90\%, 99\%\)</span>。</p>
</blockquote>
<p>假定我們用 <span class="math inline">\(95\%\)</span> 作爲信賴區間的水平。那麼下面我們嘗試推導一下信賴區間的計算公式。從長遠來說 (也就是假設我們從總體中抽樣無數次，每次都進行信賴區間的計算，也獲得無數個信賴區間) ，這些信賴區間中有 <span class="math inline">\(95\%\)</span> 是包含了總體的真實均值 (但是卻是未知) 的，而且這些信賴區間由於是從一個服從正態分佈的數據而來，它們也服從正態分佈 (對真實均值左右對稱) 。所以我們有理由相信，可以找到一個數值 <span class="math inline">\(c\)</span>：</p>
<p><span class="math display">\[Prob(\bar{Y} &gt; \mu+c) = 0.025 \\
  Prob(\bar{Y} &lt; \mu-c) = 0.025\]</span></p>
<p>因此，我們可以定義 <span class="math inline">\(95\%\)</span> 信賴區間的上限和下限分別是：</p>
<p><span class="math display">\[L=\bar{Y}-c \Rightarrow Prob(L&gt;\mu)=0.025 \\
  U=\bar{Y}+c \Rightarrow Prob(U&lt;\mu)=0.025\]</span></p>
<p><img src="img/Selection_082.png" /></p>
<p>接下來就是推倒 (故意的) <span class="math inline">\(c\)</span> 的過程啦：</p>
<p><span class="math display">\[
\begin{aligned}
Prob(\bar{Y}&gt;\mu+c)=Prob(\bar{Y}-\mu&gt;c) \;&amp;= 0.025 \\
\Rightarrow Prob(\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}} &gt; \frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;= 0.025 \\
\Rightarrow Prob(Z&gt;\frac{c}{\sqrt{Var(\bar{Y})}}) \;&amp;= 0.025 \\
we\;have\;proved\; Z\sim N(0,1) \\
we\;also\;know\; Prob(Z&gt;1.96) \;&amp;= 0.025 \\
so\;let\; \frac{c}{\sqrt{Var(\bar{Y})}} =1.96 \\
\Rightarrow c=1.96\sqrt{Var(\bar{Y})} \\
the\;95\%\;confidence\;interval \;of\; &amp;the\;population\;mean\;is\\
\mu = \bar{Y}\pm1.96\sqrt{Var(\bar{Y})}=\bar{Y}\pm &amp; 1.96\frac{\sigma}{\sqrt{n}}
\end{aligned}
\]</span></p>
<p>其中，<span class="math inline">\(\sqrt{Var(\bar{Y})}\)</span> 就是我們熟知的估計量 <span class="math inline">\(\bar{Y}\)</span> 的標準誤。</p>
</div>
<div id="估計量的特質" class="section level2">
<h2><span class="header-section-number">10.2</span> 估計量的特質</h2>
<p>考慮以下的問題：</p>
<ol style="list-style-type: decimal">
<li>什麼因素決定了一個估計量 (estimator) 的好壞，是否實用？</li>
<li>如果有其他的可選擇估計量，該如何取捨呢？</li>
<li>當情況複雜的時候，我們該如何尋找合適的估計量？</li>
</ol>
<div id="bias" class="section level3">
<h3><span class="header-section-number">10.2.1</span> 偏倚</h3>
<p>假設 <span class="math inline">\(T\)</span> 是我們估計總體參數 <span class="math inline">\(\theta\)</span> 的一個估計量。一般來說我們希望估計量的樣本分佈可以在 <code>“正確的位置”</code> 左右均勻分佈。換句話說我們希望：</p>
<p><span class="math display">\[E(T)=\theta\]</span></p>
<p>如果實現了這個條件，我們說這樣的估計量是無偏的 (<code>unbiased</code>)。然而，天下哪有這等好事，我們叫真實值和估計量之間的差距爲偏倚：</p>
<p><span class="math display">\[bias(T) = E(T)-\theta\]</span></p>
<p>其實偏倚完全等於零並不是最重要，許多常見的估計量都是有偏倚的。重要的是，這個偏倚會隨着樣本量的增加而逐漸趨近於零。所以我們就可以認爲這樣的估計量是漸進無偏的 (asymptotically unbiased)：</p>
<p><span class="math display">\[T\;is\;an\;\textbf{unbiased}\;estimator\;for\;\theta\;if\;\\E(T)=\theta\\
T\;is\;an\;\textbf{asymptotically unbiased}\;estimator\;for\;\theta\;if\;\\lim_{n\rightarrow\infty}E(T)=\theta\]</span></p>
</div>
<div id="估計量的效能-efficiency" class="section level3">
<h3><span class="header-section-number">10.2.2</span> 估計量的效能 Efficiency</h3>
<p>通常，我們希望一個估計量 (estimator) 的偏倚要小，同時，它的樣本分佈也希望能儘可能的不要波動太大。換句話說，我們還希望估計量的方差越小越好。</p>
<p>如果說，兩個估計量有相同的偏倚，均可以選擇來推斷總體，我們說，其中樣本分佈的方差小的那個 (波動幅度小) 的那個估計量是相對更好的。因爲樣本分佈方差越小，說明可以<strong>更加精確的</strong>估計總體參數。這兩個估計量的方差之比：<span class="math inline">\(Var(S)/Var(T)\)</span> 被叫做這兩個估計量的<strong>相對效能 (relative efficiency)</strong>。所以我們用估計量去推斷總體時，需要選用效能最高，精確度最好的估計量 <strong>(the minimum variance unbiased estimator/an efficient estimator)</strong>。</p>
</div>
<div id="均值和中位數的相對效能" class="section level3">
<h3><span class="header-section-number">10.2.3</span> 均值和中位數的相對效能</h3>
<p>在一個服從 <span class="math inline">\(N(\mu,\sigma^2)\)</span> 正態分佈的數據中，中位數和均值是一樣的，也都同時等於總體均值參數 <span class="math inline">\(\mu\)</span>。而且，樣本均數 <span class="math inline">\(\bar{Y}\)</span> 和樣本中位數 <span class="math inline">\(\dot{Y}\)</span> 都是對總體均值的無偏估計量。那麼應該選用中位數還是平均值呢？</p>
<p>之前證明過當 <span class="math inline">\(Y_i \sim N(\mu,\sigma^2)\)</span> 時， <span class="math inline">\(Var(\bar{Y})=\sigma^2/n\)</span>。然而，當 <span class="math inline">\(n\)</span> 較大的時候，可以證明的是：</p>
<p><span class="math display">\[Var(\dot{Y})=\frac{\pi}{2}\frac{\sigma^2}{n}\approx1.571\frac{\sigma^2}{n}\]</span></p>
<p>因此，這兩個估計量的相對效能就是：</p>
<p><span class="math display">\[\frac{Var(\dot{Y})}{Var(\bar{Y})}\approx1.571\]</span></p>
<p>所以總體是正態分佈時，平均值就是較中位數更適合用來估計總體的估計量。</p>
</div>
<div id="均方差-mean-square-error-mse" class="section level3">
<h3><span class="header-section-number">10.2.4</span> 均方差 mean square error (MSE)</h3>
<p>兩個估計量的偏倚不同時，可以比較他們和總體參數之間的差距，這被叫做均方差, Mean Square Error (MSE)。</p>
<p><span class="math display">\[MSE(T)=E[(T-\theta)^2]\]</span></p>
<p>這裏用一個數學技巧，將式子中的估計量和總體參數之間的差，分成兩個部分：一是估計量本身的方差 (<span class="math inline">\(T-E(T)\)</span>)，一是估計量的偏倚 (<span class="math inline">\(E(T)-\theta\)</span>)。</p>
<p><span class="math display">\[
\begin{aligned}
MSE(T) &amp;= E[(T-\theta)^2] \\
       &amp;= E\{[T-E(T)+E(T)-\theta]^2\} \\
       &amp;= E\{[T-E(T)]^2+[E(T)-\theta]^2 \\
       &amp; \;\;\;\;\; \;\;+2[T-E(T)][E(T)-\theta]\} \\
       &amp;= E\{[T-E(T)]^2\}+E\{[E(T)-\theta]^2\} + 0\\
       &amp;= Var(T) + [bias(T)^2]
\end{aligned}
\]</span></p>
</div>
</div>
<div id="samplevarbias" class="section level2">
<h2><span class="header-section-number">10.3</span> 總體方差的估計，自由度</h2>
<p>如果 <span class="math inline">\(Y_i \sim (\mu, \sigma^2)\)</span>，並不需要默認或者假定它服從正態分佈或者任何分佈。那麼它的方差我們會用：</p>
<p><span class="math display">\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2\]</span></p>
<p><strong>證明 <span class="math inline">\(V_{\mu}\)</span> 是 <span class="math inline">\(\sigma^2\)</span> 的無偏估計：</strong></p>
<p><span class="math display">\[
\begin{aligned}
V_{\mu} &amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
 we\;need\;to\;prove &amp;E(V_{\mu}) = \sigma^2 \\
\Rightarrow E(V_{\mu}) &amp;= \frac{1}{n}\sum_{i=1}^nE(Y_i-\mu)^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^nVar(Y_i) \\
        &amp;= \frac{1}{n}\sum_{i=1}^n\sigma^2 \\
        &amp;= \sigma^2
\end{aligned}
\]</span></p>
<p>然而通常情況下，我們並不知道總體的均值 <span class="math inline">\(\mu\)</span>。因此，只好用樣本的均值 <span class="math inline">\(\bar{Y}\)</span> 來估計 <span class="math inline">\(\mu\)</span>。所以上面的方程就變成了：</p>
<p><span class="math display">\[V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span></p>
<p>你如果仔細觀察認真思考，就會發現，上面這個式子是<code>有問題的</code>。這個大問題就在於，<span class="math inline">\(Y_i-\bar{Y}\)</span> 中我們忽略掉了樣本均值 <span class="math inline">\(\bar{Y}\)</span> 和總體均值 <span class="math inline">\(\mu\)</span> 之間的差 (<span class="math inline">\(\bar{Y}-\mu\)</span>)。因此上面的計算式來估計總體方差時，很顯然是會低估平均平方差，從而低估了總體方差。</p>
<p>這裏需要引入<strong>自由度 (degree of freedom)</strong> 在參數估計中的概念。</p>
<p>字面上可以理解爲：自由度是估計過程中使用了多少互相獨立的信息。所以在上面第一個公式中：<span class="math inline">\(V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2\)</span>。所有的 <span class="math inline">\(n\)</span> 個觀察值互相獨立，不僅如此，他們還對總體均值獨立。然而在第二個我們用 <span class="math inline">\(\bar{Y}\)</span> 取代了 <span class="math inline">\(\mu\)</span> 的公式中，樣本均數則與觀察值不互相獨立。因爲<strong>樣本均數必然總是落在觀察值的中間</strong>。然而總體均數並不一定就會落在觀察值中間。總體均數，和觀察值之間是自由，獨立的。因此，當我們觀察到 <span class="math inline">\(n-1\)</span> 個觀察值時，剩下的最後一個觀察值，決定了樣本均值的大小。所以說，樣本均值的自由度，是 <span class="math inline">\(n-1\)</span>。</p>
<p>所以，加入了自由度的討論，我們可以相信，用樣本估計總體的方差時，使用下面的公式將會是總體方差的無偏估計：</p>
<p><span class="math display">\[V_{n-1}=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})=\frac{n}{n-1}V_n\]</span></p>
<p><strong>證明</strong></p>
<p>利用上面也用到過的證明方法 – 把樣本和總體均值之間的差分成兩部分：</p>
<p><span class="math display">\[
\begin{aligned}
V_{\mu} &amp;= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})+(\bar{Y}-\mu)]^2 \\
        &amp;= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})^2+(\bar{Y}-\mu)^2\\
        &amp;\;\;\;\;\;\;\;\;\;\;\;\;+2(Y_i-\bar{Y})(\bar{Y}-\mu)]\\
        &amp;=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2+\frac{1}{n}\sum_{i=1}^n(\bar{Y}-\mu)^2\\
        &amp;\;\;\;\;\;\;\;\;\;\;\;\;+\frac{2}{n}(\bar{Y}-\mu)\sum_{i=1}^n(Y_i-\bar{Y}) \\
        &amp;= V_n+(\bar{Y}-\mu)^2 \\ &amp;\;\;\;\;\;\;\;\;\;\;\;\;(\text{note that}\;\sum_{i=1}^n(Y_i-\bar{Y})=0) \\
\Rightarrow  V_n &amp;= V_{\mu}-(\bar{Y}-\mu)^2  \\
\therefore E(V_n)&amp;= E(V_{\mu}) - E[(\bar{Y}-\mu)^2] \\
                 &amp;= Var(Y)-Var(\bar{Y}) \\
                 &amp;= \sigma^2-\frac{\sigma^2}{n} \\
                 &amp;= \sigma^2(\frac{n-1}{n})
\end{aligned}
\]</span></p>
<p>因此，我們看見 <span class="math inline">\(V_n\)</span> 正如上面討論的那樣，是低估了總體方差的。雖然當 <span class="math inline">\(n\rightarrow\infty\)</span> 時無限接近 <span class="math inline">\(\sigma^2\)</span> 但是依然是低估了的。所以，我們可以對之進行修正：</p>
<p><span class="math display">\[
\begin{aligned}
E[\frac{n}{n-1}V_n]     &amp;= \frac{n}{n-1}E[V_n] =\sigma^2 \\
\Rightarrow E[V_{n-1}]  &amp;= \sigma^2
\end{aligned}
\]</span></p>
</div>
<div id="samplevar" class="section level2">
<h2><span class="header-section-number">10.4</span> 樣本方差的樣本分佈</h2>
<p><span class="math inline">\(S^2\)</span> 常用來標記樣本方差，取代上面我們用到的 <span class="math inline">\(V_{n-1}\)</span>：</p>
<p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span></p>
<p>而且上面也證明了，<span class="math inline">\(E(S^2)=\sigma^2\)</span> 是總體方差的無偏估計。然而，要注意的是，樣本標準差 <span class="math inline">\(\sqrt{S^2}\)</span> 卻不是總體標準差 <span class="math inline">\(\sigma\)</span> 的無偏估計(因爲並不是線性變換，而是開了根號) 。</p>
<p><strong>證明樣本標準差 <span class="math inline">\(S\)</span> 不是總體標準差 <span class="math inline">\(\sigma\)</span> 的無偏估計</strong></p>
<p><span class="math display">\[
\begin{aligned}
Var(S)               &amp;=E(S^2)-[E(S)]^2 \\
\Rightarrow [E(S)]^2 &amp;=E(S^2)-Var(S) \\
\because E(S^2)      &amp;=\sigma^2 \\
\therefore   [E(S)]^2 &amp;=\sigma^2-Var(S) \\
             E(S)     &amp;=\sqrt{\sigma^2-Var(S)} \\
\end{aligned}\]</span></p>
<p><strong>可見樣本標準差是低估了總體標準差的。</strong></p>
<p>另外可以被證明的是：</p>
<p><span class="math display">\[\frac{n-1}{\sigma^2}S^2\sim \mathcal{X}_{n-1}^2\\
Var(S^2)=\frac{2\sigma^4}{n-1}\]</span></p>
<p><span class="math inline">\(\mathcal{X}^2_m\)</span>： 自由度爲 <span class="math inline">\(m\)</span> 的卡方分佈 (Section <a href="#chi-square-distribution">11</a>)。是在圖形上向右歪曲的分佈。當自由度增加時，會越來越接近正態分佈。</p>
</div>
</div>
<div id="chi-square-distribution" class="section level1">
<h1><span class="header-section-number">第 11 章</span> 卡方分佈 Chi-square distribution</h1>
<div id="卡方分佈的期望和方差的證明" class="section level2">
<h2><span class="header-section-number">11.1</span> 卡方分佈的期望和方差的證明</h2>
<p>當 <span class="math inline">\(X\sim N(0,1)\)</span> 時， <span class="math inline">\(X^2\sim \mathcal{X}_1^2\)</span></p>
<p>如果 <span class="math inline">\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)</span>，
那麼 <span class="math inline">\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)</span></p>
<p>其中： <span class="math inline">\(\mathcal{X}_n^2\)</span> 表示自由度爲 <span class="math inline">\(n\)</span> 的卡方分佈。</p>
<p>且 <span class="math inline">\(X_m^2+X_n^2=\mathcal{X}_{m+n}^2\)</span></p>
</div>
<div id="卡方分佈的期望" class="section level2">
<h2><span class="header-section-number">11.2</span> 卡方分佈的期望</h2>
<p><span class="math display">\[E(X_1^2)=Var(X)+[E(X)]^2=1+0=1\]</span></p>
<p><span class="math display">\[\Rightarrow E(X_n^2)=n\]</span></p>
</div>
<div id="卡方分佈的方差" class="section level2">
<h2><span class="header-section-number">11.3</span> 卡方分佈的方差</h2>
<p><span class="math display">\[
\begin{aligned}
Var(X_1^2) &amp;= E(X_1^{2^2}) - E(X_1^2)^2 \\
           &amp;= E(X_1^4)-1
\end{aligned}
\]</span></p>
<div id="下面來求-ex_14" class="section level3">
<h3><span class="header-section-number">11.3.1</span> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></h3>
<p><span class="math display">\[
\begin{aligned}
\because E(X_1) &amp;= \int_{-\infty}^{+\infty} xf(x)dx \\
\therefore E(X_1^4) &amp;= \int_{-\infty}^{+\infty} x^4f(x)dx
\end{aligned}\]</span></p>
<p>已知： <span class="math inline">\(f(x)=\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}\)</span> 代入上式：</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \int_{-\infty}^{+\infty} x^4f(x)dx \\
         &amp;= \int_{-\infty}^{+\infty} x^4\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}dx\\
         &amp;=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^4e^{(-\frac{x^2}{2})}dx\\
         &amp;=\frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^3(-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>令 <span class="math inline">\(u=x^3, v=e^{(-\frac{x^2}{2})},t=-\frac{x^2}{2}\)</span>
可以推導：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{dv}{dx} &amp;= \frac{dv}{dt}\frac{dt}{dx} \\
              &amp;= e^t(-\frac{1}{2}\times2x) \\
              &amp;= (-x)e^{(-\frac{x^2}{2})} \\
\Rightarrow dv &amp;= (-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>再代入上面的式子：</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u\:dv \\
integrate\; &amp;by\; parts:\\
E(X_1^4) &amp;= \frac{-1}{\sqrt{2\pi}}\{[u\:v] \rvert_{-\infty}^{+\infty}-\int_{-\infty}^{+\infty}v\:du\} \\
&amp;= \frac{-1}{\sqrt{2\pi}}\{[x^3e^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}v\:du\} \\
&amp;=\frac{-1}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx^3\} \\
&amp;=\frac{-1}{\sqrt{2\pi}}[-3\int_{-\infty}^{+\infty}x^2e^{(-\frac{x^2}{2})}dx] \\
&amp;=\frac{-3}{\sqrt{2\pi}}[\int_{-\infty}^{+\infty}x(-x)e^{(-\frac{x^2}{2})}dx] \\
\end{aligned}
\]</span></p>
<p>再來一次分部積分：</p>
<p>令 <span class="math inline">\(a=x,b=e^{(-\frac{x^2}{2})},d\:b = (-x)e^{(-\frac{x^2}{2})}dx\)</span></p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{-3}{\sqrt{2\pi}}\{[a\:b] \rvert_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty}b\:da\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}\{[xe^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}b\:da\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\} \\
&amp;=\frac{-3}{\sqrt{2\pi}}[-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx] \\
&amp;=\frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx
\end{aligned}
\]</span></p>
<p>下面令 <span class="math inline">\(I=\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\\ \Rightarrow I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy\)</span></p>
<p>接下來需要用到 <a href="https://www.youtube.com/watch?v=r0fv9V9GHdo">座標轉換</a>的知識，將 <span class="math inline">\(x,y\)</span> 表示的笛卡爾座標，轉換爲用角度 <span class="math inline">\(\theta\)</span> 和半徑 <span class="math inline">\(r\)</span> 表示的形式。之後的證明可以在<a href="https://www.youtube.com/watch?v=fWOGfzC3IeY">油管</a>上看到，但是我還是繼續證明下去。</p>
<p>直角座標系 (cartesian coordinators) 和
極座標系 (polar coordinators) 之間轉換的關係如下：</p>
<p><span class="math display">\[
\begin{aligned}
x&amp;=r\:cos\theta\\
y&amp;=r\:sin\theta\\
r^2&amp;=x^2+y^2\\
\end{aligned}
\]</span></p>
<p>座標轉換以後可以繼續求 <span class="math inline">\(E(X_1^4)\)</span>。 在那之前我們先求 <span class="math inline">\(I^2\)</span>。
注意轉換座標系統以後，<span class="math inline">\(\theta\in[0,2\pi], r\in[0,+\infty]\)</span></p>
<p><span class="math display">\[
\begin{aligned}
I^2 &amp;= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy \\
&amp;= \int_{0}^{+\infty}\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta dr \\
\end{aligned}
\]</span></p>
<p>由於先從中間的 <span class="math inline">\(\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta\)</span> 開始積分，<span class="math inline">\(\theta\)</span> 以外都可以視爲常數，那麼這個 <span class="math inline">\([0,2\pi]\)</span> 上的積分就的等於 <span class="math inline">\(2\pi e^{(-\frac{r^2}{2})}r\)</span>。</p>
<p>因此上面的式子又變爲：</p>
<p><span class="math display">\[
\begin{aligned}
I^2 &amp;=  2\pi\int_{0}^{+\infty}e^{(-\frac{r^2}{2})}r\:dr \\
\because \frac{d(e^{\frac{-r^2}{2}})}{dr} &amp;= -e^{(-\frac{r^2}{2})}r \\
\therefore I^2 &amp;= 2\pi(-e^{\frac{-r^2}{2}})\rvert_0^{+\infty} \\
               &amp;= 0-(2\pi\times(-1)) \\
               &amp;= 2\pi\\
\Rightarrow I  &amp;= \sqrt{2\pi}
\end{aligned}
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[
\begin{aligned}
E(X_1^4) &amp;= \frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx \\
&amp;= \frac{3}{\sqrt{2\pi}}\times I \\
&amp;= 3 \\
\Rightarrow Var(X_1^2) &amp;= E(X_1^4) - 1 \\
                       &amp;= 3-1 =2
\end{aligned}
\]</span></p>
</div>
</div>
<div id="把上面的推導擴展" class="section level2">
<h2><span class="header-section-number">11.4</span> 把上面的推導擴展</h2>
<p><span class="math display">\[
\text{Suppose } \mathcal{X}^2_1, \cdots \mathcal{X}^2_k \stackrel{i.i.d}{\sim} \mathcal{X}^2_1 \\
\Rightarrow \sum_{i=1}^k \mathcal{X}^2_i \sim \mathcal{X}^2_k \\
\Rightarrow \text{E}(\sum_{i=1}^n\mathcal{X}^2_i)=\sum_{i-1}^n\text{E}(\mathcal{X}^2_i)=n\times1=n\\
\text{Var}(\sum_{i=1}^n\mathcal{X}^2_i)=\sum_{i=1}^n\text{Var}(\mathcal{X}^2_i) = n\times2=2n
\]</span></p>
<p>結論：<span class="math inline">\(X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)\)</span> 時，<span class="math inline">\(\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2\)</span> 服從卡方分佈，其期望 <span class="math inline">\(E(X_n^2)=n\)</span>，方差 <span class="math inline">\(Var(X_n^2)=2n\)</span>。
根據<strong>中心極限定理</strong>(Section <a href="#CLT">8</a>)</p>
<p><span class="math display">\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]</span></p>
</div>
</div>
<div id="likelihood-definition" class="section level1">
<h1><span class="header-section-number">第 12 章</span> 似然 Likelihood</h1>
<div id="概率-vs.-推斷-probability-vs.-inference" class="section level2">
<h2><span class="header-section-number">12.1</span> 概率 vs. 推斷 Probability vs. Inference</h2>
<p>在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 <span class="math inline">\(0.5\; Prob(coin\;landing\;heads)=0.5\)</span>。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率(例如，10次投擲硬幣以後4次正面朝上的概率是多少？) 。</p>
<p><span class="math display">\[
\binom{10}{4}\times(0.5^4)\times(0.5^{10-4}) = 0.205
\]</span></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1"><span class="kw">dbinom</span>(<span class="dv">4</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.2051</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="co"># or you can calculate by hand:</span></a>
<a class="sourceLine" id="cb20-2" title="2"><span class="kw">factorial</span>(<span class="dv">10</span>)<span class="op">*</span>(<span class="fl">0.5</span><span class="op">^</span><span class="dv">10</span>)<span class="op">/</span>(<span class="kw">factorial</span>(<span class="dv">4</span>)<span class="op">*</span>(<span class="kw">factorial</span>(<span class="dv">6</span>)))</a></code></pre></div>
<pre><code>## [1] 0.2051</code></pre>
<p>在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少(神如果存在話，只有神知道) 。故這個 <span class="math inline">\(Prob(coin\;landing\;heads)\)</span> 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，<strong>似然法 (likelihood)</strong> 就是我們進行參數估計的最佳手段。</p>
</div>
<div id="似然和極大似然估計-likelihood-and-maximum-likelihood-estimators" class="section level2">
<h2><span class="header-section-number">12.2</span> 似然和極大似然估計 Likelihood and maximum likelihood estimators</h2>
<p>此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患<del>中二</del>病，我們假定這個患病的概率爲 <span class="math inline">\(\pi\)</span>。於是我們就有了下面的模型：</p>
<p><strong>模型：</strong> 我們假定患病與否是一個服從<strong>二項分佈的隨機變量</strong>，<span class="math inline">\(X\sim Bin(10,\pi)\)</span>。同時也默認每個人之間是否患病是相互獨立的。</p>
<p><strong>數據：</strong> 觀察到的數據是，10人中有4人患病。於是 <span class="math inline">\(x=4\)</span>。</p>
<p>現在按照觀察到的數據，參數 <span class="math inline">\(\pi\)</span> 變成了未知數：</p>
<p><span class="math display">\[Prob(X=4|\pi)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]</span></p>
<p>此時我們會很自然的考慮，當 <span class="math inline">\(\pi\)</span> 是未知數的時候，<strong>它取值爲多大的時候才能讓這個事件(即：10人中4人患病) 發生的概率最大？</strong> 所以我們可以將不同的數值代入 <span class="math inline">\(\pi\)</span> 來計算該事件在不同概率的情況下發生的可能性到底是多少：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Table 12.1: The probability of observing <span class="math inline">\(X=4\)</span>
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(\pi\)</span>
</th>
<th style="text-align:center;">
事件 <span class="math inline">\(X=4\)</span> 發生的概率
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.0
</td>
<td style="text-align:center;">
0.000
</td>
</tr>
<tr>
<td style="text-align:center;">
0.2
</td>
<td style="text-align:center;">
0.088
</td>
</tr>
<tr>
<td style="text-align:center;">
<strong>0.4</strong>
</td>
<td style="text-align:center;">
<strong>0.251</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.205
</td>
</tr>
<tr>
<td style="text-align:center;">
0.6
</td>
<td style="text-align:center;">
0.111
</td>
</tr>
<tr>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
0.006
</td>
</tr>
<tr>
<td style="text-align:center;">
1.0
</td>
<td style="text-align:center;">
0.000
</td>
</tr>
</tbody>
</table>
<p>很顯然，如果 <span class="math inline">\(\pi=0.4\)</span> 時，我們觀察到的事件發生的概率要比 <span class="math inline">\(\pi\)</span> 取其它值時更大。於是小總結一下目前爲止的步驟如下：</p>
<ul>
<li>觀察到實驗數據(10人中4個患病) ；</li>
<li>假定這數據服從二項分佈的概率模型，計算不同(<span class="math inline">\(\pi\)</span> 的取值不同的) 情況下，該事件按照假定模型發生的概率；</li>
<li>通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (<span class="math inline">\(\pi=0.4\)</span>)。</li>
</ul>
<p>至此，我們可以知道，似然方程，是一個關於未知參數 <span class="math inline">\(\pi\)</span> 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 <span class="math inline">\(\pi\)</span> ：</p>
<p><span class="math display">\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\]</span></p>
<p>我們可以畫出這個似然方程的形狀， <span class="math inline">\(\pi\in[0,1]\)</span></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)</a>
<a class="sourceLine" id="cb22-2" title="2">y &lt;-<span class="st"> </span>(<span class="kw">factorial</span>(<span class="dv">10</span>)<span class="op">/</span>(<span class="kw">factorial</span>(<span class="dv">4</span>)<span class="op">*</span>(<span class="kw">factorial</span>(<span class="dv">6</span>))))<span class="op">*</span>(x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>)</a>
<a class="sourceLine" id="cb22-3" title="3"><span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.3</span>), <span class="dt">ylab =</span> <span class="st">&quot;L(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb22-4" title="4"><span class="co">#title(&quot;Figure 1. Binomial Likelihood&quot;)</span></a>
<a class="sourceLine" id="cb22-5" title="5"><span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">0.251</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb22-6" title="6"><span class="kw">abline</span>(<span class="dt">v=</span><span class="fl">0.4</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:binomial-likelihood"></span>
<img src="bookdown_files/figure-html/binomial-likelihood-1.png" alt="Binomial Likelihood" width="90%" />
<p class="caption">
圖 12.1: Binomial Likelihood
</p>
</div>
<p>從圖形上我們也能確認，<span class="math inline">\(\pi=0.4\)</span> 時能夠讓這個似然方程取得最大值。</p>
</div>
<div id="似然方程的一般化定義" class="section level2">
<h2><span class="header-section-number">12.3</span> 似然方程的一般化定義</h2>
<p>對於一個概率模型，如果其參數爲 <span class="math inline">\(\theta\)</span>，那麼在給定觀察數據 <span class="math inline">\(\underline{x}\)</span> 時，該參數的似然方程被定義爲：</p>
<p><span class="math inline">\(L(\theta|\underline{x})=P(\underline{x}|\theta)\)</span></p>
<p>注意：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(\underline{x}|\theta)\)</span> 可以是概率(離散分佈) 方程，也可以是概率密度(連續型變量) 方程。對於此方程，<span class="math inline">\(\theta\)</span> 是給定的，然後再計算某些事件發生的概率。</li>
<li><span class="math inline">\(L(\theta|\underline{x})\)</span> 是一個關於參數 <span class="math inline">\(\theta\)</span> 的方程，此時，<span class="math inline">\(\underline{x}\)</span> 是固定不變的(觀察值) 。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。</li>
<li>似然方程<strong>不是</strong>一個概率密度方程。</li>
</ol>
<p>另一個例子：</p>
<p>有一組觀察數據是離散型隨機變量 <span class="math inline">\(X\)</span>，它符合概率方程 <span class="math inline">\(f(x|\theta)\)</span>。下表羅列了當 <span class="math inline">\(\theta\)</span> 分別取值 <span class="math inline">\(1,2,3\)</span> 時的概率方程的值，試求每個觀察值 <span class="math inline">\(X = 0,1,2,3,4\)</span> 的最大似然參數估計：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Exercise 12.3
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(x\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|1)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|2)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|3)\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/6
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/2
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Exercise 12.3 answer
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(x\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|1)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|2)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(f(x|3)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\theta\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
<strong>1</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
<strong>1</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
<strong>2</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
1/4
</td>
<td style="text-align:center;">
1/2
</td>
<td style="text-align:center;">
<strong>3</strong>
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1/6
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1/3
</td>
<td style="text-align:center;">
<strong>3</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="對數似然方程-log-likelihood" class="section level2">
<h2><span class="header-section-number">12.4</span> 對數似然方程 log-likelihood</h2>
<p>似然方程的最大值，可通過求 <span class="math inline">\(L(\theta|data)\)</span> 的最大值獲得，也可以通過求該方程的對數方程 <span class="math inline">\(\ell(\theta|data)\)</span> 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”(因爲這是觀察獲得的數據告訴我們的參數) ： <span class="math inline">\(\hat{\theta}\)</span>。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=\ell^\prime(\theta)=0\\
AND\\
\frac{d^2\ell}{d\theta^2}&lt;0\]</span></p>
<p>要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了：</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="dt">by=</span><span class="fl">0.001</span>)</a>
<a class="sourceLine" id="cb23-2" title="2">y &lt;-<span class="st"> </span>(x<span class="dv">-1</span>)<span class="op">^</span><span class="dv">2-5</span></a>
<a class="sourceLine" id="cb23-3" title="3"><span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">0-1</span>), <span class="dt">ylab =</span> <span class="st">&quot;L(\U03B8)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03B8&quot;</span>)</a>
<a class="sourceLine" id="cb23-4" title="4"><span class="co">#title(&quot;Figure 2. Likelihood function with \n a limited domain&quot;)</span></a>
<a class="sourceLine" id="cb23-5" title="5"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:likelihood-limited"></span>
<img src="bookdown_files/figure-html/likelihood-limited-1.png" alt="Likelihood function with a limited domain" width="90%" />
<p class="caption">
圖 12.2: Likelihood function with a limited domain
</p>
</div>
<p><strong>證明：當 <span class="math inline">\(L(\theta|data)\)</span> 取最大值時，該方程的對數方程 <span class="math inline">\(\ell(\theta|data)\)</span> 也是最大值：</strong></p>
<p>如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 <span class="math inline">\(\hat{\theta}\)</span> 使該方程取最大值，那麼：</p>
<p><span class="math display">\[\frac{dL}{d\theta}=0, \frac{d^2L}{d\theta^2}&lt;0 \Rightarrow \theta=\hat{\theta}\]</span></p>
<p>令 <span class="math inline">\(\ell=\text{log}L\)</span> 那麼 <span class="math inline">\(\frac{d\ell}{dL}=\ell^\prime=\frac{1}{L}\)</span>：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=\frac{d\ell}{dL}\cdot\frac{dL}{d\theta}=\frac{1}{L}\cdot\frac{dL}{d\theta}\]</span></p>
<p>當 <span class="math inline">\(\ell(\theta|data)\)</span> 取最大值時：</p>
<p><span class="math display">\[\frac{d\ell}{d\theta}=0\Leftrightarrow\frac{1}{L}\cdot\frac{dL}{d\theta}=0\\
\because \frac{1}{L}\neq0 \\
\therefore \frac{dL}{d\theta}=0\\
\Leftrightarrow \theta=\hat{\theta}\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{d^2\ell}{d\theta^2} &amp;= \frac{d}{d\theta}(\frac{d\ell}{dL}\cdot\frac{dL}{d\theta})\\
 &amp;= \frac{d\ell}{dL}\cdot\frac{d^2L}{d\theta^2} + \frac{dL}{d\theta}\cdot\frac{d}{d\theta}(\frac{d\ell}{dL})
\end{aligned}
\]</span></p>
<p>當 <span class="math inline">\(\theta=\hat{\theta}\)</span> 時，<span class="math inline">\(\frac{dL}{d\theta}=0\)</span> 且 <span class="math inline">\(\frac{d^2L}{d\theta^2}&lt;0 \Rightarrow \frac{d^2\ell}{d\theta^2}&lt;0\)</span></p>
<p>所以，求獲得 <span class="math inline">\(\ell(\theta|data)\)</span> 最大值的 <span class="math inline">\(\theta\)</span> 即可令 <span class="math inline">\(L(\theta|data)\)</span> 獲得最大值。</p>
</div>
<div id="極大似然估計-maximum-likelihood-estimator-mle-的性質" class="section level2">
<h2><span class="header-section-number">12.5</span> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</h2>
<ol style="list-style-type: decimal">
<li>漸進無偏 Asymptotically unbiased: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow E(\hat{\Theta}) \rightarrow \theta\)</span></li>
<li>漸進最高效能 Asymptotically efficient: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow Var(\hat{\Theta})\)</span> 是所有參數中方差最小的估計</li>
<li>漸進正態分佈 Asymptotically normal: <br> <span class="math inline">\(n\rightarrow \infty \Rightarrow \hat{\Theta} \sim N(\theta, Var(\hat{\Theta}))\)</span></li>
<li>變形後依然保持不變 Transformation invariant: <br> <span class="math inline">\(\hat{\Theta}\)</span> 是 <span class="math inline">\(\theta\)</span> 的MLE時 <span class="math inline">\(\Rightarrow g(\hat{\Theta})\)</span> 是 <span class="math inline">\(g(\theta)\)</span> 的 MLE</li>
<li>信息足夠充分 Sufficient：<br> <span class="math inline">\(\hat{\Theta}\)</span> 包含了觀察數據中所有的能夠用於估計參數的信息</li>
<li>始終不變 consistent: <br> <span class="math inline">\(n\rightarrow\infty\Rightarrow\hat{\Theta}\rightarrow\theta\)</span> 或者可以寫成：<span class="math inline">\(\varepsilon&gt;0, lim_{n\rightarrow\infty}P(|\hat{\Theta}-\theta|&gt;\varepsilon)=0\)</span></li>
</ol>
</div>
<div id="likelihood-poi" class="section level2">
<h2><span class="header-section-number">12.6</span> 率的似然估計 Likelihood for a rate</h2>
<p>如果在一項研究中，參與者有各自不同的追蹤隨訪時間(長度) ，那麼我們應該把事件(疾病) 的發病率用率的形式(多少事件每單位人年, e.g. per person year of observation) 。如果這個發病率的參數用 <span class="math inline">\(\lambda\)</span> 來表示，所有參與對象的隨訪時間之和爲 <span class="math inline">\(p\)</span> 人年。那麼這段時間內的期望事件(疾病發病) 次數爲：<span class="math inline">\(\mu=\lambda p\)</span>。假設事件(疾病發病) 發生是相互獨立的，可以使用泊松分佈來模擬期望事件(疾病發病) 次數 <span class="math inline">\(D\)</span>：</p>
<p><span class="math display">\[D\sim Poi(\mu)\]</span></p>
<p>假設我們觀察到了 <span class="math inline">\(D=d\)</span> 個事件，我們獲得這個觀察值的概率應該用以下的模型：</p>
<p><span class="math display">\[Prob(D=d)=e^{-\mu}\frac{\mu^d}{d!}=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]</span></p>
<p>因此，<span class="math inline">\(\lambda\)</span> 的似然方程是：</p>
<p><span class="math display">\[L(\lambda|observed \;data)=e^{-\lambda p}\frac{\lambda^dp^d}{d!}\]</span></p>
<p>所以，<span class="math inline">\(\lambda\)</span> 的對數似然方程是：</p>
<p><span class="math display">\[
\begin{aligned}
\ell(\lambda|observed\;data) &amp;= \text{log}(e^{-\lambda p}\frac{\lambda^dp^d}{d!}) \\
  &amp;= -\lambda p+d\:\text{log}(\lambda)+d\:\text{log}(p)-\text{log}(d!) \\
\end{aligned}
\]</span></p>
<p>解 <span class="math inline">\(\ell^\prime(\lambda|data)=0\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\ell^\prime(\lambda|data) &amp;= -p+\frac{d}{\lambda}=0\\
\Rightarrow \hat{\lambda} &amp;= \frac{d}{p} \\
\end{aligned}
\]</span></p>
<p><strong>注意：</strong>
在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，<span class="math inline">\(d\:\text{log}(p)-\text{log}(d!)\)</span> 不包含參數 <span class="math inline">\(\lambda\)</span> 可以直接不寫出來。</p>
</div>
<div id="有-n-個獨立觀察時的似然方程和對數似然方程" class="section level2">
<h2><span class="header-section-number">12.7</span> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</h2>
<p>當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之<strong>乘積</strong>。如果 <span class="math inline">\(X_1,\dots,X_n\stackrel{i.i.d}{\sim}f(\cdot|\theta)\)</span></p>
<p><span class="math display">\[L(\theta|x_1,\cdots,x_n)=f(x_1,\cdots,x_n|\theta)=\prod_{i=1}^nf(x_i|\theta)\\
\Rightarrow \ell(\theta|x_1,\cdots,x_n)=\sum_{i=1}^n\text{log}(f(x_i|\theta))\]</span></p>
</div>
</div>
<div id="llr" class="section level1">
<h1><span class="header-section-number">第 13 章</span> 對數似然比 Log-likelihood ratio</h1>
<p>對數似然比的想法來自於將對數似然方程圖形的 <span class="math inline">\(y\)</span> 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的<strong>對數似然比 (log-likelihood ratio)</strong> 來獲得：</p>
<p><span class="math display">\[llr(\theta)=\ell(\theta|data)-\ell(\hat{\theta}|data)\]</span></p>
<p>由於 <span class="math inline">\(\ell(\theta)\)</span> 的最大值在 <span class="math inline">\(\hat{\theta}\)</span> 時， 所以，<span class="math inline">\(llr(\theta)\)</span> 就是個當 <span class="math inline">\(\theta=\hat{\theta}\)</span> 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 <span class="math inline">\(LR(\theta)=\frac{L(\theta)}{L(\hat{\theta})}\)</span> 取對數而已。</p>
<p><a href="https://winterwang.github.io/post/likelihood/">之前</a>我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子：</p>
<p><span class="math display">\[L(\pi|X=4)=\binom{10}{4}\pi^4(1-\pi)^{10-4}\\
\Rightarrow \ell(\pi)=\text{log}[\pi^4(1-\pi)^{10-4}]\\
\Rightarrow llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=\text{log}\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]</span></p>
<p>其實由上也可以看出 <span class="math inline">\(llr(\theta)\)</span> 只是將對應的似然方程的 <span class="math inline">\(y\)</span> 軸重新調節了一下而已。形狀是沒有改變的：</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb24-2" title="2">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)</a>
<a class="sourceLine" id="cb24-3" title="3">y &lt;-<span class="st"> </span>(x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>)<span class="op">/</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)</a>
<a class="sourceLine" id="cb24-4" title="4">z &lt;-<span class="st"> </span><span class="kw">log</span>((x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>))<span class="op">-</span><span class="kw">log</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)</a>
<a class="sourceLine" id="cb24-5" title="5"><span class="kw">plot</span>(x, y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.1</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>,</a>
<a class="sourceLine" id="cb24-6" title="6">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;LR(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb24-7" title="7"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.2</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-8" title="8"><span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial likelihood ratio&quot;</span>)</a>
<a class="sourceLine" id="cb24-9" title="9"><span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">1.0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-10" title="10"><span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.4</span>, <span class="dt">y0=</span><span class="dv">0</span>, <span class="dt">x1=</span><span class="fl">0.4</span>, <span class="dt">y1=</span><span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-11" title="11"><span class="kw">plot</span>(x, z, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">1</span>), <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb24-12" title="12">     <span class="dt">ylab =</span> <span class="st">&quot;llr(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )</a>
<a class="sourceLine" id="cb24-13" title="13"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-14" title="14"><span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial log-likelihood ratio&quot;</span>)</a>
<a class="sourceLine" id="cb24-15" title="15"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb24-16" title="16"><span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.4</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">10</span>, <span class="dt">x1=</span><span class="fl">0.4</span>, <span class="dt">y1=</span><span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:binomial-logornot"></span>
<img src="bookdown_files/figure-html/binomial-logornot-1.png" alt="Binomial likelihood ratio and log-likelihood ratio" width="90%" />
<p class="caption">
圖 13.1: Binomial likelihood ratio and log-likelihood ratio
</p>
</div>
<div id="正態分佈數據的極大似然和對數似然比" class="section level2">
<h2><span class="header-section-number">13.1</span> 正態分佈數據的極大似然和對數似然比</h2>
<p>假設單個樣本 <span class="math inline">\(y\)</span> 是來自一組服從正態分佈數據的觀察值：<span class="math inline">\(Y\sim N(\mu, \tau^2)\)</span></p>
<p>那麼有：</p>
<p><span class="math display">\[
\begin{aligned}
f(y|\mu) &amp;= \frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow L(\mu|y) &amp;=\frac{1}{\sqrt{2\pi\tau^2}}e^{(-\frac{1}{2}(\frac{y-\mu}{\tau})^2)} \\
\Rightarrow \ell(\mu)&amp;=\text{log}(\frac{1}{\sqrt{2\pi\tau^2}})-\frac{1}{2}(\frac{y-\mu}{\tau})^2\\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;= -\frac{1}{2}(\frac{y-\mu}{\tau})^2 \\
\Rightarrow \ell^\prime(\mu) &amp;= 2\cdot[-\frac{1}{2}(\frac{y-\mu}{\tau})\cdot\frac{-1}{\tau}] \\
&amp;=\frac{y-\mu}{\tau^2} \\
let \; \ell^\prime(\mu) &amp;= 0 \\
\Rightarrow \frac{y-\mu}{\tau^2} &amp;= 0 \Rightarrow \hat{\mu} = y\\
\because \ell^{\prime\prime}(\mu) &amp;=  \frac{-1}{\tau^2} &lt; 0 \\
\therefore \hat{\mu} &amp;= y \Rightarrow \ell(\hat{\mu}=y)_{max}=0 \\
llr(\mu)&amp;=\ell(\mu)-\ell(\hat{\mu})=\ell(\mu)\\
&amp;=-\frac{1}{2}(\frac{y-\mu}{\tau})^2
\end{aligned}
\]</span></p>
</div>
<div id="llr-chi1" class="section level2">
<h2><span class="header-section-number">13.2</span> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</h2>
<p>假設一組觀察值來自正態分佈 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>，先假設 <span class="math inline">\(\sigma^2\)</span> 已知。將觀察數據 <span class="math inline">\(x_1,\cdots, x_n\)</span> 標記爲 <span class="math inline">\(\underline{x}\)</span>。 那麼：</p>
<p><span class="math display">\[
\begin{aligned}
L(\mu|\underline{x}) &amp;=\prod_{i=1}^nf(x_i|\mu)\\
\Rightarrow \ell(\mu|\underline{x}) &amp;=\sum_{i=1}^n\text{log}f(x_i|\mu)\\
&amp;=\sum_{i=1}^n[-\frac{1}{2}(\frac{x_i-\mu}{\sigma})^2]\\
&amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
&amp;=-\frac{1}{2\sigma^2}[\sum_{i=1}^n(x_i-\bar{x})^2+\sum_{i=1}^n(\bar{x}-\mu)^2]\\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;=-\frac{1}{2\sigma^2}\sum_{i=1}^n(\bar{x}-\mu)^2\\
&amp;=-\frac{n}{2\sigma^2}(\bar{x}-\mu)^2 \\
&amp;=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
\because \ell(\hat{\mu}) &amp;= 0 \\
\therefore llr(\mu) &amp;= \ell(\mu)-\ell(\hat{\mu}) = \ell(\mu)
\end{aligned}
\]</span></p>
</div>
<div id="llr-chi" class="section level2">
<h2><span class="header-section-number">13.3</span> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</h2>
<p>假設我們用 <span class="math inline">\(\mu_0\)</span> 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。</p>
<p>考慮一個服從正態分佈的單樣本 <span class="math inline">\(Y\)</span>: <span class="math inline">\(Y\sim N(\mu_0,\tau^2)\)</span>。那麼它的對數似然比：</p>
<p><span class="math display">\[llr(\mu_0|Y)=\ell(\mu_0)-\ell(\hat{\mu})=-\frac{1}{2}(\frac{Y-\mu_0}{\tau})^2\]</span></p>
<p>根據<strong>卡方分佈</strong> (Section <a href="#chi-square-distribution">11</a>) 的定義：</p>
<p><span class="math display">\[\because \frac{Y-\mu_0}{\tau}\sim N(0,1)\\
\Rightarrow (\frac{Y-\mu_0}{\tau})^2 \sim \mathcal{X}_1^2\\
\therefore -2llr(\mu_0|Y) \sim \mathcal{X}_1^2\]</span></p>
<p>所以，如果有一組服從正態分佈的觀察值：<span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu_0,\sigma^2)\)</span>，且 <span class="math inline">\(\sigma^2\)</span> 已知的話：</p>
<p><span class="math display">\[-2llr(\mu_0|\bar{X})\sim \mathcal{X}_1^2\]</span></p>
<p>根據<strong>中心極限定理</strong> (Section <a href="#CLT">8</a>)，可以將上面的結論一般化：</p>

<div class="theorem">
<span id="thm:inference04" class="theorem"><strong>Theorem 13.1  </strong></span>如果 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\theta)\)</span>。 那麼當重複多次從參數爲 <span class="math inline">\(\theta_0\)</span> 的總體中取樣時，那麼統計量 <span class="math inline">\(-2llr(\theta_0)\)</span> 會漸進於自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈： <span class="math display">\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\xrightarrow[n\rightarrow\infty]{}\;\sim \mathcal{X}_1^2\]</span>
</div>

</div>
<div id="似然比信賴區間" class="section level2">
<h2><span class="header-section-number">13.4</span> 似然比信賴區間</h2>
<p>如果樣本量 <span class="math inline">\(n\)</span> 足夠大 (通常應該大於 <span class="math inline">\(30\)</span>)，根據上面的定理：</p>
<p><span class="math display">\[-2llr(\theta_0)=-2\{\ell(\theta_0)-\ell(\hat{\theta})\}\sim \mathcal{X}_1^2\]</span></p>
<p>所以：</p>
<p><span class="math display">\[Prob(-2llr(\theta_0)\leqslant \mathcal{X}_{1,0.95}^2=3.84) = 0.95\\
\Rightarrow Prob(llr(\theta_0)\geqslant-3.84/2=-1.92) = 0.95\]</span></p>
<p>故似然比的 <span class="math inline">\(95\%\)</span> 信賴區間就是能夠滿足 <span class="math inline">\(llr(\theta)=-1.92\)</span> 的兩個 <span class="math inline">\(\theta\)</span> 值。</p>
<div id="binomial-ex" class="section level3">
<h3><span class="header-section-number">13.4.1</span> 以二項分佈數據爲例</h3>
<p>繼續用本文開頭的例子：</p>
<p><span class="math display">\[llr(\pi)=\ell(\pi)-\ell(\hat{\pi})=\text{log}\frac{\pi^4(1-\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\]</span></p>
<p>如果令 <span class="math inline">\(llr(\pi)=-1.92\)</span> 在代數上可能較難獲得答案。然而從圖形上，如果我們在 <span class="math inline">\(y=-1.92\)</span> 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限：</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.001</span>)</a>
<a class="sourceLine" id="cb25-2" title="2">z &lt;-<span class="st"> </span><span class="kw">log</span>((x<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>x)<span class="op">^</span><span class="dv">6</span>))<span class="op">-</span><span class="kw">log</span>(<span class="fl">0.4</span><span class="op">^</span><span class="dv">4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">^</span><span class="dv">6</span>)</a>
<a class="sourceLine" id="cb25-3" title="3"><span class="kw">plot</span>(x, z, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">1</span>), <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb25-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;llr(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )</a>
<a class="sourceLine" id="cb25-5" title="5"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb25-6" title="6"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb25-7" title="7"><span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb25-8" title="8"><span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.15</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">12</span>, <span class="dt">x1=</span><span class="fl">0.15</span>, <span class="dt">y1=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb25-9" title="9"><span class="kw">segments</span>(<span class="dt">x0=</span><span class="fl">0.7</span>, <span class="dt">y0=</span><span class="op">-</span><span class="dv">12</span>, <span class="dt">x1=</span><span class="fl">0.7</span>, <span class="dt">y1=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb25-10" title="10"><span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">at=</span><span class="kw">c</span>(<span class="fl">0.15</span>,<span class="fl">0.7</span>))</a>
<a class="sourceLine" id="cb25-11" title="11"><span class="kw">text</span>(<span class="fl">0.9</span>, <span class="dv">-1</span>, <span class="st">&quot;-1.92&quot;</span>)</a>
<a class="sourceLine" id="cb25-12" title="12"><span class="kw">arrows</span>(<span class="fl">0.8</span>, <span class="fl">-1.92</span>, <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">length =</span> <span class="fl">0.08</span>)</a>
<a class="sourceLine" id="cb25-13" title="13"><span class="kw">arrows</span>( <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="fl">0.8</span>, <span class="fl">-1.92</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">length =</span> <span class="fl">0.08</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin-llr-95"></span>
<img src="bookdown_files/figure-html/bin-llr-95-1.png" alt="Log-likelihood ratio for binomial example, with 95% confidence intervals shown" width="90%" />
<p class="caption">
圖 13.2: Log-likelihood ratio for binomial example, with 95% confidence intervals shown
</p>
</div>
<p>從上圖中可以讀出，<span class="math inline">\(95\%\)</span> 對數似然比信賴區間就是 <span class="math inline">\((0.15, 0.7)\)</span></p>
</div>
<div id="normal-ex" class="section level3">
<h3><span class="header-section-number">13.4.2</span> 以正態分佈數據爲例</h3>
<p>本文前半部分證明過，
<span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>，先假設 <span class="math inline">\(\sigma^2\)</span> 已知。將觀察數據 <span class="math inline">\(x_1,\cdots, x_n\)</span> 標記爲 <span class="math inline">\(\underline{x}\)</span>。 那麼：</p>
<p><span class="math display">\[llr(\mu|\underline{x}) = \ell(\mu|\underline{x})-\ell(\hat{\mu}) = \ell(\mu|\underline{x}) \\
=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]</span></p>
<p>很顯然，這是一個關於 <span class="math inline">\(\mu\)</span> 的二次方程，且最大值在 MLE <span class="math inline">\(\hat{\mu}=\bar{x}\)</span> 時取值 <span class="math inline">\(0\)</span>。所以可以通過對數似然比法求出均值的 <span class="math inline">\(95\%\)</span> 信賴區間公式：</p>
<p><span class="math display">\[-2\times[-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2]=3.84\\
\Rightarrow L=\bar{x}-\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
U=\bar{x}+\sqrt{3.84}\frac{\sigma}{\sqrt{n}} \\
note: \;\sqrt{3.84}=1.96\]</span></p>
<p>注意到這和我們之前求的正態分佈均值的信賴區間公式 (Section <a href="#CI-for-sample-mean">10.1</a>) 完全一致。</p>
</div>
</div>
<div id="練習題" class="section level2">
<h2><span class="header-section-number">13.5</span> 練習題</h2>
<div id="q1" class="section level3">
<h3><span class="header-section-number">13.5.1</span> Q1</h3>
<ol style="list-style-type: lower-alpha">
<li>假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 <span class="math inline">\(\pi\)</span> 的似然方程和圖形 (likelihood) ?</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[\begin{aligned}
 L(\pi|3) &amp;= \binom{10}{3}\pi^3(1-\pi)^{10-3} \\
 omitting\;&amp;terms\;not\;in\;\pi \\
 \Rightarrow \ell(\pi|3) &amp;= \text{log}[\pi^3(1-\pi)^7] \\
 &amp;= 3\text{log}\pi+7\text{log}(1-\pi)\\
 \Rightarrow \ell^\prime(\pi|3)&amp;= \frac{3}{\pi}-\frac{7}{1-\pi} \\
 let \; \ell^\prime&amp; =0\\
 &amp;\frac{3}{\pi}-\frac{7}{1-\pi} = 0 \\
 &amp;\frac{3-10\pi}{\pi(1-\pi)} = 0 \\
 \Rightarrow MLE &amp;= \hat\pi = 0.3
\end{aligned}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:bin3-10"></span>
<img src="bookdown_files/figure-html/bin3-10-1.png" alt="Binomial likelihood function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.3: Binomial likelihood function 3 out of 10 subjects
</p>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>計算似然比，並作圖，注意方程圖形未變，<span class="math inline">\(y\)</span> 軸的變化；取對數似然比，並作圖</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" title="1">LR &lt;-<span class="st"> </span>L<span class="op">/</span><span class="kw">max</span>(L) ; <span class="kw">head</span>(LR)</a></code></pre></div>
<pre><code>## [1] 0.0000000 0.0004192 0.0031234 0.0098111 0.0216286 0.0392577</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1"><span class="kw">plot</span>(pi, LR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;darkblue&quot;</span>,</a>
<a class="sourceLine" id="cb28-2" title="2">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb28-3" title="3"><span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb28-4" title="4"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.2</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb28-5" title="5"><span class="kw">title</span>(<span class="dt">main =</span> <span class="st">&quot;Binomial likelihood ratio function</span><span class="ch">\n</span><span class="st"> 3 out of 10 subjects&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-ratio"></span>
<img src="bookdown_files/figure-html/bin3-10-ratio-1.png" alt="Binomial likelihood ratio function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.4: Binomial likelihood ratio function 3 out of 10 subjects
</p>
</div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1">logLR &lt;-<span class="st"> </span><span class="kw">log</span>(L<span class="op">/</span><span class="kw">max</span>(L))</a>
<a class="sourceLine" id="cb29-2" title="2"><span class="kw">plot</span>(pi, logLR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;darkblue&quot;</span>,</a>
<a class="sourceLine" id="cb29-3" title="3">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb29-4" title="4"><span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb29-5" title="5"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb29-6" title="6"><span class="co">#title(main = &quot;Binomial log-likelihood ratio function\n 3 out of 10 subjects&quot;)</span></a>
<a class="sourceLine" id="cb29-7" title="7"><span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb29-8" title="8"><span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">0</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-logratio"></span>
<img src="bookdown_files/figure-html/bin3-10-logratio-1.png" alt="Binomial log-likelihood ratio function 3 out of 10 subjects" width="90%" />
<p class="caption">
圖 13.5: Binomial log-likelihood ratio function 3 out of 10 subjects
</p>
</div>
</div>
<div id="q2" class="section level3">
<h3><span class="header-section-number">13.5.2</span> Q2</h3>
<ol style="list-style-type: lower-alpha">
<li>與上面用同樣的模型，但是觀察人數變爲 <span class="math inline">\(100\)</span> 人 患病人數爲 <span class="math inline">\(30\)</span> 人，試作對數似然比方程之圖形，與上圖對比：</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:bin3-10-30-100-logllr"></span>
<img src="bookdown_files/figure-html/bin3-10-30-100-logllr-1.png" alt="Binomial log-likelihood ratio function 3 out of 10 and 30 out of 100 subjects" width="90%" />
<p class="caption">
圖 13.6: Binomial log-likelihood ratio function 3 out of 10 and 30 out of 100 subjects
</p>
</div>
<p>可以看出，兩組數據的 MLE 都是一致的， <span class="math inline">\(\hat\pi=0.3\)</span>，但是對數似然比方程圖形在 樣本量爲 <span class="math inline">\(n=100\)</span> 時比 <span class="math inline">\(n=10\)</span> 時窄很多，由此產生的似然比信賴區間也就窄很多(精確很多) 。所以對數似然比方程的曲率(二階導數) ，反映了觀察獲得數據提供的對總體參數 <span class="math inline">\(\pi\)</span> 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。</p>
</div>
<div id="q3" class="section level3">
<h3><span class="header-section-number">13.5.3</span> Q3</h3>
<p>在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 <span class="math inline">\(95\%\)</span> 信賴區間。</p>
<p><strong>解</strong></p>
<p><span class="math display">\[\begin{aligned}
 d = 8, \;p &amp;= 160\; person\cdot year \\
  \Rightarrow D\sim Poi(\mu &amp;=\lambda p) \\
 L(\lambda|data) &amp;= Prob(D=d=8) \\
   &amp;=  e^{-\mu}\frac{\mu^d}{d!} \\
   &amp;=   e^{-\lambda p}\frac{\lambda^d p^d}{d!} \\
  omitting&amp;\;terms\;not\;in\;\lambda \\
   &amp;= e^{-\lambda p}\lambda^d \\
\Rightarrow \ell(\lambda|data)&amp;= \text{log}(e^{-\lambda p}\lambda^d) \\
     &amp;= d\cdot \text{log}(\lambda)-\lambda p \\
     &amp; = 8\times \text{log}(\lambda) - 160\times\lambda
\end{aligned}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:Poi-llr-8-160"></span>
<img src="bookdown_files/figure-html/Poi-llr-8-160-1.png" alt="Poisson log-likelihood ratio function
 8 events in 160 person-years" width="90%" />
<p class="caption">
圖 13.7: Poisson log-likelihood ratio function
8 events in 160 person-years
</p>
</div>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
lambda
</th>
<th style="text-align:right;">
LogLR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.010
</td>
<td style="text-align:right;">
-6.4755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-5.8730
</td>
</tr>
<tr>
<td style="text-align:right;">
0.012
</td>
<td style="text-align:right;">
-5.3369
</td>
</tr>
<tr>
<td style="text-align:right;">
0.013
</td>
<td style="text-align:right;">
-4.8566
</td>
</tr>
<tr>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
-4.4237
</td>
</tr>
<tr>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
-4.0318
</td>
</tr>
<tr>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
-3.6755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.017
</td>
<td style="text-align:right;">
-3.3505
</td>
</tr>
<tr>
<td style="text-align:right;">
0.018
</td>
<td style="text-align:right;">
-3.0532
</td>
</tr>
<tr>
<td style="text-align:right;">
0.019
</td>
<td style="text-align:right;">
-2.7807
</td>
</tr>
<tr>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
-2.5303
</td>
</tr>
<tr>
<td style="text-align:right;">
0.021
</td>
<td style="text-align:right;">
-2.3000
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.022
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-2.0878
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.023
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.8922
</td>
</tr>
<tr>
<td style="text-align:right;">
0.024
</td>
<td style="text-align:right;">
-1.7118
</td>
</tr>
<tr>
<td style="text-align:right;">
0.025
</td>
<td style="text-align:right;">
-1.5452
</td>
</tr>
<tr>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
-1.3914
</td>
</tr>
<tr>
<td style="text-align:right;">
0.027
</td>
<td style="text-align:right;">
-1.2495
</td>
</tr>
<tr>
<td style="text-align:right;">
0.028
</td>
<td style="text-align:right;">
-1.1185
</td>
</tr>
<tr>
<td style="text-align:right;">
0.029
</td>
<td style="text-align:right;">
-0.9978
</td>
</tr>
<tr>
<td style="text-align:right;">
0.030
</td>
<td style="text-align:right;">
-0.8866
</td>
</tr>
<tr>
<td style="text-align:right;">
0.031
</td>
<td style="text-align:right;">
-0.7843
</td>
</tr>
<tr>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
-0.6903
</td>
</tr>
<tr>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
-0.6041
</td>
</tr>
<tr>
<td style="text-align:right;">
0.034
</td>
<td style="text-align:right;">
-0.5253
</td>
</tr>
<tr>
<td style="text-align:right;">
0.035
</td>
<td style="text-align:right;">
-0.4534
</td>
</tr>
<tr>
<td style="text-align:right;">
0.036
</td>
<td style="text-align:right;">
-0.3880
</td>
</tr>
<tr>
<td style="text-align:right;">
0.037
</td>
<td style="text-align:right;">
-0.3288
</td>
</tr>
<tr>
<td style="text-align:right;">
0.038
</td>
<td style="text-align:right;">
-0.2755
</td>
</tr>
<tr>
<td style="text-align:right;">
0.039
</td>
<td style="text-align:right;">
-0.2277
</td>
</tr>
<tr>
<td style="text-align:right;">
0.040
</td>
<td style="text-align:right;">
-0.1851
</td>
</tr>
<tr>
<td style="text-align:right;">
0.041
</td>
<td style="text-align:right;">
-0.1476
</td>
</tr>
<tr>
<td style="text-align:right;">
0.042
</td>
<td style="text-align:right;">
-0.1148
</td>
</tr>
<tr>
<td style="text-align:right;">
0.043
</td>
<td style="text-align:right;">
-0.0866
</td>
</tr>
<tr>
<td style="text-align:right;">
0.044
</td>
<td style="text-align:right;">
-0.0627
</td>
</tr>
<tr>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
-0.0429
</td>
</tr>
<tr>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
-0.0271
</td>
</tr>
<tr>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
-0.0150
</td>
</tr>
<tr>
<td style="text-align:right;">
0.048
</td>
<td style="text-align:right;">
-0.0066
</td>
</tr>
<tr>
<td style="text-align:right;">
0.049
</td>
<td style="text-align:right;">
-0.0016
</td>
</tr>
<tr>
<td style="text-align:right;">
0.050
</td>
<td style="text-align:right;">
0.0000
</td>
</tr>
<tr>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
-0.0016
</td>
</tr>
<tr>
<td style="text-align:right;">
0.052
</td>
<td style="text-align:right;">
-0.0062
</td>
</tr>
<tr>
<td style="text-align:right;">
0.053
</td>
<td style="text-align:right;">
-0.0138
</td>
</tr>
<tr>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
-0.0243
</td>
</tr>
<tr>
<td style="text-align:right;">
0.055
</td>
<td style="text-align:right;">
-0.0375
</td>
</tr>
<tr>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
-0.0534
</td>
</tr>
<tr>
<td style="text-align:right;">
0.057
</td>
<td style="text-align:right;">
-0.0718
</td>
</tr>
<tr>
<td style="text-align:right;">
0.058
</td>
<td style="text-align:right;">
-0.0926
</td>
</tr>
<tr>
<td style="text-align:right;">
0.059
</td>
<td style="text-align:right;">
-0.1159
</td>
</tr>
<tr>
<td style="text-align:right;">
0.060
</td>
<td style="text-align:right;">
-0.1414
</td>
</tr>
<tr>
<td style="text-align:right;">
0.061
</td>
<td style="text-align:right;">
-0.1692
</td>
</tr>
<tr>
<td style="text-align:right;">
0.062
</td>
<td style="text-align:right;">
-0.1991
</td>
</tr>
<tr>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
-0.2311
</td>
</tr>
<tr>
<td style="text-align:right;">
0.064
</td>
<td style="text-align:right;">
-0.2651
</td>
</tr>
<tr>
<td style="text-align:right;">
0.065
</td>
<td style="text-align:right;">
-0.3011
</td>
</tr>
<tr>
<td style="text-align:right;">
0.066
</td>
<td style="text-align:right;">
-0.3389
</td>
</tr>
<tr>
<td style="text-align:right;">
0.067
</td>
<td style="text-align:right;">
-0.3786
</td>
</tr>
<tr>
<td style="text-align:right;">
0.068
</td>
<td style="text-align:right;">
-0.4201
</td>
</tr>
<tr>
<td style="text-align:right;">
0.069
</td>
<td style="text-align:right;">
-0.4633
</td>
</tr>
<tr>
<td style="text-align:right;">
0.070
</td>
<td style="text-align:right;">
-0.5082
</td>
</tr>
<tr>
<td style="text-align:right;">
0.071
</td>
<td style="text-align:right;">
-0.5547
</td>
</tr>
<tr>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
-0.6029
</td>
</tr>
<tr>
<td style="text-align:right;">
0.073
</td>
<td style="text-align:right;">
-0.6525
</td>
</tr>
<tr>
<td style="text-align:right;">
0.074
</td>
<td style="text-align:right;">
-0.7037
</td>
</tr>
<tr>
<td style="text-align:right;">
0.075
</td>
<td style="text-align:right;">
-0.7563
</td>
</tr>
<tr>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
-0.8103
</td>
</tr>
<tr>
<td style="text-align:right;">
0.077
</td>
<td style="text-align:right;">
-0.8657
</td>
</tr>
<tr>
<td style="text-align:right;">
0.078
</td>
<td style="text-align:right;">
-0.9225
</td>
</tr>
<tr>
<td style="text-align:right;">
0.079
</td>
<td style="text-align:right;">
-0.9806
</td>
</tr>
<tr>
<td style="text-align:right;">
0.080
</td>
<td style="text-align:right;">
-1.0400
</td>
</tr>
<tr>
<td style="text-align:right;">
0.081
</td>
<td style="text-align:right;">
-1.1006
</td>
</tr>
<tr>
<td style="text-align:right;">
0.082
</td>
<td style="text-align:right;">
-1.1624
</td>
</tr>
<tr>
<td style="text-align:right;">
0.083
</td>
<td style="text-align:right;">
-1.2255
</td>
</tr>
<tr>
<td style="text-align:right;">
0.084
</td>
<td style="text-align:right;">
-1.2896
</td>
</tr>
<tr>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
-1.3550
</td>
</tr>
<tr>
<td style="text-align:right;">
0.086
</td>
<td style="text-align:right;">
-1.4214
</td>
</tr>
<tr>
<td style="text-align:right;">
0.087
</td>
<td style="text-align:right;">
-1.4889
</td>
</tr>
<tr>
<td style="text-align:right;">
0.088
</td>
<td style="text-align:right;">
-1.5575
</td>
</tr>
<tr>
<td style="text-align:right;">
0.089
</td>
<td style="text-align:right;">
-1.6271
</td>
</tr>
<tr>
<td style="text-align:right;">
0.090
</td>
<td style="text-align:right;">
-1.6977
</td>
</tr>
<tr>
<td style="text-align:right;">
0.091
</td>
<td style="text-align:right;">
-1.7693
</td>
</tr>
<tr>
<td style="text-align:right;">
0.092
</td>
<td style="text-align:right;">
-1.8419
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.093
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.9154
</td>
</tr>
<tr>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
0.094
</td>
<td style="text-align:right;font-weight: bold;color: white !important;background-color: #D7261E !important;">
-1.9898
</td>
</tr>
<tr>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
-2.0652
</td>
</tr>
<tr>
<td style="text-align:right;">
0.096
</td>
<td style="text-align:right;">
-2.1414
</td>
</tr>
<tr>
<td style="text-align:right;">
0.097
</td>
<td style="text-align:right;">
-2.2185
</td>
</tr>
<tr>
<td style="text-align:right;">
0.098
</td>
<td style="text-align:right;">
-2.2964
</td>
</tr>
<tr>
<td style="text-align:right;">
0.099
</td>
<td style="text-align:right;">
-2.3752
</td>
</tr>
<tr>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
-2.4548
</td>
</tr>
</tbody>
</table>
<p>所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。</p>
</div>
</div>
</div>
<div id="quadratic-llr" class="section level1">
<h1><span class="header-section-number">第 14 章</span> 二次方程近似法求對數似然比 approximate log-likelihood ratios</h1>
<p>爲什麼要用二次方程近似對數似然比方程？</p>
<ol style="list-style-type: decimal">
<li>上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (Section <a href="#binomial-ex">13.4.1</a>: binomial example)。</li>
<li>我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。</li>
<li>所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。</li>
</ol>
<div id="quadratic-llr2" class="section level2">
<h2><span class="header-section-number">14.1</span> 正態近似法求對數似然 Normal approximation to the log-likelihood</h2>
<p>根據前一節 (Section <a href="#normal-ex">13.4.2</a>)，如果樣本均數的分佈符合正態分佈：<span class="math inline">\(\bar{X}\sim N(\mu, \sigma^2/n)\)</span>。那麼樣本均數的對數似然比爲：</p>
<p><span class="math display">\[llr(\mu|\bar{X})=\ell(\mu|\bar{X})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\]</span></p>
<p>其中， <span class="math inline">\(\bar{x}\)</span> 是正態分佈總體均數 <span class="math inline">\(\mu\)</span> 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 <span class="math inline">\(\sigma/\sqrt{n}\)</span> 是 <span class="math inline">\(\bar{x}\)</span> 的標準誤 (standard error)。</p>
<p>因此，假設 <span class="math inline">\(\theta\)</span> 是我們想尋找的總體參數。有些人提議可以使用下面的關於 <span class="math inline">\(\theta\)</span> 的二次方程來做近似：</p>
<p><span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></p>
<p>上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， <span class="math inline">\(M\)</span> 的標準誤爲 <span class="math inline">\(S\)</span>。如果我們正確地選用 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>，那我們就可以用這樣的方程來近似求真實觀察數據的似然 <span class="math inline">\(\ell(\theta|data)\)</span>。</p>
<p>通過近似正態對數似然比，<span class="math inline">\(M\)</span> 應當選用使方程取最大值時，參數 <span class="math inline">\(\theta\)</span> 的極大似然估計 <span class="math inline">\(M=\hat{\Theta}\)</span>。</p>
<p>但是在選用標準誤 <span class="math inline">\(S\)</span> 上必須滿足下列條件：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(S\)</span> 是極大似然估計 <span class="math inline">\(\hat{\Theta}\)</span> 的標準誤。</li>
<li>被選擇的 <span class="math inline">\(S\)</span> 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率(二階導數) 。</li>
</ol>
<p>由於，一個方程的曲率是該方程的二階導數(斜線斜率變化的速度) 。所以對數似然比方程在 MLE 取最大值時的曲率(二階導數) 爲：</p>
<p><span class="math display">\[\left.\frac{d^2}{d\theta^2}\ell(\theta)\right\vert_{\theta=\hat{\theta}}=\ell^{\prime\prime}(\hat{\theta})=-\frac{1}{S^2}\\
\Rightarrow S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}
\]</span></p>
<p>在正態分佈的例子下，<span class="math inline">\(M=\bar{x}, S=\sigma/\sqrt{n}\)</span>。對數似然比方程最大值時的曲率(二階導數) 恰好就爲標準誤的平方的負倒數：</p>
<p><span class="math inline">\(\ell^{\prime\prime}(\theta)=-\frac{1}{SE^2}\)</span> <span class="math inline">\(\Rightarrow\)</span> 被叫做 <strong>Fisher information</strong>。</p>
<p>稍微總結一下：</p>
<ol style="list-style-type: decimal">
<li>任意的對數似然比方程 <span class="math inline">\(llr(\theta)\)</span> 都可以考慮用一個二次方程來近似：
<span class="math display">\[f(\theta|data)=-\frac{1}{2}(\frac{\theta-M}{S})^2\]</span></li>
<li>其中<br>
<span class="math inline">\(\begin{aligned}  &amp;M=\hat\theta\\  &amp;S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\\  &amp;when \\  &amp; n\rightarrow\infty \Rightarrow  \begin{cases}  S^2\rightarrow Var(\hat\theta) \\  S\rightarrow SE(\hat\theta)  \end{cases}  \end{aligned}\)</span></li>
</ol>
<div id="近似法估算對數似然比的信賴區間" class="section level3">
<h3><span class="header-section-number">14.1.1</span> 近似法估算對數似然比的信賴區間</h3>
<p>一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是：</p>
<p><span class="math display">\[-2f(\theta)&lt;\mathcal{X}_{1,(1-\alpha)}^2\]</span></p>
<p>故信賴區間爲： <span class="math inline">\(m\pm\sqrt{\mathcal{X}_{1,(1-\alpha)}^2}S\)</span>。求<span class="math inline">\(95\%\)</span> 水平的信賴區間時，<span class="math inline">\(\mathcal{X}_{1,0.95}^2=3.84\)</span>，所以就又看到了熟悉的 <span class="math inline">\(M\pm1.96S\)</span>。</p>
</div>
<div id="以泊松分佈爲例" class="section level3">
<h3><span class="header-section-number">14.1.2</span> 以泊松分佈爲例</h3>
<p>一個被追蹤的樣本，經過了 <span class="math inline">\(p\)</span> 人年的觀察，記錄到了 <span class="math inline">\(d\)</span> 個我們要研究的事件：</p>
<p><span class="math display">\[D\sim Poi(\mu), where \mu=\lambda p\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)，之前介紹似然方程時推導過的泊松分佈的似然方程 (Section <a href="#likelihood-poi">12.6</a>)：</p>
<p><span class="math display">\[\begin{aligned}
P(D=d|\lambda) &amp;= \frac{e^{-\mu}\cdot\mu^d}{d!} \\
 &amp;=\frac{e^{-\lambda p}\cdot\lambda^d p^d}{d!} \\
omitting&amp;\;terms\;not\;in\;\mu \\
&amp;\Rightarrow \ell(\lambda) = d\text{log}\lambda - \lambda p \\
&amp;\Rightarrow \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp;\Rightarrow \hat\lambda=\frac{d}{p} = \textbf{M}
\end{aligned}\]</span></p>
<p>Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \ell^\prime(\lambda) = \frac{d}{\lambda} -p \\
&amp; \Rightarrow \ell^{\prime\prime}(\lambda) = -\frac{d}{\lambda^2}&lt;0 \Rightarrow \textbf{MLE is maximum} \\
&amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\lambda)}\right\vert_{\lambda=\hat{\lambda}=d/p} = -\frac{1}{-d/\hat\lambda^2} = -\frac{1}{-d/(d/p)^2} \\
&amp;\Rightarrow S^2 = \frac{d}{p^2} \\
\end{aligned}\]</span></p>
<p>Step 3. 把前兩部求得的 <span class="math inline">\(MLE\)</span> 和 <span class="math inline">\(S^2\)</span> 代入近似的二次方程：</p>
<p><span class="math display">\[\begin{aligned}
&amp; \hat\lambda=\frac{d}{p}=M,\; S^2 = \frac{d}{p^2}  \\
&amp; using\;approximate\;quadratic\;llr \\
&amp; q(\lambda) = -\frac{1}{2}(\frac{\lambda-M}{S})^2\\
&amp;\Rightarrow q(\lambda) = -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2\\
&amp; let \; q(\lambda)=-1.92\\
&amp;\Rightarrow -\frac{1}{2}(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=-1.92\\
&amp;(\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}})^2=3.84\\
&amp;\frac{\lambda-\frac{d}{p}}{\frac{\sqrt{d}}{p}} = \pm1.96\\
&amp;\Rightarrow 95\%CI \;for \;\lambda = \frac{d}{p}\pm1.96\frac{\sqrt{d}}{p}
\end{aligned}\]</span></p>
<p>結論就是： 發病(死亡) 率 <span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間爲： <span class="math inline">\(M\pm1.96S\)</span>。所以我們不需要每次都代入對數似然比方程，只要算出 <span class="math inline">\(MLE = M\)</span> 和 <span class="math inline">\(S\)</span> 之後代入這個公式就可以用二次方程近似法算出信賴區間。</p>
</div>
<div id="quadratic-binomial-approx" class="section level3">
<h3><span class="header-section-number">14.1.3</span> 以二項分佈爲例</h3>
<p><span class="math display">\[K\sim Bin(n,\pi)\]</span></p>
<p>Step 1. 找極大似然估計 (MLE)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Prob(K=k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;\Rightarrow L(\pi|k) = \pi^k(1-\pi)\binom{n}{k}\\
&amp;omitting\;terms\;not\;in\;\pi \\
&amp;\Rightarrow \ell(\pi) = k\:\text{log}\pi+(n-k)\text{log}(1-\pi) \\
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp; let\;\ell^\prime(\hat\pi) =0 \\
&amp;\Rightarrow \frac{k}{\hat\pi}-\frac{n-k}{1-\hat\pi}=0\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k}{n-k}\\
&amp;\Rightarrow \frac{\hat\pi}{1-\hat\pi}=\frac{k/n}{1-k/n}\\
&amp;\Rightarrow \hat\pi=\frac{k}{n} = p = \textbf{M}
\end{aligned}
\]</span></p>
<p>Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 <span class="math inline">\(S^2\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\ell^\prime(\pi) = \frac{k}{\pi}-\frac{n-k}{1-\pi} \\
&amp;\ell^{\prime\prime}(\pi)=\frac{-k}{\pi^2}-\frac{n-k}{(1-\pi)^2} &lt;0 \\
&amp;\therefore at\;\textbf{MLE}\;\ell(\pi)\;has\;maximum \\
S^2&amp;=\left.-\frac{1}{\ell^{\prime\prime}(\pi)}\right\vert_{\pi=\hat\pi=k/n=p}\\
&amp;=\frac{1}{\frac{k}{\hat\pi^2}+\frac{n-k}{(1-\hat\pi)^2}}\\
&amp;=\frac{\hat\pi^2(1-\hat\pi)^2}{k(1-\hat\pi)^2+(n-k)\hat\pi^2}\\
&amp;=\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\
&amp;=\frac{p(1-p)}{n(1-p)+np}\\
&amp;=\frac{p(1-p)}{n}\\
&amp;\Rightarrow S=\sqrt{\frac{p(1-p)}{n}}
\end{aligned}
\]</span></p>
<p>Step 3. 將求得的 MLE 和 <span class="math inline">\(S^2\)</span> 代入近似信賴區間：</p>
<p><span class="math display">\[
95\% CI \;for \; \pi:\\
M\pm1.96S=p\pm1.96\sqrt{\frac{p(1-p)}{n}}\\
\]</span></p>
</div>
</div>
<div id="para-trans" class="section level2">
<h2><span class="header-section-number">14.2</span> 參數转换 parameter transformations</h2>
<p>如果將參數 <span class="math inline">\(\theta\)</span> 通過某種數學方程轉化成 <span class="math inline">\(g(\theta)\)</span>，那麼我們可以認爲，轉化後的方程的 MLE 爲 <span class="math inline">\(g(\hat\theta)\)</span>，其中 <span class="math inline">\(\hat\theta\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的 MLE。</p>
<p>類似地，如果 <span class="math inline">\(\theta_1 \sim \theta_2\)</span> 是參數 <span class="math inline">\(\theta\)</span> 的似然比信賴區間，那麼 <span class="math inline">\(g(\theta_1)\sim g(\theta_2)\)</span> 就是 <span class="math inline">\(g(\theta)\)</span> 的似然比信賴區間。</p>
<p>以下爲轉換參數以後獲取信賴區間的步驟：</p>
<ol style="list-style-type: decimal">
<li>將參數通過某些數學方程(通常是取對數) 轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。<br> Transform parameter so that <span class="math inline">\(llr\)</span> is closer to a quadratic shape.</li>
<li>用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 <br> Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals.</li>
<li>將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。<br> Transform the confidence intervals back, or to any scale we wish – they remain valid.</li>
</ol>
<div id="Possion-log-transform" class="section level3">
<h3><span class="header-section-number">14.2.1</span> 以泊松分佈爲例</h3>
<p>當我們用泊松分佈模擬事件在某段時間內發生率 <span class="math inline">\(\lambda\)</span> 時，注意到這個事件發生率必須滿足 <span class="math inline">\(\lambda&gt;0\)</span>。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 <span class="math inline">\(\lambda \rightarrow \text{log}(\lambda)\)</span> 此時 <span class="math inline">\(\text{log}(\lambda)\)</span> 就不再被限制與 <span class="math inline">\(&gt;0\)</span>。下面我們嘗試尋找對數轉換過後的 <span class="math inline">\(M\)</span> 和 <span class="math inline">\(S\)</span>。</p>
<p>令 <span class="math inline">\(\beta=\text{log}(\lambda), \Rightarrow e^\beta=\lambda\)</span> 從本文上半部分中我們已知 <span class="math inline">\(\hat\lambda=\frac{d}{p}\)</span>。</p>
<ul>
<li><p>對數轉換以後的 <span class="math inline">\(M\)</span> 是什麼? <br>根據定義，<span class="math inline">\(MLE(\beta)=MLE[\text{log}(\lambda)]=\text{log}(\hat\lambda)\)</span>
<span class="math inline">\(\Rightarrow M=\hat\beta=\text{log}(\frac{d}{p})\)</span></p></li>
<li><p>對數轉換以後的 <span class="math inline">\(S\)</span> 是什麼? <br> 泊松分佈的對數似然方程是：<span class="math inline">\(\ell(\lambda|d)=d \text{log}(\lambda) - \lambda p\)</span> 用 <span class="math inline">\(\beta\)</span> 替換掉 <span class="math inline">\(\lambda\)</span></p>
<p><span class="math inline">\(\begin{aligned}  &amp; \ell(\beta|d)=d \beta - pe^\beta\\  &amp; \Rightarrow \ell^\prime(\beta)=d-pe^\beta \Rightarrow \ell^{\prime\prime}(\beta)=-pe^\beta \\  &amp; S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \left.\frac{1}{pe^\beta}\right\vert_{\beta=\hat{\beta}} = \frac{1}{pe^{\text{log}(d/p)}}\\  &amp;\Rightarrow S^2=\frac{1}{d} \therefore S=\frac{1}{\sqrt{d}} \end{aligned}\)</span></p></li>
<li><p>轉換後的近似二次方程：<br>
<span class="math inline">\(\begin{aligned}  &amp; q(\beta) = -\frac{1}{2}(\frac{\beta-M}{S})^2 = -\frac{1}{2}(\frac{\beta-\text{log}(\frac{d}{p})}{\frac{1}{\sqrt{d}}})^2  \end{aligned}\)</span></p></li>
<li><p><span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=\text{log}(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}}\)</span></p></li>
<li><p><span class="math inline">\(\lambda\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\(=exp(\text{log}(\frac{d}{p})\pm1.96\frac{1}{\sqrt{d}})\)</span></p></li>
</ul>
</div>
<div id="以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">14.2.2</span> 以二項分佈爲例</h3>
<p>在研究對象 <span class="math inline">\(n\)</span> 人中觀察到 <span class="math inline">\(k\)</span> 個人患有某種<del>中二</del>疾病。</p>
<p>令 <span class="math inline">\(\beta=\text{log}(\pi) \Rightarrow \pi=e^\beta\)</span> 從上文的推倒也已知 <span class="math inline">\(\hat\pi=\frac{k}{n}=p\)</span></p>
<p><span class="math inline">\(\begin{aligned} &amp;\Rightarrow \ell(\beta)=k\text{log}\pi+(n-k)\text{log}(1-\pi)=k\beta+(n-k)\text{log}(1-e^\beta) \\ &amp;\Rightarrow \ell^{\prime}(\beta)=k-\frac{(n-k)(e^\beta)}{1-e^\beta} \\ &amp;\Rightarrow \ell^{\prime\prime}(\beta)=-(n-k)\frac{e^\beta(1-e^\beta)+e^{2\beta}}{(1-e^\beta)^2} \\ &amp; \ell^{\prime\prime}(\beta)= -(n-k)\frac{e^\beta}{(1-e^\beta)^2}\\ &amp;\Rightarrow S^2 = \left.-\frac{1}{\ell^{\prime\prime}(\beta)}\right\vert_{\beta=\hat{\beta}} = \frac{(1-e^{\hat\beta})^2}{(n-k)e^{\hat\beta}} \\ &amp;\because \hat\beta=\text{log}(\hat\pi) \\ &amp;\therefore e^{\hat\beta} = \frac{k}{n}\\ &amp;\Rightarrow S^2=\frac{(1-\frac{k}{n})^2}{(n-k)\frac{k}{n}}=\frac{n-k}{nk}=\frac{1}{k}-\frac{1}{n}\\ &amp; \Rightarrow S=\sqrt{\frac{1}{k}-\frac{1}{n}}\\ \end{aligned}\)</span></p>
</div>
</div>
<div id="練習題-1" class="section level2">
<h2><span class="header-section-number">14.3</span> 練習題</h2>
<div id="q1-1" class="section level3">
<h3><span class="header-section-number">14.3.1</span> Q1</h3>
<ol style="list-style-type: lower-alpha">
<li>在<span class="math inline">\(n=100\)</span>人中觀察到有<span class="math inline">\(k=40\)</span>人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，<span class="math inline">\(\pi\)</span> 爲患病的概率。下面是 <span class="math inline">\(\pi \in [0.2,0.6]\)</span> 區間的對數似然比方程曲線。</li>
</ol>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" title="1">pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.2</span>, <span class="fl">0.6</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb30-2" title="2">L &lt;-<span class="st"> </span>(pi<span class="op">^</span><span class="dv">40</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>pi)<span class="op">^</span><span class="dv">60</span>)</a>
<a class="sourceLine" id="cb30-3" title="3">Lmax &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">max</span>(L), <span class="dv">41</span>)</a>
<a class="sourceLine" id="cb30-4" title="4">LR &lt;-<span class="st"> </span>L<span class="op">/</span>Lmax</a>
<a class="sourceLine" id="cb30-5" title="5">logLR &lt;-<span class="st"> </span><span class="kw">log</span>(LR)</a>
<a class="sourceLine" id="cb30-6" title="6"></a>
<a class="sourceLine" id="cb30-7" title="7"><span class="kw">plot</span>(pi, logLR, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>,</a>
<a class="sourceLine" id="cb30-8" title="8">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;logLR(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb30-9" title="9"><span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">5</span>, <span class="dt">lwd =</span> <span class="dv">2</span>) <span class="co"># add some horizontal grid on the background</span></a>
<a class="sourceLine" id="cb30-10" title="10"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">12</span>,<span class="dv">0</span>,<span class="dv">2</span>), <span class="dt">las=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bin-llr-40-100"></span>
<img src="bookdown_files/figure-html/bin-llr-40-100-1.png" alt="Binomial log-likelihood ratio between 0.2-0.6" width="90%" />
<p class="caption">
圖 14.1: Binomial log-likelihood ratio between 0.2-0.6
</p>
</div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="co">#title(main = &quot;Figure 1. Binomial log-likelihood ratio&quot;)</span></a></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>用一個二次方程來模擬上面的對數似然比曲線：<span class="math inline">\(f(\pi)=-\frac{(\pi-M)^2}{2S^2}\)</span>，其中 <span class="math inline">\(M=\hat\pi=\frac{k}{n}=0.4\)</span>，<span class="math inline">\(S^2=\frac{p(1-p)}{n}=0.0024\)</span></li>
</ol>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1"><span class="kw">par</span>(<span class="dt">mai =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.7</span>))</a>
<a class="sourceLine" id="cb32-2" title="2">quad &lt;-<span class="st"> </span><span class="op">-</span>(pi<span class="fl">-0.4</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.0024</span>)</a>
<a class="sourceLine" id="cb32-3" title="3"><span class="kw">plot</span>(pi, quad, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,</a>
<a class="sourceLine" id="cb32-4" title="4">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb32-5" title="5"><span class="kw">lines</span>(pi, logLR, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb32-6" title="6"><span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">4</span>, <span class="dt">lwd =</span> <span class="dv">1</span>) <span class="co"># add some horizontal grid on the background</span></a>
<a class="sourceLine" id="cb32-7" title="7"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb32-8" title="8"><span class="co">#title(main = &quot;Figure 2. Quadratic approximation\n of binomial log-likelihood ratio \n 40 out of 100 subjects&quot;)</span></a>
<a class="sourceLine" id="cb32-9" title="9"><span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb32-10" title="10"><span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb32-11" title="11"><span class="kw">legend</span>(<span class="dt">x=</span><span class="fl">0.27</span>, <span class="dt">y=</span> <span class="fl">-5.5</span> ,<span class="dt">xpd =</span> <span class="ot">TRUE</span>,  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;logLR&quot;</span>,<span class="st">&quot;Quadratic&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,</a>
<a class="sourceLine" id="cb32-12" title="12">       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>), <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">horiz =</span> <span class="ot">TRUE</span>) <span class="co">#the legend is below the graph</span></a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin-1.png" alt="Quadratic approximation
 of binomial log-likelihood ratio 40 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.2: Quadratic approximation
of binomial log-likelihood ratio 40 out of 100 subjects
</p>
</div>
</div>
<div id="q2-1" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Q2</h3>
<p>依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。</p>
<ol style="list-style-type: decimal">
<li>類比上面的問題，用同樣的 <span class="math inline">\(\hat\pi=0.4\)</span>，但是 <span class="math inline">\(n=10, k=4\)</span> 時的圖形：</li>
</ol>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"><span class="kw">par</span>(<span class="dt">mai =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.7</span>))</a>
<a class="sourceLine" id="cb33-2" title="2">pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.0</span>, <span class="fl">0.85</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb33-3" title="3">L &lt;-<span class="st"> </span>(pi<span class="op">^</span><span class="dv">4</span>)<span class="op">*</span>((<span class="dv">1</span><span class="op">-</span>pi)<span class="op">^</span><span class="dv">6</span>)</a>
<a class="sourceLine" id="cb33-4" title="4">logLR &lt;-<span class="st"> </span><span class="kw">log</span>(L<span class="op">/</span><span class="kw">max</span>(L))</a>
<a class="sourceLine" id="cb33-5" title="5"></a>
<a class="sourceLine" id="cb33-6" title="6">quad &lt;-<span class="st"> </span><span class="op">-</span>(pi<span class="fl">-0.4</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.4</span><span class="op">*</span><span class="fl">0.6</span><span class="op">/</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb33-7" title="7"><span class="kw">plot</span>(pi, quad, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">0</span>),<span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,</a>
<a class="sourceLine" id="cb33-8" title="8">     <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span>)</a>
<a class="sourceLine" id="cb33-9" title="9"><span class="kw">lines</span>(pi, logLR, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb33-10" title="10"><span class="kw">grid</span>(<span class="ot">NA</span>, <span class="dv">4</span>, <span class="dt">lwd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb33-11" title="11"><span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb33-12" title="12"><span class="co">#title(main = &quot;Figure 3. Quadratic approximation\n of binomial log-likelihood ratio\n 4 out of 10 subjects&quot;)</span></a>
<a class="sourceLine" id="cb33-13" title="13"><span class="kw">abline</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb33-14" title="14"><span class="kw">axis</span>(<span class="dv">4</span>, <span class="dt">at=</span><span class="op">-</span><span class="fl">1.92</span>, <span class="dt">las=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb33-15" title="15"></a>
<a class="sourceLine" id="cb33-16" title="16"><span class="kw">legend</span>(<span class="dt">x=</span><span class="fl">0.17</span>, <span class="dt">y=</span> <span class="fl">-6.5</span> ,<span class="dt">xpd =</span> <span class="ot">TRUE</span>,  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;logLR&quot;</span>,<span class="st">&quot;Quadratic&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,</a>
<a class="sourceLine" id="cb33-17" title="17">       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>), <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">horiz =</span> <span class="ot">TRUE</span>) <span class="co">#the legend is below the graph</span></a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin4-10"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin4-10-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 4 out of 10 subjects" width="90%" />
<p class="caption">
圖 14.3: Quadratic approximation of binomial log-likelihood ratio 4 out of 10 subjects
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.4, n=1000, k=400\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin400-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin400-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 400 out of 1000 subjects" width="90%" />
<p class="caption">
圖 14.4: Quadratic approximation of binomial log-likelihood ratio 400 out of 1000 subjects
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=100, k=1\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。</p>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin1-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin1-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 1 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.5: Quadratic approximation of binomial log-likelihood ratio 1 out of 100 subjects
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=1000, k=10\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin10-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin10-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 10 out of 1000 subjects" width="90%" />
<p class="caption">
圖 14.6: Quadratic approximation of binomial log-likelihood ratio 10 out of 1000 subjects
</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.01, n=10000, k=100\)</span></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin100-1000"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin100-1000-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 100 out of 10000 subjects" width="90%" />
<p class="caption">
圖 14.7: Quadratic approximation of binomial log-likelihood ratio 100 out of 10000 subjects
</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li><span class="math inline">\(\hat\pi=0.99, n=100, k=99\)</span></li>
</ol>
<p>注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。</p>
<div class="figure" style="text-align: center"><span id="fig:qua-apprx-bin99-100"></span>
<img src="bookdown_files/figure-html/qua-apprx-bin99-100-1.png" alt="Quadratic approximation of binomial log-likelihood ratio 99 out of 100 subjects" width="90%" />
<p class="caption">
圖 14.8: Quadratic approximation of binomial log-likelihood ratio 99 out of 100 subjects
</p>
</div>
<p>總結： 二次方程近似時，在二項分佈的情況下，隨着 <span class="math inline">\(n, k\)</span> 增加，近似越理想。</p>
</div>
</div>
</div>
<div id="假設檢驗的構建-construction-of-a-hypothesis-test" class="section level1">
<h1><span class="header-section-number">第 15 章</span> 假設檢驗的構建 Construction of a hypothesis test</h1>
<div id="null-and-alter" class="section level2">
<h2><span class="header-section-number">15.1</span> 什麼是假設檢驗 Hypothesis testing</h2>
<p>一般來說，我們的<strong>假設</strong>(或者叫<strong>假說</strong>) 是對與我們實驗觀察數據來自的總體(或人羣) 的<strong>概率分佈</strong>的描述。在參數檢驗的背景下，就是要檢驗描述這個總體(或人羣) 的<strong>概率分佈</strong>的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作<strong>零假設</strong>(或者叫<strong>原假設</strong>) ，null hypothesis (<span class="math inline">\(H_0\)</span>)；另一個是與之對應的(互補的) 替代假設，althernative hypothesis (<span class="math inline">\(H_1/H_A\)</span>)。</p>
<p>例如，若 <span class="math inline">\(X\)</span> 是一個服從二項分佈的隨機離散變量 <span class="math inline">\(X\sim Bin(5, \theta)\)</span>。可以考慮如下的零假設和替代假設：<span class="math inline">\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)</span>。</p>
<p>當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定：</p>
<ol style="list-style-type: decimal">
<li>從樣本中計算所得的參數估計值爲多少時，拒絕零假設。(接受替代假設爲“真”)</li>
<li>從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。(接受零假設爲“真”)</li>
</ol>
<p>注意：(這一段很繞)</p>
<p>上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的(不對稱的) 假設：即簡單的 <span class="math inline">\(H_0\)</span>，複雜的 <span class="math inline">\(H_1\)</span>。如此一來當零假設 <span class="math inline">\(H_0\)</span> 不被拒絕時，我們並不一定就接受之。因爲無證據證明 <span class="math inline">\(H_1\)</span> 不等於有證據證明 <span class="math inline">\(H_0\)</span>。<strong>(Absence of evidence is not evidence of absence).</strong> 換句話說，無證據讓我們拒絕 <span class="math inline">\(H_0\)</span> 本身並不成爲支持 <span class="math inline">\(H_0\)</span> 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。</p>
<p>在樣本空間 sample space 中，決定了零假設 <span class="math inline">\(H_0\)</span> 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 <span class="math inline">\(\mathfrak{R}\)</span> 來標記。</p>
</div>
<div id="錯誤概率和效能方程-error-probabilities-and-the-power-function" class="section level2">
<h2><span class="header-section-number">15.2</span> 錯誤概率和效能方程 error probabilities and the power function</h2>
<p>這一部分也可以參考本書臨牀試驗樣本量計算 (Section <a href="#sample-size">33</a>) 部分。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 15.1 : Definition of Type I and Type II error
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="2">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
SAMPLE
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(\underline{x} \notin \mathfrak{R}\)</span> Accept <span class="math inline">\(H_0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\underline{x} \in \mathfrak{R}\)</span> Reject <span class="math inline">\(H_0\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;vertical-align: middle !important;" rowspan="2">
TRUTH
</td>
<td style="text-align:center;">
<span class="math inline">\(H_0\)</span> is true
</td>
<td style="text-align:center;">
<span class="math inline">\(\checkmark\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\alpha\)</span> <br> Type I error
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(H_1\)</span> is true
</td>
<td style="text-align:center;">
<span class="math inline">\(\beta\)</span> <br> Type II error
</td>
<td style="text-align:center;">
<span class="math inline">\(\checkmark\)</span>
</td>
</tr>
</tbody>
</table>
<p>假如一個假設檢驗是關於總體參數 <span class="math inline">\(\theta\)</span> 的：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta=\theta_1 \]</span></p>
<p>這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率(該檢驗方法能夠檢驗出有真實差別的能力) ：</p>
<p><span class="math display">\[\text{Power}=\text{Prob}(\underline{x}\in\mathfrak{R}|H_1\text{ is true}) = 1-\text{Prob}(\text{Type II error})\]</span></p>
<p>觀察數據只有兩種可能：落在拒絕域內，或者落在拒絕域之外。第二類錯誤我們常常使用 <span class="math inline">\(\beta\)</span> 來表示，所以 <span class="math inline">\(\text{Power}=1-\beta\)</span>。</p>
<p>檢驗的顯著性水平用 <span class="math inline">\(\alpha\)</span> 來表示。<span class="math inline">\(\alpha\)</span> 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 <span class="math inline">\(H_0\)</span>，接受了替代假設 <span class="math inline">\(H_1\)</span>，即假陽性的概率。</p>
<p><span class="math display">\[\text{Prob}(\underline{x}\in \mathfrak{R} |H_0 \text{ is true})=\text{Prob(Type I error)}\]</span></p>
<div id="以二項分佈爲例-1" class="section level3">
<h3><span class="header-section-number">15.2.1</span> 以二項分佈爲例</h3>
<p>用本文開頭的例子： <span class="math inline">\(X\sim Bin(5,\theta)\)</span>。和我們建立的零假設和替代假設：<span class="math inline">\(H_0: \theta=\frac{1}{2}; H_1: \theta=\frac{2}{3}\)</span>：</p>
<p>考慮兩種檢驗方法：</p>
<ol style="list-style-type: decimal">
<li>A 方法：當且僅當5次觀察都爲“成功”時才拒絕 <span class="math inline">\(H_0 (\text{i.e.}\; X=5)\)</span>。所以此時判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲 <span class="math inline">\(5\)</span>。檢驗效能 <span class="math inline">\(\text{Power}=1-\beta\)</span> 爲：<span class="math inline">\(Prob(X=5|H_1 \text{ is true})=(\frac{2}{3})^5=0.1317\)</span>。顯著性水平 <span class="math inline">\(\alpha\)</span> 爲 <span class="math inline">\(Prob(X=5|H_0 \text{ is true})=(\frac{1}{2})^5=0.03125\)</span>。</li>
<li>B 方法：當觀察到3,4,5次“成功”時，拒絕 <span class="math inline">\(H_0 (\text{i.e.} X=3,4,5)\)</span>。此時判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲 <span class="math inline">\(3,4,5\)</span>。檢驗效能 <span class="math inline">\(Power\)</span> 爲：<span class="math inline">\(Prob(X=3,4,\text{ or }5|H_1 \text{ is ture})=\sum_{i=3}^5(\frac{2}{3})^i(\frac{1}{3})^{5-i}\approx0.7901\)</span>；顯著性水平 <span class="math inline">\(\alpha\)</span> 爲：<span class="math inline">\(Prob(X=3,4,5|H_0 \text{ is true})=\sum_{i=3}^5(\frac{1}{2})^i(\frac{1}{2})^{5-i}=0.5\)</span></li>
</ol>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1"><span class="co"># the power in test B</span></a>
<a class="sourceLine" id="cb34-2" title="2"><span class="kw">dbinom</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.7901</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1"><span class="co"># the size in test B</span></a>
<a class="sourceLine" id="cb36-2" title="2"><span class="kw">dbinom</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)<span class="op">+</span><span class="kw">dbinom</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果(犯第一類錯誤，錯誤地拒絕 <span class="math inline">\(H_0\)</span>，接受 <span class="math inline">\(H_1\)</span>)，但是也有更高的檢驗效能 <span class="math inline">\(1-\beta\)</span>(真陽性更高) 。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 <span class="math inline">\(\alpha=0.05\)</span>，然後儘可能選擇檢驗效能最高的檢驗方法。</p>
</div>
</div>
<div id="Neyman-Pearson" class="section level2">
<h2><span class="header-section-number">15.3</span> 如何選擇要檢驗的統計量</h2>
<p>在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。</p>
<p>幸運地是，當明確了零假設和替代假設後，我們可以利用 <a href="https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma">Neyman-Pearson lemma</a> 似然比公式<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<p>來決定使用哪個統計量做檢驗<strong>最有效</strong>：</p>
<p><span class="math display">\[\text{Neyman-Pearson lemma}=\frac{L_{H_0}}{L_{H_1}}\]</span></p>
<p>這公式很直觀，因爲當觀察數據更加支持 <span class="math inline">\(H_1\)</span> 時 (<span class="math inline">\(L_{H_1}\)</span> 更大)，<span class="math inline">\(H_0\)</span> 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，實際計算時我們常使用對數似然比：<span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span>。</p>
<p>問題來了，那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定：</p>
<ol style="list-style-type: decimal">
<li>被檢驗統計量的樣本分佈 (the sampling distribution of the test statistic)</li>
<li>第一類錯誤概率 <span class="math inline">\(\alpha\)</span> (the required value of <span class="math inline">\(\alpha\)</span>)</li>
</ol>
<div id="以已知方差的正態分佈爲例" class="section level3">
<h3><span class="header-section-number">15.3.1</span> 以已知方差的正態分佈爲例</h3>
<p>假如已知 <span class="math inline">\(X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span> 而且方差 <span class="math inline">\(\sigma^2\)</span> 也是已知的。如果令 <span class="math inline">\(H_0: \mu=5\; ;H_1: \mu=10\)</span> 可以通過如下的方法找到我們需要的最佳檢驗統計量 <u>best statistic</u> 根據之前的推導 (Section <a href="#llr">13</a>) 可知正態分佈的似然方程如下：</p>
<p><span class="math display">\[\ell(\mu|\underline{x}) =-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\]</span></p>
<p>所以已知 <span class="math inline">\(\sigma^2\)</span> 時，我們的零假設和替代假設之間的對數似然比 <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> 爲:</p>
<p><span class="math display">\[\ell_{H_0}-\ell_{H_1}=-\frac{1}{2\sigma^2}(\sum_{i=1}^n(x_i-5)^2-\sum_{i=1}^n(x_i-10)^2)\]</span></p>
<p>然而，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>：</p>
<p><span class="math display">\[
\begin{aligned}
\ell_{H_0}-\ell_{H_1} &amp; = -(\sum_{i=1}^n(x_i-5)^2-\sum_{i=i}^n(x_i-10)^2)\\
                &amp; = 75n - 2\times(10-5)\sum_{i=1}^nx_i \\
\end{aligned}
\]</span></p>
<p>所以只要樣本和 (sum of sample) <span class="math inline">\(\sum_{i=1}^nx_i\)</span> <u>(最佳統計量 best statistic)</u> 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。爲了方便我們就用樣本均數 <span class="math inline">\(\frac{1}{n}\sum_{i=1}^nx_i\)</span> 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 (判別區域) 。</p>
</div>
</div>
<div id="複合假設-composite-hypotheses" class="section level2">
<h2><span class="header-section-number">15.4</span> 複合假設 composite hypotheses</h2>
<p>目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_0: \theta=\theta_0 \;\text{v.s.}\; H_1: \theta&gt;\theta_0\)</span> [<strong>單側</strong>的替代假設]</li>
<li><span class="math inline">\(H_0: \theta=\theta_0 \;\text{v.s.}\; H_1: \theta\neq\theta_0\)</span> [<strong>雙側</strong>的替代假設]</li>
</ol>
<p>所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是始終如一地適用？我們一一來看：</p>
<div id="單側替代假設" class="section level3">
<h3><span class="header-section-number">15.4.1</span> 單側替代假設</h3>
<p>本章目前爲止的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 <span class="math inline">\(H_1: \mu=10\)</span> 擴展爲，任意大於 <span class="math inline">\(5\)</span> 的 <span class="math inline">\(\mu\)</span> ，即 <span class="math inline">\(\mu&gt;5\)</span> 。因爲大於 <span class="math inline">\(5\)</span> 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是<strong>樣本均值</strong>。</p>
</div>
<div id="雙側替代假設" class="section level3">
<h3><span class="header-section-number">15.4.2</span> 雙側替代假設</h3>
<p>雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：<span class="math inline">\(H_0: \mu=5 \;\text{v.s.}\; H_1: \mu&lt;5\)</span> 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。此處暫且先按下不表。</p>
</div>
</div>
<div id="爲反對零假設-h_0-的證據定量" class="section level2">
<h2><span class="header-section-number">15.5</span> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</h2>
<p>重新再考慮複合假設：<span class="math inline">\(H_0: \theta=\theta_0\;\text{v.s.}\;H_1: \theta&gt;\theta_0\)</span> 假如存在一個總是可用的最佳檢驗統計量，用 <span class="math inline">\(T\)</span> 來標記 (或 <span class="math inline">\(T(x)\)</span>)， 這個統計量足夠大時，我們拒絕 <span class="math inline">\(H_0\)</span>。 別忘了我們還要給事先固定好的顯著性水平 <span class="math inline">\(\alpha\)</span> 定義與之相關的判別區域：</p>
<p><span class="math display">\[\text{Prob}(\underline{x}\in\mathfrak{R}|H_0)=\alpha\]</span></p>
<p>如果我們知道 <span class="math inline">\(T\)</span> 的樣本分佈，我們就可以使用一個閾值 <span class="math inline">\(c\)</span> 來定義這個判別區域：</p>
<p><span class="math display">\[Prob(T\geqslant c|H_0)=\alpha\]</span></p>
<p>更加正式的，我們定義判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 爲：</p>
<p><span class="math display">\[\{\underline{x}:\text{Prob}(T(x)\geqslant c|H_0)=\alpha\}\]</span></p>
<p>換句話說，當統計量 <span class="math inline">\(T&gt;c\)</span> 時，我們拒絕 <span class="math inline">\(H_0\)</span> 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 <span class="math inline">\(H_0\)</span> 的證據。再考慮從觀察數據中獲得的 <span class="math inline">\(T\)</span> ，即數據告訴我們的 <span class="math inline">\(t\)</span> 。所以，當 <span class="math inline">\(t\)</span> 值越大，說明觀察值相對零假設 <span class="math inline">\(H_0\)</span> 越往極端的方向走。因此我們可以用 <span class="math inline">\(T\)</span> 的樣本分佈來計算觀察值大大於等於這個閾值(極端值) 時的概率：</p>
<p><span class="math display">\[p=\text{Prob}(T\geqslant t|H_0)\]</span></p>
<p>這個概率公式被稱爲是單側 <span class="math inline">\(p\)</span> 值 <strong>(one-side p-value)</strong>。單側 <span class="math inline">\(p\)</span> 值越小，統計量 <span class="math inline">\(T\)</span> 的樣本空間就有越小比例(越強) 的證據支持零假設 <span class="math inline">\(H_0\)</span>。</p>
<p>我們把這以思想用到假設檢驗中時，就可以認爲：</p>
<p><span class="math display">\[p&lt;\alpha \Leftrightarrow t&gt;c\]</span></p>
<p>所以用我們一貫的設定 <span class="math inline">\(\alpha=0.05\)</span>，所以如果計算獲得 <span class="math inline">\(p&lt;0.05\)</span> 我們就認爲獲得了足夠強的拒絕零假設 <span class="math inline">\(H_0\)</span> 的證據。</p>
<div id="normal-mean-compare" class="section level3">
<h3><span class="header-section-number">15.5.1</span> 回到正態分佈的均值比較問題上來(單側替代假設)</h3>
<p>繼續考慮 <span class="math inline">\(X_1,\cdots,X_n\stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span>，假設 <span class="math inline">\(\sigma^2=10\)</span>，我們要檢驗的是 <span class="math inline">\(H_0: \mu=5 \;\text{v.s}.\; H_1: \mu&gt;5\)</span></p>
<ol style="list-style-type: decimal">
<li>確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是<strong>樣本均值 <span class="math inline">\(\bar{x}\)</span></strong>。</li>
<li>確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 <span class="math inline">\(\bar{X}\sim N(\mu,\sigma^2/n)\)</span> 。<br><span class="math inline">\(\Rightarrow Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\)</span>，所以在 <span class="math inline">\(H_0\)</span> 條件下，<span class="math inline">\(\Rightarrow Z=\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}} \sim N(0,1)\)</span></li>
<li>所以當一個檢驗的顯著性水平設定爲 <span class="math inline">\(\alpha=0.05\)</span> 時，我們用判別區域 <span class="math inline">\(\mathfrak{R}\)</span>，使統計量據落在該判別區域內的概率爲 <span class="math inline">\(0.05\)</span>：<br> <span class="math inline">\(\text{Prob}(\bar{X}\geqslant c|H_0) = 0.05\)</span> <br> 已知在標準正態分佈時，<span class="math inline">\(\text{Prob}(Z\geqslant1.64)=0.05=\text{Prob}(\frac{\bar{X}-5}{\sqrt{10}/\sqrt{n}}\geqslant1.64)\)</span></li>
<li>假設樣本量是 <span class="math inline">\(10\)</span>，那麼數據的判別區域 <span class="math inline">\(\mathfrak{R}\)</span> 就是 <span class="math inline">\(\bar{X}\geqslant6.64\)</span>。</li>
<li>假設觀察數據告訴我們，<span class="math inline">\(\bar{X}=7.76\)</span> 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，就提供了足夠的證據拒絕接受 <span class="math inline">\(H_0\)</span>。</li>
<li>我們可以給這個觀察數據計算相應的單側 <span class="math inline">\(p\)</span> 值：<br> <span class="math inline">\(p=\text{Prob}(\bar{X}\geqslant7.76|H_0)=\text{Prob}(Z+5\geqslant7.76)\\=\text{Prob}(Z\geqslant2.76)=0.003\)</span> <br> 所以，觀察數據告訴我們，在 <span class="math inline">\(H_0\)</span> 的前提下，觀察值出現的概率是 <span class="math inline">\(0.3\%\)</span> 。即，在無數次<strong>重複</strong>取樣實驗中，僅有 <span class="math inline">\(0.3\%\)</span> 的結果可以給出支持 <span class="math inline">\(H_0\)</span> 的證據。因此我們拒絕 <span class="math inline">\(H_0\)</span> 接受 <span class="math inline">\(H_1\)</span>。</li>
</ol>
</div>
</div>
<div id="雙側替代假設情況下雙側-p-值的定量方法" class="section level2">
<h2><span class="header-section-number">15.6</span> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</h2>
<div class="figure" style="text-align: center"><span id="fig:assymmetric"></span>
<img src="bookdown_files/figure-html/assymmetric-1.png" alt="Deliberately use an assymmetrical distribution to highlight the issues" width="90%" />
<p class="caption">
圖 15.1: Deliberately use an assymmetrical distribution to highlight the issues
</p>
</div>
<p>此處故意使用一個左右不對稱的概率密度分佈來解釋。</p>
<p>現在的替代假設是雙側的：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \;\text{v.s.}\; H_1:  \theta\neq\theta_0\]</span></p>
<p>正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(H_1: \theta&gt;\theta_0\)</span>;</li>
<li><span class="math inline">\(H_1: \theta&lt;\theta_0\)</span>.</li>
</ol>
<p>每個單側檢驗都有自己的最佳檢驗統計量。令 <span class="math inline">\(T\)</span> 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖 <a href="#fig:assymmetric">15.1</a> 所示(左右不對稱) 。假如觀察數據給出的統計量爲 <span class="math inline">\(t_{\text{obs}}\)</span>，那麼在概率上反對零假設的情況可以有兩種：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(T\geqslant t_{\text{obs}}\)</span> 其中， <span class="math inline">\(\text{Prob}(T\geqslant t_{\text{obs}}|H_0)=\tilde p\)</span>;</li>
<li><span class="math inline">\(T\leqslant t^\prime\)</span> 其中，<span class="math inline">\(t^\prime\)</span> 滿足： <span class="math inline">\(\text{Prob}(T\leqslant t^\prime|H_0) =\tilde p\)</span>。(圖<a href="#fig:assymmetric">15.1</a>)</li>
</ol>
<p>所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(<span class="math inline">\(=\tilde p\)</span>)相同，那麼就可以直接認爲，雙側 <span class="math inline">\(p\)</span> 值是兩側面積之和 (<span class="math inline">\(p=2\times \tilde p\)</span>)，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 <span class="math inline">\(H_0\)</span>。</p>
<p>注意：</p>
<ul>
<li>被選中的 <span class="math inline">\(t^\prime\)</span> 值大小不大可能滿足：<span class="math inline">\(|t^\prime - E(T|\theta_0)|=|t_{obs}-E(T|\theta_0)|\)</span>。因爲那只有在完全左右對稱的分佈中才會出現。但是，此處我們關心的是面積左右兩邊的尾部要相等即可，所以我們只需要知道右半邊，較大的那個 <span class="math inline">\(t_{obs}\)</span> 就完全足夠了。</li>
</ul>
<p>回到上面的均值比較問題 (Section <a href="#normal-mean-compare">15.5.1</a>)。現在我們要進行雙側假設檢驗，即： <span class="math inline">\(H_0: \mu=5 \text{ v.s. } H_1: \mu\neq5\)</span>，最佳統計量依然還是樣本均數 <span class="math inline">\(\bar{X}\)</span>。數據告訴我們說 <span class="math inline">\(\bar{X}=7.76\)</span>，因此雙側 <span class="math inline">\(p\)</span> 值就是將已求得的單側 <span class="math inline">\(\tilde p\)</span> 值乘以 <span class="math inline">\(2\)</span>： <span class="math inline">\(\text{two-sided } p=2\tilde p= 0.006\)</span></p>
<p>當然，實際操作中我們很少進行這樣繁瑣的論證，多數情況下就直接報告雙側 <span class="math inline">\(p\)</span> 值。</p>
</div>
<div id="test-summary" class="section level2">
<h2><span class="header-section-number">15.7</span> 假設檢驗構建之總結</h2>
<p>按照如下的步驟一一構建我們的假設檢驗過程：</p>
<ol style="list-style-type: decimal">
<li>先建立<strong>零假設，和替代假設</strong> (Section <a href="#null-and-alter">15.1</a>)；</li>
<li>定義<strong>最佳檢驗統計量</strong> (用 Neyman-Pearson lemma) (Section <a href="#Neyman-Pearson">15.3</a>)；</li>
<li>取得零假設條件下，最佳統計量的樣本分佈(通常都較爲困難，有時候我們會傾向於使用“不太理想”，但是計算較爲簡便的過程。) ；</li>
<li>定義<strong>拒絕域(判別區域) </strong> (常用 <span class="math inline">\(\alpha=0.05\)</span>) ；</li>
<li>計算<strong>觀察數據</strong>的檢驗統計量；</li>
<li>如果觀察數據的檢驗統計量落在了提前定義好的拒絕域內，那麼我們的檢驗結論就是：觀察數據<strong>拒絕了零假設支持替代假設</strong>。然而在實際操作時，如果發現數據的檢驗統計量不在拒絕域內，我們僅僅只能下結論說：觀察數據<strong>無法拒絕零假設</strong>(<strong>而不是接受零假設！</strong>) ；</li>
<li>報告計算得到的反對零假設的定量 <span class="math inline">\(p\)</span> 值。</li>
</ol>
<p>作爲統計學家，我們的任務是評價數據提供的證據，而不是簡單的去接受或者拒絕一個假設。</p>
</div>
<div id="練習題-2" class="section level2">
<h2><span class="header-section-number">15.8</span> 練習題</h2>
<div id="q1-2" class="section level3">
<h3><span class="header-section-number">15.8.1</span> Q1</h3>
<p>某種藥物有兩種使用方法：可以口服，也可以注射。兩種方法都被認爲可以使血漿中藥物濃度在24小時候達到相似的平均水平，<span class="math inline">\(3 \mu \text{g/L}\)</span>。已知口服該藥物後，濃度的方差爲 <span class="math inline">\(1\)</span>，而如果是注射的話方差只有 <span class="math inline">\(1/4\)</span>。因此設計了一個口服臨牀實驗，觀察到24小時後血漿中藥物濃度數據爲：2.54, 0.93, 2.75, 4.51, 3.71, 1.62, 3.01, 4.13, 2.08, 3.33。假設這組觀察數據獨立同分佈 <span class="math inline">\(\stackrel{i.i.d}{\sim} N(3, \sigma^2)\)</span></p>
<ol style="list-style-type: decimal">
<li>證明以下的假設的最佳檢驗統計量是 <span class="math inline">\(\sum_{i=1}^{10}(x_i-3)^2\)</span>：
<span class="math display">\[H_0: \sigma^2=1/4 \text{ v.s. } H_1: \sigma^2=1\]</span></li>
</ol>
<p><strong>解</strong></p>
<p>根據 Neyman-Pearson lemma (Section <a href="#Neyman-Pearson">15.3</a>) 來判斷最佳檢驗統計量：</p>
<p>下面用 <span class="math inline">\(\sigma^2_0, \sigma^2_1\)</span> 分別標記零假設和替代假設時的方差。</p>
<p><span class="math display">\[
\begin{aligned}
L(\sigma^2|\underline{x},\mu=3) &amp;= \prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma^2}}\text{exp}(-\frac{1}{2}(\frac{x_i-3}{\sigma})^2) \\
\Rightarrow \ell(\sigma^2) &amp;=-\frac{1}{2}\sum_{i=1}^n\text{log}\sigma^2-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-3)^2 \\
  &amp;= -\frac{n}{2}\text{log}\sigma^2-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-3)^2 \\
\Rightarrow \ell(\sigma_0^2)-\ell(\sigma_1^2)&amp;= \frac{n}{2}\text{log}\sigma_1^2+\frac{1}{2\sigma_1^2}\sum_{i=1}^n(x_i-3)^2\\
&amp;\;\;\;\;\;\;-\frac{n}{2}\text{log}\sigma_0^2-\frac{1}{2\sigma_0^2}\sum_{i=1}^n(x_i-3)^2\\
&amp;=\frac{n}{2}(\text{log}\sigma_1^2-\text{log}\sigma_0^2)+\frac{1}{2}(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})\sum_{i=1}^n(x_i-3)^2\\
&amp;=\frac{n}{2}\text{log}\frac{\sigma_1^2}{\sigma_0^2}+\frac{1}{2}(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})\sum_{i=1}^n(x_i-3)^2
\end{aligned}
\]</span></p>
<p>觀察上面的式子就會發現，當實驗重複後唯一會發生變化的就是後面的 <span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span>。
由於，<span class="math inline">\(\sigma_0^2=1/4, \; \sigma_1^2=1\)</span>，所以 <span class="math inline">\((\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})&lt;0\)</span>。那麼當 <span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span> 越大，<span class="math inline">\(\ell(\sigma_0^2)-\ell(\sigma_1^2)\)</span> 就越小。因此，這就是我們尋找的最佳檢驗統計量。</p>
<ol start="2" style="list-style-type: decimal">
<li>證明上面的檢驗統計量總是可以作爲最佳檢驗統計量，用於檢驗單側替代假設：<span class="math inline">\(H_1: \sigma^2&gt;1/4\)</span>。</li>
</ol>
<p>上面的替代假設中 <span class="math inline">\(\sigma_1^2=1\)</span>，如果將替代假設改成 <span class="math inline">\(\sigma_1^2&gt;1/4\)</span>，那麼 <span class="math inline">\((\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})&lt;0\)</span> 依然成立。所以，<span class="math inline">\(\sum_{i=1}^n(x_i-3)^2\)</span>，或者這部分乘以任何一個不變的常數依然是替代假設爲 <span class="math inline">\(H_1: \sigma^2&gt;1/4\)</span> 時的最佳檢驗統計量。</p>
<ol start="3" style="list-style-type: decimal">
<li>在 <span class="math inline">\(H_0\)</span> 條件下，樣本分佈 <span class="math inline">\(\sum_{i=1}^{10}(x_i-3)^2\)</span> 是怎樣的分佈？利用這個分佈來定義顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 時的拒絕域。</li>
</ol>
<p>在<span class="math inline">\(H_0\)</span> 條件下，有：
<span class="math display">\[X_1,\cdots,X_n\stackrel{i.i.d}{\sim}N(3,1/4)\\
\Rightarrow \frac{X_i-3}{\sqrt{1/4}}\sim N(0,1)\\
\Rightarrow (\frac{X_i-3}{\sqrt{1/4}})^2 \sim \mathcal{X}_1^2\\
\Rightarrow \sum_{i=1}^{10}(\frac{X_i-3}{\sqrt{1/4}})^2 \sim \mathcal{X}_{10}^2\\
\Rightarrow 4\sum_{i=1}^{10}(X_i-3)^2\sim \mathcal{X}_{10}^2\\
\text{Let } T=\sum_{i=1}^{10}(X_i-3)^2\\
\Rightarrow 4T \sim \mathcal{X}_{10}^2\]</span></p>
<p>拒絕域被定義爲檢驗統計量取大於等於某個臨界值時概率爲 <span class="math inline">\(0.05\)</span>，即 <span class="math inline">\(\text{Prob}(T\geqslant t)=0.05\)</span></p>
<p><span class="math display">\[\text{Prob}(4T\geqslant \mathcal{X}^2_{10,0.95})=0.05\\
\Rightarrow \text{Prob}(T\geqslant 1/4\mathcal{X}^2_{10,0.95})=0.05\]</span></p>
<p>所以，此處當顯著性水平定爲 <span class="math inline">\(\alpha=0.05\)</span> 時，拒絕域就是要大於自由度爲 <span class="math inline">\(10\)</span> 的卡方分佈的 <span class="math inline">\(95\%\)</span> 分位點。</p>
<ol start="4" style="list-style-type: decimal">
<li>在 <span class="math inline">\(H_0\)</span> 條件下，該檢驗統計量的正態分佈模擬是怎樣的？</li>
</ol>
<p>根據<strong>中心極限定理</strong>(Section <a href="#CLT">8</a>) 和 <strong>卡方分佈的性質</strong> (Section <a href="#chi-square-distribution">11</a>)</p>
<p><span class="math display">\[n\rightarrow \infty, X_n^2\sim N(n, 2n)\]</span></p>
<p>所以近似地，</p>
<p><span class="math display">\[\mathcal{X}_{10}^2\sim N(\text{E}(\mathcal{X}_{10}^2)=10,\text{Var}(\mathcal{X}_{10}^2)=20)\\
\Rightarrow 4T\sim \text{approx} N(10,20)\\
\Rightarrow \frac{4T-10}{\sqrt{20}} \stackrel{\cdot}{\sim} N(0,1)\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>用上面的正態分佈模擬，和觀察嘗試對單側替代假設作統計檢驗並依據所得結果作出結論：<span class="math display">\[H_0: \sigma^2=1/4 \text{ v.s. } H_1: \sigma^2&gt;1/4\]</span></li>
</ol>
<p>用上面的正態分佈近似法，我們可以計算拒絕域：</p>
<p><span class="math display">\[\text{Prob}(\frac{4T-10}{\sqrt{20}}\geqslant Z_{0.95})=0.05\]</span></p>
<p>已知標準正態分佈的 <span class="math inline">\(95\%\)</span> 分位點取值 <span class="math inline">\(1.64\)</span>，所以拒絕域：</p>
<p><span class="math display">\[\frac{4T-10}{\sqrt{20}}\geqslant 1.64\\
\Rightarrow T\geqslant1/4(10+1.64\sqrt{20})=1/4\times17.33\]</span></p>
<p>由觀察數據可得：<span class="math inline">\(T=11.5\)</span> ，所以觀察數據的檢驗統計量落在了拒絕域內。我們的結論是：觀察數據提供了極強的證據證明在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，口服該藥物24小時後的血漿藥物濃度的方差大於 <span class="math inline">\(1/4\)</span>。</p>
</div>
</div>
</div>
<div id="假設檢驗的近似方法" class="section level1">
<h1><span class="header-section-number">第 16 章</span> 假設檢驗的近似方法</h1>
<p>本章教你怎麼徒手搞似然比檢驗 (likelihood ratio test)，Wald 檢驗 (Wald test)，和 Score 檢驗 (Score test)。</p>
<div id="近似和精確檢驗-approximate-and-exact-tests" class="section level2">
<h2><span class="header-section-number">16.1</span> 近似和精確檢驗 approximate and exact tests</h2>
<p>前一章描述了如何用對數似然比尋找最佳檢驗統計量 (Section <a href="#Neyman-Pearson">15.3</a>)。一旦找到並確定了最佳檢驗統計量，接下去還需要確定這個最佳檢驗統計量的樣本分佈，用定好的顯著性水平(<span class="math inline">\(\alpha=0.05\)</span>)確定拒絕域，再使用觀察數據計算數據本身的統計量，然後對反對零假設的證據定量(計算 <span class="math inline">\(p\)</span> 值) 。前一章用的例子均來自於正態分佈，所以我們都能夠不太複雜地獲得樣本均值，樣本方差等較容易取得樣本分佈的檢驗統計量。正如我們在前一章最後部分 (Section <a href="#test-summary">15.7</a>) 總結的那樣，<strong>大多數情況下我們沒有那麼幸運</strong>。最佳檢驗統計量的樣本分佈會很難確定。所以另一個進行假設檢驗的途徑就是近似檢驗法 (approximate tests)。</p>
</div>
<div id="LRT" class="section level2">
<h2><span class="header-section-number">16.2</span> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</h2>
<p>記得我們之前說到，簡單假設 <span class="math inline">\(H_0: \theta=\theta_0\text{ v.s. } H_1: \theta=\theta_1\)</span> 的檢驗的最佳檢驗統計量可以使用 Neyman-Pearson lemma (尼曼皮爾森輔助定理) (Section <a href="#Neyman-Pearson">15.3</a>) 來確定：</p>
<p><span class="math display">\[\ell_{H_0}-\ell_{H_1} = \ell(\theta_0)-\ell(\theta_1)\]</span></p>
<p>如果假設變成了複合型假設：<span class="math inline">\(H_0: \theta\in\omega_0 \text{ v.s. } H_1: \theta\in\omega_1\)</span>。此時，<span class="math inline">\(\omega_0, \omega_1\)</span> 分別指兩種假設條件下我們關心的總體參數的可能取值範圍。那麼可以把上面的定理擴展成，在 <span class="math inline">\(\omega_0, \omega_1\)</span> 兩個取值範圍內，零假設和對立假設在給出的觀察數據條件下的極大似然之比：</p>
<p><span class="math display">\[\text{log}\frac{\text{max}_{H_0}[L(\theta|data)]}{\text{max}_{H_1}[L(\theta|data)]}=\text{max}_{H_0}[\ell(\theta|data)]-\text{max}_{H_1}[\ell(\theta|data)]\\
=\text{max}_{\theta\in\omega_0}[\ell(\theta|data)]-\text{max}_{\theta\in\omega_1}[\ell(\theta|data)]\]</span></p>
<p>典型的假設檢驗情況下，我們面對的是簡單的零假設和複合型的替代假設：</p>
<p><span class="math display">\[H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta\neq\theta_0\]</span></p>
<p>所以在這個情況下，套用擴展以後的 Neyman-Pearson lemma：</p>
<p><span class="math display">\[\text{max}_{H_0}[\ell(\theta)]-\text{max}_{H_1}[\ell(\theta)]=\ell(\theta_0) - \ell(\hat\theta)=llr(\theta_0)\]</span></p>
<p>之前討論對數似然比 (Section <a href="#llr-chi">13.3</a>) 時我們已知：</p>
<p><span class="math display">\[\text{Under }H_0: \theta=\theta_0\Rightarrow -2llr(\theta_0)\stackrel{\cdot}{\sim}\mathcal{X}_1^2\]</span></p>
<p>於是利用自由度爲 <span class="math inline">\(1\)</span> 的卡方檢驗的特徵我們就可以爲反對零假設的證據定量，計算關鍵的拒絕域。如果說顯著性水平爲 <span class="math inline">\(\alpha\)</span> 那麼，我們拒絕零假設 <span class="math inline">\(H_0:\theta=\theta_0\)</span> 的拒絕域是：</p>
<p><span class="math display">\[-2llr(\theta_0)&gt;\mathcal{X}^2_{1,1-\alpha}\]</span></p>
<p>當使用 <span class="math inline">\(\alpha=0.05\)</span> 時，這個關鍵的拒絕域就是：<span class="math inline">\(-2llr(\theta_0)&gt;3.84\)</span>。</p>
<p>這就是傳說中的 (對數) 似然比檢驗，(log-)Likelihood ratio test (LRT)。</p>
<p>LRT 的優點：</p>
<ol style="list-style-type: decimal">
<li>簡單；</li>
<li><span class="math inline">\(p\)</span> 值不會被參數尺度 (parameter scale) 左右，也就是說如果我們對參數進行了數學轉換 (Section <a href="#para-trans">14.2</a>) 也不會影響似然比檢驗計算得到的 <span class="math inline">\(p\)</span> 值大小。</li>
</ol>
<p>LRT 的缺點：</p>
<ol style="list-style-type: decimal">
<li>非正態分佈的數據時，LRT 只能算是漸進有效 (asymptotic valid)，即樣本量要足夠大時結果才能令人滿意；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>需要計算兩次對數似然 (MLE 和 零假設時)。</li>
</ol>
</div>
<div id="練習題-3" class="section level2">
<h2><span class="header-section-number">16.3</span> 練習題</h2>
<p>假設有在觀察對象 <span class="math inline">\(n=100\)</span> 人中發生了 <span class="math inline">\(k=40\)</span> 個事件。假定數據服從二項分佈，已知人羣中每個人發生該事件的概率爲 <span class="math inline">\(\pi_0=0.5\)</span>。嘗試計算似然比檢驗統計量：<span class="math inline">\(-2llr(\pi_0)\)</span>，並進行顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 的假設檢驗：<span class="math inline">\(H_0: \pi=\pi_0 \text{ v.s. }H_1: \pi\neq\pi_0\)</span></p>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\because f(k=40|\pi) = \binom{100}{40}\pi^{40}(1-\pi)^{100-40} \\
&amp;\text{Ignoring terms}  \text{ not with }  \pi \\
&amp;\therefore \ell(\pi|k=40) = 40\text{log}\pi+60\text{log}(1-\pi) \\
&amp;\Rightarrow \ell^\prime(\pi|k=40) = \frac{40}{\pi}-\frac{60}{1-\pi} \\
&amp;\text{Let }   \ell^\prime(\pi|k=40) = 0 \\
&amp;\Rightarrow   \frac{40}{\pi}-\frac{60}{1-\pi} =0 \\
&amp;\Rightarrow  \text{ MLE } \hat\pi=0.4 \\
&amp;\Rightarrow llr(\pi_0)=\ell(\pi_0)-\ell(\hat\pi) \\
&amp;\;\;\;\;\;\;\;\;\;=40\text{log}0.5+60\text{log}(1-0.5)-40\text{log}0.4-60\text{log}(1-0.4)\\
&amp;\;\;\;\;\;\;\;\;\;=-2.013\\
&amp;\Rightarrow -2llr=4.026 &gt; \text{Pr}(\mathcal{X}^2_{1,0.95})=3.84
\end{aligned}
\]</span></p>
<p>所以當顯著性水平爲 <span class="math inline">\(\alpha=0.05\)</span> 時，數據提供了足夠拒絕零假設的證據。該事件在此人羣中發生的概率要低於人羣的 <span class="math inline">\(0.5\)</span>。</p>
</div>
<div id="Wald" class="section level2">
<h2><span class="header-section-number">16.4</span> 近似檢驗法之 – Wald 檢驗</h2>
<p>和 LRT 一樣， Wald 檢驗也適用於檢驗 <span class="math inline">\(H_0: \theta=\theta_0 \text{ v.s. } H_1: \theta\neq\theta_0\)</span>。但是本方法其實是使用對數似然比方程的近似二次方程 (Section <a href="#quadratic-llr">14</a>)。相比之下，LRT 使用的是精確的對數似然比，只對檢驗統計量 <span class="math inline">\(-2llr\)</span> 進行了自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈 <span class="math inline">\(\mathcal{X}_1^2\)</span> 近似。本節介紹的 Wald 檢驗過程中使用了兩次近似，一次是計算對數似然比時使用了二次方程，一次則是和 LRT 一樣對檢驗統計量進行 <span class="math inline">\(\mathcal{X}_1^2\)</span> 近似。</p>
<p>根據之前的對數似然比近似結論 (Section <a href="#quadratic-llr2">14.1</a>) ：</p>
<p><span class="math display">\[llr(\theta)\approx-\frac{1}{2}(\frac{M-\theta}{S})^2\text{ asymptotically}\]</span></p>
<p>其中，<span class="math inline">\(M\)</span> 是 <span class="math inline">\(\text{MLE }\hat\theta\)</span>，<span class="math inline">\(S=\sqrt{\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}}\)</span></p>
<p>而且前一節我們也看到，</p>
<p><span class="math display">\[
\text{Under }H_0: \theta=\theta_0\Rightarrow -2llr(\theta_0) \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
\Rightarrow -2\times-\frac{1}{2}(\frac{M-\theta_0}{S})^2 \stackrel{\cdot}{\sim}\mathcal{X}_1^2 \\
\Rightarrow (\frac{M-\theta_0}{S}) \stackrel{\cdot}{\sim} N(0,1)\\
\text{Let } W=(\frac{M-\theta_0}{S})
\]</span></p>
<p><span class="math inline">\(W\)</span> 就是我們在 Wald 檢驗中用到的檢驗統計量。接下來就可以計算給定顯著水平 <span class="math inline">\(\alpha\)</span> 時的拒絕域，給 <span class="math inline">\(p\)</span> 值定量：</p>
<p>當 <span class="math inline">\(W&gt;N(0,1)_{1-\alpha/2}\)</span> 或 <span class="math inline">\(W&lt;N(0,1)_{\alpha/2}\)</span>時，拒絕 <span class="math inline">\(H_0: \theta=\theta_0\)</span>；</p>
<p>或者，當 <span class="math inline">\(W^2&gt;\mathcal{X}^2_{1,1-\alpha}\)</span> 時，拒絕 <span class="math inline">\(H_0: \theta=\theta_0\)</span>。</p>
<p>這就是我們心心念念的 Wald 檢驗。</p>
<div class="figure" style="text-align: center"><span id="fig:llr-wald"></span>
<img src="img/Selection_083.png" alt="Likelihood ratio and Wald tests: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation" width="90%" />
<p class="caption">
圖 16.1: Likelihood ratio and Wald tests: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation
</p>
</div>
<p>上圖 <a href="#fig:llr-wald">16.1</a> 解釋了 LRT 和 Wald 檢驗的不同之處。紅色虛線是二次方程，用於近似似然比方程(綠色實線) 。二者在 <span class="math inline">\(\text{MLE}=\hat\theta\)</span> 時同時取極大值。Wald 檢驗的是，數據提供的 <span class="math inline">\(\hat\theta\)</span> 和我們想要比較的零假設 <span class="math inline">\(\theta_0\)</span> 之間的橫軸差距。在檢驗量 <span class="math inline">\(W\)</span> 中我們還把這個差除以觀察數據均值的標準差(數據的標準誤) 。 如果數據本身波動大，<span class="math inline">\(W\)</span> 的分母(標準誤) 較大，那麼即使 <span class="math inline">\(\hat\theta - \theta_0\)</span> 保持不變，統計量變小，反對零假設的證據也就越小。反觀，LRT 檢驗的檢驗統計量就是上圖 <a href="#fig:llr-wald">16.1</a> 顯示的縱軸差 <span class="math inline">\(\ell(\theta_0)-\ell(\hat\theta)\)</span> 的大小。二者之間的關係被直觀的顯示在圖中。</p>
<p>Wald 檢驗優點：</p>
<ol style="list-style-type: decimal">
<li>比 LRT 略簡單；</li>
<li>不必再計算零假設時的對數似然，只需要 <span class="math inline">\(MLE\)</span> 和它的標準誤。</li>
</ol>
<p>Wald 檢驗缺點：</p>
<ol style="list-style-type: decimal">
<li>兩次近似(LRT只用了一次近似) ；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>參數如果被數學轉換 (Section <a href="#para-trans">14.2</a>)，<span class="math inline">\(p\)</span> 值會跟着變化。</li>
</ol>
<div id="再以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">16.4.1</span> 再以二項分佈爲例</h3>
<p>在 <span class="math inline">\(n\)</span> 個實驗對象中觀察到 <span class="math inline">\(k\)</span> 個事件，使用參數爲 <span class="math inline">\(\pi\)</span> 的二項分佈模型來模擬。使用 Wald 檢驗法對下列假設做出統計檢驗： <span class="math inline">\(H_0: \pi=\pi_0 \text{ v.s. } H1: \pi\neq\pi_0\)</span>。將參數 logit 轉換 (log-odds) 之後，對轉換後的新參數再做一次 Wald 檢驗。</p>
<p><strong>解</strong></p>
<p>根據之前的二次方程近似法推導 (Section <a href="#quadratic-binomial-approx">14.1.3</a>)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; M=\text{MLE}=\hat\pi=\frac{k}{n}=p\\
&amp; S=se(\hat\pi)=\sqrt{\frac{p(1-p)}{n}}\\
&amp; \Rightarrow \text{Under } H_0: \pi=\pi_0\\
&amp; W=(\frac{p-\pi_0}{\sqrt{\frac{p(1-p)}{n}}})\stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>根據參數數學轉換的性質 (Section <a href="#para-trans">14.2</a>)</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{New parameter } \beta=g(\pi)=\text{logit}(\pi)=\text{log}\frac{\pi}{1-\pi}\\
&amp; \text{MLE}=\text{logit}(\hat\pi)=\text{log}\frac{\hat\pi}{1-\hat\pi} \\
&amp; \text{Here we need to use delta-method to approximate standard error of } g(\pi)\\
&amp; S=se[g(\hat\pi)]\approx g^\prime(\pi)\times se(\hat\pi) \\
&amp; = \frac{1}{\hat\pi(1-\hat\pi)}\sqrt{\frac{p(1-p)}{n}}\\
&amp; =\sqrt{\frac{1}{k}+\frac{1}{n-k}} \\
&amp; \text{So the Wald test becomes}\\
&amp; H_0: \beta=\beta_0\\
&amp; \Rightarrow W=\frac{\text{log}(\frac{\hat\pi}{1-\hat\pi})-\text{log}(\frac{\pi_0}{1-\pi_0})}{\sqrt{\frac{1}{k}+\frac{1}{n-k}}}\stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>可見對參數進行了數學轉換之後，檢驗統計量的計算式發生了變化。因此 <span class="math inline">\(p\)</span> 值也會不同。</p>
</div>
</div>
<div id="Score" class="section level2">
<h2><span class="header-section-number">16.5</span> 近似檢驗法之 – Score 检验</h2>
<p>注意到 Wald 檢驗使用的近似二次方程是在 MLE， 也就是極大似然比時的點 <span class="math inline">\(\hat\theta\)</span> 和對數似然比方程取相同的值和相同曲率 (二次導數)。
可以類比的是，Score 检验是基于另一種二次方程模擬，Score 檢驗的近似二次方程和對數似然比方程在零假設 (<span class="math inline">\(\theta_0\)</span>) 時取相同的曲率。所以，Score 檢驗使用的近似方程在 <span class="math inline">\(\theta_0\)</span> 時和對數似然比方程在相同位置時的傾斜度 (一階導數)，和曲率 (坡度的變化程度，二階導數) 相同。所以令 <span class="math inline">\(U\)</span> 爲對數似然比方程在 <span class="math inline">\(\theta_0\)</span> 時的坡度，定義 <span class="math inline">\(V\)</span> 是對數似然比方程在 <span class="math inline">\(\theta_0\)</span> 時的曲率的負數：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; U=\ell^\prime(\theta)|_{\theta=\theta_0}=\ell^\prime(\theta_0)\\
&amp; V=-E[\ell^{\prime\prime}(\theta)]|_{\theta=\theta_0}=-E[\ell^{\prime\prime}(\theta_0)]
\end{aligned}
\]</span></p>
<p>注：此處的 <span class="math inline">\(V=-E[l^{\prime\prime}(\theta_0)]\)</span> 又常常被叫做 Expected Fisher information。</p>
<p>記得在 Wald 檢驗中使用的近似方程：
<span class="math display">\[llr(\theta)\approx-\frac{1}{2}(\frac{M-\theta}{S})^2\text{ asymptotically}\]</span></p>
<p>令 <span class="math inline">\(q(\theta)=-\frac{1}{2}(\frac{M-\theta}{S})^2\)</span>
就有：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; q^\prime(\theta)                      =\frac{M-\theta}{S^2}\\
&amp; \Rightarrow q^\prime(\theta_0)        =\frac{M-\theta_0}{S^2}\\
&amp; q^{\prime\prime}(\theta)              =-\frac{1}{S^2}\\
&amp; \Rightarrow q^{\prime\prime}(\theta_0)=E[l^{\prime\prime}(\theta_0)]\\
&amp; \Rightarrow \frac{1}{S^2}             =-E[l^{\prime\prime}(\theta_0)]\\
&amp; q^\prime(\theta_0)                    = \frac{M-\theta_0}{S^2} = -E[l^{\prime\prime}(\theta_0)](M-\theta_0)\\
&amp;                                       = \ell^\prime(\theta_0)\\
&amp; \Rightarrow     M-\theta_0  = -\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}\\
&amp; \Rightarrow     M  =  -\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}+\theta_0\\
&amp; q(\theta)=-\frac{1}{2}(\frac{M-\theta}{S})^2=\frac{E[l^{\prime\prime}(\theta_0)]}{2}(-\frac{\ell^\prime(\theta_0)}{E[l^{\prime\prime}(\theta_0)]}+\theta_0-\theta)^2\\
&amp; q(\theta)=-\frac{V}{2}(\frac{U}{V}+\theta_0-\theta)^2\\
&amp; \Rightarrow \text{ Under } H_0: \theta=\theta_0\\
&amp; \Rightarrow q(\theta_0)=-\frac{V}{2}(\frac{U}{V})^2=-\frac{U^2}{2V}\\
&amp; \Rightarrow -2q(\theta_0)=\frac{U^2}{V} \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \text{Or equivalently} \frac{U}{\sqrt{V}} \stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
<p>這就是 Score 檢驗時使用的檢驗統計量。相應的拒絕域就可以被定義爲：
當 <span class="math inline">\(\frac{U^2}{V}&gt;\mathcal{X}_{1,1-\alpha}^2\)</span> 時，拒絕 <span class="math inline">\(H_0\)</span></p>
<p>如下面的示意圖 <a href="#fig:score-test">16.2</a> 所示，Score 檢驗，比較的是 <span class="math inline">\(\theta_0\)</span> 時的校正後似然方程的坡度 (一階導數/二階導數)，和極大似然時的坡度 (一階導數=0) 的差別。如果這個值越大，說明零假設時的似然和極大似然 (觀察數據的信息) 的距離越遠，拒絕零假設的證據就越有力。</p>
<div class="figure" style="text-align: center"><span id="fig:score-test"></span>
<img src="img/Selection_084.png" alt="Score test: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation" width="90%" />
<p class="caption">
圖 16.2: Score test: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation
</p>
</div>
<p>Score 檢驗優點：</p>
<ol style="list-style-type: decimal">
<li>比 LRT 簡單；</li>
<li>不需要計算 MLE，只需要計算零假設時的對數似然比方程之坡度和曲率；</li>
<li>在流行病學用到的檢驗方法中最常用，也最容易擴展 (Mantel-Haenszel test, log rank test, generalised linear models such as logistic, Poisson, Cox regressions)。</li>
</ol>
<p>Score 檢驗缺點：</p>
<ol style="list-style-type: decimal">
<li>和 Wald 檢驗一樣用到了兩次近似；</li>
<li>無法總是保證這是最佳檢驗統計量；</li>
<li>參數如果被數學轉換 (Section <a href="#para-trans">14.2</a>)，<span class="math inline">\(p\)</span> 值會跟着變化。</li>
</ol>
<div id="再再以二項分佈爲例" class="section level3">
<h3><span class="header-section-number">16.5.1</span> 再再以二項分佈爲例</h3>
<p><span class="math inline">\(K\sim Bin(n, \pi)\)</span> 假如已知人羣中事件發生的概率是 <span class="math inline">\(\pi_0\)</span>。試推導此時的 Score 檢驗的檢驗統計量。</p>
<p><strong>解</strong></p>
<p>對二項分佈數據進行 Score 檢驗的時候我們需要計算 <span class="math inline">\(U, V\)</span>，然後計算統計量 <span class="math inline">\(\frac{U^2}{V}\)</span> 和 <span class="math inline">\(\mathcal{X}_1^2\)</span> 比較即可。</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Let } p=\frac{k}{n} \\
&amp; \ell(\pi|k) = k\text{log}(\pi)+(n-k)\text{log}(1-\pi)\\
&amp; \ell^\prime(\pi)=\frac{k}{\pi}-\frac{n-k}{1-\pi}=\frac{k-n\pi}{\pi(1-\pi)}\\
&amp; = \frac{p-\pi}{\pi(1-\pi)/n}\\
&amp; \Rightarrow U = \ell^\prime(\pi_0)=\frac{p-\pi_0}{\pi_0(1-\pi_0)/n}\\
&amp; \ell^{\prime\prime}(\pi|K)=-\frac{K}{\pi^2}-\frac{n-K}{(1-\pi)^2}\\
&amp; \Rightarrow -\ell^{\prime\prime}(\pi|K)=\frac{K}{\pi^2}+\frac{n-K}{(1-\pi)^2}\\
&amp; \because E(K)=n\pi\\
&amp; \therefore -E[\ell^{\prime\prime}(\pi|K)]=\frac{n\pi}{\pi^2}+\frac{n-n\pi}{(1-\pi)^2}\\
&amp; =\frac{n}{\pi}+\frac{n}{1-\pi}=\frac{n}{\pi(1-\pi)}\\
&amp; \text{ Under } H_0: \pi=\pi_0 \Rightarrow V=-E[\ell^{\prime\prime}(\pi_0)]=\frac{n}{\pi_0(1-\pi_0)}\\
&amp; \Rightarrow \frac{U^2}{V}=\frac{(p-\pi_0)^2}{\pi_0(1-\pi_0)/n} \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \text{OR } \frac{U}{\sqrt{V}} = \frac{p-\pi_0}{\sqrt{\pi_0(1-\pi_0)/n}} \stackrel{\cdot}{\sim} N(0,1)
\end{aligned}
\]</span></p>
</div>
</div>
<div id="LRTwaldScore-Compare" class="section level2">
<h2><span class="header-section-number">16.6</span> LRT, Wald, Score 檢驗三者的比較</h2>
<ol style="list-style-type: decimal">
<li><p>LRT 比較的是對數似然方程在零假設 <span class="math inline">\(H_0\)</span> 和極大似然估計 (MLE) 時之間的縱軸差 (圖 <a href="#fig:llr-wald">16.1</a>)；Wald 檢驗試圖直接比較 MLE 和 <span class="math inline">\(H_0\)</span> 的橫軸差 (二次方程近似法，並用標準誤校正) (圖 <a href="#fig:llr-wald">16.1</a>)；Score 檢驗比較的是對數似然方程在 <span class="math inline">\(H_0\)</span> 時的切線斜率 (二次方程近似法，用曲率也就是二階導數校正) (圖 <a href="#fig:score-test">16.2</a>)。三種檢驗比較的東西各不相同，但是這種差距大到進入拒絕域時，數據就會拒絕零假設。其中 Score 檢驗的計算過程最爲簡便，只需要計算 <span class="math inline">\(H_0\)</span> 時對數似然方程的一階和二階導數，而不用去計算 MLE，因此更多的被應用在流行病學數據計算中。</p></li>
<li><p>如果對數似然方程本身就是左右對稱的 (正態分佈的情況下)，這三個檢驗方法計算的所有結果都是完全一致的。如果對數似然方程只是近似左右對稱，那麼三者的計算結果會十分接近。可以說，三種檢驗方法是漸進等價的。</p></li>
<li><p>如果對觀測值進行了數學轉換，三者中只有 LRT 的計算結果保持不變。如果對參數的數學轉換使得對數似然方程更加接近左右對稱的二次方程，那麼 Wald 和 Score 檢驗的計算結果可以得到改善。</p></li>
<li><p>如果說，MLE 和 零假設之間的差距很大，那麼 Wald 或者 Score 檢驗所使用的二次方程近似法的誤差會增加，此時傾向於使用 LRT 來進行精確檢驗。當然如果當樣本量較大，要檢驗的差距也很大，三種檢驗方案都能夠提供證據拒絕零假設 (<span class="math inline">\(p\)</span> 值都會很小)。</p></li>
<li><p>如果三種檢驗方案給出的計算結果迥異，即使使用了數學轉換結果也沒有明顯改善的話，那麼最大的問題是樣本量太小。這時候還是老老實實用 LRT 吧。</p></li>
<li><p>幾乎所有的參數檢驗都歸類與這章節介紹的三種檢驗方法。比如說 <span class="math inline">\(Z\)</span> 檢驗， <span class="math inline">\(t\)</span> 檢驗， <span class="math inline">\(F\)</span> 檢驗都是 LRT。在流行病學研究中最常用的還是 Score 檢驗。</p></li>
</ol>
<p>我們的結論是，當條件允許的情況下，統計檢驗都推薦儘量使用精確檢驗 LRT。</p>
</div>
<div id="練習題-4" class="section level2">
<h2><span class="header-section-number">16.7</span> 練習題</h2>
<div id="q1-3" class="section level3">
<h3><span class="header-section-number">16.7.1</span> Q1</h3>
<p>在對數似然比章節 (Section <a href="#llr-chi1">13.2</a>)，我們曾經證明過，已知方差時：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; llr(\mu|\underline{x})=\ell(\mu|\underline{x})=-\frac{1}{2}(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2\\
&amp; \Rightarrow -2llr(\mu|\underline{x})=-2\ell(\mu|\underline{x})=(\frac{\bar{x}-\mu}{\sigma/\sqrt{n}})^2
\end{aligned}
\]</span></p>
<p>當觀察數據 <span class="math inline">\(X_1,\cdots,X_n\sim N(\mu,1^2)\)</span> ，求 LRT, Wald, Score 三種檢驗方法對下列假設進行檢驗時的檢驗統計量：
<span class="math inline">\(H_0: \mu=\mu_0 \text{ v.s. } H_1: \mu\neq\mu_0\)</span></p>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Model: } X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu, 1)\\
&amp; H_0: \mu=\mu_0 \text{ v.s. } H_1: \mu\neq\mu_0\\
&amp; \text{Model } \Rightarrow \bar{X} \sim N(\mu, \frac{1}{n}) \\
&amp; \text{If we observe } \bar{X} = \bar{x}\\
&amp; \ell(\mu|\bar{x})=-\frac{1}{2}(\frac{\bar{x}-\mu}{1/\sqrt{n}})^2\\
&amp; \textbf{For LRT, under } H_0: \mu=\mu_0 \Rightarrow -2llr(\mu_0) \stackrel{\cdot}{\sim}\mathcal{X}_1^2\\
&amp; \Rightarrow \frac{\bar{x}-\mu}{1/\sqrt{n}} \sim N(0,1)\\
&amp; \textbf{For Wald test, under } H_0: \mu=\mu_0 \Rightarrow \frac{M-\mu_0}{S}\sim N(0,1) \\
&amp; \Rightarrow \frac{\bar{x}-\mu}{1/\sqrt{n}} \sim N(0,1)\\
&amp; \textbf{For Score test, under } H_0: \mu=\mu_0 \Rightarrow U=\ell^\prime(\mu_0), V=-E[\ell^{\prime\prime}(\mu_0)]\\
&amp; U=\ell^\prime(\mu_0)=(\frac{\bar{x}-\mu_0}{1/\sqrt{n}})\sqrt{n}=\frac{\bar{x}-\mu_0}{1/n}\\
&amp; \ell^{\prime\prime}(\mu_0)=-\frac{1}{1/n}=-n \Rightarrow V=-E[n]=n\\
&amp; \frac{U^2}{V}=(\frac{\bar{x}-\mu_0}{1/n})^2/n=(\frac{\bar{x}-\mu_0}{1/\sqrt{n}})^2\\
&amp; \Rightarrow \frac{U^2}{V} \sim \mathcal{X}_1^2 \Rightarrow \frac{U}{\sqrt{V}}=\frac{\bar{x}-\mu_0}{1/\sqrt{n}} \sim N(0,1)
\end{aligned}
\]</span></p>
<p><strong>本題證明了，當數據服從正態分佈時，三種檢驗方法使用的檢驗統計量，是完全一致的。</strong></p>
</div>
<div id="q2-2" class="section level3">
<h3><span class="header-section-number">16.7.2</span> Q2</h3>
<p>根據醫生的觀察，某種癌症患者的生存時間服從平均值爲 <span class="math inline">\(1/\beta_0\)</span> 的指數分佈 (exponentially distributed)。有一種新藥物可以改善平均生存時間 (仍然服從指數分佈)。已知指數分佈的密度方程是：<span class="math inline">\(f(x|\beta)=\beta \text{exp} (-\beta x), \text{ where } \beta, x&gt;0\)</span>。</p>
<ol style="list-style-type: decimal">
<li>證明指數分佈的均值是 <span class="math inline">\(1/\beta\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; X\sim f(x|\beta), x&gt;0 \Rightarrow E(X)=\int_0^\infty x\cdot f(x)\text{d} x = \int_0^\infty x\cdot \beta \cdot e^{-\beta x} \text{d}x\\
&amp; E(x)= - \int_0^\infty x\cdot \frac{\text{d}e^{-\beta x}}{\text{d}x} \cdot \text{d}x\\
&amp; \text{We can now integrate by parts, using } \int_a^b u \frac{\text{d}v}{\text{d}x} \text{d}x = [uv]_a^b-\int_a^b v \frac{\text{d}u}{\text{d}x} \text{d}x \\
&amp; E(X) = -[x\cdot e^{-\beta x}]_0^\infty + \int_0^\infty e^{-\beta x} \text{d} x \\
&amp; \;\;\;\; = -0+\int_0^\infty e^{-\beta x} \text{d} x\\
&amp; \;\;\;\; = \int_0^\infty\frac{\text{d}}{\text{d}x} \frac{e^{-\beta x}}{-\beta} \text{d} x\\
&amp; \;\;\;\; = [\frac{e^{-\beta x}}{-\beta}]_0^\infty = \frac{1}{-\beta}[0-1]=\frac{1}{\beta}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>請寫下本題設定條件下的數學模型，零假設和替代假設</li>
</ol>
<p><strong>解：</strong> 假設患者人數爲 <span class="math inline">\(n\)</span>，他們的生存時間爲相互獨立的隨機變量： <span class="math inline">\(X_1,\cdots,X_n\)</span>。那麼本例中的數學模型爲：<span class="math inline">\(\text{Model: } X_1,\cdots,X_n\stackrel{i.i.d}{\sim}f(x|\beta)=\beta e^{-\beta x}\)</span>。我們可以提出如下的零假設和替代假設：<span class="math inline">\(H_0: \beta=\beta_0 \text{ v.s. } H_1: \beta\neq\beta_0\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>推導此模型參數 <span class="math inline">\(\beta\)</span> 的極大似然估計 (MLE)，試使用似然比檢驗法來推導進行假設檢驗時使用的檢驗統計量。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; L(\beta|\underline{x}) = \prod_{i=1}^n f(x_i|\beta)=\prod_{i=1}^n\beta e^{-\beta x_i} \\
&amp; \ell(\beta)=\sum_{i=1}^n\text{log}(\beta e^{-\beta x_i})=\sum\text{log}\beta-\sum\beta x_i=n\text{log}\beta-\beta\sum x_i \\
&amp; \;\;\;\; = n\text{log}\beta-\beta n \bar{x} \\
&amp; \Rightarrow \ell^\prime(\beta)=\frac{n}{\beta}-n\bar{x}\text{ MLE solves } \ell^\prime(\beta)=0 \text{ when }\ell^{\prime\prime}(\beta) &lt; 0 \\
&amp; \ell^\prime(\beta)=0 \Rightarrow \hat\beta=\frac{1}{\bar{x}}, \text{ and } \ell^{\prime\prime}(\beta)=-n\frac{1}{\beta^2} &lt; 0\\
&amp; \Rightarrow \text{ LRT test statistic: Under } H_0: \beta=\beta_0 \Rightarrow -2llr(\beta_0) \sim \mathcal{X}_1^2\\
&amp; llr(\beta_0)=\ell(\beta_0)-\ell(\hat\beta)=n\text{log}\beta_0-\beta_0n\bar{x}-n\text{log}\hat\beta+\hat\beta n \bar{x}\\
&amp; \text{ Substituting with MLE } \hat\beta=\frac{1}{\bar{x}}\\
&amp; \;\;\;\;\;\;\;\;\;\; = n\text{log}\beta_0-\beta_0n\bar{x}+n\text{log}\bar{x}+ n\\
&amp; \;\;\;\;\;\;\;\;\;\; = n(\text{log}\beta_0\bar{x}-\beta_0\bar{x}+1) \textbf{ this is the statistic for LRT}
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>推導 Score 和 Wald 檢驗法時的檢驗統計量</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \textbf{Score test: under } H_0 \Rightarrow \frac{U^2}{V}\sim \mathcal{X}_1^2 \text{ where } U=\ell^\prime(\beta_0), V=-E[\ell^{\prime\prime}(\beta_0)]\\
&amp; \Rightarrow U=\frac{n}{\beta_0}-n\bar{x}; V = -E[-n\frac{1}{\beta_0^2}] = n\frac{1}{\beta_0^2} \\
&amp; \Rightarrow \frac{U^2}{V}=(\frac{n}{\beta_0}-n\bar{x})^2\cdot\frac{\beta_0^2}{n} = (\frac{(\frac{n}{\beta_0}-n\bar{x})\beta_0}{\sqrt{n}})^2\\
&amp; \;\;\;\;\;\;\;\;\; = n(1-\bar{x}\beta_0)^2\\
&amp; \textbf{This is the statistic for Score test}\\
&amp; \textbf{Wald test: under } H_0: \beta=\beta_0 \Rightarrow W=(\frac{M-\beta_0}{S})^2 \sim \mathcal{X}_1^2, \\
&amp; \text{ where } M=\hat\beta=\frac{1}{\bar{x}}, \text{ and } S^2=-\frac{1}{\ell^{\prime\prime}(\hat\beta)}\\
&amp; \ell^{\prime\prime}(\beta)=-n\frac{1}{\beta^2}\Rightarrow \ell^{\prime\prime}(\hat\beta)=-n\bar{x}^2\Rightarrow S^2=\frac{1}{n\bar{x}^2}\\
&amp; \Rightarrow W=(\frac{M-\beta_0}{S})^2=\frac{(\frac{1}{\bar{x}}-\beta_0)^2}{\frac{1}{n\bar{x}^2}}=n(1-\beta_0\bar{x})^2\\
&amp; \textbf{This is the statistic for Wald test}
\end{aligned}
\]</span></p>
<p>注意到在這個特例中， Score 和 Wald 檢驗的統計量竟然不謀而合。</p>
<ol start="5" style="list-style-type: decimal">
<li>觀察5名患者，獲得診斷後的生存數據 (年)： <span class="math inline">\(0.5,1,1.25,1.5,0.75\)</span>。用上面推導的統計量對這個數據進行假設檢驗：<span class="math inline">\(H_0: \beta=0.5 \text{ v.s. } \beta\neq0.5\)</span>，你如何下結論？</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Data: } x_1,\cdots,x_n=0.5,1,1.25,1.5,0.75. \Rightarrow \bar{x}=1\\
&amp;H_0: \beta=0.5 \text{ v.s. } \beta\neq0.5\\
&amp;\textbf{LRT test: } \\
&amp; llr(\beta_0) = n(\text{log}\beta_0\bar{x}-\beta_0\bar{x}+1) = 5\times(\text{log}0.5-0.5\times1+1) = -0.966\\
&amp;\Rightarrow -2llr=1.93 &lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
&amp;\textbf{Score test: } \\
&amp; \frac{U^2}{V} = n(1-\bar{x}\beta_0)^2 = 5\times(1-1\times0.5)^2=1.25 &lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
&amp;\textbf{Wald test: } \\
&amp; W=n(1-\beta_0\bar{x})^2=5\times(1-0.5\times1)^2=1.25&lt; \text{Prob}(\mathcal{X}^2_{1,0.95}) = 3.84 \\
&amp; \text{There is no evidence that } \beta\neq0.5.\\
\end{aligned}
\]</span></p>
</div>
<div id="q3-1" class="section level3">
<h3><span class="header-section-number">16.7.3</span> Q3</h3>
<p>隨機變量 <span class="math inline">\(X_1,\cdots,X_n\)</span> 互相獨立且在區間 <span class="math inline">\([0,\alpha]\)</span> 內服從相同的恆定概率分佈 (identical uniform distribution)。
試着畫出參數 <span class="math inline">\(\alpha\)</span> 的似然方程示意圖。不進行任何數學計算，試着想象一下如果對 <span class="math inline">\(\alpha\)</span> 進行某種假設檢驗會出現什麼問題嗎？</p>
</div>
</div>
</div>
<div id="正態誤差模型-normal-error-models" class="section level1">
<h1><span class="header-section-number">第 17 章</span> 正態誤差模型 Normal error models</h1>
<p>正態誤差模型，其實沒有其名字那麼複雜，就是討論在正態分布條件下，<strong>均值和方差都需要被估計</strong> (都是未知狀態) 的模型。</p>
<p>本章還介紹</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈，試着闡述如何將 <span class="math inline">\(t\)</span> 分佈應用於兩個獨立樣本均值的比較；</li>
<li><span class="math inline">\(\chi^2\)</span> 分佈在統計學中各種常用分佈中的中心位置。</li>
</ol>
<div id="服從正態分佈的隨機變量" class="section level2">
<h2><span class="header-section-number">17.1</span> 服從正態分佈的隨機變量</h2>
<p><span class="math display">\[
X_1,\cdots,X_n \stackrel{i.i.d}{\sim} N(\mu,\sigma^2) \Leftrightarrow \bar{X} \sim N(\mu, \frac{\sigma^2}{n})
\]</span></p>
<p>如果總體方差 <span class="math inline">\(\sigma^2\)</span> 已知 (理想狀態，現實中不太可能)：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1) \\
&amp; 95\% \text{CI for } \mu = \bar{X} \pm Z_{0.975}\frac{\sigma}{\sqrt{n}} \\
&amp; \text{H}_0: \mu=\mu_0 \Rightarrow \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \sim N(0,1)
\end{aligned}
\]</span></p>
<p>如果總體方差 <span class="math inline">\(\sigma^2\)</span> 是未知的，腫麼辦？ (模型中出現了兩個參數 <span class="math inline">\(\mu \;\&amp;\; \sigma^2\)</span>)</p>
<p><span class="math display">\[
T=\frac{\bar{X}-\mu_0}{\hat\sigma/\sqrt{n}} \sim ?????????
\]</span></p>
</div>
<div id="Fandtdistr" class="section level2">
<h2><span class="header-section-number">17.2</span> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</h2>
<p>如果 <span class="math inline">\(X\sim N(0,1)\)</span>，那麼 <span class="math inline">\(X^2 \sim \chi^2_1\)</span> (Section <a href="#chi-square-distribution">11</a>)。類似地，如果 <span class="math inline">\(X_1,\cdots,X_n \stackrel{i.i.d}{\sim} N(0,1)\)</span> 那麼 <span class="math inline">\(\sum_{i=1}^n X^2_i \sim \chi^2_k\)</span>。</p>
<p><span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈是建立在 <span class="math inline">\(\chi^2\)</span> 分佈的基礎上的：</p>
<ul>
<li><span class="math inline">\(F\)</span> 分佈： <span class="math inline">\(Y_1, Y_2\)</span> 是獨立的兩個隨機變量，且 <span class="math inline">\(Y_1 \sim \chi^2_{k_1}; Y_2 \sim \chi^2_{k_2}\)</span>，那麼</li>
</ul>
<p><span class="math display">\[
F=\frac{Y_1/k_1}{Y_2/k_2} \sim F_{k_1, k_2}
\]</span></p>
<ul>
<li><span class="math inline">\(t\)</span> 分佈，是 <span class="math inline">\(F\)</span> 分佈的特殊情況 <span class="math inline">\((k_1=1)\)</span>：</li>
</ul>
<p><span class="math display">\[
T\sim t_{k_2} \Rightarrow T^2 = \frac{Y_1/1}{Y_2/k_2} \sim F_{1,k_2}
\]</span></p>
<p>此時我們再來考慮正態分佈模型中有兩個參數 <span class="math inline">\(\mu, \sigma^2\)</span> 需要被估計的模型：</p>
<p><span class="math display">\[
Y_i \stackrel{i.i.d}{\sim} N(\mu,\sigma^2) \text{ where } i = 1, \cdots, n
\]</span></p>
<p>其實可以改寫爲</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Y_i = \mu + \varepsilon_i \\
&amp; \text{Where } \varepsilon_i \stackrel{i.i.d}{\sim} N(0,\sigma^2)
\end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\varepsilon_i \stackrel{i.i.d}{\sim} N(0,\sigma^2)\)</span> 就是正態誤差 normal (random) error。<span class="math inline">\(Y_i = \mu + \varepsilon_i\)</span> 就是正態誤差模型 normal error model。誤差的含義就是統計模型中的隨機誤差 (模型不能解釋的部分)。如果一個正態誤差模型像前面的式子這樣沒有其他變量，那麼所有的觀察值 <span class="math inline">\(Y_i\)</span>，就是由總體均值 <span class="math inline">\(\mu\)</span> population mean，和隨機誤差 <span class="math inline">\(\varepsilon\)</span> random error 來說明 (就是這個式子 <span class="math inline">\(Y_i = \mu + \varepsilon_i\)</span>)。</p>
<p>如果觀察值 <span class="math inline">\(Y_i\)</span> 的一部分除了可以用均值解釋，還可以由某個變量 <span class="math inline">\(x\)</span> 來說明 (叫做解釋變量 explanatory variable 詳見線性迴歸部分 Section <a href="#defLM">26.3.3</a>)，即：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;Y_i | x \stackrel{i.i.d}{\sim} N(\mu+\beta x_i, \sigma^2)\\
&amp; E(Y|x) = \mu+\beta x, \text{Var}(Y|x) = \sigma^2 \\
&amp; \text{ or } Y_i|x = \mu + \beta x_i + \varepsilon_i ; \text{ where }  \varepsilon_i \stackrel{i.i.d}{\sim} N(0, \sigma^2)
\end{aligned}
\]</span></p>
<p>上面的模型會在後面講線性迴歸的部分深入探討，此處簡單用下面的圖形來輔助理解。圖 <a href="#fig:normal-error0">17.1</a> 中繪製的是 <span class="math inline">\(Y_i|x = \mu + \beta x_i + \varepsilon_i ; \text{ where } \varepsilon_i \stackrel{i.i.d}{\sim} N(0, \sigma^2)\)</span> 的示意圖，用 <span class="math inline">\(x_i\)</span> 標記兩個組，其中 <span class="math inline">\(x_i = 0\)</span> 時爲組 A 的人的觀察值，<span class="math inline">\(x_i=1\)</span> 時爲組 B 的人的觀察值。兩組的平均值如 Y 軸顯示的那樣，組 A 是 <span class="math inline">\(\mu\)</span>，組 B 是 <span class="math inline">\(\mu+\beta\)</span>。所以，這裏可以看到，正態誤差模型是假定兩組具有相同的方差的 common variance，如圖 <a href="#fig:normal-error1">17.2</a>。如果解釋變量 (explanatory variable) 是一個連續型變量，則解釋爲在 X 軸上的任意一點對應的 Y 值的誤差都服從相同的方差，如圖 <a href="#fig:normal-error2">17.3</a></p>
<div class="figure" style="text-align: center"><span id="fig:normal-error0"></span>
<img src="img/Selection_105.png" alt="Normal error models with categorical explanatory variable" width="90%" />
<p class="caption">
圖 17.1: Normal error models with categorical explanatory variable
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:normal-error1"></span>
<img src="img/Selection_106.png" alt="Normal error models shown with common error variance" width="90%" />
<p class="caption">
圖 17.2: Normal error models shown with common error variance
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:normal-error2"></span>
<img src="img/Selection_107.png" alt="Normal error models shown with continuous variable and common error variance" width="80%" />
<p class="caption">
圖 17.3: Normal error models shown with continuous variable and common error variance
</p>
</div>
</div>
<div id="兩個參數的模型" class="section level2">
<h2><span class="header-section-number">17.3</span> 兩個參數的模型</h2>
<div id="一組數據兩個參數" class="section level3">
<h3><span class="header-section-number">17.3.1</span> 一組數據兩個參數</h3>
<p>如果觀察數據 <span class="math inline">\(\underline{x} = x_1, \cdots, x_n\)</span> 是互相獨立的，該觀察數據的模型可以用一個包含兩個參數 <span class="math inline">\(\theta,\phi\)</span> 的概率方程 <span class="math inline">\(f\)</span> 來描述，那麼這個包含兩個參數的概率方程的似然和對數似然分別是：</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta, \phi | \underline{x}) &amp;=  \prod_{i=1}^nf(x_i | \theta, \phi) \\
\ell(\theta, \phi | \underline{x}) &amp;= \sum_{i=1}^n\text{log}f(x_i | \theta, \phi)
\end{aligned}
\]</span></p>
<p>兩個參數的 <span class="math inline">\(\text{MLE}\)</span> 可以通過對對數似然方程進行兩次偏微分，然後解連立方程組：</p>
<p><span class="math display">\[
\left\{
\begin{array}{ll}
\frac{\partial\ell}{\partial\theta} = 0\\
\frac{\partial\ell}{\partial\phi} = 0 \\
\end{array}
\right.
\]</span></p>
</div>
<div id="兩組數據各一個參數" class="section level3">
<h3><span class="header-section-number">17.3.2</span> 兩組數據各一個參數</h3>
<p>如果是兩組獨立數據，各由一個參數描述他們各自的概率方程：</p>
<p><span class="math display">\[
X_1, \cdots, X_n \stackrel{i.i.d}\sim f(\theta_1) \\
Y_1, \cdots, Y_m \stackrel{i.i.d}\sim f(\theta_2)
\]</span></p>
<p>那麼以兩組數據爲聯合條件 (應該可以理解爲同時觀察到時的) 的聯合似然 (joint likelihood)：</p>
<p>We describe the likelihood as the joint likelihood, conditional on jointly observing both datasets:</p>
<p><span class="math display">\[
L(\theta_1, \theta_2|\underline{x},\underline{y}) = \prod_{i=1}^nf_1(x_{1i}|\theta_1) \times \prod_{i=1}^mf_2(y_{i}|\theta_2)
\]</span></p>
<p>所以，聯合之後的對數似然方程就是兩個對數似然方程之和：</p>
<p><span class="math display">\[
\ell(\theta_1,\theta_2|\underline{x},\underline{y}) = \sum_{i=1}^n\text{log} f(x_i|\theta_1) + \sum_{i=1}^m\text{log} f(y_i|\theta_2)
\]</span></p>
<p>你會發現，分成兩組數據兩個獨立的概率方程之後的聯合對數似然方程求 <span class="math inline">\(\text{MLE}\)</span> 時需要用偏微分。可是偏微分之後的結果，和兩組數據合二爲一，用含有兩個參數的概率方程，計算其 <span class="math inline">\(\text{MLE}\)</span> 的結果會<strong>完全相同</strong>。</p>
</div>
</div>
<div id="正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導" class="section level2">
<h2><span class="header-section-number">17.4</span> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</h2>
<p>此時的情況如同前面的把兩組數據合二爲一的情況，用正態分佈的概率方程，然後有兩個參數 <span class="math inline">\(\mu, \sigma^2\)</span>。</p>
<p><span class="math display">\[
Y_1,\cdots,Y_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2) \\
\ell(\mu, \sigma^2 | \underline{y}) = -\frac{n}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}\sum^n_{i=1} (x_i - \mu)^2
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mu: \frac{\partial \ell}{\partial \mu} = \frac{\sum^n_{i=1}(y_i-\mu)}{2\sigma^2} = 0 \Rightarrow \hat\mu = \bar{y}\\
&amp; \sigma^2: \frac{\partial \ell}{\partial (\sigma^2)} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\mu)^2 \\
&amp; \text{ Substituting } \mu=\hat\mu = \bar{y} \text{ and set equal to } 0\\
&amp; \frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\bar{y})^2 = 0 \\
&amp; \Rightarrow \hat\sigma^2 = \frac{1}{n}\sum^n_{i=1}(y_i - \bar{y})^2
\end{aligned}
\]</span></p>
<p>有沒有覺得這裏的方差的極大似然估計似曾相識 (Section <a href="#samplevarbias">10.3</a>)。在早期的章節中，我們學到了分部法 (“把樣本和總體均值之間的差的平方和分成兩部分”)：</p>
<p><span class="math display">\[
\begin{aligned}
\sum^n_{i=1}(y_i-\mu)^2 &amp; = \sum^n_{i=1}(y_i - \bar{y} + \bar{y} -\mu)^2  \\
                        &amp; = \sum^n_{i=1}(y_i - \bar{y})^2 + \sum^n_{i=1}(\bar{y}-\mu)^2 \\
\Rightarrow \sum^n_{i=1}(y_i - \bar{y})^2 &amp; = \sum^n_{i=1}(y_i-\mu)^2 - \sum^n_{i=1}(\bar{y}-\mu)^2
\end{aligned}
\]</span></p>
<p>當時分的是平方和，這裏再介紹一種把概率分部的方法 <strong>partition the probabilities</strong>。</p>
<p>We can “partition” the probability of observing the data, conditional on unknown <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>, into</p>
<ol style="list-style-type: decimal">
<li>the probability of observing the data conditional on the observed sample mean <span class="math inline">\(\bar{y}\)</span> and unknown <span class="math inline">\(\sigma^2\)</span> ;</li>
<li>the probability of observing the sample mean <span class="math inline">\(\bar{y}\)</span> conditional on the two unknown parameters.</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Prob}(\underline{y} | \mu, \sigma^2) = \text{Prob}(\underline{y}|\bar{y}, \sigma^2) \times \text{Prob}(\bar{y}|\mu, \sigma^2) \\
&amp;\Rightarrow \text{Prob}(\underline{y} | \bar{y}, \sigma^2) = \frac{\text{Prob}(\underline{y} | \mu, \sigma^2)}{\text{Prob}(\bar{y}|\mu, \sigma^2)}
\end{aligned}
\]</span></p>
<p>看到這裏你是否會想起概率論中討論的條件概率方程 (Section <a href="#conditonalProb">1.2</a>)：</p>
<p><span class="math display">\[
f(x|Y=y) = \frac{f(x,y)}{f(y)}
\]</span></p>
<p>利用上述概率分佈的方法，我們可以進而推導方差 <span class="math inline">\(\sigma^2\)</span> 的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
f(\underline{y} | \bar{y}, \sigma^2) &amp;= \frac{
\color{red}{f(\underline{y} | \mu, \sigma^2)}
}{f(\bar{y}|\mu, \sigma^2)} \\
  &amp;=  \frac{
  \color{red}{(\frac{1}{\sqrt{2\pi\sigma^2}})^ne^{-\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \mu)^2}}
  }{(\frac{1}{\sqrt{2\pi\sigma^2/n}})e^{-\frac{1}{2\sigma^2/n}(\bar{y}-\mu)^2}} \\
\Rightarrow \ell(\sigma^2| \underline{y}, \bar{y}) &amp;=
\color{red}{-\frac{n}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}\sum^n_{i=1}(y_i-\mu)^2} \\ &amp; \;\;\;+\frac{1}{2}\text{log}\frac{\sigma^2}{n} + \frac{1}{2\sigma^2/n}(\bar{y}-\mu)^2 \\
&amp;= -\frac{n-1}{2}\text{log}\sigma^2 - \frac{1}{2\sigma^2}(\sum^n_{i=1}(y_i-\mu)^2 - n(\bar{y}-\mu)^2) \\
 \text{Because }  &amp;\sum^n_{i=1}(y_i - \bar{y})^2  = \sum^n_{i=1}(y_i-\mu)^2 - \sum^n_{i=1}(\bar{y}-\mu)^2 \\
 \Rightarrow \ell(\sigma^2| \underline{y}, \bar{y}) &amp;= -\frac{n-1}{2}\text{log}\sigma^2 -\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \bar{y})^2 \\
 \text{Note that the } &amp;\text{above conditional log-likelihood is now free of } \mu \\
 \Rightarrow \ell^\prime(\sigma^2) &amp;= -\frac{n-1}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum^n_{i=1}(y_i-\bar{y})^2 \\
 \text{Set equal } &amp; \text{to zero and rearrange} \\
 \Rightarrow \hat\sigma^2 &amp;= \frac{1}{n-1}\sum^n_{i=1}(y_i-\bar{y})^2\\
 \text{This is the } &amp;\color{red}{\text{unbiased estimate of } \sigma^2}
\end{aligned}
\]</span></p>
<p>現在再重新考慮對數據 <span class="math inline">\(Y_1, \cdots, Y_n \stackrel{i.i.d}{\sim} N(\mu, \sigma^2)\)</span> 進行均值的假設檢驗：</p>
<p><span class="math display">\[
\text{H}_0: \mu = \mu_0 \text{ v.s H}_1: \mu &gt; \mu_0
\]</span></p>
<p>當 <span class="math inline">\(\sigma^2\)</span> 是<strong>已知的</strong>，在零假設條件下的檢驗統計量是：</p>
<p><span class="math display" id="eq:infer8-1">\[
\begin{aligned}
&amp; \text{H}_0 \Rightarrow (\frac{\bar{Y}-\mu_0}{\sigma/\sqrt{n}}) \sim N(0,1) \\
&amp; \text{Or equivalently, } \\
&amp; (\frac{\bar{Y}-\mu_0}{\sigma/\sqrt{n}})^2 \sim \chi_1^2
\end{aligned}
\tag{17.1}
\]</span></p>
<p>當 <span class="math inline">\(\sigma^2\)</span> 是<strong>未知的</strong>，它需要通過樣本數據來估計時。我們就該使用前面從條件對數似然方程推導出的方差無偏估計：</p>
<p><span class="math display">\[
\hat\sigma^2 = S^2 = \frac{1}{n-1}\sum^n_{i=1}(y_i-\bar{y})^2
\]</span></p>
<p>但是，假如只把無偏估計的方差放到公式 <a href="#eq:infer8-1">(17.1)</a> 裏去，可以當作新的檢驗統計量嗎？有這麼簡單嗎？</p>
<p><span class="math display">\[
(\frac{\bar{Y}-\mu_0}{s/\sqrt{n}})^2
\]</span></p>
<p>當然沒有這麼簡單！這種方式僅僅考慮了樣本的方差估計，卻忽略了這個估計是有不確定性的 (uncertainty)，它並不是真實的 <span class="math inline">\(\sigma^2\)</span>，只是個估計 (estimator)。我們需要找到一種方法把方差的不確定性也考慮進新的檢驗統計量裏去。利用章節 <a href="#samplevar">10.4</a> 的結論：</p>
<p><span class="math display" id="eq:infer8-2">\[
\begin{equation}
\frac{n-1}{\sigma^2}S^2 \sim \chi^2_{n-1}\\
\Rightarrow \frac{S^2}{\sigma^2} = \frac{\chi^2_{n-1}}{n-1}
\end{equation}
\tag{17.2}
\]</span></p>
<p>把公式 <a href="#eq:infer8-1">(17.1)</a> 除以 <a href="#eq:infer8-2">(17.2)</a> 獲得：</p>
<p><span class="math display">\[
\frac{(\bar{Y}-\mu_0)^2}{S^2/n} \sim \frac{\chi^2_1/1}{\chi^2_{n-1}/n-1} = F_{1,n-1}
\]</span></p>
<p>這樣我們就同時考慮了方差估計本身，和它的不確定性了。這個新的統計量被定義爲 <span class="math inline">\(T\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; T=\frac{\bar{Y}-\mu_0}{S/\sqrt{n}} \\
&amp; \text{Then under H}_0: T^2 \sim F_{1,n-1} \text{ or equivalently } T \sim \sqrt{F_{1,n-1}}=t_{n-1}
\end{aligned}
\]</span></p>
<p>這個特殊的 <span class="math inline">\(F\)</span> 分佈，就是我們之前定義過的，這裏用手紮紮實實地推導出來的檢驗統計量 <span class="math inline">\(t\)</span> 和 <span class="math inline">\(t\)</span> 分佈。利用這個方差未知時的分佈，均值的 <span class="math inline">\(95\%\)</span> 信賴區間的估計就是：</p>
<p><span class="math display">\[
95\% \text{ CI for } \mu: \bar{Y} \pm t_{n-1,0.975}\frac{S}{\sqrt{n}}
\]</span></p>
</div>
<div id="比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2" class="section level2">
<h2><span class="header-section-number">17.5</span> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></h2>
<p>本節要來推導<strong>方差齊時</strong>的兩個獨立樣本的均值比較 two sample <span class="math inline">\(t\)</span> test。兩個獨立樣本用下面的數學符號標記：</p>
<p><span class="math display">\[
X_1, \cdots, X_n \stackrel{i.i.d}{\sim} N(\mu_1, \sigma^2); Y_1, \cdots, Y_m, \stackrel{i.i.d}{\sim} N(\mu_2, \sigma^2)
\]</span></p>
<p>要進行的假設檢驗是：</p>
<p><span class="math display">\[
\text{H}_0: \mu_1 = \mu_2 \text{ v.s. } \text{H}_1: \mu_1 &gt; \mu_2
\]</span></p>
<p>此時，兩組獨立樣本的共同方差 <span class="math inline">\(\hat\sigma^2\)</span> 需要被估計，利用上面相同的推導過程，可以獲得合併後的共同方差的無偏估計：</p>
<p><span class="math display" id="eq:infer8-3">\[
\begin{equation}
\hat\sigma^2 = S^2_p = \frac{\sum^n_{i=1}(X_i-\bar{X})^2 + \sum^m_{i=1}(Y_i-\bar{Y})^2}{n+m-2}\\
\end{equation}
\tag{17.3}
\]</span></p>
<p>因爲兩組數據互相獨立，所以有：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{1}{\sigma^2}\sum^n_{i=1}(X_i - \bar{X})^2 \sim \chi^2_{n-1} \\
&amp; \frac{1}{\sigma^2}\sum^m_{i=1}(Y_i - \bar{Y})^2 \sim \chi^2_{m-1} \\
\Rightarrow &amp;\frac{1}{\sigma^2}\{ \sum^n_{i=1}(X_i - \bar{X})^2 + \sum^m_{i=1}(Y_i - \bar{Y})^2 \} \sim \chi^2_{n+m-2}
\end{aligned}
\]</span></p>
<p>把公式 <a href="#eq:infer8-3">(17.3)</a> 代入此式可得：</p>
<p><span class="math display" id="eq:infer8-4">\[
\begin{equation}
(n+m-2)\frac{S^2_p}{\sigma^2} \sim \chi^2_{n+m-2}
\end{equation}
\tag{17.4}
\]</span></p>
<p>由於 <span class="math inline">\(\bar{X} \sim N(\mu_1, \frac{\sigma^2}{n}); \bar{Y} \sim N(\mu_2, \frac{\sigma^2}{m})\)</span>，所以在零假設條件下 <span class="math inline">\(\text{H}_0: \mu_1=\mu_2\Rightarrow \bar{X}-\bar{Y} \sim N(0,\sigma^2(\frac{1}{n}+\frac{1}{m}))\)</span>。</p>
<p><span class="math display" id="eq:infer8-5">\[
\begin{equation}
\Rightarrow \frac{\bar{X}-\bar{Y}}{\sqrt{\sigma^2(\frac{1}{n}+\frac{1}{m})}} \sim N(0,1) \\
\Leftrightarrow \frac{(\bar{X}-\bar{Y})^2}{\sigma^2(\frac{1}{n}+\frac{1}{m})} \sim \chi^2_1
\end{equation}
\tag{17.5}
\]</span></p>
<p>現在把公式 <a href="#eq:infer8-5">(17.5)</a> 除以 <a href="#eq:infer8-4">(17.4)</a> 可得：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{(\bar{X}-\bar{Y})^2}{\sigma^2(\frac{1}{n}+\frac{1}{m})} \times \frac{\sigma^2}{S^2_p(n+m-2)} = \frac{\chi^2_1/1}{\chi^2_{n+m-2}} \\
&amp;\Rightarrow T^2 = \frac{(\bar{X}-\bar{Y})^2}{S^2_p(\frac{1}{n}+\frac{1}{m})} = \frac{\chi^2_1/1}{\chi^2_{n+m-2}/(n+m-2)} \sim F_{1,n+m-2} \\
&amp;\Rightarrow T = \frac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2}
\end{aligned}
\]</span></p>
<p>這就是標準的兩個齊方差的獨立樣本均值比較的 <span class="math inline">\(t\)</span> 檢驗，two-sample <span class="math inline">\(t\)</span> test with pooled variance。這裏推導的兩個 <span class="math inline">\(t\)</span> 檢驗，是都是精確的<strong>似然比檢驗 (likelihood ratio test)</strong> (Section <a href="#LRT">16.2</a>)。壯士請自己跟着似然比檢驗的方法推導一次。</p>
</div>
<div id="各個統計分佈之間的關係" class="section level2">
<h2><span class="header-section-number">17.6</span> 各個統計分佈之間的關係</h2>
<p>卡方分佈 <span class="math inline">\(\chi^2\)</span> 是統計學常用分佈中極爲重要的分佈，其他的許多分佈都與之相關。</p>
<p><span class="math display">\[
\{N(0,1)\}^2 = \chi^2_1 \\
\chi^2_k = \sum_{i-1}^k \chi^2_1 \\
F_{k,n} = \frac{\chi^2_k/k}{\chi^2_n/n}\\
t^2_n = F_{1,n} =\frac{\chi^2_1/1}{\chi^2_n/n}
\]</span></p>
</div>
</div>
<div id="多個參數時的統計推斷-inference-with-multiple-parameters-i" class="section level1">
<h1><span class="header-section-number">第 18 章</span> 多個參數時的統計推斷 Inference with multiple parameters I</h1>
<p>前一章介紹單樣本和雙樣本 <span class="math inline">\(t\)</span> 檢驗時已經接觸到了 2 個未知參數情況下的檢驗統計量推導，本章把之前用到的方法擴展到 2 個以上參數的情況。帶你推導兩個以上參數的似然比檢驗 likelihood ratio test，Wald 檢驗，和 Score 檢驗推論。</p>
<div id="多參數-multiple-parameters---lrt" class="section level2">
<h2><span class="header-section-number">18.1</span> 多參數 multiple parameters - LRT</h2>
<div id="似然-likelihood" class="section level3">
<h3><span class="header-section-number">18.1.1</span> 似然 likelihood</h3>
<p>如果一個觀察數據 <span class="math inline">\(\underline{x} = (x_1, \cdots, x_n)\)</span> 相互獨立，可以用含有 <span class="math inline">\(k\)</span> 個參數 <span class="math inline">\(\theta_1,\cdots,\theta_k\)</span> 的數學模型 <span class="math inline">\(f\)</span> 來描述，那麼它的似然公式爲：</p>
<p><span class="math display">\[
L(\theta_1,\cdots,\theta_k | \underline{x}) = f(\underline{x} | \theta_1,\cdots,\theta_k) = \prod^n_{i=1}f(x_i|\theta_1,\cdots,\theta_k)
\]</span></p>
<p>它的對數似然公式爲：</p>
<p><span class="math display">\[
\ell(\theta_1,\cdots,\theta_k|\underline{x}) = \sum^n_{i=1}\text{log}f(x_1|\theta_1,\cdots,\theta_k)
\]</span></p>
<p>每個參數的 <span class="math inline">\(\text{MLE}\)</span> 通過解下面的 <span class="math inline">\(k\)</span> 個連立方程組獲得：</p>
<p><span class="math display">\[
\left\{
\begin{array}{c}
\frac{\partial \ell}{\partial \theta_1} = \ell^\prime(\theta_1) = 0 \\
\frac{\partial \ell}{\partial \theta_2} = \ell^\prime(\theta_k) = 0 \\
\vdots \\
\frac{\partial \ell}{\partial \theta_k} = \ell^\prime(\theta_k) = 0 \\
\end{array}
\right.
\]</span></p>
<ul>
<li><p>這些連立方程有時被叫做 <strong>score equations</strong>；</p></li>
<li><p><span class="math inline">\(\text{MLE}\)</span> 的恆定性，不變性 invariance 在多個參數時同樣適用。</p></li>
<li><p>當參數只有一個 <span class="math inline">\(\theta\)</span> 時，其 <span class="math inline">\(\text{MLE}\)</span> 的方差是 <span class="math inline">\(S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}}\)</span></p></li>
<li><p>當參數有多個時，<span class="math inline">\(k\)</span> 個 <span class="math inline">\(\text{MLE}\)</span> 的方差是一個 <span class="math inline">\(k\times k\)</span> 的對稱矩陣，其中二次微分矩陣 <a href="#eq:hessian-matrix">(18.1)</a> 的昵稱是<strong>海森矩陣 Hessian matrix</strong>：</p></li>
</ul>
<p><span class="math display" id="eq:hessian-matrix">\[
\begin{equation}
\underline{\ell^{\prime\prime}(\theta)} = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)
\end{equation}
\tag{18.1}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \underline{\ell^{\prime\prime}(\theta)} |_{\color{red}{\theta=\hat\theta}} =  \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k} \\
\end{array}
\right)_{\color{red}{\theta=\hat\theta}}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \underline{\text{Var}(\hat\theta)} = - \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)^{\color{red}{-1}}_{\color{red}{\theta=\hat\theta}}
\]</span></p>
</div>
<div id="對數似然比檢驗" class="section level3">
<h3><span class="header-section-number">18.1.2</span> 對數似然比檢驗</h3>
<p>多個參數未知時的對數似然比檢驗可以被這樣拓展：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{H}_0: \underline{\theta} = \underline{\theta_0} \\
&amp; \Rightarrow -2llr(\underline{\theta_0}) = -2(\ell(\underline{\theta_0})- \ell(\hat{\underline{\theta}})) \stackrel{\cdot}{\sim} \chi^2_r \\
&amp; \text{Where } r \text{ is the number of parameters restricted under H}_0
\end{aligned}
\]</span></p>
</div>
</div>
<div id="多參數-wald-檢驗---wald-test" class="section level2">
<h2><span class="header-section-number">18.2</span> 多參數 Wald 檢驗 - Wald test</h2>
<p>單個參數時的 Wald 檢驗的檢驗統計量：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{H}_0: \theta=\theta_0 \Rightarrow W_\theta = (\frac{M-\theta_0}{S})^2 \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; \text{Where } M=\hat\theta, S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}} \\
&amp; \Rightarrow W=(\hat\theta-\theta_0)^2(-\ell^{\prime\prime}(\hat\theta)) \stackrel{\cdot}{\sim} \chi^2_1
\end{aligned}
\]</span></p>
<p>如果是兩個參數 <span class="math inline">\(\lambda, \psi\)</span> 的 Wald 檢驗： <span class="math inline">\(\text{H}_0: \lambda=\lambda_0, \psi=\psi_0 \text{ v.s. H}_1: \lambda \neq \lambda_0 \text{ or } \psi \neq \psi_0\)</span>。</p>
<ul>
<li>我們可以先一個一個考慮參數：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; W_\lambda  = (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; W_\psi     = (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_1 \\
&amp; \Rightarrow W_\lambda + W_\psi \stackrel{\cdot}{\sim} \chi^2_2 \\
&amp; \Rightarrow W = (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) + (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_2
\end{aligned}
\]</span></p>
<ul>
<li>也可以一開始就兩個參數一起考慮：</li>
</ul>
<p><span class="math display">\[
\underline{\ell^\prime} = \left(
\begin{array}{c}
\frac{\partial\ell}{\partial\lambda}\\
\frac{\partial\ell}{\partial\psi}
\end{array}
\right)
\Rightarrow \underline{\ell^{\prime\prime}} = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)
\]</span></p>
<p>然後單參數時 <span class="math inline">\(W\)</span> 的分子 <span class="math inline">\((\theta_0-\hat\theta)^2\)</span> 此時變爲：</p>
<p><span class="math display">\[
(\hat\lambda-\lambda_0)^2+(\hat\psi-\psi_0)^2 = (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right)
\]</span></p>
<p>所以兩個參數時的 Wald 檢驗統計量爲：</p>
<p><span class="math display">\[
\begin{aligned}
W = &amp; (\hat\lambda-\lambda_0, \hat\psi-\psi_0)(-\underline{\ell^{\prime\prime}}(\hat\lambda,\hat\psi))\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right) \\
= &amp; - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)_{\hat\lambda,\hat\psi}
\left(
\begin{array}{c}
\hat\lambda-\lambda_0 \\
\hat\psi-\psi_0
\end{array}
\right)\\
 &amp; \text{ Because } \lambda \text{ and } \psi \text{ are independent,} \\
 &amp; \text{ so their covariance } \frac{\partial^2\ell}{\partial\lambda\partial\psi} = \frac{\partial^2\ell}{\partial\psi\partial\lambda} = 0\\
 \Rightarrow  = &amp; - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
 \begin{array}{c}
 \ell^{\prime\prime}(\hat\lambda)  &amp; 0 \\
 0 &amp; \ell^{\prime\prime}(\hat\psi)
 \end{array}
 \right)
 \left(
 \begin{array}{c}
 \hat\lambda-\lambda_0 \\
 \hat\psi-\psi_0
 \end{array}
 \right)\\
 = &amp;  - (\hat\lambda-\lambda_0, \hat\psi-\psi_0)\left(
 \begin{array}{c}
 \ell^{\prime\prime}(\hat\lambda)(\hat\lambda-\lambda_0) \\
 \ell^{\prime\prime}(\hat\psi)(\hat\psi-\psi_0)
 \end{array}
 \right) \\
= &amp; (\hat\lambda-\lambda_0)^2(-\ell^{\prime\prime}(\hat\lambda)) + (\hat\psi-\psi_0)^2(-\ell^{\prime\prime}(\hat\psi)) \stackrel{\cdot}{\sim} \chi^2_2
\end{aligned}
\]</span></p>
<p>由此可見，兩個參數分開來考慮之後把統計量相加，和一開始就把兩個參數放在一起，利用矩陣計算後獲得的檢驗統計量完全相同。用矩陣的好處是可以把上面的推導過程直接擴展成 <span class="math inline">\(k\)</span> 個參數的形式，且標記簡便：</p>
<p><span class="math display">\[
W = -(\hat{\underline{\theta}} - \underline{\theta_0})^T\underline{\ell^{\prime\prime}(\hat\theta)}(\underline{\hat\theta} - \underline{\theta_0})  \stackrel{\cdot}{\sim} \chi^2_k
\]</span></p>
</div>
<div id="多參數-score-檢驗---score-test" class="section level2">
<h2><span class="header-section-number">18.3</span> 多參數 Score 檢驗 - Score test</h2>
<p>單個參數時的 Score 檢驗的檢驗統計量：</p>
<p><span class="math display">\[
 \text{H}_0: \theta=\theta_0 \text{ v.s. H}_1: \theta \neq \theta_0 \\
 \frac{U^2}{V} \stackrel{\cdot}{\sim} \chi^2_1 \\
 \text{Where } U=\ell^\prime(\theta_0), V=E[-\ell^{\prime\prime}(\theta_0)]
\]</span></p>
<p>類似 Wald 檢驗法的矩陣推導過程和標記法，<span class="math inline">\(k\)</span> 個參數的 Score 檢驗的統計量可以標記爲：</p>
<p><span class="math display">\[
\underline{U}^T\underline{V}^{-1}\underline{U} \stackrel{\cdot}{\sim} \chi^2_k \\
\text{Where } \underline{U} = \left.\frac{\partial\ell}{\partial\underline{\theta}} \right\vert_{\underline{\theta}=\underline{\theta_0}},
\underline{V} = E[-\underline{\ell^{\prime\prime}(\theta)}]_{\underline{\theta}=\underline{\theta_0}}
\]</span></p>
<p>所以如果是兩個參數 <span class="math inline">\(\lambda, \psi\)</span> 那麼檢驗 <span class="math inline">\(\text{H}_0:\lambda = \lambda_0, \psi = \psi_0 \text{ v.s. H}_1: \lambda \neq \lambda_0 \text{ or } \psi\neq\psi_0\)</span> 的 Score 檢驗統計量是：</p>
<p><span class="math display">\[
(\frac{\partial\ell}{\partial\lambda}, \frac{\partial\ell}{\partial\psi})_{\lambda_0, \psi_0}\left(
E\left[
-\left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\lambda^2} &amp; \frac{\partial^2\ell}{\partial\lambda\partial\psi} \\
\frac{\partial^2\ell}{\partial\psi\partial\lambda} &amp; \frac{\partial^2\ell}{\partial\psi^2}
\end{array}
\right)_{\lambda_0,\psi_0}
\right]
\right)^{-1}\left(
\begin{array}{c}
\frac{\partial\ell}{\partial\lambda}\\
\frac{\partial\ell}{\partial\psi}
\end{array}
\right)_{\lambda_0,\psi_0} \stackrel{\cdot}{\sim} \chi^2_2
\]</span></p>
</div>
<div id="condilikeli" class="section level2">
<h2><span class="header-section-number">18.4</span> 條件似然 conditional likelihood</h2>
<p>現實的例子中，參數可能有非常多，但是我們可能只關心其中幾個。下章介紹的子集似然函數 (profile likelihood) 是可以在多種情況下應用的好方法。本節介紹的方法是<strong>條件似然法</strong>。簡單原理是，把模型中不能提供我們感興趣的參數的有效信息的那些參數 (“nuisance” parameters) 當作是固定的 (fixed)。由此可以定義一個新的概率模型 – <strong>條件概率模型 conditional probability model</strong>。</p>
<p>我們用泊松模型來解釋如何建立這樣的模型。</p>
<p>兩個獨立的人羣追蹤樣本，在 <span class="math inline">\(p_0, p_1\)</span> 人年的隨訪中發生事件 A 的次數分別是 <span class="math inline">\(k_0, k_1\)</span>。假設我們只關心兩組的事件 A 發生率的比 <span class="math inline">\(\text{Rate ratio:} \theta=\frac{\lambda_1}{\lambda_0}\)</span>。</p>
<p>合併兩個人羣，發生事件 A 的總次數爲 <span class="math inline">\(k=k_0+k_1\)</span>。只知道 <span class="math inline">\(k\)</span> 並不能讓我們推算兩個人羣中各發生了多少次事件 A，也無法用它來計算發生率的比 <span class="math inline">\(\theta\)</span>，而這個 <span class="math inline">\(k\)</span> 就是條件概率模型中的條件。</p>
<p><span class="math display">\[
K_0 \sim Po(\mu_0); K_1 \sim Po(\mu_1) ; \text{ where } \mu_0 = \lambda_0 p_0 \mu_1 = \lambda_1 p_1\\
k=k_0 + k_1 \Rightarrow K_0+K_1 \sim Po(\mu_0 + \mu_1)
\]</span></p>
<p><span class="math display" id="eq:infer9-1">\[
\begin{aligned}
  &amp; \text{Prob}(k_0 \text{events in group 0} | k \text{ events in total}) \\
= &amp; \frac{\text{Prob}(k_0 \text{ events in group }0 \text{ and } k-k_0 \text{ events in  group } 1)}
 {\text{Prob}(k \text{ events in total})} \\
\end{aligned}
\tag{18.2}
\]</span></p>
<p>由於兩個樣本是來自獨立的人羣，所以公式 <a href="#eq:infer9-1">(18.2)</a> 的分母，和分子分別是</p>
<p><span class="math display">\[
\begin{aligned}
\text{Prob}(k &amp;\text{ events in total}) \\
 = &amp; \frac{(\lambda_0 p_0 + \lambda_1 p_1)^k e^{-(\lambda_0 p_0 + \lambda_1 p_1)}}{k!} \\
\text{Prob}(k_0 &amp;\text{ events in group }0 \text{ and } k-k_0 \text{ events in  group } 1) \\
 = &amp; \frac{(\lambda_0 p_0)^{k_0}e^{-\lambda_0 p_0}}{k_0!}\times\frac{(\lambda_1 p_1)^{k-k_0}e^{-\lambda_1 p_1}}{(k-k_0)!}
\end{aligned}
\]</span></p>
<p>所以公式 <a href="#eq:infer9-1">(18.2)</a> 可以整理成：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\frac{(\lambda_0 p_0)^{k_0}e^{-\lambda_0 p_0}}{k_0!}\times\frac{(\lambda_1 p_1)^{k-k_0}e^{-\lambda_1 p_1}}{(k-k_0)!}}
{\frac{(\lambda_0 p_0 + \lambda_1 p_1)^k e^{-(\lambda_0 p_0 + \lambda_1 p_1)}}{k!}} \\
= &amp;  \frac{e^{-(\lambda_0 p_0 + \lambda_1 p_1)}(\lambda_0 p_0)^{k_0}(\lambda_1 p_1)^{k-k_0}\cdot k!}{e^{-(\lambda_0 p_0 + \lambda_1 p_1)}(\lambda_0p_0+\lambda_1p_1)^k\cdot k_0!\cdot (k-k_0)!}\\
= &amp; (\frac{\lambda_0 p_0}{\lambda_0 p_0+\lambda_1 p_1})^{k_0}(\frac{\lambda_1 p_1}{\lambda_0 p_0+\lambda_1 p_1})^{k-k_0}\cdot\frac{k!}{k_0!(k-k_0)!} \\
= &amp; (\pi)^{k_0}(1-\pi)^{k-k_0}\cdot\frac{k!}{k_0!(k-k_0)!} \\
\text{Where } &amp; \pi = \frac{\lambda_0 p_0}{\lambda_0 p_0 + \lambda_1 p_1} = \frac{p_0}{p_0+(\lambda_1/\lambda_0)p_1} = \frac{p_0}{p_0+\theta p_1}\\
\Rightarrow &amp;\text{ Given } K_0+K_1=K, K_0 \sim Bin(k, \pi=\frac{p_0}{p_0+\theta p_1})
\end{aligned}
\]</span></p>
<p>我們就把兩個泊松分佈的模型，變形成爲了一個條件二項分佈，而且只有一個未知參數 <span class="math inline">\(\theta\)</span>。之後就可以用二項分佈的對數似然方程進行下一步的假設檢驗的構建：</p>
<p><span class="math display" id="eq:inference9-2">\[
\begin{aligned}
               L(\pi) &amp; = (\pi)^{k_0}(1-\pi)^{k-k_0}  \\
\Rightarrow \ell(\pi) &amp; = k_0 \text{log}\pi + (k-k_0)\text{log} (1-\pi) \\
\text{Because }  \pi  &amp; = \frac{p_0}{p_0+\theta p_1} \\
        \ell_c(\theta)  &amp; = k_0 \text{log}(\frac{\pi}{1-\pi}) + k\text{log}(1-\pi) \\
                      &amp; = k_0 \text{log}(\frac{p_0}{\theta p_1}) + k\text{log}(\frac{\theta p_1}{p_0 + \theta p_1}) \\
\text{Ignoring} &amp; \text{ terms not involving } \theta \\
        \ell_c(\theta)&amp; = k_1 \text{log}\theta - k\text{log}(p_0 + \theta p_1)
\end{aligned}
\tag{18.3}
\]</span></p>
<p>至此，推導發生率比 <span class="math inline">\(\theta = \frac{\lambda_1}{\lambda_0}\)</span> 的條件對數似然就完成了。Elegant and Bravo!</p>
<p>關於條件對數似然：</p>
<ol style="list-style-type: decimal">
<li>推導出的條件對數似然是一個<strong>真實</strong>的以觀察數據爲條件的對數似然，可以用於假設檢驗；</li>
<li>條件似然過程依賴於我們能否找到這樣一個“條件似然”，使得模型的對數似然<strong>只取決於我們關心的參數</strong>，我們幸運地找到了發生率比的對數似然方程，<strong>但是至今沒有人找到發生率差 <span class="math inline">\(\lambda_1-\lambda_0\)</span> 的條件對數似然</strong>；</li>
<li>與此相對地是，下一章介紹的子集似然函數 (profile likelihood)，可以用於幾乎所有的多參數模型的假設檢驗之構建；</li>
<li>但是，條件對數似然相當之重要，特別是它作爲 Cox proportional hazard model 模型的基本模型構架在生存分析 (survival analysis) 中的應用，以及在配對病例對照分析 (matched case-control study) 中用於條件邏輯迴歸 (conditional logistic regression) 的理論基礎 (將會在第二學期的碩士課程中介紹，敬請期待)。</li>
</ol>
</div>
<div id="練習" class="section level2">
<h2><span class="header-section-number">18.5</span> 練習</h2>
<p>某項研究追蹤隨訪 50-69 歲男性的心臟病發病率。研究對象根據心臟病發病史的有無分成兩組。有心臟病史的對象被隨訪 512 人・年，觀察到 25 例新的心臟病發作病例；無心臟病史的對象被隨訪 4862 人・年，觀察到 52 例新的心臟病發作病例。</p>
<ol style="list-style-type: decimal">
<li>如果需要檢驗的零假設是 <span class="math inline">\(\text{H}_0:\)</span> 有心臟病史的男性<strong>發病率的對數</strong>等於 <span class="math inline">\(-3\)</span>，無心臟病史的男性發病率的對數等於 <span class="math inline">\(-4.5\)</span>。請推導該實驗的<strong>聯合</strong>對數似然比檢驗，Wald 檢驗兩種檢驗法的檢驗統計量，並進行假設檢驗。</li>
</ol>
<p><strong>解</strong></p>
<ul>
<li>模型：</li>
</ul>
<p>令隨機變量 <span class="math inline">\(K_i\)</span> 標記新發生的心臟病病例數，其中當 <span class="math inline">\(i=0\)</span> 時代表<strong>無心臟病史組</strong>；當 <span class="math inline">\(i=1\)</span> 時代表<strong>有心臟病史組</strong>。所以可以用下面的泊松模型來標記兩組的新發生心臟病病例數：</p>
<p><span class="math display">\[
K_i \sim \text{Poisson}(\mu_i); \mu_i = \lambda_i p_i\\
\text{Where } \lambda_i \text{ is the rate parameter in group } i, \\
p_i \text{ is the person-years at risk in group }i \\
\]</span></p>
<p>有無心臟病史組之間由於是相互獨立的，故兩組的對數似然相加之後就可得到合併後的對數似然。</p>
<ul>
<li>數據：</li>
</ul>
<p><span class="math display">\[
k_0 = 52, p_0 = 4862; k_1 = 25, p_1 = 512
\]</span></p>
<p>泊松模型的對數似然方程爲 (Section <a href="#likelihood-poi">12.6</a>)：</p>
<p><span class="math display">\[
\ell(\lambda | \text{data}) = -\lambda p + k \text{log} \lambda
\]</span></p>
<p>令 <span class="math inline">\(\psi = \text{log} \lambda\)</span> 有：</p>
<p><span class="math display">\[
\ell(\psi) = k \psi - e^\psi p
\]</span></p>
<p>令 <span class="math inline">\(\psi_0 = \text{log}\lambda_0; \psi_1 = \text{log}\lambda_1\)</span>，那麼本題中的假設檢驗可以寫成是：</p>
<p><span class="math display">\[\text{H}_0: {\psi_0}_0 = -4.5, {\psi_1}_0 = -3 \text{ v.s. H}_1: {\psi_0}_0 \neq -4.5 \text{ or } {\psi_1}_0 \neq -3\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>對數似然比檢驗需要尋找的檢驗統計量是 <span class="math inline">\(-2llr({\psi_0}_0,{\psi_1}_0)\)</span>，其中：</li>
</ol>
<p><span class="math display">\[
llr({\psi_0}_0,{\psi_1}_0) = \ell({\psi_0}_0,{\psi_1}_0) - \ell(\hat\psi_0,\hat\psi_1)
\]</span></p>
<p>所以我們分別來計算 <span class="math inline">\(\ell({\psi_0}_0,{\psi_1}_0)\)</span> 和 <span class="math inline">\(\ell(\hat\psi_0,\hat\psi_1)\)</span>：</p>
<p><span class="math display" id="eq:infer9-prac-1">\[
\begin{equation}
\ell(\psi_0, \psi_1) = k_0 \psi_0 - e^{\psi_0} p_0 + k_1 \psi_1 - e^{\psi_1} p_1
\end{equation}
\tag{18.4}
\]</span></p>
<p><span class="math display">\[
\Rightarrow \frac{\partial\ell}{\partial\psi_0} = k_0 - e^{\psi_0}p_0 \\
\text{and} \\
\frac{\partial\ell}{\partial\psi_1} = k_1 - e^{\psi_1}p_1
\]</span></p>
<p>然後我們把這兩個偏微分式子等於零時的解作爲 <span class="math inline">\(\psi_0, \psi_1\)</span> 的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial\ell}{\partial{\psi}_0} &amp; = 0 \\
\Rightarrow          e^{{\hat\psi}_0} &amp; = \frac{k_0}{p_0} \\
\Rightarrow             {\hat\psi}_0  &amp; = \text{log}(\frac{k_0}{p_0}) \\
\text{And similarly }   {\hat\psi}_1  &amp; = \text{log}(\frac{k_1}{p_1})
\end{aligned}
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[
\begin{aligned}
\ell({\psi_0}_0,{\psi_1}_0) &amp; = 52\times(-4.5) - e^{-4.5}\times4862+25\times(-3)-e^{-3}\times512 \\
                            &amp; = -388.5029 \\
\ell(\hat\psi_0,\hat\psi_1) &amp; = 52\times\text{log}\frac{52}{4862} - e^{\text{log}\frac{52}{4862}}\times4862 + 25\times\text{log}\frac{25}{512} - e^{\text{log}\frac{25}{512}}\times512 \\
                            &amp; = 52\times\text{log}\frac{52}{4862} - 52 + 25\times\text{log}\frac{25}{512} - 25 \\
                            &amp; = -388.4602 \\
\Rightarrow llr({\psi_0}_0,{\psi_1}_0)  &amp; =   -388.5029 - (-388.4602) = - 0.0427 \\
\Rightarrow -2llr({\psi_0}_0,{\psi_1}_0)  &amp; = 0.0854
\end{aligned}
\]</span></p>
<p>因爲在零假設條件下 <span class="math inline">\(-2llr \stackrel{\cdot}{\sim} \chi^2_2\)</span>，本次檢驗的拒絕域是 <span class="math inline">\(\mathfrak{R} &gt; \chi^2_{2,0.95} = 5.99\)</span>，所以，檢驗的結果 <span class="math inline">\(-2llr = 0.0854 &lt; 5.99\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Wald 檢驗時我們需要的檢驗統計量爲：</li>
</ol>
<p><span class="math display">\[
W = (\hat\psi_0-{\psi_0}_0, \hat\psi_1-{\psi_1}_0)(-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\left(
\begin{array}{c}
\hat\psi_0-{\psi_0}_0 \\
\hat\psi_1-{\psi_1}_0
\end{array}
\right)
\]</span></p>
<p>先處理中間那個看起來比較棘手的 <span class="math inline">\((-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\underline{\ell^\prime}(\psi_0, \psi_1) &amp; = \left(
\begin{array}{c}
k_0 - e^{\psi_0}p_0 \\
k_1 - e^{\psi_1}p_1
\end{array}
\right) \\
\Rightarrow \underline{\ell^{\prime\prime}}(\psi_0,\psi_1) &amp; = \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\psi^2_0} &amp; \frac{\partial^2\ell}{\partial\psi_1\partial\psi_0} \\
\frac{\partial^2\ell}{\partial\psi_0\partial\psi_1} &amp; \frac{\partial^2\ell}{\partial\psi^2_1}
\end{array}
\right) = \left(
\begin{array}{c}
-e^{\psi_0}p_0  &amp; 0\\
0  &amp; -e^{\psi_1}p_1
\end{array}
\right) \\
\Rightarrow -\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1) &amp; = \left(
\begin{array}{c}
-e^{\hat\psi_0}p_0  &amp; 0\\
0  &amp; -e^{\hat\psi_1}p_1
\end{array}
\right) \\
 &amp; = \left(
\begin{array}{c}
-e^{\text{log}(\frac{52}{4862})}\times4862  &amp; 0\\
0  &amp; -e^{\text{log}(\frac{25}{512})}\times512
\end{array}
\right) \\
&amp; = \left(
\begin{array}{c}
52  &amp; 0\\
0  &amp; 25
\end{array}
\right)
\end{aligned}
\]</span></p>
<p>又有 <span class="math inline">\(\hat\psi_1-{\psi_1}_0 = \text{log}(\frac{25}{512})-(-3) = -0.0194\)</span></p>
<p>和 <span class="math inline">\(\hat\psi_0-{\psi_0}_0 = \text{log}(\frac{52}{4862})-(-4.5) = -0.0379\)</span></p>
<p>所以</p>
<p><span class="math display">\[
\begin{aligned}
W &amp; = (\hat\psi_0-{\psi_0}_0, \hat\psi_1-{\psi_1}_0)(-\underline{\ell^{\prime\prime}}(\hat\psi_0,\hat\psi_1))\left(
\begin{array}{c}
\hat\psi_0-{\psi_0}_0 \\
\hat\psi_1-{\psi_1}_0
\end{array}
\right) \\
  &amp; = (-0.0379, -0.0194)\left(
  \begin{array}{c}
  52  &amp; 0\\
  0  &amp; 25
  \end{array}
  \right)\left(
  \begin{array}{c}
  -0.0379 \\
  -0.0194
  \end{array}
  \right) = 0.08439208
\end{aligned}
\]</span></p>
<p>Wald 檢驗的檢驗統計量也一樣服從 <span class="math inline">\(\chi^2_2\)</span>，所以拒絕域同對數似然比檢驗法的<span class="math inline">\(\mathfrak{R} &gt; \chi^2_{2,0.95} = 5.99\)</span>，所以，檢驗的結果 <span class="math inline">\(W = 0.08439208 &lt; 5.99\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
<ol start="2" style="list-style-type: decimal">
<li>利用本節推導出的發生率比的<strong>條件對數似然方程</strong>，請嘗試進行對數似然比檢驗：心臟病發作率在無病史男性中和有病史男性中的比例爲 <span class="math inline">\(0.2\)</span>。</li>
</ol>
<p>本章推導的發生率的比值的條件對數似然方程爲：</p>
<p><span class="math display">\[
\ell_c(\theta)  = k_1 \text{log}\theta - k\text{log}(p_0 + \theta p_1) \\
\text{Where } \theta = \frac{\lambda_1}{\lambda_0}
\]</span></p>
<p>題目要求比較的是 <span class="math inline">\(\frac{\lambda_0}{\lambda_1} = 0.2\)</span>，用本題中的 <span class="math inline">\(\lambda_0\)</span> 取代條件對數似然方程中的 <span class="math inline">\(\lambda_1\)</span> 則有：</p>
<p><span class="math display">\[
\ell_c{\theta} = k_0\text{log}\theta - k\text{log}(p_1 + \theta p_0) \\
\text{H}_0: \theta_0 = 0.2 \text{ v.s. H}_1: \theta_0 \neq 0.2
\]</span></p>
<p>對於條件對數似然比檢驗，需要的檢驗統計量是 <span class="math inline">\(-2llr_c(\theta_0)\)</span> 其中：</p>
<p><span class="math display">\[
llr_c(\theta_0) = \ell_c(\theta_0) - \ell_c(\hat\theta)
\]</span></p>
<p>先計算 <span class="math inline">\(\ell_c(\hat\theta)\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
      \text{Let }\ell_c^\prime &amp; = \frac{k_0}{\theta} - \frac{kp_0}{p_1+\theta p_0} = 0 \\
\Rightarrow \frac{k_0}{\theta} &amp; = \frac{kp_0}{p_1+\theta p_0} \\
\Rightarrow \hat\theta         &amp; = \frac{k_0p_1}{p_0k_1} = \frac{k_0/p_0}{k_1/p_1} \\
\Rightarrow \hat\theta         &amp; = \frac{52\times512}{4862\times25} = 0.219037 \\
\Rightarrow \ell_c(\theta_0)   &amp; = k_0\text{log}0.2 -  k\text{log}(p_1 + \theta p_0) \\
                               &amp; = 52\times\text{log}0.2 - 77\times\text{log}(512 + 0.2\times4862) \\
                               &amp; = -646.003 \\
          \ell_c{\hat\theta}   &amp; = 52\times\text{log}0.219037 - 77\times\text{log}(512 + 0.219037\times4862)\\
                               &amp; = -645.933 \\
\Rightarrow -2llr(\theta_0)    &amp; = -2\times(-646.003-(-645.933)) = 0.14
\end{aligned}
\]</span></p>
<p>因爲在零假設條件下 <span class="math inline">\(-2llr \stackrel{\cdot}{\sim} \chi^2_1\)</span>，本次檢驗的拒絕域是 <span class="math inline">\(\mathfrak{R} &gt; \chi^2_{1,0.95} = 3.84\)</span>，所以，檢驗的結果 <span class="math inline">\(-2llr = 0.14 &lt; 3.84\)</span>，在顯著性水平爲 <span class="math inline">\(5\%\)</span> 時，沒有證據反對零假設。There is no evidence at the <span class="math inline">\(5\%\)</span> level against the null hypothesis.</p>
</div>
</div>
<div id="profile-log-likelihood" class="section level1">
<h1><span class="header-section-number">第 19 章</span> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</h1>
<p>本章介紹的子集似然法是處理多個參數模型的主要方法。前章介紹的<strong>條件似然法</strong>也是相當出色的方法，但是許多情況下我們無法找到合適的“條件”來輔助我們擺脫那些模型中不需要的，<strong>障礙 (或者叫噪音) 參數 nuisance parameters</strong>。</p>
<p>我們還是沿用上一節的例子。</p>
<p>兩個獨立的人羣追蹤樣本，在 <span class="math inline">\(p_0, p_1\)</span> 人年的隨訪中發生事件 A 的次數分別是 <span class="math inline">\(k_0, k_1\)</span>。我們只關心兩組的事件 A 發生率的比 <span class="math inline">\(\text{Rate ratio:} \theta=\frac{\lambda_1}{\lambda_0}\)</span>。兩個人羣的聯合對數似然函數如下：</p>
<p><span class="math display">\[
\ell(\lambda_0, \lambda_1) = k_0\text{log}\lambda_0 - \lambda_0p0 + k_1\text{log}\lambda_1 - \lambda_1p1
\]</span></p>
<ul>
<li>Step 1. 先用 <span class="math inline">\(\lambda_1 = \lambda_0\theta\)</span> 取代掉上面式子中的 <span class="math inline">\(\lambda_1\)</span>。</li>
</ul>
<p><span class="math display" id="eq:infer10-1">\[
\begin{aligned}
\Rightarrow \ell(\lambda_0, \theta) &amp; = k\text{log}\lambda_0 + k_1\text{log}\theta - \lambda_0(P_0 + \theta p_1) \\
\text{Where } k &amp; = k_0 + k_1
\end{aligned}
\tag{19.1}
\]</span></p>
<p>這一步先是消滅了一個障礙參數 <span class="math inline">\(\lambda_1\)</span>，獲得了一個我們關心的參數 <span class="math inline">\(\theta\)</span>，和 <span class="math inline">\(\lambda_0\)</span> 的對數似然方程。接下來，我們尋找用 <span class="math inline">\(\theta\)</span> 表示 <span class="math inline">\(\lambda_0\)</span> (用 <span class="math inline">\(\hat\lambda_0(\theta)\)</span> 標記) 的似然方程，使得只包含一個參數 <span class="math inline">\(\theta\)</span> 的對數似然方程可以在每個 <span class="math inline">\(\lambda_0\)</span> 時取得極大值。此時我們定義 <span class="math inline">\(\theta\)</span> 的子集對數似然方程 profile log-likelihood是：</p>
<p><span class="math display">\[
\ell_p(\theta) = \ell(\hat\lambda_0(\theta),\theta)
\]</span></p>
<ul>
<li>Step 2. 爲了求 <span class="math inline">\(\hat\lambda_0(\theta)\)</span>，先視 <span class="math inline">\(\theta\)</span> 爲不變的，對上式 <a href="#eq:infer10-1">(19.1)</a> 求 <span class="math inline">\(\lambda_0\)</span> 的微分：</li>
</ul>
<p><span class="math display">\[
\frac{\partial\ell(\lambda_0,\theta)}{\partial\lambda_0}=\frac{k}{\lambda_0} - (p_0+\theta p_1)
\]</span></p>
<p>把該微分方程等於0，推導出 <span class="math inline">\(\hat\lambda_0=\frac{k}{p_0+\theta p_1}\)</span> 就是 <span class="math inline">\(\theta\)</span> 在取值範圍內所有能使對數似然方程 <a href="#eq:infer10-1">(19.1)</a> 取極大值的對應 <span class="math inline">\(\lambda_0\)</span>。</p>
<ul>
<li>Step 3. 將這個 <span class="math inline">\(\theta\)</span> 表示的 <span class="math inline">\(\lambda_0\text{ MLE}\)</span> 代替 <span class="math inline">\(\lambda_0\)</span> 代入對數似然方程 <a href="#eq:infer10-1">(19.1)</a> 中去：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\ell_p(\theta) &amp;= k\text{log}\frac{k}{p_0 + \theta p_1} + k_1 \text{log}\theta - k \\
\text{Ignoring} &amp;\text{ items not involving } \theta\\
\Rightarrow &amp;= k_1\text{log}\theta - k\text{log}(p_0+\theta p_1)
\end{aligned}
\]</span></p>
<p>這個用子集似然法推導的關於參數 <span class="math inline">\(\theta\)</span> 的似然方程和前一章用條件似然法 (Section <a href="#condilikeli">18.4</a>) 推導的結果是完全一致的 <a href="#eq:inference9-2">(18.3)</a>。</p>
<div id="子集似然法推導的過程總結" class="section level2">
<h2><span class="header-section-number">19.1</span> 子集似然法推導的過程總結</h2>
<ol style="list-style-type: decimal">
<li>多個參數中區分出我們感興趣的參數 <span class="math inline">\(\psi\)</span> 和其餘的障礙(噪音)參數 <span class="math inline">\(\lambda\)</span>；</li>
<li>爲了從對數似然方程中消除噪音參數，把它們一一通過微分求極值的辦法表達成用 <span class="math inline">\(\psi\)</span> 標記的表達式，用這些包含了 <span class="math inline">\(\psi\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 代替所有的噪音參數；</li>
<li>整理最終獲得的只有感興趣的參數的對數似然方程，記得把不包含參數的部分忽略掉。</li>
</ol>
<div id="子集對數似然方程的分佈" class="section level3">
<h3><span class="header-section-number">19.1.1</span> 子集對數似然方程的分佈</h3>
<p><span class="math display">\[
-2pllr(\psi) = -2\{ \ell_p(\psi) - \ell(\hat\psi)\} \stackrel{\cdot}{\sim} \chi^2_r
\]</span></p>
<p>其中自由度 <span class="math inline">\(r\)</span> 是想要檢驗的零假設中受限制的參數的個數。Degree of freedom <span class="math inline">\(r\)</span> is the number of parameters restricted under the null hypothesis. 所以，如果 <span class="math inline">\(\psi\)</span> 是一個維度 (dimension) 爲 <span class="math inline">\(p\)</span> 的向量，如果零假設是 <span class="math inline">\(\text{H}_0: \psi = \psi_0\)</span>，那麼自由度就是 <span class="math inline">\(p\)</span>。</p>
</div>
<div id="假設檢驗過程舉例" class="section level3">
<h3><span class="header-section-number">19.1.2</span> 假設檢驗過程舉例</h3>
<p>兩個獨立的二項分佈樣本：<span class="math inline">\(K_0 \sim \text{Bin}(n_0, \pi_0), K_1 \sim \text{Bin}(n_1, \pi_1)\)</span>。它們的聯合對數似然爲：</p>
<p><span class="math display">\[
\ell(\pi_0, \pi_1) = \ell(\pi_0) + \ell(\pi_1)
\]</span></p>
<p>如果要檢驗的零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \pi_0 = \pi_1 \text{ v.s. H}_1: \pi_0 \neq \pi_1\)</span>。</p>
<p>如果令 <span class="math inline">\(\theta=\frac{\pi_1}{\pi_0}\)</span>，那麼要檢驗的零假設和替代假設就變成了：</p>
<p><span class="math display">\[
\text{H}_0: \theta = 1 \text{ v.s. H}_1: \theta \neq 1 \\
\Rightarrow -2 pllr \stackrel{\cdot}{\sim} \chi^2_1
\]</span></p>
<p>而且在零假設條件下，<span class="math inline">\(\text{H}_0: K_0+K_1 \sim \text{Bin}(n_0+n_1, \pi)\)</span>，那麼自己對數似然比檢驗的統計量是：</p>
<p><span class="math display">\[
\begin{aligned}
-2 pllr &amp; = -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi_0,\theta\pi_0)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\theta\pi_0)}] \} \\
\Rightarrow -2 pllr &amp; =  -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi,\theta\pi)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\pi_1)}] \} \\
\Rightarrow -2 pllr &amp; = -2\{ \ell{(\hat\pi)} - \ell{(\hat\pi_0, \hat\pi_1)} \}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="子集對數似然比的近似" class="section level2">
<h2><span class="header-section-number">19.2</span> 子集對數似然比的近似</h2>
<p>假如有兩個獨立樣本數據，參數分別只有一個 <span class="math inline">\(\beta_0, \beta_1\)</span>，我們關心他們二者之間的差是否有意義 <span class="math inline">\(\gamma = \beta_1-\beta_0\)</span>。如果 <span class="math inline">\(\beta_0\)</span> 的對數似然比檢驗統計量的相應的 Wald 檢驗統計量 (二次方程近似法 Section <a href="#Wald">16.4</a>) 可以用 <span class="math inline">\(\hat\beta_0, S_0\)</span> 定義，其中 <span class="math inline">\(\beta_0\)</span> 是 <span class="math inline">\(\text{MLE}\)</span>，<span class="math inline">\(S_0\)</span> 是標準誤差。類似的，<span class="math inline">\(\beta_1\)</span> 的 Wald 檢驗統計量可以用 <span class="math inline">\(\hat\beta_1, S_1\)</span> 定義。那麼，我們關心的參數，<span class="math inline">\(\gamma = \beta_1 - \beta_0\)</span> 的 Wald 檢驗統計量可以用 <span class="math inline">\(\hat\gamma = \hat\beta_1 - \hat\beta_1, S=\sqrt{S^2_1 + S^2_0}\)</span> 定義：</p>
<p><span class="math display">\[
\begin{aligned}
pllr(\gamma) &amp; = -\frac{1}{2}(\frac{\gamma-\hat\gamma}{\sqrt{S^2_1+S^2_0}})^2 \\
&amp; = -\frac{1}{2}(\frac{(\beta_1-\beta_0)-(\hat\beta_1-\hat\beta_0)}{\sqrt{S^2_1+S^2_0}})^2
\end{aligned}
\]</span></p>
<div id="子集對數似然比近似的一般化" class="section level3">
<h3><span class="header-section-number">19.2.1</span> 子集對數似然比近似的一般化</h3>
<p>如果我們關心的參數，和模型參數的關係可以用下面的表達式來表示：</p>
<p><span class="math display">\[
\gamma = W_0\beta_0 + W_1\beta_1 + \cdots \\
\text{ Where } W_i \text{ are arbitrary cosntants}
\]</span></p>
<p>如果，模型中的每個參數 <span class="math inline">\(\beta_0, \beta_1, \cdots\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\beta_0, \hat\beta_1, \cdots\)</span>，標準誤是 <span class="math inline">\(S=\sqrt{(W_0S_0)^2+(W_1S_2)^2+\cdots}\)</span></p>
</div>
<div id="事件發生率之比的-wald-檢驗統計量" class="section level3">
<h3><span class="header-section-number">19.2.2</span> 事件發生率之比的 Wald 檢驗統計量</h3>
<p>事件發生率 (Possion rate ratio) <span class="math inline">\(\theta = \frac{\lambda_1}{\lambda_0}\)</span></p>
<p>令 <span class="math inline">\(\beta_1 = \text{log}\lambda_1, \beta_0 = \text{log}\lambda_0, \gamma = \text{log}\theta\)</span>。</p>
<p>所以有 <span class="math inline">\(\gamma=\beta_1-\beta_0\)</span>。</p>
<p>由於</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta_0 &amp; = \text{log}(\frac{k_0}{p_0}), \\
\hat\beta_1 &amp; = \text{log}(\frac{k_1}{p_1}) \\
\end{aligned}
\]</span></p>
<p>因而</p>
<p><span class="math display">\[
\begin{aligned}
\hat\gamma &amp; = \text{log}\frac{k_1}{p_1} - \text{log}\frac{k_0}{p_0} \\
           &amp; = \text{log}\frac{k_1/p_1}{k_0/p_0}
\end{aligned}
\]</span></p>
<p>又由於 <span class="math inline">\(S_0 = \frac{1}{\sqrt{k_0}}, S_1 = \frac{1}{\sqrt{k_1}}\)</span> (Section <a href="#Possion-log-transform">14.2.1</a>)。</p>
<p>所以 <span class="math inline">\(S=\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}\)</span>。</p>
<p>綜上，事件發生率之比的 Wald 檢驗統計量爲</p>
<p><span class="math display">\[
\begin{aligned}
pllr(\gamma) &amp; = -\frac{1}{2}(\frac{\gamma - \hat\gamma}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2 \\
             &amp; = -\frac{1}{2}(\frac{\text{log}\theta - \text{log}\frac{k_1/p_1}{k_0/p_0}}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2
\end{aligned}
\]</span></p>
</div>
</div>
<div id="練習-practical" class="section level2">
<h2><span class="header-section-number">19.3</span> 練習 Practical</h2>
<p><span class="math inline">\(n\)</span> 名肺癌 I 期患者的倖存時間 <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span> 被認爲服從指數分佈 (參數 <span class="math inline">\(\lambda_x\)</span>)，概率方程爲 <span class="math inline">\(\lambda_x e^{-x\lambda_x},\text{ where } x &gt; 0\)</span>。</p>
<ol style="list-style-type: decimal">
<li>證明 <span class="math inline">\(\lambda_x\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\lambda_x = \frac{1}{\bar{x}}\)</span>, 對數似然方程是 <span class="math display">\[\ell(\lambda_x | \underline{x}) = n\text{log}\lambda_x - \lambda_x n \bar{x}\]</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
f(\underline{x}|\lambda_x) &amp; = \lambda_x\cdot e^{-x\lambda_x} \\
F(\underline{x}|\lambda_x)  &amp; = \prod_{i=1}^n\lambda_{x}\cdot e^{-x_i\lambda_{x}} \\
\Rightarrow L(\lambda_x | \underline{x}) &amp; = \prod_{i=1}^n\lambda_xe^{-x_i\lambda_{x}} \\
\Rightarrow \ell(\lambda_x|\underline{x}) &amp; = \sum_{i=1}^n(\text{log}\lambda_x + \text{log}e^{-x_i\lambda_{x}}) \\
                                        &amp; = n\text{log}\lambda_x  + \sum_{i=1}^n(-x_i\lambda_{x}) \\
                                        &amp; = n\text{log}\lambda_x - n\bar{x}\lambda_x \\
\Rightarrow \ell^\prime(\lambda_x) &amp; = \frac{n}{\lambda_x} - n\bar{x}\lambda_x \\
\text{Let } \ell^\prime(\lambda_x) &amp; = 0 \Rightarrow \text{ MLE of } \lambda_x \text{ is } \hat\lambda_x = \frac{1}{\bar{x}} \\
\because \ell^{\prime\prime} = -\frac{n}{\lambda^2_x} &amp; &lt; 0 \therefore \frac{1}{\bar{x}} \text{ is the MLE}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>另一組獨立數據是樣本量爲 <span class="math inline">\(n\)</span> ，但是肺癌診斷爲 II 期的患者的倖存時間 <span class="math inline">\(Y_1, \cdots, Y_n\)</span>。這組數據也被認爲服從參數爲 <span class="math inline">\(\lambda_y\)</span> 的指數分佈。用 <span class="math inline">\(\theta=\frac{\lambda_x}{\lambda_y}\)</span> 標記兩組患者倖存時間之比，用 <span class="math inline">\(r=\frac{\bar{x}}{\bar{y}}\)</span> 標記樣本的倖存時間均值之比。證明使兩個樣本數據的聯合對數似然取極大值的 <span class="math inline">\(\hat\lambda_y(\theta) = \frac{2}{\bar{y}(\theta r+1)}\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\ell(\lambda_x|\underline{x}) &amp; = n\text{log}\lambda_x - n \bar{x} \lambda_x \\
\ell(\lambda_y|\underline{y}) &amp; = n\text{log}\lambda_y - n \bar{y} \lambda_y \\
\Rightarrow \text{ Joint log-likelihood: } &amp; \ell(\lambda_x, \lambda_y | \underline{x}, \underline{y}) = n\text{log}\lambda_x - n\bar{x}\lambda_x \\
&amp; \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;+  n\text{log} \lambda_y - n\bar{y}\lambda_y \\
\text{Subsitute } \lambda_x &amp; =\theta\cdot\lambda_y \\
\Rightarrow \ell(\theta, \lambda_y) &amp;= n\text{log}\theta\lambda_y - n\bar{x}\theta\lambda_y + n\text{log} \lambda_y - n\bar{y}\lambda_y \\
\ell(\theta, \lambda_y) &amp; = n(\text{log}\theta + \text{log}\lambda_y - \bar{x}\theta\lambda_y + \text{log}\lambda_y - \bar{y}\lambda_y) \\
                        &amp; = n[\text{log}\theta + 2\text{log}\lambda_y - \lambda_y(\bar{x}\theta + \bar{y})] \\
\Rightarrow \frac{\partial\ell(\theta, \lambda_y)}{\partial \lambda_y} &amp; = n[\frac{2}{\lambda_y} - (\bar{x}\theta + \bar{y})] \\
\text{Let } \frac{\partial\ell(\theta, \lambda_y)}{\partial \lambda_y} &amp; = 0 \text{ and because } r = \frac{\bar{x}}{\bar{y}} \\
\hat\lambda_y(\theta) &amp; = \frac{2}{\bar{x}\theta + \bar{y}} = \frac{2}{\bar{y}(r\cdot\theta +1)}
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>證明參數 <span class="math inline">\(\theta\)</span> 的子集對數似然是 <span class="math inline">\(\ell_p(\theta|r) = n\text{log}\theta - 2n \text{log}(\theta\cdot r + 1)\)</span>，且 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\theta = \frac{1}{r}\)</span></li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\ell_p (\theta) &amp; = n[\text{log}\theta + 2\cdot\text{log}\frac{2}{\bar{y}(r\cdot\theta +1)} - \text{log}\frac{2}{\bar{y}(r\cdot\theta +1)}(\bar{x}\theta+\bar{y})] \\
                &amp; = n\{\text{log}\theta + 2\cdot\text{log}2 - 2\cdot\text{log}[\bar{y}(r\theta+1)] -2 \} \\
\text{Ignoring } &amp; \text{ items not involving } \theta\\
                &amp; = n[\text{log}\theta - 2\text{log}(r\theta+1)] \\
\Rightarrow \ell_p^{\prime}(\theta) &amp; = n(\frac{1}{\theta} - \frac{2r}{r\theta+1}) \\
\text{Let } \ell_p^{\prime}(\theta) &amp; = 0 \Rightarrow  n(\frac{1}{\theta} - \frac{2r}{r\theta+1}) = 0 , \hat\theta=\frac{1}{r}\\
\because  \ell_p^{\prime\prime}(\theta) &amp; = -\frac{1}{\theta^2} - \frac{2r^2}{(r\theta^2+1)^2} &lt; 0 \\
\therefore \hat\theta &amp; =\frac{1}{r} \text{ is the MLE}
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>根據 <span class="math inline">\(\text{MLE}\)</span> 的恆定性，可以直接推導出 <span class="math inline">\(\theta\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 嗎?</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\because \hat\lambda_x = \frac{1}{x} , \hat\lambda_y = \frac{1}{y} \\
\therefore \theta = \frac{\lambda_x}{\lambda_y} \Rightarrow \hat\theta = \frac{\hat\lambda_x}{\hat\lambda_y} = \frac{1}{r}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>證明檢驗下列假設 <span class="math inline">\(\text{H}_0: \theta_0 = 1 \text{ v.s. H}_1: \theta_0 \neq 1\)</span> 的子集對數似然比檢驗統計量是 <span class="math inline">\(2n\text{log}\frac{(r+1)^2}{4r}\)</span>，並進行 <span class="math inline">\(n=16, r=2\)</span> 的假設檢驗。</li>
</ol>
<p><strong>解</strong></p>
<p><span class="math display">\[
\begin{aligned}
\text{Under H}_0 &amp; \Rightarrow \text{ test statistic is } \\
-2llr(\theta_0)  &amp; = -2[\ell(\theta_0) - \ell(\hat\theta)] \stackrel{\cdot}{\sim} \chi^2_1 \\
\Rightarrow \ell_p(\theta_0) &amp; = n\text{log}1 - 2n \text{log}(r+1) = -2n\text{log}(r+1) \\
          \ell_p(\hat\theta) &amp; = n\text{log}\frac{1}{r} - 2n\text{log}(2) \\
                             &amp; = -n\text{log}r-2n\text{log}2 = -n\text{log}4r\\
\Rightarrow \ell_p(\theta_0) - \ell_p(\hat\theta) &amp; = -2n\text{log}(r+1) + n\text{log}4r = n\text{log}\frac{4r}{(r+1)^2} \\
\Rightarrow -2llr(\theta_0)  &amp; = -2n\text{log}\frac{4r}{(r+1)^2} = 2n\text{log}\frac{(r+1)^2}{4r} \\
\text{ When } n=16, r=2 -2llr(\theta_0) &amp; = 2\times16\times\text{log}(\frac{2+1}{4\times2})^2 = 3.769 &lt; \chi^2_{1,0.95} = 3.84\\
\text{ We do not reject }&amp;\text{ the null hypothesis at the } 5% \text{ level.}
\end{aligned}
\]</span></p>
<p>此時如果精確計算可以獲得 <span class="math inline">\(p=0.052\)</span>，從檢驗統計量的計算值我們也能看出距離拒絕零假設的拒絕域十分接近。此時可以認爲是一個臨界的 <span class="math inline">\(p\)</span> 值。所以數據提供了臨界 <span class="math inline">\(p=0.052\)</span> 的證據證明肺癌 II 期患者的倖存時間平均要少於 I 期患者。</p>
</div>
<div id="總結" class="section level2">
<h2><span class="header-section-number">19.4</span> 總結</h2>
<p>推斷是十分具有挑戰性的一個章節，我們在此做個簡單的複習和總結，用一些常見的問題來結束本章。</p>
<div id="快速複習" class="section level3">
<h3><span class="header-section-number">19.4.1</span> 快速複習</h3>
<p>對於收集到的<strong>樣本數據 data</strong>，我們需要提出一個所謂的“科學問題 scientific question”。</p>
<p>爲了回答這個“科學問題”，我們會設想，並提出一個合適的 <strong>統計學模型 statistical model</strong>，確認提出的統計學模型中的<strong>參數 parameters</strong>。通過樣本數據的信息對參數進行<strong>估計 estimation</strong>，或者進行<strong>假設檢驗 hypothesis tests</strong>。</p>
<p>統計學模型具有自己的概率分佈，通過相應的參數，和模型的分佈可以解釋觀察數據的分佈，並且利用這些信息進行我們需要的推斷。同時，我們還需要利用觀察數據對我們提出的模型是否擬合數據做出合適的<strong>診斷</strong>。</p>
<p>估計和假設檢驗，是以<strong>似然方程</strong>爲基礎的。通常我們會利用便於計算的對數似然(比)，進行假設檢驗。</p>
<p>獲得似然方程以後，我們可以用對數似然比，進一步進行推斷：</p>
<ol style="list-style-type: decimal">
<li>確認最佳估計 <span class="math inline">\(MLE\)</span>，和它的方差 (標準誤)；</li>
<li>計算參數的點估計量，和信賴區間；</li>
<li>爲感興趣的參數實施假設檢驗。</li>
</ol>
</div>
<div id="試爲下面的醫學研究問題提出合適的統計學模型" class="section level3">
<h3><span class="header-section-number">19.4.2</span> 試爲下面的醫學研究問題提出合適的統計學模型</h3>
<ol style="list-style-type: decimal">
<li>在一所醫院收集了 80 名患者的血壓和體重的數據，醫生想要分析血壓 (bp) 跟體重 (weight) 之間是否有相關性。</li>
</ol>
<p>答： 用簡單線性迴歸模型。(r.v. = random variable)</p>
<p><span class="math display">\[
Y \text{ r.v. for bp } Y_j | \text{weight}_j \stackrel{i}{\sim} N(\alpha + \beta \text{weight}, \sigma^2), j = 1,2,\cdots,80; \text{H}_0: \beta=0
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>爲了調查某市青光眼的患病率 (prevalence)，從一般人羣中隨機抽取了 100 人進行眼部檢查。</li>
</ol>
<p>答：用二項分佈模型。</p>
<p><span class="math display">\[
K \text{ r.v. for number of people found with glaucoma } \\
K \sim \text{Bin}(100, \pi); \text{ Estimate } \pi \text{ with CI.}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>另一個醫生拿到了 2. 的數據，打算分析這100人中青光眼的患病與否是否和血壓相關。</li>
</ol>
<p>答：用邏輯迴歸模型。 <span class="math inline">\(\text{logit}\pi = \text{log}\frac{\pi}{1-\pi}\)</span></p>
<p><span class="math display">\[
K_i | bp_i \sim \text{Bin}(100, \pi_i), \text{logit}(\pi_i) = \alpha + \beta bp_i; \text{H}_0: \beta = 0
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>有好事者打算調查 25 名研究對象的血清膽固醇水平是否在實驗前後 (實驗時間3個月) 發生有意義的改變。</li>
</ol>
<p>答：正態分佈模型，單樣本 <span class="math inline">\(t\)</span> 檢驗。</p>
<p><span class="math display">\[
D \text{ r.v. for cholesterol change; } D_j \stackrel{i.i.d}{\sim} N(\delta, \sigma^2), j= 1,\cdots,25; \text{H}_0: \delta = 0\\
\text{Where } D_j = \text{chol}_{j,3m} - \text{chol}_{j,entry}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>前一題的好事者，打算進一步分析膽固醇水平的變化在某些進行特殊飲食的觀察對象中是否更加顯著。</li>
</ol>
<p>答：簡單線性迴歸模型。</p>
<p><span class="math display">\[
D_j | \text{diet}_j \stackrel{i}{\sim} N(\alpha + \beta \text{diet}_j, \sigma^2), j=1,\cdots,25; \text{H}_0: \beta = 0
\]</span></p>
<ol start="6" style="list-style-type: decimal">
<li>某降壓藥物已知能有效地降低高血壓患者的血壓。某項實驗將收集來的高血壓患者分成 6 個小組，每組給予的藥物劑量不同，最低 1 毫克每次，最高 6 毫克每次，每組相差 1 毫克劑量。研究者希望通過實驗確定該藥物的降壓效果是否在某個劑量時達到最大，如果沒有，是否降壓藥物的效果隨着劑量增加而增加。</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; bp_j | \text{dose}_j \stackrel{\cdot}{\sim} N(\alpha + \beta\text{dose}_j + \gamma\text{dose}^2_j, \sigma^2), j=1,\cdots,n;\\
\text{1) test } &amp; \text{ H}_0: \gamma=0; \text{ if do not reject, then do next test } \\
&amp; bp_j | \text{dose}_j \stackrel{\cdot}{\sim} N(\alpha + \beta\text{dose}_j, \sigma^2)
\text{2) test } &amp; \text{ H}_0: \beta=0
\end{aligned}
\]</span></p>
</div>
<div id="醫生來找統計學家問問題" class="section level3">
<h3><span class="header-section-number">19.4.3</span> 醫生來找統計學家問問題</h3>
<ol start="7" style="list-style-type: decimal">
<li>一個<strong>“臨牀醫生”</strong>來找你問了這樣的一個常見的問題：當我們使用 <span class="math inline">\(t\)</span> 檢驗的時候，爲什麼前提假設是數據服從 <strong>正態分佈</strong>? 而不使用<strong>服從 <span class="math inline">\(t\)</span> 分佈</strong> 這樣的前提條件，因爲我們實施該檢驗的時候明明就在用 <span class="math inline">\(t\)</span> 分佈？</li>
</ol>
<p>答：我們從未假定<strong>觀察數據服從 <span class="math inline">\(t\)</span> 分佈</strong>，我們假定的前提是檢驗統計量，也就是樣本均值和標準誤服從 <span class="math inline">\(t\)</span> 分佈。因爲我們不知道收集獲得的數據來自的人羣的方差是多少，需要使用樣本數據對方差也進行估計的時候，不得已而必須使用 <span class="math inline">\(t\)</span> 分佈來獲得估計的樣本均值的標準誤差，用於計算信賴區間和實施假設檢驗。</p>
<ol start="8" style="list-style-type: decimal">
<li>還是那個有好奇心的<strong>“臨牀醫生”</strong>又來問一個弱智問題：當我們使用正態分佈近似法對一個服從二項分佈的比例的單樣本檢驗的時候，我們把計算的檢驗統計量拿去跟正態分佈的特徵值作比較。然而，不用正態分佈近似，直接對連續型變量實施單樣本 <span class="math inline">\(t\)</span> 檢驗的時候卻把計算的檢驗統計量拿去和 <span class="math inline">\(t\)</span> 分佈的特徵值作比較，這是爲什麼？</li>
</ol>
<p>答：對連續型變量實施單樣本 <span class="math inline">\(t\)</span> 檢驗的時候，我們需要用樣本數據同時估計均值和標準誤。但是對於二項分佈的數據來說，它的樣本比例的標準誤是總體比例的一個方程，所以只要用樣本比例估計總體比例以後，總體的標準誤就已經可以知道，不必再作估計。所以，二項分佈的正態近似法就真的使用標準正態分佈的特徵值，但是連續型變量的總體標準誤同時被估計，它的不確定性也要考慮進來，只能使用 <span class="math inline">\(t\)</span> 分佈。</p>
<ol start="9" style="list-style-type: decimal">
<li>某<strong>“臨牀醫生”</strong>假裝很熱心想學習統計跑來問問題：該醫生實施的臨牀試驗，比較病例和對照之間某指標是否不同。但是，病例組看上去的年齡似乎比對照組要高一些，該醫生記得自己統計課上聽老師說過混雜因素的知識。所以他跑回家自己實施了一下病例組和對照組之間年齡是否有差別的 <span class="math inline">\(t\)</span> 檢驗，結果顯示病例組對照組的年齡沒有顯著性差異。所以他認爲可以從線性模型中去掉年齡這一變量。但是身爲統計學家的你堅持必須要保留年齡在模型裏。所以醫生問你是否關心年齡有差別所以才堅持要調整年齡。你的回答是“對不起大哥，我對病例對照之間的年齡差是否有統計學意義完全沒有興趣。”醫生更加困惑了。<span class="math inline">\(\text{variable}_i = \alpha + \beta\text{patient}_i + \gamma\text{age}_i + \varepsilon_i\)</span></li>
</ol>
<p>答：年齡是否會混雜了病人分組和指標之間的關係，<strong>不是通過比較兩組來自的人羣的年齡是否有差別來判斷的</strong>。如果<strong>樣本的年齡有差別</strong>，就很有可能會對你想要分析的關係造成混淆。因爲你進行的年齡均值是否有差異的 <span class="math inline">\(t\)</span> 檢驗，比較的並不是樣本年齡的差別，而是用樣本估計來自的人羣的年齡之間的比較。</p>

</div>
</div>
</div>



<div id="探索數據和簡單描述" class="section level1">
<h1><span class="header-section-number">第 20 章</span> 探索數據和簡單描述</h1>
<blockquote>
<dl>
<dt>Happy families are all alike, every unhappy family is unhappy in its own way.</dt>
<dd>Leo Tolstoy
</dd>
</dl>
</blockquote>
<blockquote>
<dl>
<dt>Tidy datasets are all alike, but every messy dataset is messy in its own way.</dt>
<dd>Hadley Wickham
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Analytic Techique lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/collier.timothy">Timothy Collier</a>.
</div>

<div id="數據分析的流程" class="section level2">
<h2><span class="header-section-number">20.1</span> 數據分析的流程</h2>
<div class="figure" style="text-align: center"><span id="fig:AT00"></span>
<img src="img/AT1.png" alt="Population, sample and statistical inference" width="70%" />
<p class="caption">
圖 20.1: Population, sample and statistical inference
</p>
</div>
<p>統計推斷的目的，是通過從人群中取樣本，經過對樣本特徵的 (描述) 統計分析 (summary statistic)，去推斷人群的相應特徵。</p>
<p>所以，無論什麼數據，到手以後我們一定要做的第一件事情，就是對其進行總結和描述，其過程又要盡可能地簡單明了。</p>
<p>在絕大多數的科學研究中數據分析都很重要，然而現實是，它多數情況下只出現在研究的第三部分：</p>
<ol style="list-style-type: decimal">
<li>研究設計</li>
<li>實施研究，收集數據</li>
<li><strong>數據分析</strong></li>
<li>結果報告</li>
</ol>
<div id="研究設計和實施" class="section level3">
<h3><span class="header-section-number">20.1.1</span> 研究設計和實施</h3>
<p>正確的統計推斷需要獲得具有代表性可以值得分析的數據，這必須建立在實驗研究設計良好，實施過程縝密的基礎上。設計糟糕，執行效率低下或者漏洞百出的實驗，給出的實驗數據必然是不可靠的，分析它也沒有意義。但是，不是說設計和實施階段就不需要統計學家的參與了。相反地，統計學家必須在研究實施過程中盡可能早的階段 (實驗設計) 參與進來。因為理解了實驗的目的，統計學家才能真正決定這個實驗要收集怎樣的數據，多大的樣本量，實施怎樣的分析方法。這些決定，注定了一項實驗研究的成敗。</p>
</div>
<div id="數據分析" class="section level3">
<h3><span class="header-section-number">20.1.2</span> 數據分析</h3>
<p>然而現實很殘酷，多數情況下實驗設計階段好像沒有統計學家什麼事，等到了數據分析階段，某些人才拍腦袋想讓統計學家來拯救他們收集的垃圾數據。通常都太晚了 (too late!)。</p>
<p>假設理想狀態下，我們收集到了想要分析的數據，可是接下來的工作流程的第一步，又常常被太多人忽略。許多 “科學家” 興奮地把數據輸入軟件，立刻就開始著手建立數學模型，進行假設檢驗，卻對數據的特徵一無所知！要知道，建立怎樣的模型，做怎樣的推斷，選用什麼樣的分析手段，都必須建立在你對數據內容完全熟悉的前提下，才能正確地實施。</p>
<p>數據分析第一步：<strong>數據清理, data cleaning</strong>。</p>
<p>這一步的目的很簡單，把收集來的粗糙的，充滿了缺失值和數據類型註解等等無法直接分析的數據，整理打扮成可以建模的數據庫。這個過程中，你可能需要對某些變量進行分類，可能兩三個實驗的結果需要被合併協調，可能在這個過程中你會發現數據錄入出現了一些錯誤導致數據庫裡有一些異常值，甚至是重複錄入。所以，各位小伙伴當你拿到一個數據準備分析的第一步，你必須要先了解你的數據。常用的手段包括簡單作圖，對感興趣的變量做概括分析 (summary your data!)。除此之外，由於沒有人能保證實驗中能收集到所有對象的完整數據，我們還需要分析缺失數據的特徵，思考他們為什麼會變成缺失數據。</p>
</div>
</div>
<div id="數據類型" class="section level2">
<h2><span class="header-section-number">20.2</span> 數據類型</h2>
<p>不同類型的數據，使用的初步描述手段各不相同。因此區分定性數據和定量數據，連續型數據，離散型數據，分類型數據顯得十分必要。</p>
<ol style="list-style-type: decimal">
<li>連續型變量，continuous data <br>連續型數據多來自實驗中對某些特徵的測量，例如身高，體重等，它們本質上是一組連續型的數據。現實生活中接觸到的許多數據也都是連續型的，例如：時間，距離，骨骼密度，藥物濃度等等。所謂連續型變量是由於它理論上可以取某段數值區間內的任何值。當然我們還會被測量尺度的精確度所局限。</li>
<li>離散型變量，discrete data <br>許多數據，是通過計數來收集的。離散型變量的本質上也是屬於數值型數據 (numeric)，特徵是這種數值型數據總是<strong>取正整數</strong>或者零。例如，醫院中發生感染的次數，一個家庭中兄弟姐妹的人數，術後患者存活天數等等。</li>
<li>分類型變量，categorical data <br>分類型變量的數據，其每一個觀察值都歸類於一種類別 (或者屬性)。分類型數據和離散型數據最大的不同是，它從本質上說就不屬於數值型數據。例如，頭髮的顏色 (紅色，黃色，黑色)，職業類型 (裝修工人，教師，總統)。儘管分類型數據本質上不是數值，分析過程中我們常常會給它們賦予一定的數值以便於計算。
<ol style="list-style-type: decimal">
<li>二分類型數據，binary：十分常見，例如，生存/死亡，有效/無效，成功/失敗；</li>
<li>名義型數據，nominal：數據本身沒有高低順序之分，例如，種族，血型等；</li>
<li>排序型數據，ordinal：每個分類是包函了順序含義的數據，例如，回答某些問卷問題時用的 “十分同意，同意，不同意，十分不同意”，某些癌症使用的分級診斷 “一級，二級，三級，終級”，對一些結果的評價時使用的 “優，良，中，差”。</li>
</ol></li>
</ol>
<p>其實，對於連續型變量我們還常常會將它們轉化成分類型變量，使用一些特定的或者事先定義好的閾值 (cutoff values) 把連續型數據分組，分級，分層等等。最常見的例子就是體重指數 (BMI)，它本身是一個連續型的變量，但是又可以根據定義好的閾值把它分類成低體重 (<span class="math inline">\(&lt; 18.5 \; kg/m^2\)</span>)，正常體重 (<span class="math inline">\(18.5 - 24.9 \; kg/m^2\)</span>)，超重 (<span class="math inline">\(25-29.9 \; kg/m^2\)</span>)，肥胖 (<span class="math inline">\(\geqslant 30 \; kg/m^2\)</span>)。另一個例子是血紅蛋白 (haemoglobin, <span class="math inline">\(g/l\)</span>)，它本身是一個連續型變量，但是我們利用它的閾值 (女性，<span class="math inline">\(&lt;120 \; g/l\)</span>；男性，<span class="math inline">\(&lt; 130 \; g/l\)</span>)，作為診斷是否患有貧血症的依據。</p>
<p>把連續型變量進行分類處理的代價是信息的丟失。如果一個人的體重指數是 <span class="math inline">\(25\)</span>，他/她的數據被和體重指數為 <span class="math inline">\(29.9\)</span> 的人當作相同數值來對待是否合理是我們需要考慮的問題。而且許多情況下閾值的定義並不能達成共識，即使達成共識的閾值又是十分人為且恣意的，它可能導致一些相關關係被“強化”，或者反過來被“弱化”。所以，如果要對連續型數值進行分組，現在的要求是，在實驗設計階段就必須明確分組的閾值之定義，而不能在看到數據以後進行人為地劃分。<strong>更加不推薦的是直接使用四分位或者五分位來對數據分組。</strong></p>
</div>
<div id="如何總結並展示數據" class="section level2">
<h2><span class="header-section-number">20.3</span> 如何總結並展示數據</h2>
<p>光觀察原始數據很難真正明白數據的分佈特徵和形式，所以使用表格，或者用散點圖，柱狀圖等形式來描述數據就成為了常用的手段。前一節所描述的數據類型，決定了一組數據該如何被描述。</p>
<div id="離散型分類型數據的描述---頻數分佈表-frequency-table" class="section level3">
<h3><span class="header-section-number">20.3.1</span> 離散型分類型數據的描述 - 頻數分佈表 frequency table</h3>
<p>下面的表格就是使用頻數分佈表來描述 <code>cars</code> 這個數據包中不同車速 (mph) 的分佈。汽車車速本身應該是一個連續型變量，但是這是1920年的數據當時的記錄只精確到整數，因此人為地造成了一組離散型變量的情況。下面的第二個表格使用的是繪圖瑞士軍刀包 <code>ggplot2</code> 裡自帶的鑽石數據。其中 <code>cut</code> 是對於鑽石切割水平的評價，所以是一個帶有排序性質的分組型變量。</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" title="1"><span class="kw">data</span>(<span class="st">&quot;cars&quot;</span>)</a>
<a class="sourceLine" id="cb38-2" title="2">epiDisplay<span class="op">::</span><span class="kw">tab1</span>(cars<span class="op">$</span>speed, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## cars$speed : 
##         Frequency Percent Cum. percent
## 4               2       4            4
## 7               2       4            8
## 8               1       2           10
## 9               1       2           12
## 10              3       6           18
## 11              2       4           22
## 12              4       8           30
## 13              4       8           38
## 14              4       8           46
## 15              3       6           52
## 16              2       4           56
## 17              3       6           62
## 18              4       8           70
## 19              3       6           76
## 20              5      10           86
## 22              1       2           88
## 23              1       2           90
## 24              4       8           98
## 25              1       2          100
##   Total        50     100          100</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1"><span class="kw">data</span>(<span class="st">&quot;diamonds&quot;</span>)</a>
<a class="sourceLine" id="cb40-2" title="2">epiDisplay<span class="op">::</span><span class="kw">tab1</span>(diamonds<span class="op">$</span>cut, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## diamonds$cut : 
##           Frequency Percent Cum. percent
## Fair           1610     3.0          3.0
## Good           4906     9.1         12.1
## Very Good     12082    22.4         34.5
## Premium       13791    25.6         60.0
## Ideal         21551    40.0        100.0
##   Total       53940   100.0        100.0</code></pre>
<p>離散型變量和分類型變量的描述還可以使用柱狀圖的形式來展示如下：</p>
<div class="figure" style="text-align: center"><span id="fig:car-speed"></span>
<img src="bookdown_files/figure-html/car-speed-1.png" alt="Bar chart displaying the speed of cars" width="80%" />
<p class="caption">
圖 20.2: Bar chart displaying the speed of cars
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:diamonds-cut"></span>
<img src="bookdown_files/figure-html/diamonds-cut-1.png" alt="Bar chart displaying distribution of evaluation of diamonds cut" width="80%" />
<p class="caption">
圖 20.3: Bar chart displaying distribution of evaluation of diamonds cut
</p>
</div>
<p>上面這兩圖的 y 軸都用的是頻率，當然還可以使用百分比。不同組間分類型變量的分佈比較的話更常使用百分比作為 y 軸。如下面的表格及百分比條形圖所示。</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" title="1">diamonds<span class="op">$</span>clarity2g &lt;-<span class="st"> &quot;Good&quot;</span></a>
<a class="sourceLine" id="cb42-2" title="2">diamonds<span class="op">$</span>clarity2g[(diamonds<span class="op">$</span>clarity<span class="op">==</span><span class="st">&quot;I1&quot;</span>)<span class="op">|</span></a>
<a class="sourceLine" id="cb42-3" title="3"><span class="st">                    </span>(diamonds<span class="op">$</span>clarity<span class="op">==</span><span class="st">&quot;SI2&quot;</span>)<span class="op">|</span></a>
<a class="sourceLine" id="cb42-4" title="4"><span class="st">                     </span>(diamonds<span class="op">$</span>clarity<span class="op">==</span><span class="st">&quot;SI1&quot;</span>)<span class="op">|</span></a>
<a class="sourceLine" id="cb42-5" title="5"><span class="st">                     </span>(diamonds<span class="op">$</span>clarity<span class="op">==</span><span class="st">&quot;VS2&quot;</span>)] &lt;-<span class="st"> &quot;Poor&quot;</span></a>
<a class="sourceLine" id="cb42-6" title="6">tab &lt;-<span class="st"> </span><span class="kw">stat.table</span>(<span class="dt">index=</span><span class="kw">list</span>(<span class="dt">Cut=</span>cut,<span class="dt">Clarity=</span>clarity2g),</a>
<a class="sourceLine" id="cb42-7" title="7">                   <span class="dt">contents=</span><span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(cut)), <span class="dt">data=</span>diamonds, <span class="dt">margins=</span>T)</a>
<a class="sourceLine" id="cb42-8" title="8"><span class="kw">print</span>(tab, <span class="dt">digits =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##  --------------------------------------- 
##             ----------Clarity----------- 
##  Cut             Good     Poor    Total  
##  --------------------------------------- 
##  Fair          265.00  1345.00  1610.00  
##                  1.42     3.81     2.98  
##                                          
##  Good         1191.00  3715.00  4906.00  
##                  6.38    10.54     9.10  
##                                          
##  Very Good    4067.00  8015.00 12082.00  
##                 21.77    22.73    22.40  
##                                          
##  Premium      3705.00 10086.00 13791.00  
##                 19.83    28.61    25.57  
##                                          
##  Ideal        9454.00 12097.00 21551.00  
##                 50.60    34.31    39.95  
##                                          
##                                          
##  Total       18682.00 35258.00 53940.00  
##                100.00   100.00   100.00  
##  ---------------------------------------</code></pre>
<div class="figure" style="text-align: center"><span id="fig:diamonds-cut-clarity"></span>
<img src="bookdown_files/figure-html/diamonds-cut-clarity-1.png" alt="Bar chart displaying distribution of evaluation of diamonds cut by clarity" width="80%" />
<p class="caption">
圖 20.4: Bar chart displaying distribution of evaluation of diamonds cut by clarity
</p>
</div>
</div>
<div id="連續型變量" class="section level3">
<h3><span class="header-section-number">20.3.2</span> 連續型變量</h3>
<p>連續型變量如果做頻數分佈表一般提供的信息量就較小。常用來描述連續型變量的手段是柱狀圖，histogram，和箱形圖，boxplot。柱狀圖應該不必過多解釋。箱形圖，展示的是連續型變量的中位數，四分位，範圍值，以及異常值。一個典型的箱形圖，中間的方形區域包括了該數據的四分位距，interquartile range (即中間 50% 的數據, IQR)。</p>
<div class="figure" style="text-align: center"><span id="fig:diamond-carat-box"></span>
<img src="bookdown_files/figure-html/diamond-carat-box-1.png" alt="Boxplot of the diamond carat data" width="80%" />
<p class="caption">
圖 20.5: Boxplot of the diamond carat data
</p>
</div>
<p>R作出的箱形圖如 <a href="#fig:diamond-carat-box">20.5</a> 所示，箱子以上的橫線，意為最高值為75%分位值加上1.5倍的IQR；箱子以下橫線，意為最低值為25%分位值減去1.5倍的IQR。其他的觀察值如果不在這個上下限範圍之內的，會用黑點標記出來。這些值被認為是異常值 (outliers)。</p>
</div>
</div>
<div id="數據總結方案位置分散偏度和峰度" class="section level2">
<h2><span class="header-section-number">20.4</span> 數據總結方案：位置，分散，偏度，和峰度</h2>
<div id="位置" class="section level3">
<h3><span class="header-section-number">20.4.1</span> 位置</h3>
<p>描述一組連續型變量的位置，location，此處的位置指的是數據分佈的<strong>中心</strong>位置，常用的數值是眾數 (mode)，中位數 (median)，均值 (mean)。</p>
<ul>
<li>眾數 mode，的定義是，一組數據中出現最多次的數值大小；</li>
<li>中位數 median，的定義是，一組數據中從小到大/或者從大到小排序後50%位置的數值大小，如果觀察值有偶數個，中位數的定義是中間兩個數值的平均值大小；</li>
<li>算術平均值 arithmetic mean 的<strong>大小受異常值影響較大</strong>，通常簡略為均值，其定義可以用下面的表達式：<span class="math display">\[\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\]</span></li>
<li>幾何平均值 geometrix mean，常用在正偏態分佈數據 (positively skewed data)，其定義為： <span class="math display">\[\sqrt[n]{\prod_{i=1}^n X_i}=exp[\frac{1}{n}\sum_{i=1}^n log_e(X_i)]\]</span></li>
<li>調和平均值 harmonic mean，是所有觀察值的倒數和的倒數，定義為：<span class="math display">\[\frac{1}{\frac{1}{n}\sum_{i=1}^n\frac{1}{X_i}}\]</span></li>
</ul>
</div>
<div id="分散" class="section level3">
<h3><span class="header-section-number">20.4.2</span> 分散</h3>
<p>數據的分散程度，dispersion，也就是數據的波動大小 variation。同樣均值的數據，他們的分散可能差別很大：</p>
<div class="figure" style="text-align: center"><span id="fig:diff-dispersion"></span>
<img src="bookdown_files/figure-html/diff-dispersion-1.png" alt="Distributions with similar central location but different dispersion" width="80%" />
<p class="caption">
圖 20.6: Distributions with similar central location but different dispersion
</p>
</div>
<p>分散程度的描述方法花樣不少，我們這裡先考慮範圍 (range)，四分位差 (interquartile range)，方差 (variance)，標準差 (standard deviation)。</p>
<div id="範圍-range" class="section level4">
<h4><span class="header-section-number">20.4.2.1</span> 範圍 range</h4>
<ul>
<li><p>定義：最大值和最小值的差。</p></li>
<li><p>缺點：受樣本量大小，以及異常值影響較大。</p></li>
<li><p>在表格，論文中需要同時報告最大值和最小值。</p></li>
</ul>
</div>
<div id="四分位差-interquartile-range-iqr" class="section level4">
<h4><span class="header-section-number">20.4.2.2</span> 四分位差 interquartile range (IQR)</h4>
<ul>
<li><p>定義：四分位差是包含了數據中間 50% 數值的範圍。即，75%分位數-25%分位數的差值。</p></li>
<li><p>當觀察值數量為奇數個時，計算方法為：去掉中位數，計算大於中位數和小於兩個部分數值的中位數，求其差，例如：<span class="math inline">\(5,10,12,14,16,19,22\)</span> 這組數字，25%分位數為10，75%分位數為19，所以IQR等於9。</p></li>
<li><p>當觀察值數量為偶數個時，計算方法為：計算較小的50%數值的中位數，和較大50%數值的中位數，求其差，例如：<span class="math inline">\(5,10,12,14,16,19,22,38\)</span> 這組數字，上下兩半部分的中位數分別是 <span class="math inline">\(Q_L=\frac{10+12}{2}=11;\;Q_U=\frac{19+22}{2}=20.5\)</span>，所以，其IQR等於9.5.</p></li>
<li><p>在表格，論文中需要同時報告25%，75%分位數兩個數值，例：[11,20.5]。</p></li>
</ul>
</div>
<div id="方差和標準差-variance-and-standard-deviation" class="section level4">
<h4><span class="header-section-number">20.4.2.3</span> 方差和標準差 variance and standard deviation</h4>
<ul>
<li><p>先定義每一個觀察值和均值之間的差為 <span class="math inline">\(D_i = X_i - \bar{X}\)</span>。</p></li>
<li><p>根據定義，<span class="math inline">\(\frac{1}{n}\sum_{i=1}^n D_i=0\)</span>。</p></li>
<li><p>樣本方差 Variance 被定義為 <span class="math inline">\(\frac{1}{n-1}\sum_{i=1}^n D_i^2\)</span>。</p></li>
<li><p>樣本方差的平方根，被定義為標準差 standard deviation，<span class="math inline">\(\text{SD}=\sqrt{\frac{1}{n-1}\sum_{i=1}^n D_i^2}\)</span></p></li>
<li><p>更常見的表達式為：</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\text{Var} &amp;= \frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2 \\
           &amp;= \frac{1}{n-1}[(\sum_{i=1}^nX_i^2)-n\bar{X}^2]
\end{aligned}
\]</span></p>
<p>此處分母為 <span class="math inline">\(n-1\)</span> 而不是 <span class="math inline">\(n\)</span> 的原因，需要參考推斷部分的解釋 (Section <a href="#samplevarbias">10.3</a>)。</p>
<ul>
<li>方差標準差受異常值影響較大。例如，下面的數據：</li>
</ul>
<p><span class="math display">\[
5, 9, 12, 14, 14, 15, 16, 19, 22\;\;\; \text{Var}=25.5\\
5, 9, 12, 14, 14, 15, 16, 19, 58\;\; \text{Var}=241.5
\]</span></p>
</div>
</div>
<div id="偏度-skewness" class="section level3">
<h3><span class="header-section-number">20.4.3</span> 偏度 skewness</h3>
<p>使用柱狀圖來描述數據時，如果柱狀圖左右基本對稱 (中位數和均值基本一致)，偏度為零，正態分佈數據都是左右對稱的。如果柱狀圖右側的尾巴較長，偏度為正；如果左側的尾巴較長，偏度為負。偏度計算公式為：</p>
<p><span class="math display">\[
\frac{\frac{1}{n}\sum_{i=1}^n D_i^3}{(\frac{1}{n}\sum_{i=1}^n D_i^2)^{\frac{3}{2}}}
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:skewness"></span>
<img src="bookdown_files/figure-html/skewness-1.png" alt="Relationship between skew and measures of location" width="80%" />
<p class="caption">
圖 20.7: Relationship between skew and measures of location
</p>
</div>
</div>
<div id="峯度-kurtosis" class="section level3">
<h3><span class="header-section-number">20.4.4</span> 峯度 kurtosis</h3>
<p>峯度是描述數據分佈的最後一個指標。峯度衡量的是一組數據分佈的尾部的厚度。一個正態分佈數據，大約 5% 的數據分佈在左右兩邊的尾部 (2.5% 低於 <span class="math inline">\(\mu-2\sigma\)</span>，2.5% 高於 <span class="math inline">\(\mu +2\sigma\)</span>)。峯度測量的是一組數據尾部數據的分佈和正態分佈兩側尾部數據之間的差距。</p>
<p>峯度的計算公式爲：
<span class="math display">\[
\frac{\frac{1}{n}\sum_{i=1}^nD_i^4}{(\frac{1}{n}\sum_{i=1}^nD_i^2)^2}
\]</span>
一個正態分佈數據，峯度值爲 3。當左右兩段的數值佔比低於正態分佈預期時，峯度值小於 3。反之，峯度大於 3。尾部較厚 (峯度較大) 的典型分佈之一是 <span class="math inline">\(t\)</span> 分佈 (圖 <a href="#fig:kurtosis">20.8</a>)</p>
<div class="figure" style="text-align: center"><span id="fig:kurtosis"></span>
<img src="bookdown_files/figure-html/kurtosis-1.png" alt="t distributions with 5 and 10 degrees of freedom compared with a standard normal distribution" width="80%" />
<p class="caption">
圖 20.8: t distributions with 5 and 10 degrees of freedom compared with a standard normal distribution
</p>
</div>
</div>
</div>
</div>
<div id="信賴區間-confidence-intervals-1" class="section level1">
<h1><span class="header-section-number">第 21 章</span> 信賴區間 confidence intervals</h1>
<div id="定義" class="section level2">
<h2><span class="header-section-number">21.1</span> 定義</h2>
<p>信賴區間的定義，曾經在統計推斷中介紹過 (Section <a href="#CI-for-sample-mean">10.1</a>)。信賴區間 (CI)，提供了一種對參數估計精確度的度量。CI，也是一種統計量，有自己的樣本分佈，它總是成對成對地出現的。L，表示下限，U，表示上限。顯著性水平 (confidence level) 下的下限和上限之間的間距大小，是由信賴區間本身的樣本分佈決定的。</p>
<p>一般地，對於一個總體參數 <span class="math inline">\(\mu\)</span>，它的 <span class="math inline">\(100(1-\alpha)\%\text{CI}\)</span> 信賴區間的含義爲：</p>
<p><span class="math display" id="eq:confi">\[
\begin{equation}
\text{Prob}\{\mu\in (\text{L}, \text{U}) | \mu\} = (1-\alpha)
\end{equation}
\tag{21.1}
\]</span></p>
<p>所以，一個總體參數 <span class="math inline">\(\mu\)</span>，的 <span class="math inline">\(95\%\text{CI}\)</span> 信賴區間爲：</p>
<p><span class="math display" id="eq:confinv">\[
\begin{equation}
\text{Prob}\{ \mu \in (\text{L, U}) | \mu\} =0.95
\end{equation}
\tag{21.2}
\]</span></p>
<p>用公式 <a href="#eq:confinv">(21.2)</a> 來解釋就是，區間 <span class="math inline">\(\text{(L, U)}\)</span> 內包含了總體參數 <span class="math inline">\(\mu\)</span> 的概率爲 <span class="math inline">\(95\%\)</span>。本文以下部分從公式中省略 <span class="math inline">\(|\mu\)</span> 部分。但是必須要記住，概率論環境下的信賴區間 (或者其他統計學參數估計) 都是總體參數的條件概率。在概率論語境下，信賴區間一般是左右對稱的。所以 <span class="math inline">\(100(1-\alpha)\%\text{CI}\)</span> 的含義可以解讀爲：</p>
<p><span class="math display" id="eq:confinvmean">\[
\begin{equation}
\text{Prob} \{ \mu \leqslant \text{L} \} = \text{Prob} \{ \mu \geqslant \text{U} \} = \frac{\alpha}{2}
\end{equation}
\tag{21.3}
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:CIdefin"></span>
<img src="img/Selection_100.png" alt="General definition of a CI for a 95% CI" width="80%" />
<p class="caption">
圖 21.1: General definition of a CI for a 95% CI
</p>
</div>
</div>
<div id="利用總體參數的樣本分佈求信賴區間" class="section level2">
<h2><span class="header-section-number">21.2</span> 利用總體參數的樣本分佈求信賴區間</h2>
<p>總體參數的樣本分佈是求其信賴區間的關鍵。假設 <span class="math inline">\(\hat\mu\)</span> 是總體參數 <span class="math inline">\(\mu\)</span> 的估計量。且已知存在兩個單調遞增函數 <span class="math inline">\(A(\mu), B(\mu)\)</span> 來描述該總體參數 <span class="math inline">\(\mu\)</span> ：</p>
<p><span class="math display" id="eq:AT4">\[
\begin{equation}
\text{Prob} \{ \hat\mu \leqslant A(\mu) \} = \text{Prob} \{ \hat\mu \geqslant B(\mu) \} = \frac{\alpha}{2}
\end{equation}
\tag{21.4}
\]</span></p>
<p>所以，</p>
<p><span class="math display" id="eq:AT5">\[
\begin{equation}
\text{Prob} \{ A^{-1} (\hat\mu) \leqslant \mu \} = \text{Prob} \{ B^{-1}(\hat\mu) \geqslant \mu \} = \frac{\alpha}{2}
\end{equation}
\tag{21.5}
\]</span></p>
<p>因此，<span class="math inline">\(A^{-1}(\hat\mu), B^{-1}(\hat\mu)\)</span> 就是我們想要找的公式 <a href="#eq:confinvmean">(21.3)</a> 參數的估計信賴區間的下限 <span class="math inline">\(\text{L}\)</span>，和上限 <span class="math inline">\(\text{U}\)</span>。所以，關鍵的任務就在於，每一次尋找計算參數樣本分佈的方程 <span class="math inline">\(A, B\)</span> 。</p>
</div>
<div id="情況1已知方差的正態分佈數據均值的信賴區間" class="section level2">
<h2><span class="header-section-number">21.3</span> 情況1：已知方差的正態分佈數據均值的信賴區間</h2>
<p>從已知<strong>正態分佈且方差</strong>爲 <span class="math inline">\(\sigma^2\)</span> 的人羣中抽取樣本量爲 <span class="math inline">\(n\)</span> 的相互獨立觀察數據 <span class="math inline">\(Y_i (i=1,2,\cdots,n)\)</span>。該樣本均值的估計量 <span class="math inline">\(\hat\mu=\bar{Y}\)</span>，也服從方差已知的 <span class="math inline">\((\frac{\sigma^2}{n})\)</span> 正態分佈：</p>
<p><span class="math display" id="eq:AT6">\[
\begin{equation}
\bar{Y}\sim N(\mu, \frac{\sigma^2}{n}) \Leftrightarrow Z=\frac{\bar{Y}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \sim N(0,1)
\end{equation}
\tag{21.6}
\]</span></p>
<p>所以利用標準正態分佈，往公式 <a href="#eq:confinvmean">(21.3)</a> 儘可能靠：<span class="math inline">\(\text{Prob}\{ Z \leqslant z_{\alpha/2}\} = \text{Prob}\{ Z \geqslant z_{1-\alpha/2}\} = \frac{\alpha}{2}\)</span> 。</p>
<p>把式子 <a href="#eq:AT6">(21.6)</a> 代入以後：</p>
<p><span class="math display" id="eq:AT7">\[
\begin{equation}
\text{Prob}\{ \bar{Y} \leqslant \mu+z_{\alpha/2}\frac{\alpha}{\sqrt{n}} \} = \text{Prob}\{ \bar{Y} \geqslant \mu+z_{1-\alpha/2}\frac{\alpha}{\sqrt{n}} \} = \frac{\alpha}{2}
\end{equation}
\tag{21.7}
\]</span></p>
<p>至此，我們找到了描述總體均值的單調函數：</p>
<p><span class="math display">\[
\begin{aligned}
A(\mu) &amp;= \mu + z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \\
B(\mu) &amp;= \mu + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{aligned}
\]</span></p>
<p>由於標準正態分佈左右對稱，所以 <span class="math inline">\(z_{\alpha/2}=-z_{1-\alpha/2}\)</span> ，因而，<span class="math inline">\(A(\mu) = \mu - z_{1-\alpha/2}\frac{\sigma}{n}\)</span>。</p>
<p>此時，求信賴區間上限和下限的方法應該已經一目瞭然：</p>
<p><span class="math display" id="eq:AT2-8">\[
\begin{equation}
\text{U} =A^{-1}(\bar{Y})=\bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
\text{L} = B^{-1}(\bar{Y})=\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{equation}
\tag{21.8}
\]</span></p>
<p>我們也常將它簡寫成爲：<span class="math inline">\(\text{CI} = \bar{Y} \pm z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span>。</p>
<p>它的意義是：</p>
<p><span class="math display" id="eq:AT2-9">\[
\begin{equation}
\text{Prob} \{ \bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} &lt; \mu &lt; \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} \} = 1-\alpha
\end{equation}
\tag{21.9}
\]</span></p>
<p>所以區間 <span class="math inline">\((\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}, \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}})\)</span> 包含了總體參數均值 <span class="math inline">\((\mu)\)</span> 的概率是 <span class="math inline">\(1-\alpha\)</span>。我們把這個區間叫做總體均值 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(100(1-\alpha)\%\)</span> 信賴區間。常說的 <span class="math inline">\(95\%\)</span> 信賴區間我們使用的 <span class="math inline">\(z_{0.975} = 1.96\)</span>。其他置信水平的 <span class="math inline">\(z\)</span> 值舉例如下：</p>
<p><span class="math display">\[
\begin{array}{lr}
z_{0.90} = 1.28 &amp;  \text{for } 80\% \text{ level} \\
z_{0.95} = 1.645 &amp;  \text{for } 90\% \text{ level} \\
z_{0.995} = 2.58 &amp;  \text{for } 99\% \text{ level} \\
z_{0.9995} = 3.29 &amp;  \text{for } 99.9\% \text{ level} \\
\end{array}
\]</span></p>
<p>所以，根據上面羅列的不同置信水平下 <span class="math inline">\(z\)</span> 值的大小，我們不難判斷 <span class="math inline">\(\text{CI} = \bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span> 範圍隨着標準差增大而變寬 (不精確)，隨着樣本量增加而變窄 (精確)。</p>
<p>這裏補充另一個容易混淆的概念，參數估計的信賴區間公式 <span class="math inline">\(\text{CI} = \bar{Y} \pm z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\)</span> ，和參考值範圍 (reference range) 是不同的概念。後者的公式爲 <span class="math inline">\(\bar{Y}\pm z_{1-\alpha/2} \sigma\)</span>。參考值範圍的意義是， <span class="math inline">\(95\%\)</span> 的樣本數據包含在這個區間內。信賴區間，給出的是這個樣本對總體均值的估計的<strong>精確度</strong>。</p>
</div>
<div id="CImean" class="section level2">
<h2><span class="header-section-number">21.4</span> 信賴區間的意義</h2>
<p>當 <span class="math inline">\(\alpha = 0.05\)</span> 時，我們說<span class="math inline">\((\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}, \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}})\)</span> 包含了總體參數均值 <span class="math inline">\((\mu)\)</span> 的概率是 <span class="math inline">\(95\%\)</span>。但是要記住，千萬不能說：總體參數 <span class="math inline">\(\mu\)</span> 有 <span class="math inline">\(95\%\)</span> 的概率落在這個信賴區間內。因爲<strong>總體參數不是隨機變量</strong>，它不會隨我們的樣本變化而變化，它是恆定不變的。我們每一次實驗，每一次採樣，獲得的樣本數據，計算出一個新的信賴區間，這樣的區間都是在估計這個未知位置的總體參數。所以，<strong>從長遠來說，相同的實驗，重複20次，其中19次計算獲得的信賴區間，會包含真實的總體參數。</strong></p>
</div>
<div id="AT2-5" class="section level2">
<h2><span class="header-section-number">21.5</span> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</h2>
<p>多數情況下，總體的方差我們無從知曉。它也必須通過實驗數據來估計 <span class="math inline">\(\hat\sigma^2\)</span>。那麼，下面的公式計算的統計量 <span class="math inline">\(T\)</span> 服從自由度爲 <span class="math inline">\(n-1\)</span> 的 <span class="math inline">\(t\)</span> 分佈：</p>
<p><span class="math display">\[
T=\frac{\bar{Y}-\mu}{\sqrt{\hat\sigma^2/n}} \sim t_{n-1}
\]</span></p>
<p>用跟前面類似的辦法，用統計量 <span class="math inline">\(T\)</span> 取代 <span class="math inline">\(Z\)</span>，我們可以求未知方差時正態分佈數據均值的信賴區間 (類比 <a href="#eq:AT2-8">(21.8)</a>)：</p>
<p><span class="math display" id="eq:AT2-10">\[
\begin{aligned}
&amp;\text{U} = \bar{Y} + t_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
&amp;\text{L} = \bar{Y} - z_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
&amp;\text{Or, equivalently :} \\
&amp;\text{CI } = \bar{Y} \pm t_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{aligned}
\tag{21.10}
\]</span></p>
</div>
<div id="varCI" class="section level2">
<h2><span class="header-section-number">21.6</span> 情況3：服從正態分佈的隨機變量方差的信賴區間</h2>
<p>用 <span class="math inline">\(Y_i (i=1,2,\cdots,n)\)</span> 標記樣本量爲 <span class="math inline">\(n\)</span> 的獨立觀察數據。已知該數據來自的人羣服從正態分佈，但是方差未知。那麼從統計推斷第二章 (Section <a href="#samplevar">10.4</a>) 推導過的內容，我們知道：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Sample variance is defined as: } \\
&amp;\hat\sigma^2 = \frac{\sum_{i=1}^n(Y_i-\bar{Y})^2}{n-1} \\
&amp;\text{and } \\
&amp;\frac{(n-1)\hat\sigma^2}{\sigma^2} \sim \chi^2_{n-1} \\
&amp;\text{It follows that we want } \\
&amp;\text{Prob}\{ \hat\sigma^2 \leqslant \frac{\sigma^2}{n-1}\chi^2_{n-1, \alpha/2} \} = \text{Prob}\{ \hat\sigma^2 \geqslant \frac{\sigma^2}{n-1}\chi^2_{n-1, 1-\alpha/2} \} = \frac{\alpha}{2} \\
&amp; \Rightarrow \text{U} = \frac{(n-1)\hat\sigma^2}{\chi^2_{n-1, \alpha/2}} \; \text{L} = \frac{(n-1)\hat\sigma^2}{\chi^2_{n-1, 1-\alpha/2}} \\
\end{aligned}
\]</span></p>
</div>
<div id="當樣本量足夠大時" class="section level2">
<h2><span class="header-section-number">21.7</span> 當樣本量足夠大時</h2>
<p>根據中心極限定理，當樣本量足夠大時，<strong>樣本均數</strong>服從正態分佈，即使<strong>樣本數據</strong>並不服從正態分佈。這就意味着，樣本足夠大，章節 <a href="#CImean">21.4</a> 中用到的均值信賴區間公式，也可適用於樣本數據不服從正態分佈的情況下。我們常使用這個定理，和章節 <a href="#CImean">21.4</a> 中的公式去計算許多總體均數以外的參數的 <span class="math inline">\(95\%\)</span> 信賴區間，通過正態分佈近似法計算獲得的信賴區間，被叫做近似信賴區間。</p>
</div>
<div id="情況4求人羣百分比的信賴區間" class="section level2">
<h2><span class="header-section-number">21.8</span> 情況4：求人羣百分比的信賴區間</h2>
<div id="一般原則" class="section level3">
<h3><span class="header-section-number">21.8.1</span> 一般原則</h3>
<p>用 <span class="math inline">\(R\)</span> 表示 <span class="math inline">\(n\)</span> 次實驗中成功的次數。如果滿足實驗相互獨立的條件，那麼 <span class="math inline">\(R\sim \text{Binomial}(n,\pi)\)</span>。那麼樣本比例 <span class="math inline">\(P=\frac{R}{n}\)</span> 是人羣比例 <span class="math inline">\(\pi\)</span> 的無偏估計。如果想要求 <span class="math inline">\(\pi\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間 <span class="math inline">\((\pi_L, \pi_U)\)</span>，我們可能自然而讓想到用成功次數 <span class="math inline">\(R\)</span> 來計算。然而，由於 <span class="math inline">\(R\)</span> 本身是離散型變量 (只能取大於等於零的整數)，恰好加起來概率等於 <span class="math inline">\(95\%\)</span> 的 <span class="math inline">\(\pi\)</span> 的區間是幾乎不可能計算的。我們處理比例的信賴區間的問題時，要計算的兩個下限值和上限值要滿足的條件：</p>
<ol style="list-style-type: decimal">
<li>尋找最小的 <span class="math inline">\(\pi_L\)</span> 滿足 <span class="math inline">\(\text{Prob}(\pi_L&gt;\pi) \leqslant 0.025\)</span></li>
<li>尋找最大的 <span class="math inline">\(\pi_U\)</span> 滿足 <span class="math inline">\(\text{Prob}(\pi_U&lt;\pi) \leqslant 0.025\)</span></li>
</ol>
<p>有兩種方案可供選擇：</p>
<ol style="list-style-type: decimal">
<li>利用樣本分佈服從二項分佈 <span class="math inline">\(R \sim \text{Binomial}(n, \pi)\)</span> 的原則來“精確”計算；</li>
<li>正態近似法計算。</li>
</ol>
<p>第一種方法被叫做精確法，並不是因爲它能夠精確計算恰好概率和等於 <span class="math inline">\(95\%\)</span> 的所有的 <span class="math inline">\(\pi\)</span>，而是因爲它利用的是樣本分佈的二項分佈屬性進行計算。然而隨着樣本量的增加，兩種方法計算的信賴區間結果越來越接近概率和 <span class="math inline">\(95\%\)</span>。</p>
</div>
<div id="exactprop" class="section level3">
<h3><span class="header-section-number">21.8.2</span> 二項分佈的“精確法”計算信賴區間</h3>
<p>例：樣本量 <span class="math inline">\(n=20\)</span>, 成功次數 <span class="math inline">\(r=5\)</span> 時，你可以用查水錶的辦法，也可以利用 R 進行精確計算</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1"><span class="kw">binom.test</span>(<span class="dv">5</span>, <span class="dv">20</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  5 and 20
## number of successes = 5, number of trials = 20, p-value = 0.04
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.08657 0.49105
## sample estimates:
## probability of success 
##                   0.25</code></pre>
<p>下面兩個圖分別展示了當 <span class="math inline">\(\pi\)</span> 等於精確法計算的下限和上限時的概率分佈。可以看出 <span class="math inline">\(\pi=0.0866\)</span> 時，<span class="math inline">\(\text{Prob}\{R \geqslant 5\} \leqslant 0.025\)</span>。同時，當 <span class="math inline">\(\pi = 0.4910\)</span> 時， <span class="math inline">\(\text{Prob}\{ R\leqslant 5 \} \leqslant 0.025\)</span></p>
<div class="figure" style="text-align: center"><span id="fig:ATfig2-1"></span>
<img src="bookdown_files/figure-html/ATfig2-1-1.png" alt="Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.0866" width="70%" />
<p class="caption">
圖 21.2: Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.0866
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ATfig2-2"></span>
<img src="bookdown_files/figure-html/ATfig2-2-1.png" alt="Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.4910" width="70%" />
<p class="caption">
圖 21.3: Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.4910
</p>
</div>
</div>
<div id="二項分佈的近似法計算信賴區間" class="section level3">
<h3><span class="header-section-number">21.8.3</span> 二項分佈的近似法計算信賴區間</h3>
<p>當 <span class="math inline">\(n\)</span> 較大時，百分比 <span class="math inline">\(P\)</span> 分佈 可以用正態分佈來近似：</p>
<p><span class="math display">\[
P\sim N(\pi, \sigma^2) \text{ where } \sigma^2 = \frac{\pi(1-\pi)}{n}
\]</span></p>
<p>總體均值用樣本百分比 <span class="math inline">\(p\)</span> 替代，方差用樣本方差 <span class="math inline">\(\hat\sigma^2 = \frac{p(1-p)}{n}\)</span>，因此，當樣本量較大時二項分佈的近似正態分佈特徵可以描述爲：</p>
<p><span class="math display">\[
P \sim N(p, \hat\sigma^2) \text{ where } \hat\sigma^2 = \frac{p(1-p)}{n}
\]</span></p>
<p>接下去對與百分比的信賴區間的計算就可以套用章節 <a href="#CImean">21.4</a> 中用到的均值信賴區間公式：</p>
<p><span class="math display" id="eq:AT2-16">\[
\begin{aligned}
&amp; P\pm z_{1-\alpha/2}\sqrt{\frac{P(1-P)}{n}}  \\
&amp; \text{ where } z_{1-\alpha/2} = 1.96 \text{ for } 95\% \text{CI}
\end{aligned}
\tag{21.11}
\]</span></p>
<p>正態近似法的好處是簡單，但是代價就是樣本量小時不準確。</p>
<p>例如：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(n=10, r=4, p=0.4\)</span> 時
<ul>
<li>精確法 <span class="math inline">\(95\%\)</span> 信賴區間：0.1216, 0.7376</li>
<li>正態近似法 <span class="math inline">\(95\%\)</span> 信賴區間：<span class="math inline">\(0.4\pm1.96\sqrt{\frac{0.4\times0.6}{10}} =\)</span> 0.0964, 0.7036</li>
</ul></li>
<li><span class="math inline">\(n=50, r=20, p=0.4\)</span> 時
<ul>
<li>精確法 <span class="math inline">\(95\%\)</span> 信賴區間：0.2641, 0.5482</li>
<li>正態近似法 <span class="math inline">\(95\%\)</span> 信賴區間： <span class="math inline">\(0.4\pm1.96\sqrt{\frac{0.4\times0.6}{50}} =\)</span> 0.2642, 0.5358</li>
</ul></li>
<li><span class="math inline">\(n=1000, r=400, p=0.4\)</span> 時
<ul>
<li>精確法 <span class="math inline">\(95\%\)</span> 信賴區間：0.3695, 0.4311</li>
<li>正態近似法 <span class="math inline">\(95\%\)</span> 信賴區間： <span class="math inline">\(0.4\pm1.96\sqrt{\frac{0.4\times0.6}{1000}} =\)</span> 0.3696, 0.4304</li>
</ul></li>
</ol>
<p>可以明顯看到隨着樣本量增加，信賴區間本身的範圍在不斷變小 (精確)。且正態近似法計算的信賴區間也越來越接近“精確法”。“Statistical Methods in Medical Research” <span class="citation">(Armitage, Berry, and Matthews <a href="#ref-Armitage2008" role="doc-biblioref">2008</a>)</span> 書中建議，滿足 <span class="math inline">\(n\pi \geqslant 10 \text{ or } n(1-\pi) \geqslant 10\)</span> 時，正態近似法可以給出較爲滿意的百分比的信賴區間估計。</p>
</div>
</div>
<div id="CIrate" class="section level2">
<h2><span class="header-section-number">21.9</span> 率的信賴區間</h2>
<div id="利用泊松分佈精確計算" class="section level3">
<h3><span class="header-section-number">21.9.1</span> 利用泊松分佈精確計算</h3>
<p>假設在一段時間 <span class="math inline">\(t\)</span> 內某事件發生的次數記爲 <span class="math inline">\(Y\)</span>。如果每個相同事件的發生相互獨立那麼 <span class="math inline">\(Y \sim \text{Poisson}(\mu t)\)</span>。樣本率 <span class="math inline">\(R=\frac{Y}{t}\)</span>，是人羣事件發生概率 <span class="math inline">\(\mu\)</span> 的無偏估計。</p>
<p><span class="math display">\[
\text{The probability that } Y=y \text{ is given by } \frac{(\mu t)^y e^{-\mu t}}{y!} \text{ for } y= 0,1,2,\cdots,\infty
\]</span></p>
<p>與前一節百分比的精確計算信賴區間相類似 (Section <a href="#exactprop">21.8.2</a>)，我們可以使用泊松分佈的性質進行計算：</p>
<ol style="list-style-type: decimal">
<li>尋找最小的 <span class="math inline">\(\mu_L\)</span> 滿足 <span class="math inline">\(\text{Prob}(\mu_L&gt;\mu) \leqslant 0.025\)</span></li>
<li>尋找最大的 <span class="math inline">\(\mu_U\)</span> 滿足 <span class="math inline">\(\text{Prob}(\mu_U&lt;\mu) \leqslant 0.025\)</span></li>
</ol>
<p>例：某核電站附近的村莊從1968年起的10年內，發生了 6 人死於白血病。平均死亡率爲 0.6/年。計算死亡率的95%信賴區間。</p>
<p>可以利用 R 的精確計算發病率的代碼 <code>poission.test</code> 來獲得精確法率的信賴區間：</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="kw">poisson.test</span>(<span class="dv">6</span>, <span class="dv">10</span>)</a></code></pre></div>
<pre><code>## 
##  Exact Poisson test
## 
## data:  6 time base: 10
## number of events = 6, time base = 10, p-value = 0.3
## alternative hypothesis: true event rate is not equal to 1
## 95 percent confidence interval:
##  0.2202 1.3059
## sample estimates:
## event rate 
##        0.6</code></pre>
</div>
<div id="利用正態近似法計算" class="section level3">
<h3><span class="header-section-number">21.9.2</span> 利用正態近似法計算</h3>
<p>當樣本量較大時，發生事件次數 <span class="math inline">\(Y\)</span> 近似服從正態分佈，其均值和方差均等於 <span class="math inline">\(\mu t\)</span> (參考 Section <a href="#poisson">6</a> 推導)：</p>
<p><span class="math display">\[
Y \sim N(\mu t, \sigma^2) \text{ where } \sigma^2=\mu t
\]</span></p>
<p>所以事件發生率 <span class="math inline">\(\mu\)</span> 的信賴區間公式爲 <span class="math inline">\(\frac{Y\pm 1.96\sqrt{Y}}{t}\)</span>。</p>
</div>
</div>
</div>
<div id="假設檢驗" class="section level1">
<h1><span class="header-section-number">第 22 章</span> 假設檢驗</h1>
<div id="拋硬幣的例子" class="section level2">
<h2><span class="header-section-number">22.1</span> 拋硬幣的例子</h2>
<p>對數據進行假設檢驗是統計分析最重要的部分。一般進行實驗或者調查時我們會先設定一個零假設。假如實驗或者調查中獲得的一系列數據可以認爲是相互獨立且隨機地從人羣中抽取的樣本，那麼根據零假設爲真的條件，樣本數據提供的參數估計和零假設條件下的參數應該是差距不大 (一致) 的。因爲概率論環境下，我們用樣本數據來作假設檢驗，如果樣本提供的數值比起零假設條件下的參數大很多或者小很多，我們就有理由，有證據拒絕零假設。</p>
<p>下面用投硬幣作爲例子說明。硬幣如果是公平的，那麼拋硬幣後正反面出現的概率應該一樣，都是 <span class="math inline">\(50\%\)</span> (零假設：<span class="math inline">\(p=0.5\)</span>)。假如有一枚硬幣，拋了 <span class="math inline">\(10\)</span> 次只有一次是反面朝上的，我們可能就會懷疑，這枚資本主義硬幣一定是被做了手腳 (變得不再公平了)，這就是通過實驗質疑和挑戰零假設的思想。如此粗糙的想法卻是統計學假設檢驗的理論起源。只是在統計學裏面，需要制定一些規則來規定，實驗數據跟零假設 (設想) 差異達到多大時 (檢驗)，認爲證據足夠達到相信零假設“非真” (挑戰權威)。</p>
<p>檢驗的過程，就是計算我們朝思暮想的 <span class="math inline">\(p\)</span> 值。<span class="math inline">\(p\)</span> 值的定義是，當零假設爲真時，我們<strong>觀察到的實驗結果以及比這個結果更加極端 (雙側) 的情況</strong>在所有可能的情況中出現的概率。繼續使用拋硬幣的例子來說的話，跟 “<span class="math inline">\(10\)</span> 次拋硬幣出現一次反面朝上” 一樣極端或者更加極端的事件有：</p>
<ul>
<li>“一次反面朝上”，</li>
<li>“零次反面朝上”，</li>
<li>“九次反面朝上 (或者說一次正面朝上)”，</li>
<li>“十次反面朝上 (或者說零次正面朝上)”。</li>
</ul>
<p>相反地，沒有觀察事件 “<span class="math inline">\(10\)</span> 次拋硬幣出現一次反面朝上” 那麼極端的事件就包括了：</p>
<ul>
<li>“兩次反面朝上”，</li>
<li>“三次反面朝上”，</li>
<li>“四次反面朝上”，</li>
<li>“五次反面朝上”，</li>
<li>“六次反面朝上”，</li>
<li>“七次反面朝上”，</li>
<li>“八次反面朝上”。</li>
</ul>
<p>檢驗的過程我們會定義一個被檢驗的統計量，一般就是我們感興趣的參數的估計 (estimator of a parameter of interest)。在上面拋硬幣的例子中，這個檢驗統計量就是 “硬幣反面朝上的次數”。觀察到的反面朝上次數除以拋硬幣次數 (<span class="math inline">\(10\)</span> 次) 就是獲得硬幣反面朝上的概率 (參數) 的估計。用 <span class="math inline">\(R\)</span> 表示十次拋硬幣中觀察到反面朝上的次數，那麼此時 <span class="math inline">\(R\)</span> 就是一個服從二項分佈的隨機變量，其服從的二項分佈成功 (反面朝上事件發生) 的概率 (參數) 是<span class="math inline">\(\pi\)</span>。所以某一次實驗中 (拋十次硬幣算一次實驗)，<span class="math inline">\(R=r\)</span>，那麼這次試驗的參數估計的 <span class="math inline">\(p\)</span> 值被定義爲：</p>
<p><span class="math display" id="eq:AT3-1">\[
\begin{equation}
\text{Prob}\{ R \text{ as or more extreme than } r | \pi=0.5 \}
\end{equation}
\tag{22.1}
\]</span></p>
<p>零假設：反面朝上出現的概率是 <span class="math inline">\(\pi=0.5\)</span>；替代假設： <span class="math inline">\(\pi\neq 0.5\)</span>。當零假設爲真時，<span class="math inline">\(R\sim \text{Bin}(10, 0.5)\)</span>，它的零假設分佈如下圖 <a href="#fig:ATfig3-1">22.1</a>：</p>
<div class="figure" style="text-align: center"><span id="fig:ATfig3-1"></span>
<img src="bookdown_files/figure-html/ATfig3-1-1.png" alt="Binomial distribution n=10, π = 0.5" width="80%" />
<p class="caption">
圖 22.1: Binomial distribution n=10, π = 0.5
</p>
</div>
<p>本節拋硬幣的例子我們觀察到十次拋硬幣只有一次反面朝上，<span class="math inline">\(r=1\)</span>。其發生的概率等於上面列舉的四種與之同等極端或者更加極端的情況發生概率之和：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Prob} \{R=0|\pi=0.5\} + \text{Prob} \{R=1|\pi=0.5\} + \text{Prob} \{R=9|\pi=0.5\} + \text{Prob} \{R=10|\pi=0.5\} \\
&amp; = (\binom{10}{0} + \binom{10}{1} + \binom{10}{9} + \binom{10}{10})\times(0.5)^{10} = 0.021
\end{aligned}
\]</span></p>
<div id="單側和雙側檢驗" class="section level3">
<h3><span class="header-section-number">22.1.1</span> 單側和雙側檢驗</h3>
<p>在上面的例子中其實我們已經用到了雙側檢驗的概念。例如，我們把 “九次反面朝上” 事件發生的概率當作和 “一次反面朝上” 事件發生的概率具有同等 “極端”概率事件，但是其實在圖 <a href="#fig:ATfig3-1">22.1</a> 中也能看出兩種事件發生的方向是在概率分佈的左右兩側，這就是典型的雙側檢驗思想。一個“單側”檢驗則不考慮另一個方向發生的極端事件。</p>
<p>還是用本節的例子，如果要計算單側檢驗 <span class="math inline">\(p\)</span> 值：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Prob}\{R\leqslant r| \pi=0.5\}\\
&amp;\text{In the example } r=1 \\
&amp;\Rightarrow \text{Prob}\{R=0 | \pi = 0.5\} + \text{Prob}\{ R=1 | \pi = 0.5 \} = 0.011
\end{aligned}
\]</span></p>
<p>此時零假設爲 <span class="math inline">\(\pi=0.5\)</span>，替代假設爲 <span class="math inline">\(\pi &lt; 0.5\)</span>。</p>
<p>大多數時候，單側檢驗的 <span class="math inline">\(p\)</span> 值十分接近雙側檢驗 <span class="math inline">\(p\)</span> 值的一半。但是實施單側假設檢驗的前提是，我們有絕對的把握事件不會發生另一個方向上，但是這種情況少之又少，所以基本上你能看到的絕大多數假設檢驗計算的 <span class="math inline">\(p\)</span> 值都是雙側檢驗 <span class="math inline">\(p\)</span> 值。</p>
</div>
<div id="p-值的意義" class="section level3">
<h3><span class="header-section-number">22.1.2</span> <span class="math inline">\(p\)</span> 值的意義</h3>
<p>假設檢驗被認爲是作決策的一種手段。你會看到一些人使用 <span class="math inline">\(0.05\)</span> 作閾值來作爲拒絕 (<span class="math inline">\(&lt;0.05\)</span>) 或接受 (<span class="math inline">\(&gt;0.05\)</span>) 零假設的依據。許多醫學實驗，醫學研究的結果確實是用來作決策的依據。例如某個臨牀試驗用隨機雙盲對照實驗法比較新藥物和已有藥物對某種疾病的治療效果差異，通過實驗結果來決定是否向市場和患者推廣新的治療藥物，此時 <span class="math inline">\(p\)</span> 值的大小就是作決斷的重大依據。然而還有另外的很多實驗/研究並非爲了作什麼直接的決策，可能只是爲了更多的瞭解疾病發生的原因和機制。例如可能乳腺癌多發在女性少發在男性人羣，這顯然是十分顯著的差異，但是這種結果不能讓我們決策說要不要改變一個人的性別，而只是提供了疾病發生發展過程的機理上的證據。因此，許多研究者主張<strong>把 <span class="math inline">\(p\)</span> 值大小當作是反對零假設證據的強弱指標</strong>。但是此處要指出的是，並非<strong>所有統計學家都認同 <span class="math inline">\(p\)</span> 值大小真的可以度量證據的強弱水平</strong>。</p>
<p>所以，建議在寫論文，作報告時，儘量避免說：“本次實驗研究結果具有顯著的統計學意義，there was evidence that the result was statistically significant”。建議使用的語言類似這樣：“在顯著性水平爲 5% 時，本研究結果達到了統計學意義，statistically significant at the 5% level”；或者 “在顯著性水平爲 5% 時，我們的研究提供了足夠的證據證明零假設是不正確的，there was evidence that at the 5% level, that the hypothesis being tested was incorrect”。</p>
<p>如果一個實驗結果 <span class="math inline">\(p\)</span> 值大於 0.05，可以被解讀爲：實驗結果不能提供足夠的證據證明零假設是錯誤的，there was no (or insufficient) evidence against the null hypothesis。另外還有一些人會使用一些詞語來描述 <span class="math inline">\(p\)</span> 值大小：如果 <span class="math inline">\(p=0.0001\)</span>，可能會被解讀爲實驗提供了“強有力的證據”，反對零假設；如果 <span class="math inline">\(p=0.06; p=0.04\)</span>，會被人解讀爲是具有“臨界統計學意義，borderline statistically significant”，或者試驗結果提供了“一些證據，some evidence” 反對零假設。</p>
</div>
<div id="p-值和信賴區間的關係" class="section level3">
<h3><span class="header-section-number">22.1.3</span> <span class="math inline">\(p\)</span> 值和信賴區間的關係</h3>
<p>總體參數 <span class="math inline">\(\mu\)</span> 如果真的被我們計算的估計值的 <span class="math inline">\(95\%\)</span> 信賴區間所包含，那麼 <span class="math inline">\(p &gt; 0.05\)</span>。如果參數 <span class="math inline">\(\mu\)</span> 不被計算的 <span class="math inline">\(95\%\)</span> 信賴區間所包含，那麼 <span class="math inline">\(p &lt; 0.05\)</span>。</p>
</div>
</div>
<div id="二項分佈的精確假設檢驗" class="section level2">
<h2><span class="header-section-number">22.2</span> 二項分佈的精確假設檢驗</h2>
<p>若 <span class="math inline">\(n\)</span> 次實驗中成功次數爲 <span class="math inline">\(R\)</span>，那麼樣本百分比 (估計，estimator) <span class="math inline">\(P=\frac{R}{n}\)</span> 是它的人羣比例 <span class="math inline">\(\pi\)</span> (參數，parameter) 的無偏估計。欲檢驗的零假設 <span class="math inline">\(\pi=\pi_0\)</span>，替代假設 <span class="math inline">\(\pi\neq\pi_0\)</span>，且某一次觀察結果爲 <span class="math inline">\(R=r\)</span>，我們要計算的 <span class="math inline">\(p\)</span> 值就是在零假設條件下，所有情況中 <span class="math inline">\(R=r\)</span> 或者與之同等極端甚至更加極端的事件所佔的比例。</p>
<ul>
<li>如果 <span class="math inline">\(r&lt;n\pi_0\)</span>，單側 <span class="math inline">\(p\)</span> 值等於</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
p &amp; = \text{Prob}\{ r\text{ or fewer successes out of n | \pi=\pi_0} \} \\
  &amp; = P_0 + P_1 + P_2 + \cdots + P_r \\
\text{Where } &amp; P_x = \binom{n}{x} \pi_0^x (1-\pi_0)^{n-x}
\end{aligned}
\]</span></p>
<ul>
<li>如果 <span class="math inline">\(r&gt;n\pi_0\)</span>，單側 <span class="math inline">\(p\)</span> 值等於</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
p &amp; = \text{Prob}\{ r\text{ or more successes out of n | \pi=\pi_0} \} \\
  &amp; = P_r + P_{r+1} + P_{r+2} + \cdots + P_{n} \\
\text{Where } &amp; P_x = \binom{n}{x} \pi_0^x (1-\pi_0)^{n-x}
\end{aligned}
\]</span></p>
<p>一般情況下兩個單側 <span class="math inline">\(p\)</span> 值很接近，所以雙側 <span class="math inline">\(p\)</span> 值就可以計算其中一個然後乘以 <span class="math inline">\(2\)</span>。你也可以計算兩側的單側 <span class="math inline">\(p\)</span> 值然後相加。</p>
</div>
<div id="當樣本量較大" class="section level2">
<h2><span class="header-section-number">22.3</span> 當樣本量較大</h2>
<p>如果樣本量 <span class="math inline">\(n\)</span> 比較大，那麼計算上面的精確法是十分繁瑣的 (計算器也會累。。。)。可以考慮利用中心極限定理用正態近似法進行假設檢驗。此時需要做的就是把近似後的正態分佈標準化，然後和標準正態分佈做比較獲得 <span class="math inline">\(p\)</span> 值即可：</p>
<p><span class="math display" id="eq:binapprox">\[
\begin{equation}
Z=\frac{R-E(R)}{\sqrt{\text{Var}(R)}} = \frac{R-E(R)}{\text{SE}(R)}
\end{equation}
\tag{22.2}
\]</span></p>
<p>在目前爲止人類所知道的範圍內，上面公式的 <span class="math inline">\(Z\)</span> 值隨着實驗樣本量 <span class="math inline">\(n\)</span> 的增加而無限接近標準正態分佈 <span class="math inline">\(N(0,1)\)</span>。</p>
</div>
<div id="二項分佈的正態近似法假設檢驗" class="section level2">
<h2><span class="header-section-number">22.4</span> 二項分佈的正態近似法假設檢驗</h2>
<p>二項分佈的特徵值：</p>
<p><span class="math display">\[
E(R) = n\pi_0; \text{ and Var}(R) = n\pi_0(1-\pi_0)
\]</span></p>
<p>套用公式 <a href="#eq:binapprox">(22.2)</a>，計算 <span class="math inline">\(Z\)</span> 值如下：</p>
<p><span class="math display">\[
\begin{aligned}
Z &amp; = \frac{R-E(R)}{\sqrt{\text{Var}(R)}} \\
  &amp; = \frac{R-n\pi_0}{\sqrt{n\pi_0(1-\pi_0)}} \\
  &amp; = \frac{P-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}} \\
\text{Where } &amp; P=\frac{R}{n}
\end{aligned}
\]</span></p>
<p>利用實驗數據的 <span class="math inline">\(p=r/n\)</span>，以及零假設時的 <span class="math inline">\(\pi_0\)</span>，就可以計算上面的觀察 <span class="math inline">\(Z\)</span> 值，之後查閱標準正態分佈的概率表格就可以獲得單側 <span class="math inline">\(p\)</span> 值，別忘了乘以 <span class="math inline">\(2\)</span>。</p>
<div id="連續性校正-continuity-correction" class="section level3">
<h3><span class="header-section-number">22.4.1</span> 連續性校正 continuity correction</h3>
<p>在使用正態分佈近似法進行二項分佈數據的假設檢驗時，我們其實是在使用一個連續型分佈近似一個離散型分佈，誤差通常會比較大。我們會使用矯正後的正態近似法計算 <span class="math inline">\(Z\)</span> 值：</p>
<p><span class="math display">\[
Z=\frac{|R-n\pi_0|-\frac{1}{2}}{\sqrt{n\pi_0(1-\pi_0)}}  \text{ or } Z=\frac{|P-\pi_0|-\frac{1}{2n}}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}
\]</span></p>
<p>“Statistical Methods in Medical Research” <span class="citation">(Armitage, Berry, and Matthews <a href="#ref-Armitage2008" role="doc-biblioref">2008</a>)</span> 書中建議，滿足 <span class="math inline">\(n\pi \geqslant 10 \text{ or } n(1-\pi) \geqslant 10\)</span> 時近似法計算的 <span class="math inline">\(p\)</span> 值可以給出較爲滿意的結果。另外，當 <span class="math inline">\(n&gt;100\)</span> 則建議不再進行連續性校正，即把校正部分的 <span class="math inline">\(-\frac{1}{2}\)</span> 或者 <span class="math inline">\(-\frac{1}{2n}\)</span> 去掉。</p>
</div>
</div>
<div id="AT3-5" class="section level2">
<h2><span class="header-section-number">22.5</span> 情況1：對均值進行假設檢驗 (方差已知)</h2>
<p>假設從已知方差 <span class="math inline">\((\sigma^2)\)</span> 的人羣中隨機抽取樣本進行血糖值測量 <span class="math inline">\((Y_n)\)</span>，該樣本測量的人羣的平均血糖值爲 <span class="math inline">\(\mu=\bar{Y}\)</span>，假設我們要比較該人羣的血糖值和某個理想血糖值 <span class="math inline">\(\mu_0\)</span>，進行假設檢驗：</p>
<p><span class="math display">\[\text{H}_0: \mu=\mu_0 \text{ v.s. H}_1: \mu\neq\mu_0\]</span></p>
<p>根據中心極限定理，當 <span class="math inline">\(n\)</span> 足夠大，樣本均值 <span class="math inline">\(\bar{Y}\)</span> 的分佈接近正態分佈，且均值 <span class="math inline">\(\mu\)</span>，方差 <span class="math inline">\(\frac{\sigma^2}{n}\)</span>。所以可以計算 <span class="math inline">\(Z\)</span> 值：</p>
<p><span class="math display">\[
Z = \frac{\bar{Y}-E(\bar{Y})}{\sqrt{\text{Var}\bar{Y}}} = \frac{\bar{Y}-\mu_0}{\sqrt{\sigma^2/n}}
\]</span></p>
<p>進而計算其 <span class="math inline">\(p\)</span> 值：</p>
<p><span class="math display">\[
\begin{aligned}
p &amp;= \text{Prob}(\bar{Y}\leqslant\bar{y}|\mu=\mu_0) \\
  &amp;= \text{Prob}(Z&lt;\frac{\bar{y}-\mu_0}{\sqrt{\sigma^2/n}}) \\
  &amp;= \Phi(\frac{\bar{y}-\mu_0}{\sqrt{\sigma^2/n}}) \\
\text{Where } &amp; \Phi \text{ is the distribution function for a } N(0,1) \text{distribution}
\end{aligned}
\]</span></p>
<p>所以計算了上面的單側 <span class="math inline">\(p\)</span> 值以後別忘了乘以 <span class="math inline">\(2\)</span> 以獲得雙側 <span class="math inline">\(p\)</span> 值：</p>
<p><span class="math display">\[
\text{Two-sided } p \text{ value } = 2\times[1-\Phi(\frac{\bar{y}-\mu_0}{\sqrt{\sigma^2/n}})]
\]</span></p>
</div>
<div id="OneSampleT" class="section level2">
<h2><span class="header-section-number">22.6</span> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</h2>
<p>如果方差未知，我們仍要比較一個樣本均值和一個數值的話，零假設和替代假設依然不變：</p>
<p><span class="math display">\[\text{H}_0: \mu=\mu_0 \text{ v.s. H}_1: \mu\neq\mu_0\]</span></p>
<p>但是此時計算的統計量的分母，總體方差的地方使用了樣本方差 <span class="math inline">\(\frac{\hat\sigma^2}{n}\)</span> 替代時，該統計量不再服從標準正態分佈，而服從自由度爲 <span class="math inline">\(n-1\)</span> 的 <span class="math inline">\(t\)</span> 分佈。<span class="math inline">\(t\)</span> 分佈看上去和標準正態分佈很像，但是其分佈的雙側尾部“較厚”，峯度大於 3：</p>
<p><span class="math display">\[
T = \frac{\bar{Y}-\mu_0}{\sqrt{\hat\sigma^2/n}} \sim t_{n-1}
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:tdistrifig"></span>
<img src="bookdown_files/figure-html/tdistrifig-1.png" alt="Student t distributions with 1, 4 and infinity degrees of freedom compared with a standard normal distribution" width="80%" />
<p class="caption">
圖 22.2: Student t distributions with 1, 4 and infinity degrees of freedom compared with a standard normal distribution
</p>
</div>
</div>
<div id="情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test" class="section level2">
<h2><span class="header-section-number">22.7</span> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</h2>
<p>配對 t 檢驗可以用於實驗前後數據的比較，或者是某兩個對象兩兩配對時的均值比較。這樣的實驗數據我們就可以去配對數據的差值，然後利用單樣本 t 檢驗比較這個配對數據的差是否等於零。</p>
</div>
</div>
<div id="相關-association" class="section level1">
<h1><span class="header-section-number">第 23 章</span> 相關 association</h1>
<div id="背景介紹" class="section level2">
<h2><span class="header-section-number">23.1</span> 背景介紹</h2>
<p>兩個變量如果相關 (associated)，那麼它們二者中的一個的分佈是依賴另一個的分佈的 the distribution of one is dependent on the value taken by the other and vice-versa。統計學中如何描述兩個變量之間的相關關係取決於兩個變量的性質 (連續型還是分類型，continuous or categorical variables)。本章討論不同情形下兩個變量相關關係及統計學上的假設檢驗方法。</p>
<p>兩個變量之間的關係除了可以用相關來描述，還可以利用迴歸的手段來分析。但是迴歸分析，和本章討論的相關性分析的本質區別在於，相關分析着重討論兩個變量的聯合分佈 (joint distribution)，而迴歸分析則是要探索一個變量在另一個變量的條件下的條件分佈 (conditional distribution)。因此，相關分析從某種意義上來說是對稱的 (X 與 Y 的相關性等同於 Y 與 X 的相關性)，迴歸分析則不然 (Y 對 X 的迴歸不等同與 X 對 Y 的迴歸)。</p>
<p>另外一個要點是，<strong>相關分析絕不討論因果關係。</strong></p>
</div>
<div id="兩個連續型變量的相關分析" class="section level2">
<h2><span class="header-section-number">23.2</span> 兩個連續型變量的相關分析</h2>
<div id="相關係數的定義" class="section level3">
<h3><span class="header-section-number">23.2.1</span> 相關係數的定義</h3>
<p>在概率論 (Section <a href="#correlation">8.2</a>) 中也已經介紹過相關係數 <span class="math inline">\(\rho\)</span> 的定義：</p>
<p><span class="math display" id="eq:AT4-1">\[
\begin{equation}
\rho=\frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{E(X-E(X))^2E(Y-E(Y))^2}} = \frac{\text{Cov}(X,Y)}{\sqrt{V(X)V(Y)}}
\end{equation}
\tag{23.1}
\]</span></p>
<p>用 <span class="math inline">\(\textbf{x}=\{x_1, x_2, \cdots, x_n \}\)</span> 和 <span class="math inline">\(\textbf{y}=\{ y_1, y_2, \cdots, y_n \}\)</span> 表示對 <span class="math inline">\(n\)</span> 個隨機研究對象測量的兩個變量。那麼這兩個變量的相關關係 <span class="math inline">\(r\)</span> 的計算式爲：</p>
<p><span class="math display" id="eq:AT4-2">\[
\begin{equation}
r = \frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}} = \frac{S_{xy}}{S_xS_y}
\end{equation}
\tag{23.2}
\]</span></p>
<p><span class="math inline">\(S_{xy}\)</span> 代表樣本數據的協方差 (Section <a href="#covariance">8.1</a>)，<span class="math inline">\(S_x\)</span> 是變量 <span class="math inline">\(X\)</span> 的樣本標準差 (有時會記爲 <span class="math inline">\(\hat\rho_x\)</span>)，<span class="math inline">\(S_y\)</span> 是變量 <span class="math inline">\(Y\)</span> 的樣本標準差。<span class="math inline">\(r\)</span> 被命名爲相關係數 <span class="math inline">\(\rho\)</span> 的 Pearson 积矩估計 (Pearson Product-Moment estimator)。</p>
</div>
<div id="相關係數的性質" class="section level3">
<h3><span class="header-section-number">23.2.2</span> 相關係數的性質</h3>
<div class="figure" style="text-align: center"><span id="fig:rho-char"></span>
<img src="img/Selection_101.png" alt="Examples of Peason correlation coefficients" width="100%" />
<p class="caption">
圖 23.1: Examples of Peason correlation coefficients
</p>
</div>
<p>上圖 <a href="#fig:rho-char">23.1</a> 描述了9種不同設定時的相關係數 <span class="math inline">\(r\)</span>。<span class="math inline">\(r\)</span> 的主要性質可以總結爲：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(r\)</span> 的取值範圍是 <span class="math inline">\(-1\sim1\text{, i.e. } -1\leqslant r \leqslant 1\)</span>；</li>
<li><span class="math inline">\(r&gt;0\)</span> 時，二者呈正相關， <span class="math inline">\(r&lt;0\)</span> 時，二者呈負相關；</li>
<li>當且僅當兩個變量的散點圖呈現圖 <a href="#fig:rho-char">23.1</a> 中 A，B 顯示的直線時才有 <span class="math inline">\(|r|=1\)</span>，然而直線的坡度卻與相關係數無關；</li>
<li>如果兩個變量之間沒有<strong>直線的 linear</strong>相關關係，那麼相關係數 <span class="math inline">\(r\)</span> 會接近於零；</li>
<li>求 X 和 Y 的相關係數，等同於求 Y 和 X 的相關係數 (<strong>與迴歸不同</strong>)；</li>
<li>相關係數 <span class="math inline">\(r\)</span> 沒有單位，並且位置不會發生改變 (location invariant)，如果兩個變量乘以或者除以，加上或者減去任意常數，不會改變相關係數的大小 (<strong>與迴歸不同</strong>)。</li>
</ol>
<p>圖 <a href="#fig:rho-char">23.1</a> 中 F 顯示的相關關係可以看出，<span class="math inline">\(r\)</span> 受異常值的影響很大，如果將右上角的異常值從數據中去除掉的話，該圖中的相關係數會變小到幾乎爲零。G 和 H 則表示非線性相關時，Pearson 相關係數不適用。I 則告訴我們如果不熟悉數據本身的分佈的話，如果只看總體的相關是多麼的危險 (總體爲負相關，但是在不同的分層數據中卻是呈正相關的)。</p>
</div>
<div id="對相關係數是否爲零進行假設檢驗" class="section level3">
<h3><span class="header-section-number">23.2.3</span> 對相關係數是否爲零進行假設檢驗</h3>
<p>在線性迴歸 (Section <a href="#t-r2-F">27.6</a>) 中會討論和證明 Pearson 相關係數和統計量 <span class="math inline">\(t\)</span> 之間的關係，該公式也被用於檢驗相關係數是否爲零：</p>
<p><span class="math display" id="eq:AT4-3">\[
\begin{equation}
T=r\sqrt{\frac{n-2}{1-r^2}} \sim t_{n-2}
\end{equation}
\tag{23.3}
\]</span></p>
</div>
<div id="相關係數的-95-信賴區間" class="section level3">
<h3><span class="header-section-number">23.2.4</span> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</h3>
<p>如果要計算相關係數 <span class="math inline">\(r\)</span> 的信賴區間，我們需要知道兩個變量 <span class="math inline">\(X,Y\)</span> 之間的聯合分佈 (joint distribution)。<span class="math inline">\(X,Y\)</span> 如果服從二元正態分佈，可以利用 Fisher’s Z-transformation 計算相關係數的信賴區間。圖 <a href="#fig:binormal">23.2</a> 完美展示了兩個服從二元正態分佈的三維立體概率密度分布圖。可以用鼠標拖動下面那個三維圖，就能理解什麼叫做二元正態分佈。就是無論是在 X 軸看 Y，還是在 Y 軸看 X，每一個切面都呈現正態分佈。因此二元正態分佈的概率密度方程繪製出來是成爲一個完美的鍾罩形狀。很美吧！</p>
<p><span class="math display">\[
X|Y \sim N(\mu_x, \sigma_x^2) \text{ AND } Y|X \sim N(\mu_y, \sigma_y^2)
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:binormal"></span>
<img src="bookdown_files/figure-html/binormal-1.png" alt="Bivariate normal distribution of X and Y" width="100%" />
<p class="caption">
圖 23.2: Bivariate normal distribution of X and Y
</p>
</div>
<p>如果 <span class="math inline">\(\rho\neq0\)</span>，相關係數的樣本分佈雖然不是正態分佈，但是只要 <span class="math inline">\(X,Y\)</span> 服從上面的圖形顯示的二元正態分佈，就可以利用Fisher’s Z-transformation 公式計算統計量 <span class="math inline">\(Z_r\)</span>：</p>
<p><span class="math display" id="eq:AT4-4">\[
\begin{equation}
Z_r = \frac{1}{2}\text{log}_e(\frac{1+r}{1-r}) = \text{tanh}^{-1} (r)
\end{equation}
\tag{23.4}
\]</span></p>
<p><span class="math inline">\(Z_r\)</span>，近似服從正態分佈：</p>
<p><span class="math display" id="eq:AT4-5">\[
\begin{equation}
Z_r \sim N(\frac{1}{2}\text{log}_e(\frac{1+\rho}{1-\rho}), \frac{1}{n-3})
\end{equation}
\tag{23.5}
\]</span></p>
<p>利用這個性質，我們可以計算 <span class="math inline">\(Z_\rho\)</span> 的信賴區間，然後再通過逆運算轉換之後獲得 <span class="math inline">\(\rho\)</span> 的信賴區間：</p>
<p><span class="math display" id="eq:AT4-6">\[
\begin{equation}
\rho = \frac{exp(2Z_\rho)-1}{exp(2Z_\rho)+1} = \text{tanh}(Z_\rho)
\end{equation}
\tag{23.6}
\]</span></p>
</div>
<div id="比較兩個相關係數是否相等" class="section level3">
<h3><span class="header-section-number">23.2.5</span> 比較兩個相關係數是否相等</h3>
<p>假設需要比較兩個相關係數，可以繼續使用 Fisher’s Z-transformation 計算相關係數之差的統計量，<strong>它服從標準正態分佈</strong> <span class="math inline">\(N(0,1)\)</span>。很少會碰到比較兩個相關係數，但是偶爾碰到的實例有這樣的：要比較男性和女性之間，食鹽攝入量和血壓的相關關係是否相同。</p>
<p><span class="math display">\[
\text{Test statistics} = \frac{Z_{r_2}-Z_{r_1}}{\sqrt{\frac{1}{n_2-3}+\frac{1}{n_1-3}}} \sim N(0,1)
\]</span></p>
<p>在實際應用中，其實相關係數的比較意義並不是很大。更常見的是使用迴歸分析的手段比較兩個人羣 (男性女性) 中血壓和食鹽攝入量的迴歸係數 (即，性別對實驗和血壓的關係是否產生了交互作用，interaction)。</p>
</div>
<div id="相關係數那些事兒" class="section level3">
<h3><span class="header-section-number">23.2.6</span> 相關係數那些事兒</h3>
<p>醫學文獻中你會碰見非常多的人使用相關係數，但是相信我，許多人都用錯了。其實比起相關係數，能提供更多信息的手段是進行迴歸分析。下面羅列一些常見的錯誤使用相關係數的例子：</p>
<div class="figure" style="text-align: center"><span id="fig:rho-restrict"></span>
<img src="img/Selection_102.png" alt="Effect of data restrictions on the Pearson correlation coefficient" width="80%" />
<p class="caption">
圖 23.3: Effect of data restrictions on the Pearson correlation coefficient
</p>
</div>
<ol style="list-style-type: decimal">
<li>圖 <a href="#fig:rho-restrict">23.3</a> 展示了同樣的一組數據，如果只是斷章取義，其相關係數可能發生極大的變化。所以，想用相關係數作合理的統計推斷，必須保證數據的完整性，否則就有玩弄數據之嫌。然而，如果你用的是線性迴歸的方法，受數據限制 (data restriction) 的影響就幾乎可以忽略不計。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:regre-to-mean"></span>
<img src="img/Selection_103.png" alt="Effect of regression to the mean" width="80%" />
<p class="caption">
圖 23.4: Effect of regression to the mean
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li><p>均數迴歸現象，regression to the mean phenomenon，是指在進行重複測量時，前次測量中獲得的極高或極低分數會在後期測量時傾向於向平均值偏移，即隨着時間的推移，高分者成績下降，低分者成績升高的一種自然迴歸效應。所以在一些臨牀實驗中宣稱自己發現的測量值的變化和基線值之間的相關關係 (correlation between initial measurement and a change in that measurement)，其實是一種自然現象而不是真的存在什麼相關關係，如圖 <a href="#fig:regre-to-mean">23.4</a>。要避免這樣的低級失誤，可以計算測量值的變化 (<span class="math inline">\(X_2-X_1\)</span>) 和前後兩次測量值的均值 (<span class="math inline">\((X_2+X_1)/2\)</span>) 之間的相關關係。</p></li>
<li><p>有些科學家聲稱自己用迴歸係數來衡量兩個變量之間的一致性 (assess agreement between variables)，這當然是完全錯誤的。兩個變量之間高度相關，和他們高度一致是完全不同的概念 (單位，測量方法，可能都不一樣怎麼可能一致呢)。你完全可以將同一個變量乘以2以後和它原來的值作相關分析，就會發現二者相關係數等於 1，但是二者數值上相差兩倍。</p></li>
</ol>
<p>一般來說，迴歸模型 (regression models) 顯得比 Pearson 相關係數更加實用，能提供更多的信息用於推斷 (甚至是用一個值的變化預測另一個變量的大小)，也能避免上面舉例的錯誤使用。</p>
</div>
<div id="在-r-裏面計算相關係數" class="section level3">
<h3><span class="header-section-number">23.2.7</span> 在 R 裏面計算相關係數</h3>
<div class="figure" style="text-align: center"><span id="fig:age-hei"></span>
<img src="bookdown_files/figure-html/age-hei-1.png" alt="Association between age and height in children aged 6-36 months" width="80%" />
<p class="caption">
圖 23.5: Association between age and height in children aged 6-36 months
</p>
</div>
<p>在 R 裏面用 <code>cor()</code> 可以簡單的獲得兩個變量之間的相關係數，<code>cor.test()</code> 可以用於獲得相關係數的信賴區間和是否爲零的假設檢驗結果：</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1"><span class="kw">cor</span>(growgam1<span class="op">$</span>age, growgam1<span class="op">$</span>len)</a></code></pre></div>
<pre><code>## [1] 0.8676</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" title="1"><span class="kw">cor.test</span>(growgam1<span class="op">$</span>age, growgam1<span class="op">$</span>len)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  growgam1$age and growgam1$len
## t = 24, df = 188, p-value &lt;2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.8275 0.8990
## sample estimates:
##    cor 
## 0.8676</code></pre>
</div>
</div>
<div id="二元變量之間的相關性-association-between-pairs-of-binary-variables" class="section level2">
<h2><span class="header-section-number">23.3</span> 二元變量之間的相關性 association between pairs of binary variables</h2>
<p>兩個二元變量之間的相關性常用比值比 Odds Ratio (OR) 來衡量。跟連續型變量的 Pearson 相關係數一樣，二元變量之間的比值比也是一種對稱的特徵值。所以，X 對於 Y 的 OR，和 Y 對於 X 的 OR 是一樣的。令 <span class="math inline">\(\pi_{ij}\)</span> 表示 <span class="math inline">\(X=i, Y=j\)</span> 時的概率。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表23.1： Population parameters in a <span class="math inline">\(2\times2\)</span> contingency table
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 1\)</span>
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{0\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{1\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{\cdot 0}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{\cdot 1}\)</span>
</td>
<td style="text-align:center;">
1
</td>
</tr>
</tbody>
</table>
<p>利用表格可以看出，求 Y 對 X 的 OR 計算式爲 (horizontal)：</p>
<p><span class="math display">\[
\Psi = \frac{\pi_{00}/\pi_{01}}{\pi_{10}/\pi_{11}} = \frac{\pi_{00}\times\pi_{11}}{\pi_{10}\times\pi_{01}}
\]</span></p>
<p>求 X 對 Y 的 OR 計算式爲 (vertical)：</p>
<p><span class="math display">\[
\Psi = \frac{\pi_{00}/\pi_{10}}{\pi_{01}/\pi_{11}} = \frac{\pi_{00}\times\pi_{11}}{\pi_{10}\times\pi_{01}}
\]</span></p>
<p>可見兩個計算 OR (parameter) 值關係的計算式是完全等價的。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表23.2： Observed data in a <span class="math inline">\(2\times2\)</span> contingency table
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 1\)</span>
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{0\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{1\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot 0}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot 1}\)</span>
</td>
<td style="text-align:center;">
1
</td>
</tr>
</tbody>
</table>
<p>所以用觀察數據 (Observed data, all “O”s in the table) 替代掉 OR 計算式中的 <span class="math inline">\(\pi\)</span> 可得觀察數據的 OR 估計值 (estimator) 的計算公式：</p>
<p><span class="math display" id="eq:AT4-8">\[
\begin{equation}
\hat\Psi = \frac{\hat\pi_{00}\times\hat\pi_{11}}{\hat\pi_{10}\times\hat\pi_{01}} = \frac{O_{00}\times O_{11}}{O_{10}\times O_{01}}
\end{equation}
\tag{23.7}
\]</span></p>
<div id="or-的信賴區間" class="section level3">
<h3><span class="header-section-number">23.3.1</span> OR 的信賴區間</h3>
<p>由於 OR 是乘法計算的結果，我們習慣上使用對數轉換 OR 以後 <span class="math inline">\((\text{log}(\hat\Psi))\)</span> 計算完對稱的 95% 信賴區間，然後再通過對數的反函數獲得 OR 的 95% 信賴區間。</p>
<p>樣本量足夠大時， <span class="math inline">\(\text{log}(\hat\Psi)\)</span> 的分佈是正態分佈，標準誤 (standard error) 是：</p>
<p><span class="math display" id="eq:ORse">\[
\begin{equation}
\sqrt{\frac{1}{N\pi_{00}}+\frac{1}{N\pi_{01}}+\frac{1}{N\pi_{10}}+\frac{1}{N\pi_{11}}}
\end{equation}
\tag{23.8}
\]</span></p>
<p>其中 <span class="math inline">\(N\pi_{ij}\)</span> 表示的是 <span class="math inline">\(2\times2\)</span> 表格中四個觀察數據的觀察樣本量 (sample size in the contingency table)。</p>
<p>所以一個 OR 的信賴區間的計算流程如下：</p>
<ol style="list-style-type: decimal">
<li>計算 OR 值 <span class="math inline">\(\hat\Psi\)</span> (用公式 <a href="#eq:AT4-8">(23.7)</a>)；</li>
<li>取對數 <span class="math inline">\(\text{log}\Psi\)</span>；</li>
<li>求 <span class="math inline">\(\text{SE}(\text{log}\Psi)\)</span> (用公式 <a href="#eq:ORse">(23.8)</a>)；</li>
<li>計算 <span class="math inline">\(\text{log}\Psi\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間：<span class="math inline">\(\text{log}\Psi \pm 1.96\text{SE}(\text{log}\Psi)\)</span>；</li>
<li>求獲得的 <span class="math inline">\(\text{log}\Psi\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的下限上限的對數的反函數 (自然底數的指數函數) 作爲 OR <span class="math inline">\(\hat\Psi\)</span> 值的信賴區間。</li>
</ol>
</div>
<div id="比值比的假設檢驗" class="section level3">
<h3><span class="header-section-number">23.3.2</span> 比值比的假設檢驗</h3>
<p>比值比 OR 假設檢驗時的零假設爲，二者不相關，比值比 <span class="math inline">\(\Psi=1\)</span>。所以：<span class="math inline">\(\text{H}_0: \Psi = 1 \text{ or log}_e(\Psi) = 0\)</span>。</p>
<p>這個零假設可以用計算信賴區間時的性質進行：</p>
<p><span class="math display">\[
z=\frac{\text{log}(\hat\Psi)}{SE(\text{log}_e(\Psi))} \sim N(0,1)
\]</span></p>
<p>另外更加常用的檢驗 OR 值是否等於 1 的檢驗方法有下面兩種：</p>
<ol style="list-style-type: decimal">
<li>樣本量大時：<span class="math inline">\(\chi^2\)</span> 的擬合優度檢驗 goodness of fit test；</li>
<li>小樣本時：Fisher 的精確檢驗法 Fisher’s exact test。</li>
</ol>
</div>
<div id="chisquaretest" class="section level3">
<h3><span class="header-section-number">23.3.3</span> 兩個百分比的卡方檢驗</h3>
<p>檢驗統計量如下：</p>
<p><span class="math display" id="eq:AT4-9">\[
\begin{aligned}
\chi^2 &amp;= \sum_i\sum_i(\frac{(O_{ij}-E_{ij})^2}{E_{ij}})  \\
\text{Where } &amp;E_{ij} = \frac{O_{i\cdot}\times O_{\cdot j}}{O_{\cdot\cdot}}
\end{aligned}
\tag{23.9}
\]</span></p>
<p>計算獲得了卡方值之後和自由度爲 1 的卡方分佈相比較獲得雙側 <span class="math inline">\(p\)</span> 值。</p>
<p><strong>優化版本</strong> 用連續性校正法：</p>
<p><span class="math display" id="eq:AT4-10">\[
\begin{aligned}
\chi^2 &amp;= \sum_i\sum_i(\frac{(|O_{ij}-E_{ij}| - 0.5)^2}{E_{ij}})  \\
\text{Where } &amp;E_{ij} = \frac{O_{i\cdot}\times O_{\cdot j}}{O_{\cdot\cdot}}
\end{aligned}
\tag{23.10}
\]</span></p>
</div>
<div id="確切檢驗法-fishers-exact-test" class="section level3">
<h3><span class="header-section-number">23.3.4</span> 確切檢驗法 Fisher’s “exact” test</h3>
<p>如果 <span class="math inline">\(2\times2\)</span> 表格中的四個數字的 <strong>期待值</strong> 均大於 5，那麼用上面的卡方檢驗沒有問題，如果期待值都很小，就建議要使用精確檢驗法。
確切檢驗法的思想理論是超幾何分佈 (Section <a href="#hyperdist">5.2</a>)，在四個表格邊緣合計固定不變的條件下，利用下面公式 <a href="#eq:AT4-Fisher">(23.11)</a> 直接計算表內四個格子數據的<strong>各種組合</strong>的概率，然後計算單側或者雙側累計概率，與顯著性水平 <span class="math inline">\(\alpha\)</span> 比較。</p>
<p><span class="math display" id="eq:AT4-Fisher">\[
\begin{aligned}
P_{O_{00}} &amp; = \text{Prob}(O_{00},O_{01},O_{10},O_{11}|O_{0\cdot},O_{1\cdot},O_{\cdot0},O_{\cdot1}) \\
    &amp; = \frac{O_{0\cdot}!O_{1\cdot}!O_{\cdot0}!O_{\cdot1}!}{O_{\cdot\cdot}!O_{00}!O_{01}!O_{10}!O_{11}!}
\end{aligned}
\tag{23.11}
\]</span></p>
<p>在 R 裏可以用 <code>fisher.test</code> 對四格表內容進行確切檢驗。</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">x3 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">5</span>,<span class="dv">3</span>,<span class="dv">8</span>), <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb52-2" title="2"><span class="kw">addmargins</span>(x3)</a></code></pre></div>
<pre><code>##           Sum
##      7  5  12
##      3  8  11
## Sum 10 13  23</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1"><span class="kw">fisher.test</span>(x3)</a></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  x3
## p-value = 0.2
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##   0.4942 31.9433
## sample estimates:
## odds ratio 
##      3.513</code></pre>
</div>
</div>
<div id="多分類-無排序-的情況-mtimes-n-表格" class="section level2">
<h2><span class="header-section-number">23.4</span> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</h2>
<p>卡方檢驗可以推廣到兩個多分類變量之間的相關分析。</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \chi^2 = \sum_i\sum_j(\frac{(O_{ij}-E_{ij})^2}{E_{ij}}) \\
&amp; \text{Where } E_{ij} = \frac{O_{i\cdot}O_{\cdot j}}{O_{\cdot\cdot}} \\
&amp; \text{Under H}_0: \chi^2 \sim \chi^2_{(m-1)\times(n-1)}
\end{aligned}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表23.3： Observed data in a <span class="math inline">\(M\times N\)</span> contingency table
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 1\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = 2\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y = n\)</span>
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{12}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{1n}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{1\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = 2\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{21}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{22}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{2n}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{2\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X = m\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{m1}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{m2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{mn}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{m\cdot}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot 1}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot 2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot n}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(O_{\cdot\cdot}\)</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="比較-comparisons" class="section level1">
<h1><span class="header-section-number">第 24 章</span> 比較 Comparisons</h1>
<ul>
<li>本章暫且只討論<strong>兩組之間</strong>的比較 (均值，方差，百分比)；</li>
<li>本章也只討論兩種類型的變量，<strong>連續型和二分類型變量</strong>；</li>
<li>本章會介紹點估計 (point estimation)，信賴區間計算 (confidence intervals)，假設檢驗 (hypothesis testing)。</li>
</ul>
<div id="比較兩個均值-comparing-two-population-means" class="section level2">
<h2><span class="header-section-number">24.1</span> 比較兩個均值 comparing two population means</h2>
<div id="當方差已知且數據服從正態分佈-z-test" class="section level3">
<h3><span class="header-section-number">24.1.1</span> 當方差已知，且數據服從正態分佈 Z-test</h3>
<p>令 <span class="math inline">\(Y_{1i} (i=1,2,\cdots, n_1); Y_{2i} (i=1,2,\cdots, n_2)\)</span> 表示兩個獨立且隨機的變量，他們來自兩個人羣 (1 和 2)，且各自的人羣均值爲 <span class="math inline">\(\mu_k\)</span>，方差爲 <span class="math inline">\(\sigma_k^2\)</span>：</p>
<p><span class="math display">\[
E(Y_{ki})=\mu_k \text{ and Var}(Y_{ki}) = \sigma_k^2 \text{ for } k=1,2 \text{ and } i= 1,2,\cdots,n_k
\]</span></p>
<p>用樣本均值 <span class="math inline">\(\bar{Y}_k\)</span> 作爲總體均值 <span class="math inline">\(\mu_k\)</span> 的估計：</p>
<p><span class="math display">\[
\bar{Y}_k \sim N(\mu_k, \frac{\sigma_k^2}{n_k}) \text{ for } k=1,2
\]</span></p>
<p>如果兩個樣本的觀察值互相獨立，我們知道均值差 <span class="math inline">\(\bar{Y}_2 - \bar{Y}_1\)</span>，也服從下面描述的正態分佈：</p>
<p><span class="math display" id="eq:AT5-1">\[
\begin{equation}
\bar{Y}_2-\bar{Y}_1  \sim N(\mu_2-\mu_1, \frac{\sigma^2_2}{n_2}+\frac{\sigma^2_1}{n_1})
\end{equation}
\tag{24.1}
\]</span></p>
<p>根據這個性質，可以計算均值差的統計量 <span class="math inline">\(Z\)</span>：</p>
<p><span class="math display" id="eq:AT5-2">\[
\begin{equation}
Z=\frac{\bar{Y}_2-\bar{Y}_1}{\sqrt{(\sigma_2^2/n_2)+(\sigma_1^2)/n_1}} \sim N(\frac{\mu_2-\mu_1}{\sqrt{(\sigma_2^2/n_2)+(\sigma_1^2)/n_1}},1)
\end{equation}
\tag{24.2}
\]</span></p>
<p>所以 <span class="math inline">\(\bar{Y}_2-\bar{Y}_1\)</span> 的樣本分佈 <a href="#eq:AT5-2">(24.2)</a>，就可以應用於爲 <span class="math inline">\(\mu_2-\mu_1\)</span> 計算顯著性水平爲 <span class="math inline">\(\alpha\)</span> 的 <span class="math inline">\(100(1-\alpha)\%\)</span> 信賴區間，或者進行假設檢驗。</p>
<p>用信賴區間章節 (Section <a href="#CImean">21.4</a>) 學到的方法，均值差的信賴區間的下限 <span class="math inline">\(L\)</span>，和上限 <span class="math inline">\(U\)</span>，分別是：</p>
<p><span class="math display">\[
\begin{aligned}
L &amp; = (\bar{Y}_2 - \bar{Y}_1) + z_{\alpha/2}\sqrt{\frac{\sigma_2^2}{n_2}+\frac{\sigma_1^2}{n_1}}\\
U &amp; = (\bar{Y}_2 - \bar{Y}_1) + z_{1-\alpha/2}\sqrt{\frac{\sigma_2^2}{n_2}+\frac{\sigma_1^2}{n_1}}
\end{aligned}
\]</span></p>
<p>由於標準正態分佈左右對稱 <span class="math inline">\(z_{\alpha/2}=-z_{1-\alpha/2}\)</span>，所以<span class="math inline">\(100(1-\alpha)\%\)</span> 信賴區間爲：</p>
<p><span class="math display" id="eq:AT5-3">\[
\begin{equation}
(\bar{Y}_2 - \bar{Y}_1) \pm z_{1-\alpha/2}\sqrt{\frac{\sigma_2^2}{n_2}+\frac{\sigma_1^2}{n_1}}
\end{equation}
\tag{24.3}
\]</span></p>
<p>進行均值差的假設檢驗時，零假設是均值差等於零 <span class="math inline">\(\text{H}_0: \mu_2-\mu_1 = 0\)</span>；替代假設是均值差不等於零 <span class="math inline">\(\text{H}_1: \mu_2-\mu_1\neq0\)</span>。</p>
<p>在零假設條件下 <span class="math inline">\(\mu_2-\mu_1 = 0\)</span>，公式 <a href="#eq:AT5-2">(24.2)</a> 計算的均值差的檢驗統計量 <span class="math inline">\(Z\)</span> 服從標準正態分佈 <span class="math inline">\(Z\sim N(0,1)\)</span>。根據章節 <a href="#AT3-5">22.5</a> 同理知雙側 <span class="math inline">\(p\)</span> 值的計算式爲：</p>
<p><span class="math display" id="eq:AT5-4">\[
\begin{equation}
2[1-\Phi(\frac{|\bar{y}_2-\bar{y}_1|}{\sqrt{(\sigma_2^2/n_2)+(\sigma_1^2/n_1)}})]
\end{equation}
\tag{24.4}
\]</span></p>
<p>此時，我們進行的假設檢驗，計算的信賴區間用到的前提有：</p>
<ol style="list-style-type: decimal">
<li>兩組的觀察數據 <span class="math inline">\(Y_{ki}\)</span> 均服從正態分佈；</li>
<li>所有的觀察對象互相獨立；</li>
<li>兩組數據來自的人羣的方差已知。</li>
</ol>
<p>違反這些前提的話：
1. 如果不滿足前提 1，對統計結果影響不會很大，只要觀察樣本較大，均值或者均值差本身的樣本分佈也就服從了正態分佈 (中心極限定理)；
2. 如果不滿足前提 2，則不應該採用此方法，觀察對象本身如果有一定的結構構成或者不滿足相互獨立，本方法不適用；
3. 前提 3，大多數現實例子中都不太可能滿足，因爲總體/人羣的方差多數情況下都是未知的，所以，下一小節討論方差未知的情況，逐漸放寬我們的統計分析前提條件。</p>
</div>
<div id="當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test" class="section level3">
<h3><span class="header-section-number">24.1.2</span> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</h3>
<p>如果兩組數據來自的人羣可以被認爲方差是齊的 <span class="math inline">\(\sigma_1^2=\sigma_2^2=\sigma^2\)</span>，公式 <a href="#eq:AT5-1">(24.1)</a> 可以變爲：</p>
<p><span class="math display">\[
\bar{Y}_2-\bar{Y}_1 \sim N(\mu_2-\mu_1, \sigma^2(\frac{1}{n_2}+\frac{1}{n_1}))
\]</span></p>
<p>但是這個分佈中的方差是未知的，所以除了均值和均值差，這個共同的方差也變成了需要用樣本方差 <span class="math inline">\(\hat{\sigma}^2\)</span> 來作估計。此時，兩個樣本的方差的無偏估計爲，<strong>加權方差</strong>：</p>
<p><span class="math display" id="eq:AT5-5">\[
\begin{equation}
\hat\sigma^2 = \frac{(n_1-1)\hat\sigma^2_1+(n_2-1)\hat\sigma^2_2}{n_1+n_2-2}
\end{equation}
\tag{24.5}
\]</span></p>
<p>因爲 <span class="math inline">\(\frac{(n_1-1)\hat\sigma^2_1}{\sigma^2} \sim \chi^2_{n_1-1}; \frac{(n_2-1)\hat\sigma^2_2}{\sigma^2} \sim \chi^2_{n_2-1}\)</span>，所以兩樣本的加權方差 <span class="math inline">\(\hat\sigma^2\)</span> 服從自由度爲 <span class="math inline">\(n_1+n_2-2\)</span> 的卡方分佈：</p>
<p><span class="math display">\[
\frac{(n_1+n_2-2)\hat\sigma^2_1}{\sigma^2} \sim \chi^2_{n_1+n_2-2}
\]</span></p>
<p>所以，此時的檢驗統計量 <span class="math inline">\(T\)</span>，服從自由度爲 <span class="math inline">\(n_1+n_2-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈：</p>
<p><span class="math display">\[
T=\frac{(\bar{Y}_2-\bar{Y}_1) - (\mu_2-\mu_1)}{\hat\sigma\sqrt{(1/n_2)+(1/n_1)}} \sim t_{n_1+n_2-2}
\]</span></p>
<p>接下來就可以利用這個統計量進行假設檢驗，求均值差的 <span class="math inline">\(100(1-\alpha)\%\)</span> 信賴區間，類比章節 <a href="#AT2-5">21.5</a>：</p>
<p><span class="math display">\[
(\bar{Y}_2-\bar{Y}_1) \pm t_{n_1+n_2-2, 1-\alpha/2}\hat\sigma\sqrt{(1/n_2)+(1/n_1)}
\]</span></p>
</div>
<div id="練習-1" class="section level3">
<h3><span class="header-section-number">24.1.3</span> 練習</h3>
<p>下表展示的是，隨機將11名嬰兒分配到實驗組和對照組，記錄嬰兒能夠獨立行走的月齡。試用表格總結的數據進行能獨立行走的月齡的均值是否在實驗組和對照組之間有差異的假設檢驗，並求月齡均差的 <span class="math inline">\(95\%\)</span> 信賴區間。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 24.1: Children’s ages at time of first walking alone by randomisation group
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Age in months for walking alone
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Active exercise group (i=1)
</th>
<th style="text-align:center;">
Eight week control group (i=2)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
9.00, 9.50, 9.75, 10.00, 13.00, 9.50
</td>
<td style="text-align:center;">
13.25, 11.50, 12.00, 13.50, 11.50
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(n_i\)</span>
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\bar{Y}_i\)</span>
</td>
<td style="text-align:center;">
10.125
</td>
<td style="text-align:center;">
12.350
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\hat\sigma_i\)</span>
</td>
<td style="text-align:center;">
1.447
</td>
<td style="text-align:center;">
0.962
</td>
</tr>
</tbody>
</table>
<p><strong>解</strong></p>
<p>假設 <span class="math inline">\(\text{H}_0: \mu_2-\mu_1 = 0 \text{ v.s } \text{H}_1: \mu_2-\mu_1 \neq 0\)</span></p>
<p>假如，實驗組對照組的月齡方差可以認爲是方差相同的，那麼他們的加權方差則可以計算爲：</p>
<p><span class="math display">\[
\hat\sigma^2 = \frac{(6-1)\times(1.447)^2+(5-1)\times(0.962)^2}{6+5-2} = \frac{14.172}{9} = 1.575
\]</span></p>
<p>零假設條件下，則檢驗統計量 <span class="math inline">\(T\)</span> 服從自由度爲 <span class="math inline">\(9\)</span> 的 <span class="math inline">\(t\)</span> 分佈，本例的數據給出的檢驗統計量大小爲：</p>
<p><span class="math display">\[
T=\frac{12.350-10.125}{\sqrt{1.575\times(1/5+1/6)}} = \frac{2.225}{0.76} = 2.928
\]</span></p>
<p>通過查閱<a href="http://www.statisticshowto.com/tables/t-distribution-table/">統計數據表格</a>：</p>
<div class="figure" style="text-align: center"><span id="fig:t-distr"></span>
<img src="img/Selection_104.png" alt="T-Distribution table (0ne-Tail)" width="80%" />
<p class="caption">
圖 24.1: T-Distribution table (0ne-Tail)
</p>
</div>
<p>圖 <a href="#fig:t-distr">24.1</a> 中顯示統計量 <span class="math inline">\(t=2.928\)</span> 的單側 <span class="math inline">\(p\)</span> 值介於 <span class="math inline">\(0.01\sim0.005\)</span> 之間，所以此例的雙側 <span class="math inline">\(0.01 &lt; p &lt; 0.02\)</span>。</p>
<p>均值差 <span class="math inline">\(\mu_2-\mu_1\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間爲：</p>
<p><span class="math display">\[
\begin{aligned}
(\bar{Y}_2-\bar{Y}_1) &amp;\pm t_{9, 0.975}\hat\sigma\sqrt{(1/n_2)+(1/n_1)} \\
= 2.225 &amp;\pm 2.262 \times 0.76 = (0.51, 3.94)
\end{aligned}
\]</span></p>
<p>上面的手計算過程，如果你像我一樣運氣好可能在考場上碰到，實際生活中我們肯定是使用 R 進行計算拉。下面用了兩種不同的代碼，但是結果和目的都是一樣的： <code>t.test()</code> 時指定 <code>var.equal = TRUE</code>或者用簡單線性迴歸的代碼 <code>lm()</code>。</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1"><span class="kw">t.test</span>(Walk<span class="op">$</span>Age <span class="op">~</span><span class="st"> </span>Walk<span class="op">$</span>Group, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Walk$Age by Walk$Group
## t = -2.9, df = 9, p-value = 0.02
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.9437 -0.5063
## sample estimates:
## mean in group exercise  mean in group control 
##                  10.12                  12.35</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data =</span> Walk))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Age ~ Group, data = Walk)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -1.125 -0.738 -0.375  0.388  2.875 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    10.125      0.512   19.77    1e-08 ***
## Groupcontrol    2.225      0.760    2.93    0.017 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.25 on 9 degrees of freedom
## Multiple R-squared:  0.488,  Adjusted R-squared:  0.431 
## F-statistic: 8.58 on 1 and 9 DF,  p-value: 0.0168</code></pre>
</div>
<div id="當方差未知但是方差不可以被認爲相等且數據服從正態分佈" class="section level3">
<h3><span class="header-section-number">24.1.4</span> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</h3>
<p>下一節會討論如何比較方差是否齊的手段，用於本節分析方法在實際應用時的參考。</p>
<p>當兩組連續型正態分佈的數據不能被認爲方差相同時，有幾種方法可以採用。一是將數據通過數學轉換 (log-transformed, etc.)，人爲的把方差的差異縮小以後，使用前一節的齊方差時的均值比較法 (two-sample <span class="math inline">\(t\)</span> test)。另一種方法是，既然方差不齊，那就用各自的觀察數據來估計其方差 <span class="math inline">\((\hat\sigma_1^2, \hat\sigma_2^2)\)</span>。只要各自的樣本量較大 <span class="math inline">\(n_1, n_2\)</span>，兩組數據均值差 <span class="math inline">\(|\bar{y}_2-\bar{y}_1|\)</span> 除以其合併後的標準誤 <span class="math inline">\(\sqrt{\frac{\hat\sigma_1^2}{n_1}+\frac{\hat\sigma_2^2}{n_2}}\)</span>。利用公式 <a href="#eq:AT5-3">(24.3)</a> 和 <a href="#eq:AT5-4">(24.4)</a>，<strong>把已知的兩組數據各自的方差用樣本方差取代</strong>之後即可用於計算信賴區間，實施假設檢驗求 <span class="math inline">\(p\)</span> 值。</p>
<p>但是，當兩組觀察數據的樣本量不大時 <span class="math inline">\((&lt; 30)\)</span>，根據 <a href="https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation">Welch–Satterthwaite</a> 建議的，估計均值差除以估計標準誤服從一個自由度爲 <span class="math inline">\(n^*\)</span> 的 <span class="math inline">\(t\)</span> 分佈。值得注意的是，這個自由度並非正整數：</p>
<p><span class="math display">\[
n^*=\frac{(\frac{\hat\sigma_1^2}{n_1}+\frac{\hat\sigma_2^2}{n_2})^2}{[\frac{(\hat\sigma_1^2/n_1)^2}{n_1-1}] + [\frac{(\hat\sigma_2^2/n_2)^2}{n_2-1}]}
\]</span></p>
<p>在 R 裏可以指定 <code>var.equal = TRUE</code> 進行 <span class="math inline">\(t\)</span> 檢驗：</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1"><span class="kw">t.test</span>(Walk<span class="op">$</span>Age <span class="op">~</span><span class="st"> </span>Walk<span class="op">$</span>Group, <span class="dt">var.equal =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Walk$Age by Walk$Group
## t = -3, df = 8.7, p-value = 0.01
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.8879 -0.5621
## sample estimates:
## mean in group exercise  mean in group control 
##                  10.12                  12.35</code></pre>
<p>值得注意的是在 R 裏面，<span class="math inline">\(t\)</span> 檢驗是默認組間方差不齊的，如果你沒有指定 <code>var.equal = TRUE</code>，R 就會默認進行上面的方差不齊的 <span class="math inline">\(t\)</span> 檢驗。</p>
</div>
</div>
<div id="兩個人羣的方差比較" class="section level2">
<h2><span class="header-section-number">24.2</span> 兩個人羣的方差比較</h2>
<div id="Ftest" class="section level3">
<h3><span class="header-section-number">24.2.1</span> 方差比值檢驗 variance ratio test</h3>
<p>前一節介紹的樣本均值比較中一個重要的前提是方差齊不齊的問題，所以本節我們就來討論如何比較兩個人羣的方差是否相同，進而爲均值比較時是選用方差齊的檢驗方法 (two sample <span class="math inline">\(t\)</span> test) 還是方差不齊的方法 (Welch Two Sample <span class="math inline">\(t\)</span> test) 提供有價值的參考信息。</p>
<p>比較方差是否相同，最簡單的是利用 <span class="math inline">\(F\)</span> 檢驗，也就是標題的方差比值檢驗 variance ratio test。和大多數檢驗方法一樣，多數情況下進行的也是雙側檢驗，零假設是方差齊，替代假設是方差不齊。</p>
<p>同前例，我們用 <span class="math inline">\(Y_{1i} (i=1,2,\cdots, n_1), Y_{2i} (i=1,2,\cdots,n_2)\)</span> 標記兩組從兩個不同人羣中隨機觀察的獨立樣本數據。兩個數據服從正態分佈。檢驗統計量是兩個方差之比 <span class="math inline">\(F=\frac{\hat\sigma_1^2}{\hat\sigma_2^2}\)</span>。這個比值距離零假設條件下的 1 越遠，證明兩個方差不相同的證據越強。</p>
<p>此時需要有 <span class="math inline">\(F\)</span> 分佈的知識，具體的推導和證明需要參考統計推斷部分 (Section <a href="#Fandtdistr">17.2</a>)，此處直接使用其結論。如果兩個獨立變量，各自服從相應自由度的卡方分佈，那麼他們各自除以自由度後的商，服從 <span class="math inline">\(F\)</span> 分佈。正式的數學定義描述如下：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{If } A\sim \chi_a^2 \text{ and } B \sim \chi_b^2 \text{ independently} \\
&amp; \text{then } F = \frac{A/a}{B/b} \sim F_{a,b}
\end{aligned}
\]</span></p>
<p>在應用方差比值檢驗時，零假設條件下 (方差相等)，兩方差自由度分別是 <span class="math inline">\(n_1-1, n_2-1\)</span>，故 <span class="math inline">\(F=\frac{\hat\sigma_1^2}{\hat\sigma_2^2} \sim F_{n_1-1, n_2-1}\)</span>，即服從自由度爲 <span class="math inline">\(n_1-1, n_2-1\)</span> 的 <span class="math inline">\(F\)</span> 分佈。所以需要比較計算所得的統計量 <span class="math inline">\(F\)</span> 值的大小和相應自由度的 <span class="math inline">\(F\)</span> 分佈。</p>
<p>比較方差大小時，習慣上先計算兩樣本的方差，然後把較大的那個當作分子除以較小的那個，由此計算的檢驗統計量就會總是大於 <span class="math inline">\(1\)</span>。此時我們查閱統計表格獲得的 <span class="math inline">\(p\)</span> 值是單側的，你可以將之乘以 <span class="math inline">\(2\)</span>，或者計算另一半 <span class="math inline">\(p\)</span> 值相加即可。<span class="math inline">\(F\)</span> 檢驗高度依賴<strong>數據服從正態分佈</strong>這一前提。在 R 裏面 <code>var.test()</code> 是進行 <span class="math inline">\(F\)</span> 檢驗的代碼，另外包 <code>car</code> 裏還有 <code>leveneTest()</code> 是一種更加穩健的比較方差的方法，適用於數據不服從正態分佈時：</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1"><span class="kw">var.test</span>(Walk<span class="op">$</span>Age<span class="op">~</span>Walk<span class="op">$</span>Group)</a></code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  Walk$Age by Walk$Group
## F = 2.3, num df = 5, denom df = 4, p-value = 0.4
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##   0.2417 16.7226
## sample estimates:
## ratio of variances 
##              2.264</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" title="1"><span class="kw">leveneTest</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data =</span> Walk, <span class="dt">center =</span> median)</a></code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  1       0   0.95
##        9</code></pre>
</div>
<div id="信賴區間" class="section level3">
<h3><span class="header-section-number">24.2.2</span> 信賴區間</h3>
<p>類比章節 <a href="#varCI">21.6</a>，可以容易地推導出方差比值 <span class="math inline">\(\frac{\sigma_1^2}{\sigma_2^2}\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間公式爲：</p>
<p><span class="math display" id="eq:AT5-6">\[
\begin{equation}
(\frac{F}{F_{n_1-1,n_2-1, 0.975}} , \frac{F}{F_{n_1-1,n_2-1,0.025}})
\end{equation}
\tag{24.6}
\]</span></p>
<p>上面的式子會需要計算檢驗統計量 <span class="math inline">\(F\)</span> 值左側的 <span class="math inline">\(p\)</span> 值，一般的檢驗統計表個不提供。但是利用 <span class="math inline">\(F\)</span> 分佈的性質如果 <span class="math inline">\(F\sim F_{a,b}\)</span> 那麼 <span class="math inline">\(\frac{1}{F} \sim F_{b,a}\)</span> ，所以下面的公式在查閱表格時更加實用：</p>
<p><span class="math display">\[
(\frac{F}{F_{n_1-1,n_2-1, 0.975}} , F\times F_{n_2-1,n_1-1,0.975})
\]</span></p>
</div>
</div>
<div id="比較兩個百分比" class="section level2">
<h2><span class="header-section-number">24.3</span> 比較兩個百分比</h2>
<div id="proportiontest" class="section level3">
<h3><span class="header-section-number">24.3.1</span> 兩個百分比差是否爲零的推斷 Risk difference</h3>
<p>令 <span class="math inline">\(R_1, R_2\)</span> 爲兩種不同實驗的成功次數，每種實驗進行的次數分別是 <span class="math inline">\(n_1, n_2\)</span>。類似地，令 <span class="math inline">\(P_1, P_2\)</span> 表示兩種實驗的觀察勝率。所以 <span class="math inline">\(R_1, R_2\)</span> 服從二項分佈：<span class="math inline">\(R_k \sim \text{Bin}(n_k, \pi_k) \text{ for } k=1,2\)</span>。所以有：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; E(P_k) = \pi_k \text{ and Var}(P_k) = \frac{\pi_k(1-\pi_k)}{n_k}  \\
&amp; \text{For } k = 1,2 \text{ and } P_1, P_2 \text{ independent }
\end{aligned}
\]</span></p>
<p>當 <span class="math inline">\(n_k\)</span> 足夠大，每個百分比都可以根據中心極限定理用下面的正態分佈來近似：</p>
<p><span class="math display">\[
P_k \sim N(\pi_k, \frac{\pi_k(1-\pi_k)}{n_k}) \text{ for } k= 1,2
\]</span></p>
<p>由於兩樣本是獨立的，所以百分比差也是服從下面的正態分佈的：</p>
<p><span class="math display" id="eq:AT5-7">\[
\begin{equation}
P_2-P_1 \sim N(\pi_2-\pi_1, \frac{\pi_1(1-\pi_1)}{n_1}+\frac{\pi_2(1-\pi_2)}{n_2})
\end{equation}
\tag{24.7}
\]</span></p>
<p>所以，作大樣本的百分比比較時，百分比差 <span class="math inline">\(\pi_2-\pi_1\)</span> 的 <span class="math inline">\(100(1-\alpha)\%\)</span> 信賴區間公式爲：</p>
<p><span class="math display">\[
(P_2-P_1) \pm z_{1-\alpha/2}\sqrt{\frac{P_1(1-P_1)}{n_1}+\frac{P_2(1-P_2)}{n_2}}
\]</span></p>
<p>進行的百分比差的假設檢驗爲： <span class="math inline">\(\text{H}_0: \pi_2-\pi_1 = 0 \text{ v.s. H}_1: \pi_2-\pi_1 \neq 0\)</span>
檢驗統計量 <span class="math inline">\(Z\)</span> 爲：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Z=\frac{P_2-P_1}{\sqrt{P(1-P)(\frac{1}{n_2}+\frac{1}{n_1})}} \sim N(0,1) \\
&amp; \text{Where } P=\frac{R_1+R_2}{n_1+n_2} \text{ is the marginal probability of success} \\
&amp; p\text{-value} = 2\times(1-\Phi\{ \frac{|P_2-P_1|}{\sqrt{P(1-P)(\frac{1}{n_2}+\frac{1}{n_1})}} \})
\end{aligned}
\]</span></p>
</div>
<div id="兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio" class="section level3">
<h3><span class="header-section-number">24.3.2</span> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</h3>
<p>兩個百分比商，在流行病學中通常使用相對危險度 (relative risk) 或者危險度比 (risk ratio) 來表示。從樣本數據中獲得的相對危險度比的估計爲 <span class="math inline">\(RR=\frac{P_2}{P_1}\)</span>。樣本量大時，百分比近似服從正態分佈，所以百分比差也近似服從正態分佈，然而百分比商則不然。此時用到數據的轉換，將百分比商求對數以後 <span class="math inline">\(\text{log}\frac{P_2}{P_1}\)</span> ，得到近似正態分佈的對數樣本分佈進而進行假設檢驗，計算信賴區間。</p>
<p>下一章會着重介紹數據的轉換 (transformation)，本章暫且先用其結論，當 <span class="math inline">\(Y_k=\text{log}(P_k)\)</span> ，其方差爲 <span class="math inline">\(\text{Var}(Y_k) = \frac{1-\pi_k}{n_k\pi_k}\)</span>，所以此方差的估計量爲 <span class="math inline">\(\frac{1-P_k}{R_k}\)</span>。</p>
<p>由此可得 <span class="math inline">\(\text{log}\frac{\pi_2}{\pi_1}\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間公式爲：</p>
<p><span class="math display">\[
\text{log} \frac{P_2}{P_1} \pm 1.96\times\sqrt{\frac{1-P_1}{R_1}+\frac{1-P_2}{R_2}}
\]</span></p>
<p>如果把上面式子計算的 <span class="math inline">\(\text{log}\frac{\pi_2}{\pi_1}\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間標記爲 <span class="math inline">\((L,U)\)</span>，那麼相對危險度 <span class="math inline">\(\frac{\pi_2}{\pi_1}\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間爲 <span class="math inline">\((exp(L), exp(U))\)</span>。</p>
</div>
</div>
</div>
<div id="前提和數據轉換-assumptions-and-transformations" class="section level1">
<h1><span class="header-section-number">第 25 章</span> 前提和數據轉換 Assumptions and transformations</h1>
<p>幾乎所有的統計分析手法都有自己的前提條件，所以重要的問題來了：</p>
<ol style="list-style-type: decimal">
<li>在多大的程度上分析結果引導的結論會依賴於這些前提？</li>
<li>有沒有方法檢驗，至少檢查數據是否滿足前提條件？</li>
<li>如果數據無法滿足相應的前提條件，該怎麼辦？</li>
</ol>
<p>目前爲止，分析方法中接觸到的簡單統計檢驗法中典型的前提舉例如下：</p>
<ol style="list-style-type: decimal">
<li>單樣本 <span class="math inline">\(t\)</span> 檢驗 (Section <a href="#OneSampleT">22.6</a>) 需要的前提條件是<strong>所有的觀察數據</strong>
<ul>
<li>相互獨立 independent；</li>
<li>服從正態分佈 normally distributed。</li>
</ul></li>
<li>事件發生率的信賴區間計算 (Section <a href="#CIrate">21.9</a>) 需要的前提條件是
<ul>
<li>事件發生的件數服從泊松分佈 Poisson distributed。</li>
</ul></li>
<li>兩個百分比的卡方檢驗 (Section <a href="#chisquaretest">23.3.3</a> and Section <a href="#proportiontest">24.3.1</a>) 需要的前提條件是
<ul>
<li>兩組數據中成功次數的數據服從二項分佈 Binomial distributed。</li>
</ul></li>
</ol>
<p>當觀察數據可能不滿足上述前提條件時，一個最爲常用的手段是對原始數據進行數學轉換 (transformation)。然而，數學轉換會對推斷的結果意義產生影響：</p>
<ol style="list-style-type: decimal">
<li>數學轉換以後的數據可能更加滿足前提條件，不好的數學轉換則可能使轉換後的數據更加偏離前提條件；</li>
<li>數學轉換以後，<strong>改變了統計結果的現實意義</strong>，change the ease of interpretation of the results。</li>
</ol>
<p>比方說，一組採樣獲得的血壓數據，你發現把原始數據開根號之後的結果可以符合正態分佈的前提，但是此種轉換最大的缺點是，轉換後的數據使用 two sample <span class="math inline">\(t\)</span> test 時比較的不再是均值差，而是開根號之後的差。這就導致了無法良好的解釋這樣的差異在實際生活中有什麼意義 (臨牀上的意義)，換句話說，醫生和患者是無法理解什麼是<strong>根號血壓差</strong>的 <span class="math inline">\(\sqrt{\text{mmHg}}\)</span>。</p>
<div id="穩健性" class="section level2">
<h2><span class="header-section-number">25.1</span> 穩健性</h2>
<p>其實應用統計學方法時真實數據多多少少會偏離一些前提條件，在某些前提條件不能滿足的情況下，分析結果是否穩健 (robustness) 有如下不太精確但是廣泛被接受的定義：</p>
<blockquote>
<p>A statistical procedure is robust if it performs well when the needed assumptions are not violated
“too badly”, or if the procedure performs well for a large family of probabilty distributions.</p>
<p>— van Belle <em>et al.</em> (p253) <span class="citation">(Belle et al. <a href="#ref-van2004biostatistics" role="doc-biblioref">2004</a>)</span></p>
</blockquote>
<p>那麼什麼情況下可以說一個統計方法是表現良好的呢，performing well？</p>
<p>我們說一個<strong>統計方法表現良好</strong>，是指該方法用於定義是否有意義的臨界值，或者叫名義顯著性水平 (<strong>nominal</strong> signficance level)，和實際上計算的檢驗統計量在所有的可能中達到或超過該臨界值的概率 (<strong>actual</strong> probability the test statistic exceeds the cut-off)。用 <span class="math inline">\(t\)</span> 檢驗舉例如下：</p>
<p><span class="math display">\[
\text{Prob}(|T| &gt; t_{df,0.975} | \text{H}_0 \text{true}) = 0.05
\]</span></p>
<p>類似地，我們說一個<strong>信賴區間的計算方法表現良好</strong>，是指該方法計算獲得的 <span class="math inline">\(95\%\)</span> 信賴區間包含真實參數值的概率真的可以無限接近 <span class="math inline">\(95\%\)</span>：</p>
<p><span class="math display">\[
\text{Prob}(\mu \in (L, U) | \mu) = 0.95
\]</span></p>
<p>一些常見方法的穩健性列舉：</p>
<ol style="list-style-type: decimal">
<li>樣本量小且分佈偏度越大時，依賴正態分佈前提的信賴區間計算和其他的檢驗手段就變得不再可靠；</li>
<li>兩個方差比較時使用的 <span class="math inline">\(F\)</span> 檢驗 (Section <a href="#Ftest">24.2.1</a>) 常常由於數據不服從正態分佈缺乏穩健性，即使樣本量較大也不能改善；</li>
<li>根據中心極限定理，樣本量足夠大時，單樣本 <span class="math inline">\(t\)</span> 檢驗 (Section <a href="#OneSampleT">22.6</a>) 具有良好的穩健性。</li>
<li>一般地，基於均值的檢驗方法都相對其他統計量較爲穩健。</li>
</ol>
</div>
<div id="正態性" class="section level2">
<h2><span class="header-section-number">25.2</span> 正態性</h2>
<p>大多數情況下，正如我們在這個部分最開頭的章節提到的，拿到數據以後先用圖形手段探索，並熟悉該數據。從圖形來判斷一組數據是否接近正態分佈或者偏離正態分佈。常用的探索連續型變量是否服從正態分佈的圖形方法是：</p>
<ol style="list-style-type: decimal">
<li>箱形圖，box and whisker plot，如圖 <a href="#fig:diamond-carat-box">20.5</a>；</li>
<li>柱狀圖，histogram，如圖 <a href="#fig:normal-hist">25.1</a>；</li>
<li>正態分佈圖，normal plots，如圖 <a href="#fig:normal-qq">25.2</a>。</li>
</ol>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" title="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb66-2" title="2">Normal &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">2500</span>, <span class="dt">mean =</span> <span class="dv">120</span>, <span class="dt">sd =</span> <span class="dv">8</span>)</a>
<a class="sourceLine" id="cb66-3" title="3">h &lt;-<span class="st"> </span><span class="kw">hist</span>(Normal,<span class="dt">breaks =</span> <span class="dv">20</span>, <span class="dt">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;some value&quot;</span> ,</a>
<a class="sourceLine" id="cb66-4" title="4">          <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">300</span>))</a>
<a class="sourceLine" id="cb66-5" title="5">xfit&lt;-<span class="kw">seq</span>(<span class="kw">min</span>(Normal),<span class="kw">max</span>(Normal),<span class="dt">length=</span><span class="dv">40</span>)</a>
<a class="sourceLine" id="cb66-6" title="6">yfit&lt;-<span class="kw">dnorm</span>(xfit,<span class="dt">mean=</span><span class="kw">mean</span>(Normal),<span class="dt">sd=</span><span class="kw">sd</span>(Normal))</a>
<a class="sourceLine" id="cb66-7" title="7">yfit &lt;-<span class="st"> </span>yfit<span class="op">*</span><span class="kw">diff</span>(h<span class="op">$</span>mids[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>])<span class="op">*</span><span class="kw">length</span>(Normal)</a>
<a class="sourceLine" id="cb66-8" title="8"><span class="kw">lines</span>(xfit, yfit, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:normal-hist"></span>
<img src="bookdown_files/figure-html/normal-hist-1.png" alt="Appearance of histogram with normal curve" width="100%" />
<p class="caption">
圖 25.1: Appearance of histogram with normal curve
</p>
</div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" title="1"><span class="kw">qqnorm</span>(Normal,<span class="dt">frame=</span>F); <span class="kw">qqline</span>(Normal)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:normal-qq"></span>
<img src="bookdown_files/figure-html/normal-qq-1.png" alt="Appearance of normal plot for a normally distributed variable" width="100%" />
<p class="caption">
圖 25.2: Appearance of normal plot for a normally distributed variable
</p>
</div>
<div id="normalplot" class="section level3">
<h3><span class="header-section-number">25.2.1</span> 正態分佈圖 normal plot</h3>
<p>其實光看柱狀圖和箱形圖，有時候很難判斷數據正態性與否，當數據和正態分佈有些微妙的不同時可能就沒辦法從柱狀圖覺察出來。此時需要借用正態分布圖的威力。正態分布圖的原理就是，把原始數據 (Y軸) 和理論上服從正態分佈的期待數據 (X軸) 從小到大排序一一對應以後繪製散點圖。所以理論上，如果原始數據服從正態分佈，那麼正態分佈中第10百分位的點，我們期望和原始數據中第10百分位的點十分接近，那麼繪成的散點圖應該接近於完美的貼在 <span class="math inline">\(y=x\)</span> 這條直線上。如果正態分布圖的點越偏離 <span class="math inline">\(y=x\)</span> 的直線，覺說明原始數據越偏離正態分佈。</p>
<p>下面的系列圖<a href="#fig:Outliers-hist-normal">25.3</a>，<a href="#fig:skewpos-hist-normal">25.4</a>，<a href="#fig:skewneg-hist-normal">25.5</a>，<a href="#fig:skewneg-hist-normal">25.5</a>展示了各種非正態分佈時會出現的柱狀圖，和正態分布圖的特徵：</p>
<div class="figure" style="text-align: center"><span id="fig:Outliers-hist-normal"></span>
<img src="bookdown_files/figure-html/Outliers-hist-normal-1.png" alt="Appearance of histogram and normal plot for a variable with outlying values" width="80%" />
<p class="caption">
圖 25.3: Appearance of histogram and normal plot for a variable with outlying values
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:skewpos-hist-normal"></span>
<img src="bookdown_files/figure-html/skewpos-hist-normal-1.png" alt="Appearance of histogram and normal plot for a variable exhibiting right-skewness" width="80%" />
<p class="caption">
圖 25.4: Appearance of histogram and normal plot for a variable exhibiting right-skewness
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:skewneg-hist-normal"></span>
<img src="bookdown_files/figure-html/skewneg-hist-normal-1.png" alt="Appearance of histogram and normal plot for a variable exhibiting left-skewness" width="80%" />
<p class="caption">
圖 25.5: Appearance of histogram and normal plot for a variable exhibiting left-skewness
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:heavytail-hist-normal"></span>
<img src="bookdown_files/figure-html/heavytail-hist-normal-1.png" alt="Appearance of histogram and normal plot for a heavy tailed variable" width="80%" />
<p class="caption">
圖 25.6: Appearance of histogram and normal plot for a heavy tailed variable
</p>
</div>
<p>如果對數據是否服從正態分佈實在沒有信心，統計學家也很少使用那些檢驗是否服從正態分佈的所謂檢驗方法 (<a href="https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test">Sharpiro-Wilk test</a> 或者 <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov-Smirnov test</a>)，而是傾向用直接改用穩健統計學分析法 (Robust Statistical Methods)。</p>
</div>
</div>
<div id="總結連續型變量不服從正態分佈時的處理方案" class="section level2">
<h2><span class="header-section-number">25.3</span> 總結連續型變量不服從正態分佈時的處理方案</h2>
<ul>
<li>根據中心極限定理，樣本量足夠大時，即使原始樣本數據不服從正態分佈，仍然可以用一般的參數估計技巧來分析類似均值這樣較爲穩健的參數。</li>
<li>用非參數檢驗法，會在穩健統計學方法中介紹，但是這些方法的缺點很明顯，例如無法進行精確的參數估計，且容易失去較大的統計學檢驗力 (loss of power)，增加一類錯誤概率 (錯誤的拒絕掉可能存在有意義差異的檢驗)。更重要的是，沒有一種非參數檢驗法是可以和多重線性迴歸等較爲複雜，高級的技巧等價的。</li>
<li>用一些穩健統計學方法 (bootstrap，“sandwich” estimators of variance)，可行但是對電腦的計算需求較高。</li>
<li>數據轉換法。但是沒有人能保證一定能找到合適的數學轉換法來滿足前提條件 (下節討論)。</li>
</ul>
</div>
<div id="數學冪轉換-power-transformations" class="section level2">
<h2><span class="header-section-number">25.4</span> 數學冪轉換 power transformations</h2>
<p>數據轉換家族：</p>
<p><span class="math display">\[
\cdots,x^{-2},x^{-1},x^{-\frac{1}{2}},\text{log}(x),x^{\frac{1}{2}},x^1,x^2,\cdots
\]</span></p>
<p>上面舉例的數學冪轉換方法，都是常見的手段用於降低原始數據的偏度 (skewness)，相反地，冪轉換卻不一定能夠改變數據的峯度 (kurtosis)。下面的方程，(非常的羅嗦的方程 sorry)，用於實施類似 <code>ladder</code> 在 Stata 中的效果，即對數據進行各種轉換，然後輸出每種冪轉換後的數據是否爲正態分佈的檢驗結果 (使用 <code>shapiro.test()</code>)：</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" title="1">Ladder.x &lt;-<span class="st"> </span><span class="cf">function</span>(x){</a>
<a class="sourceLine" id="cb68-2" title="2">    data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x<span class="op">^</span><span class="dv">3</span>,x<span class="op">^</span><span class="dv">2</span>,x,<span class="kw">sqrt</span>(x),<span class="kw">log</span>(x),<span class="dv">1</span><span class="op">/</span><span class="kw">sqrt</span>(x),<span class="dv">1</span><span class="op">/</span>x,<span class="dv">1</span><span class="op">/</span>(x<span class="op">^</span><span class="dv">2</span>),<span class="dv">1</span><span class="op">/</span>(x<span class="op">^</span><span class="dv">3</span>))</a>
<a class="sourceLine" id="cb68-3" title="3">    <span class="kw">names</span>(data) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;cubic&quot;</span>,<span class="st">&quot;square&quot;</span>,<span class="st">&quot;identity&quot;</span>,<span class="st">&quot;square root&quot;</span>,<span class="st">&quot;log&quot;</span>,<span class="st">&quot;1/(square root)&quot;</span>,</a>
<a class="sourceLine" id="cb68-4" title="4">                     <span class="st">&quot;inverse&quot;</span>,<span class="st">&quot;1/square&quot;</span>,<span class="st">&quot;1/cubic&quot;</span>)</a>
<a class="sourceLine" id="cb68-5" title="5">   <span class="co"># options(scipen=5)</span></a>
<a class="sourceLine" id="cb68-6" title="6">    test1 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span>cubic)</a>
<a class="sourceLine" id="cb68-7" title="7">    test2 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span>square)</a>
<a class="sourceLine" id="cb68-8" title="8">    test3 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span>identity)</a>
<a class="sourceLine" id="cb68-9" title="9">    test4 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span><span class="st">`</span><span class="dt">square root</span><span class="st">`</span>)</a>
<a class="sourceLine" id="cb68-10" title="10">    test5 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span>log)</a>
<a class="sourceLine" id="cb68-11" title="11">    test6 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span><span class="st">`</span><span class="dt">1/(square root)</span><span class="st">`</span>)</a>
<a class="sourceLine" id="cb68-12" title="12">    test7 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span>inverse)</a>
<a class="sourceLine" id="cb68-13" title="13">    test8 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span><span class="st">`</span><span class="dt">1/square</span><span class="st">`</span>)</a>
<a class="sourceLine" id="cb68-14" title="14">    test9 &lt;-<span class="st"> </span><span class="kw">shapiro.test</span>(data<span class="op">$</span><span class="st">`</span><span class="dt">1/cubic</span><span class="st">`</span>)</a>
<a class="sourceLine" id="cb68-15" title="15">    W.statistic &lt;-<span class="st"> </span><span class="kw">c</span>(test1<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-16" title="16">                     test2<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-17" title="17">                     test3<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-18" title="18">                     test4<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-19" title="19">                     test5<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-20" title="20">                     test6<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-21" title="21">                     test7<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-22" title="22">                     test8<span class="op">$</span>statistic,</a>
<a class="sourceLine" id="cb68-23" title="23">                     test9<span class="op">$</span>statistic)</a>
<a class="sourceLine" id="cb68-24" title="24">    p.value &lt;-<span class="st"> </span><span class="kw">c</span>(test1<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-25" title="25">                 test2<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-26" title="26">                 test3<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-27" title="27">                 test4<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-28" title="28">                 test5<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-29" title="29">                 test6<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-30" title="30">                 test7<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-31" title="31">                 test8<span class="op">$</span>p.value,</a>
<a class="sourceLine" id="cb68-32" title="32">                 test9<span class="op">$</span>p.value)</a>
<a class="sourceLine" id="cb68-33" title="33">    Hmisc<span class="op">::</span><span class="kw">format.pval</span>(p.value ,<span class="dt">digits=</span><span class="dv">5</span>, <span class="dt">eps =</span> <span class="fl">0.00001</span>, <span class="dt">scientific =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb68-34" title="34">    Transformation &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;cubic&quot;</span>,<span class="st">&quot;square&quot;</span>,<span class="st">&quot;identity&quot;</span>,<span class="st">&quot;square root&quot;</span>,<span class="st">&quot;log&quot;</span>,<span class="st">&quot;1/(square root)&quot;</span>,</a>
<a class="sourceLine" id="cb68-35" title="35">                        <span class="st">&quot;inverse&quot;</span>,<span class="st">&quot;1/square&quot;</span>,<span class="st">&quot;1/cubic&quot;</span>)</a>
<a class="sourceLine" id="cb68-36" title="36">    Formula &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x^3&quot;</span>,<span class="st">&quot;x^2&quot;</span>,<span class="st">&quot;x&quot;</span>,<span class="st">&quot;sqrt(x)&quot;</span>,<span class="st">&quot;log(x)&quot;</span>,<span class="st">&quot;1/sqrt(x)&quot;</span>,<span class="st">&quot;1/x&quot;</span>,<span class="st">&quot;1/(x^2)&quot;</span>,<span class="st">&quot;1/(x^3)&quot;</span>)</a>
<a class="sourceLine" id="cb68-37" title="37">    (results &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Transformation, Formula, W.statistic, p.value))</a>
<a class="sourceLine" id="cb68-38" title="38">  }</a></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1">Normal &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">2500</span>, <span class="dt">mean =</span> <span class="dv">120</span>, <span class="dt">sd =</span> <span class="dv">8</span>)</a>
<a class="sourceLine" id="cb69-2" title="2"><span class="kw">Ladder.x</span>(Normal)</a></code></pre></div>
<pre><code>##    Transformation   Formula W.statistic   p.value
## 1           cubic       x^3      0.9901 3.906e-12
## 2          square       x^2      0.9968 4.283e-05
## 3        identity         x      0.9994 5.835e-01
## 4     square root   sqrt(x)      0.9990 2.039e-01
## 5             log    log(x)      0.9977 8.750e-04
## 6 1/(square root) 1/sqrt(x)      0.9952 3.370e-07
## 7         inverse       1/x      0.9917 8.896e-11
## 8        1/square   1/(x^2)      0.9816 1.735e-17
## 9         1/cubic   1/(x^3)      0.9674 2.175e-23</code></pre>
<div id="對數轉換-logarithmic-transformation" class="section level3">
<h3><span class="header-section-number">25.4.1</span> 對數轉換 logarithmic Transformation</h3>
<p>在衆多冪轉換中，對數轉換是最常用的，因爲對數轉換之後，再通過逆運算轉換回原單位數據的方法，被發現是相較於其他冪轉換較爲容易解釋和應用在臨牀醫學中。假如現在在分析男女之間收縮期血壓的均值差別。下面是對數轉換前後的檢驗方法步驟，試作一個對比：</p>
<p>轉換前：</p>
<ul>
<li>計算收縮期血壓在男性女性中各自的均值 <span class="math inline">\(\bar{Y}_j, j=1,2\)</span>；</li>
<li>計算男女間均值差 <span class="math inline">\(D=\bar{Y}_2 - \bar{Y}_1\)</span>；</li>
<li>所以均值差就被解釋爲男女減血壓的平均差距 (difference of mmHg)；</li>
<li>例如，均值差爲 10 mmHg，就可以被解讀爲女性血壓平均值比男性低 10 mmHg。</li>
</ul>
<p>對數轉換後：</p>
<ul>
<li>計算觀察值的對數值 <span class="math inline">\(t_{ij} = \text{log}_e(y_{ij})\)</span>；</li>
<li>計算男女對數收縮期血壓的算數平均值 <span class="math inline">\(\bar{T}_j, j=1,2\)</span>；</li>
<li>計算對數血壓均值差 <span class="math inline">\(D=\bar{T}_2-\bar{T}_1\)</span>；</li>
<li>由於 <span class="math inline">\(exp(\bar{T}_j) = G_j\)</span> 是男女收縮期血壓的幾何平均值，所以 <span class="math inline">\(exp(D)=exp(\text{log}_eG_2 - \text{log}_eG_1) = \frac{G_2}{G_1}\)</span>，就可以解釋爲男女收縮期血壓的幾何平均值之比；</li>
<li>例如，<span class="math inline">\(D=-0.05\)</span>，那麼男女收縮期血壓的幾何平均值之比爲 <span class="math inline">\(exp(-0.05)=0.951\)</span>，就可以被解讀爲女性收縮期血壓平均比男性低 <span class="math inline">\(4.9\%\)</span>。</li>
</ul>
</div>
<div id="逆轉換信賴區間-back-transformation-of-cis" class="section level3">
<h3><span class="header-section-number">25.4.2</span> 逆轉換信賴區間 back-transformation of CIs</h3>
<p>當使用轉換後數據計算信賴區間以後，需要再把數據逆轉換回原始數據的單位才能順利被解讀。但是逆轉換回去以後的信賴區間就不再左右對稱了 (no way)。</p>
</div>
<div id="對數正態分佈-log-normal-distribution" class="section level3">
<h3><span class="header-section-number">25.4.3</span> 對數正態分佈 log-normal distribution</h3>
<p>一個隨機變量的對數轉換如果服從正態分佈，我們說這個數據服從對數正態分佈。</p>
</div>
<div id="百分比的轉換" class="section level3">
<h3><span class="header-section-number">25.4.4</span> 百分比的轉換</h3>
<p>百分比被侷限在 <span class="math inline">\([0,1]\)</span> 的範圍內，所以爲了打破這個取值範圍的限制，百分比常用的數學轉換有：</p>
<ol style="list-style-type: decimal">
<li>把百分比 <span class="math inline">\(\pi\)</span> 轉換成 Odds <span class="math inline">\(\frac{\pi}{1-\pi}\)</span>。如此 Odds 的取值範圍就可以變成 <span class="math inline">\([0, \infty)\)</span>；</li>
<li>Odds <span class="math inline">\(\frac{\pi}{1-\pi}\)</span> 又常被轉換成 log-odds <span class="math inline">\(\text{log}(\frac{\pi}{1-\pi})\)</span>。這樣的轉換方程 <span class="math inline">\(f(\pi)=\text{log}(\frac{\pi}{1-\pi})\)</span> 又被命名爲邏輯轉換 (logit transformation)；</li>
<li>百分比的商 (危險度比，risk ratio) <span class="math inline">\(\pi_1/\pi_2\)</span> 可以轉換成 <span class="math inline">\(\text{log}(\pi_1/\pi_2)\)</span>；</li>
<li>比值比 (odds ratio) <span class="math inline">\(\frac{\pi_1(1-\pi_2)}{\pi_2(1-\pi_1)}\)</span> 可以轉換成對數比值比 (log odds ratio) <span class="math inline">\(\text{log}[\frac{\pi_1(1-\pi_2)}{\pi_2(1-\pi_1)}] = \text{log}[\pi_1(1-\pi_1)] - \text{log}[\pi_2(1-\pi_2)]\)</span>。</li>
</ol>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表25.1： Common Transformation and their range
</caption>
<thead>
<tr>
<th style="text-align:center;">
Transformation
</th>
<th style="text-align:center;">
Formula
</th>
<th style="text-align:center;">
Range
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Odds
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi}{1-\pi}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\([0,\infty)\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Log Odds
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{log}(\frac{\pi}{1-\pi})\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\((-\infty,+\infty)\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Risk Ratio
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_1}{\pi_2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\([0,\infty)\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Log Risk Ratio
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{log}(\frac{\pi_1}{\pi_2})\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\((-\infty,+\infty)\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratio
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_1(1-\pi_2)}{\pi_2(1-\pi_1)}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\([0,\infty)\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Log Odds Ratio
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{log}[\frac{\pi_1(1-\pi_2)}{\pi_2(1-\pi_1)}]\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\((-\infty,+\infty)\)</span>
</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>



<div id="lm" class="section level1">
<h1><span class="header-section-number">第 26 章</span> 簡單線性迴歸 Simple Linear Regression</h1>
<blockquote>
<dl>
<dt>Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong questions, which can always be made precise.</dt>
<dd>John Tukey
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Linear Regression lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/nicholas.jennifer">Jennifer Nicholas</a>.
</div>

<div id="一些背景和術語" class="section level2">
<h2><span class="header-section-number">26.1</span> 一些背景和術語</h2>
<p>思考下面這些問題：</p>
<ol style="list-style-type: decimal">
<li>脂肪攝入量增加，會導致體重增加嗎？</li>
<li>兒童成年時的身高，可以用父母親的身高來預測嗎？</li>
<li>如果其他條件都沒有變化，飲食習慣的改變，是否能影響血清膽固醇的水平？</li>
</ol>
<p>上面的問題中，自變量 (預測變量)，和因變量 (反應量) 分別是什麼？</p>
<p>你可能還會碰到像下面這些稱呼，他們都是一個意思：</p>
<ul>
<li>因變量 Dependent variable = 反應量 response variable = 結果變量 outcome variable;</li>
<li>自變量 independent variable = 預測變量 predictor variable = 解釋變量 explanatory variable = 共變量 covariate.</li>
</ul>
<p>所有的非簡單統計模型 (non-trivial statistical models) 都包括以下三個部分：</p>
<ol style="list-style-type: decimal">
<li>隨機變量 random variables：
<ul>
<li>因變量永遠都是隨機變量；</li>
<li>預測變量不一定是隨機變量；</li>
<li>在相對簡單的模型中，我們討論的因變量和預測變量幾乎都來自於從人羣中抽取觀察樣本收集來的數據。</li>
</ul></li>
<li>人羣參數 population parameters：
<ul>
<li>人羣參數，是我們希望通過收集樣本獲得的數據來估計 (estimate) 的參數。</li>
</ul></li>
<li>對不確定性的描述 representation of uncertainty：
<ul>
<li>不確定性，意爲因變量的變動中，沒有被預測變量解釋的部分。</li>
</ul></li>
</ol>
<p>其他的術語問題：</p>
<ul>
<li><strong>單一因變量</strong>的統計模型：<strong>univariate model</strong>;</li>
<li><strong>多個因變量</strong>的統計模型： <strong>multivariate model</strong>;</li>
<li><strong>單一因變量</strong>，含有<strong>多個預測變量</strong>的統計模型：<strong>multivariable model</strong>；</li>
<li>在線性迴歸中，單一因變量，單一預測變量的統計模型：<strong>simple linear regression</strong> (簡單線性迴歸)；</li>
<li>在線性迴歸中，單一因變量，多個預測變量的統計模型：<strong>multiple linear regression</strong> (多重線性迴歸)；</li>
</ul>
<p>儘量避免將預測變量 (predictor variable) 寫作自變量 (independent variable)，因爲 “independent” 有自己的統計學含義 (獨立)。然而我們在線性迴歸中使用的預測變量，不一定都<strong>互相獨立</strong>，所以容易讓人混淆其意義。</p>
</div>
<div id="簡單線性迴歸模型-simple-linear-regression-model" class="section level2">
<h2><span class="header-section-number">26.2</span> 簡單線性迴歸模型 simple linear regression model</h2>
<p>即：<strong>單一因變量，單一預測變量</strong>的統計模型。</p>
<div id="數據-a" class="section level3">
<h3><span class="header-section-number">26.2.1</span> 數據 A</h3>
<p>下面的散點圖 <a href="#fig:age-wt">26.1</a> 展示的是一項橫斷面調查的結果，調查的是一些兒童的年齡 (月)，和他們的體重 (千克) 之間的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt"></span>
<img src="bookdown_files/figure-html/age-wt-1.png" alt="Age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.1: Age and weight of children in a cross-sectional survey
</p>
</div>
</div>
<div id="數據-b" class="section level3">
<h3><span class="header-section-number">26.2.2</span> 數據 B</h3>
<p>表 <a href="#tab:walk">26.1</a> 羅列的是11名兒童能夠自己獨立行走時的年齡。這些兒童在剛出生時被隨機分配到兩個組中 (積極鍛鍊走路，和對照組)。如果你熟悉均數比較，這樣的數據可以通過簡單 <span class="math inline">\(t\)</span> 檢驗來分析其均值的不同。但是實際上後面你會看到簡單 <span class="math inline">\(t\)</span> 檢驗和簡單線性迴歸是同一回事。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:walk">表 26.1: </span>Childen’s ages at time of first walking aline by randomisation group
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Age in months for walking alone
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Active Exercise (n=6)
</th>
<th style="text-align:center;">
Eight Week Control (n=5)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
9.00
</td>
<td style="text-align:center;">
13.25
</td>
</tr>
<tr>
<td style="text-align:center;">
9.50
</td>
<td style="text-align:center;">
11.5
</td>
</tr>
<tr>
<td style="text-align:center;">
9.75
</td>
<td style="text-align:center;">
12
</td>
</tr>
<tr>
<td style="text-align:center;">
10.00
</td>
<td style="text-align:center;">
13.5
</td>
</tr>
<tr>
<td style="text-align:center;">
13.00
</td>
<td style="text-align:center;">
11.5
</td>
</tr>
<tr>
<td style="text-align:center;">
9.50
</td>
<td style="text-align:center;">
–
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="區分因變量和預測變量" class="section level2">
<h2><span class="header-section-number">26.3</span> 區分因變量和預測變量</h2>
<p>在簡單兩樣本 <span class="math inline">\(t\)</span> 檢驗中，我們不區分那兩個要比較的數據 <span class="math inline">\((X, Y)\)</span>。所以 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 的關係，同分析 <span class="math inline">\(Y\)</span> 和 <span class="math inline">\(X\)</span> 的關係是一樣的。表 <a href="#tab:walk">26.1</a> 的例子中，視“直立行走的年齡”這一變量爲因變量十分直觀且自然。圖 <a href="#fig:age-wt">26.1</a> 的例子中我們顯然可以關心是否可以用兒童的年齡來推測他/她的體重。所以年齡被視爲預測變量 <span class="math inline">\((X)\)</span>，體重被視爲因變量或者叫結果變量 <span class="math inline">\((Y)\)</span>。</p>
<div id="meanfunction" class="section level3">
<h3><span class="header-section-number">26.3.1</span> 均值 (期待值) 公式</h3>
<p>圖 <a href="#fig:age-wt">26.1</a> 的例子中，當我們決定考察體重變化 <span class="math inline">\((Y)\)</span> 和年齡的關係 <span class="math inline">\((X)\)</span> 後，我們需要提出一個模型，來描述二者之間的關係。這個模型中，最重要的信息，是均值，或者叫期待值：</p>
<p><span class="math display">\[
E(Y|X=x), \text{ the expected value of } Y \text{ when } X \text{ takes the value } x
\]</span></p>
<p>在簡單線性迴歸模型中，我們認爲這個均值方程是線性關係：</p>
<p><span class="math display">\[
E(Y|X=x) = \alpha +\beta x
\]</span></p>
<p>所以這個線性關係中，有兩個參數 (parameters) 是我們關心的 <span class="math inline">\(\alpha, \beta\)</span>。</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距 intecept。意爲當 <span class="math inline">\(X\)</span> 取 <span class="math inline">\(0\)</span>時， <span class="math inline">\(Y\)</span> 的期待值大小；</li>
<li><span class="math inline">\(\beta\)</span> 是方程的斜率 slope。意爲當 <span class="math inline">\(X\)</span> 上升一個單位時，<span class="math inline">\(Y\)</span> 上升的期待值大小。</li>
</ul>
<p>需要強調的是，這樣的線性模型，是我們提出，用來模擬真實數據時使用的。<del>你如果作死</del>當然還可以提出更加複雜的模型。如下面圖 <a href="#fig:age-wt-lm">26.2</a> 顯示的是線性迴歸直線， 而圖 <a href="#fig:age-wt-loess">26.3</a> 顯示的是較爲複雜的迴歸曲線。曲線方程可能更加擬合我們收集到的數據，然而這樣的連續的斜率變化很可能僅僅只解釋了這個樣本量數據，而不能解釋在人羣中年齡和體重的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm"></span>
<img src="bookdown_files/figure-html/age-wt-lm-1.png" alt="Linear mean function for age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.2: Linear mean function for age and weight of children in a cross-sectional survey
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:age-wt-loess"></span>
<img src="bookdown_files/figure-html/age-wt-loess-1.png" alt="Non-linear mean function for age and weight of children in a cross-sectional survey" width="80%" />
<p class="caption">
圖 26.3: Non-linear mean function for age and weight of children in a cross-sectional survey
</p>
</div>
</div>
<div id="條件分佈和方差-the-conditional-distribution-and-the-variance-function" class="section level3">
<h3><span class="header-section-number">26.3.2</span> 條件分佈和方差 the conditional distribution and the variance function</h3>
<p>如果要完全明確一個統計模型，另一個重要的點在於，提出的模型能否準確描述因變量在預測變量的條件下的分佈 (conditional distribution) it is necessary to describe the distribution of the dependent variable conditional on the predictor variable。使用簡單線性迴歸模型有幾個前提假設：</p>
<ol style="list-style-type: decimal">
<li>因變量對預測變量的條件分佈的方差是保持不變的 the variance of the dependent variable (conditional on the predictor variable) is constant。</li>
<li>該條件分佈是一個正態分佈。</li>
</ol>
<p>有時候，這些假設條件並不能得到滿足。上面的散點圖 <a href="#fig:age-wt">26.1</a>看上去還算符合這兩個假設前提：在每一個年齡階段，體重的分佈沒有發生歪斜 (skew)，分散分佈 (方差) 也相對穩定。但是圖 <a href="#fig:diamond">26.4</a> 中的價格-克拉數據很明顯無法滿足上面的前提假設。在線性迴歸模型中，我們使用 <span class="math inline">\(\sigma^2\)</span> 表示殘差的方差 (residual variance)。</p>
<div class="figure" style="text-align: center"><span id="fig:diamond"></span>
<img src="bookdown_files/figure-html/diamond-1.png" alt="Relationship between diamond carat and price" width="80%" />
<p class="caption">
圖 26.4: Relationship between diamond carat and price
</p>
</div>
</div>
<div id="defLM" class="section level3">
<h3><span class="header-section-number">26.3.3</span> 定義簡單線性迴歸模型</h3>
<p>用來描述一個隨機變量 <span class="math inline">\((Y)\)</span> 和另一個變量 <span class="math inline">\((X)\)</span> 之間關係的簡單線性迴歸模型，被定義爲：</p>
<p><span class="math display">\[
(Y|X=x) \sim N(\alpha+\beta x, \sigma^2)
\]</span></p>
<p>上面這個模型，同時還描述了我們對數據的分佈的假設。同樣的模型，你可能更多得看到被寫成如下的方式：</p>
<p><span class="math display">\[
y=\alpha+\beta x+ \varepsilon \text{, where } \varepsilon\sim N(0,\sigma^2)
\]</span></p>
<p>假如，我們有一組樣本量爲 <span class="math inline">\(n\)</span> 的數據 <span class="math inline">\(\underline{x}\)</span>。我們就可以把通過上面的迴歸模型實現的 <span class="math inline">\(Y_i\)</span> 和它對應的 <span class="math inline">\(X_i (i=1,\cdots, n)\)</span>。描述爲如下的形式：</p>
<p><span class="math display" id="eq:NID">\[
\begin{equation}
  (Y_i|X_i=x_i) \sim \text{NID}(\alpha+\beta x, \sigma^2) \text{ where } i=1,\cdots,n
\end{equation}
  \tag{26.1}
\]</span></p>
<p>此處的 <span class="math inline">\(\text{NID}\)</span> 意爲獨立且服從正態分佈 <strong>(normally and independently distributed)</strong>。這裏默認的一個重要前提是所有的觀察值 <span class="math inline">\(X_i\)</span> 是相互獨立互不影響的。例如上面圖 <a href="#fig:age-wt">26.1</a> 所示兒童的年齡和體重數據，就必須假設這些兒童都來自<strong>沒有血緣關係的獨立家庭</strong>。如果這以數據中的兒童，有些是兄弟姐妹的話，觀察數據互相獨立的前提就無法得到滿足。不滿足相互獨立前提的數據，其分析方法會在 “Analysis of hierarchical and other dependent data (Term 2)” 中詳盡介紹。</p>
<p>公式 <a href="#eq:NID">(26.1)</a> 常被記爲：</p>
<p><span class="math display" id="eq:NID1">\[
\begin{equation}
(Y_i|X_i=x_i) = \alpha + \beta x_i + \varepsilon_i, \text{ where } \varepsilon_i\sim \text{NID}(0,\sigma^2)
\end{equation}
 \tag{26.2}
\]</span></p>
<p>或者爲了簡潔表述寫成：</p>
<p><span class="math display" id="eq:NID2">\[
\begin{equation}
y_i = \alpha + \beta x_i + \varepsilon_i, \text{ where } \varepsilon_i\sim \text{NID}(0,\sigma^2)
\end{equation}
 \tag{26.3}
\]</span></p>
</div>
<div id="殘差-residuals" class="section level3">
<h3><span class="header-section-number">26.3.4</span> 殘差 residuals</h3>
<p>公式 <a href="#eq:NID1">(26.2)</a> 和 <a href="#eq:NID2">(26.3)</a> 其實已經包含了殘差的表達式：</p>
<p><span class="math display">\[
\varepsilon_i = y_i - (\alpha + \beta x_i)
\]</span></p>
<p>所以 <span class="math inline">\(\varepsilon_i\)</span> 的意義是第 <span class="math inline">\(i\)</span> 個觀察對象的隨機(偶然)誤差 (random error)，或者叫真實殘差 (true residual)。其實就是從線性迴歸模型計算獲得的映射值 <span class="math inline">\(\alpha+\beta x_i\)</span>，和實際觀察值 <span class="math inline">\(y_i\)</span> 之間的差距。而且從其公式可見，殘差本身也是由人羣的參數 <span class="math inline">\((\alpha, \beta)\)</span> 決定的。殘差也被定義爲迴歸模型的偏差值。當我們用樣本數據獲得的參數估計 <span class="math inline">\((\hat\alpha, \hat\beta)\)</span> 來取代掉參數 <span class="math inline">\((\alpha, \beta)\)</span> 時，這時的模型變成了估計模型，殘差也成了估計殘差或者叫觀察模型和觀察殘差。須和真實殘差加以區分。</p>
</div>
</div>
<div id="參數的估計-estimation-of-parameters" class="section level2">
<h2><span class="header-section-number">26.4</span> 參數的估計 estimation of parameters</h2>
<p>簡單線性迴歸模型中有三個人羣參數 <span class="math inline">\((\alpha, \beta, \sigma^2)\)</span>。統計分析的目標，就是使用樣本數據 <span class="math inline">\(Y_i, X_i, (i=1, \cdots, n)\)</span> 來對總體參數做出推斷 (inference)。在線性迴歸中主要使用<strong>普通最小二乘法 (ordinary least squares, OLS)</strong> 作爲推斷的工具。在統計學中，我們習慣給希臘字母戴上“帽子”，作爲該參數的估計值，例如 <span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是參數 <span class="math inline">\(\alpha, \beta\)</span> 的估計值。通過線性迴歸模型，給第 <span class="math inline">\(i\)</span> 個觀察值擬合的預測值，被叫做因變量的估計期望值 (estimated expectation)。用下面的式子來表示:</p>
<p><span class="math display">\[
\hat{y}_i=\hat\alpha+\hat\beta x_i
\]</span></p>
<p>此時，第 <span class="math inline">\(i\)</span> 名對象的觀察殘差 (observed or fitted or estimated residuals) 用下面的式子來表示：</p>
<p><span class="math display">\[
\hat{\varepsilon}_i = y_i-\hat{y}_i=y_i-(\hat\alpha+\hat\beta x_i)
\]</span></p>
<div id="MLEalphabeta" class="section level3">
<h3><span class="header-section-number">26.4.1</span> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></h3>
<p>普通最小二乘法估計的 <span class="math inline">\(\alpha, \beta\)</span> 會最小化擬合迴歸直線的偏差 minimize the sum of squared deviations from the fitted regression line。其正式的定義爲：OLS估計值，指的是能夠使<strong>殘差平方和 (residual sum of squares, <span class="math inline">\(SS_{RES}\)</span>)</strong>取最小值的 <span class="math inline">\(\hat\alpha, \hat\beta\)</span>。</p>
<p><span class="math display" id="eq:ssres">\[
\begin{equation}
SS_{RES} = \sum_{i=1}^n \hat{\varepsilon}^2_i = \sum_{i=1}^n (y_i-\hat\alpha-\hat\beta x_i)^2
\end{equation}
\tag{26.4}
\]</span></p>
<p>可以證明的是，OLS的 <span class="math inline">\(\alpha, \beta\)</span> 估計值的計算公式爲：</p>
<p><span class="math display" id="eq:hatalpha">\[
\begin{equation}
\hat\alpha=\bar{y}-\hat\beta\bar{x}
\tag{26.5}
\end{equation}
\]</span></p>
<p><span class="math display" id="eq:hatbeta">\[
\begin{equation}
\hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}
\tag{26.6}
\end{equation}
\]</span></p>
<p>其中 <span class="math inline">\(\bar{y}=\frac{\sum_{i=1}^ny_i}{n}, \bar{x}=\frac{\sum_{i=1}^nx_i}{n}\)</span></p>
<p><strong>證明</strong></p>
<p>求能最小化 <span class="math inline">\(SS_{RES}\)</span> 的 <span class="math inline">\(\alpha\)</span>， 我們需要把公式 <a href="#eq:ssres">(26.4)</a> 對 <span class="math inline">\(\hat\alpha\)</span> 求導，然後將求導之後的式子等於 <span class="math inline">\(0\)</span> 之後求根即可：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\text{d}SS_{RES}}{\text{d}\hat\alpha} =\sum_{i=1}^n -2(y_i-\hat\alpha-\hat\beta x_i) = 0\\
&amp; \text{Since } \sum_{i=1}^n(y_i) = n\bar{y}; \sum_{i=1}^n (x_i) =n\bar{x} \\
&amp; \Rightarrow -n\bar{y}+n\hat\alpha+n\hat\beta\bar{x} = 0 \\
&amp; \Rightarrow \hat\alpha = \bar{y}-\hat\beta\bar{x}
\end{aligned}
\]</span></p>
<p>求能最小化 <span class="math inline">\(SS_{RES}\)</span> 的 <span class="math inline">\(\beta\)</span>，求導之前我們先把公式 <a href="#eq:ssres">(26.4)</a> 中含有 <span class="math inline">\(\hat\alpha\)</span> 的部分替換掉：</p>
<p><span class="math display" id="eq:ssres-rearrange">\[
\begin{equation}
\begin{split}
SS_{RES} &amp;= \sum_{i=1}^n\hat\varepsilon_i^2=\sum_{i=1}^n(y_i-(\bar{y}-\hat\beta\bar{x})-\hat\beta x_i)^2\\
         &amp;= \sum_{i=1}^n((y_i-\bar{y})-\hat\beta(x_i-\bar{x}))^2 \\
\end{split}
\tag{26.7}
\end{equation}
\]</span></p>
<p>接下來對上式 <a href="#eq:ssres-rearrange">(26.7)</a> 求導之後，用相同辦法求根：</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{\mathrm{d} SS_{RES}}{\mathrm{d} \hat\beta} = \sum_{i=1}^n -2(x_i-\bar{x})(y_i-\bar{y}) + 2\hat\beta(x_i-\bar{x})^2 = 0\\
&amp; \Rightarrow \hat\beta\sum_{i=1}^n(x_i-\bar{x})^2 = \sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y}) \\
&amp; \hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}
\end{aligned}
\]</span></p>
<p>這兩個式子 <a href="#eq:hatalpha">(26.5)</a> <a href="#eq:hatbeta">(26.6)</a> 同時也是參數 <span class="math inline">\(\alpha, \beta\)</span> 的極大似然估計 (MLE)。</p>
</div>
</div>
<div id="ResidualVar" class="section level2">
<h2><span class="header-section-number">26.5</span> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></h2>
<p>殘差方差等於殘差平方和除以樣本量。所以我們會把殘差方差的估計用下面的式子表示：</p>
<p><span class="math display" id="eq:sigma2wrong">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n \frac{\hat\varepsilon^2}{n} = \sum_{i=1}^n \frac{(y_i-\hat\alpha-\hat\beta x_i)^2}{n}
\end{equation}
\tag{26.8}
\]</span></p>
<p>這的確是 <span class="math inline">\(\sigma^2\)</span> 的極大似然估計 (MLE)。然而我們知道，公式 <a href="#eq:sigma2wrong">(26.8)</a> 並不是殘差方差的無偏估計。類似與樣本方差低估了總體方差 (Section <a href="#samplevarbias">10.3</a>)，那樣，這裏殘差方差的觀察值也是低估了總體殘差方差的。所以，殘差方差的無偏估計需要用下面的式子來校正：</p>
<p><span class="math display" id="eq:sigma2right">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n \frac{\hat\varepsilon^2}{n-2} = \sum_{i=1}^n \frac{(y_i-\hat\alpha-\hat\beta x_i)^2}{n-2}
\end{equation}
\tag{26.9}
\]</span></p>
<p>公式 <a href="#eq:sigma2right">(26.9)</a> 被叫做殘差均方 (Residual Mean Squares, RMS)，常常被標記爲 <span class="math inline">\(\text{MS}_{RES}\)</span>。分母的 <span class="math inline">\(n-2\)</span>，表示進行殘差方差估計時用掉了兩個信息量 <span class="math inline">\(\alpha, \beta\)</span> (自由度減少了 2)，</p>
</div>
<div id="growgam" class="section level2">
<h2><span class="header-section-number">26.6</span> R 演示 例 1： 圖 <a href="#fig:age-wt">26.1</a> 數據</h2>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb71-2" title="2">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb71-3" title="3"></a>
<a class="sourceLine" id="cb71-4" title="4">slm &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb71-5" title="5"></a>
<a class="sourceLine" id="cb71-6" title="6"><span class="kw">summary</span>(slm) <span class="co"># basic default output of the summary</span></a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.924 -0.785  0.007  0.797  4.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.8376     0.2101    32.5   &lt;2e-16 ***
## age           0.1653     0.0111    14.9   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.27 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(slm), <span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show the sum of squares for the fitted model and residuals</span></a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>也可以用 <code>stargazer</code> 包輸出很酷的表格報告：</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1"><span class="kw">library</span>(stargazer)</a>
<a class="sourceLine" id="cb75-2" title="2"><span class="kw">stargazer</span>(slm, <span class="dt">type =</span> <span class="st">&quot;html&quot;</span>)</a></code></pre></div>
<table style="text-align:center">
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
wt
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
0.165<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
6.838<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.210)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
190
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.541
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.538
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
1.274 (df = 188)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
221.400<sup>***</sup> (df = 1; 188)
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
<p>其實結果都一樣。我們這裏詳細來看 <span class="math inline">\(\alpha, \beta, \sigma^2\)</span>：</p>
<p><span class="math inline">\(\hat\alpha = 6.84\)</span>：當年齡爲 <span class="math inline">\(0\)</span> 時，體重爲 <span class="math inline">\(6.84 kg\)</span>。本數據 <a href="#fig:age-wt">26.1</a> 中並沒有 <span class="math inline">\(0\)</span> 歲的兒童，所以這裏的截距的解釋需要非常小心是否合理。</p>
<p><span class="math inline">\(\hat\beta = 0.165\)</span>：這數據中兒童的體重估計隨着年齡升高 <span class="math inline">\(1\)</span> 個月增長 <span class="math inline">\(0.165 kg\)</span>。所以使用這兩個估計值我們就可以來估計任意年齡時兒童的體重。圖 <a href="#fig:age-wt-lm">26.2</a> 就是擬合數據以後的簡單線性迴歸曲線。</p>
<p><span class="math inline">\(\hat\sigma^2 = 1.62, \hat\sigma=1.27\)</span> 就是默認輸出中最下面的 <code>Residual standard error: 1.274</code> 和 ANOVA 表格中 Residuals 的 <code>Mean Sq=1.62184</code> 部分。含義是，沿着擬合的直線，在每一個給定的年齡上兒童體重的分佈的標準差是 <span class="math inline">\(1.27 kg\)</span>。</p>
</div>
<div id="binarylms" class="section level2">
<h2><span class="header-section-number">26.7</span> R 演示 例 2： 表<a href="#tab:walk">26.1</a> 數據</h2>
<p>如果在 <code>Stata</code> 聽說你還需要自己生成啞變量 (dummy variables) (應該是計算時，在想要變成啞變量的變量名前面加上 <code>i.</code>)。在 <a href="https://www.r-project.org/">R</a> 裏面，分類變量被設置成因子 “factor” 時，你就完全可以忽略生成啞變量的過程。下圖 <a href="#fig:age-walk">26.5</a> 顯示了兩組兒童直立行走時的年齡。</p>
<div class="figure" style="text-align: center"><span id="fig:age-walk"></span>
<img src="bookdown_files/figure-html/age-walk-1.png" alt="Age at walking by group" width="80%" />
<p class="caption">
圖 26.5: Age at walking by group
</p>
</div>
<p>擬合簡單線性迴歸也是小菜一碟：</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1">wk_age &lt;-<span class="st"> </span><span class="kw">lm</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>Walk)</a>
<a class="sourceLine" id="cb76-2" title="2"></a>
<a class="sourceLine" id="cb76-3" title="3"><span class="kw">summary</span>(wk_age)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Age ~ Group, data = Walk)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -1.125 -0.738 -0.375  0.388  2.875 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    10.125      0.512   19.77    1e-08 ***
## Groupcontrol    2.225      0.760    2.93    0.017 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.25 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.488,  Adjusted R-squared:  0.431 
## F-statistic: 8.58 on 1 and 9 DF,  p-value: 0.0168</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">anova</span>(wk_age)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Age
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Group      1   13.5   13.50    8.58  0.017 *
## Residuals  9   14.2    1.57                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>這裏的 <span class="math inline">\(\hat\alpha=10.125\)</span>，意爲參照組 (此處，“exercise” 被默認設定爲參照組，而 “control” 被默認拿來和參照組相比較) 的兒童也就是，積極練習走路的小朋友這組能夠獨立行走的平均年齡是 <span class="math inline">\(10.125\)</span> 個月。</p>
<p><span class="math inline">\(\hat\beta=2.225\)</span>，意爲和參照組 (積極練習組) 相比，對照組兒童能夠自己行走的年齡平均要晚 <span class="math inline">\(2.225\)</span> 個月。所以對照組兒童能夠直立行走的平均年齡就是 <span class="math inline">\(10.125+2.225=12.35\)</span> 個月。</p>
<p>上述結果，你如果拿來和下面的兩樣本 <span class="math inline">\(t\)</span> 檢驗的結果相比就知道，是完全一致的。其中統計量 <span class="math inline">\(t^2=2.9285^2=F_{1,9}=8.58\)</span>。</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="kw">t.test</span>(Age<span class="op">~</span>Group, <span class="dt">data=</span>Walk, <span class="dt">var.equal=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Age by Group
## t = -2.9, df = 9, p-value = 0.02
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.9437 -0.5063
## sample estimates:
## mean in group exercise  mean in group control 
##                  10.12                  12.35</code></pre>
</div>
<div id="exeChol" class="section level2">
<h2><span class="header-section-number">26.8</span> 練習</h2>
<p>使用的數據內容爲：兩次調查同一樣本，99 名健康男性的血清膽固醇水平，間隔一年。</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="co"># 數據讀入</span></a>
<a class="sourceLine" id="cb82-2" title="2">Chol &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/chol.dta&quot;</span>)</a>
<a class="sourceLine" id="cb82-3" title="3"><span class="kw">summary</span>(Chol)</a></code></pre></div>
<pre><code>##        id           chol1         chol2    
##  Min.   : 1.0   Min.   :152   Min.   :170  
##  1st Qu.:25.5   1st Qu.:235   1st Qu.:240  
##  Median :50.0   Median :265   Median :260  
##  Mean   :50.0   Mean   :265   Mean   :264  
##  3rd Qu.:74.5   3rd Qu.:290   3rd Qu.:290  
##  Max.   :99.0   Max.   :360   Max.   :355</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1"><span class="co"># Alternative Descriptive Statistics using psych package</span></a>
<a class="sourceLine" id="cb84-2" title="2"><span class="kw">describe</span>(Chol)</a></code></pre></div>
<pre><code>## Chol 
## 
##  3  Variables      99  Observations
## ----------------------------------------------------------------------------------------------------
## id  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       99        1       50    33.33      5.9     10.8     25.5     50.0     74.5 
##      .90      .95 
##     89.2     94.1 
## 
## lowest :  1  2  3  4  5, highest: 95 96 97 98 99
## ----------------------------------------------------------------------------------------------------
## chol1  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       51    0.999    264.6    46.11    204.5    210.0    235.0    265.0    290.0 
##      .90      .95 
##    320.0    330.3 
## 
## lowest : 152 170 190 200 205, highest: 333 340 350 355 360
## ----------------------------------------------------------------------------------------------------
## chol2  Format:%9.0g 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       99        0       30    0.997    263.5    43.28      200      215      240      260      290 
##      .90      .95 
##      311      330 
## 
## lowest : 170 190 195 200 205, highest: 320 330 345 350 355
## ----------------------------------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="co"># 兩次膽固醇水平的直方圖 Distribution of the two measures</span></a>
<a class="sourceLine" id="cb86-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb86-3" title="3"><span class="kw">hist</span>(Chol<span class="op">$</span>chol1)</a>
<a class="sourceLine" id="cb86-4" title="4"><span class="kw">hist</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM04-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" title="1"><span class="co"># 對兩次膽固醇水平作散點圖</span></a>
<a class="sourceLine" id="cb87-2" title="2"><span class="kw">ggplot</span>(Chol, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-3" title="3"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb87-4" title="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-5" title="5"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM04-2.png" width="80%" style="display: block; margin: auto;" /></p>
<div id="兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些" class="section level3">
<h3><span class="header-section-number">26.8.1</span> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</h3>
<ul>
<li>每個觀察對象互相獨立。</li>
<li>前後兩次測量的膽固醇水平呈線性相關。</li>
<li>殘差值，在每一個給定的 <span class="math inline">\(C_1\)</span> 值處呈現正態分佈，且方差不變。</li>
</ul>
<p>從散點圖來看這些假設應該都能得到滿足。</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="co"># 計算兩次膽固醇水平的 均值，方差，以及二者的協方差</span></a>
<a class="sourceLine" id="cb88-2" title="2"><span class="kw">mean</span>(Chol<span class="op">$</span>chol1); <span class="kw">mean</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 264.6</code></pre>
<pre><code>## [1] 263.5</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">var</span>(Chol<span class="op">$</span>chol1); <span class="kw">var</span>(Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 1661</code></pre>
<pre><code>## [1] 1457</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1"><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)</a></code></pre></div>
<pre><code>## [1] 961.2</code></pre>
</div>
<div id="計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta" class="section level3">
<h3><span class="header-section-number">26.8.2</span> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></h3>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp;= \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}\\
&amp;=\frac{\text{Cov}(C_1,C_2)}{\text{Var}(C_1)}\\
&amp;=\frac{1661.061}{961.224}=0.578
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1"><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)<span class="op">/</span><span class="kw">var</span>(Chol<span class="op">$</span>chol1)</a></code></pre></div>
<pre><code>## [1] 0.5787</code></pre>
<p><span class="math display">\[\hat\alpha=\bar{y}-\hat\beta\bar{x}=263.54-0.578\times264.59=110.425\]</span></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" title="1"><span class="kw">mean</span>(Chol<span class="op">$</span>chol2)<span class="op">-</span><span class="kw">mean</span>(Chol<span class="op">$</span>chol1)<span class="op">*</span><span class="kw">cov</span>(Chol<span class="op">$</span>chol1, Chol<span class="op">$</span>chol2)<span class="op">/</span><span class="kw">var</span>(Chol<span class="op">$</span>chol1)</a></code></pre></div>
<pre><code>## [1] 110.4</code></pre>
</div>
<div id="和迴歸模型計算的結果作比較解釋這些估計值的含義" class="section level3">
<h3><span class="header-section-number">26.8.3</span> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</h3>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chol2 ~ chol1, data = Chol)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -56.88 -22.06   1.85  16.63  84.12 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 110.4247    20.0113    5.52  2.8e-07 ***
## chol1         0.5787     0.0748    7.74  9.5e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.2 on 97 degrees of freedom
## Multiple R-squared:  0.382,  Adjusted R-squared:  0.375 
## F-statistic: 59.9 on 1 and 97 DF,  p-value: 9.51e-12</code></pre>
<ul>
<li>截距的估計值是 110.4 mg/100ml: 意爲這組樣本，第一次採集數據時，膽固醇水平的平均值是 110.4。</li>
<li>斜率的估計值是 0.58：意爲第一次採集的膽固醇水平每高 1 mg/100ml，那麼第二次採集的膽固醇相應提高的值的期待量爲 0.58.</li>
</ul>
</div>
<div id="加上計算的估計值直線-即迴歸直線" class="section level3">
<h3><span class="header-section-number">26.8.4</span> 加上計算的估計值直線 (即迴歸直線)</h3>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1"><span class="kw">ggplot</span>(Chol, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-2" title="2"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-3" title="3"><span class="st">   </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb102-4" title="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb102-5" title="5"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM09-1.png" width="672" /></p>
<p>可以注意到，第一次訪問時膽固醇水平高的人，第二次被測量時膽固醇值高於平均值，但是卻沒有第一次高出平均值的部分多。
相似的，第一次膽固醇水平低的人，第二次膽固醇水平低於平均值，但是卻沒有第一次低於平均值的部分多。這一現象被叫做 “向均數迴歸-regression to the mean”</p>
</div>
<div id="diagnosis" class="section level3">
<h3><span class="header-section-number">26.8.5</span> 下面的代碼用於模型的假設診斷</h3>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1">M &lt;-<span class="st"> </span><span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol)</a>
<a class="sourceLine" id="cb103-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))  <span class="co"># Split the plotting panel into a 2 x 2 grid</span></a>
<a class="sourceLine" id="cb103-3" title="3"><span class="kw">plot</span>(M)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM10-1.png" width="672" /></p>
<p>好心人在 <a href="https://gist.github.com/atyre2/ff4e1ec24e42adda8dbd43cda99d6282">github</a> 上共享了 <code>Check_assumption.R</code> 的代碼，可以使用 ggplot2 來獲取高逼格的模型診斷圖：</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">source</span>(<span class="st">&quot;checkassumptions.R&quot;</span>)</a>
<a class="sourceLine" id="cb104-2" title="2"><span class="kw">check_assumptions</span>(M)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM11-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference" class="section level1">
<h1><span class="header-section-number">第 27 章</span> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</h1>
<p>前一章介紹了簡單線性迴歸模型中對總體參數 <span class="math inline">\(\alpha, \beta, \sigma^2\)</span> 的估計公式，分別是 <a href="#eq:hatalpha">(26.5)</a> <a href="#eq:hatbeta">(26.6)</a> <a href="#eq:sigma2right">(26.9)</a>。本章繼續介紹他們的統計學性質。下面的標記和統計量也會被用到：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\bar{y}=\frac{\sum_{i=1}^n y_i}{n}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本均值；</li>
<li><span class="math inline">\(\bar{x}=\frac{\sum_{i=1}^n x_i}{n}\)</span>，預測變量 <span class="math inline">\(x\)</span> 的樣本均值；</li>
<li><span class="math inline">\(SS_{yy}=\sum_{i=1}^n(y_i-\bar{y})^2\)</span>，因變量 <span class="math inline">\(y\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SS_{xx}=\sum_{i=1}^n(x_i-\bar{x})^2\)</span>，預測變量 <span class="math inline">\(x\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SD_y^2=\frac{\sum_{i=1}(y_i-\bar{y})^2}{n-1}=\frac{SS_{yy}}{n-1}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本方差；</li>
<li><span class="math inline">\(SD_x^2=\frac{\sum_{i=1}(x_i-\bar{x})^2}{n-1}=\frac{SS_{xx}}{n-1}\)</span>，預測變量 <span class="math inline">\(x\)</span> 的樣本方差；</li>
<li><span class="math inline">\(S_{xy}=\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})\)</span>，<span class="math inline">\(x,y\)</span> 的交叉乘積；</li>
<li><span class="math inline">\(CV_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}=\frac{S_{xy}}{n-1}\)</span>，樣本協方差；</li>
<li><span class="math inline">\(r_{xy}=\frac{CV_{xy}}{SD_xSD_y}\)</span>，<span class="math inline">\(x,y\)</span> 的樣本相關係數；</li>
<li><span class="math inline">\(SS_{RES}=\sum_{i=1}^n\hat\varepsilon^2=\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2\)</span>，殘差的估計平方和。</li>
</ol>
<div id="ols-估計量的性質" class="section level2">
<h2><span class="header-section-number">27.1</span> OLS 估計量的性質</h2>
<ol style="list-style-type: decimal">
<li>樣本估計的迴歸直線必定穿過數據的中心 <span class="math inline">\((\bar{x},\bar{y})\)</span>。</li>
</ol>
<p><strong>證明</strong></p>
<p>由於樣本估計的截距和斜率公式 <a href="#eq:hatalpha">(26.5)</a> <a href="#eq:hatbeta">(26.6)</a> 可知：</p>
<p><span class="math display" id="eq:lmcenter">\[
\begin{aligned}
\hat\alpha &amp;= \bar{y} - \hat\beta\bar{x} \\
 \hat y_i  &amp;= \hat\alpha + \hat\beta x_i \\
 \Rightarrow \hat y_i &amp;= \bar{y}+\hat\beta(x_i-\bar{x})
\end{aligned}
\tag{27.1}
\]</span></p>
<p>所以，當 <span class="math inline">\(\hat x_i=\bar{x}\)</span> 時 <span class="math inline">\(\hat y_i=\bar{y}\)</span>。即迴歸直線必然穿過中心點。</p>
<ol start="2" style="list-style-type: decimal">
<li>如果擬合模型是正確無誤的， <span class="math inline">\(\hat\alpha,\hat\beta,\hat\sigma^2\)</span> 分別是各自的無偏估計。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是極大似然估計， <span class="math inline">\(\hat\sigma^2\)</span> 不是MLE。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是 <span class="math inline">\(\alpha, \beta\)</span> 最有效的估計量。</li>
</ol>
</div>
<div id="beta" class="section level2">
<h2><span class="header-section-number">27.2</span> <span class="math inline">\(\hat\beta\)</span> 的性質</h2>
<p><span class="math display" id="eq:hatbetaalt">\[
\begin{equation}
\hat\beta=\frac{S_{xy}}{SS_{xx}}=\frac{CV_{xy}}{SD_x^2}
\end{equation}
\tag{27.2}
\]</span></p>
<div id="randbeta" class="section level3">
<h3><span class="header-section-number">27.2.1</span> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</h3>
<p>如果我們使用 <span class="math inline">\(\hat\beta_{y|x}\)</span> 表示預測變量 <span class="math inline">\(x\)</span>，因變量 <span class="math inline">\(y\)</span> 的簡單線性迴歸係數，那麼我們就有：</p>
<p><span class="math display" id="eq:r2">\[
\begin{equation}
\hat\beta_{y|x} = \frac{CV_{xy}}{SD_x^2}  \text{ and } \hat\beta_{x|y} = \frac{CV_{xy}}{SD_y^2} \\
\text{Hence, } \hat\beta_{y|x}\hat\beta_{x|y} = r^2_{xy}
\end{equation}
\tag{27.3}
\]</span></p>
<p>公式 <a href="#eq:r2">(27.3)</a> 也證明了：如果兩個變量相關係數爲 <span class="math inline">\(1\)</span> (100% 相關)， <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸的迴歸係數，是 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸的迴歸係數的倒數。</p>
</div>
<div id="例-1-還是圖-reffigage-wt-數據" class="section level3">
<h3><span class="header-section-number">27.2.2</span> 例 1： 還是圖 <a href="#fig:age-wt">26.1</a> 數據</h3>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb105-2" title="2">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb105-3" title="3"></a>
<a class="sourceLine" id="cb105-4" title="4"><span class="co"># regress wt on age</span></a>
<a class="sourceLine" id="cb105-5" title="5"><span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.924 -0.785  0.007  0.797  4.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.8376     0.2101    32.5   &lt;2e-16 ***
## age           0.1653     0.0111    14.9   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.27 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" title="1"><span class="co"># regress age on wt</span></a>
<a class="sourceLine" id="cb109-2" title="2"><span class="kw">summary</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = age ~ wt, data = growgam1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.010  -4.239   0.083   3.130  21.111 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -14.57       2.16   -6.75  1.8e-10 ***
## wt              3.27       0.22   14.88  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.66 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: age
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## wt          1 7103.6730 7103.6730 221.39203 &lt; 2.22e-16 ***
## Residuals 188 6032.2428   32.0864                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>可以看到二者的輸出結果中統計檢驗量一樣，但是一個是將體重針對年齡迴歸，另一個則是反過來，所以迴歸係數和截距都不同。迴歸方程的含義也就發生了變化。如果把兩條迴歸曲線同時作圖可以更加直觀：</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm1"></span>
<img src="bookdown_files/figure-html/age-wt-lm1-1.png" alt="Simple linear regression model line relating weight to age" width="80%" />
<p class="caption">
圖 27.1: Simple linear regression model line relating weight to age
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:wt-age-lm"></span>
<img src="bookdown_files/figure-html/wt-age-lm-1.png" alt="Simple linear regression model line relating age to weight" width="80%" />
<p class="caption">
圖 27.2: Simple linear regression model line relating age to weight
</p>
</div>
</div>
</div>
<div id="截距和迴歸係數的方差協方差" class="section level2">
<h2><span class="header-section-number">27.3</span> 截距和迴歸係數的方差，協方差</h2>
<p>假如簡單線性迴歸模型是正確的，那麼截距 <span class="math inline">\(\hat\alpha\)</span> 和迴歸係數 <span class="math inline">\(\hat\beta\)</span> 的方差分別是：</p>
<p><span class="math display" id="eq:varhatalpha">\[
\begin{equation}
V(\hat\alpha) = \sigma^2(\frac{1}{n}+\frac{\bar{x}^2}{SS_{xx}}) = \frac{\sigma^2}{(n-1)} (1-\frac{1}{n}+\frac{\bar{x}^2}{SD_x^2})
\end{equation}
\tag{27.4}
\]</span></p>
<p><span class="math display" id="eq:varhatbeta">\[
\begin{equation}
V(\hat\beta) = \frac{\sigma^2}{SS_{xx}}=\frac{\sigma^2}{(n-1)SD_x^2}
\end{equation}
\tag{27.5}
\]</span></p>
<p>從公式 <a href="#eq:varhatalpha">(27.4)</a> 和 <a href="#eq:varhatbeta">(27.5)</a> 也可以看出，兩個估計量的方差隨着殘差方差的增加而增加 (估計不精確)，隨着樣本量的增加而減少 (估計更精確)。截距 <span class="math inline">\(\hat\alpha\)</span> 的方差會隨着樣本均值的增加而增加。</p>
<p>通常來說，截距和迴歸係數二者之間並非相互獨立。他們的協方差爲：</p>
<p><span class="math display" id="eq:covaralphabeta">\[
\begin{equation}
Cov(\hat\alpha,\hat\beta) = -\frac{\sigma^2\bar{x}}{SS_{xx}}
\end{equation}
\tag{27.6}
\]</span></p>
<p>上面的公式 <a href="#eq:varhatalpha">(27.4)</a> <a href="#eq:varhatbeta">(27.5)</a> <a href="#eq:covaralphabeta">(27.6)</a> 都包含了真實的殘差方差 <span class="math inline">\(\sigma^2\)</span>。這個量對於我們“人類”來說是未知的。</p>
<div id="centring" class="section level3">
<h3><span class="header-section-number">27.3.1</span> 中心化 centring</h3>
<p>簡單線性迴歸模型常用的一個技巧是將預測變量中心化。即，求預測變量的均值，然後將每個觀測值減去均值之後再用這個新的預測變量擬合簡單線性迴歸模型。這樣做其實完全不影響回顧係數，卻會影響截距的大小。此時新的迴歸直線的截距，就等於因變量 (體重) 的均值。</p>
<p>用圖 <a href="#fig:age-wt">26.1</a> 數據來解釋：</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" title="1"><span class="co"># mean value of age</span></a>
<a class="sourceLine" id="cb113-2" title="2"><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a></code></pre></div>
<pre><code>## [1] 16.98</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" title="1">growgam1<span class="op">$</span>age_cen &lt;-<span class="st"> </span>growgam1<span class="op">$</span>age<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb115-2" title="2"><span class="co"># regress wt on age</span></a>
<a class="sourceLine" id="cb115-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 6.837584   0.210070  32.549 &lt; 2.2e-16 ***
## age         0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" title="1"><span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age_cen, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age_cen, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 9.644737   0.092391 104.391 &lt; 2.2e-16 ***
## age_cen     0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>很明顯，結果顯示中心化不會改變迴歸係數，也不會改變它的方差。但是“新”的截距，其實就等於因變量 (體重) 的均值。而且很多數據都集中在這個均值附近，因而，截距的方差比沒有中心化的迴歸方程要小。</p>
</div>
</div>
<div id="alpha-beta-的推斷" class="section level2">
<h2><span class="header-section-number">27.4</span> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</h2>
<p><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 都可以被改寫成關於因變量 <span class="math inline">\(Y\)</span> 的方程，因此同時也是隨機誤差的方程式：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp;= \sum_{i=1}^n[\frac{(x_i-\bar{x})}{SS_{xx}}(y_i-\bar{y})] \\
\text{Substituting } &amp;(y_i-\bar{y}) = \beta(x_i-\bar{x})+(\varepsilon_i-\bar{\varepsilon}) \\
          &amp;= \beta + \sum_{i=1}^n[\frac{x_i-\bar{x}}{SS_{xx}}(\varepsilon_i-\bar{\varepsilon})]
\end{aligned}
\]</span></p>
<p>又因爲，<span class="math inline">\(\varepsilon_i \sim NID(0,\sigma^2)\)</span>，估計量 <span class="math inline">\(\hat\alpha, \hat\beta\)</span> 均爲 <span class="math inline">\(\varepsilon_i\)</span> 的線性轉換，所以他們也都是服從正態分佈的。</p>
<div id="對迴歸係數進行假設檢驗" class="section level3">
<h3><span class="header-section-number">27.4.1</span> 對迴歸係數進行假設檢驗</h3>
<p>對於迴歸係數 <span class="math inline">\(\beta\)</span>，我們可以使用 Wald statistic (Section <a href="#Wald">16.4</a>) 進行零假設爲 <span class="math inline">\(\text{H}_0: \beta=0\)</span> 的假設檢驗。此時，替代假設爲 <span class="math inline">\(\text{H}_1: \beta\neq0\)</span>。最佳檢驗統計量爲：</p>
<p><span class="math display" id="eq:betattest">\[
\begin{equation}
t = \frac{\hat\beta-0}{SE(\hat\beta)} \\
\end{equation}
\tag{27.7}
\]</span></p>
<p>根據公式 <a href="#eq:varhatbeta">(27.5)</a> <span class="math inline">\(SE(\hat\beta) = \sqrt{V(\hat\beta)} = \frac{\hat\sigma}{\sqrt{SS_{xx}}}\)</span>。用 <span class="math inline">\(\hat\sigma^2\)</span> 替換掉公式 <a href="#eq:varhatbeta">(27.5)</a> 中的 <span class="math inline">\(\sigma^2\)</span>，意味着迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 服從自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈。之後就可以根據 <span class="math inline">\(t\)</span> 分佈的性質求相應的 <span class="math inline">\(p\)</span> 值了，對相關係數是否爲 <span class="math inline">\(0\)</span> 進行檢驗。之所以我們可以在這裏使用 Wald 檢驗，是因爲前提條件：隨機誤差服從正態分佈，於是 <span class="math inline">\(\beta\)</span> 的對數似然比也是左右對稱的，當對數似然比的圖形左右對稱時，就可以使用二次方程來近似 (Wald 檢驗的實質)。</p>
</div>
<div id="迴歸係數截距的信賴區間" class="section level3">
<h3><span class="header-section-number">27.4.2</span> 迴歸係數，截距的信賴區間</h3>
<p>估計量 <span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算公式如下：</p>
<p><span class="math display" id="eq:CIbeta">\[
\begin{equation}
\hat\beta \pm t_{n-2,0.975}SE(\hat\beta)
\end{equation}
\tag{27.8}
\]</span></p>
<p>其中，<span class="math inline">\(t_{n-2, 0.975}\)</span> 表示自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈的 <span class="math inline">\(97.5\%\)</span> 位點的值。繼續使用之前的實例，圖 <a href="#fig:age-wt">26.1</a> 中的數據。體重對年齡進行簡單線性迴歸之後，年齡的估計回顧係數 <span class="math inline">\(\hat\beta=0.165, SE(\hat\beta)=0.0111\)</span>, 此例中 <span class="math inline">\(n=190\)</span>，所以 <span class="math inline">\(t_{188, 0.975}=1.973\)</span>。所以迴歸係數的 <span class="math inline">\(95\%\)</span> 信賴區間可以如此計算：<span class="math inline">\(0.165\pm1.973\times0.0111=(0.143, 0.187)\)</span>。</p>
<p>類似的，估計截距 <span class="math inline">\(\hat\alpha\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算式便是： <span class="math inline">\(\hat\alpha \pm t_{n-2, 0.975}SE(\hat\alpha)\)</span>。同樣的例子裏，<span class="math inline">\(\hat\alpha=6.838, SE(\hat\beta) = 0.210, t_{188, 0.975}=1.973\)</span>。所以截距的 <span class="math inline">\(95\%\)</span> 信賴區間的計算方法就是： <span class="math inline">\(6.838\pm1.973\times0.210=(6.42, 7.25)\)</span></p>
<p>跟下面 R 計算的完全一樣：</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</a></code></pre></div>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 6.4232 7.2520
## age         0.1434 0.1873</code></pre>
</div>
<div id="預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性" class="section level3">
<h3><span class="header-section-number">27.4.3</span> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</h3>
<p>這裏所謂的“預測值”其實並沒有拿來預測什麼新的數值，而是說我們希望通過線性迴歸找到因變量真實值的存在區間 (信賴區間)。所以這個預測值的真實含義其實應該是在預測變量取 <span class="math inline">\(X=x\)</span> 時，因變量的期待值，<span class="math inline">\(E(Y|X=x)\)</span>。</p>
<p>這個預測值的方差公式如下：</p>
<p><span class="math display" id="eq:predictvar">\[
\begin{equation}
V(\hat y_{x}) = \sigma^2[\frac{1}{n}+\frac{(x_i-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{27.9}
\]</span></p>
<p>於是可以計算它的 <span class="math inline">\(95\%\)</span> 信賴區間公式是：</p>
<p><span class="math display" id="eq:predictCI">\[
\begin{equation}
\hat y_x \pm t_{n-2, 0.975} \hat\sigma \sqrt{[\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]}
\end{equation}
\tag{27.10}
\]</span></p>
<p>其實在之前的圖 (圖 <a href="#fig:age-wt-lm">26.2</a>) 我們也已經展示過這個信賴區間的範圍。</p>
</div>
<div id="預測帶-reference-range---包含了-95-觀察值的區間" class="section level3">
<h3><span class="header-section-number">27.4.4</span> 預測帶 Reference range - 包含了 95% 觀察值的區間</h3>
<p>此處的 <span class="math inline">\(95\%\)</span> 預測帶，其實是包含了 <span class="math inline">\(95\%\)</span> 觀察數據的區間。所以預測帶要比置信帶更寬。它的方差計算公式爲：</p>
<p><span class="math display" id="eq:refrangevar">\[
\begin{equation}
V(\hat y_x)+\sigma^2 = \sigma^2[1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{27.11}
\]</span></p>
<p>區間計算公式爲：</p>
<p><span class="math display" id="eq:refrangeCI">\[
\begin{equation}
\hat{y}_x \pm t_{n-2, 0.975} \sqrt{1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}}
\end{equation}
\tag{27.12}
\]</span></p>
<p>將置信帶和預測帶同時展現則如下圖：</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb121-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb121-2" title="2"></a>
<a class="sourceLine" id="cb121-3" title="3"></a>
<a class="sourceLine" id="cb121-4" title="4">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb121-5" title="5">temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a>
<a class="sourceLine" id="cb121-6" title="6"></a>
<a class="sourceLine" id="cb121-7" title="7">new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(growgam1, temp_var)</a>
<a class="sourceLine" id="cb121-8" title="8"></a>
<a class="sourceLine" id="cb121-9" title="9"></a>
<a class="sourceLine" id="cb121-10" title="10"><span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>wt)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-11" title="11"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">TRUE</span>, <span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-12" title="12"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb121-13" title="13"><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb121-14" title="14"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">38</span>, <span class="dv">4</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">36.5</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb121-15" title="15"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">5</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">20.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-16" title="16"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age (Months)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Weight (kg)&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm-pred"></span>
<img src="bookdown_files/figure-html/age-wt-lm-pred-1.png" alt="Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range" width="80%" />
<p class="caption">
圖 27.3: Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range
</p>
</div>
</div>
</div>
<div id="rsquare" class="section level2">
<h2><span class="header-section-number">27.5</span> 線性迴歸模型和 Pearson 相關係數</h2>
<p>前面也推導過線性迴歸係數和 Pearson 相關係數之間的關係 (Section <a href="#randbeta">27.2.1</a>)，這裏詳細再展開討論它們之間關係的另外兩個重要結論。</p>
<div id="r2-可以理解爲因變量平方和被模型解釋的比例" class="section level3">
<h3><span class="header-section-number">27.5.1</span> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</h3>
<p>Pearson 相關係數，因變量的平方和，模型的殘差平方和之間有如下的關係：</p>
<p><span class="math display" id="eq:rSSyySSres">\[
\begin{equation}
r^2 = \frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1-\frac{SS_{RES}}{SS_{yy}}
\end{equation}
\tag{27.13}
\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\frac{SS_{RES}}{SS_{yy}} = \frac{\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\]</span></p>
<p>因爲 <a href="#eq:hatalpha">(26.5)</a> : <span class="math inline">\(\hat\alpha=\bar{y}-\hat{\beta}\bar{x}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= \frac{\sum_{i=1}^n[(y_i-\bar{y})-\hat\beta(x_i-\bar{x})]^2}{\sum_{i=1}^n(y_i-\bar{y})^2} \\
                  &amp;=\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}-\frac{2\hat\beta\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(y_i-\bar{y})^2}+\frac{\hat\beta^2\sum_{i=1}^n(x_i-\bar{x})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}\\
                  &amp;=1-\frac{2\hat\beta S_{xy}}{SS_{yy}} + \frac{\hat\beta^2SS_{xx}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>又因爲 <span class="math inline">\(\hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{S_{xy}}{SS_{xx}}, r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= 1-\frac{2S_{xy}^2}{SS_{yy}SS_{xx}}+\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\
&amp;=1-2r^2+r^2\\
&amp;=1-r^2\\
\Rightarrow r^2&amp;=1-\frac{SS_{RES}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>因此，這裏就引出了非常重要的一個結論，<strong>Pearson 相關係數的平方 <span class="math inline">\(r^2\)</span> 的統計學含義是，因變量的平方和 <span class="math inline">\(SS_{yy}\)</span> 中，模型的預測變量能夠解釋的部分 <span class="math inline">\(1-SS_{RES}\)</span> 的百分比。</strong> 統計學結果的報告中，爲了和一般相關係數的意義區分，會用大寫的 <span class="math inline">\(R^2\)</span> 來表示這個模型解釋了因變量的百分比。(Section <a href="#Rsquare">28.2.3</a>)</p>
</div>
</div>
<div id="t-r2-F" class="section level2">
<h2><span class="header-section-number">27.6</span> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</h2>
<p><span class="math display" id="eq:t-r2">\[
\begin{equation}
t=r\sqrt{\frac{n-2}{1-r^2}}
\end{equation}
\tag{27.14}
\]</span></p>
<p><strong>證明</strong></p>
<p>由於前面推導的 <span class="math inline">\(r^2\)</span> 公式 <a href="#eq:rSSyySSres">(27.13)</a>，而且 <span class="math inline">\(r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{\frac{S_{xy}^2}{SS_{xx}SS_{yy}}}{\frac{SS_{RES}}{SS_{yy}}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}SS_{RES}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}(n-2)\hat\sigma^2}
\end{aligned}
\]</span></p>
<p>由於公式 <a href="#eq:varhatbeta">(27.5)</a>，所以 <span class="math inline">\(\hat\sigma^2=V(\hat\beta)SS_{xx}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{S_{xy}^2}{SS^2_{xx}(n-2)V(\hat\beta)} \\
                  &amp; = \frac{\hat\beta^2}{(n-2)V(\hat\beta)} \\
\Rightarrow t=r\sqrt{\frac{n-2}{1-r^2}}
\end{aligned}
\]</span></p>
<p>這個結論也被用於相關係數的假設檢驗。而且也正如 Section <a href="#randbeta">27.2.1</a> 證明過的那樣，在簡單線性迴歸裏因變量和預測變量的位置對調以後，對於回顧係數是否爲零的檢驗統計量不受影響。</p>
</div>
<div id="練習-2" class="section level2">
<h2><span class="header-section-number">27.7</span> 練習</h2>
<p>數據同前一章練習部分數據相同 <a href="#exeChol">26.8</a>：</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1"><span class="co"># 數據讀入</span></a>
<a class="sourceLine" id="cb122-2" title="2">Chol &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/chol.dta&quot;</span>)</a>
<a class="sourceLine" id="cb122-3" title="3">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol)</a>
<a class="sourceLine" id="cb122-4" title="4"><span class="kw">print</span>(<span class="kw">summary</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chol2 ~ chol1, data = Chol)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -56.87654 -22.06181   1.84937  16.63107  84.11839 
## 
## Coefficients:
##                Estimate  Std. Error t value   Pr(&gt;|t|)    
## (Intercept) 110.4246582  20.0113279 5.51811 2.8499e-07 ***
## chol1         0.5786806   0.0747598 7.74053 9.5114e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.16 on 97 degrees of freedom
## Multiple R-squared:  0.381834,   Adjusted R-squared:  0.375462 
## F-statistic: 59.9159 on 1 and 97 DF,  p-value: 9.51139e-12</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: chol2
##           Df  Sum Sq Mean Sq F value     Pr(&gt;F)    
## chol1      1 54511.7 54511.7 59.9159 9.5114e-12 ***
## Residuals 97 88250.9   909.8                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1"><span class="co"># 計算截距和迴歸係數的 P 值 HAND CALCULATIONS twosided p-value in R can be obtained by pt(t, df) function</span></a>
<a class="sourceLine" id="cb126-2" title="2"></a>
<a class="sourceLine" id="cb126-3" title="3"><span class="co">## p value for intercept:</span></a>
<a class="sourceLine" id="cb126-4" title="4"></a>
<a class="sourceLine" id="cb126-5" title="5"><span class="fl">110.42466</span><span class="op">/</span><span class="fl">20.01133</span> <span class="co">#=5.518107</span></a></code></pre></div>
<pre><code>## [1] 5.518</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">5.518107</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 2.85e-07</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="co">## p value for beta:</span></a>
<a class="sourceLine" id="cb130-2" title="2"></a>
<a class="sourceLine" id="cb130-3" title="3"><span class="fl">0.57868</span><span class="op">/</span><span class="fl">0.07476</span> <span class="co">#= 7.740503</span></a></code></pre></div>
<pre><code>## [1] 7.741</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">7.740503</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 9.513e-12</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" title="1"><span class="co"># add fitted regression lines 95% CIs and reference range</span></a>
<a class="sourceLine" id="cb134-2" title="2">temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a>
<a class="sourceLine" id="cb134-3" title="3"></a>
<a class="sourceLine" id="cb134-4" title="4">new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(Chol, temp_var)</a>
<a class="sourceLine" id="cb134-5" title="5"></a>
<a class="sourceLine" id="cb134-6" title="6"><span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb134-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">TRUE</span>, <span class="dt">size=</span><span class="fl">0.5</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb134-8" title="8"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb134-9" title="9"><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb134-10" title="10"><span class="st">   </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb134-11" title="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb134-12" title="12"><span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</a></code></pre></div>
<p><img src="bookdown_files/figure-html/LM15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>圖中可見，95% 置信帶變化顯著，距離均值越遠的地方，置信帶越寬。然而預測帶基本是平行的沒有變化。因爲預測帶的涵義是，95%的觀察數據都在這個區間範圍內。</p>
</div>
</div>
<div id="ANOVA" class="section level1">
<h1><span class="header-section-number">第 28 章</span> 方差分析 Introduction to Analysis of Variance</h1>
<div id="背景" class="section level2">
<h2><span class="header-section-number">28.1</span> 背景</h2>
<p>當我們用統計模型模擬真實數據的時候，我們常常會被問到這樣的問題：“兩個模型哪個能更好的擬合這個數據？”</p>
<p>本章我們先考慮簡單的情況，兩個模型互相比較時，其中一個稍微簡單些的模型使用的預測變量，同時也是另一個較複雜的模型的預測變量 (nested models)。所以，複雜模型的預測變量較多，而其中一個或者幾個預測變量又構成了新的較爲簡單的模型。這兩個模型之間的比較，就需要用到方差分析 Analysis of Variance (ANOVA)。</p>
<p>此處方差分析的原則是：如果複雜模型能夠更好的擬合真實實驗數據，那我們會認爲簡單模型無法解釋的大量殘差平方和，有效地被複雜模型解釋了。所以，這一原則下，可以推理，複雜模型計算獲得的殘差平方和，會顯著地小於簡單模型計算獲得的殘差平方和。ANOVA 就提供了這個殘差平方和變化的定量比較方法。</p>
</div>
<div id="簡單線性迴歸模型的方差分析" class="section level2">
<h2><span class="header-section-number">28.2</span> 簡單線性迴歸模型的方差分析</h2>
<p>其實從線性迴歸的第一章節開始，我們都在使用方差分析的思想。圖 <a href="#fig:age-wt">26.1</a> 數據的迴歸模型中，我們其實比較了以下兩個模型：</p>
<ol style="list-style-type: decimal">
<li>零假設模型：null model, 即認爲年齡和體重之間沒有任何關係 (水平直線)；</li>
<li>替代模型： alternative model, 認爲年齡和體重之間有一定的線性關係 (擬合後的直線)。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm-anova"></span>
<img src="bookdown_files/figure-html/age-wt-lm-anova-1.png" alt="NULL (red) and Alternative models (blue) for the data" width="80%" />
<p class="caption">
圖 28.1: NULL (red) and Alternative models (blue) for the data
</p>
</div>
<div id="兩個模型的參數估計" class="section level3">
<h3><span class="header-section-number">28.2.1</span> 兩個模型的參數估計</h3>
<p>無論是零假設模型，還是替代假設模型，都需要通過最小化殘差來獲得其參數估計：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n \hat\varepsilon^2= \sum_{i=1}^n(y_i-\hat y_i)^2
\]</span></p>
<p>替代假設模型，在線性迴歸第一部分 (Section <a href="#meanfunction">26.3.1</a>) 已經提到過，均值方程是 <span class="math inline">\(E(Y|X=x) = \alpha+\beta x\)</span>，且這個方程的參數 <span class="math inline">\(\alpha, \beta\)</span> 以及殘差方差 <span class="math inline">\(\sigma^2\)</span> 的估計值計算公式也已經推導完成 <a href="#eq:hatalpha">(26.5)</a> <a href="#eq:hatbeta">(26.6)</a> <a href="#eq:sigma2right">(26.9)</a>。</p>
<p>零假設模型，它的均值方程是 <span class="math inline">\(E(Y|X=x)=\alpha\)</span>。所以需要將它的殘差最小化：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n(y_i-\hat\alpha)^2
\]</span></p>
<p>由於 <a href="#eq:hatalpha">(26.5)</a> ：<span class="math inline">\(\hat\alpha=\bar{y}-\hat\beta\)</span>，所以 <span class="math inline">\(\hat\alpha = \bar{y}\)</span>。</p>
<p>所以對於零假設模型來說：</p>
<p><span class="math display">\[
SS_{RES} = \sum_{i=1}^n(y_i-\bar{y})^2 =SS_{yy}
\]</span></p>
<p>因此，沒有預測變量的零假設模型，它的殘差平方和，就等於因變量的平方和。</p>
</div>
<div id="分割零假設模型的殘差平方和" class="section level3">
<h3><span class="header-section-number">28.2.2</span> 分割零假設模型的殘差平方和</h3>
<p>ANOVA，方差分析的原則，其實就是將較簡單模型 (零假設模型) 的殘差平方和 <span class="math inline">\((SS_{RES_{NULL}})\)</span>，分割成下面兩個部分：</p>
<ol style="list-style-type: decimal">
<li>替代假設的複雜模型能夠說明的模型平方和 <span class="math inline">\((SS_{REG})\)</span>；</li>
<li>替代假設的複雜模型的殘差平方和 <span class="math inline">\((SS_{RES_{ALT}})\)</span>。</li>
</ol>
<p>用數學表達式表示爲：</p>
<p><span class="math display" id="eq:SSres-partition">\[
\begin{equation}
\sum_{i=1}^n(y_i-\bar{y})^2 = \sum_{i=1}^n(\hat{y}-\bar{y})^2 + \sum_{i=1}^n(y_i-\hat{y}_i)^2 \\
SS_{RES_{NULL}}(SS_{yy}) = SS_{REG} + SS_{RES_{ALT}}
\end{equation}
\tag{28.1}
\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^n(y_i-\bar{y})^2 &amp;= \sum_{i=1}^n[(\hat{y}-\bar{y})+(y_i-\hat{y})]^2\\
                            &amp;= \sum_{i=1}^n(\hat{y}-\bar{y})^2+\sum_{i=1}^n(y_i-\hat{y})^2+2\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y}) \\
                            &amp;= SS_{REG} + SS_{RES_{ALT}} + 2\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y})
\end{aligned}
\]</span></p>
<p>接下來就是要證明 <span class="math inline">\(\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y})=0\)</span></p>
<p>因爲公式 <a href="#eq:lmcenter">(27.1)</a> <span class="math inline">\(\hat{y}_i=\bar{y}+\hat{\beta}(x_i-\bar{x})\)</span> 所以公式變形如下：</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^n(\hat{y}_i-\bar{y})(y_i-\hat{y}) &amp;=  \sum_{i=1}^n(\bar{y}+\hat\beta(x_i-\bar{x})-\bar{y})(y_i-\bar{y}-\hat\beta(x_i-\bar{x})) \\
&amp;= \sum_{i=1}^n\hat\beta(x_i-\bar{x})[y_i-\bar{y}-\hat\beta(x_i-\bar{x})] \\
&amp;= \hat\beta\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) - \hat\beta^2\sum_{i=1}^n(x_i-\bar{x}) \\
&amp;= \frac{S_{xy}}{S_{xx}}S_{xy} - (\frac{S_{xy}}{S_{xx}})^2SS_{xx}\\
&amp;= 0 \\
\Rightarrow  SS_{RES_{NULL}}(SS_{yy}) &amp;= SS_{REG} + SS_{RES_{ALT}}
\end{aligned}
\]</span></p>
</div>
<div id="Rsquare" class="section level3">
<h3><span class="header-section-number">28.2.3</span> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</h3>
<p>在公式 <a href="#eq:SSres-partition">(28.1)</a> 中，因變量的平方和被分割成了兩個部分：<span class="math inline">\(SS_{REG}\)</span> 迴歸模型能說明的部分，和 <span class="math inline">\(SS_{RES_{ALT}}\)</span> 迴歸模型的殘差平方和。所以，我們定義迴歸模型能說明的部分，佔因變量平方和的百分比 <span class="math inline">\(\frac{SS_{REG}}{SS_{yy}}\)</span>，爲決定係數 <span class="math inline">\(R^2\)</span>。</p>
<p>這個決定係數之前 (Section <a href="#rsquare">27.5</a>) 也出現過：</p>
<p><span class="math display" id="eq:R-square">\[
\begin{equation}
R^2 = \frac{SS_{REG}}{SS_{yy}} = \frac{\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\end{equation}
\tag{28.2}
\]</span></p>
<p>再一次回到數據 (<a href="#fig:age-wt">26.1</a>) 的線性迴歸來看：</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb135-2" title="2">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb135-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.924182 -0.784889  0.007099  0.797468  4.067806 
## 
## Coefficients:
##              Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept) 6.8375842  0.2100701 32.5491 &lt; 2.22e-16 ***
## age         0.1653314  0.0111115 14.8793 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.540782,   Adjusted R-squared:  0.53834 
## F-statistic: 221.392 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>R 輸出的結果中最下面的部分 <code>Multiple R-squared:  0.5408</code>。我們就可以用“人話”來解釋其意義：假定年齡和體重成直線關係，那麼年齡解釋了這組數據中兒童體重變化 (平方和) 的 54%。</p>
</div>
<div id="方差分析表格-the-anova-table" class="section level3">
<h3><span class="header-section-number">28.2.4</span> 方差分析表格 the ANOVA table</h3>
<p>一般情況下一個簡單線性迴歸，通過 ANOVA 對因變量平方和的分割，會被彙總成下面這樣的表格：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 28.1: Analysis of Variance table for a simple liear regression model
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Regression (model)
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{reg}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{reg} = \frac{SS_{reg}}{1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{res}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-2\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{res} = \frac{SS_{res}}{(n-2)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>表格中最右邊一列是平均平方和 (mean sum of squares)。它的定義是將平方和除以各自的自由度。其中殘差的平均平方和 <span class="math inline">\(MS_{RES}=\frac{SS_{RES}}{(n-2)}\)</span> 是替代模型下殘差方差的無偏估計。總體平均平方和 (total mean sum of squares)，則是零假設模型時的殘差方差估計。在 R 裏面也已經演示過多次 <code>anova(model)</code> 是調取方差分析表格的代碼：</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" title="1">Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb137-2" title="2"><span class="kw">print</span>(<span class="kw">anova</span>(Model), <span class="dt">digit=</span><span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)    
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16 ***
## Residuals 188 304.90655   1.62184                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>注意到 R 省略掉第三行總體平方和的部分，不過其實也不太需要。檢驗統計量 F 的計算也很簡單，就是359.06320/1.62184=221.39。</p>
</div>
<div id="用-anova-進行假設檢驗" class="section level3">
<h3><span class="header-section-number">28.2.5</span> 用 ANOVA 進行假設檢驗</h3>
<p>在 ANOVA 中使用的檢驗手段是 <span class="math inline">\(F\)</span> 檢驗。這裏用 <span class="math inline">\(F\)</span> 檢驗來比較<strong>模型解釋的因變量平方和部分</strong> <span class="math inline">\((SS_{REG})\)</span> 和<strong>這個模型不能解釋的殘差平方和部分</strong> <span class="math inline">\(SS_{RES}\)</span> 經過自由度校正以後比值的大小。</p>
<p>此時我們需要知道零假設和替代假設 <span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span> 時，<span class="math inline">\(SS_{REG}, SS_{RES}\)</span> 的分佈。</p>
<ol style="list-style-type: decimal">
<li>零假設和替代假設時，<span class="math inline">\(SS_{RES}\)</span> 均服從自由度爲 <span class="math inline">\(n-2\)</span> 的卡方分佈：</li>
</ol>
<p><span class="math display" id="eq:distributionSSres">\[
\begin{equation}
\text{Because } SS_{RES} = \sum_{i=1}^n \varepsilon \sim N(0, \sigma^2)\\
\frac{SS_{RES}}{\sigma^2} \sim \chi^2_{n-2}
\end{equation}
\tag{28.3}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>零假設時， <span class="math inline">\(SS_{REG}\)</span> 服從自由度爲 <span class="math inline">\(1\)</span> 的卡方分佈，且與 <span class="math inline">\(SS_{RES}\)</span> 相互獨立：</li>
</ol>
<p><span class="math display" id="eq:distributionSSreg">\[
\begin{equation}
\frac{SS_{REG}}{\sigma^2} \sim \chi^2_1
\end{equation}
\tag{28.4}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>替代假設時，<span class="math inline">\(SS_{REG}\)</span> 服從一個非中心化的卡方檢驗，且與 <span class="math inline">\(SS_{RES}\)</span> 相互獨立：</li>
</ol>
<p><span class="math display" id="eq:distributionSSregh1">\[
\begin{equation}
SS_{REG} = \beta^2 SS_{xx} + U \text{ where }\frac{U}{\sigma^2} \sim \chi_1^2
\end{equation}
\tag{28.5}
\]</span></p>
</div>
<div id="lm-Ftest" class="section level3">
<h3><span class="header-section-number">28.2.6</span> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</h3>
<p>如果兩個隨機變量各自服從相應自由度的卡方分佈，他們的每個元素的比值服從 <span class="math inline">\(F\)</span> 分佈：</p>
<p><span class="math display">\[
A\sim \chi_a^2 \text{ and } B\sim \chi_b^2\\
\Rightarrow \frac{A/a}{B/b} \sim F_{a,b}
\]</span></p>
<p>因此，目前爲止的推導過程我們也可以看到，在零假設條件下，<span class="math inline">\(MS_{REG}\)</span> 和 <span class="math inline">\(MS_{RES}\)</span> 的比值會服從 <span class="math inline">\(F\)</span> 分佈，自由度爲 <span class="math inline">\((1, n-2)\)</span>：</p>
<p><span class="math display" id="eq:Fdistri">\[
\begin{equation}
F=\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \frac{MS_{REG}}{MS_{RES}} \sim F_{1,n-2}
\end{equation}
\tag{28.6}
\]</span></p>
<p>在替代假設條件下 <span class="math inline">\((\text{H}_1: \beta\neq0)\)</span>，<span class="math inline">\(SS_{REG}\)</span> 的期望值是 <span class="math inline">\(\sigma^2+\beta^2SS_{xx}\)</span>，所以替代假設條件下的 <span class="math inline">\(F\)</span> 檢驗量總是會大於零假設時的 <span class="math inline">\(F\)</span>。因此你可以看到，這是一個雙側檢驗 (<span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span>)，但是由於替代假設的 <span class="math inline">\(F\)</span> 總是較大，所以只需要 <span class="math inline">\(F\)</span> 的右半部分的概率密度積分 (單側 <span class="math inline">\(p\)</span> 值)。</p>
</div>
<div id="F-t-same" class="section level3">
<h3><span class="header-section-number">28.2.7</span> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</h3>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
&amp;F=\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \frac{SS_{REG}}{(SS_{yy}-SS_{REG})/(n-2)} \\
&amp;\text{Since } r^2 = \frac{SS_{REG}}{SS_{yy}} \\
&amp;F=(n-2)\frac{SS_{yy}r^2}{SS_{yy}-SS_{yy}r^2}=(n-2)(\frac{r^2}{1-r^2})=t^2
\end{aligned}
\]</span></p>
<p>最後一步用到 (Section <a href="#t-r2-F">27.6</a>) 證明過的，迴歸係數檢驗統計量 <span class="math inline">\(t\)</span>，和 Pearson 相關係數 <span class="math inline">\(r\)</span> 之間的關係。</p>
</div>
</div>
<div id="分類變量用作預測變量時的-anova" class="section level2">
<h2><span class="header-section-number">28.3</span> 分類變量用作預測變量時的 ANOVA</h2>
<p>方差分析的應用是如此的廣泛，你可以在多重迴歸中使用，也可以在模型中有分類變量時使用，甚至是同時有連續性變量和分類變量的迴歸模型中得到應用。</p>
<p>之前也遇到過二分類變量的簡單線性迴歸模型，當時我們的做法是使用一個啞變量來表示一個二分類變量。同樣的方法也可以用到多組分類變量上來，然後繼續使用線性迴歸。</p>
<div id="一個二分類預測變量" class="section level3">
<h3><span class="header-section-number">28.3.1</span> 一個二分類預測變量</h3>
<p>在前面的例子 (Section <a href="#binarylms">26.7</a>) 中也已經展示過，可以通過線性迴歸來分析一個二分類變量 (實驗組對照組)，和一個連續型變量 (能直立行走時的兒童年齡)兩個變量之間的關係。而且其結果同兩樣本 <span class="math inline">\(t\)</span> 檢驗的結果完全一致。</p>
<p>繼續回到之前用過的這個兒童行走數據 (表 <a href="#tab:walk">26.1</a>)：</p>
<pre><code>## 
## Call:
## lm(formula = Age ~ Group, data = Walk)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1250 -0.7375 -0.3750  0.3875  2.8750 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  10.12500    0.51223 19.7663 1.007e-08 ***
## Groupcontrol  2.22500    0.75977  2.9285    0.0168 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.255 on 9 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.48795,    Adjusted R-squared:  0.43105 
## F-statistic: 8.5763 on 1 and 9 DF,  p-value: 0.016797</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Age
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Group      1 13.502 13.5017  8.5763 0.0168 *
## Residuals  9 14.169  1.5743                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>之前分析這個數據的時候也說明過了，這裏的迴歸係數 <span class="math inline">\(2.225\)</span> 的含義是兩組之間均值的差異。而且注意看，這個迴歸係數是否爲零的檢驗統計量<span class="math inline">\((t-test)\)</span>獲得的 <span class="math inline">\(p\)</span> 值和 ANOVA 的檢驗結果 <span class="math inline">\((F-test)\)</span> 也是一致的。正驗證了我們前面證明的結果。(Section <a href="#F-t-same">28.2.7</a>)</p>
</div>
<div id="一個模型兩種表述" class="section level3">
<h3><span class="header-section-number">28.3.2</span> 一個模型，兩種表述</h3>
<p>上面這個例子中，一個二分類的預測變量和一個因變量之間的關係，實際上可以用兩種數學模型來表達：</p>
<ol style="list-style-type: decimal">
<li>令 <span class="math inline">\(y_i, x_i\)</span> 分別是第 <span class="math inline">\(i\)</span> 名觀察對象的因變量 (“直立行走的年齡”)，和預測變量 (“實驗組或者對照組”) <span class="math inline">\((i=1,\cdots,n)\)</span>。那麼<strong>迴歸模型</strong>可以寫作：</li>
</ol>
<p><span class="math display" id="eq:regremodel">\[
\begin{equation}
y_i = \alpha+\beta x_i + \varepsilon_i, \text{ where } \varepsilon_i \sim NID(0, \sigma^2)
\end{equation}
\tag{28.7}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(x_i=0\)</span> 時，表示第 <span class="math inline">\(i\)</span> 名觀察對象在實驗組；</li>
<li><span class="math inline">\(x_i=1\)</span> 時，表示第 <span class="math inline">\(i\)</span> 名觀察對象在對照組。</li>
</ul>
<p>在這樣的迴歸模型標記下，零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \beta=0 \text{ v.s. H}_1: \beta\neq0\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>另一種模型的表達方式，被叫做 ANOVA 表達方式。是如此描述上面的關係的：令 <span class="math inline">\(y_{ki}\)</span> 表示第 <span class="math inline">\(i\)</span> 名觀察對象，他在第 <span class="math inline">\(k\)</span> 組 <span class="math inline">\((i=1,\cdots, n_k; k=1,2)\)</span>，此時的模型被寫作：</li>
</ol>
<p><span class="math display" id="eq:anovamodel">\[
\begin{equation}
y_{ki} = \mu_k + \varepsilon_{ki}, \text{ where } \varepsilon_{ki} \sim NID(0, \sigma^2)
\end{equation}
\tag{28.8}
\]</span></p>
<p>此時，<span class="math inline">\(\mu_k\)</span> 表示第 <span class="math inline">\(k\)</span> 組因變量的均值。零假設和替代假設分別是 <span class="math inline">\(\text{H}_0: \mu_k=\mu \text{ v.s. H}_1: \mu_k\neq\mu\)</span>。這裏的 <span class="math inline">\(\mu\)</span> 表示，每個組的平均值等於一個共同的均值 <span class="math inline">\(\mu\)</span>。</p>
</div>
<div id="分組變量的平方和" class="section level3">
<h3><span class="header-section-number">28.3.3</span> 分組變量的平方和</h3>
<p>對於預測變量只有一個分組變量的模型，擬合後的數值就是兩組的因變量均值 <span class="math inline">\((\bar{y}_k)\)</span>。在零假設條件下，兩組均值相等，均等於總體均值 <span class="math inline">\(\bar{y}\)</span>。這就導致了，殘差平方和，模型平方和在分組變量的 ANOVA 分析時要使用與連續型變量不同的術語。</p>
<ul>
<li>殘差平方和表示爲：</li>
</ul>
<p><span class="math display" id="eq:withingroupSS">\[
\begin{equation}
SS_{RES} = \sum_{k=1}^k\sum_{i=1}^{n_k} (y_{ki}-\bar{y}_k)^2
\end{equation}
\tag{28.9}
\]</span></p>
<p>其實這就是<strong>組內平方和</strong> (within group sum of squares)。</p>
<ul>
<li>模型平方和表示爲：</li>
</ul>
<p><span class="math display" id="eq:betweengroupSS">\[
\begin{equation}
SS_{REG} = \sum_{k=1}^k\sum_{i=1}^{n_k}(\bar{y}_k-\bar{y})^2=\sum_{k=1}^kn_k(\bar{y}_k-\bar{y})^2
\end{equation}
\tag{28.10}
\]</span></p>
<p>其實這就是<strong>組間平方和</strong> (between group sum of squares)</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" title="1">Mdl0 &lt;-<span class="st"> </span><span class="kw">aov</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data =</span> Walk) <span class="co"># fit a one-way ANOVA</span></a>
<a class="sourceLine" id="cb141-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Mdl0), <span class="dt">digits =</span> <span class="dv">6</span>)</a></code></pre></div>
<pre><code>##             Df  Sum Sq  Mean Sq F value   Pr(&gt;F)  
## Group        1 13.5017 13.50170 8.57629 0.016797 *
## Residuals    9 14.1687  1.57431                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 1 observation deleted due to missingness</code></pre>
<p>其實這跟之前的 <code>anova(Model)</code> 給出的結果完全一致。</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" title="1"><span class="kw">bartlett.test</span>(Age <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data=</span>Walk)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Age by Group
## Bartlett&#39;s K-squared = 0.63, df = 1, p-value = 0.4</code></pre>
<p>FYI. 上面的代碼 <code>bartlett.test()</code> 利用的是另外一個叫做 Bartlett 檢驗法的方差比較公式。(在 STATA 的 <code>oneway</code> 命令中也會默認給出 Bartlett 檢驗的方差是否一致的檢驗結果)</p>
</div>
<div id="簡單模型的分組變量大於兩組的情況" class="section level3">
<h3><span class="header-section-number">28.3.4</span> 簡單模型的分組變量大於兩組的情況</h3>
<p>公式 <a href="#eq:anovamodel">(28.8)</a>, <a href="#eq:withingroupSS">(28.9)</a>, 和 <a href="#eq:betweengroupSS">(28.10)</a> 在兩組以上分組變量作預測變量時也是適用的。但是當組數爲 <span class="math inline">\(K\)</span> 時，組內平方和 (殘差平方和 <span class="math inline">\(SS_{RES}\)</span>) 的自由度需要修改成 <span class="math inline">\(n-K\)</span> (這是因爲模型中使用了 <span class="math inline">\(K\)</span> 個參數)。此時方差分析 ANOVA 的彙總表格就變爲了下面這樣：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 28.2: One-way ANOVA table
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br> variation
</th>
<th style="text-align:center;">
Sum of <br> Squares
</th>
<th style="text-align:center;">
Degrees of <br> Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br> Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Between groups
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{between}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(K-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{between}}{(K-1)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Within groups
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{within}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-K\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{within}}{(n-K)}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>此時，檢驗統計量 <span class="math inline">\(F\)</span> 的計算公式爲：</p>
<p><span class="math display" id="eq:F1way-anova">\[
\begin{equation}
F=\frac{SS_{between}/(K-1)}{SS_{within}/(n-K)} \sim F_{(K-1),(n-K)}
\end{equation}
\tag{28.11}
\]</span></p>
<p>在解釋兩組以上分組變量的分析結果時，要注意的是如果 <span class="math inline">\(p\)</span> 值很小，檢驗結果告訴我們的是，各組中因變量的均值<strong>不全相等</strong>，而<strong>不是全部都不相等</strong>。其實就是，即使做了這個檢驗，我們也不知道到底那兩組之間是有差異的。如果此時我們發現結果提示均值不全相等，通常我們還會再作進一步的分析，使用類似成對比較法等等 (以後再繼續詳述)。不過提前要記住，如果使用成對比較法時 (pair-wise comparisons)，<strong>多重比較的問題 (multiple comparisons)</strong>會凸顯出來，主要的結果是增加統計檢驗的假陽性 (false-positive) 概率，此時再繼續使用 <span class="math inline">\(p&lt;0.05\)</span> 作爲統計學意義的標準則是不妥當的。</p>
</div>
</div>
</div>
<div id="多元模型分析-multivariable-models" class="section level1">
<h1><span class="header-section-number">第 29 章</span> 多元模型分析 Multivariable Models</h1>
<p>簡單線性迴歸描述的是一個連續型的因變量 <span class="math inline">\((y)\)</span>，和一個單一的預測變量 <span class="math inline">\((x)\)</span> 之間的關係。我們考慮把這個模型擴展成包含多個預測變量，單一因變量的模型。例如，我們可以考慮建立一個模型使用生活習慣 (包括“年齡，性別，運動，飲食習慣等”) 來預測收縮期血壓。此時多重迴歸的思想就可以幫我們理解一些我們<strong>更加關心的因子</strong>，與因變量之間的關係，同時控制或者叫調整了其他的<strong>混雜因子</strong> (control or adjust confounders)。有時候這樣的模型也可以直接應用到生活中去，比如上面的例子，我們可以通過瞭解一個人的生活習慣，用建立好的模型來估計這個人的收縮期血壓。</p>
<p>建立模型之前，必須明確研究的目的是什麼。例如我們關心一個<strong>新發現的因子</strong>可能與高血壓有關係，那麼模型中我們放進去調整的其他因子 (如年齡，性別，運動) 等和因變量 (血壓) 之間的關係就變得不那麼重要。</p>
<p>多重線性迴歸，或者叫多元模型分析 (multiple linear regression or multivariable linear regression) 是研究一個連續型因變量和多個預測變量之間關係的重要模型。本章還會着重討論<strong>混雜 (confounding)</strong>的概念。</p>
<div id="兩個預測變量的線性迴歸模型" class="section level2">
<h2><span class="header-section-number">29.1</span> 兩個預測變量的線性迴歸模型</h2>
<div id="數學標記法和解釋" class="section level3">
<h3><span class="header-section-number">29.1.1</span> 數學標記法和解釋</h3>
<p>這裏假設我們研究一個因變量 <span class="math inline">\(Y\)</span>，和兩個預測變量 <span class="math inline">\((X_1,X_2)\)</span> 的模型。那麼此時兩個預測變量的線性迴歸模型可以記爲：</p>
<p><span class="math display" id="eq:2varmultilm">\[
\begin{equation}
y_i = \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \varepsilon_i, \text{ where } \varepsilon_i \sim \text {NID}(0, \sigma^2)
\end{equation}
\tag{29.1}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(y_i\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的因變量數據 (例如體重)；
<ul>
<li><span class="math inline">\(x_{1i}\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的第一個預測變量數據 (例如年齡)， <span class="math inline">\(X_1\)</span>；</li>
<li><span class="math inline">\(x_{2i}\)</span> 是第 <span class="math inline">\(i\)</span> 名研究對象的第二個預測變量數據 (例如身高)， <span class="math inline">\(X_1\)</span>；</li>
<li><span class="math inline">\(\alpha\)</span> 的涵義是，當兩個預測變量均爲 <span class="math inline">\(0\)</span> 時，因變量的期望值；</li>
<li><span class="math inline">\(\beta_1\)</span> 的涵義是，當 <span class="math inline">\(X_2\)</span> 不變時，<span class="math inline">\(X_1\)</span> 每升高一個單位，因變量的期望值；</li>
<li><span class="math inline">\(\beta_2\)</span> 的涵義是，當 <span class="math inline">\(X_1\)</span> 不變時，<span class="math inline">\(X_2\)</span> 每升高一個單位，因變量的期望值。</li>
</ul></li>
</ul>
<p><span class="math inline">\(\beta_1, \beta_2\)</span> 叫做偏迴歸係數 (partial regression coefficient)。它們測量的是兩個預測變量中，當一個被控制 (保持不變) 時，另一個對因變量的影響。</p>
<p>這個模型也可以用矩陣的形式來表示：</p>
<p><span class="math display" id="eq:matrixlm">\[
\begin{equation}
\textbf{Y} = \textbf{X}\beta+\varepsilon, \text{ where } \varepsilon \sim N(0, \textbf{I}\sigma^2) \\
\left(
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array}
\right) = \left(
\begin{array}{c}
1&amp;  x_{11} &amp; x_{21}  \\
1&amp;  x_{12} &amp; x_{22} \\
\vdots &amp;   \vdots&amp; \vdots \\
1&amp;   x_{1n}&amp; x_{2n} \\
\end{array}
\right)\left(
\begin{array}{c}
\alpha \\
\beta_1\\
\beta_2
\end{array}
\right)+\left(
\begin{array}{c}
\varepsilon_1\\
\varepsilon_2\\
\vdots\\
\varepsilon_n\\
\end{array}
\right)
\end{equation}
\tag{29.2}
\]</span></p>
<p>此時上面的表達式中，<span class="math inline">\(\textbf{X}\)</span> 是一個矩陣，<span class="math inline">\(\textbf{Y, \beta, \varepsilon}\)</span> 均為向量。殘差被認為服從多變量正態分佈 <strong>(Multivariate normal distribution)</strong> ，這個多變量正態分佈的協方差矩陣為 <span class="math inline">\(\sigma^2\)</span> 和單位矩陣 <span class="math inline">\(\textbf{I}\)</span> 的乘積來描述。這等價於假設殘差是獨立同分佈且方差 <span class="math inline">\(\sigma^2\)</span> 不變。</p>
</div>
<div id="最小平方和估計-least-squares-estimation" class="section level3">
<h3><span class="header-section-number">29.1.2</span> 最小平方和估計 Least Squares Estimation</h3>
<p>跟簡單線性回歸相似地，我們需要通過對殘差平方和最小化，來獲得此時多重線性回歸的各項參數估計：</p>
<p><span class="math display" id="eq:se">\[
\begin{equation}
SS_{RES} = \sum_{i=1}^n \hat\varepsilon_{i}^2 = \sum_{i=1}^n(y_i-\hat{y})^2=\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i})^2
\end{equation}
\tag{29.3}
\]</span></p>
<p>求能讓這個殘差平方和取最小值的參數估計 <span class="math inline">\(\hat\alpha,\hat\beta_1,\hat\beta_2\)</span> 我們會在下一章用矩陣標記法來解釋。此處要強調的是，這些估計量都是無偏估計量，且可以被證明的是殘差方差可以用下面的式子來定義：</p>
<p><span class="math display" id="eq:multivar">\[
\begin{equation}
\hat\sigma^2=\sum_{i=1}^n\frac{\hat\varepsilon_i^2}{(n-3)}=\frac{\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i})^2}{(n-3)}
\end{equation}
\tag{29.4}
\]</span></p>
</div>
</div>
<div id="線性回歸模型中使用分組變量" class="section level2">
<h2><span class="header-section-number">29.2</span> 線性回歸模型中使用分組變量</h2>
<p>之前我們已展示過，分組變量可以使用啞變量來表示。分組變量多於兩組時，可用多個啞變量來同時表示。現在假設變量 <span class="math inline">\(X\)</span> 有三個分組分別用 <span class="math inline">\(1,2,3\)</span> 來表示。那麼用啞變量來描述含有這個分組變量的數學方法可以標記為：</p>
<p><span class="math display" id="eq:dummy3">\[
\begin{equation}
y_i  = \alpha+\beta_1u_{1i}+\beta_2u_{2i}+\varepsilon_i, \text{ where } \varepsilon_i \sim \text{NID} (0,\sigma^2)
\end{equation}
\tag{29.5}
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
\begin{aligned}
u_{1i}=\left\{
 \begin{array}{ll}
 1 \text{ if } x_i=2 \\
 0 \text{ if } x_i\neq2 \\
 \end{array}
\right. ;
u_{2i}=\left\{
 \begin{array}{ll}
 1 \text{ if } x_i=3 \\
 0 \text{ if } x_i\neq3 \\
 \end{array}
\right.
\end{aligned}
\]</span></p>
<p>其實如果你願意，你也可以把公式 <a href="#eq:dummy3">(29.5)</a> 寫成下面這樣：</p>
<p><span class="math display">\[
\begin{aligned}
\begin{array}{ll}
y_i = \alpha + \varepsilon_i   &amp; \text{if }  x_i=1 \\
y_i = \alpha +\beta_1+ \varepsilon_i   &amp; \text{if }  x_i=2 \\
y_i = \alpha +\beta_2+ \varepsilon_i   &amp; \text{if }  x_i=3 \\
\end{array}
\end{aligned}
\]</span>
所以，</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是 <span class="math inline">\(X=1\)</span> 時因變量的期待值；</li>
<li><span class="math inline">\(\alpha+\beta_1\)</span> 是 <span class="math inline">\(X=2\)</span> 時因變量的期待值，所以 <span class="math inline">\(\beta_1\)</span> 是分組變量 <span class="math inline">\(X\)</span> 前兩組之間因變量的期待值的差；</li>
<li><span class="math inline">\(\alpha+\beta_2\)</span> 是 <span class="math inline">\(X=3\)</span> 時因變量的期待值，所以 <span class="math inline">\(\beta_2\)</span> 是分組變量 <span class="math inline">\(X\)</span> 前兩組之間因變量的期待值的差。</li>
</ul>
<p>此時的 <span class="math inline">\(X=1\)</span> 這個組通常被當作是分組變量中的基準組，也就是參照組 (reference group)。實際情況下你可能可以改變這個參照組為其他組的任意一個。</p>
</div>
<div id="協方差分析模型-the-analysis-of-covariance-ancova-model" class="section level2">
<h2><span class="header-section-number">29.3</span> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</h2>
<p>協方差分析模型用來分析一個連續型的因變量 <span class="math inline">\(Y\)</span> ，與一個連續型的預測變量 <span class="math inline">\((X_1)\)</span>和一個二分類的預測變量 <span class="math inline">\((X_2= 1,2)\)</span>，模型被標記為：</p>
<p><span class="math display" id="eq:ancova">\[
\begin{equation}
y_i=\alpha+\beta_1x_{1i}+\beta_2u_{2i}+\varepsilon_i, \text{ where } \varepsilon_i \sim \text{NID}(0,\sigma^2)
\end{equation}
\tag{29.6}
\]</span>
其中，</p>
<ul>
<li><span class="math inline">\(y_{i}\)</span> 為第 <span class="math inline">\(i\)</span> 名研究對象的因變量數據 (連續型)；</li>
<li><span class="math inline">\(x_{1i}\)</span> 為第 <span class="math inline">\(i\)</span> 名研究對象的第一個預測變量 (也是連續型)；</li>
<li><span class="math inline">\(u_i =\left\{ \begin{array}{ll} 1 \text{ if } x_{2i}=2 \\ 0 \text{ if } x_{2i}=1 \\ \end{array}\right.\)</span></li>
</ul>
<p>此模型中用到的參數有：</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距，意為當 <span class="math inline">\(X_1=0\)</span> 且 <span class="math inline">\(X_2=1 \; (u=0)\)</span> 時的因變量期待值；</li>
<li><span class="math inline">\(\beta_1\)</span> 是當 <span class="math inline">\(X_2\)</span> 保持不變時，<span class="math inline">\(X_1\)</span> 每升高一個單位時，因變量 <span class="math inline">\(Y\)</span> 的期待值；</li>
<li><span class="math inline">\(\beta_2\)</span> 是當 <span class="math inline">\(X_1\)</span> 保持不變時，分組變量 <span class="math inline">\(X_2\)</span> 的兩組之間因變量 <span class="math inline">\(Y\)</span> 的期待值差異大小。</li>
</ul>
<p>所以理解了上面的解釋之後，就可以將表達式 <a href="#eq:ancova">(29.6)</a> 描述為：</p>
<p><span class="math display">\[
\begin{array}{ll}
y_i=\alpha+\beta_1x_{1i}+\varepsilon_i &amp; \text{ if } x_{2i}=1 \\
y_i=\alpha+\beta_2+\beta_1x_{1i}+\varepsilon_i &amp; \text{ if } x_{2i} = 2
\end{array}
\]</span></p>
<p>所以，在一個二維圖形中繪製這兩條回歸直線，你會發現他們之間是<strong>平行的</strong>。因為他們之間相差的只有截距，決定直線斜率的回歸係數，都是 <span class="math inline">\(\beta_1\)</span>。再用之前用過的數據，兒童的體重和年齡，如果此時考慮了性別因素的話，多重線性回歸的輸出結果和圖形分別應該是：</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb145-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb145-3" title="3"></a>
<a class="sourceLine" id="cb145-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb145-5" title="5"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + sex, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -4.19236 -0.76268 -0.00696  0.75675  3.79163 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  7.152414   0.234254 30.5327 &lt; 2.2e-16 ***
## age          0.163998   0.010919 15.0189 &lt; 2.2e-16 ***
## sex2        -0.518854   0.183053 -2.8344  0.005095 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.25 on 187 degrees of freedom
## Multiple R-squared:  0.5597, Adjusted R-squared:  0.55499 
## F-statistic: 118.85 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
## age         1 359.06  359.06 229.6755 &lt; 2.2e-16 ***
## sex         1  12.56   12.56   8.0341  0.005095 ** 
## Residuals 187 292.35    1.56                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:age-wt-mlm"></span>
<img src="bookdown_files/figure-html/age-wt-mlm-1.png" alt="Data and fitted values from a regression model relating age and gender to data from a cross-sectional survey. For male children data points shown as circles and fitted values linked by a solid line. For female children data points shown as triangles and fitted values linked by a dashed line." width="80%" />
<p class="caption">
圖 29.1: Data and fitted values from a regression model relating age and gender to data from a cross-sectional survey. For male children data points shown as circles and fitted values linked by a solid line. For female children data points shown as triangles and fitted values linked by a dashed line.
</p>
</div>
</div>
<div id="偏回歸係數的變化" class="section level2">
<h2><span class="header-section-number">29.4</span> 偏回歸係數的變化</h2>
<p>在增加不同的預測變量進入線性回歸模型中時，原先在方程中的預測變量的偏回歸係數發生了怎樣的變化？</p>
<p>我們先從最簡單的開始入手。先只考慮一個簡單先行回歸模型的情況。當我們新加入一個預測變量，模型發生了什麼變化？</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Model 1: } y_i = \alpha^*+\beta_1^*x_{1i}+\varepsilon^*_i \\
&amp; \text{Model 2: } y_i = \alpha + \beta_1x_{1i} + \beta_2 x_{2i}+\varepsilon_i
\end{aligned}
\]</span>
<span class="math inline">\(\beta_1, \beta_1^*\)</span> 表示的其實是完全不同的含義。<span class="math inline">\(\beta_1^*\)</span> 被稱為粗回歸係數 (crude coefficient)，或者叫做調整前回歸係數，<span class="math inline">\(\beta_1\)</span> 被稱為調整後回歸係數 (adjusted coefficient)。二者之間的差異，其實是可以通過對這兩個變量進行簡單線性回歸來度量的：</p>
<p><span class="math display">\[
\text{Model 3: } x_{2i} = \gamma+\delta_1x_{1i}+\omega_i
\]</span>
將 Model 2 中的 <span class="math inline">\(x_{2i}\)</span> 用 Model 3 來替換掉：
<span class="math display">\[
\begin{aligned}
\text{Model 2: }y_i  &amp;= \alpha + \beta_1 x_{1i} + \beta_2(\gamma + \delta_1x_{1i}+\omega_i) +\varepsilon_i \\
       &amp;= \alpha + \beta_2\gamma+(\beta_1+\beta_2\delta_1)x_{1i}+\beta_2\omega_i + \varepsilon_i
\end{aligned}
\]</span>
比較 Model 1 和變形過後的 Model 2 中 <span class="math inline">\(x_{1i}\)</span> 的係數就不難發現：</p>
<p><span class="math display">\[
\beta_1^* = \beta_1 + \beta_2\delta_1
\]</span>
由此可見，調整前後 <span class="math inline">\(x_{1i}\)</span> 的回歸係數的變化 <span class="math inline">\(\beta_1^*, \beta_1\)</span> 之間的差異，取決於兩個部分的大小：</p>
<ul>
<li><span class="math inline">\(\beta_2\)</span> 的大小和它的符號；</li>
<li><span class="math inline">\(X_1, X_2\)</span> 這兩個預測變量之間有多大關聯，用 Model 3 的 <span class="math inline">\(\delta_1\)</span> 來度量。</li>
</ul>
<p>所以，當調整後的 <span class="math inline">\(\beta_1 &gt; 0\)</span> 時，要分三種情況來討論</p>
<div id="情況1-beta_1-beta_1" class="section level3">
<h3><span class="header-section-number">29.4.1</span> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></h3>
<p>此時，<span class="math inline">\(\beta_2\delta_1&lt;0\)</span> 所以，二者之間一正一負。如下圖所示：</p>
<p><img src="img/lr4confounding1.png" width="50%" style="display: block; margin: auto;" />
按圖所示，當 <span class="math inline">\(X_2\)</span> 保持不變，<span class="math inline">\(X_1\)</span> 與因變量 <span class="math inline">\(Y\)</span> 正相關 (<span class="math inline">\(\beta_1&gt;0\)</span>)。但是，兩個預測變量之間 <span class="math inline">\(X_1, X_2\)</span> 也呈正相關關係 <span class="math inline">\(\delta_1 &gt;0\)</span>。而同時，<span class="math inline">\(X_2\)</span> 的升高會導致因變量 <span class="math inline">\(Y\)</span> 的下降 ($_2 &lt;0 $)。這種情況就意味著，如果，我們不調整 <span class="math inline">\(X_2\)</span> (使之保持不變)，那麼 <span class="math inline">\(X_1\)</span> 每升高一個單位，<span class="math inline">\(Y\)</span> 的變化會<strong>低於</strong>調整 <span class="math inline">\(X_2\)</span> 時，<span class="math inline">\(X_1\)</span> 的變化所引起的 <span class="math inline">\(Y\)</span> 的變化。如果這時候 <span class="math inline">\(\beta_2,\delta_1\)</span> 較大，那麼對於 <span class="math inline">\(X_1\)</span> 來說，調整 <span class="math inline">\(X_2\)</span> 前後，回歸係數的變化較大，如果大到一定程度，甚至調整前後的回歸係數的方向 (正負) 都會發生變化。</p>
</div>
<div id="情況2beta_1beta_1" class="section level3">
<h3><span class="header-section-number">29.4.2</span> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></h3>
<p>本情況下，<span class="math inline">\(\beta_2\delta_1&gt;0\)</span> 是正的。所以二者要麼同時爲正，要麼同時爲負。如下圖所示：</p>
<p><img src="img/lr4confounding2.png" width="50%" style="display: block; margin: auto;" /></p>
<p>當 <span class="math inline">\(X_2\)</span> 保持不變時， <span class="math inline">\(X_1\)</span> 同 <span class="math inline">\(Y\)</span> 呈正關係。但是，<span class="math inline">\(X_1\)</span> 的升高也會引起 <span class="math inline">\(X_2\)</span> 的升高，同時通過 <span class="math inline">\(X_2\)</span> 和 <span class="math inline">\(Y\)</span> 之間的正關係升高 <span class="math inline">\(Y\)</span>。所以假設在模型裏我們不對 <span class="math inline">\(X_2\)</span> 進行控制 (controld or adjust)，那麼 <span class="math inline">\(X_1\)</span> 和 <span class="math inline">\(Y\)</span> 之間的關係就被誇大了。</p>
<p>所以，當 <span class="math inline">\(X_1\rightarrow X_2\rightarrow Y\)</span> 的這條通路大大超過 <span class="math inline">\(X_1\rightarrow Y\)</span> 的話，調整後的迴歸係數 <span class="math inline">\(\beta_1\)</span> 就會變得很小。</p>
</div>
<div id="情況3-beta_1-beta_1" class="section level3">
<h3><span class="header-section-number">29.4.3</span> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></h3>
<p>這種情況只有當 <span class="math inline">\(\beta_2\delta_1=0\)</span> 時才會出現。所以，二者至少有一個是 <span class="math inline">\(0\)</span>。 如下圖所示：</p>
<p><img src="img/lr4confounding3.png" width="50%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(X_1\)</span> 與 <span class="math inline">\(Y\)</span> 呈正關係，<span class="math inline">\(X_1\)</span> 與 <span class="math inline">\(X_2\)</span> 呈正關係。但是 <span class="math inline">\(X_2\)</span> 與 <span class="math inline">\(Y\)</span> 無關聯。所以此時無論模型是否調整了 <span class="math inline">\(X_2\)</span> 都不會影響 <span class="math inline">\(X_1\)</span> 和 <span class="math inline">\(Y\)</span> 之間關係的計算。</p>
</div>
</div>
<div id="confounding" class="section level2">
<h2><span class="header-section-number">29.5</span> 混雜 confounding</h2>
<p>流行病學家最喜歡的詞彙恐怕要屬混雜 (confounding) 了 (interaction, 交互作用也要算一個 (Section <a href="#interaction">32</a>，(笑))。他們常用混雜來解釋爲什麼調整其他因子前後迴歸係數發生了變化。當有其他因子 (測量了或者甚至是未知的) 對我們關心的預測變量和因變量之間的關係產生了影響 (加強或是減弱) 時，就叫做發生了混雜。</p>
<p>對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件：</p>
<ul>
<li>與關心的預測變量相關 (i.e. <span class="math inline">\(\delta_1 \neq 0\)</span>)；</li>
<li>與因變量相關 (當關心的預測變量不變時，<span class="math inline">\(\beta_2\neq0\)</span> )；</li>
<li>不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable.</li>
</ul>
<p>有時，判斷一個因子是否對我們關心的預測變量和因變量之間的關係構成了混雜並不容易，也不直觀。所以，有太多太多的情況下，我們無法準確地 100% 地確定我們關心的關係是否被別的因子混雜。所以，莫要用 “混雜” 一詞簡單糊弄人。</p>
<div id="作為媒介-mediation-effect" class="section level3">
<h3><span class="header-section-number">29.5.1</span> 作為媒介 mediation effect</h3>
<p>多數情況下，我們也無法從數據判斷一個變量是否在我們關心的預測變量和因變量之間關係的通路上。此時要做的是離開你的電腦，去學習他們之間的生物學知識，看是否真的有關係。</p>
<p>但是有些例子就很簡單啦。比如說，服用降血壓藥物可以預防發生中風。那麼此時血壓的降低，就處在了這二者因果關係的通路上。因爲藥物通過降低了血壓，從而預防了中風的發生。這一關係中，我們不能說血壓是混雜因子，它是一個媒介 (mediator)。但是多數的橫斷面研究 (cross-sectional study) 中我們無法是很難下結論的。</p>
</div>
<div id="兩個預測變量之間的關係" class="section level3">
<h3><span class="header-section-number">29.5.2</span> 兩個預測變量之間的關係</h3>
<p>如果另一個變量不是媒介，且它和我們關心的預測變量，因變量之間如果都有相關關係，那它的確有可能成為混雜因子。但是僅僅通過統計學模型來考察混雜是絕對不夠的。例如樣本量較小的數據中，我們可能無法檢驗出一個變量對模型的混雜影響是不是有統計學意義的，但是這不能提供證據否認它不是混雜因子。同樣的，更多的混雜因子是我們沒有測量沒有觀察到收集到的未知因素。<strong>所以，任何數據都無法提供完全去除混雜因子影響的模型。</strong></p>
</div>
<div id="rct臨床實驗是個特例" class="section level3">
<h3><span class="header-section-number">29.5.3</span> RCT臨床實驗是個特例</h3>
<p>因為隨機對照臨床實驗，在設計階段就已經把治療組對照組之間的差異最小化了，理想的隨機對照實驗，其治療組和對照組之間理論上除了治療藥物的差別之外完全相同。當然這是理想狀況，且所有的臨床實驗都必須向這個方向努力設計和實施。偶然出現的治療組和對照組在某些特徵上的不平衡，不能被認為是混雜因子。只能說這樣的臨床實驗是不理想的，提供的證據水平也就較弱。</p>
</div>
</div>
</div>
<div id="多元模型分析矩陣標記與其意義" class="section level1">
<h1><span class="header-section-number">第 30 章</span> 多元模型分析：矩陣標記與其意義</h1>
<p>在線性回歸目前為止介紹的內容中，我們最多只談到了預測變量為兩個的情況。本章，我們要把這些概念推廣到三個或者三個以上預測變量的情況。同時，多重線性回歸時採用的假設檢驗也會被談及。其實最常見的就是 <span class="math inline">\(F\)</span> 檢驗。而且我們也見識過了，當預測變量只有一個的時候，<span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗是等價的。</p>
<p>重要的概念我們都已經介紹完畢。前一章的多重回歸模型中也強調了，我們之所以希望把多個預測變量放進模型，最大的目的就是想了解這些預測變量之間的相互關係，當他們得到調整 (adjustment) 之後，彼此之間的關係是怎樣的。這樣的關係我們稱之為條件關係 (conditional relationships)。當我們使用條件關係的稱呼時，需要同時指明我們說的是哪個變量，在那個變量不變的條件下，與因變量的關係是如何如何。</p>
<p>本章節最後的部分將會著重關注共線性 (collinearity) 的問題。</p>
<div id="線性回歸模型的矩陣非矩陣標記法" class="section level2">
<h2><span class="header-section-number">30.1</span> 線性回歸模型的矩陣/非矩陣標記法</h2>
<div id="模型標記" class="section level3">
<h3><span class="header-section-number">30.1.1</span> 模型標記：</h3>
<p>假如，因變量用 <span class="math inline">\(Y\)</span> 表示，預測變量有 <span class="math inline">\(p\)</span> 個之多 <span class="math inline">\((X_1,\cdots, X_p)\)</span>。該模型的非矩陣標記法如下：
<span class="math display" id="eq:nonmatrixlm">\[
\begin{equation}
y_i  = \alpha + \beta_1 x_{1i}+ \beta_2 x_{2i} + \cdots +  \beta_p x_{pi} + \varepsilon_i \text{ with } \varepsilon_i \sim \text{NID}(0, \sigma^2)
\end{equation}
\tag{30.1}
\]</span>
其中，</p>
<ul>
<li><span class="math inline">\(y_i =\)</span> 第 <span class="math inline">\(i\)</span> 名觀察對象的因變量數據；</li>
<li><span class="math inline">\(x_{pi} =\)</span> 第 <span class="math inline">\(i\)</span> 名觀察對象的第 <span class="math inline">\(p\)</span> 個預測變量的觀察數據。</li>
</ul>
<p>上面的非矩陣標記法，等同於如下的矩陣標記法：
<span class="math display" id="eq:matrixlm2">\[
\begin{equation}
\textbf{Y} = \textbf{X}\beta+\varepsilon, \text{ where } \varepsilon \sim N(0, \textbf{I}\sigma^2) \\
\left(
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array}
\right) = \left(
\begin{array}{c}
1&amp;  x_{11} &amp; \cdots &amp; x_{p1}  \\
1&amp;  x_{12} &amp; \cdots &amp; x_{p2} \\
\vdots &amp;   \vdots&amp; \vdots &amp; \vdots \\
1&amp;   x_{1n}&amp; \cdots &amp;x_{pn} \\
\end{array}
\right)\left(
\begin{array}{c}
\alpha \\
\beta_1\\
\beta_2 \\
\vdots \\
\beta_p
\end{array}
\right)+\left(
\begin{array}{c}
\varepsilon_1\\
\varepsilon_2\\
\vdots\\
\varepsilon_n\\
\end{array}
\right)
\end{equation}
\tag{30.2}
\]</span>
此公式 <a href="#eq:matrixlm2">(30.2)</a> 中</p>
<ul>
<li><span class="math inline">\(\textbf{X}\)</span> 是一個 <span class="math inline">\(n\times(p+1)\)</span> 的矩陣；</li>
<li><span class="math inline">\(\textbf{Y}\)</span> 和 <span class="math inline">\(\varepsilon\)</span> 分別是長度為 <span class="math inline">\(n\)</span> 的列向量；</li>
<li><span class="math inline">\(\beta\)</span> 是長度為 <span class="math inline">\(p+1\)</span> 的列向量，且第一個元素是 <span class="math inline">\(\alpha\)</span>，偶爾被人誤寫成 <span class="math inline">\(\beta_0\)</span>。</li>
</ul>
<p>殘差被認為服從<strong>多元正態分佈 (multivariate normal distribution)</strong>，這個多元正態分佈的方差協方差矩陣等於 <span class="math inline">\(\sigma^2\)</span> 與單位矩陣相乘獲得的矩陣。這其實等價於認為殘差服從獨立正態且方差為 <span class="math inline">\(\sigma^2\)</span> 的分佈，</p>
</div>
</div>
<div id="解讀參數" class="section level2">
<h2><span class="header-section-number">30.2</span> 解讀參數</h2>
<p>模型中的參數的涵義為：</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是截距，所有的預測變量都是零的時候，因變量 <span class="math inline">\(Y\)</span> 的期待值大小；</li>
<li><span class="math inline">\(\beta_j\)</span> 是預測變量 <span class="math inline">\(X_j\)</span> 升高一個單位，且其他變量保持不變的同時，因變量 <span class="math inline">\(Y\)</span> 的期待值的變化；</li>
<li><span class="math inline">\(\beta_j\)</span> 都是偏回歸係數，每個偏回歸係數，測量的都是該預測變量調整了其他預測變量之後對於因變量期待值的影響。</li>
</ul>
<div id="最小二乘估計" class="section level3">
<h3><span class="header-section-number">30.2.1</span> 最小二乘估計</h3>
<p>還是同之前一樣，我們對殘差的平方和最小化，來獲取我們關心的預測變量的回歸變量。</p>
<p><span class="math display" id="eq:lsemulti">\[
\begin{aligned}
SS_{RES} &amp; = \sum_{i=1}^n \hat\varepsilon_i^2 =  \sum_{i=1}^n(y_i-\hat{y})^2 \\
&amp; = \sum_{i=1}^n (y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i}-\cdots-\hat\beta_px_{pi})^2
\end{aligned}
\tag{30.3}
\]</span></p>
<p>下面用矩陣標記法計算 <span class="math inline">\(\hat\beta\)</span>：</p>
<p><span class="math display" id="eq:lm5-4">\[
\begin{aligned}
\text{Because } \mathbf{Y} &amp; = \mathbf{X\hat\beta + \varepsilon} \\
\Rightarrow \mathbf{\varepsilon} &amp; = \mathbf{Y - X\hat\beta}\\
\Rightarrow \mathbf{SS_{RES}} &amp; = \varepsilon_1\times \varepsilon_1 + \varepsilon_2\times \varepsilon_2 + \cdots + \varepsilon_n\times \varepsilon_n \\
                     &amp; = (\varepsilon_1, \varepsilon_2, \cdots, \varepsilon_n)\left(
                     \begin{array}{c}
                     \varepsilon_1\\
                     \varepsilon_2\\
                     \vdots\\
                     \varepsilon_n
                     \end{array}
                     \right) \\
                     &amp; = \mathbf{\varepsilon^\prime} \mathbf{\varepsilon} \\
                     &amp; = \mathbf{(Y-X\hat\beta)^\prime(Y-X\hat\beta)} \\
                     &amp; = \mathbf{Y^\prime Y - X^\prime\hat\beta^\prime Y - Y^\prime X\hat\beta + X^\prime\hat\beta^\prime X \hat\beta} \\
\text{Because} &amp;\text{ transpose of a scalar is a scalar:} \\
 \mathbf{Y^\prime X\hat\beta} &amp; = \mathbf{(Y^\prime X\hat\beta)^\prime = X^\prime\hat\beta^\prime Y} \\
\Rightarrow  \mathbf{SS_{RES}} &amp; = \mathbf{Y^\prime Y - 2X^\prime\hat\beta^\prime Y + X^\prime\hat\beta^\prime X \hat\beta}\\
\Rightarrow \mathbf{\frac{\partial SS_{RES}}{\partial \hat\beta}} &amp; = \mathbf{-2X^\prime Y + 2 X^\prime X \hat\beta} = 0 \\
\Rightarrow \mathbf{\hat\beta} &amp; = \mathbf{(X^\prime X)^{-1}X^\prime Y}
\end{aligned}
\tag{30.4}
\]</span></p>
<p>公式 <a href="#eq:lm5-4">(30.4)</a> 是參數矩陣 <span class="math inline">\(\mathbf{\beta}\)</span> 的無偏估計，且服從方差協方差矩陣爲 <span class="math inline">\(\mathbf{(X^\prime X)^{-1}\sigma^2}\)</span> 的多元正態分佈：</p>
<p><span class="math display" id="eq:lm5-5">\[
\begin{equation}
\mathbf{\hat\beta} \sim  N(\mathbf{\beta, (X^\prime X)^{-1}\sigma^2})
\end{equation}
\tag{30.5}
\]</span></p>
<p>另外可以被證明的是，多元線性迴歸模型的殘差方差的估計量計算公式爲：</p>
<p><span class="math display" id="eq:lm5-6">\[
\begin{aligned}
\hat\sigma^2 &amp; = \sum^n_{i=1}\frac{\hat\varepsilon^2_i}{[n-(p+1)]} \\
             &amp; = \sum^n_{i=1}\frac{\sum_{i=1}^n (y_i-\hat\alpha-\hat\beta_1x_{1i}-\hat\beta_2x_{2i}-\cdots-\hat\beta_px_{pi})^2}{[n-(p+1)]} \\
\text{Where } &amp; p \text{ is the number of predictors}
\end{aligned}
\tag{30.6}
\]</span></p>
</div>
<div id="因變量的期待值-mathbfhat-y" class="section level3">
<h3><span class="header-section-number">30.2.2</span> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></h3>
<p>因變量的期待值矩陣 <span class="math inline">\(\mathbf{\hat Y}\)</span> 根據公式 <a href="#eq:lm5-4">(30.4)</a> 推導：</p>
<p><span class="math display" id="eq:lm5-7">\[
\begin{aligned}
\mathbf{\hat Y} &amp; = \mathbf{X\hat\beta} \\
                &amp; = \mathbf{X(X^\prime X)^{-1}X^\prime Y}= \mathbf{PY} \\
\text{Where } \mathbf{P} &amp;= \mathbf{X(X^\prime X)^{-1}X^\prime}
\end{aligned}
\tag{30.7}
\]</span></p>
<p>這裏的 <span class="math inline">\(n\times n\)</span> 的正方形矩陣 <span class="math inline">\(\mathbf{P}\)</span> 在多元線性迴歸中是一個極爲重要的矩陣。</p>
<ul>
<li>它常被叫做“帽子/映射 (hat/projection)”矩陣，因爲它把觀察值 <span class="math inline">\(\mathbf{Y}\)</span> 和觀察值的擬合值一一映射；</li>
<li>帽子矩陣的第 <span class="math inline">\(i\)</span> 個對角元素，是第 <span class="math inline">\(i\)</span> 名觀察值的影響值 (leverage)，會用在下章節的模型診斷中；</li>
<li>擬合值矩陣的方差協方差矩陣被定義爲：</li>
</ul>
<p><span class="math display" id="eq:lm5-8">\[
\begin{equation}
\text{Var}(\mathbf{\hat Y}) = \mathbf{P}\sigma^2
\end{equation}
\tag{30.8}
\]</span></p>
</div>
<div id="殘差" class="section level3">
<h3><span class="header-section-number">30.2.3</span> 殘差</h3>
<p>殘差的觀察值 <span class="math inline">\(\mathbf{\hat\varepsilon}\)</span> 被定義爲觀察值和擬合值的差。根據前節 <a href="#eq:lm5-8">(30.8)</a> 推導：</p>
<p><span class="math display" id="eq:lm5-9">\[
\begin{equation}
\mathbf{\hat\varepsilon} = \mathbf{Y - \hat Y} = \mathbf{Y - PY} = \mathbf{(I - P)Y}
\end{equation}
\tag{30.9}
\]</span></p>
<p>這個觀察殘差的方差被定義爲：</p>
<p><span class="math display" id="eq:lm5-10">\[
\begin{equation}
\text{Var}(\mathbf{\hat\varepsilon}) = \mathbf{(I - P)}\sigma^2
\end{equation}
\tag{30.10}
\]</span></p>
<ul>
<li>一般地，<span class="math inline">\(\mathbf{P}\)</span> 不是一個對角矩陣，意思是觀察殘差之間無法保證是獨立的；</li>
<li><span class="math inline">\(\mathbf{P}\)</span> 的對角元素也不全都相等，意思是觀察殘差的方差無法保證是恆定不變的。</li>
</ul>
</div>
</div>
<div id="方差分析一般化和-f-檢驗" class="section level2">
<h2><span class="header-section-number">30.3</span> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</h2>
<div id="多元線性迴歸時的決定係數和殘差方差" class="section level3">
<h3><span class="header-section-number">30.3.1</span> 多元線性迴歸時的決定係數和殘差方差</h3>
<p>和簡單線性迴歸一樣，因變量的校正平方和可以被分割成兩部分：迴歸模型能夠解釋的平方和；模型無法解釋的殘差平方和。類比方差分析章節 (Section <a href="#ANOVA">28</a>) 的公式 <a href="#eq:SSres-partition">(28.1)</a>：</p>
<p><span class="math display" id="eq:lm5-11">\[
\begin{aligned}
\sum_{i=1}^n(y_i-\bar{y})^2 &amp; = \sum_{i=1}^n(\hat{y}_i - \bar{y})^2 + \sum_{i=1}^n(y_i - \hat{y}_i)^2 \\
SS_{yy}  &amp; = SS_{REG} + SS_{RES}
\end{aligned}
\tag{30.11}
\]</span></p>
<p>和簡單線性迴歸也一樣，多元線性迴歸時的模型決定係數 (coefficient of determination) 的定義爲：</p>
<p><span class="math display" id="eq:lm5-12">\[
\begin{aligned}
R^2 &amp; = \frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1- \frac{SS_{RES}}{SS_{yy}} \\
    &amp; = 1 - \frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i - \bar{y})^2}
\end{aligned}
\tag{30.12}
\]</span></p>
<p>這裏的 <span class="math inline">\(R^2\)</span> 也一樣可以被解釋爲模型能夠解釋的因變量變動部分的百分比 (proportion of the variability in the dependent variable explained by the model)。值得注意的是，當模型中預測變量不減少，每加入一個新的預測變量，決定係數也會增加，相反殘差平方和卻絕不會增加。</p>
</div>
<div id="方差分析表格" class="section level3">
<h3><span class="header-section-number">30.3.2</span> 方差分析表格</h3>
<p>下表和簡單線性迴歸的方差分析表格很類似，也可以用來作假設檢驗 (迴歸方程的顯著性檢驗 Global <span class="math inline">\(F-\text{test}\)</span>，和偏 <span class="math inline">\(F\)</span> 檢驗 Partial <span class="math inline">\(F-\text{test}\)</span>)。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.1: Analysis of Variance table for a liear regression model with <span class="math inline">\(p\)</span> predictor variables
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Regression (model)
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{REG} = \frac{SS_{REG}}{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{RES}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-(p+1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{RES} = \frac{SS_{RES}}{[n-(p+1)]}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="globalsig" class="section level3">
<h3><span class="header-section-number">30.3.3</span> 迴歸方程的顯著性檢驗</h3>
<p>整個方程的顯著性檢驗，檢驗的是所有的迴歸係數都等於零的零假設，其對應的替代假設則是：“迴歸係數<strong>不全爲零</strong>”。就是至少有一個不等於零。</p>
<p>在零假設條件下，檢驗統計量的計算公式爲：</p>
<p><span class="math display" id="eq:lm5-13">\[
\begin{equation}
F = \frac{MS_{REG}}{MS_{RES}} \sim F_{p, [n-(p+1)]}
\end{equation}
\tag{30.13}
\]</span></p>
<p>在零假設條件下，<span class="math inline">\(F\)</span> 的期望值接近 <span class="math inline">\(1\)</span>，而替代假設條件下的 <span class="math inline">\(F\)</span> 總是會大於此，所以和 <span class="math inline">\(F\)</span> 分佈比較特徵值時只需要比較單側的 (右側的) 值，即可獲得雙側 <span class="math inline">\(p\)</span> 值。</p>
<p>在 R 裏面，迴歸方程的結果的最底下會出現統計量 <span class="math inline">\(F\)</span> 的大小，但是 <span class="math inline">\(MS_{REG}, MS_{RES}\)</span> 要用 <code>anova()</code> 代碼獲得：</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb149-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb149-3" title="3"></a>
<a class="sourceLine" id="cb149-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb149-5" title="5"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.20525 -0.64402 -0.00303  0.55967  2.86277 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.351244   1.259968 -6.6281 3.531e-10 ***
## age         -0.011260   0.016751 -0.6722    0.5023    
## len          0.237129   0.019516 12.1502 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9546 on 187 degrees of freedom
## Multiple R-squared:  0.74337,    Adjusted R-squared:  0.74063 
## F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## age         1 359.06  359.06  394.06 &lt; 2.2e-16 ***
## len         1 134.52  134.52  147.63 &lt; 2.2e-16 ***
## Residuals 187 170.39    0.91                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>可以看到 <code>summary()</code> 輸出結果的最後一行是關於迴歸方程整體的 <span class="math inline">\(F\)</span> 檢驗結果 <code>F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code>，從 <code>anova()</code> 結果中可以獲得 <span class="math inline">\(MS_{REG} = \frac{359.0632 + 134.5153}{2} = 246.7892\)</span>。<span class="math inline">\(F_{2,187} = \frac{246.7892}{0.9111833} = 270.84\)</span>。這個檢驗結果證明了，兩個預測變量 “體重” 和 “身長” 至少有一個的迴歸係數不等於零。</p>
</div>
<div id="partialF" class="section level3">
<h3><span class="header-section-number">30.3.4</span> <span class="math inline">\(\text{partial }F\)</span> 檢驗</h3>
<p>如果我們建立兩個模型，一個稍微複雜一些 <span class="math inline">\((B)\)</span>，比起略簡單的模型 <span class="math inline">\((A)\)</span>，增加了 <span class="math inline">\(k\)</span> 個預測變量。兩個模型放在一起的方差分析表格可以歸納成：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.2: Analysis of Variance table comparing the fit of a model <span class="math inline">\((B)\)</span> with <span class="math inline">\(p\)</span> predictor variables with that of one (model <span class="math inline">\(A\)</span>) with <span class="math inline">\(p-k\)</span> predictor variables
</caption>
<thead>
<tr>
<th style="text-align:center;">
Source of <br>Variation
</th>
<th style="text-align:center;">
Sum of <br>Squares
</th>
<th style="text-align:center;">
Degrees of <br>Freedom
</th>
<th style="text-align:center;">
Mean Sum of <br>Squares
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Explained by <br> model <span class="math inline">\(A\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG_A}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(p-k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{REG_A} = \frac{SS_{REG_A}}{p-k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Extra Explained <br> by model <span class="math inline">\(B\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{REG_B}-SS_{REG_A}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{REG_B}-SS_{REG_A}}{k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Residual from <br> model <span class="math inline">\(B\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{RES_B}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-(p+1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(MS_{RES_B} = \frac{SS_{RES_B}}{[n-(p+1)]}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(SS_{yy}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{SS_{yy}}{(n-1)}\)</span>
</td>
</tr>
</tbody>
</table>
<p>那麼偏 <span class="math inline">\(F\)</span> 檢驗的零假設就是：<span class="math inline">\(B\)</span> 模型中包含，<span class="math inline">\(A\)</span> 模型中不包含的 <span class="math inline">\(k\)</span> 個預測變量的迴歸係數都等於零。</p>
<p><span class="math display" id="eq:lm5-14">\[
\begin{equation}
F=\frac{(SS_{REG-B}-SS_{REG-A})/k}{MS_{RES-B}} \sim F_{k, [n-(p+1)]}
\end{equation}
\tag{30.14}
\]</span></p>
<p>在 R 裏建立兩個模型：</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb153-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.155217 -0.629239  0.014555  0.544783  2.928738 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -7.6694406  0.7463556 -10.276 &lt; 2.2e-16 ***
## len          0.2257467  0.0096893  23.299 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9532 on 188 degrees of freedom
## Multiple R-squared:  0.74275,    Adjusted R-squared:  0.74139 
## F-statistic: 542.82 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## len         1 493.17  493.17  542.82 &lt; 2.2e-16 ***
## Residuals 188 170.80    0.91                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data =</span> growgam1)</a>
<a class="sourceLine" id="cb157-2" title="2"><span class="kw">print</span>(<span class="kw">summary</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len + age + sex, data = growgam1)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3.110422 -0.648401  0.026103  0.560621  2.768583 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -7.8906758  1.3003091 -6.0683 7.091e-09 ***
## len          0.2317997  0.0198470 11.6793 &lt; 2.2e-16 ***
## age         -0.0077959  0.0168974 -0.4614    0.6451    
## sex2        -0.1964758  0.1421171 -1.3825    0.1685    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9522 on 186 degrees of freedom
## Multiple R-squared:  0.74599,    Adjusted R-squared:  0.74189 
## F-statistic: 182.08 on 3 and 186 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df Sum Sq Mean Sq  F value Pr(&gt;F)    
## len         1 493.17  493.17 543.8753 &lt;2e-16 ***
## age         1   0.41    0.41   0.4540 0.5013    
## sex         1   1.73    1.73   1.9113 0.1685    
## Residuals 186 168.66    0.91                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>根據公式 <a href="#eq:lm5-14">(30.14)</a>，<span class="math inline">\(F=\frac{0.4116944+1.7330862}{2\times0.9067645} = 1.18\)</span>。<span class="math inline">\(p\)</span> 值可以在 R 裏面這樣計算：</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" title="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(<span class="dt">df1 =</span> <span class="dv">2</span>,<span class="dt">df2 =</span> <span class="dv">186</span>,<span class="dt">q =</span> (<span class="fl">0.4116944+1.7330862</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="fl">0.9067645</span>))</a></code></pre></div>
<pre><code>## [1] 0.3088</code></pre>
<p>更方便的是直接用 <code>anova()</code> 進行偏 <span class="math inline">\(F\)</span> 檢驗：</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(Model1, Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wt ~ len
## Model 2: wt ~ len + age + sex
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    188 170.80                           
## 2    186 168.66  2    2.1448 1.1827 0.3088</code></pre>
</div>
</div>
<div id="添加新變量對迴歸模型的影響" class="section level2">
<h2><span class="header-section-number">30.4</span> 添加新變量對迴歸模型的影響</h2>
<p>當你決定給建立的模型 <span class="math inline">\(\mathbf{A}\)</span> 增加新的預測變量時，輸出的結果<strong>改變</strong>的有：</p>
<ol style="list-style-type: decimal">
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數的方差</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的預測變量的<strong>偏迴歸係數的檢驗結果</strong>會改變；</li>
<li>模型 <span class="math inline">\(\mathbf{A}\)</span> 原先的 <strong>擬合值 (predicted values/fitted values)</strong>會改變；</li>
<li>決定係數 <span class="math inline">\(R^2\)</span> 會改變。</li>
</ol>
<div id="偏迴歸係數方差的改變" class="section level3">
<h3><span class="header-section-number">30.4.1</span> 偏迴歸係數方差的改變</h3>
<p>偏迴歸係數矩陣 <span class="math inline">\(\mathbf{\hat\beta}\)</span> 的方差 <span class="math inline">\(\mathbf{(X^\prime X)^{-1}\sigma^2}\)</span> <a href="#eq:lm5-5">(30.5)</a>，取決於</p>
<ol style="list-style-type: decimal">
<li>殘差方差 (residual variance) <span class="math inline">\(\sigma^2\)</span>；</li>
<li>樣本量大小 (sample size) <span class="math inline">\(n\)</span>；</li>
<li>預測變量之間的協方差 (covariance between the predictor variable in question and the others)。</li>
</ol>
<p>在簡單線性迴歸中，預測變量的變化性 (variability，用方差或標準差衡量) 越大，迴歸係數的估計就越精確。類似地，多元線性迴歸中，預測變量之間的協方差之所以重要，因爲它決定了<strong>其他預測變量保持不變時</strong>，該預測變量的變化性。如果某兩個預測變量之間高度相關 (high covariance)，那麼當一個預測變量保持不變時，另一個的變化性就很小。</p>
<p>所以當給一個模型加入新的預測變量時，可能觀察的現象是原先模型中已有的預測變量的偏迴歸係數的方差<strong>可能升高，也可能降低</strong>。</p>
<ul>
<li>如果新加入的變量能解釋很大比例的殘差方差，那麼其他原有變量的偏迴歸係數會降低 (變精確)；</li>
<li>如果新加入的變量和原模型中的某個變量高度相關，那麼加入新變量後，原模型中與之高度相關的預測變量的方差會升高 (不精確)，這個現象會在共線性 (collinearity) 中繼續討論。</li>
</ul>
</div>
<div id="偏迴歸係數檢驗結果的改變" class="section level3">
<h3><span class="header-section-number">30.4.2</span> 偏迴歸係數檢驗結果的改變</h3>
<p>加入新預測變量時，原有的偏迴歸係數的檢驗結果發生的改變可以歸類成兩種情況：</p>
<ol style="list-style-type: decimal">
<li>估計的偏迴歸係數本身發生了改變；</li>
<li>偏迴歸係數的方差改變，導致了檢驗結果發生變化。</li>
</ol>
</div>
<div id="擬合值的改變" class="section level3">
<h3><span class="header-section-number">30.4.3</span> 擬合值的改變</h3>
<p>很明顯，當模型中加入新的變量，觀察對象的擬合值會發生改變，但是通常這樣的影響要遠遠小於對偏迴歸係數估計 (和其方差) 的影響。</p>
</div>
<div id="決定係數的改變" class="section level3">
<h3><span class="header-section-number">30.4.4</span> 決定係數的改變</h3>
<p>模型中增加新的預測變量，那麼模型的決定係數不會減少，只會增加。</p>
</div>
<div id="共線性-collinearity" class="section level3">
<h3><span class="header-section-number">30.4.5</span> 共線性 collinearity</h3>
<p>當預測變量 <span class="math inline">\(X_1\)</span> 和另一個預測變量 <span class="math inline">\(X_2\)</span> 之間呈高度線性關係時被定義爲共線性現象。如果這兩個變量的關係是<strong>完全線性 (exact linear)</strong>，那麼多元迴歸其實是無法進行的，因爲這兩個變量中的一個隨着另一個改變，無法像我們設想的那樣把其中一個變量保持不變，從而估計另一個變量的迴歸係數。用矩陣表示多元預測變量時 <span class="math inline">\(\mathbf{X}\)</span> 是<strong><a href="https://www.youtube.com/watch?v=UqyN7-tRS00">奇異矩陣 singular matrix</a></strong>，<span class="math inline">\(\mathbf{(X^\prime X)^{-1}}\)</span> 是不存在的。</p>
<p>完全線性的最佳例子是我們在對分類變量使用啞變量的情況下。每個啞變量之間都是完全線性的關係，因而我們只能用 <span class="math inline">\(0,1\)</span> 來編碼啞變量，當某個啞變量存在時，其餘的啞變量取 <span class="math inline">\(0\)</span> 從模型中消失。否則模型將無法擬合。</p>
<p>如果某兩個變量之間高度相關，那麼他們的預測變量矩陣接近 <strong>奇異矩陣</strong>，把這兩個變量同時作爲預測變量放入模型中會引起共線性現象，表現出來的形式有：</p>
<ol style="list-style-type: decimal">
<li>偏迴歸係數的方差變得很大；</li>
<li>偏迴歸係數本身的絕對值變得異常大；</li>
<li>某些已知的重要預測變量的偏迴歸係數變得過小且不再有意義；</li>
<li>雖然會有 1-3 描述的異常現象出現，但是擬合值的變化卻可能微不足道。</li>
</ol>
<p>所以擬合多元線性迴歸模型時，<strong>極爲重要的一點是要避免共線性</strong>。如果有些變量高度相關，必須考慮改變他們放入模型的形式：</p>
<ol style="list-style-type: decimal">
<li>收縮期血壓，舒張期血壓兩個變量是高度相關的，不能一起放入模型中。如果需要同時考慮兩個變量，可以用其中一個，另一個預測變量用二者之差；</li>
<li>身高，體重常常是高度相關的，儘量不要一起放入模型中，可以使用他們的結合形式體質指數 (BMI, <span class="math inline">\(\text{kg/m}^2\)</span>)；</li>
<li>當使用二次方程進行模型擬合的時候，用 <span class="math inline">\((x_i - \bar{x})^2\)</span> 取代 <span class="math inline">\(x_i^2\)</span>。</li>
</ol>
</div>
</div>
<div id="實戰演習" class="section level2">
<h2><span class="header-section-number">30.5</span> 實戰演習</h2>
<div id="血清維生素-c-濃度的預測變量" class="section level3">
<h3><span class="header-section-number">30.5.1</span> 血清維生素 C 濃度的預測變量</h3>
<p>數據來自與某個橫斷面研究，其目的是找出與血清維生素 C 濃度相關的預測變量。</p>
<p>數據中個變量含義如下表所示。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.3: Data set of serum vitamin C level explained
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable name
</th>
<th style="text-align:left;">
content
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<code>serial</code>
</td>
<td style="text-align:left;">
Patient identifier
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>age</code>
</td>
<td style="text-align:left;">
Age of subjects in years
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>height</code>
</td>
<td style="text-align:left;">
Height in metres
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>cigs</code>
</td>
<td style="text-align:left;">
Smoking status (0=non-smoker; 1=smoker)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>weight</code>
</td>
<td style="text-align:left;">
Weight in kg
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>sex</code>
</td>
<td style="text-align:left;">
Gender (0=men; 1=women)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>seruvitc</code>
</td>
<td style="text-align:left;">
Serum Vitamin C level (<span class="math inline">\(\mu\text{mol/L}\)</span>)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>ctakers</code>
</td>
<td style="text-align:left;">
Vitamin C supplements taken (1=yes, 0=no)
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>在 R 裏讀入數據，並對數據內容總結，對維生素C濃度和其他連續性變量作散點圖，對分類變量如性別，吸菸狀況，和維生素C補充劑服用與否之間的維生素 C 濃度作初步的分析表格。</li>
</ol>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb165-2" title="2">vitC &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/vitC.dta&quot;</span>)</a>
<a class="sourceLine" id="cb165-3" title="3"></a>
<a class="sourceLine" id="cb165-4" title="4"><span class="co">##########################################</span></a>
<a class="sourceLine" id="cb165-5" title="5"><span class="co"># Recoding the categorical variables     #</span></a>
<a class="sourceLine" id="cb165-6" title="6"><span class="co">##########################################</span></a>
<a class="sourceLine" id="cb165-7" title="7"></a>
<a class="sourceLine" id="cb165-8" title="8">vitC<span class="op">$</span>sex[vitC<span class="op">$</span>sex <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;Men&quot;</span></a>
<a class="sourceLine" id="cb165-9" title="9">vitC<span class="op">$</span>sex[vitC<span class="op">$</span>sex <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Women&quot;</span></a>
<a class="sourceLine" id="cb165-10" title="10">vitC<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb165-11" title="11">vitC<span class="op">$</span>cigs[vitC<span class="op">$</span>cigs <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;Non-smoker&quot;</span></a>
<a class="sourceLine" id="cb165-12" title="12">vitC<span class="op">$</span>cigs[vitC<span class="op">$</span>cigs <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Smoker&quot;</span></a>
<a class="sourceLine" id="cb165-13" title="13">vitC<span class="op">$</span>cigs &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>cigs)</a>
<a class="sourceLine" id="cb165-14" title="14">vitC<span class="op">$</span>ctakers[vitC<span class="op">$</span>ctakers <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> &quot;No&quot;</span></a>
<a class="sourceLine" id="cb165-15" title="15">vitC<span class="op">$</span>ctakers[vitC<span class="op">$</span>ctakers <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;Yes&quot;</span></a>
<a class="sourceLine" id="cb165-16" title="16">vitC<span class="op">$</span>ctakers &lt;-<span class="st"> </span><span class="kw">as.factor</span>(vitC<span class="op">$</span>ctakers)</a>
<a class="sourceLine" id="cb165-17" title="17"></a>
<a class="sourceLine" id="cb165-18" title="18"><span class="co">############################################</span></a>
<a class="sourceLine" id="cb165-19" title="19"><span class="co"># End of recoding the categorical variables#</span></a>
<a class="sourceLine" id="cb165-20" title="20"><span class="co">############################################</span></a>
<a class="sourceLine" id="cb165-21" title="21"></a>
<a class="sourceLine" id="cb165-22" title="22"><span class="kw">summary</span>(vitC) <span class="co">#Basic summary without any package</span></a></code></pre></div>
<pre><code>##      serial           age           height             cigs        weight         sex    
##  Min.   :  1.0   Min.   :65.0   Min.   :1.48   Non-smoker:80   Min.   : 44.0   Men  :44  
##  1st Qu.: 23.8   1st Qu.:67.0   1st Qu.:1.58   Smoker    :12   1st Qu.: 57.8   Women:48  
##  Median : 49.0   Median :69.0   Median :1.64                   Median : 67.0             
##  Mean   : 49.2   Mean   :69.3   Mean   :1.65                   Mean   : 68.6             
##  3rd Qu.: 73.2   3rd Qu.:71.0   3rd Qu.:1.72                   3rd Qu.: 76.5             
##  Max.   :100.0   Max.   :74.0   Max.   :1.89                   Max.   :103.0             
##                                 NA&#39;s   :1                      NA&#39;s   :1                 
##     seruvitc     ctakers 
##  Min.   :  8.0   No :73  
##  1st Qu.: 34.8   Yes:19  
##  Median : 58.0           
##  Mean   : 53.2           
##  3rd Qu.: 71.0           
##  Max.   :100.0           
## </code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1"><span class="kw">head</span>(vitC) <span class="co">#See the first 6 observations</span></a></code></pre></div>
<pre><code>## # A tibble: 6 x 8
##   serial   age height cigs       weight sex   seruvitc ctakers
##    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  
## 1      1    71   1.72 Smoker       68.8 Men          9 No     
## 2      2    70   1.63 Non-smoker   58.2 Women       19 No     
## 3      3    69   1.65 Non-smoker   94.3 Women       69 Yes    
## 4      4    67   1.62 Non-smoker   87.6 Women       71 No     
## 5      5    68   1.53 Non-smoker   66.3 Women       87 Yes    
## 6      6    71   1.64 Non-smoker   72.2 Women       96 Yes</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1"><span class="kw">library</span>(psych) <span class="co">#some detailed summary function from this package</span></a>
<a class="sourceLine" id="cb169-2" title="2"><span class="kw">describe</span>(vitC)</a></code></pre></div>
<pre><code>## vitC 
## 
##  8  Variables      92  Observations
## ----------------------------------------------------------------------------------------------------
## serial : subject number  Format:%3.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       92        1    49.25    33.74     5.55    10.10    23.75    49.00    73.25 
##      .90      .95 
##    88.90    95.45 
## 
## lowest :   1   2   3   4   5, highest:  96  97  98  99 100
## ----------------------------------------------------------------------------------------------------
## age : age on study entry  Format:%2.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       10    0.988    69.32    3.353     65.0     65.1     67.0     69.0     71.0 
##      .90      .95 
##     74.0     74.0 
##                                                                       
## Value         65    66    67    68    69    70    71    72    73    74
## Frequency     10     9    12     8    10    10    11     3     8    11
## Proportion 0.109 0.098 0.130 0.087 0.109 0.109 0.120 0.033 0.087 0.120
## ----------------------------------------------------------------------------------------------------
## height  Format:%4.1f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       91        1       34    0.999    1.647   0.1128     1.50     1.52     1.58     1.64     1.72 
##      .90      .95 
##     1.79     1.81 
## 
## lowest : 1.48 1.49 1.51 1.52 1.53, highest: 1.80 1.81 1.82 1.86 1.89
## ----------------------------------------------------------------------------------------------------
## cigs 
##        n  missing distinct 
##       92        0        2 
##                                 
## Value      Non-smoker     Smoker
## Frequency          80         12
## Proportion       0.87       0.13
## ----------------------------------------------------------------------------------------------------
## weight : Clothed weight  Format:%5.1f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       91        1       79        1    68.57    15.35    48.85    50.40    57.80    67.00    76.55 
##      .90      .95 
##    88.30    91.60 
## 
## lowest :  44.0  46.7  48.1  48.4  48.5, highest:  92.0  94.3  97.5 102.4 103.0
## ----------------------------------------------------------------------------------------------------
## sex 
##        n  missing distinct 
##       92        0        2 
##                       
## Value        Men Women
## Frequency     44    48
## Proportion 0.478 0.522
## ----------------------------------------------------------------------------------------------------
## seruvitc : Serum ascorbate  Format:%3.0f 
##        n  missing distinct     Info     Mean      Gmd      .05      .10      .25      .50      .75 
##       92        0       60        1    53.21    27.12    11.55    17.00    34.75    58.00    71.00 
##      .90      .95 
##    80.90    84.45 
## 
## lowest :   8   9  10  11  12, highest:  85  86  87  96 100
## ----------------------------------------------------------------------------------------------------
## ctakers 
##        n  missing distinct 
##       92        0        2 
##                       
## Value         No   Yes
## Frequency     73    19
## Proportion 0.793 0.207
## ----------------------------------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1"><span class="kw">library</span>(epiDisplay) <span class="co">#some STATA-like simple summary function</span></a>
<a class="sourceLine" id="cb171-2" title="2"><span class="kw">summ</span>(vitC)</a></code></pre></div>
<pre><code>## 
## No. of observations = 92
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 serial    92   49.25  49      29.07  1      100   
## 2 age       92   69.32  69      2.91   65     74    
## 3 height    91   1.65   1.64    0.1    1.48   1.89  
## 4 cigs                                              
## 5 weight    91   68.57  67      13.48  44     103   
## 6 sex                                               
## 7 seruvitc  92   53.21  58      23.83  8      100   
## 8 ctakers</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1">vitC<span class="op">$</span>serial[<span class="kw">which</span>(<span class="kw">is.na</span>(vitC<span class="op">$</span>height))]</a></code></pre></div>
<pre><code>## [1] 24</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1">vitC<span class="op">$</span>serial[<span class="kw">which</span>(<span class="kw">is.na</span>(vitC<span class="op">$</span>weight))]</a></code></pre></div>
<pre><code>## [1] 24</code></pre>
<p>從初步的熟悉數據結構和歸納結果可以看出，身高體重兩個數據有出現缺損值 (編號 24 的患者)。</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>sex, <span class="dt">graph =</span> <span class="ot">FALSE</span>) <span class="co"># From package &quot;epiDisplay&quot;</span></a></code></pre></div>
<pre><code>## For vitC$sex = Men 
##  obs. mean   median  s.d.   min.   max.  
##  44   46.091 52.5    24.877 8      100   
## 
## For vitC$sex = Women 
##  obs. mean   median  s.d.   min.   max.  
##  48   59.729 66.5    21.043 15     96</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>cigs, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## For vitC$cigs = Non-smoker 
##  obs. mean   median  s.d.   min.   max.  
##  80   55.138 58      23.323 8      100   
## 
## For vitC$cigs = Smoker 
##  obs. mean   median  s.d.   min.   max.  
##  12   40.333 49.5    24.186 9      68</code></pre>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" title="1"><span class="kw">summ</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">by=</span>vitC<span class="op">$</span>ctakers, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## For vitC$ctakers = No 
##  obs. mean   median  s.d.   min.   max.  
##  73   48.644 55      22.795 8      84    
## 
## For vitC$ctakers = Yes 
##  obs. mean   median  s.d.   min.   max.  
##  19   70.737 72      19.612 13     100</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" title="1"><span class="co"># You can also get similar detailed descriptive statistics by groups from package &quot;psych&quot;</span></a>
<a class="sourceLine" id="cb183-2" title="2"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>sex)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: Men
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 44 46.09 24.88   52.5   45.61 25.95   8 100    92 -0.06    -1.12 3.75
## --------------------------------------------------------------------------- 
## group: Women
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 48 59.73 21.04   66.5   61.15 15.57  15  96    81 -0.65    -0.62 3.04</code></pre>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" title="1"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>cigs)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: Non-smoker
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis   se
## X1    1 80 55.14 23.32     58    56.3 22.24   8 100    92 -0.43    -0.85 2.61
## --------------------------------------------------------------------------- 
## group: Smoker
##    vars  n  mean    sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 12 40.33 24.19   49.5    40.7 25.2   9  68    59 -0.19    -1.93 6.98</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" title="1"><span class="kw">describeBy</span>(vitC<span class="op">$</span>seruvitc, <span class="dt">group =</span> vitC<span class="op">$</span>ctakers)</a></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: No
##    vars  n  mean    sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 73 48.64 22.79     55   49.47 25.2   8  84    76 -0.33    -1.24 2.67
## --------------------------------------------------------------------------- 
## group: Yes
##    vars  n  mean    sd median trimmed   mad min max range  skew kurtosis  se
## X1    1 19 70.74 19.61     72   72.41 19.27  13 100    87 -1.07     1.52 4.5</code></pre>
<p>所以，血清維生素水平在女性，非吸菸者，和服用補充劑(廢話) 的人中較高。</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb189-2" title="2"><span class="kw">plot</span>(vitC<span class="op">$</span>age, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;age on study entry&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a>
<a class="sourceLine" id="cb189-3" title="3"><span class="kw">plot</span>(vitC<span class="op">$</span>weight, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;Clothed weight&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a>
<a class="sourceLine" id="cb189-4" title="4"><span class="kw">plot</span>(vitC<span class="op">$</span>height, vitC<span class="op">$</span>seruvitc, <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">xlab =</span> <span class="st">&quot;Height&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Serum ascorbate&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:practicalfig1"></span>
<img src="bookdown_files/figure-html/practicalfig1-1.png" alt="Scatter plots between serum ascorbate and age/weight/height" width="80%" />
<p class="caption">
圖 30.1: Scatter plots between serum ascorbate and age/weight/height
</p>
</div>
<p>散點圖似乎沒有證據提示血清維生素 C 濃度和連續型變量，年齡，身高，體重之間有什麼相關性。</p>
<ol start="2" style="list-style-type: decimal">
<li>建立維生素 C 和其他預測變量的簡單線性迴歸模型，你有什麼結論？</li>
</ol>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>age, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ age, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.94 -18.98   5.82  16.67  46.52 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  113.104     59.511    1.90    0.061 .
## age           -0.864      0.858   -1.01    0.316  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.8 on 90 degrees of freedom
## Multiple R-squared:  0.0111, Adjusted R-squared:  0.000163 
## F-statistic: 1.01 on 1 and 90 DF,  p-value: 0.316</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>age, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 %   97.5 %
## (Intercept) -5.125 231.3335
## age         -2.568   0.8401</code></pre>
<p>血清維生素 C 濃度隨着年齡增加遞減，但是迴歸係數不具有統計學意義 (<span class="math inline">\(p=0.32\)</span>)。年齡每增加 1 歲，血清維生素平均下降 <span class="math inline">\(0.864 \:\mu\text{mol/L， 95% CI:} (-2.57, 0.840)\)</span>，</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb194-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>height, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ height, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -45.11 -19.81   5.76  17.94  48.29 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    115.9       41.2    2.81    0.006 **
## height         -37.8       25.0   -1.51    0.134   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.3 on 89 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.0251, Adjusted R-squared:  0.0141 
## F-statistic: 2.29 on 1 and 89 DF,  p-value: 0.134</code></pre>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>height, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 % 97.5 %
## (Intercept)  34.05 197.75
## height      -87.37  11.84</code></pre>
<p>血清維生素 C 濃度隨着身高增加遞減，但是迴歸係數不具有統計學意義 (<span class="math inline">\(p=0.134\)</span>)。身高每增加 1cm，血清維生素平均下降 <span class="math inline">\(0.378 \:\mu\text{mol/L， 95% CI:} (-0.874, 0.118)\)</span>，</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>cigs, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ cigs, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -47.14 -19.53   3.26  17.86  44.86 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    55.14       2.62   21.05   &lt;2e-16 ***
## cigsSmoker    -14.80       7.25   -2.04    0.044 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.4 on 90 degrees of freedom
## Multiple R-squared:  0.0442, Adjusted R-squared:  0.0336 
## F-statistic: 4.17 on 1 and 90 DF,  p-value: 0.0442</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>cigs, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##              2.5 %  97.5 %
## (Intercept)  49.93 60.3417
## cigsSmoker  -29.21 -0.3945</code></pre>
<p>血清維生素 C 濃度與在吸菸人羣中較低，與不吸菸人羣相比，吸菸人羣的血清維生素 C 濃度平均低 <span class="math inline">\(14.8 \:\mu\text{mol/L， 95% CI:} (0.394, 29.2)\)</span>，這個濃度差具有臨界統計學意義 <span class="math inline">\((p=0.044)\)</span>。</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>weight, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ weight, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.71 -18.39   4.41  17.21  46.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 53.04017   12.90016    4.11  8.7e-05 ***
## weight       0.00967    0.18463    0.05     0.96    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.6 on 89 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  3.08e-05,   Adjusted R-squared:  -0.0112 
## F-statistic: 0.00274 on 1 and 89 DF,  p-value: 0.958</code></pre>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>weight, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##               2.5 %  97.5 %
## (Intercept) 27.4078 78.6725
## weight      -0.3572  0.3765</code></pre>
<p>維生素濃度和體重關係幾乎可以忽略 <span class="math inline">\((p=0.96)\)</span>。</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.73 -20.23   6.59  17.27  53.91 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    46.09       3.46   13.32   &lt;2e-16 ***
## sexWomen       13.64       4.79    2.85   0.0055 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23 on 90 degrees of freedom
## Multiple R-squared:  0.0826, Adjusted R-squared:  0.0724 
## F-statistic:  8.1 on 1 and 90 DF,  p-value: 0.00547</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##             2.5 % 97.5 %
## (Intercept) 39.22  52.97
## sexWomen     4.12  23.16</code></pre>
<p>血清維生素 C 濃度與在女性中較高，與男性相比，女性的血清維生素 C 濃度平均高 <span class="math inline">\(13.6 \:\mu\text{mol/L， 95% CI:} (4.12, 23.2)\)</span>，這個濃度差具有顯著統計學意義 <span class="math inline">\((p=0.005)\)</span>。</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ ctakers, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -57.74 -15.42   5.81  18.61  35.36 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    48.64       2.60   18.73  &lt; 2e-16 ***
## ctakersYes     22.09       5.72    3.87  0.00021 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.2 on 90 degrees of freedom
## Multiple R-squared:  0.142,  Adjusted R-squared:  0.133 
## F-statistic: 14.9 on 1 and 90 DF,  p-value: 0.000209</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##             2.5 % 97.5 %
## (Intercept) 43.48  53.80
## ctakersYes  10.74  33.45</code></pre>
<p>血清維生素 C 濃度與在服用補充劑的人中較高，與不服用補充劑的人相比，服用者的血清維生素 C 濃度平均高 <span class="math inline">\(22.1 \:\mu\text{mol/L， 95% CI:} (10.7, 33.4)\)</span>，這個濃度差具有顯著統計學意義 <span class="math inline">\((p=0.00021)\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>擬合一個多元線性迴歸模型，因變量爲血清維生素 C 濃度，預測變量使用 性別，吸菸狀態，和 是否服用維生素補充劑。解釋輸出結果的數字的含義。跟這些預測變量單獨和血清維生素 C 濃度建立的簡單線性迴歸模型作比較。說明哪些結果發生了改變，爲什麼。</li>
</ol>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.66 -19.07   2.24  17.62  38.03 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    44.97       3.55   12.69  &lt; 2e-16 ***
## sexWomen       10.66       4.51    2.36  0.02044 *  
## cigsSmoker    -11.57       6.66   -1.74  0.08586 .  
## ctakersYes     20.25       5.51    3.67  0.00041 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.3 on 88 degrees of freedom
## Multiple R-squared:  0.23,   Adjusted R-squared:  0.203 
## F-statistic: 8.74 on 3 and 88 DF,  p-value: 3.88e-05</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" title="1"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC)), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## sex        1   4270  4270.0  9.4354 0.0028320 ** 
## cigs       1   1497  1497.0  3.3080 0.0723454 .  
## ctakers    1   6102  6101.8 13.4831 0.0004125 ***
## Residuals 88  39824   452.5                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb218-1" title="1"><span class="kw">confint</span>(<span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC))</a></code></pre></div>
<pre><code>##               2.5 % 97.5 %
## (Intercept)  37.927 52.017
## sexWomen      1.687 19.630
## cigsSmoker  -24.799  1.666
## ctakersYes    9.291 31.211</code></pre>
<p>從這個多元線性迴歸的輸出報告來看，血清維生素 C 濃度</p>
<ul>
<li>在吸菸者中較低 <span class="math inline">\(-11.6 \:\mu\text{mol/L， 95% CI:} (-24.8, +1.67), p = 0.086\)</span>；</li>
<li>在女性中較高 <span class="math inline">\(+10.7 \:\mu\text{mol/L， 95% CI:} (1.69, 19.6), p = 0.020\)</span>；</li>
<li>在服用維生素補充劑的人中較高 <span class="math inline">\(+20.3 \:\mu\text{mol/L， 95% CI:} (9.29, 31.2), p = 0.0004\)</span>。</li>
</ul>
<p>故，本次數據告訴我們，服用維生素補充劑是最強的預測變量。在多元線性迴歸模型的結果中可以看到：</p>
<ul>
<li>性別之間維生素 C 濃度差變小了 (<span class="math inline">\(+13.6 \rightarrow +10.7\)</span>) <br> 這是因爲女性中有較多人服用維生素補充劑。即便如此，性別差在多元線性迴歸模型中仍然是有意義的。</li>
</ul>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Vitamin C taker&quot;</span>=ctakers, <span class="st">&quot;Gender&quot;</span> =<span class="st"> </span>sex), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(ctakers)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb220-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ---------------------------------- 
##           ---------Gender---------- 
##  Vitamin       Men   Women   Total  
##  C taker                            
##  ---------------------------------- 
##  No             37      36      73  
##              84.09   75.00   79.35  
##                                     
##  Yes             7      12      19  
##              15.91   25.00   20.65  
##                                     
##                                     
##  Total          44      48      92  
##             100.00  100.00  100.00  
##  ----------------------------------</code></pre>
<ul>
<li>吸菸與非吸菸者之間的維生素 C 濃度差也變小了 (<span class="math inline">\(-14.8 \rightarrow -11.6\)</span>)，因爲儘管吸菸與非吸菸者的維生素補充劑服用比例差不不大，但是吸菸者中大部分是男性。(詳見下表) <br> 吸菸者和非吸菸者之間維生素 C 濃度差經過多元線性迴歸調整後變得不再有統計學意義 <span class="math inline">\((p=0.086)\)</span>。</li>
</ul>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb222-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Vitamin C taker&quot;</span>=ctakers, <span class="st">&quot;Smoker&quot;</span> =<span class="st"> </span>cigs), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(ctakers)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb222-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ------------------------------------- 
##           -----------Smoker----------- 
##  Vitamin   Non-smoker  Smoker   Total  
##  C taker                               
##  ------------------------------------- 
##  No                63      10      73  
##                 78.75   83.33   79.35  
##                                        
##  Yes               17       2      19  
##                 21.25   16.67   20.65  
##                                        
##                                        
##  Total             80      12      92  
##                100.00  100.00  100.00  
##  -------------------------------------</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb224-1" title="1">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Gender&quot;</span> =<span class="st"> </span>sex, <span class="st">&quot;Smoker&quot;</span> =<span class="st"> </span>cigs), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(sex)), <span class="dt">data =</span> vitC, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb224-2" title="2"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  ------------------------------------ 
##          -----------Smoker----------- 
##  Gender   Non-smoker  Smoker   Total  
##  ------------------------------------ 
##  Men              36       8      44  
##                45.00   66.67   47.83  
##                                       
##  Women            44       4      48  
##                55.00   33.33   52.17  
##                                       
##                                       
##  Total            80      12      92  
##               100.00  100.00  100.00  
##  ------------------------------------</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>在前一個模型中加入年齡，身高，體重作爲新的預測變量。先解釋新的模型中報告的個數值的意義，利用方差分析表格比較兩個模型的差別 (先手計算，再用 R 計算確認你的答案)。</li>
</ol>
<p>由於身高體重有缺損值(serial=24)，所以要比較預測變量增加前後的模型，需要先把之前的模型中 serial=24 的觀察對象刪除掉才公平。</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers, <span class="dt">data =</span> vitC[<span class="op">-</span><span class="dv">24</span>,])</a>
<a class="sourceLine" id="cb226-2" title="2"><span class="kw">summary</span>(Model1);<span class="kw">anova</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC[-24, 
##     ])
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.79 -18.21   2.21  17.59  36.97 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    46.03       3.55   12.96  &lt; 2e-16 ***
## sexWomen        9.76       4.49    2.18  0.03228 *  
## cigsSmoker    -12.26       6.59   -1.86  0.06627 .  
## ctakersYes     19.83       5.45    3.64  0.00047 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21 on 87 degrees of freedom
## Multiple R-squared:  0.226,  Adjusted R-squared:  0.199 
## F-statistic: 8.46 on 3 and 87 DF,  p-value: 5.39e-05</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## sex        1   3689    3689    8.35 0.00486 ** 
## cigs       1   1679    1679    3.80 0.05440 .  
## ctakers    1   5841    5841   13.23 0.00047 ***
## Residuals 87  38418     442                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(seruvitc <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>ctakers <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>weight <span class="op">+</span><span class="st"> </span>height, <span class="dt">data =</span> vitC[<span class="op">-</span><span class="dv">24</span>,])</a>
<a class="sourceLine" id="cb229-2" title="2"><span class="kw">summary</span>(Model2);<span class="kw">anova</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ sex + cigs + ctakers + age + weight + 
##     height, data = vitC[-24, ])
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -40.56 -17.72   4.23  18.75  35.58 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   65.352     89.482    0.73  0.46722    
## sexWomen      10.367      7.285    1.42  0.15843    
## cigsSmoker   -11.800      6.757   -1.75  0.08444 .  
## ctakersYes    19.859      5.547    3.58  0.00057 ***
## age           -0.353      0.840   -0.42  0.67499    
## weight         0.107      0.223    0.48  0.63174    
## height        -1.573     42.259   -0.04  0.97040    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.3 on 84 degrees of freedom
## Multiple R-squared:  0.233,  Adjusted R-squared:  0.178 
## F-statistic: 4.25 on 6 and 84 DF,  p-value: 0.00088</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: seruvitc
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## sex        1   3689    3689    8.14 0.00546 ** 
## cigs       1   1679    1679    3.70 0.05767 .  
## ctakers    1   5841    5841   12.88 0.00056 ***
## age        1    205     205    0.45 0.50283    
## weight     1    133     133    0.29 0.58951    
## height     1      1       1    0.00 0.97040    
## Residuals 84  38079     453                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>利用偏 <span class="math inline">\(F\)</span> 檢驗的公式</p>
<p><span class="math display">\[
F=\frac{(205.2889295+132.9899543+0.6280691)/3}{38079.42/84} = 0.2492713
\]</span></p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb232-1" title="1"><span class="kw">anova</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: seruvitc ~ sex + cigs + ctakers
## Model 2: seruvitc ~ sex + cigs + ctakers + age + weight + height
##   Res.Df   RSS Df Sum of Sq    F Pr(&gt;F)
## 1     87 38418                         
## 2     84 38079  3       339 0.25   0.86</code></pre>
<p>所以檢驗統計量對應的 <span class="math inline">\(p=0.86\)</span> 告訴我們沒有證明據證明調整了性別，吸菸狀況，服用補充劑與否之後，增加的年齡，體重，身高作爲預測變量和觀察對象的血清維生素 C 濃度有關係。模型 2 比模型 1 不能解釋更多的模型殘差 (不比模型 1 更加擬合數據)。</p>
</div>
<div id="紅細胞容積與血紅蛋白" class="section level3">
<h3><span class="header-section-number">30.5.2</span> 紅細胞容積與血紅蛋白</h3>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 30.4: Data set of haemoglobin and PCV explained
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable name
</th>
<th style="text-align:left;">
content
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<code>hb</code>
</td>
<td style="text-align:left;">
Haemoglobin (gm/dl)
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>pcv</code>
</td>
<td style="text-align:left;">
Pack cell volume %
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>age</code>
</td>
<td style="text-align:left;">
Age (years)
</td>
</tr>
<tr>
</tbody>
</table>
<ol start="5" style="list-style-type: decimal">
<li>把數據導入 R，並且建立因變量爲血紅蛋白，預測變量爲 PCV 和 年齡的多元線性迴歸模型</li>
</ol>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb234-2" title="2">haem &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/haem.dta&quot;</span>)</a>
<a class="sourceLine" id="cb234-3" title="3">psych<span class="op">::</span><span class="kw">describe</span>(haem)</a></code></pre></div>
<pre><code>##     vars  n  mean   sd median trimmed   mad  min  max range  skew kurtosis   se
## hb     1 12 12.53 1.70   12.8   12.56  1.70  9.6 15.1   5.5 -0.26    -1.39 0.49
## pcv    2 12 38.58 8.14   37.5   38.80 11.12 25.0 50.0  25.0 -0.10    -1.59 2.35
## age    3 12 32.75 8.98   31.5   32.40  9.64 20.0 49.0  29.0  0.31    -1.20 2.59</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(hb <span class="op">~</span><span class="st"> </span>pcv <span class="op">+</span><span class="st"> </span>age, <span class="dt">data =</span> haem)</a>
<a class="sourceLine" id="cb236-2" title="2"><span class="kw">summary</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = hb ~ pcv + age, data = haem)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -1.413 -1.002  0.302  0.662  1.867 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   5.0606     1.9680    2.57    0.030 *
## pcv           0.1056     0.0429    2.46    0.036 *
## age           0.1036     0.0389    2.66    0.026 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.15 on 9 degrees of freedom
## Multiple R-squared:  0.63,   Adjusted R-squared:  0.548 
## F-statistic: 7.65 on 2 and 9 DF,  p-value: 0.0114</code></pre>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" title="1">haem<span class="op">$</span>e_hat &lt;-<span class="st"> </span>Model3<span class="op">$</span>residuals</a>
<a class="sourceLine" id="cb238-2" title="2">haem<span class="op">$</span>y_hat &lt;-<span class="st"> </span>Model3<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb238-3" title="3"><span class="kw">print</span>(haem)</a></code></pre></div>
<pre><code>## # A tibble: 12 x 5
##       hb   pcv   age  e_hat y_hat
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1  11.1    35    20  0.274  10.8
##  2  10.7    45    22 -1.39   12.1
##  3  12.4    47    25 -0.211  12.6
##  4  14      50    28  0.762  13.2
##  5  13.1    31    28  1.87   11.2
##  6  10.5    30    31 -0.938  11.4
##  7   9.6    25    32 -1.41   11.0
##  8  12.5    33    35  0.331  12.2
##  9  13.5    35    38  0.810  12.7
## 10  13.9    40    40  0.475  13.4
## 11  15.1    45    45  0.629  14.5
## 12  13.9    47    49 -1.20   15.1</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>利用 R 的矩陣計算重現迴歸模型的計算結果</li>
</ol>
<ul>
<li>計算因變量和兩個預測變量各自的和</li>
</ul>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" title="1">sumy &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb)</a>
<a class="sourceLine" id="cb240-2" title="2">sumx1 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>pcv)</a>
<a class="sourceLine" id="cb240-3" title="3">sumx2 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>age)</a></code></pre></div>
<ul>
<li>計算因變量和兩個預測變量各自的平方和</li>
</ul>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" title="1">sumy2 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>hb)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-2" title="2">sumx1y &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb<span class="op">*</span>haem<span class="op">$</span>pcv)</a>
<a class="sourceLine" id="cb241-3" title="3">sumx2y &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>hb<span class="op">*</span>haem<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb241-4" title="4">sumx12 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>pcv)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-5" title="5">sumx22 &lt;-<span class="st"> </span><span class="kw">sum</span>((haem<span class="op">$</span>age)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb241-6" title="6">sumx1x2 &lt;-<span class="st"> </span><span class="kw">sum</span>(haem<span class="op">$</span>pcv<span class="op">*</span>haem<span class="op">$</span>age)</a></code></pre></div>
<ul>
<li>生成一個數值爲 1 的變量，名爲 <code>one</code></li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" title="1">one &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">12</span>)</a></code></pre></div>
<ul>
<li>用 <code>matrix()</code> 命令生成矩陣</li>
</ul>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" title="1">Rownames &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb243-2" title="2"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>) {</a>
<a class="sourceLine" id="cb243-3" title="3">  a &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;row&quot;</span>, i, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb243-4" title="4">  Rownames &lt;-<span class="st"> </span><span class="kw">c</span>(Rownames,a); <span class="kw">rm</span>(a)</a>
<a class="sourceLine" id="cb243-5" title="5">  }</a>
<a class="sourceLine" id="cb243-6" title="6"></a>
<a class="sourceLine" id="cb243-7" title="7">Y &lt;-<span class="st"> </span><span class="kw">matrix</span>(haem<span class="op">$</span>hb ,<span class="dt">dimnames =</span> <span class="kw">list</span>(Rownames, <span class="st">&quot;hb&quot;</span>))</a>
<a class="sourceLine" id="cb243-8" title="8">Y</a></code></pre></div>
<pre><code>##         hb
## row1  11.1
## row2  10.7
## row3  12.4
## row4  14.0
## row5  13.1
## row6  10.5
## row7   9.6
## row8  12.5
## row9  13.5
## row10 13.9
## row11 15.1
## row12 13.9</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" title="1">X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(one, haem<span class="op">$</span>pcv, haem<span class="op">$</span>age), <span class="dt">nrow =</span> <span class="dv">12</span>, <span class="dt">dimnames =</span> <span class="kw">list</span>(Rownames, <span class="kw">c</span>(<span class="st">&quot;one&quot;</span>, <span class="st">&quot;pcv&quot;</span>, <span class="st">&quot;age&quot;</span>)))</a>
<a class="sourceLine" id="cb245-2" title="2">X</a></code></pre></div>
<pre><code>##       one pcv age
## row1    1  35  20
## row2    1  45  22
## row3    1  47  25
## row4    1  50  28
## row5    1  31  28
## row6    1  30  31
## row7    1  25  32
## row8    1  33  35
## row9    1  35  38
## row10   1  40  40
## row11   1  45  45
## row12   1  47  49</code></pre>
<ul>
<li>用公式 <a href="#eq:lm5-4">(30.4)</a> 計算估計 <span class="math inline">\(\mathbf{\hat\beta}\)</span> 矩陣</li>
</ul>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb247-1" title="1">XX &lt;-<span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X <span class="co"># these are the sum of squares of each variable and the sum of the cross products of the pairs of variables</span></a>
<a class="sourceLine" id="cb247-2" title="2">XX</a></code></pre></div>
<pre><code>##     one   pcv   age
## one  12   463   393
## pcv 463 18593 15276
## age 393 15276 13757</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb249-1" title="1">(<span class="kw">data.frame</span>(sumx1,sumx12,sumx2,sumx22, sumx1x2))</a></code></pre></div>
<pre><code>##   sumx1 sumx12 sumx2 sumx22 sumx1x2
## 1   463  18593   393  13757   15276</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb251-1" title="1">XY &lt;-<span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y <span class="co"># this is the cross-product matrix of predictors against outcome</span></a>
<a class="sourceLine" id="cb251-2" title="2">XY</a></code></pre></div>
<pre><code>##         hb
## one  150.3
## pcv 5887.7
## age 5026.0</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" title="1">(<span class="kw">data.frame</span>(sumy, sumx1y, sumx2y))</a></code></pre></div>
<pre><code>##    sumy sumx1y sumx2y
## 1 150.3   5888   5026</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb255-1" title="1">betahat &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X ) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y</a>
<a class="sourceLine" id="cb255-2" title="2">betahat</a></code></pre></div>
<pre><code>##         hb
## one 5.0606
## pcv 0.1056
## age 0.1036</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" title="1"><span class="co">###or equivalently you can use</span></a>
<a class="sourceLine" id="cb257-2" title="2">betahat &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">crossprod</span>(X) ) <span class="op">%*%</span><span class="st"> </span><span class="kw">crossprod</span>( X, Y )</a>
<a class="sourceLine" id="cb257-3" title="3">betahat</a></code></pre></div>
<pre><code>##         hb
## one 5.0606
## pcv 0.1056
## age 0.1036</code></pre>
<p>可以看到 <code>betahat</code> 的結果和多元迴歸模型輸出的迴歸係數估計是一致的。</p>
<ul>
<li>計算擬合值</li>
</ul>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" title="1">Fitted &lt;-<span class="st"> </span>X<span class="op">%*%</span>betahat</a>
<a class="sourceLine" id="cb259-2" title="2">Fitted</a></code></pre></div>
<pre><code>##          hb
## row1  10.83
## row2  12.09
## row3  12.61
## row4  13.24
## row5  11.23
## row6  11.44
## row7  11.01
## row8  12.17
## row9  12.69
## row10 13.43
## row11 14.47
## row12 15.10</code></pre>
<ul>
<li>估計迴歸係數的方差協方差矩陣</li>
</ul>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb261-1" title="1">e_hat &lt;-<span class="st"> </span>Y<span class="op">-</span>Fitted <span class="co"># residuals</span></a>
<a class="sourceLine" id="cb261-2" title="2">e_hat</a></code></pre></div>
<pre><code>##            hb
## row1   0.2736
## row2  -1.3892
## row3  -0.2110
## row4   0.7616
## row5   1.8674
## row6  -0.9377
## row7  -1.4134
## row8   0.3314
## row9   0.8096
## row10  0.4747
## row11  0.6291
## row12 -1.1962</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb263-1" title="1">SSres &lt;-<span class="st"> </span><span class="kw">t</span>(e_hat) <span class="op">%*%</span><span class="st"> </span>e_hat <span class="co"># residual sum of squares</span></a>
<a class="sourceLine" id="cb263-2" title="2">SSres</a></code></pre></div>
<pre><code>##       hb
## hb 11.81</code></pre>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" title="1">Sigma2 &lt;-<span class="st"> </span>SSres <span class="op">%*%</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>(<span class="dv">12</span><span class="op">-</span>(<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>))) <span class="co"># residual variance</span></a>
<a class="sourceLine" id="cb265-2" title="2">Sigma2</a></code></pre></div>
<pre><code>##     [,1]
## hb 1.312</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" title="1"><span class="co"># multiply the inverse of the cross-product matrix for the predictors</span></a>
<a class="sourceLine" id="cb267-2" title="2"><span class="co"># by the residual variance to get the variance-covariance matrix of</span></a>
<a class="sourceLine" id="cb267-3" title="3"><span class="co"># the coefficients</span></a>
<a class="sourceLine" id="cb267-4" title="4">V &lt;-<span class="st"> </span><span class="kw">solve</span>( <span class="kw">crossprod</span>(X) ) <span class="op">*</span><span class="st"> </span><span class="kw">as.numeric</span>(Sigma2)</a>
<a class="sourceLine" id="cb267-5" title="5">V</a></code></pre></div>
<pre><code>##          one        pcv        age
## one  3.87296 -0.0632072 -0.0404537
## pcv -0.06321  0.0018365 -0.0002336
## age -0.04045 -0.0002336  0.0015105</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" title="1"><span class="co"># the square root of the diagonal terms in the above matrix are the standard errors shown in the regression output</span></a>
<a class="sourceLine" id="cb269-2" title="2"><span class="kw">sqrt</span>(<span class="kw">diag</span>(V))</a></code></pre></div>
<pre><code>##     one     pcv     age 
## 1.96798 0.04285 0.03887</code></pre>
</div>
</div>
</div>
<div id="線性迴歸的模型診斷" class="section level1">
<h1><span class="header-section-number">第 31 章</span> 線性迴歸的模型診斷</h1>
<p>和其他的統計學模型一樣，線性迴歸也有自己的前提條件，而且從模型結果作出的各種推斷都依賴這些前提條件的成立。所以，我們需要有一些統計學的手段來檢查線性迴歸模型中這些前提是否得到滿足。然而理想總是很豐滿，現實通常又太骨感。你不大可能找到一組真實的數據能夠 100% 完美的滿足所需要的前提條件。當然不是說不能滿足模型的前提條件，我們就無法進行統計推斷了。而且我們也有不少結果穩健 (robust) 的統計學手段，讓我們可以不必考慮太多前提條件。檢查數據，瞭解數據內容，理解數據本身的結構永遠都是有助於數據分析的。</p>
<p>還要記得一點就是，根據中心極限定理，(即使有一些前提假設不能成立) 大型數據分析結果的穩健性/可靠性，要高於小型數據的分析。</p>
<div id="線性迴歸模型的前提條件" class="section level2">
<h2><span class="header-section-number">31.1</span> 線性迴歸模型的前提條件</h2>
<ol style="list-style-type: decimal">
<li>因變量和各個預測變量之間的關係都是線性 linear relationship 的；</li>
<li>因變量之間相互獨立；</li>
<li>真實 <strong>true</strong> 殘差的方差是恆定不變的 constant。這裏的含義是在真實迴歸直線上下散佈的因變量的點，在任意一個預測變量值的位置的方差 (分散) 要保持恆定不變。這個特性被描述成方差齊性 homoscedasticity (殘差方差的一致性 homogeneity of the residual variance)，與之相對的定義是異方差性 heteroscedasticity (殘差方差的不同質性，heterogeneity of the residual variance)。</li>
<li>真實殘差服從正態分佈。(儘管你發現統計忍者包裏丟入隨便什麼數據都能給你個線性迴歸的報告來，但是，如果你真想用其結果做統計推斷，p CI 的話，這條前提必須滿足。)</li>
</ol>
<p>本章着重討論第 1，3，4 前提條件的診斷法。因爲觀測數據之間是否獨立性 (第 2 條) 並不是你光盯着數據看就能知道的。你要去問給你數據的 (沒良心的) 人。</p>
</div>
<div id="用圖形來視覺診斷" class="section level2">
<h2><span class="header-section-number">31.2</span> 用圖形來視覺診斷</h2>
<div class="figure" style="text-align: center"><span id="fig:fig6-1"></span>
<img src="img/Selection_109.png" alt="Illustration the usefullness of scatter plots of the dependent variable against the predictor variable in simple linear regression" width="80%" />
<p class="caption">
圖 31.1: Illustration the usefullness of scatter plots of the dependent variable against the predictor variable in simple linear regression
</p>
</div>
<p>圖 <a href="#fig:fig6-1">31.1</a> 中展示了四種實例。把預測變量和因變量做散點圖，這常常是甄別出異方差性 (Example C)，非線性 (Example A)，異常值 (Example D) 的最好方法。其中右上角的 Example B 是良好的迴歸模型的散點圖應該有的樣子。</p>
<p>建議進行視覺判斷的時候把擬合曲線去掉再作一次，看看有迴歸直線和沒有迴歸直線前後的散點圖差別，更容易看出數據的分佈特徵。但是光看散點圖作判斷的方法，在多元線性迴歸模型中只能看看能否找到一些異常值，對輔助判斷方差齊性和線性關係就沒有太大的用處。殘差點圖就更加實用。</p>
</div>
<div id="殘差圖" class="section level2">
<h2><span class="header-section-number">31.3</span> 殘差圖</h2>
<p>如果線性迴歸模型的前提條件能夠得到滿足，那麼擬合模型後的殘差，一定會服從正態分佈且方差均勻一致。所以另一個診斷異方差性的辦法可以通過作觀察殘差和擬合值之間的散點圖來輔助判斷。下圖 <a href="#fig:fig6-2">31.2</a> 是各個簡單線性迴歸擬合後的<strong>殘差和擬合值</strong>之間的散點圖。可以看出左下角的 Example C 的異方差性展現得更加明顯了。同樣此圖也能幫助判斷線性關係，如左上角的 Example A 所示，如果預測變量和因變量之間不是線性關係，那麼殘差就不可能均勻的分佈在 <span class="math inline">\(0\)</span> 的兩側。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-2"></span>
<img src="img/Selection_111.png" alt="Plots of residuals agianst fitted values for the examples in the previous figure" width="80%" />
<p class="caption">
圖 31.2: Plots of residuals agianst fitted values for the examples in the previous figure
</p>
</div>
<p>對於一個簡單線性迴歸模型來說，擬合值僅僅只是預測變量的一個線性數學轉換，所以上面圖中的殘差和擬合值的散點圖，其實等價於殘差和預測變量的散點圖。所以圖 <a href="#fig:fig6-1">31.1</a> 和圖 <a href="#fig:fig6-2">31.2</a> 兩圖展現的信息量此時是一樣的。</p>
<p>但是，多元線性迴歸時，殘差和擬合值的散點圖會比殘差和預測變量散點圖更適合判斷異方差性，和線性關係的假設。</p>
</div>
<div id="殘差正態圖-normal-plot-of-residuals" class="section level2">
<h2><span class="header-section-number">31.4</span> 殘差正態圖 normal plot of residuals</h2>
<p>正態圖在分析技巧的章節也有介紹 (Section <a href="#normalplot">25.2.1</a>)。這是最佳的判斷數據是否服從正態分佈的視覺圖。所以用它來繪製線性迴歸擬合後的殘差，是個很好的辦法。可惜的是殘差正態圖無法用於判斷異方差性，和線性關係兩個假設。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-3"></span>
<img src="img/Selection_112.png" alt="Normal plots of residuals for the examples in the previous figure" width="80%" />
<p class="caption">
圖 31.3: Normal plots of residuals for the examples in the previous figure
</p>
</div>
<p>有時後觀察殘差 (observed residuals) 可能不能滿足齊方差性質而真實殘差 (true residuals) 反而滿足。所以一些統計學家建議把計算的殘差標準化 (standardised residuals) 以後再作正態圖。</p>
<div id="模型診斷實例" class="section level3">
<h3><span class="header-section-number">31.4.1</span> 模型診斷實例</h3>
<p>前面建立過的兒童體重和年齡，身長之間的多元迴歸模型的診斷 (Section <a href="#globalsig">30.3.3</a>) 見下圖。所有四個圖都沒有證據證明非線性關係和異方差性。看不見顯著的異常值。正態圖看出殘差有那麼一點點不太正態分佈，但是不嚴重到讓人懷疑模型給出的推斷是否受到重大影響。</p>
<div class="figure" style="text-align: center"><span id="fig:fig6-4"></span>
<img src="bookdown_files/figure-html/fig6-4-1.png" alt="Residual plots for the linear regression relating a child's weight to their age and length" width="100%" />
<p class="caption">
圖 31.4: Residual plots for the linear regression relating a child’s weight to their age and length
</p>
</div>
</div>
</div>
<div id="前提條件的統計學檢驗" class="section level2">
<h2><span class="header-section-number">31.5</span> 前提條件的統計學檢驗</h2>
<div id="二次方程迴歸法檢驗非線性" class="section level3">
<h3><span class="header-section-number">31.5.1</span> 二次方程迴歸法檢驗非線性</h3>
<p>二次方程迴歸法是一種多元迴歸模型，它包含了兩個預測變量，一個是另一個的平方。數學模型可以標記成爲：</p>
<p><span class="math display" id="eq:lm6-1">\[
\begin{aligned}
y_i &amp; = \alpha + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i \\
\text{Where } &amp; \varepsilon_i \sim \text{NID}(0, \sigma^2)
\end{aligned}
\tag{31.1}
\]</span></p>
<p>儘管你看到了二次方程在這裏，但是這仍然是一個線性迴歸模型。但是二次方程的迴歸模型描述的是 <span class="math inline">\(Y, X\)</span> 兩個變量之間的非線性關係。如果你把方程 <span class="math inline">\(\hat{y}_i = \hat\alpha + \hat\beta_1x_i + \hat\beta_2x^2_i\)</span> 對 <span class="math inline">\(x_i\)</span> 求微分，你會得到 <span class="math inline">\(\hat\beta_1+2\hat\beta_2 x_i\)</span>。這是二次方程的曲率方程。所以如果結果中報告 <span class="math inline">\(\hat\beta_2\)</span> 是有統計學意義的，就等於是有證據證明這兩個變量之間的關係不是線性的。</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb271-1" title="1">growgam1<span class="op">$</span>age2 &lt;-<span class="st"> </span>(growgam1<span class="op">$</span>age)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb271-2" title="2">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb271-3" title="3"><span class="kw">print</span>(<span class="kw">summary</span>(Model1), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.20525 -0.64402 -0.00303  0.55967  2.86277 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.351244   1.259968 -6.6281 3.531e-10 ***
## age         -0.011260   0.016751 -0.6722    0.5023    
## len          0.237129   0.019516 12.1502 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9546 on 187 degrees of freedom
## Multiple R-squared:  0.74337,    Adjusted R-squared:  0.74063 
## F-statistic: 270.84 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb273-1" title="1"><span class="kw">print</span>(<span class="kw">summary</span>(Model2), <span class="dt">digits =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ len + age + age2, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.30561 -0.64811 -0.01615  0.54829  2.74233 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -8.5918429  1.2537775 -6.8528 1.031e-10 ***
## len          0.2514685  0.0205039 12.2644 &lt; 2.2e-16 ***
## age         -0.1110198  0.0502050 -2.2113   0.02823 *  
## age2         0.0023351  0.0011091  2.1055   0.03659 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9459 on 186 degrees of freedom
## Multiple R-squared:  0.74935,    Adjusted R-squared:  0.74531 
## F-statistic: 185.36 on 3 and 186 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>正如上面的二次方程模型輸出結果所示，年齡和體重之間，當調整了身高以後，有證據 (但是較弱) 證明不呈現線性關係 <span class="math inline">\((p=0.037)\)</span>。</p>
</div>
<div id="非線性關係模型" class="section level3">
<h3><span class="header-section-number">31.5.2</span> 非線性關係模型</h3>
<p>二次方程的迴歸模型的應用在非線性模型中的應用其實有許許多多的缺陷。例如二次方程迴歸只能默認有一個極致點。也就是在二次方程模型中，預測變量和因變量的關係要麼是先下降後升高，要麼是先升高再下降。不光如此，二次方程迴歸還默認二者之間的關係在極致點是左右對稱的。這無論如何在現實中都很難有成這樣關係的兩個變量。所以，假如你使用二次方程模型迴歸之後發現非線性的證據是有意義的，那麼更好的辦法是接下來擬合一個更加符合實際情況的非線性模型-多項式曲線迴歸模型。</p>
<p>二次方程回顧模型是多項式曲線迴歸模型的最簡單形式，其次是三次方程模型 (其實就是在公式 <a href="#eq:lm6-1">(31.1)</a> 裏面加一個 <span class="math inline">\(+\beta_3 x_i^3\)</span>)。另一種更加靈活的模型是擬合一個精確的分段式多項式模型，即允許在不同範圍 (被描述爲 “結點 knots”) 的預測變量 <span class="math inline">\(X\)</span> 內擬合不同的模型。其中一種叫做 <strong>限制性立方曲線模型</strong> restricted cubic spline model (<a href="http://wangcc.me/publication/hpylorimeta/">點這裏看我用了這種方法的論文</a>)：</p>
<ol style="list-style-type: decimal">
<li>默認第一個節點之前和最後一個節點以後爲直線模型；</li>
<li>其餘節點之間默認用三次方迴歸模型擬合數據；</li>
<li>在節點處的兩個方程之間用平滑的曲線連接 (強制兩個方程的一階二階導數相等即可 constraining the first and second derivatives of adjacent functions to agree when they meet at the knot point)</li>
</ol>
</div>
</div>
<div id="異常值槓桿值和庫克距離" class="section level2">
<h2><span class="header-section-number">31.6</span> 異常值，槓桿值，和庫克距離</h2>
<p>觀測值中的異常值很顯然對模型的擬合會有較大的影響。如果某個觀測值對應的擬合值是異常值的話，那麼這樣的值被認爲槓桿值很大。庫克距離 (Cook’s Distance) 是另一種用來衡量異常值的手段。</p>
<div id="standardres" class="section level3">
<h3><span class="header-section-number">31.6.1</span> 異常值和標準化殘差</h3>
<p>異常值指的是那些通過模型擬合過後，觀測值和擬合值差異很大的那些觀察對象。這些值需要被甄別出來因爲它們</p>
<ol style="list-style-type: decimal">
<li>可能是數據錄入階段造成的人爲失誤，或者是有什麼別的原因導致的系統性異常需要讓輸入數據的人員進行進一步的調查；</li>
<li>異常值可能較大的影響迴歸係數的方差估計，造成不精確甚至錯誤的結果；</li>
<li>異常值也會影響迴歸係數本身的估計。</li>
</ol>
<p>觀測值和擬合值之間的差，被命名爲觀測殘差 (observed residuals)。線性迴歸模型的前提之一是 <strong>真實殘差</strong> 獨立且方差維持恆定不變。但是<strong>觀測殘差卻無可能做到獨立且方差恆定不變</strong>。</p>
<p>之所以說觀測殘差不是獨立的，可以這樣來理解：假如擬合某個線性迴歸模型，預測變量是二分類的，且其中一個分類只有兩個觀測值，那麼擬合的直線會通過這兩個觀測值的中心點 (均值)，那麼這兩個觀測值的觀測殘差就恰好分佈在迴歸直線的兩側 (相加之和爲零，呈完美負相關)，它們是<strong>相關的</strong>！！！</p>
<p>觀測殘差的方差不可能恆定的理由，可以這樣來理解：同樣假如擬合某個預測變量是二分類的線性迴歸模型，其中一個分類只有一個觀測值，那麼迴歸直線在這個觀測值處的殘差方差是零。</p>
<p>標準化殘差 (standardized residuals) <span class="math inline">\((r_i)\)</span>，被定義爲每個觀測值的殘差和模型估計的殘差標準誤相除獲得的數據。所以符合前提條件的線性模型擬合後，計算的標準化殘差會服從標準正態分佈。從標準正態分佈的知識你也應該知道，<strong><span class="math inline">\(95\%\)</span> 的觀測值的標準化殘差必須分佈在數值 <span class="math inline">\(-2, 2\)</span> 範圍內</strong>。另外一種標準化殘差的方法叫做<strong>內學生化殘差 (studentised residual)</strong>。內學生化殘差是把觀測值的殘差除以每一個觀測值各自的估計標準誤。在 R 裏面可以通過 <code>rstandard()</code> 命令計算迴歸模型每個觀測值的內學生化殘差。<strong>內學生化殘差也是服從標準正態分佈的</strong>。</p>
</div>
<div id="槓桿值-leverage" class="section level3">
<h3><span class="header-section-number">31.6.2</span> 槓桿值 Leverage</h3>
<p>如果一個觀測值的擬合值十分極端，那麼該觀測值本身可能對迴歸模型的參數估計影響很大。這個影響程度大小用槓桿值衡量。簡單線性迴歸時，每個觀測值的槓桿值計算公式爲：</p>
<p><span class="math display" id="eq:lm6-4">\[
\begin{aligned}
l_i = \frac{1}{n} + \frac{x_i-\bar{x}}{SS_{xx}}
\end{aligned}
\tag{31.2}
\]</span></p>
<p>槓桿值的範圍是 <span class="math inline">\(\frac{1}{n}, 1\)</span> 之間。槓杆值方程提示這是一個單調函數，它是評價預測變量本身到該變量均值之間距離的指標。槓桿值越大，該觀測值就有越大的可能性對模型擬合造成影響。如果槓桿值大到等於 <span class="math inline">\(1\)</span>，那麼槓桿效應造成的影響極大，觀測值和擬合值就完全一致。意味着在這個觀測值附近，只有它自己，沒有其他觀測值。</p>
<p>(2018-05-14 嘗試過去試題 2014 Paper 2-Q2 時發現槓杆值的問題，在此繼續增加關於多元現行回歸中槓杆值的性質。)</p>
<p>多元線性迴歸時的槓桿值計算公式和 <a href="#eq:lm5-7">(30.7)</a> 中的帽子矩陣 <span class="math inline">\(\mathbf{P}\)</span> 有關：</p>
<p><span class="math display" id="eq:lm6-5">\[
\begin{aligned}
 &amp; l_i = \mathbf{P}_{ii} \text{ The } i\text{ th diagonal element of } \\
 &amp; \mathbf{X(X^\prime X)^{-1}X^\prime}
\end{aligned}
\tag{31.3}
\]</span></p>
<p>In multiple regression, leverage measures “distance” from the centre of the joint distribution of the predecitor variables, but with distance scaled by the directional degree of dispersion. Notice that the point with largest leverage would not have particularly high leverage in either simple linear regression models including only one of the two (or more) predictor variables. Further this point would not be readily identified in plots of each of the predictor variables against the dependent variable. The value of measures such as the leverage is greatest in complex multiple regression models where it can be difficult to identify points with an atypical (非典型) combination of predictor variables using more simple graphical techniques.</p>
</div>
<div id="庫克距離-cooks-distance" class="section level3">
<h3><span class="header-section-number">31.6.3</span> 庫克距離 Cook’s Distance</h3>
<p>當通過計算觀測值的槓桿值之後，發現具有較大槓桿值的那些觀測點，應該被視爲對模型的穩定性有<strong>“潛在威脅”</strong>。此時就輪到庫克距離的登場。庫克距離可以用來衡量一個觀測值對模型的影響大小 (比較把觀測值移除出模型前後的模型變化)。</p>
<p>對於一個有 <span class="math inline">\(p\)</span> 個預測變量的迴歸模型來說，如果殘差方差的估計值爲 <span class="math inline">\(\hat\sigma^2\)</span>，那麼第 <span class="math inline">\(i\)</span> 個觀測值的庫克距離的計算過程就是把該觀測值移除，重新擬合相同的模型，計算獲得該點做的新的擬合值 <span class="math inline">\(\hat y_{j(i)}\)</span>：</p>
<p><span class="math display" id="eq:lm6-6">\[
\begin{aligned}
D_i = \frac{\sum^n_{j=1}(\hat y_{j(i)} - \hat y_j)^2}{(p+1)\hat\sigma^2}
\end{aligned}
\tag{31.4}
\]</span></p>
<p>可以被證明的是，庫克距離其實是結合標準化殘差值 <span class="math inline">\((r_i)\)</span>，和槓桿值 <span class="math inline">\((l_i)\)</span> 的一個綜合量：</p>
<p><span class="math display" id="eq:lm6-7">\[
\begin{aligned}
D_i &amp; = \frac{\sum^n_{j=1}(\hat y_{j(i)} - \hat y_j)^2}{(p+1)\hat\sigma^2} \\
    &amp; = \frac{r^2_il_i}{(p+1)(1-l_i)}
\end{aligned}
\tag{31.5}
\]</span></p>
<p>所以從庫克距離和標準化殘差，以及槓桿值之間的關係公式 <a href="#eq:lm6-7">(31.5)</a> 也可以看出，當槓桿值大同時標準化殘差值的絕對值也大的觀測值，庫克距離就會很大。用線性迴歸時，把每個觀測值得庫克距離和擬合值作散點圖，或者把槓桿值和標準化殘差作散點圖是常用的判斷異常值的手段。</p>
</div>
</div>
<div id="在統計忍者包裏面對模型診斷作圖" class="section level2">
<h2><span class="header-section-number">31.7</span> 在統計忍者包裏面對模型診斷作圖</h2>
<p>擬合好了一個線性迴歸模型以後，<code>plot(Modelname)</code> 即可看到四個診斷圖 (Section <a href="#diagnosis">26.8.5</a>)。</p>
</div>
</div>
<div id="interaction" class="section level1">
<h1><span class="header-section-number">第 32 章</span> 交互作用 Interactions</h1>
<p>線性迴歸部分目前爲止我們討論過如何用多元迴歸模型來控制 (或調整) 特定的預測變量 <span class="math inline">\((X)\)</span> 之外的變量。多元迴歸的目的之一是爲了估計預測變量和因變量之間的迴歸係數的同時，保持其他 (想要被調整的) 變量不變。如此一來，其實等於是假定了無論其餘的調整變量取值如何，<span class="math inline">\(X,Y\)</span> 之間的迴歸係數<strong>總是相同</strong> (繪製的迴歸線是一組平行線)。本章討論的交互作用，就是探討其中某個變量<strong>改變了 <span class="math inline">\(X,Y\)</span> 之間的關係 (modification effect)</strong> 的情況。放寬了之前強制所有直線都平行的限制，探討兩個變量之間的線性關係是否因爲某個變量而發生了質的改變。這樣的關係，在流行病學中被定義爲 <strong>交互作用 interaction</strong>。</p>
<p>本站會探討如何利用線性迴歸模型分析交互作用，如何理解並解釋統計忍者包輸出的報告結果的意義。具體涉及的例子爲：兩個連續型變量，兩個分類型變量，以及一個連續型，一個分類型變量之間的關係的交互作用。</p>
<div id="兩個預測變量之間的線性模型交互作用" class="section level2">
<h2><span class="header-section-number">32.1</span> 兩個預測變量之間的線性模型交互作用</h2>
<div id="交互作用線性模型的一般表達式" class="section level3">
<h3><span class="header-section-number">32.1.1</span> 交互作用線性模型的一般表達式</h3>
<p>假如準備擬合的模型是一個因變量 <span class="math inline">\(Y\)</span>，兩個預測變量 <span class="math inline">\(X_1, X_2\)</span>。同時模型考慮根據 <span class="math inline">\(X_2\)</span> 的值，<span class="math inline">\(X_1, Y\)</span> 之間關係的迴歸係數可以不相等 (直線的斜率不同，即會出現兩條相交的迴歸直線)。這樣的模型其實只要在原有的兩個預測變量的迴歸線性模型中增加一個新的預測變量，新的預測變量是 <span class="math inline">\(X_1, X_2\)</span> 的乘積即可。很簡單，不是麼？</p>
<p><span class="math display" id="eq:lm7-1">\[
\begin{aligned}
y_i  &amp; = \alpha + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i} + \varepsilon_i \\
\text{Where, } &amp; \varepsilon_i \sim \text{NID}(0,\sigma^2) \\
y_i  &amp; = \text{value of the dependent variable} \\
x_{1i} &amp; = \text{value of the first predictor variable} \\
x_{2i} &amp; = \text{value of the second predictor variable} \\
x_{3i} &amp; = x_{1i} \times x_{2i} \\
\end{aligned}
\tag{32.1}
\]</span></p>
<p>爲什麼增加一個 <span class="math inline">\(X_1\times X_2\)</span> 就能夠分析交互作用呢 (不同直線的斜率)？ 要理解其中的奧妙，我們可以這樣來理解：當像普通的線性迴歸模型那樣調整了 <span class="math inline">\(X_2\)</span> 之後，也就是當 <span class="math inline">\(X_2\)</span> 固定不變時 <span class="math inline">\((X_2=k)\)</span>，迴歸方程 <a href="#eq:lm7-1">(32.1)</a>，就變成了：</p>
<p><span class="math display" id="eq:lm7-2">\[
\begin{equation}
y_i  = (\alpha + \beta_2 k) + (\beta_1 + \beta_3 k)x_{1i} + \varepsilon_i
\end{equation}
\tag{32.2}
\]</span></p>
<p>此時的 <span class="math inline">\(X_1\)</span> 的斜率從 <span class="math inline">\(\beta_1\)</span> 變成了 <span class="math inline">\((\beta_1 + \beta_3 k)\)</span>，截距從 <span class="math inline">\(\alpha\)</span> 變成了 <span class="math inline">\((\alpha + \beta_2 k)\)</span>。</p>
</div>
<div id="interaction-cont-bin" class="section level3">
<h3><span class="header-section-number">32.1.2</span> 連續型變量和二分類變量之間的交互作用</h3>
<p>一個連續型變臉一個二分類變量的交互作用迴歸方程十分容易理解 (利用啞變量建立模型)：</p>
<p><span class="math display" id="eq:lm7-4">\[
\begin{array}{ll}
y_i  = \alpha + \beta_1 x_1i + \varepsilon_i  &amp;   \text{ when } X_2 = 0 \\
y_i  = (\alpha + \beta_2) + (\beta_1+\beta_3)x_{1i} + \varepsilon_i &amp; \text{ when } X_2 =1
\end{array}
\tag{32.3}
\]</span></p>
<p>所以，<span class="math inline">\(X_2\)</span> 取零 或者 取 <span class="math inline">\(1\)</span> 代表了不同的分組，上面的迴歸方程就可以擬合 <span class="math inline">\(Y, X_1\)</span> 在 <span class="math inline">\(X_2\)</span> 的兩組中不同截距，不同斜率的兩條直線。其中各個參數估計，用人話來解釋就是：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\alpha\)</span> 是當 <span class="math inline">\(X_2 = 0\)</span> 時的<strong>截距</strong>；</li>
<li><span class="math inline">\(\alpha + \beta_2\)</span> 是當 <span class="math inline">\(X_2 = 1\)</span> 時的截距，所以 <span class="math inline">\(\beta_2\)</span> 就是二分類預測變量 <span class="math inline">\(X_2\)</span> 的兩組之間<strong>截距的差</strong>；</li>
<li><span class="math inline">\(\beta_1\)</span> 是當 <span class="math inline">\(X_2 = 0\)</span> 時的<strong>斜率</strong>；</li>
<li><span class="math inline">\((\beta_1+\beta_3)\)</span> 是當 <span class="math inline">\(X_2 = 1\)</span> 時的截距，所以 <span class="math inline">\(\beta_3\)</span> 就是二分類預測變量 <span class="math inline">\(X_2\)</span> 的兩組之間<strong>斜率的差</strong>。</li>
</ol>
</div>
<div id="兩個二分類變量之間的交互作用" class="section level3">
<h3><span class="header-section-number">32.1.3</span> 兩個二分類變量之間的交互作用</h3>
<p>當兩個預測變量都是二分類變量時，可以用兩個啞變量來編碼各自的分組，擬合下面的迴歸模型：</p>
<p><span class="math display" id="eq:lm7-5">\[
\begin{array}{lll}
y_i = \alpha + \varepsilon_i   &amp;  \text{ when } X_1 = 0 \&amp; X_2 = 0  &amp; \mu_{00} \\
y_i = \alpha + \beta_1 + \varepsilon_i &amp; \text{ when } X_1 = 1 \&amp; X_2 =0  &amp; \mu_{10} \\
y_i = \alpha + \beta_2 + \varepsilon_i &amp; \text{ when } X_1 = 0 \&amp; X_2 =1  &amp; \mu_{01} \\
y_i = \alpha + \beta_1 + \beta_2+ \beta_3 + \varepsilon_i &amp; \text{ when } X_1 = 1 \&amp; X_2 = 1 &amp; \mu_{11}
\end{array}
\tag{32.4}
\]</span></p>
<p>如果用 <span class="math inline">\(\mu_{ij}\)</span> 表示 <span class="math inline">\(X_1 = i, X_2 = j\)</span> 時的總體均值 (population mean)，那麼模型 <a href="#eq:lm7-5">(32.4)</a> 各個參數估計及其意義爲：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\alpha\)</span> 是當 <span class="math inline">\(X_1 = 0, \&amp; X_2 = 0\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\((\mu_{00})\)</span>；</li>
<li><span class="math inline">\(\alpha+\beta_1\)</span> 是當 <span class="math inline">\(X_1 = 1 \&amp; X_2 = 0\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\(\mu_{10}\)</span>，所以 <span class="math inline">\(\beta_1\)</span> 是 <span class="math inline">\(X_2 = 0\)</span> 時 <span class="math inline">\(X_1\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差，<span class="math inline">\(\mu_{10}-\mu_{00}\)</span>；</li>
<li><span class="math inline">\(\alpha+\beta_2\)</span> 是當 <span class="math inline">\(X_1 = 0 \&amp; X_2 = 1\)</span> 時 <span class="math inline">\(Y\)</span> 的均值估計 <span class="math inline">\(\mu_{01}\)</span>，所以 <span class="math inline">\(\beta_2\)</span> 是 <span class="math inline">\(X_1 = 0\)</span> 時 <span class="math inline">\(X_2\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差，<span class="math inline">\(\mu_{01}-\mu_{00}\)</span>；</li>
<li><span class="math inline">\(\alpha + \beta_1 + \beta_2 + \beta_3\)</span> 是當 <span class="math inline">\(X_1 = 1 \&amp; X_2 = 1\)</span> 時的均值估計 <span class="math inline">\(\mu_{11}\)</span>，所以 <span class="math inline">\(\beta_3\)</span> 是 <span class="math inline">\(X_1 = 1\)</span> 時，<span class="math inline">\(X_2\)</span> 的兩組之間 <span class="math inline">\(Y\)</span> 的均值差 <span class="math inline">\(\mu_{11}-\mu_{10}\)</span> <strong>減去</strong> <span class="math inline">\(X_2 = 0\)</span> 時，<span class="math inline">\(X_1\)</span> 的兩組之間的均值差 <span class="math inline">\(\mu_{01}-\mu_{00}\)</span>：<span class="math inline">\((\mu_{11}-\mu_{10}) - (\mu_{01}-\mu_{00})\)</span>。</li>
</ol>
<p>當 <span class="math inline">\(X_1\)</span> 是連續型變量時，交互作用項的迴歸係數 <span class="math inline">\(\beta_3\)</span> 的幾何意義是兩個迴歸直線斜率的差。但是本例中，兩個預測變量都是二分類變量的情況下，<span class="math inline">\(\beta_3\)</span> 的實際意義就變成了，被 <span class="math inline">\(X_2\)</span> 定義的兩組 <span class="math inline">\(X_1\)</span> 之間因變量差的差，<span class="math inline">\((\mu_{11}-\mu_{10}) - (\mu_{01}-\mu_{00})\)</span>。</p>
</div>
<div id="兩個連續變量之間的交互作用" class="section level3">
<h3><span class="header-section-number">32.1.4</span> 兩個連續變量之間的交互作用</h3>
<p>前面 (Section <a href="#interaction-cont-bin">32.1.2</a>) 已經討論過，一個是連續型變量 <span class="math inline">\(X_1\)</span>，另一個是分類變量時 <span class="math inline">\(X_2\)</span>，線性迴歸的交互作用項迴歸係數的含義是因變量 <span class="math inline">\(Y\)</span> 和連續性變量 <span class="math inline">\(X_1\)</span> 在不同的 <span class="math inline">\(X_2\)</span> 組中的迴歸係數之差(斜率之差)。但是，當兩個預測變量 <span class="math inline">\(X_1, X_2\)</span> 都是連續型變量時，交互作用項的迴歸係數該如何解釋呢？直觀的說，此時的交互作用項迴歸係數應該被理解爲：<strong>預測變量 <span class="math inline">\(X_2\)</span> 每增加一個單位時，<span class="math inline">\(Y, X_1\)</span> 之間關係的迴歸方程的斜率變化</strong>。爲了更好地解釋這個概念，我們沿用前面兒童年齡和身長預測其身高的模型 (Section <a href="#globalsig">30.3.3</a>)，加入年齡和身高的交互作用項結果如下：</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb275-1" title="1">growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)</a>
<a class="sourceLine" id="cb275-2" title="2">growgam1<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">as.factor</span>(growgam1<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb275-3" title="3"></a>
<a class="sourceLine" id="cb275-4" title="4">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>len <span class="op">+</span><span class="st"> </span>age<span class="op">*</span>len, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb275-5" title="5"><span class="co"># or equivalently use lm(wt ~  age*len, data=growgam1)</span></a>
<a class="sourceLine" id="cb275-6" title="6"></a>
<a class="sourceLine" id="cb275-7" title="7"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + len + age * len, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.200 -0.651  0.003  0.522  2.895 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4.51956    1.90918   -2.37   0.0189 *  
## age         -0.28490    0.10496   -2.71   0.0073 ** 
## len          0.18777    0.02681    7.00  4.4e-11 ***
## age:len      0.00340    0.00129    2.64   0.0090 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.94 on 186 degrees of freedom
## Multiple R-squared:  0.753,  Adjusted R-squared:  0.749 
## F-statistic:  189 on 3 and 186 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" title="1"><span class="kw">confint</span>(Model1)</a></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -8.2859887 -0.753130
## age         -0.4919562 -0.077844
## len          0.1348837  0.240657
## age:len      0.0008588  0.005937</code></pre>
<p>這裏的模型中，兒童的身長和年齡相乘的部分構成了一個交互作用項。我們用這個擬合的迴歸方程寫出當兒童年齡爲 12 個月時，身長預測體重的方程：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=12) &amp; = (-4.5196 - 0.2849\times12) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times12)\times\text{Length} \\
                        &amp; = -7.9384 + 0.2286\times \text{Length}
\end{aligned}
\]</span></p>
<p>類似地，年齡 13 個月時， 預測體重的方程是：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=13) &amp; = (-4.5196 - 0.2849\times13) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times13)\times\text{Length} \\
                        &amp; = -8.2233 + 0.2320\times \text{Length}
\end{aligned}
\]</span></p>
<p>年齡 13 個月時， 預測體重的方程是：</p>
<p><span class="math display">\[
\begin{aligned}
E(\text{weight|age}=14) &amp; = (-4.5196 - 0.2849\times14) \\
                        &amp; \;\;\;\;\;\;\;\;+ (0.1878 + 0.0034\times14)\times\text{Length} \\
                        &amp; = -8.5082 + 0.2354\times \text{Length}
\end{aligned}
\]</span></p>
<p>所以你會看到每個給定的兒童年齡時的方程身長預測體重的方程都是線性方程，截距和斜率都在變化。兒童的年齡每增加 <span class="math inline">\(1\)</span> 個月，身長和體重的相關係數增加 <span class="math inline">\(0.0034 \text{kg/cm}\)</span>。除了迴歸係數，其餘的數字都是不能用正常的數據來理解的 (沒有兒童身長 或者 體重會等於零)。如果非要解釋，那麼需要把數據全部中心化 (Section <a href="#centring">27.3.1</a>)。</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb279-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(growgam1<span class="op">$</span>age, <span class="dt">graph=</span><span class="ot">FALSE</span>); epiDisplay<span class="op">::</span><span class="kw">summ</span>(growgam1<span class="op">$</span>len, <span class="dt">graph=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  190  16.979 16      8.337  5      36</code></pre>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  190  76.697 76.05   7.156  60.1   95.5</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" title="1">growgam1<span class="op">$</span>age_c &lt;-<span class="st"> </span>growgam1<span class="op">$</span>age<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb282-2" title="2">growgam1<span class="op">$</span>len_c &lt;-<span class="st"> </span>growgam1<span class="op">$</span>len<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>len)</a>
<a class="sourceLine" id="cb282-3" title="3"></a>
<a class="sourceLine" id="cb282-4" title="4">Model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age_c <span class="op">+</span><span class="st"> </span>len_c <span class="op">+</span><span class="st"> </span>age_c<span class="op">*</span>len_c, <span class="dt">data=</span>growgam1)</a>
<a class="sourceLine" id="cb282-5" title="5"><span class="co"># or equivalently use lm(wt ~  age_c*len_c, data=growgam1)</span></a>
<a class="sourceLine" id="cb282-6" title="6"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age_c + len_c + age_c * len_c, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.200 -0.651  0.003  0.522  2.895 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  9.46978    0.09507   99.60   &lt;2e-16 ***
## age_c       -0.02427    0.01721   -1.41    0.160    
## len_c        0.24547    0.01947   12.61   &lt;2e-16 ***
## age_c:len_c  0.00340    0.00129    2.64    0.009 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.94 on 186 degrees of freedom
## Multiple R-squared:  0.753,  Adjusted R-squared:  0.749 
## F-statistic:  189 on 3 and 186 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" title="1"><span class="kw">confint</span>(Model2)</a></code></pre></div>
<pre><code>##                  2.5 %   97.5 %
## (Intercept)  9.2822177 9.657345
## age_c       -0.0582290 0.009680
## len_c        0.2070560 0.283877
## age_c:len_c  0.0008588 0.005937</code></pre>
<p>你會解釋上面中心化數據以後擬合的迴歸方程的結果，和各個參數估計的意義嗎？</p>

</div>
</div>
</div>



<div id="sample-size" class="section level1">
<h1><span class="header-section-number">第 33 章</span> 樣本量計算問題</h1>
<div id="背景-1" class="section level2">
<h2><span class="header-section-number">33.1</span> 背景</h2>
<p>計劃臨牀實驗的時候，爲了避免偏倚和帶有偏見的結論，應當將注意力放在</p>
<ol style="list-style-type: decimal">
<li>如何將實驗對象隨機分配 (randomisation)</li>
<li>設計對照組 (control group)</li>
<li>合適（且必須）的貫徹盲法 (blinding)</li>
</ol>
<p>另外一個同樣重要的問題是–<strong>“我到底需要多少樣本?”</strong></p>
<p>一項臨牀實驗，應該提供足夠的證據來證明新藥物（新治療方法）是否有效，是否安全。影響一個實驗設計的樣本量的因素可能有如下幾種：</p>
<ol style="list-style-type: decimal">
<li><strong>統計學方案。</strong>
<br> 從統計學上可以推算出，需要多少樣本來獲得一個堅實可信的證據來證明藥物的實際有效性。</li>
<li>經濟上的因素。
<br> 然而實際上可能還有經濟上，時間上，人力物力資源上的現實因素，會制約到底一個實驗能夠收集到多少樣本量。</li>
<li>倫理道德上的因素。
<br> 許多臨牀實驗還必須受制於醫學倫理因素。在倫理上一個實驗到底可以維持多久。或者說，要考慮當實驗中一些受試者的結果不理想，或者是有副作用的時候，我們何時該及時停止該實驗？</li>
<li>實驗本身的可信度。
<br> 如果一個臨牀實驗的規模在設計上就很小，可能它本身的可信度就很低。</li>
</ol>
<p>這裏我們只考慮沒有其他任何因素的影響下，<strong>1. 統計學方案</strong>上該如何計算準確的所需樣本量的大小。</p>
比較下列兩個同樣比較了溶栓酶和安慰劑在預防心肌梗塞患者死亡的臨牀實驗：
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:05-clinical-trials-1">表 33.1: </span>Results from the 1st Australian and ISIS-2 trials for reducing mortality from post-MI
</caption>
<thead>
<tr>
<th style="text-align:left;">
ÖÎ.Ÿ.M
</th>
<th style="text-align:left;">
ÈÜË.Ã.
</th>
<th style="text-align:left;">
X.²Î…
</th>
<th style="text-align:left;">
p.values
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1st Australian
</td>
<td style="text-align:left;">
n=264
</td>
<td style="text-align:left;">
n=253
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
ËÀÍöÈË”µ
</td>
<td style="text-align:left;">
26 (9.8%)
</td>
<td style="text-align:left;">
32 (12.6%)
</td>
<td style="text-align:left;">
p = 0.32
</td>
</tr>
<tr>
<td style="text-align:left;">
ÔuƒrÖ¸˜Ë
</td>
<td style="text-align:left;">
Risk ratio
</td>
<td style="text-align:left;">
0.78 (95% CI: 0.48 to 1.27)
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
ISIS-2
</td>
<td style="text-align:left;">
n=8592
</td>
<td style="text-align:left;">
n=8595
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
ËÀÍöÈË”µ
</td>
<td style="text-align:left;">
791 (9.2%)
</td>
<td style="text-align:left;">
1029 (12.0%)
</td>
<td style="text-align:left;">
p &lt; 0.001
</td>
</tr>
<tr>
<td style="text-align:left;">
ÔuƒrÖ¸˜Ë
</td>
<td style="text-align:left;">
Risk ratio
</td>
<td style="text-align:left;">
0.77 (95% CI: 0.70 to 0.84)
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>這兩個臨牀實驗獲得的治療效果 (treatment effect)，在數字的百分比上幾乎十分接近。然而由於樣本量巨大的差距，可以看到第一個實驗的信賴區間十分的大，使得實驗結果是無意義的。而第二個大樣本的實驗結果就告訴我們，溶栓酶的治療效果是有效降低了心肌梗死患者死亡概率（降低了23%）。第一個實驗收集了近500個病例，卻仍然不能提供確實有效的證據證明溶栓酶的治療效果（提供了強的關聯結果，卻是極弱的證據。strong correlation, but weak evidence) 。</p>
</div>
<div id="決定所需樣本量大小的統計學因素" class="section level2">
<h2><span class="header-section-number">33.2</span> 決定所需樣本量大小的統計學因素</h2>
<ol style="list-style-type: decimal">
<li><p>實驗主要結果的測量/比較方法是什麼？ What is the principal outcome measure of the trial?
<br> 一項臨牀實驗的主要結果，應該是切合該實驗的主要目的的。並且應當能夠客觀評價。(如死亡率的改善，治癒率的提高等等)</p></li>
<li><p>實驗數據準備分析的方案是什麼？ How will the data be analysed to detect a treatment difference?
<br> 實驗結果獲得的數據是連續型的 (血壓，血糖值，BMI)？還是分類的離散變量 (死亡的發生與否，疾病的治癒與否)？統計學上認爲的，治療結果提示有意義的差別時的概率。通常定爲 5%。(p &lt; 0.05)</p></li>
<li><p>對照組的試驗期望結果是怎樣的？ What results are expected in the control group?
<br> 當然我們不可能事先預知實驗對照組可能出現的結果。此處只討論我們的預期結果。大多數情況下，我們可以從已經進行過的類似臨牀試驗報告中獲得，或者是從非臨牀干預型研究（觀察型研究）報告中獲得對照組的期望結果。</p></li>
<li><p>如果實驗藥物在治療上確實有差異，當這個差異最小爲多少時希望能從設計的實驗中被檢測到？ How small a treatment difference, if it exists, is important to detect?
<br> 這一條恐怕是每個臨牀實驗在設計階段最重要，最敏感也是最難做出決定的。如果我們已知這個藥物療效和對照相比差別很大，那麼樣本量不用很大，就足以提供值得信賴的證據。不過臨牀上常常會認爲療效差距不必<strong>非常的</strong>顯著，但是在臨牀意義上也是十分重要的。
<br> 常常在這個問題上會引起衆多討論，因爲醫生和患者可能認爲任何一點差異都是有臨牀意義的。但是如果我們想檢測出較小的差距，會需要非常巨大的樣本量，這將會是十分不切合實際的。<strong>What needs to be decided upon is the smallest clinically relevant difference that would be important to detect if it were true.</strong></p></li>
<li><p>在上面第 4 條被決定了以後，還要確定的是我們需要多大的把握來相信這個被檢測出來的療效差別？ With what degree of certainty is needed to be able to detect the treatment difference in 4?
<br> 在實際臨牀實驗中，結論是從觀察數據中得來的，而不是從我們預想的那個“未知的實驗效果”。觀察獲得的療效差別，可能比預想的大（有效），也很可能比預想的小（無效）。設計較好的臨牀實驗應該有足夠機率觀察到有意義的療效差別，即使觀察得到的結果不如預期的大。當然要增加我們觀察到有意義的療效差別，最簡單的辦法是增加樣本量。這個條件的含義是，當療效真差別真實存在，我們要有足夠大的把握把它通過實驗觀察到。</p></li>
</ol>
</div>
<div id="第一類和第二類錯誤-type-i-and-type-ii-errors" class="section level2">
<h2><span class="header-section-number">33.3</span> 第一類和第二類錯誤 Type I and type II errors</h2>
<p>下面羅列一下我們在進行實驗設計時要用到的概念和相應的標記，注意雖然我們無法知道真正的人羣裏真實參數 (parameter) 的大小，但是我們需要用一些估計 (estimator) 來代替：</p>
<ul>
<li><span class="math inline">\(p_1=\)</span> the <strong>observed percentage</strong> in those on standard treatment <br> 意爲施行標準治療法時觀察到的（治癒/有效）百分比</li>
<li><span class="math inline">\(p_2=\)</span> the <strong>observed percentage</strong> in those on “new” treatment <br> 意爲施行“新療法”時觀察到的（治癒/有效）的百分比</li>
</ul>
<p><span class="math inline">\(\Rightarrow p_1-p_2=\)</span> <strong>observed treatment effect</strong> <br> 意爲可以觀察到的治療效果。</p>
<ul>
<li><span class="math inline">\(\pi_1=\)</span> the <strong>anticipated percentage</strong> in those on standard treatment <br> 意爲施行標準治療法時，我們預期的（治癒/有效）百分比</li>
<li><span class="math inline">\(\pi_2=\)</span> the <strong>anticipated percentage</strong> in those on “new” treatment <br> 意爲施行“新療法”時，我們預期的（治療/有效）百分比</li>
</ul>
<p><span class="math inline">\(\Rightarrow \pi_1-\pi_2=\)</span> is the true difference which has been decided it is important to detect <br> 意爲上面第 4 條中我們設定好的希望通過實驗證實的真實的療效差別。</p>
<p>其餘的數學標記包括：</p>
<ul>
<li><span class="math inline">\(\alpha=\)</span> 有意義的療效差異，在統計學上的水平 (概率水平，通常設定爲 0.05 or 5%)</li>
<li><span class="math inline">\(1-\beta=\)</span> Degree of certainty that a true difference of <span class="math inline">\(\pi_1 - \pi_2\)</span> would be detected. <br> 效能, power。意爲有多大的把握能通過實驗檢測出療效差別。（通常將目標值設定爲 <span class="math inline">\(1-\beta=90\%\)</span>）</li>
</ul>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Table 33.2: Observed trial results compared to the <code>truth</code> of 1) no difference; 2) a true <span class="math inline">\(\pi_1-\pi_2\)</span> diffrence
</caption>
<thead>
<tr>
<th style="border-bottom:hidden">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
真實情況 <br> Truth
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
無差別
</th>
<th style="text-align:center;">
真實差別存在 <span class="math inline">\(\pi_1-\pi_2\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
觀察到不存在有意義差別
</td>
<td style="text-align:center;">
<span class="math inline">\(1−\alpha\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\beta\)</span> <br> Type II error
</td>
</tr>
<tr>
<td style="text-align:center;">
觀察到存在有意義差別
</td>
<td style="text-align:center;">
<span class="math inline">\(\alpha\)</span> <br> Type I error
</td>
<td style="text-align:center;">
<span class="math inline">\(1-\beta\)</span> <br> Power
</td>
</tr>
</tbody>
</table>
<p>考慮上面這個表格，可以很容易想到，一個理想的實驗設計，我們希望這個臨牀實驗獲得的結果儘可能地落在上表中的</p>
<ol style="list-style-type: decimal">
<li>左上角：即如果真實情況是無差別的，實驗結果也應該觀察到不存在有意義的差別。</li>
<li>右下角：即如果真實情況是是存在真實差別 <span class="math inline">\(\pi_1-\pi_2\)</span> 的，試驗結果也應該觀察到有意義的差別。</li>
</ol>
<p>然而，我們在獲得臨牀實驗結果之後常常犯的兩類錯誤，同樣在上面的表格中顯示：</p>
<ul>
<li><strong>Type I error:</strong> A type I error is when a treatment difference is claimed based on a statistically significant observed result when in truth no such difference exists, i.e. a false positive result. <br> 左下角爲<strong>一類錯誤</strong>，即實驗結果觀察到有顯著的療效差異，然而，真實情況是並沒有差異的話，被認爲是假陽性判斷。<span class="math inline">\(\alpha\)</span> 表示一類錯誤發生的概率。</li>
<li><strong>Type II error:</strong> A type II error is when in truth there exists a difference of <span class="math inline">\(\pi_1-\pi_2\)</span> but the observed results fail to reach statistical significance, i.e. a false negative result. <br> 右上角爲<strong>二類錯誤</strong>，即實驗結果觀察到沒有顯著的療效差異，然而，真實情況是有差異的話，被認爲是假陰性判斷。<span class="math inline">\(\beta\)</span> 表示二類錯誤發生的概率。</li>
</ul>
<p>Alternative ways of describing <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are as follows:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> is the risk of a Type I error; <span class="math inline">\(\alpha\)</span> 也被叫做檢驗的顯著水平, significant level。</li>
<li><span class="math inline">\(\beta\)</span> is the risk of a Type II error. <span class="math inline">\(1-\beta\)</span> is termed statistical power. 其中 <span class="math inline">\(1-\beta\)</span> 被叫做檢驗效能。</li>
</ul>
<p><span class="math inline">\(\alpha, 1-\beta\)</span> 的水平需要事先被確定，否則無法進行進一步的樣本量的計算。</p>
</div>
<div id="比較兩組之間的百分比-percentages-or-proportions" class="section level2">
<h2><span class="header-section-number">33.4</span> 比較兩組之間的百分比 (percentages or proportions)</h2>
<div id="樣本量計算公式-使用顯著水平-5-和檢驗效能-90" class="section level3">
<h3><span class="header-section-number">33.4.1</span> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</h3>
<p><span class="math display">\[n=10.5\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]</span></p>
<p>注意：</p>
<ul>
<li>上面的公式後面有 <span class="math inline">\(\times2\)</span> 是因爲前一半公式計算的只是一組（治療或對照組）所需的樣本量。</li>
<li>這裏使用的是百分比。所以當使用比例的時候，要把 <span class="math inline">\(100\)</span> 改成 <span class="math inline">\(1\)</span>。</li>
<li>使用公式計算的所需樣本量，並不是說我們需要的病例數就是計算出來的結果。上面的公式獲得的結果只是對所需樣本量的估算。</li>
</ul>
</div>
<div id="樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下" class="section level3">
<h3><span class="header-section-number">33.4.2</span> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</h3>
<p><span class="math display">\[n=f(\alpha, \beta)\times\frac{[\pi_1\times(100-\pi_1)+\pi_2\times(100-\pi_2)]}{(\pi_1-\pi_2)^2}\times2\]</span></p>
<p>其中， <span class="math inline">\(f(\alpha, \beta)\)</span> 指的是關於檢驗顯著水平 <span class="math inline">\(\alpha\)</span> 和檢驗效能 <span class="math inline">\(\beta\)</span> 的函數。 可以參考下面的表格：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
Table 33.2: Values of <span class="math inline">\(f(\alpha, \beta)\)</span> for different levels of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>
</caption>
<thead>
<tr>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(\alpha\)</span>
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(\beta\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
0.05
</th>
<th style="text-align:center;">
0.1
</th>
<th style="text-align:center;">
0.2
</th>
<th style="text-align:center;">
0.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(<span class="math inline">\(95\%\)</span> power)
</td>
<td style="text-align:center;">
(<span class="math inline">\(90\%\)</span> power)
</td>
<td style="text-align:center;">
(<span class="math inline">\(80\%\)</span> power)
</td>
<td style="text-align:center;">
(<span class="math inline">\(50\%\)</span> power)
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
13.0
</td>
<td style="text-align:center;">
10.5
</td>
<td style="text-align:center;">
7.85
</td>
<td style="text-align:center;">
3.84
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
17.8
</td>
<td style="text-align:center;">
14.9
</td>
<td style="text-align:center;">
11.7
</td>
<td style="text-align:center;">
6.63
</td>
</tr>
</tbody>
</table>
<p>要注意的是，除了上面表格中提供的 <span class="math inline">\(f(\alpha, \beta)\)</span> 數值，可以通過以下公式計算得出：</p>
<p><span class="math display">\[f(\alpha, \beta)=(Z_{1-\frac{\alpha}{2}}+Z_{1-\beta})^2\]</span></p>
<p>例如：</p>
<ul>
<li><span class="math inline">\(\alpha=0.05, \beta=0.1\)</span> 時：<span class="math inline">\(f(\alpha, \beta)=(1.96+1.282)^2=10.5\)</span>;</li>
<li><span class="math inline">\(\alpha=0.05, \beta=0.2\)</span> 時：<span class="math inline">\(f(\alpha, \beta)=(1.96+0.84)^2=7.85\)</span>。</li>
</ul>
</div>
</div>
<div id="比較兩組之間的均值" class="section level2">
<h2><span class="header-section-number">33.5</span> 比較兩組之間的均值</h2>
<p>許多臨牀實驗不光關心患者是否被治癒或者死亡，另外還有許多實驗的主要結果是連續變量：例如，腎功能（腎小球濾過率），或收縮期血壓。然而背後的原理其實還是一樣的。</p>
<div id="樣本量計算公式" class="section level3">
<h3><span class="header-section-number">33.5.1</span> 樣本量計算公式</h3>
<p>然而，另外一個必須考慮的因素：治療組對照組測量結果的標準差 (standard deviation, <span class="math inline">\(sd, \sigma\)</span>)。這裏先考慮兩者標準差相同的情況。標準差的數據通常來自與先行研究的科學文獻，有些（土豪）實驗會先進行預實驗獲得想要的實驗數據–標準差。通常，建議像比較百分比那樣，調整改變一下不同的檢驗顯著水品和檢驗效能，計算多個所需樣本量來互相比較參考。</p>
<p>比較兩組均值時需要用到的數學標記：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mu_1=\)</span> 標準治療法（對照組）的期待平均值；</li>
<li><span class="math inline">\(\mu_2=\)</span> 新治療法（治療組）的期待平均值；</li>
<li><span class="math inline">\(\sigma=\)</span> 兩組的標準差（假設兩組標準差相同）；</li>
<li><span class="math inline">\(\alpha=\)</span> 一類錯誤發生的概率，檢驗顯著水平；</li>
<li><span class="math inline">\(\beta=\)</span> 二類錯誤發生的概率，<span class="math inline">\(1-\beta\)</span> 是檢驗效能。</li>
</ol>
<p>用上面標記表示的公式如下：</p>
<p><span class="math display">\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{(\mu_1-\mu_2)^2}\times2\]</span></p>
<p>可以認爲，上面的公式中 <span class="math inline">\(\mu_1-\mu_2\)</span> ，各組的平均值本身並不重要，兩組之間均值的差是我們關心的。如果用 <span class="math inline">\(\delta\)</span> 表示兩組之間均值差的期待值，那麼公式可以改寫爲：</p>
<p><span class="math display">\[n=f(\alpha, \beta)\times\frac{2\sigma^2}{\delta^2}\times2\]</span></p>
</div>
</div>
<div id="樣本量計算的調整" class="section level2">
<h2><span class="header-section-number">33.6</span> 樣本量計算的調整</h2>
<p>如果我們無法成功隨訪部分患者，那麼這部分人的數據就無法獲得，實驗數據的說服力就會下降。如果我們預估計有 <span class="math inline">\(Q\%\)</span> 的人會失去隨訪，那麼我們可以將之前步驟中計算獲得的數字乘以 <span class="math inline">\(\frac{1}{1-Q\%}\)</span>。</p>
<p>如果實驗設計是我們會在某個時間點允許治療組或對照組中的部分人變更自己的實驗方案（即治療組的參與者改進入對照組，反之亦然）。那麼所需樣本量的計算調整的方法爲：</p>
<ul>
<li>令 <span class="math inline">\(Q_1=\)</span> 第一組中改成第二組治療方案的人數比例；</li>
<li>令 <span class="math inline">\(Q_2=\)</span> 第二組中改成第一組治療方案的人數比例；</li>
<li>將之前步驟中計算獲得的樣本量數字乘以 <span class="math inline">\(\frac{1}{(1-Q_1-Q_2)^2}\)</span>。</li>
</ul>
<p>如果預期參與實驗治療組（而不是對照組）的人中有部分人（比例爲 <span class="math inline">\(Q\)</span>）會中斷實驗進程，那麼調整公式爲：<span class="math inline">\(\frac{1}{(1-Q)^2}\)</span>。</p>
<p>還有的實驗會使用大於 <span class="math inline">\(1:1\)</span> 的比例設計對照組和實驗組的人數。假設這一比例爲 <span class="math inline">\(r:1\)</span> 那麼調整的樣本量數字還要乘以：<span class="math inline">\(\frac{(r+1)^2}{4r}\)</span>。</p>
</div>
</div>
<div id="baseline-adjustment-using-ancova" class="section level1">
<h1><span class="header-section-number">第 34 章</span> Baseline Adjustment using ANCOVA</h1>

</div>



<div id="穩健統計方法入門" class="section level1">
<h1><span class="header-section-number">第 35 章</span> 穩健統計方法入門</h1>
<blockquote>
<dl>
<dt>Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.</dt>
<dd>H.G. Wells
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Robust Statistic Methods lectures were orgainised and taught by Professor <a href="https://iris.ucl.ac.uk/iris/browse/profile?upi=RSILV59">Richard Silverwood</a>.
</div>

</div>
<div id="基於秩次的非參數檢驗" class="section level1">
<h1><span class="header-section-number">第 36 章</span> 基於秩次的非參數檢驗</h1>
<p>基於秩次的統計學方法不像其他參數檢驗那樣需要太多的假設和前提 (比如服從正態分佈或者其它假設)。這類方法其實放棄了數據的部分信息 – 那就是數據之間值的差距。通過給數據排序列，我們僅僅知道數據的排序。所以我們可以下結論說 <span class="math inline">\(A\)</span> 大於 <span class="math inline">\(B\)</span>，或者 <span class="math inline">\(B\)</span> 大於 <span class="math inline">\(C\)</span> (因此 <span class="math inline">\(A\)</span> 也大於 <span class="math inline">\(C\)</span>)，但是他們之間數值的差距被忽略掉了 (所以我們不能比較 <span class="math inline">\(A-B\)</span> 和 <span class="math inline">\(B-C\)</span> 的大小)。</p>
<p>所以，基於秩次的統計學方法完全只依賴數據的大小<strong>排序</strong>，觀察獲得數據的真實大小被忽視了。</p>
<div id="sign-test" class="section level2">
<h2><span class="header-section-number">36.1</span> 符號檢驗 the Sign test</h2>
<p>我們以下列一組空腹血糖測量值的數據爲例：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-1">表 36.1: </span>Fasting Glucose Level (mmol/L)
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
n=24 Diabetics
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
10.3
</td>
<td style="text-align:center;">
8.8
</td>
<td style="text-align:center;">
5.3
</td>
</tr>
<tr>
<td style="text-align:center;">
9.5
</td>
<td style="text-align:center;">
6.7
</td>
<td style="text-align:center;">
6.7
</td>
</tr>
<tr>
<td style="text-align:center;">
12.2
</td>
<td style="text-align:center;">
12.5
</td>
<td style="text-align:center;">
5.2
</td>
</tr>
<tr>
<td style="text-align:center;">
15.1
</td>
<td style="text-align:center;">
4.2
</td>
<td style="text-align:center;">
13.3
</td>
</tr>
<tr>
<td style="text-align:center;">
10.8
</td>
<td style="text-align:center;">
15.3
</td>
<td style="text-align:center;">
7.5
</td>
</tr>
<tr>
<td style="text-align:center;">
19.0
</td>
<td style="text-align:center;">
7.2
</td>
<td style="text-align:center;">
4.9
</td>
</tr>
<tr>
<td style="text-align:center;">
16.1
</td>
<td style="text-align:center;">
9.3
</td>
<td style="text-align:center;">
19.5
</td>
</tr>
<tr>
<td style="text-align:center;">
8.1
</td>
<td style="text-align:center;">
8.6
</td>
<td style="text-align:center;">
11.1
</td>
</tr>
</tbody>
</table>
<p>我們如果想要對這組數據的中位數做出假設檢驗，<span class="math inline">\(H_0: \theta = 10; \text{ v.s. } H_1: \theta\neq10\)</span>。</p>
<p>該選擇哪種檢驗方法來回答這個假設檢驗提出的問題：中位數是否等於 <span class="math inline">\(10\)</span>?</p>
<p>符號檢驗 (the <em>sign test</em>)，可以用來輔助我們對數據的中位數 (median <span class="math inline">\(\theta\)</span>) 作出推斷 (inference)。雖然往下看你會發現嚴格說來這並不算是基於秩次的檢驗方法。使用符號檢驗時我們需要的唯一假設：數據來自連續分佈 (continuous distribution)。</p>
<p>這種類型的檢驗方法常用的假設檢驗如下：</p>
<p><span class="math display">\[
H_0: \theta=\theta_0 \\
H_1: \theta\neq\theta_0
\]</span></p>
<p>其中，<span class="math inline">\(\theta_0\)</span> 就是我們想要檢驗的中位數的大小，在上面的例子中，<span class="math inline">\(\theta_0=10\)</span>。</p>
<p>此時我們用到的檢驗統計量，<span class="math inline">\(X\)</span> 的定義是：樣本數據中比 <span class="math inline">\(\theta_0\)</span> 大的數據個數，和比 <span class="math inline">\(\theta_0\)</span> 小的數據個數，兩個個數中較小的那一個。因爲在零假設的條件下，如果觀察數據的中位數等於 <span class="math inline">\(\theta_0\)</span> 的話，數據中比 <span class="math inline">\(\theta_0\)</span> 大或者小的數據個數應該是相等的。可以用一個二項分佈，概率爲 <span class="math inline">\(0.5\)</span> 的模型來模擬：</p>
<p><span class="math display">\[X\sim Bin(n, 0.5)\]</span></p>
<p>在本例中，觀察數據有 13 個小於 <span class="math inline">\(\theta_0=10\)</span>，有 11 個大於 <span class="math inline">\(\theta_0=10\)</span>。因此 <span class="math inline">\(X=11, n=24\)</span>。假如 <span class="math inline">\(\pi\)</span> 是一個觀察數據大於 <span class="math inline">\(\theta_0\)</span> 的概率的話，在零假設的條件下，<span class="math inline">\(H_0: \pi=0.5\)</span>。檢驗這個假設的雙側概率的計算公式爲：</p>
<p><span class="math display">\[2\times P(X\leqslant x|\pi=0.5)\]</span></p>
<p>在本例中， <span class="math inline">\(X=11\)</span>。如果（像在考試的時候沒有電腦輔助）要用查表的方式判斷 <span class="math inline">\(p\)</span> 值大小。可以先<a href="http://onlinelibrary.wiley.com/doi/10.1002/9780470776124.app1/pdf">下載</a> 一份統計數據的表格。下載好了找到 “Statistical Table 7.1 Critical one- and two-tailed values of x for a Sign test” 在第185頁：(下面只是截圖)</p>
<p><img src="img/Selection_088.png" width="80%" style="display: block; margin: auto;" />
<span class="math display">\[\cdots\cdots\cdots\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-3"></span>
<img src="img/Selection_089.png" alt="Critical Values for a Sign test" width="80%" />
<p class="caption">
圖 36.1: Critical Values for a Sign test
</p>
</div>
<p>找到 <span class="math inline">\(n=24\)</span> 這一行，發現顯著性水平是 <span class="math inline">\(20\%\)</span> 的拒絕域都要小於 <span class="math inline">\(8\)</span>， 所以本例的 <span class="math inline">\(p&gt;20\%\)</span>。</p>
<p>如果你很幸運沒有在考場上，那麼可以找出自己的電腦下載好 <a href="https://www.r-project.org/">R</a> 之後執行下面的命令：</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb286-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pbinom</span>(<span class="dv">11</span>,<span class="dv">24</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.8388</code></pre>
<p>或者可以使用命令 <code>binom.test</code> 來做一個二項分佈的概率檢驗：</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb288-1" title="1"><span class="kw">options</span>(<span class="dt">scipen =</span> <span class="dv">1</span>, <span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># just to show the p values are exactly the same</span></a>
<a class="sourceLine" id="cb288-2" title="2"><span class="kw">binom.test</span>(<span class="dv">11</span>,<span class="dv">24</span>,<span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  11 and 24
## number of successes = 11, number of trials = 24, p-value = 0.83882
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.25553020 0.67179192
## sample estimates:
## probability of success 
##             0.45833333</code></pre>
<p>或者你也可以使用 <a href="https://alanarnholt.github.io/BSDA/"><code>BSDA</code></a> 中的 <code>SIGN.test</code> 命令來進行一場轟轟烈烈的符號檢驗：</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb290-1" title="1"><span class="kw">options</span>(<span class="dt">scipen =</span> <span class="dv">1</span>, <span class="dt">digits =</span> <span class="dv">8</span>)</a>
<a class="sourceLine" id="cb290-2" title="2"><span class="co"># input the data</span></a>
<a class="sourceLine" id="cb290-3" title="3">dt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">10.3</span>,<span class="fl">9.5</span>,<span class="fl">12.2</span>,<span class="fl">15.1</span>,<span class="fl">10.8</span>,<span class="fl">19.0</span>,<span class="fl">16.1</span>, <span class="fl">8.1</span>, <span class="fl">8.8</span>, <span class="fl">6.7</span>,<span class="fl">12.5</span>, <span class="fl">4.2</span>,<span class="fl">15.3</span>, <span class="fl">7.2</span>, <span class="fl">9.3</span>, <span class="fl">8.6</span>, <span class="fl">5.3</span>,<span class="fl">6.7</span> ,<span class="fl">5.2</span>,<span class="fl">13.3</span>, <span class="fl">7.5</span>, <span class="fl">4.9</span>,<span class="fl">19.5</span>,<span class="fl">11.1</span>)</a>
<a class="sourceLine" id="cb290-4" title="4">BSDA<span class="op">::</span><span class="kw">SIGN.test</span>(dt, <span class="dt">md=</span><span class="dv">10</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>## 
##  One-sample Sign-Test
## 
## data:  dt
## s = 11, p-value = 0.83882
## alternative hypothesis: true median is not equal to 10
## 95 percent confidence interval:
##   7.3988241 12.3011759
## sample estimates:
## median of x 
##         9.4 
## 
## Achieved and Interpolated Confidence Intervals: 
## 
##                   Conf.Level L.E.pt  U.E.pt
## Lower Achieved CI     0.9361 7.5000 12.2000
## Interpolated CI       0.9500 7.3988 12.3012
## Upper Achieved CI     0.9773 7.2000 12.5000</code></pre>
<p>“據說”如果你用 <a href="https://www.stata.com/"><code>Stata</code></a> 的話還會給你一個絢麗的表格：</p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-7"></span>
<img src="img/Selection_090.png" alt="The Stata output of a Sign Test" width="80%" />
<p class="caption">
圖 36.2: The Stata output of a Sign Test
</p>
</div>
<p>總而言之無論你用的是哪個方法，查 (水) 表法或是統計武俠包，結果都是一樣的：數據無法提供足夠的證據拒絕零假設，即無證據證明中位數不等於10。</p>
<p>需要注意的是，如果觀察數據中有的值恰好等於 <span class="math inline">\(\theta_0\)</span> 那麼這些觀察數據就會被剔除之後再進行檢驗，相應的樣本量 (<span class="math inline">\(n\)</span>) 也就變小了。如果觀察數據樣本量足夠大，我們可以使用二項分佈的正態分佈近似 (Section <a href="#binomial-normal-approx">8.4</a>) 法計算。近似法計算時記得要進行校正 (Section <a href="#continuity-correction">8.6</a>)：</p>
<p><span class="math display">\[
z=\frac{\frac{x}{n}-\pi}{\sqrt{\pi(1-\pi)/n}}=\frac{\frac{x}{n}-0.5}{\sqrt{0.5(1-0.5)/n}}=\frac{2x}{\sqrt{n}}-\sqrt{n}\\
\text{With the continuity correction, this becomes: }\\
z=\lvert\frac{2x}{\sqrt{n}}-\sqrt{n}\rvert-\frac{1}{\sqrt{n}}
\]</span></p>
<p>在本例中：</p>
<p><span class="math display">\[z=\lvert\frac{2\times11}{\sqrt{24}}-\sqrt{24}\rvert-\frac{1}{\sqrt{24}}=0.204\]</span></p>
<p>標準正態分佈的 <span class="math inline">\(z\)</span> 爲 <span class="math inline">\(0.204\)</span> 時的雙側 <span class="math inline">\(p\)</span> 值爲：</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb292-1" title="1">(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>(<span class="fl">0.204</span>))<span class="op">*</span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 0.8383535</code></pre>
<p>和前面的直接計算法的結果還算是十分接近滴。</p>
<div id="符號檢驗的特點" class="section level3">
<h3><span class="header-section-number">36.1.1</span> 符號檢驗的特點</h3>
<p>符號檢驗十分的穩健 (Robust)，因爲我們除了數據連續性的假設之外沒有其他任何假設。但是穩健檢驗是有代價的。因爲進行符號檢驗的同時意味着我們要放棄一個個數據本身能提供的信息。結果導致這類檢驗敏感度較低，檢驗效能 (Power) 較差，以及獲得的信賴區間也就很寬 (不精確)。</p>
</div>
</div>
<div id="Wilcoxon-signed-rank-test" class="section level2">
<h2><span class="header-section-number">36.2</span> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</h2>
<p>Wilcoxon 符號秩和檢驗也可以用來檢驗一組數據的中位數是否和某個已知數字相等。進行本方法時除了像符號檢驗那樣要假設數據是連續的以外，還要假設數據的分佈是左右對稱的。因此，由於假定了左右對稱的前提，中位數也就等於均數，所以它也可以被用於檢驗均數是否等於某個已知的值。</p>
<p>Wilcoxon 符號秩和檢驗的前提可以被認爲是介於符號檢驗和單一樣本 <span class="math inline">\(t\)</span> 檢驗 (還假設數據來自於正態分佈) 之間的一種檢驗。</p>
<p>當一組隨機觀察數據 <span class="math inline">\(x_1,\cdots,x_n\)</span> 來自於對稱的連續分佈數據。如果它的中位數是 <span class="math inline">\(\theta\)</span>，在零假設：<span class="math inline">\(H_0: \theta=\theta_0\)</span> 的條件下：</p>
<ol style="list-style-type: decimal">
<li>將全部觀察數據一一和 <span class="math inline">\(\theta_0\)</span> 相減，那麼每一個 <span class="math inline">\(d_i=x_i-\theta_0, i=1,2,\cdots,n\)</span> 的正負符號概率是相等的；</li>
<li>任何一個和 <span class="math inline">\(\theta_0\)</span> 相減之後的差 <span class="math inline">\(\lvert d_i \lvert\)</span> ，取正負符號的概率是相等的。</li>
</ol>
<p>這裏我們使用另一個例子來說明 Wilcoxon 檢驗法。下列數據爲，12名女性從平躺姿勢改成直立時心跳次數的變化 (次/分)。</p>
<p><code>-2, -5, 12, 4, 16, 17, 8, 3, 20, 25, 1, 9</code></p>
<p>下面來使用 Wilcoxon 符號秩和檢驗法來檢驗中位數 <span class="math inline">\(\theta=15\)</span>。</p>
<p>首先，先計算每個數據和 <span class="math inline">\(15\)</span> 之間的差值：</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" title="1">data &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">-5</span>, <span class="dv">12</span>, <span class="dv">4</span>, <span class="dv">16</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">1</span>, <span class="dv">9</span>)</a>
<a class="sourceLine" id="cb294-2" title="2">newdata &lt;-<span class="st"> </span>data<span class="dv">-15</span></a>
<a class="sourceLine" id="cb294-3" title="3">newdata</a></code></pre></div>
<pre><code>##  [1] -17 -20  -3 -11   1   2  -7 -12   5  10 -14  -6</code></pre>
<p>下一步，計算這些差值的絕對值：</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb296-1" title="1">abs_newdata &lt;-<span class="st"> </span><span class="kw">abs</span>(newdata)</a>
<a class="sourceLine" id="cb296-2" title="2">abs_newdata</a></code></pre></div>
<pre><code>##  [1] 17 20  3 11  1  2  7 12  5 10 14  6</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb298-1" title="1">Dt &lt;-<span class="st"> </span><span class="kw">data.frame</span>(data, newdata, abs_newdata)</a>
<a class="sourceLine" id="cb298-2" title="2">Dt &lt;-<span class="st"> </span>Dt[<span class="kw">order</span>(newdata), ] <span class="co"># sort the data by newdata</span></a>
<a class="sourceLine" id="cb298-3" title="3">Dt</a></code></pre></div>
<pre><code>##    data newdata abs_newdata
## 2    -5     -20          20
## 1    -2     -17          17
## 11    1     -14          14
## 8     3     -12          12
## 4     4     -11          11
## 7     8      -7           7
## 12    9      -6           6
## 3    12      -3           3
## 5    16       1           1
## 6    17       2           2
## 9    20       5           5
## 10   25      10          10</code></pre>
<p>之後，給絕對值排序：</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" title="1">Dt<span class="op">$</span>ranks &lt;-<span class="st"> </span><span class="kw">rank</span>(Dt<span class="op">$</span>abs_newdata)</a>
<a class="sourceLine" id="cb300-2" title="2">Dt</a></code></pre></div>
<pre><code>##    data newdata abs_newdata ranks
## 2    -5     -20          20    12
## 1    -2     -17          17    11
## 11    1     -14          14    10
## 8     3     -12          12     9
## 4     4     -11          11     8
## 7     8      -7           7     6
## 12    9      -6           6     5
## 3    12      -3           3     3
## 5    16       1           1     1
## 6    17       2           2     2
## 9    20       5           5     4
## 10   25      10          10     7</code></pre>
<p>接下來，給小於 <span class="math inline">\(15\)</span> 的數據的排序加上負號：</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" title="1">Dt<span class="op">$</span>signed_ranks &lt;-<span class="st"> </span><span class="kw">ifelse</span>(Dt<span class="op">$</span>newdata <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>, Dt<span class="op">$</span>ranks<span class="op">*</span>(<span class="op">-</span><span class="dv">1</span>), Dt<span class="op">$</span>ranks)</a>
<a class="sourceLine" id="cb302-2" title="2">Dt &lt;-<span class="st"> </span>Dt[<span class="kw">order</span>(Dt<span class="op">$</span>ranks),]</a>
<a class="sourceLine" id="cb302-3" title="3">Dt</a></code></pre></div>
<pre><code>##    data newdata abs_newdata ranks signed_ranks
## 5    16       1           1     1            1
## 6    17       2           2     2            2
## 3    12      -3           3     3           -3
## 9    20       5           5     4            4
## 12    9      -6           6     5           -5
## 7     8      -7           7     6           -6
## 10   25      10          10     7            7
## 4     4     -11          11     8           -8
## 8     3     -12          12     9           -9
## 11    1     -14          14    10          -10
## 1    -2     -17          17    11          -11
## 2    -5     -20          20    12          -12</code></pre>
<p>對正的負的 <code>signed_ranks</code> 分別求和，絕對值較小的那個就是 Wilcoxon 檢驗的統計量。本例中：<span class="math inline">\(S^+=\)</span> 14，<span class="math inline">\(S^-=\)</span> -64，所以本例中的檢驗統計量等於 <span class="math inline">\(14\)</span>。如果要繼續查表的話，可以找到 <span class="math inline">\(0.05&lt;p&lt;0.1\)</span>：</p>
<p><img src="img/Selection_091.png" width="80%" style="display: block; margin: auto;" />
<span class="math display">\[\cdots\cdots\cdots\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-14"></span>
<img src="img/Selection_092.png" alt="Critical Values for a Wilcoxon Signed-Ranks test" width="80%" />
<p class="caption">
圖 36.3: Critical Values for a Wilcoxon Signed-Ranks test
</p>
</div>
<p>精確的 Wilcoxon 符號秩和檢驗可以通過下列代碼在 <a href="https://www.r-project.org/">R</a> 裏完成：</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" title="1"><span class="kw">wilcox.test</span>(Dt<span class="op">$</span>data, <span class="dt">mu=</span><span class="dv">15</span>, <span class="dt">paired =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  Dt$data
## V = 14, p-value = 0.052246
## alternative hypothesis: true location is not equal to 15</code></pre>
<p>如果數據中有觀察值和我們希望比較的數值完全相等的話，和符號檢驗類似的，這些觀察值需要被剔除之後再進行上面的個步驟檢驗。記得還要將樣本量減去相應個數再去查表尋找 <span class="math inline">\(p\)</span> 值。</p>
<p>另外，下面的代碼可以計算正態分佈近似的 Wilcoxon 秩和檢驗，結果十分接近：</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" title="1"><span class="kw">wilcox.test</span>(Dt<span class="op">$</span>data, <span class="dt">mu=</span><span class="dv">15</span>, <span class="dt">paired =</span> <span class="ot">FALSE</span>, <span class="dt">exact =</span> <span class="ot">FALSE</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  Dt$data
## V = 14, p-value = 0.04986
## alternative hypothesis: true location is not equal to 15</code></pre>
<p>值得注意的是，精確計算時，我們需要剔除那些和比較數值完全一致的觀察值。然而在正態分佈近似法的 Wilcoxon 檢驗中，這些數值並不會被剔除，而是保留下來，並且用於對方差進行調整。Wilcoxon 秩和檢驗可以在我們能夠假設數據左右對稱分佈，且明顯不服從正態分佈時使用 (即概率密度分布圖左右兩端的尾部較厚的時候)。如果數據左右完全對稱，本檢驗方法不太推薦採用。</p>
</div>
<div id="wilcoxon-mann-whitney-wmw-檢驗" class="section level2">
<h2><span class="header-section-number">36.3</span> Wilcoxon-Mann-Whitney (WMW) 檢驗</h2>
<p>本方法用於比較兩組獨立樣本的分佈是否只是<strong>左右位移 (或者叫平移)</strong>。此檢驗需要的假設前提爲：兩組獨立樣本來自連續型分佈，且僅僅只存在整體的<strong>左右位移 (或者叫平移)</strong> (location shift)。</p>
<p>例如說，兩組數據各自的累積概率方程分別是 <span class="math inline">\(F(\cdot), G(\cdot)\)</span> 時，由上面的假設可知：</p>
<p><span class="math display">\[G(y)=F(y-\Delta), \text{ where } -\infty&lt;\Delta&lt;\infty\]</span></p>
<p>上面式子中的 <span class="math inline">\(\Delta\)</span> 就是所謂的 <strong>“左右位移 (或者叫平移)”</strong>。因此本檢驗的零假設和替代假設爲：</p>
<p><span class="math display">\[H_0: \Delta=0\\
  H_1: \Delta\neq0\]</span></p>
<p>在零假設的條件下，我們可以認爲兩個樣本來自相同的人羣分佈。假如，<span class="math inline">\(F, G\)</span> 都是正態分佈，且同方差。那麼 <span class="math inline">\(\Delta\)</span> 就等於兩個分佈的均值差。在這種情況下就可以使用兩樣本 <span class="math inline">\(t\)</span> 檢驗。所以說，WMW 檢驗其實就是把假設前提放寬了的 (免去了正態分佈假設) 兩樣本 <span class="math inline">\(t\)</span> 檢驗。</p>
<p>如果兩個獨立樣本分別有樣本量 <span class="math inline">\(n, m, \text{ and } n&lt;m\)</span>：<span class="math inline">\(X_1,\cdots,X_n\)</span> 和 <span class="math inline">\(Y_1, \cdots, Y_m\)</span>。在零假設的條件下，將這兩個樣本合併之後的大樣本 (<span class="math inline">\(m+n\)</span> 個樣本量) ：<span class="math inline">\(X_1,\cdots,X_n,Y_1, \cdots, Y_m\)</span> 可以視爲來自同一分佈。那麼在合併後的樣本中，我們給每一個元素賦予它們的合併後數據中的排序 (<span class="math inline">\(\text{Rank}_i: i= 1,2,\cdots,n, n+1, \cdots, n+m\)</span>)。那麼我們感興趣的 Wilcoxon 秩和統計量 (Wilcoxon rank sum statistic) <span class="math inline">\(W_1\)</span> 是樣本量較小的那些數字在合併後數據中的排序之和。</p>
<p><span class="math display">\[W_1=\sum_{i=1}^n R_i\]</span></p>
<p>對於大小相同的數據，排序取他們的排序的平均值。</p>
<p>之後再計算 ：</p>
<p><span class="math display">\[U_1=W_1+\frac{n(n+1)}{2}\]</span></p>
<p>最後拿來判斷的檢驗統計量是 <span class="math inline">\(U_1\)</span> 和 <span class="math inline">\(n\times m -U_1\)</span> 兩者中較小的數字。(注：如果我們一開始計算樣本量較多的部分的秩和 <span class="math inline">\(W_2=\sum_{i=1}^m R_i\)</span> 時，將計算的 <span class="math inline">\(U_2=W_2-\frac{m(m+1)}{2}\)</span>，跟 <span class="math inline">\(n\times m - U_2\)</span> 中較小的數字作爲檢驗統計量的話，我們會在數學上獲得完全一樣的檢驗統計量。)</p>
<p>其實兩個統計量 <span class="math inline">\(W, U\)</span> 均可以用來作相同的統計推斷，當然各自的 <span class="math inline">\(p\)</span> 值表格不同。但是 <span class="math inline">\(U\)</span> 有另外一種統計學含義：<span class="math inline">\(U\)</span> 是 <span class="math inline">\(X_i&gt;Y_j\)</span>， 也就是所有的 <span class="math inline">\((X_i, Y_j)\)</span> 配對中 <span class="math inline">\(X_i\)</span> 較大的對的個數。</p>
<p>這裏使用下面的例子來解釋如何操作 WMW 檢驗：
採集16名甲亢兒童的血清甲狀腺素濃度值列表如下，</p>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:400px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-17">表 36.2: </span>Serum thyroxine levels
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; position: sticky; top:0; background-color: #FFFFFF;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
n=16 hypothyroid children
</div>
</th>
</tr>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
thyr
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
group
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
34
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
49
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
58
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
86
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
84
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
96
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
</tbody>
</table>
</div>
<p>這裏我們需要比較輕微症狀組和嚴重症狀組的血清甲狀腺濃度的分佈是否只是左右位移，<span class="math inline">\(H_0: \Delta=0\)</span>。</p>
<p>首先，我們要給兩組合併後的濃度排序：</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" title="1">dt<span class="op">$</span>rank &lt;-<span class="st"> </span><span class="kw">rank</span>(dt<span class="op">$</span>thyr)</a>
<a class="sourceLine" id="cb308-2" title="2">dt &lt;-<span class="st"> </span>dt[<span class="kw">order</span>(dt<span class="op">$</span>rank),]</a>
<a class="sourceLine" id="cb308-3" title="3">dt</a></code></pre></div>
<pre><code>##    thyr                 group rank
## 10    5       Marked symptoms  1.0
## 11    8       Marked symptoms  2.0
## 12   18       Marked symptoms  3.0
## 13   24       Marked symptoms  4.0
## 1    34 Slight or no symptoms  5.0
## 2    45 Slight or no symptoms  6.0
## 3    49 Slight or no symptoms  7.0
## 4    55 Slight or no symptoms  8.0
## 5    58 Slight or no symptoms  9.0
## 6    59 Slight or no symptoms 10.0
## 7    60 Slight or no symptoms 11.5
## 14   60       Marked symptoms 11.5
## 8    62 Slight or no symptoms 13.0
## 15   84       Marked symptoms 14.0
## 9    86 Slight or no symptoms 15.0
## 16   96       Marked symptoms 16.0</code></pre>
<p>Wilcoxon 統計量 <span class="math inline">\(W_1\)</span> 是人數少的組的排序之數值和。本樣本中 7 人有嚴重症狀，9人有輕微或無症狀。所以 <span class="math inline">\(W_1\)</span> 就是嚴重症狀組的秩和：</p>
<p><span class="math display">\[W_1=1+2+3+4+11.5+14+16=51.5\]</span></p>
<p>再計算統計量 <span class="math inline">\(U_1\)</span>：</p>
<p><span class="math display">\[U_1=W_1-\frac{n(n+1)}{2}=51.5-\frac{7\times(7+1)}{2}=23.5\]</span></p>
<p>所以 <span class="math inline">\(n\times m-U_1=7\times9-23.5=39.5\)</span>，顯然這兩個數值中小的 <span class="math inline">\(23.5\)</span> 就是我們尋找的 WMW 統計量。繼續查水錶：</p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-19"></span>
<img src="img/Selection_093.png" alt="Critical Values of U for a Wilcoxon-Mann-Whitney test" width="80%" />
<p class="caption">
圖 36.4: Critical Values of U for a Wilcoxon-Mann-Whitney test
</p>
</div>
<p>可知 <span class="math inline">\(n_1=7, n_2=9\)</span> 時，統計量要低於 <span class="math inline">\(15\)</span> <span class="math inline">\(p\)</span> 值才會小於 <span class="math inline">\(0.1\)</span>。所以數據給出的 <span class="math inline">\(p&gt;0.1\)</span>。</p>
<p>在 <a href="https://www.r-project.org/">R</a> 裏面用下面的代碼進行 WHW 檢驗：</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb310-1" title="1"><span class="kw">wilcox.test</span>(dt<span class="op">$</span>thyr<span class="op">~</span>dt<span class="op">$</span>group, <span class="dt">correct=</span><span class="ot">FALSE</span>) <span class="co"># without continuity correction</span></a></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test
## 
## data:  dt$thyr by dt$group
## W = 23.5, p-value = 0.39675
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb312-1" title="1"><span class="kw">wilcox.test</span>(dt<span class="op">$</span>thyr<span class="op">~</span>dt<span class="op">$</span>group) <span class="co"># with continuity correction i.e. normal appriximation</span></a></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  dt$thyr by dt$group
## W = 23.5, p-value = 0.42692
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="秩相關spearmans-rank-correlation-coefficient" class="section level2">
<h2><span class="header-section-number">36.4</span> 秩相關，Spearman’s Rank Correlation Coefficient</h2>
<p>Spearman 的秩相關 (通常用 <span class="math inline">\(\rho\)</span>)，是一種基於數據排序的相關係數算法。和傳統的 Pearson 相關係數類比，是當數據無法被認定是線性相關時的另一種相關關係檢驗方法。所以秩相關不假定兩組數據之間是線性相關 (linear association)。秩相關只關心一個數據遞增時，另一個數據是否單調遞增。所以可以用於傾向性檢驗。</p>
<p>具體的操作是，在兩組數據中先各自排序，像所有的排序檢驗一樣遇到相同大小的數值將排序取均值。之後使用一般的求相關係數的方法。本法中只用到了數值在各自組中的排序，並沒有使用他們的真實大小。近似法的秩相關計算公式爲：</p>
<p><span class="math display">\[\hat\tau=\frac{\hat\rho}{\sqrt{(1-\hat\rho^2)/(n-2)}}\]</span></p>
<p>在零假設條件下 <span class="math inline">\(H_0: \rho=0\)</span>，上面的近似法秩相關服從 <span class="math inline">\(t_{n-2}\)</span> 分佈。
下面用某血友病患者調查數據獲得的血液 <span class="math inline">\(T_4, T_8\)</span> 淋巴球計數 <span class="math inline">\((\times10^9/\ell)\)</span> 來詳細解釋計算過程：</p>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:400px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-21">表 36.3: </span>Lymphocyte counts
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; position: sticky; top:0; background-color: #FFFFFF;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
n=28 haemophiliacs
</div>
</th>
</tr>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
th4
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
th8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.17
</td>
</tr>
<tr>
<td style="text-align:center;">
0.27
</td>
<td style="text-align:center;">
0.52
</td>
</tr>
<tr>
<td style="text-align:center;">
0.28
</td>
<td style="text-align:center;">
0.25
</td>
</tr>
<tr>
<td style="text-align:center;">
0.37
</td>
<td style="text-align:center;">
0.34
</td>
</tr>
<tr>
<td style="text-align:center;">
0.38
</td>
<td style="text-align:center;">
0.14
</td>
</tr>
<tr>
<td style="text-align:center;">
0.48
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.49
</td>
<td style="text-align:center;">
0.58
</td>
</tr>
<tr>
<td style="text-align:center;">
0.56
</td>
<td style="text-align:center;">
0.23
</td>
</tr>
<tr>
<td style="text-align:center;">
0.60
</td>
<td style="text-align:center;">
0.24
</td>
</tr>
<tr>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
0.67
</td>
</tr>
<tr>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
0.90
</td>
</tr>
<tr>
<td style="text-align:center;">
0.66
</td>
<td style="text-align:center;">
0.26
</td>
</tr>
<tr>
<td style="text-align:center;">
0.70
</td>
<td style="text-align:center;">
0.61
</td>
</tr>
<tr>
<td style="text-align:center;">
0.77
</td>
<td style="text-align:center;">
0.18
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.74
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.54
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.76
</td>
</tr>
<tr>
<td style="text-align:center;">
0.90
</td>
<td style="text-align:center;">
0.62
</td>
</tr>
<tr>
<td style="text-align:center;">
1.02
</td>
<td style="text-align:center;">
0.48
</td>
</tr>
<tr>
<td style="text-align:center;">
1.10
</td>
<td style="text-align:center;">
0.58
</td>
</tr>
<tr>
<td style="text-align:center;">
1.10
</td>
<td style="text-align:center;">
0.34
</td>
</tr>
<tr>
<td style="text-align:center;">
1.18
</td>
<td style="text-align:center;">
0.84
</td>
</tr>
<tr>
<td style="text-align:center;">
1.20
</td>
<td style="text-align:center;">
0.63
</td>
</tr>
<tr>
<td style="text-align:center;">
1.30
</td>
<td style="text-align:center;">
0.46
</td>
</tr>
<tr>
<td style="text-align:center;">
1.40
</td>
<td style="text-align:center;">
0.84
</td>
</tr>
<tr>
<td style="text-align:center;">
1.60
</td>
<td style="text-align:center;">
1.20
</td>
</tr>
<tr>
<td style="text-align:center;">
1.64
</td>
<td style="text-align:center;">
0.59
</td>
</tr>
<tr>
<td style="text-align:center;">
2.40
</td>
<td style="text-align:center;">
1.30
</td>
</tr>
</tbody>
</table>
</div>
<p>給這組數據繪製散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-22"></span>
<img src="bookdown_files/figure-html/06-RobustStatistic-22-1.png" alt="Scatter plot of T4 and T8 counts" width="80%" />
<p class="caption">
圖 36.5: Scatter plot of T4 and T8 counts
</p>
</div>
<p>可以看見圖中右上角的兩個點幾乎可以認爲是異常值 (outliers)。
分別給 <code>th4, th8</code> 求各自的排序：</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" title="1">dt<span class="op">$</span>rank4 &lt;-<span class="st"> </span><span class="kw">rank</span>(dt<span class="op">$</span>th4)</a>
<a class="sourceLine" id="cb314-2" title="2">dt<span class="op">$</span>rank8 &lt;-<span class="st"> </span><span class="kw">rank</span>(dt<span class="op">$</span>th8)</a>
<a class="sourceLine" id="cb314-3" title="3"><span class="kw">kable</span>(dt, <span class="st">&quot;html&quot;</span>, <span class="dt">align =</span> <span class="st">&quot;c&quot;</span>,<span class="dt">caption =</span> <span class="st">&quot;Lymphocyte counts&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-4" title="4"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;bordered&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-5" title="5"><span class="co">#  collapse_rows(columns = c(1)) %&gt;%</span></a>
<a class="sourceLine" id="cb314-6" title="6"><span class="st">  </span><span class="kw">add_header_above</span>(<span class="kw">c</span>(<span class="st">&quot;n=28 haemophiliacs with ranks&quot;</span> =<span class="st"> </span><span class="dv">4</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-7" title="7"><span class="st">    </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;400px&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;500px&quot;</span>, <span class="dt">extra_css=</span><span class="st">&quot;margin-left: auto; margin-right: auto;&quot;</span>)</a></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:400px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-23">表 36.4: </span>Lymphocyte counts
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; position: sticky; top:0; background-color: #FFFFFF;" colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
n=28 haemophiliacs with ranks
</div>
</th>
</tr>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
th4
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
th8
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
rank4
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
rank8
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.17
</td>
<td style="text-align:center;">
1.0
</td>
<td style="text-align:center;">
3.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.27
</td>
<td style="text-align:center;">
0.52
</td>
<td style="text-align:center;">
2.0
</td>
<td style="text-align:center;">
13.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.28
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
3.0
</td>
<td style="text-align:center;">
7.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.37
</td>
<td style="text-align:center;">
0.34
</td>
<td style="text-align:center;">
4.0
</td>
<td style="text-align:center;">
9.5
</td>
</tr>
<tr>
<td style="text-align:center;">
0.38
</td>
<td style="text-align:center;">
0.14
</td>
<td style="text-align:center;">
5.0
</td>
<td style="text-align:center;">
2.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.48
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
6.0
</td>
<td style="text-align:center;">
1.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.49
</td>
<td style="text-align:center;">
0.58
</td>
<td style="text-align:center;">
7.0
</td>
<td style="text-align:center;">
15.5
</td>
</tr>
<tr>
<td style="text-align:center;">
0.56
</td>
<td style="text-align:center;">
0.23
</td>
<td style="text-align:center;">
8.0
</td>
<td style="text-align:center;">
5.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.60
</td>
<td style="text-align:center;">
0.24
</td>
<td style="text-align:center;">
9.0
</td>
<td style="text-align:center;">
6.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
0.67
</td>
<td style="text-align:center;">
10.5
</td>
<td style="text-align:center;">
21.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.64
</td>
<td style="text-align:center;">
0.90
</td>
<td style="text-align:center;">
10.5
</td>
<td style="text-align:center;">
26.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.66
</td>
<td style="text-align:center;">
0.26
</td>
<td style="text-align:center;">
12.0
</td>
<td style="text-align:center;">
8.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.70
</td>
<td style="text-align:center;">
0.61
</td>
<td style="text-align:center;">
13.0
</td>
<td style="text-align:center;">
18.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.77
</td>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
14.0
</td>
<td style="text-align:center;">
4.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.74
</td>
<td style="text-align:center;">
16.0
</td>
<td style="text-align:center;">
22.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.54
</td>
<td style="text-align:center;">
16.0
</td>
<td style="text-align:center;">
14.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.88
</td>
<td style="text-align:center;">
0.76
</td>
<td style="text-align:center;">
16.0
</td>
<td style="text-align:center;">
23.0
</td>
</tr>
<tr>
<td style="text-align:center;">
0.90
</td>
<td style="text-align:center;">
0.62
</td>
<td style="text-align:center;">
18.0
</td>
<td style="text-align:center;">
19.0
</td>
</tr>
<tr>
<td style="text-align:center;">
1.02
</td>
<td style="text-align:center;">
0.48
</td>
<td style="text-align:center;">
19.0
</td>
<td style="text-align:center;">
12.0
</td>
</tr>
<tr>
<td style="text-align:center;">
1.10
</td>
<td style="text-align:center;">
0.58
</td>
<td style="text-align:center;">
20.5
</td>
<td style="text-align:center;">
15.5
</td>
</tr>
<tr>
<td style="text-align:center;">
1.10
</td>
<td style="text-align:center;">
0.34
</td>
<td style="text-align:center;">
20.5
</td>
<td style="text-align:center;">
9.5
</td>
</tr>
<tr>
<td style="text-align:center;">
1.18
</td>
<td style="text-align:center;">
0.84
</td>
<td style="text-align:center;">
22.0
</td>
<td style="text-align:center;">
24.5
</td>
</tr>
<tr>
<td style="text-align:center;">
1.20
</td>
<td style="text-align:center;">
0.63
</td>
<td style="text-align:center;">
23.0
</td>
<td style="text-align:center;">
20.0
</td>
</tr>
<tr>
<td style="text-align:center;">
1.30
</td>
<td style="text-align:center;">
0.46
</td>
<td style="text-align:center;">
24.0
</td>
<td style="text-align:center;">
11.0
</td>
</tr>
<tr>
<td style="text-align:center;">
1.40
</td>
<td style="text-align:center;">
0.84
</td>
<td style="text-align:center;">
25.0
</td>
<td style="text-align:center;">
24.5
</td>
</tr>
<tr>
<td style="text-align:center;">
1.60
</td>
<td style="text-align:center;">
1.20
</td>
<td style="text-align:center;">
26.0
</td>
<td style="text-align:center;">
27.0
</td>
</tr>
<tr>
<td style="text-align:center;">
1.64
</td>
<td style="text-align:center;">
0.59
</td>
<td style="text-align:center;">
27.0
</td>
<td style="text-align:center;">
17.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2.40
</td>
<td style="text-align:center;">
1.30
</td>
<td style="text-align:center;">
28.0
</td>
<td style="text-align:center;">
28.0
</td>
</tr>
</tbody>
</table>
</div>
<p>接下來再給 <code>th4, th8</code> 的排序做散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-24"></span>
<img src="bookdown_files/figure-html/06-RobustStatistic-24-1.png" alt="Scatter plot of T4 and T8 ranks" width="80%" />
<p class="caption">
圖 36.6: Scatter plot of T4 and T8 ranks
</p>
</div>
<p>此時也就沒有了異常值的存在。對二者的排序計算相關係數：</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb315-1" title="1"><span class="kw">cor.test</span>(dt<span class="op">$</span>rank4, dt<span class="op">$</span>rank8)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  dt$rank4 and dt$rank8
## t = 4.11513, df = 26, p-value = 0.00034606
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.33297073 0.81107104
## sample estimates:
##        cor 
## 0.62803129</code></pre>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" title="1"><span class="kw">cor.test</span>(dt<span class="op">$</span>th4, dt<span class="op">$</span>th8)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  dt$th4 and dt$th8
## t = 5.28031, df = 26, p-value = 0.000016061
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.47328797 0.86128090
## sample estimates:
##        cor 
## 0.71934766</code></pre>
<p>秩相關的相關係數爲 <span class="math inline">\(0.628\)</span>。而原始數據的相關係數爲 <span class="math inline">\(0.719\)</span>。</p>
</div>
<div id="基於秩次的非參數檢驗的優缺點" class="section level2">
<h2><span class="header-section-number">36.5</span> 基於秩次的非參數檢驗的優缺點</h2>
<p>優點：</p>
<ul>
<li>可以讓我們拋棄很多 (正態分佈等的) 前提假設，許多真實數據本身並不能滿足這些條件，這些情況下，基於秩次的非參數檢驗能提供更高的統計效能 (power)。</li>
</ul>
<p>缺點：</p>
<ul>
<li>如果數據本身能夠滿足如正態分佈之類的假設，那麼相比較與一般的參數檢驗，基於秩次的非參數檢驗法效能就偏低。</li>
<li>基於秩次的非參數檢驗較難推廣到更加複雜的情況。</li>
<li>這些檢驗法僅僅只能幫助我們進行假設檢驗。但是多數情況下，我們更加希望能使用觀察數據對總體進行點估計 (point estimates) 並且給出信賴區間 (CIs)。通常情況下，基於秩次的非參數檢驗法就很難給出這樣的估計。</li>
</ul>
</div>
</div>
<div id="排列置換法-permutation-procedures" class="section level1">
<h1><span class="header-section-number">第 37 章</span> 排列置換法 Permutation procedures</h1>
<div id="背景介紹-1" class="section level2">
<h2><span class="header-section-number">37.1</span> 背景介紹</h2>
<p>Good<span class="citation">(Good <a href="#ref-good2006permutation" role="doc-biblioref">2006</a>)</span> 曾經提出假設檢驗構建的步驟，這裡引用如下：</p>
<ol style="list-style-type: decimal">
<li>分析問題，確認零假設 (null hypothesis)，和可能的替代假設 (alternative hypothesis)。確認這兩種假設決定以後可能伴隨的錯誤 (The potential risk associated with a decision)；</li>
<li>選擇一個檢驗統計量；</li>
<li>計算數據給出的檢驗統計量；</li>
<li>確定檢驗統計量，在<strong>零假設</strong>時的<strong>樣本分佈</strong>；</li>
<li>用確定好的樣本分佈，以及數據給出的統計量大小，做出決策！</li>
</ol>
<p>本章要介紹的排列置換法 (permutation)，和下一章會介紹的自助重抽法 (bootstrap) ，需要大量的計算機的計算，和較強的電腦性能。這兩種方法有一個共同的特徵，它們都利用手頭獲得的樣本數據輔助生成<strong>樣本分佈</strong>，同時對該數據的分佈或者特質不進行假設。也就是用在上面羅列步驟的第4步。其餘的步驟則與一般的參數假設檢驗完全相同。</p>
</div>
<div id="直接上實例" class="section level2">
<h2><span class="header-section-number">37.2</span> 直接上實例</h2>
<p>之前用過的甲亢數據：</p>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:400px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-26">表 37.1: </span>Serum thyroxine levels
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; position: sticky; top:0; background-color: #FFFFFF;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
n=16 hypothyroid children
</div>
</th>
</tr>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
thyr
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
group
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
34
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
49
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
58
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
86
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
84
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
96
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
</tbody>
</table>
</div>
<p>我們來計算這個數據中不同組的甲狀腺素的平均值，標準差，中位數等特徵描述量；</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(dt<span class="op">$</span>thyr, <span class="dt">by=</span>dt<span class="op">$</span>group, <span class="dt">graph=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## For dt$group = Marked symptoms 
##  obs. mean   median  s.d.   min.   max.  
##  7    42.143 24      37.481 5      96    
## 
## For dt$group = Slight or no symptoms 
##  obs. mean   median  s.d.   min.   max.  
##  9    56.444 58      14.222 34     86</code></pre>
<p>這個例子中我們關心的是，兩組之間的甲狀腺素水平是否相同。所以，我們的檢驗統計量在這裡就可以定義為兩組之間均值差，或者中位數差，我們先考慮用均值時的情況。</p>
<p><span class="math display">\[
T=\bar{Y}_1 - \bar{Y}_2
\]</span>
接下來我們需要這個統計量 <span class="math inline">\(T\)</span> 的樣本分佈，同時我們不對數據進行任何分佈的假設 (數據不被認為是正態分佈或者服從其他任何已知的分佈)。</p>
<p>在排列置換法中，我們利用的原則是，在<strong>零假設的條件</strong>下，所有觀察值的分組可以隨機改變。也就是說，我們認為，零假設時，所有的觀察數據，均來自於一個相同且未知的分佈，每一個觀察值的分組標籤對平均值沒有影響。故，此例中我們可以這樣認為：</p>
<ol style="list-style-type: decimal">
<li>每個人的甲狀腺激素水平相同，不受分組情況影響；</li>
<li>輕微或無症狀組的人如果也在顯著症狀組，他們的甲狀腺激素水平不會改變；</li>
<li>改變任何一個人的組別信息，對均值沒有影響。</li>
</ol>
<p>利用上述原則，檢驗統計量 <span class="math inline">\(T\)</span> 的樣本分佈，就是所有16個人的組別信息的排列組合的情況下，觀察值的均值差異大小。所以，我們可以對16個觀察對象的組別信息隨機分配，計算每一次分組情況下的觀察值均值差，獲得零假設條件下，檢驗統計量的樣本分佈。</p>
<p>這裡使用 R 進行組別的隨機分配：</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" title="1"><span class="co">#用 -sample- 對組別信息重新隨機排列</span></a>
<a class="sourceLine" id="cb321-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb321-3" title="3">g1 &lt;-<span class="st"> </span><span class="kw">sample</span>(dt<span class="op">$</span>group, <span class="kw">length</span>(dt<span class="op">$</span>group), <span class="ot">FALSE</span>) <span class="co"># FALSE means replace = FALSE</span></a>
<a class="sourceLine" id="cb321-4" title="4">g2 &lt;-<span class="st"> </span><span class="kw">sample</span>(dt<span class="op">$</span>group, <span class="kw">length</span>(dt<span class="op">$</span>group), <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb321-5" title="5">g3 &lt;-<span class="st"> </span><span class="kw">sample</span>(dt<span class="op">$</span>group, <span class="kw">length</span>(dt<span class="op">$</span>group), <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb321-6" title="6">g4 &lt;-<span class="st"> </span><span class="kw">sample</span>(dt<span class="op">$</span>group, <span class="kw">length</span>(dt<span class="op">$</span>group), <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb321-7" title="7">g5 &lt;-<span class="st"> </span><span class="kw">sample</span>(dt<span class="op">$</span>group, <span class="kw">length</span>(dt<span class="op">$</span>group), <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb321-8" title="8">dt &lt;-<span class="st"> </span><span class="kw">cbind</span>(dt, g1, g2, g3, g4, g5)</a>
<a class="sourceLine" id="cb321-9" title="9"><span class="kw">kable</span>(dt, <span class="st">&quot;html&quot;</span>, <span class="dt">align =</span> <span class="st">&quot;c&quot;</span>,<span class="dt">caption =</span> <span class="st">&quot;Serum thyroxine levels with permuted groups&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb321-10" title="10"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;bordered&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb321-11" title="11"><span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;780px&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;500px&quot;</span>, <span class="dt">extra_css=</span><span class="st">&quot;margin-left: auto; margin-right: auto;&quot;</span>)</a></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:780px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:06-RobustStatistic-28">表 37.2: </span>Serum thyroxine levels with permuted groups
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
thyr
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
group
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
g1
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
g2
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
g3
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
g4
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
g5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
34
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
49
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
58
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
86
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
84
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
<tr>
<td style="text-align:center;">
96
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Marked symptoms
</td>
<td style="text-align:center;">
Slight or no symptoms
</td>
</tr>
</tbody>
</table>
</div>
<p>接下來我們就可以計算當觀察對象的組別信息不同時，檢驗統計量 <span class="math inline">\(T\)</span> 的分佈：</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>group<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>group<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] 14.301587</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g1<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g1<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] 12.777778</code></pre>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g2<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g2<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] -2.968254</code></pre>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb328-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g3<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g3<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] -0.93650794</code></pre>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g4<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g4<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] -0.17460317</code></pre>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" title="1"><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g5<span class="op">==</span><span class="st">&quot;Slight or no symptoms&quot;</span>]) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dt<span class="op">$</span>thyr[dt<span class="op">$</span>g5<span class="op">==</span><span class="st">&quot;Marked symptoms&quot;</span>])</a></code></pre></div>
<pre><code>## [1] -2.2063492</code></pre>
<p>所以理論上，我們可以把16人中任意7人陪分配到“輕微或無症狀”組的所有排列組合窮舉出來 (有 <span class="math inline">\(\binom{16}{7} = 11,440\)</span> 不同的分組法)，計算出所有情況下的均值差，組成我們感興趣的統計量的樣本分佈。所以你會看到，當我們的樣本量只有16個人的時候，兩組分配已經達到上萬種之多，樣本量增加之後，計算量是成幾何級倍數在增加的。例如20人中兩組各10人的分組種類有：<span class="math inline">\(\binom{20}{10} = 184,756\)</span> 種，30人中兩組個15人的分組種類有：<span class="math inline">\(\binom{30}{15} = 1.55\times10^8\)</span> 種之多。所以實際情況下，我們通常的解決辦法是，隨機從所有可能的分組法中抽出足夠多的配列組合。下面以這個甲狀腺數據為例，我們對11,440種可能的排列組合隨機抽出10000種排列計算這10000個不同的均值差：</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb334-1" title="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb334-2" title="2">dist &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">10000</span>, <span class="kw">t.test</span>(<span class="kw">sample</span>(dt<span class="op">$</span>thyr, <span class="kw">length</span>(dt<span class="op">$</span>thyr), <span class="ot">FALSE</span>) <span class="op">~</span><span class="st"> </span>dt<span class="op">$</span>group, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)<span class="op">$</span>statistic)</a></code></pre></div>
<p>上面的代碼的涵義是從樣本對觀察值進行10000次排列組合，對每個組合進行 <span class="math inline">\(t\)</span> 檢驗，獲取 <span class="math inline">\(t\)</span> 檢驗的統計量。下面把觀察值原本的統計量的位置標記在所有10000次組合給出的統計量的柱狀圖中。</p>
<div class="figure" style="text-align: center"><span id="fig:06-RobustStatistic-31"></span>
<img src="bookdown_files/figure-html/06-RobustStatistic-31-1.png" alt="The sampling distribution of the difference" width="70%" />
<p class="caption">
圖 37.1: The sampling distribution of the difference
</p>
</div>
<p>可以看出來，觀察值的統計量在這10000個新樣本中，並不那麼“極端”。觀察數據的排列置換法 <span class="math inline">\(p\)</span> 值為：</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb335-1" title="1"><span class="co">#Use the distribution to obtain a p-value for the mean-difference by counting how many permuted mean-differences are more extreme than the one we observed in our actual data:</span></a>
<a class="sourceLine" id="cb335-2" title="2"><span class="kw">sum</span>(<span class="kw">abs</span>(dist) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(<span class="kw">t.test</span>(dt<span class="op">$</span>thyr <span class="op">~</span><span class="st"> </span>dt<span class="op">$</span>group, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)<span class="op">$</span>statistic))<span class="op">/</span><span class="dv">10000</span></a></code></pre></div>
<pre><code>## [1] 0.3072</code></pre>
<p>跟下面用參數檢驗法的 <span class="math inline">\(p\)</span> 值結果做一下對比，就會發現，其實二者的 <span class="math inline">\(p\)</span> 值結果十分接近。</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" title="1"><span class="kw">t.test</span>(dt<span class="op">$</span>thyr <span class="op">~</span><span class="st"> </span>dt<span class="op">$</span>group, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  dt$thyr by dt$group
## t = -1.05935, df = 14, p-value = 0.30738
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -43.256997  14.653823
## sample estimates:
##       mean in group Marked symptoms mean in group Slight or no symptoms 
##                           42.142857                           56.444444</code></pre>
</div>
<div id="排列置換法三板斧" class="section level2">
<h2><span class="header-section-number">37.3</span> 排列置換法三板斧</h2>
<p>標題黨會不服，其實排列置換法的步驟不止三步 (笑)。</p>
<ol style="list-style-type: decimal">
<li>在零假設的前提下，確認觀察數據所屬的組別，是可以任意對調的。(exchangeability) 有時候我們可能對數據進行一些轉換 (transforming)，以滿足這個要求。</li>
<li>確認檢驗統計量 <span class="math inline">\(T\)</span>，用 <span class="math inline">\(T_{NULL}\)</span> 標記。並且確定零假設時，檢驗統計量的期待值。(通常會用 <span class="math inline">\(T_{NULL}=0\)</span>)</li>
<li>計算觀察數據獲得的統計量 <span class="math inline">\(T_0\)</span>。</li>
<li>對觀察對象的組別進行 <span class="math inline">\(N\)</span> 次隨機排列組合。計算每次排列組合情況下的統計量 <span class="math inline">\((T_1, T_2, \cdots, T_N)\)</span>。</li>
<li>計算 <span class="math inline">\((T_1, T_2, \cdots, T_N)\)</span> 中比 <span class="math inline">\(T_0\)</span> 更極端的值所佔的比例 (<span class="math inline">\(&gt;|T_0|\)</span>)，作為觀察值 <span class="math inline">\(T_0\)</span> 的雙側 <span class="math inline">\(p\)</span> 值。</li>
</ol>
<div id="該如何選用合適的檢驗統計量-t" class="section level3">
<h3><span class="header-section-number">37.3.1</span> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</h3>
<p>在排列置換法中選用合適的檢驗統計量是一個需要仔細思考的過程。選用的 <span class="math inline">\(T\)</span> 必須要能反映組間的差異，並且要與話題相關。也希望能夠盡量和另假設時的統計量有一定的距離<span class="math inline">\(T_{NULL}\)</span>。然而，選擇了不同的檢驗統計量並不意味著統計結果會有天差地別。最終常常是殊途同歸。另外，檢驗統計量並不一定要是一般參數檢驗時用到的統計量 (<span class="math inline">\(t\)</span> 或者其他的似然比檢驗)，因為我們不需要對統計量的精確度 (標準差標準誤等統統不要) 作判斷，本法的統計學推斷是通過排列置換的過程實現的。</p>
</div>
<div id="可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎" class="section level3">
<h3><span class="header-section-number">37.3.2</span> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</h3>
<p>用隨機對照試驗做例子。假如在實驗開始前的某個測量變量需要作為共變量被調整 (也就是要用 ANCOVA)，以獲得調整後的 <span class="math inline">\(Y\)</span> 差異。在零假設條件下，<span class="math inline">\(Y_i\)</span> 就不滿足可置換原則 (exchangeable)，因為那個需要被調整的測量變量可能決定了他們之間組別是有差異的。</p>
<p>此時，零假設條件 (沒有組間差異) 下，滿足可置換原則的其實是不考慮組別的情況下對需要校正的變量<strong>進行線性回歸後獲得的殘差</strong> <span class="math inline">\(R_i\)</span>：</p>
<p><span class="math display">\[
R_i = Y_i - \hat{Y}_i = Y_i - \hat\alpha - \hat\beta X_i
\]</span></p>
<p>另假設條件下，只有殘差 <span class="math inline">\(R_i\)</span> 才滿足可置換原則，可以用在排列置換法中。當需要調整的變量個數增加時，同樣適用。</p>
</div>
<div id="排列置換法基於秩次的非參數檢驗之間的關係" class="section level3">
<h3><span class="header-section-number">37.3.3</span> 排列置換法，基於秩次的非參數檢驗之間的關係</h3>
<p>如果你注意到，當我們把原始觀察數據排序之後進行的排序檢驗其實就是我們本章介紹的排列置換法。它在前面的秩次非參數檢驗中以特殊的形式展現。Good <span class="citation">(Good <a href="#ref-good2006permutation" role="doc-biblioref">2006</a>)</span> 曾經說的好，“99% of common non-parametric tests are permutation tests in which the observations have been replaced by ranks. The sign is one notable exception.” 所以符號檢驗是非排序檢驗的特例。</p>
</div>
<div id="排列置換檢驗法是一種精確檢驗" class="section level3">
<h3><span class="header-section-number">37.3.4</span> 排列置換檢驗法，是一種精確檢驗</h3>
<p>複合型假設，指的是假設中只提及了所有分佈情況中的一種的例如：</p>
<p><span class="math display">\[\text{The mean of X is equal to } 0\]</span></p>
<p>相反，一個簡單假設，則是對參數分佈進行了詳細描述的假設：</p>
<p><span class="math display">\[X\sim N(0,4)\]</span></p>
<p>所以，對複合型假設進行的統計檢驗法，被稱作精確檢驗法。精確檢驗法的特點是，複合型假設中包含的所有假設發生的概率之和等於該檢驗法的第一類錯誤概率 <span class="math inline">\(\alpha\)</span>。</p>
<p>A test is said to be <em>exact</em> with respect to a compound hypothesis if the probability of making a type I error is exactly <span class="math inline">\(\alpha\)</span> for each and every one of the simple hypotheses that are subsumed within the compound hypothesis.</p>
<p>一個大家都聽說過的精確檢驗的例子就是 Fisher 精確檢驗法 (也是一種排列置換檢驗)。<strong>所有的排列置換檢驗法都是精確檢驗法。</strong></p>
</div>
</div>
<div id="基於排序置換檢驗法計算信賴區間" class="section level2">
<h2><span class="header-section-number">37.4</span> 基於排序置換檢驗法計算信賴區間</h2>
<p>基於排序置換檢驗法的信賴區間計算，是一個有些許繁瑣的過程。我們可以設定多個不同的 <span class="math inline">\(N_{NULL}\)</span> ，但是樣本分佈相同的零假設時的統計量。計算相應的 <span class="math inline">\(p\)</span> 值，95% 信賴區間就是 <span class="math inline">\(p\)</span> 值保持大於等於 <span class="math inline">\(0.05\)</span>的 <span class="math inline">\(N_{NULL}\)</span> 取值範圍。計算量將會是很大的。</p>
<p>用前面的例子來解釋就是，我們可以假設兩組之間甲狀腺素的差異是 <span class="math inline">\(T_{NULL} = 10\)</span>，然後將第二組的觀察值全部加上10 (或者將第一組的觀察值全部減去10)，然後用前面描述的方法來檢驗兩組之間的差是否等於零，獲取 <span class="math inline">\(p\)</span> 值。然後用不同的 <span class="math inline">\(T_{NULL}\)</span> 取值，重複這個過程，直到找到上限和下限的 <span class="math inline">\(T_{NULL}\)</span> 值，他們的檢驗 <span class="math inline">\(p\)</span> 值都是0.05。</p>
</div>
<div id="排序置換法的優缺點" class="section level2">
<h2><span class="header-section-number">37.5</span> 排序置換法的優缺點</h2>
<p>優點：</p>
<ol style="list-style-type: decimal">
<li>數據如果大大偏離了參數檢驗法的假設 (完全不是正態分佈)，本法則十分適用，且結果穩健 Robust；</li>
<li>所有的排序置換法計算的 <span class="math inline">\(p\)</span> 值都是<strong>精確</strong>不需要近似的；</li>
<li>排序置換法十分可靠，結果不會偏離對應的參數檢驗法，但是當你的數據樣本量很小，無法使用參數檢驗進行理想的統計分析時，排序置換法是極佳的選擇。</li>
</ol>
<p>缺點：</p>
<ol style="list-style-type: decimal">
<li>可置換原則必須得到滿足；</li>
<li>消耗極大的運算能力，當數據量大時，計算過程將會很緩慢；(Windows的話可能直接就死機了，笑)</li>
<li>用排序置換法計算信賴區間的過程比檢驗本身還好耗時費力。</li>
</ol>
</div>
</div>
<div id="自助重抽法-the-bootstrap" class="section level1">
<h1><span class="header-section-number">第 38 章</span> 自助重抽法 The bootstrap</h1>
<div id="定義-1" class="section level2">
<h2><span class="header-section-number">38.1</span> 定義</h2>
<p>自助重抽，bootstrap 法是另一種對運算能力有較高要求的非參數檢驗常用手段。</p>
</div>
</div>
<div id="the-sandwich-estimator" class="section level1">
<h1><span class="header-section-number">第 39 章</span> The sandwich estimator</h1>

</div>



<div id="intro-Bayes" class="section level1">
<h1><span class="header-section-number">第 40 章</span> 貝葉斯統計入門</h1>
<blockquote>
<p>A Bayesian statistician is one who, vaguely expecting a horse and catching a glimpse of a donkey, strongly concludes he has seen a mule.</p>
<p>— Guernsey McPearson’s Drug Development Dictionary<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
</blockquote>
<p>本章節之目的：</p>
<ul>
<li>介紹 (啓發) 貝葉斯推斷 Bayesian inference 的基本概念。並且與概率論 frequentist inference 推斷實例作比較。</li>
<li>介紹共軛分佈的概念 conjugate distributions。用單一參數家族 (single parameter family) ，特別是二項分佈的圖形來描述共軛分佈；用方差已知的正態分佈均值來描述共軛分佈。</li>
<li>介紹貝葉斯預測分佈 Bayesian prediction distribution。</li>
</ul>
<p>推薦書目：</p>
<ol style="list-style-type: decimal">
<li><a href="https://books.google.co.jp/books?id=nRgtGZXi2KkC&amp;dq=principles+of+statistical+inference&amp;lr=&amp;source=gbs_navlinks_s">“Principles of Statistical Inference”</a> by D.R. Cox <span class="citation">(Cox <a href="#ref-cox2006principles" role="doc-biblioref">2006</a>)</span></li>
<li><a href="https://books.google.co.jp/books?id=nRgtGZXi2KkC&amp;dq=principles+of+statistical+inference&amp;lr=&amp;source=gbs_navlinks_s">“Bayesian Data Analysis”</a> by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin <span class="citation">(Gelman et al. <a href="#ref-gelman2013bayesian" role="doc-biblioref">2013</a>)</span>, <a href="www.stat.columbia.edu/~gelman/book/">website for the book</a></li>
<li><a href="https://books.google.co.uk/books?id=WV7KVjEQnJMC&amp;printsec=frontcover&amp;dq=Bayesian+biostatistics&amp;hl=zh-CN&amp;sa=X&amp;ved=0ahUKEwjct_3vqcbXAhXFJ8AKHar3BbQQ6AEIJjAA#v=onepage&amp;q=Bayesian%20biostatistics&amp;f=false">“Bayesian Biostatistics”</a> by Vehtari and Rubin <span class="citation">(Lesaffre and Lawson <a href="#ref-lesaffre2012bayesian" role="doc-biblioref">2012</a>)</span></li>
</ol>
<p>貝葉斯統計推斷，提供了不同於概率論推斷的另一種考察和解決問題的思路。所有的思考，都源於貝葉斯定理 Bayes’ Theorem (Section <a href="#Bayes-Definition">2</a>)。起源於英國統計學家<a href="https://en.wikipedia.org/wiki/Thomas_Bayes">托馬斯貝葉斯 (Thomas Bayes)</a> 死後被好友 <a href="https://en.wikipedia.org/wiki/Richard_Price">Richard Price</a> 整理發表的論文: <a href="www.stat.ucla.edu/history/essay.pdf">“An essay towards solving a problem in the doctrine of chances.”</a></p>
<p>概率論推斷與貝葉斯推斷的中心都圍繞似然 likelihood (Section <a href="#likelihood-definition">12</a>) 的概念。然而二者對似然提供的信息之理解和解釋完全不同。即在對於觀察數據提供的信息的理解，和如何應用已有信息來影響未來決策（或提供預測）的問題上常常被認爲是統計學中形成鮮明對比的兩種哲學理念。過去幾個世紀二者之間孰優孰劣的爭論相當激烈。但是，從實際應用的角度來看，我們目前更關心哪種思維能更加實用地描述和模擬真實世界。幸運地是，多數情況下，二者的差距不大。所以無法簡單地從一個實驗或者一次爭論中得出誰更出色的結論。現在的統計學家們通常不再如同信仰之爭那樣的互相水火不容，而是從實用性角度來判斷一些實際情況下，採用哪種思想能使計算過程更加簡便或者計算結果更加接近真實情況。</p>
<p>請思考如下的問題：
什麼是概率？ What is probability?</p>
<ol style="list-style-type: decimal">
<li>概率論思想下的定義：某事件在<strong>多次重複觀察</strong>實驗結果中發生次數所佔的比例。<br> The probability of an event is the limit of its relative frequency in a large number of trials."</li>
<li>貝葉斯思想下的定義：概率是你相信某事件會發生的可能性。 <br> Probability is a measure of the degree of belief
about an event.</li>
</ol>
<div id="概率論推斷的複習" class="section level2">
<h2><span class="header-section-number">40.1</span> 概率論推斷的複習</h2>
<p>思考不同場景：</p>
<ul>
<li>場景 A：假如我們在監測一個製造鐵絲的工廠，需要測量該工廠生產的鐵絲的強度。</li>
<li>場景 B：假如我們正在進行一個大型隊列研究，該研究是關於心臟病和與之相關的某個危險因子的評價。數據來源是家庭醫生的診療數據庫。</li>
<li>場景 C：假如一名警察凌晨三點在空無一人的街頭巡邏時，突然聽見防盜自動警鈴的報警聲。他立刻循聲望去，對面街上的珠寶店玻璃碎了一地。一個戴着巴拉克拉瓦頭套的人正揹着一個大包從破碎玻璃窗中爬出。該警察毫不猶豫地判定該人就是劫匪，立刻將其逮捕。</li>
</ul>
<p>在這些場景下，請用概率論思想思考如下幾個問題：</p>
<ol style="list-style-type: decimal">
<li>事件是什麼？</li>
<li>如何解讀總體參數？</li>
<li>如何使用參數進行概率推斷？</li>
<li>用經典概率論時，有什麼缺點嗎？</li>
</ol>
<ul>
<li>場景 A：
<ol style="list-style-type: decimal">
<li>事件：該工廠製造的鐵絲，長期以來的強度大小是多少。</li>
<li>總體參數：鐵絲的真實強度，或者與鐵絲強度相關的特性。</li>
<li>概率推斷：我們進行鐵絲的強度實驗，即從該工廠已經生產的鐵絲中大量抽取樣本逐一進行強度檢測。用相應的概率模型來模擬抽取的樣本數據，並且使用極大似然估計找到最能體現抽樣數據的參數估計，然後對獲得的極大似然估計進行95%信賴區間的計算。然後如果我們重複這樣相同的實驗無數次，那麼我們計算的所有的信賴區間中，有95%包含了真實的鐵絲強度大小。</li>
<li>在鐵絲強度測量的場景中，經典概率論顯得十分自然，因爲我們真的可以重複這樣的實驗很多很多次以獲得想要的參數的精確估計。</li>
</ol></li>
<li>場景 B：
<ol style="list-style-type: decimal">
<li>事件：由於我們用的是整個隊列研究的數據。所以從概率論的角度來看，本事件就是假定我們可以在人數無限多的人羣中重複同樣的隊列研究。</li>
<li>總體參數：我們感興趣的心臟病相關危險因子，在抽取該隊列作爲樣本的人羣中的真實值大小。</li>
<li>概率推斷：我們用泊松分佈的概率模型來模擬人羣中從開始觀察時起，至心臟病發病這段時間內和該危險因子之間的關係大小。然後用傳統的極大似然估計法計算獲得 HR, OR 等值來表示危險因素和心臟病的關係。</li>
<li>缺點：實際情況是，經費時間和人力資源的限制下，我們無法“重複相同的隊列研究”。而且該對列本身可能就是十分獨特的，比如只有男性，或者有年齡限制，或者其他的特性使隊列本身在理論上就是不可能被重複的。所以，在這樣的場景下，用經典的概率論思想作統計推斷常常會被認爲是不自然不妥當的。</li>
</ol></li>
<li>場景 C：
<ol style="list-style-type: decimal">
<li>事件：警察無數次在同樣的時間同樣的地點巡邏時，聽見防盜自動警鈴的報警聲，他看見頭戴巴拉克拉瓦頭套的人從破碎的玻璃窗中爬出……</li>
<li>總體參數：在無數次上面描述的場景時，發生盜竊案的真實概率。</li>
<li>概率推斷：使用某種可以描述該事件（巡邏時。。。發生盜竊案的概率）的數學模型，我們用極大似然估計來計算發生盜竊案概率的估計和95%信賴區間，<strong>然後警察同志再來決定是否要去抓眼前這個頭戴巴拉克拉瓦頭套的人</strong>。</li>
<li>缺點：經典概率論在如此場景下很明顯是完全不適用的。<br>1) 這裏經典概率論思維下的概率實際上無法準確定義，充其量是一種發生盜竊案可能性的估計。<br>2) 在如此場景下，警察會根據已經觀察到的現象（已知信息），來判斷一場盜竊案發生的概率是多少。</li>
</ol></li>
</ul>
<p>通過上面不同場景的下的思考，應該能看到傳統概率論中始終假設我們可以<strong>重複相同的實驗</strong>多次，然後從長遠來估測相關事件發生的概率。許多場景下，即使事件概率能被準確定義，我們是很難知道我們關心的參數的分佈的，從而導致我們常常要用到漸進法估算 (asymptotic approximation)。</p>
</div>
<div id="貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability" class="section level2">
<h2><span class="header-section-number">40.2</span> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</h2>
<p>首先，不得不承認的一個事實是，<strong>所有的概率都是條件概率</strong>。</p>
<ul>
<li>要麼是根據已知的信息。</li>
<li>要麼是一般性大家都接受的某種假設條件。</li>
</ul>
<p>其次，概率，並不是“長遠”地重複觀察獲得的事件發生頻率。相反地，概率的大小取決與<strong>你自己</strong>和<strong>你感興趣的話題（事件）</strong>。思考下列例子：</p>
<ol style="list-style-type: decimal">
<li>明天會下雨嗎？</li>
<li>阿森納下一場比賽會贏還是會輸？</li>
<li>你的期末考試能不能過？</li>
</ol>
<div id="演繹推理-deductive-reasoning-和-三段論-weak-syllogisms" class="section level3">
<h3><span class="header-section-number">40.2.1</span> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</h3>
<p>數學要用到邏輯，假設我們用 <span class="math inline">\(A,B,C\)</span> 標記不同的事件。</p>
<ul>
<li>如果 <span class="math inline">\(A\Rightarrow B\)</span> (事件 A 可以推導出事件 B)</li>
<li>那麼當我們知道“事件 B 爲真”時，雖然B不一定能倒推回 A，但是我們會相信<strong>事件 A 很可能發生了</strong>。</li>
</ul>
<p>例如，A 表示“正在下雨”這件事，B 表示 “天上有烏雲”。那麼從邏輯學上來說，<span class="math inline">\(A\Rightarrow B\)</span> 。然而有烏雲本身不一定會下雨。但是會讓我們覺得下雨的可能性增加了。</p>
<p>再來思考警察巡邏的例子。A 表示 “在珠寶店正在發生盜竊案”，B 表示 “一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”。也是一樣的道理。</p>
<p>所以警察薯熟在做判斷的時候，需要判斷 Pr(A|B)。他需要如下的信息：</p>
<ol style="list-style-type: decimal">
<li>珠寶店發生盜竊案的前提下，有個人從碎玻璃窗中爬出來的概率。</li>
<li>該警察薯熟正處於的環境（半夜三點無人的街頭，等場景）</li>
</ol>
<p>所以，看到這裏是不是覺得貝葉斯使用的是我們的“常識”在思考決斷問題？因爲我們的先驗概率 (prior) 至關重要。這是我們的背景知識和解釋參數似然（推斷）的依據。</p>
</div>
<div id="如何給可能性定量-quantifying-plausibility" class="section level3">
<h3><span class="header-section-number">40.2.2</span> 如何給可能性定量 Quantifying plausibility</h3>
<p>進行可能性定量之前，R.T. Cox 制定了如下的規則<span class="citation">(Cox <a href="#ref-Cox1946" role="doc-biblioref">1946</a>)</span>：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{plausibility}(A)\)</span> 是一個有邊界的實數；</li>
<li>傳遞性，transitivity：如果
<ul>
<li><span class="math inline">\(\text{plaus}(C)&gt;\text{plaus}(B)\)</span> and</li>
<li><span class="math inline">\(\text{plaus}(B)&gt;\text{plaus}(A)\)</span> then</li>
<li><span class="math inline">\(\text{plaus}(C)&gt;\text{plaus}(A)\)</span></li>
</ul></li>
<li>一致性，consistency：事件 <span class="math inline">\(A\)</span> 發生的可能性只取決於所有與 <span class="math inline">\(A\)</span> 直接相關的信息，而不包括那些推理到與 <span class="math inline">\(A\)</span> 相關信息之前的信息。<br> The plausibility of proposition <span class="math inline">\(A\)</span> depends only on the relevant information on <span class="math inline">\(A\)</span> and not on the path of reasoning followed to arrive at <span class="math inline">\(A\)</span>.</li>
</ol>
<p>R.T. Cox 證明了他提出的這些規則可以完全適用於所有的可能性計算，而且可能性 (plausibility) 的這些規則和概率 (probability) 的微積分計算完全一致。</p>
<p>所以利用上面的可能性規則，我們可以對條件概率進行更深層次的定義：</p>
<p><span class="math display">\[\text{Pr}(A|B)=\frac{\text{Pr}(B|A)\text{Pr}(A)}{\text{Pr}(B)}\propto \text{Pr}(B|A)\text{Pr}(A)\]</span></p>
<p>用文字表述爲：</p>
<center>
事後概率 <span class="math inline">\(\propto\)</span> 似然 <span class="math inline">\(\times\)</span> 先驗概率
</center>
<p>其中：</p>
<ul>
<li><strong>事後概率，posterior probability</strong>：<span class="math inline">\(B\)</span> 發生的條件下, <span class="math inline">\(A\)</span> 發生的概率；</li>
<li><span class="math inline">\(\propto\)</span> ：與…成正比；</li>
<li><strong>似然，likelihood</strong>：<span class="math inline">\(A\)</span> 發生的條件下，<span class="math inline">\(B\)</span> 發生的概率；</li>
<li><strong>先驗概率，prior probability</strong>：事件 <span class="math inline">\(A\)</span> 發生的概率。</li>
</ul>
<p>這就是<strong>貝葉斯定理</strong>。這個定理也告訴我們爲什麼貝葉斯論證在18，19世紀時被叫做“逆概率推理, inverse probability reasoning”。因爲似然 (<span class="math inline">\(A\)</span> 發生的條件下，<span class="math inline">\(B\)</span> 發生的概率) 在與先驗概率相乘以後，概率發生了逆轉–事後概率 (<span class="math inline">\(B\)</span> 發生的條件下, <span class="math inline">\(A\)</span> 發生的概率)。</p>
<p>回頭再來看之前的珠寶店盜竊案：</p>
<ul>
<li>事件 <span class="math inline">\(A\)</span>：珠寶店正在發生盜竊案；</li>
<li>事件 <span class="math inline">\(B\)</span>：一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出。</li>
</ul>
<p>所以：</p>
<ul>
<li><span class="math inline">\(\text{Pr}(A)=\)</span> 珠寶店發生盜竊案的概率 – 先驗概率 (prior probability);</li>
<li><span class="math inline">\(\text{Pr}(B|A)=\)</span> 當珠寶店發生盜竊案時，觀察到“一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”事件的可能性 – 似然 (likelihood);</li>
<li><span class="math inline">\(\text{Pr}(A|B)\)</span> 當觀察到“一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”事件時，倒推珠寶店發生了盜竊案的概率 – 事後概率 (posterior probability)。</li>
</ul>
<p>用例子來解釋貝葉斯推理之後你會發現，其實貝葉斯思想也是純粹的概率理論。與經典概率論不同的是，<strong>我們沒有必要認爲某些事件發生的概率需要被重複實驗驗證</strong>。貝葉斯對整個世界的理解源於我們每個人自己認爲的事件發生概率 (personalisitic probability)，或者叫信念度（degree of belief）。</p>
</div>
</div>
<div id="貝葉斯推理的統計學實現" class="section level2">
<h2><span class="header-section-number">40.3</span> 貝葉斯推理的統計學實現</h2>
<p>在經典概率論中，概率分佈的標記 <span class="math inline">\(f_X(x;\theta)\)</span> 的涵義爲：
對於一個隨機變量 <span class="math inline">\(X\)</span>，它在我們假設的某種固定的真實（上帝才知道是多少的）參數 <span class="math inline">\(\theta\)</span> 的分佈框架下，不斷重複相同的實驗之後獲得的概率分佈。</p>
<p>在貝葉斯統計推理中，一切都被看作是一個服從概率分佈的隨機變量。利用貝葉斯定理，我們將先驗隨機概率分佈 (prior probability distribution)，和觀察數據作條件概率 (condition on the observed data)，從而獲得事後概率分佈 (posterior probability distribution)。</p>
<div id="醫學診斷測試-diagnostic-testing" class="section level3">
<h3><span class="header-section-number">40.3.1</span> 醫學診斷測試 diagnostic testing</h3>
<p>貝葉斯推理最常用的實例是在診斷測試中，即當一個人拿着陽性的檢驗報告結果來找你，你如何判斷這個人有多大的概率真的患有該疾病。</p>
<p>用 <span class="math inline">\(D\)</span> 標記患病， <span class="math inline">\(\bar{D}\)</span> 標記不患病；<span class="math inline">\(T\)</span> 標記檢查結果爲陽性，<span class="math inline">\(\bar{T}\)</span> 標記檢查結果爲陰性。那麼，陽性檢查結果時，真的患病的概率 <span class="math inline">\(\text{Pr}(D|T)\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D|T) &amp;= \frac{\text{Pr}(T|D)\text{Pr}(D)}{\text{Pr}(T)}\\
&amp;=\frac{\text{Pr}(T|D)\text{Pr}(D)}{\text{Pr}(T|D)\text{Pr}(D)+\text{Pr}(T|\bar{D})\text{Pr}(\bar{D})}
\end{aligned}
\]</span></p>
<p>其中分母的轉換用到了 Law of Total Probability (L.T.P):</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(T) &amp;= \text{Pr}(T \cap D) + \text{Pr}(T \cap \bar{D}) \\
&amp;= \text{Pr}(T|D)\text{Pr}(D)+\text{Pr}(T|\bar{D})\text{Pr}(\bar{D})
\end{aligned}
\]</span></p>
<p>所以說，貝葉斯定理在這裏告訴我們，要計算 <span class="math inline">\(\text{Pr}(D|T)\)</span> 我們只需要下列幾個信息：</p>
<ol style="list-style-type: decimal">
<li>患病率： <span class="math inline">\(\text{Pr}(D)\)</span></li>
<li>檢測手段的敏感度 (sensitivity)： <span class="math inline">\(\text{Pr}(T|D)\)</span></li>
<li>檢測手段的 1 - 特異度 (specificity)： <span class="math inline">\(\text{Pr}(T|\bar{D})=1-\text{Pr}(\bar{T}|\bar{D})\)</span></li>
</ol>
</div>
<div id="hiv-檢查時的應用" class="section level3">
<h3><span class="header-section-number">40.3.2</span> HIV 檢查時的應用</h3>
<p>假設人羣中患病率爲 <span class="math inline">\(1/1000\)</span>，所用的 HIV 檢測手段的敏感度爲 <span class="math inline">\(0.99\)</span>， 特異度爲 <span class="math inline">\(0.98\)</span>。試計算該檢測HIV手段的事後概率（即拿到陽性結果時，患病的概率 <span class="math inline">\(\text{Pr}(D|T)\)</span>）。</p>
<p><strong>解</strong></p>
<p>令 <span class="math inline">\(D=\text{HIV positive}, \bar{D}=\text{HIV negative}\\ T=\text{test postive}, \bar{T}=\text{test negative}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D|T) &amp;= \frac{\text{Pr}(T|D)\text{Pr}(D)}{\text{Pr}(T|D)\text{Pr}(D)+\text{Pr}(T|\bar{D})\text{Pr}(\bar{D})} \\
&amp;= \frac{0.99\times0.001}{0.99\times0.001+(1-0.98)\times0.999} \\
&amp;= 0.0472
\end{aligned}
\]</span></p>
<p>如果 特異度能達到 <span class="math inline">\(0.99\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D|T) &amp;= \frac{\text{Pr}(T|D)\text{Pr}(D)}{\text{Pr}(T|D)\text{Pr}(D)+\text{Pr}(T|\bar{D})\text{Pr}(\bar{D})} \\
&amp;= \frac{0.99\times0.001}{0.99\times0.001+(1-0.99)\times0.999} \\
&amp;= 0.0901
\end{aligned}
\]</span></p>
<p>如果特異度能達到 <span class="math inline">\(0.999\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D|T) &amp;= \frac{\text{Pr}(T|D)\text{Pr}(D)}{\text{Pr}(T|D)\text{Pr}(D)+\text{Pr}(T|\bar{D})\text{Pr}(\bar{D})} \\
&amp;= \frac{0.99\times0.001}{0.99\times0.001+(1-0.999)\times0.999} \\
&amp;= 0.497
\end{aligned}
\]</span></p>
<p>可見，對於像 HIV 這樣人羣中患病率較爲罕見的疾病，其檢驗手段的敏感度，特異度都要達到極高才能讓檢驗結果可靠，即拿到陽性結果的人的確患有該疾病。其中當敏感度爲 <span class="math inline">\(0.99\)</span>，特異度爲 <span class="math inline">\(0.999\)</span> 時，才能讓這樣的檢驗手段達到接近一半的可靠程度 (即只有接近一半的陽性結果是真陽性)。</p>
<p>注意本例爲貝葉斯理論的特例，即我們使用的是一個固定的先驗概率 (prior) 和似然 (likelihood)。一般情況下，先驗概率和似然會有自己的概率分佈 (probability distribution)，而很少會是一個固定的值， 其相應的事後概率 (posterior) 也擁有概率分佈，並且使用它本身的均值和方差來描述。</p>
</div>
<div id="說點小歷史" class="section level3">
<h3><span class="header-section-number">40.3.3</span> 說點小歷史</h3>
<div class="figure" style="text-align: center"><span id="fig:Bayes00"></span>
<img src="img/Fisher.jpg" alt="Sir Ronald Fisher" width="50%" />
<p class="caption">
圖 40.1: Sir Ronald Fisher
</p>
</div>
<p><a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Ronald Aylmer Fisher (1890-1962)</a> 推動了統計學在20世紀前半頁的重大發展。他鞏固了概率論統計學堅實的基礎，並且積極提倡這一套理論<span class="citation">(Fisher <a href="#ref-Fisher1922" role="doc-biblioref">1922</a>)</span>。但是 Fisher 本人對於統計學的“統計學意義, level of significance” 的認識卻是隨着時間和他年齡的變化而變化的：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 40.1: Fisher’s interpretation of ‘level of significance’ and the Neyman-Pearson interpretation
</caption>
<thead>
<tr>
<th style="text-align:center;">
早期 Fisher (1935)
</th>
<th style="text-align:center;">
晚期 Fisher (1956)
</th>
<th style="text-align:center;">
Neyman and Pearson
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
統計學有意義的水平（傳統上使用 <span class="math inline">\(\alpha=5\%\)</span>），必須在實施統計檢驗之前就被決定。因此，統計學意義的水平是相應統計學檢驗本身的性質之一。<br>
Thus, the level of significance is a property of the <em>test</em>.
</td>
<td style="text-align:left;">
統計學意義的水平，應該被精確計算並且在報告中明確 <span class="math inline">\(p\)</span> 值的大小，故統計學意義的水平本身是在實施了統計檢驗之後計算的。它應該是屬於觀察數據的固有性質。 <br>
Here the level of significance is a property of the <em>data</em>.
</td>
<td style="text-align:left;">
<span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\beta\)</span> 作爲統計檢驗的第一類錯誤和第二類錯誤指標，應該在實施統計檢驗之前被決定。所以 <span class="math inline">\(\alpha, \beta\)</span> 是屬於統計檢驗的性質。<br>
Yet, to determine <span class="math inline">\(\alpha, \beta\)</span> no convention is required, but rather a cost-benefit estimation of the severity of the two kinds of error.
</td>
</tr>
</tbody>
</table>
<p>隨着马尔科夫蒙特卡洛 (Markov-Chain Monte Carlo, MCMC) 法的廣泛應用，貝葉斯統計學在事後概率計算上（計算量超大的）棘手問題，得到了解決。</p>
</div>
</div>
<div id="練習題-5" class="section level2">
<h2><span class="header-section-number">40.4</span> 練習題</h2>
<ol style="list-style-type: decimal">
<li>從經典概率論的角度，準確定義 <span class="math inline">\(95\%\)</span> 信賴區間。思考，在貝葉斯統計理論中，它會如何被定義。</li>
</ol>
<p><strong>解</strong></p>
<p><u>概率論：</u></p>
<p>對於一個總體參數 <span class="math inline">\(\theta\)</span> 來說，<span class="math inline">\(95\%\)</span> 信賴區間是一個從觀察數據中計算得到的數值區間。如果重複相同的實驗無數次，我們從無數個觀察數據中計算這個區間，那麼這些無數多的信賴區間 (confidence interval, CI) 裏有 <span class="math inline">\(95\%\)</span> 包含了總體參數 <span class="math inline">\(\theta\)</span>。</p>
<p><u>貝葉斯：</u></p>
<p>對於一組觀察數據，它可以計算獲得可信區間 (credible interval, CI)。如果使用 <span class="math inline">\(L, U\)</span> 分別表示下限和上限的值，<span class="math inline">\(\theta\)</span> 表示參數，<span class="math inline">\(x\)</span> 表示觀察數據，<span class="math inline">\(\pi(\theta|x)\)</span> 表示事後概率分佈的密度方程， posterior distribution。那麼有：</p>
<p><span class="math display">\[\text{Pr}(\theta \in (L,U)) = \int_L^U\pi(\theta|x)\text{d}\theta = 95\%\]</span></p>
<p><strong>即，在貝葉斯理論下，95% 可信區間就是這一個區間包含了參數的概率是95%。</strong></p>
<ol start="2" style="list-style-type: decimal">
<li><p>證明貝葉斯定理。</p>
<ol style="list-style-type: lower-alpha">
<li><p>並且用二項分佈隨機變量的例子來證明：<br><span class="math inline">\(\text{posterior odds} = \text{prior odds}\times\text{likelihood ratio}\)</span></p></li>
<li><p>用前面提到的 HIV 的案例來說明這個公式的實際應用。</p></li>
</ol></li>
</ol>
<p><strong>解</strong></p>
<p>參照上面的標記法：</p>
<ul>
<li><span class="math inline">\(\theta\)</span> 表示參數</li>
<li><span class="math inline">\(x\)</span> 表示觀察數據</li>
<li><span class="math inline">\(\pi(\theta|x)\)</span> 表示事後概率分佈的密度方程， posterior distribution</li>
<li><span class="math inline">\(f(\theta,x)\)</span> 表示參數和數據的聯合分佈， joint distribution</li>
<li><span class="math inline">\(f(x)\)</span> 表示先驗概率分佈的密度方程， prior distribution</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\pi(\theta|x) &amp;= \frac{f(\theta, x)}{f(x)} \\
&amp;=\frac{f(\theta, x)}{f(x)}\cdot\frac{1/\pi(\theta)}{1/\pi(\theta)} \\
&amp;=\frac{\frac{f(\theta,x)}{\pi(\theta)}}{\frac{f(x)}{\pi(\theta)}}
\end{aligned}
\]</span></p>
<p>其中分子部分 <span class="math inline">\(\frac{f(\theta,x)}{\pi(\theta)}\)</span> 就是條件概率 <span class="math inline">\(f(x|\theta)\)</span>。</p>
<p>分母的 <span class="math inline">\(f(x)\)</span> 部分
<span class="math display">\[
\begin{aligned}
f(x) &amp;= \int f(x,\theta) \text{d}\theta \\
&amp;= \int \frac{f(x,\theta)}{\pi(\theta)} \cdot \pi(\theta) \text{d}\theta \\
&amp;= \int f(x|\theta) \cdot \pi(\theta) \text{d}\theta
\end{aligned}
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[\pi(\theta|x)=\frac{f(x|\theta)\pi(\theta)}{\int f(x|\theta) \cdot \pi(\theta) \text{d}\theta}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>用二項分佈隨機變量 (<span class="math inline">\(\theta=1, 0\)</span>) 來證明：<strong><span class="math inline">\(\text{posterior odds} = \text{prior odds}\times\text{likelihood ratio}\)</span></strong></li>
</ol>
<p><strong>解</strong></p>
<p>假設 <span class="math inline">\(\theta\)</span> 是一個二項分佈的隨機變量，那麼 <span class="math inline">\(f(\theta|x)=\text{Pr}(\theta |x)\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
\text{posterior odds} &amp;= \frac{\text{Pr}(\theta=1|x)}{\text{Pr}(\theta=0|x)}  \\
&amp;= \frac{\frac{\text{Pr}(x|\theta=1)\text{Pr}(\theta=1)}{\text{Pr}(x)}}{\frac{\text{Pr}(x|\theta=0)\text{Pr}(\theta=0)}{\text{Pr}(x)}}\\
&amp;=\frac{\text{Pr}(\theta=1)}{\text{Pr}(\theta=0)}\cdot\frac{\text{Pr}(x|\theta=1)}{\text{Pr}(x|\theta=0)}  \\
&amp;=\text{prior odds}\times\text{likelihood ratio}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>用前面提到的 HIV 案例來驗證：</li>
</ol>
<p>HIV的患病率爲 <span class="math inline">\(1/1000\)</span>，所以 <span class="math inline">\(\text{prior odds}=1:999\)</span>，似然比 <span class="math inline">\(\text{likelihood ratio}=0.99:(1-0.98)\)</span>。所以就有：</p>
<p><span class="math display">\[
\begin{aligned}
\text{posterior odds} &amp;=\text{prior odds}\times\text{likelihood ratio} \\
&amp;= \frac{1}{999}\times\frac{0.99}{1-0.98} \\
&amp;= \frac{0.99}{19.98} \\
&amp;= \frac{1}{20.18182}
\end{aligned}
\]</span></p>
<p>所以事後概率（陽性結果患病的概率）爲 <span class="math inline">\(1/(1+20.18182)=0.0472\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>史密斯先生有2個孩子，其中之一是男孩。另一個孩子是女孩的概率是多少？ 如下前提默認成立：
<ol style="list-style-type: decimal">
<li>男女比例爲: 50-50。</li>
<li>這個家庭中沒有對男孩或者女孩的偏好。</li>
<li>這兩個孩子不是同胞雙胞胎。</li>
</ol></li>
</ol>
<p>一個家庭有兩個孩子的性別組合的所有可能性：</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<table>
<thead>
<tr class="header">
<th align="center">第一個孩子性別</th>
<th align="center">第二個孩子性別</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">男孩</td>
<td align="center">男孩</td>
</tr>
<tr class="even">
<td align="center">男孩</td>
<td align="center">女孩</td>
</tr>
<tr class="odd">
<td align="center">女孩</td>
<td align="center">男孩</td>
</tr>
<tr class="even">
<td align="center">女孩</td>
<td align="center">女孩</td>
</tr>
</tbody>
</table>
</table>
<p>所以根據已知條件，其中之一是男孩，所以最後一種情況：“兩個女孩” 是不可能的。故另一孩子是女孩的概率就是 <span class="math inline">\(\frac{2}{3}\)</span>。</p>
<p>如果用貝葉斯理論來正式計算的話：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text{Pr (1 girl in family of 2 | family does not have 2 girls)} \\
&amp;= \frac{\text{Pr(family doesn&#39;t have 2 girls|1 girl in a family of 2)}\times \\ \text{Pr(1 girl in a family of 2 )}}{\sum_{j=0,1,2}\text{Pr(family doesn&#39;t have 2 girls|j girl in a family of 2)}\times\\\text{Pr(j girl in a family of 2)}} \\
&amp;= \frac{1\times\frac{1}{2}}{1\times\frac{1}{4}+1\times\frac{1}{2}+0\times\frac{1}{4}}  \\
&amp;= \frac{\frac{1}{2}}{\frac{3}{4}}=\frac{2}{3}
\end{aligned}
\]</span></p>
<p>也是一樣的結論。</p>
<ol start="4" style="list-style-type: decimal">
<li>下表是全國普查以後得出的家庭有兩個孩子，<strong>且至少一個是男孩的數據分佈</strong>：</li>
</ol>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<table>
<thead>
<tr class="header">
<th align="center">第一個孩子性別</th>
<th align="center">第二個孩子性別</th>
<th align="center">家庭數量</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">男孩</td>
<td align="center">男孩</td>
<td align="center">657</td>
</tr>
<tr class="even">
<td align="center">男孩</td>
<td align="center">女孩</td>
<td align="center">591</td>
</tr>
<tr class="odd">
<td align="center">女孩</td>
<td align="center">男孩</td>
<td align="center">610</td>
</tr>
<tr class="even">
<td align="center">女孩</td>
<td align="center">女孩</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
</table>
<p>求同樣的概率問題：</p>
<p><strong>解</strong></p>
<p>另一個孩子是女孩的概率是：<span class="math inline">\(\frac{610+591}{610+591+657}=0.646\)</span></p>
</div>
</div>
<div id="貝葉斯定理的應用單一參數模型" class="section level1">
<h1><span class="header-section-number">第 41 章</span> 貝葉斯定理的應用：單一參數模型</h1>
<p>從前一章節我們可以深切體會到，貝葉斯統計是如何讓我們的先驗概率，在觀察到數據之後，更新信息，獲得事後概率 (這是一個通過數據自我學習，進化的過程)。(How a prior belief about an event can be updated, given data, to a posterior belief.)</p>
<p>所以說，在貝葉斯模型中，我們期待使用觀察數據來學習，以增加現有的對相關參數的知識和信息。本章我們把重點放在二項分佈，用二項分佈作爲單一參數模型來瞭解怎樣推導事後分佈。</p>
<div id="貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions" class="section level2">
<h2><span class="header-section-number">41.1</span> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</h2>
<ul>
<li><span class="math inline">\(R\)</span> 用來表示服從一個二項分佈的隨機變量， <span class="math inline">\(R\sim Bin(n, \theta)\)</span>。</li>
<li><span class="math inline">\(r\)</span> 表示觀察到 <span class="math inline">\(r\)</span> 次成功實驗，實驗次數爲 <span class="math inline">\(n\)</span>。</li>
<li>先驗概率分佈： <span class="math inline">\(\pi_\Theta(\theta)\)</span></li>
<li>應用貝葉斯定理：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\pi_{\Theta|R}(\theta|r) &amp;= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{\int_0^1f_R(r|\theta)\pi_\Theta(\theta)\text{ d}\theta}\\
&amp;= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{f_R(r)}
\end{aligned}
\]</span></p>
<p>如果我們的先驗概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
1 \text{ if } \theta=0.2\\
0 \text{ otherwise}
\end{cases}
\end{equation}\]</span></p>
<p>意思就是，我們 100% 相信 <span class="math inline">\(\theta\)</span> 絕對就等於 0.2，不相信 <span class="math inline">\(\theta\)</span> 竟然還能取任何其他值（霸道自大又狂妄的我們）。</p>
<p>如果先驗概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
0.4 \text{ if } \theta=0.2\\
0.6 \text{ if } \theta=0.7
\end{cases}
\end{equation}\]</span></p>
<p>意思就是，我們有 60% 的把握相信 <span class="math inline">\(\theta=0.7\)</span>，有 40% 的把握相信 <span class="math inline">\(\theta=0.2\)</span>，稍微傾向於 <span class="math inline">\(\theta=0.7\)</span>。</p>
<p>假設進行10次實驗，觀察到3次成功。當 <span class="math inline">\(\theta=0.2\)</span> 時，觀察數據的似然 (likelihood) 爲：</p>
<p><span class="math display">\[f_R(3|\theta=0.2)=\binom{10}{3}0.2^3(1-0.2)^7\]</span></p>
<p>當 <span class="math inline">\(\theta=0.7\)</span> 時，觀察數據的似然爲：</p>
<p><span class="math display">\[f_R(3|\theta=0.7)=\binom{10}{3}0.7^3(1-0.7)^7\]</span></p>
<p>應用貝葉斯定理計算事後概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_{\Theta|R}(\theta|3)=\begin{cases}
\frac{\binom{10}{3}0.2^3(1-0.2)^7\times0.4}{\binom{10}{3}0.2^3(1-0.2)^7\times0.4+\binom{10}{3}0.7^3(1-0.7)^7\times0.6}=0.937 \text{ if } \theta=0.2\\
\frac{\binom{10}{3}0.7^3(1-0.7)^7\times0.6}{\binom{10}{3}0.7^3(1-0.7)^7\times0.6+\binom{10}{3}0.2^3(1-0.2)^7\times0.4}=0.063 \text{ if }\theta=0.7
\end{cases}
\end{equation}\]</span></p>
<p>所以，我們從一開始認爲只有40%的把握相信 <span class="math inline">\(\theta=0.2\)</span>，觀察數據告訴我們 10 次實驗，3次獲得了成功。所以我們現在有 93.7% 的把握相信 <span class="math inline">\(\theta=0.2\)</span>。也就是說，觀察數據讓我們對參數 <span class="math inline">\(\theta\)</span> 的取值可能性發生了質的變化，從原先的傾向於 <span class="math inline">\(\theta=0.7\)</span> 到現在幾乎接近 100% 的認爲 <span class="math inline">\(\theta=0.2\)</span>。也就是，觀察數據獲得的信息改變了我們的立場。</p>
<p>上面的例子很直觀，但是有下面幾個問題：</p>
<ol style="list-style-type: decimal">
<li>如果我們無法對參數 <span class="math inline">\(\theta\)</span> 賦予先驗概率的點估計時，該怎麼辦？</li>
<li>如果事後概率不是一個離散的分佈時，該如何才能表達事後概率？</li>
</ol>
</div>
<div id="theta-的先驗概率" class="section level2">
<h2><span class="header-section-number">41.2</span> <span class="math inline">\(\theta\)</span> 的先驗概率</h2>
<p>一種選擇是，我們用均一分佈 (uniform distribution)，即我們對數據一無所知，認爲所有的 <span class="math inline">\(\theta\)</span> 的可能性都一樣，概率密度方程爲 <span class="math inline">\(1\)</span>。在這一情況下，先驗概率爲 1： <span class="math inline">\(\pi_\Theta(\theta)=1\)</span>，其事後概率分佈爲：</p>
<p><span class="math display" id="eq:uniformBayes">\[
\begin{equation}
\pi_{\Theta|R}(\theta|r)=\frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \text{ d}\theta}
\tag{41.1}
\end{equation}
\]</span></p>
<p>看到即使在如此簡單的先驗概率下，我們還是要使用複雜的微積分進行計算。幸運的是，像 <a href="#eq:uniformBayes">(41.1)</a> 的分母這樣的積分公式其實是有跡可循的。這就是 beta (<span class="math inline">\(\beta\)</span>) 分佈。</p>
<div id="beta-distribution-intro" class="section level3">
<h3><span class="header-section-number">41.2.1</span> beta 分佈 the beta distribution</h3>
<div class="figure" style="text-align: center"><span id="fig:beta-distr"></span>
<img src="bookdown_files/figure-html/beta-distr-1.png" alt="Beta distribution functions for various values of a, b" width="90%" />
<p class="caption">
圖 41.1: Beta distribution functions for various values of a, b
</p>
</div>
<p>我們定義 <span class="math inline">\(a&gt;0\)</span> 時<a href="https://zh.wikipedia.org/wiki/%CE%93%E5%87%BD%E6%95%B0">伽馬方程</a>爲</p>
<p><span class="math display">\[\Gamma(a)=\int_0^\infty x^{a-1}e^{-ax}\text{ d}x\]</span></p>
<p>當 <span class="math inline">\(a\)</span> 取正整數時， <span class="math inline">\(\Gamma(a)\)</span> 是 <span class="math inline">\((a-1)!\)</span>。例如，當 <span class="math inline">\(a=4, \Gamma(a)=3\times2\times1=6\)</span>。</p>
<p>對於 <span class="math inline">\(\theta\in[0,1]\)</span> 時，beta 方程 <span class="math inline">\(Beta(a,b)\)</span> 被定義爲：</p>
<p><span class="math display">\[
\begin{aligned}
\pi\Theta(\theta|a,b) &amp;= \theta^{a-1}(1-\theta)^{b-1}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\\
&amp;= \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}
\end{aligned}
\]</span></p>
<p>其中
<span class="math display">\[B(a,b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \int_0^1\theta^{a-1}(1-\theta)^{b-1}\text{d}\theta\]</span></p>
<p><strong>莫要混淆 B 函數和 Beta 方程。B 函數的性質和詳細定義可以參照<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%87%BD%E6%95%B0">其維基百科頁面</a>。</strong></p>
<p>利用 Beta 方程作爲先驗概率顯得十分便捷且靈活。圖 <a href="#fig:beta-distr">41.1</a> 展示的是 6 種不同的 <span class="math inline">\((a,b)\)</span> 取值下的先驗概率分佈示意圖。其實我們可以看到，包括均一分佈在內的各種可能性都可以通過 Beta 分佈實現。其中 <span class="math inline">\((a,b)\)</span> 被叫做超參數 (hyperparameter)。<span class="math inline">\((a,b)\)</span> 取值越大，先驗概率分佈的方差越小。</p>
<p>關於 Beta 分佈的幾個性質：</p>
<ol style="list-style-type: decimal">
<li>均值：<span class="math inline">\(\text{mean}=\frac{a}{a+b}\)</span>；</li>
<li>衆數：<span class="math inline">\(\text{mode}=\frac{a-1}{a+b-2}\)</span>；</li>
<li>方差：<span class="math inline">\(\text{variance}=\frac{ab}{(a+b)^2(a+b+1)}\)</span>。</li>
</ol>
<p>回到均一分佈的簡單例子 <a href="#eq:uniformBayes">(41.1)</a> 上：</p>
<p><span class="math inline">\(\pi_\Theta(\theta)=Beta(1,1)\)</span> 是 <span class="math inline">\(\theta\in[0,1]\)</span> 上的均一分佈。所以事後概率 posterior 和下面的式子成正比：</p>
<p><span class="math display">\[\theta^r(1-\theta)^{n-r}\]</span></p>
<p>換句話說，事後概率分佈服從 <span class="math inline">\(Beta(r+1,n-r+1)\)</span> 分布，均值爲 <span class="math inline">\(\frac{r+1}{n+2}\)</span>，方差爲 <span class="math inline">\(\frac{(1+r)(n-r+1)}{(n+2)^2(n+3)}\)</span>。</p>
<p>由此可見，在貝葉斯統計思維下，先驗概率爲均一分佈的二項分佈數據，其事後概率分佈的均值和方差，和經典概率論下的極大似然估計 <span class="math inline">\(r/n\)</span> 不同，和它的漸進樣本方差 <span class="math inline">\(r(n-r)/n^3\)</span> 也不同。但是，當 <span class="math inline">\(n\)</span> 越來越大，獲得的觀察數據越多提供的信息越來越多以後，我們會發現事後概率分佈的均值和方差也會越來越趨近於經典概率論下的極大似然估計和它的方差。</p>
<p>於是這裏可以總結以下兩點：</p>
<ol style="list-style-type: decimal">
<li>即使先驗概率對參數毫無用處（不能提供有效信息，或者我們對所觀察的數據一無所知），也可能會對事後概率分佈結果提供一些意外的信息。</li>
<li>當樣本量增加，似然就主導了整個貝葉斯方程，在數學計算上，經典概率論和貝葉斯推理的估計結果將會十分接近。當然，其各自的意義還是截然不同的。</li>
</ol>
</div>
<div id="conjugate" class="section level3">
<h3><span class="header-section-number">41.2.2</span> 二項分佈數據事後概率分佈的一般化：共軛性</h3>
<p>當 <span class="math inline">\(r\sim \text{Binomial}(n,\theta)\)</span> 時，如果先驗概率 <span class="math inline">\(\pi_\Theta(\theta)=\text{Beta}(a,b)\)</span>。那麼參數 <span class="math inline">\(\theta\)</span> 的事後概率分佈的密度方程滿足：</p>
<p><span class="math display">\[\pi_{\Theta|r}(\theta|r)=\text{Beta}(a+r, b+n-r)\]</span></p>
<p>它的事後概率分佈均值爲：</p>
<p><span class="math display">\[E[\theta|r]=\frac{a+r}{a+b+n}\]</span></p>
<p>事後概率分佈的衆數爲：</p>
<p><span class="math display">\[\text{Mode}[\theta|r]=\frac{a+r-1}{n+a+b-2}\]</span></p>
<p>事後概率分佈方差爲：</p>
<p><span class="math display">\[\text{Var}[\theta|r]=\frac{(a+r)(b+n-r)}{(a+b+n)^2(a+b+n+1)}\]</span></p>
<p>因此，我們看到先驗概率服從 <span class="math inline">\(\text{Beta}(a,b)\)</span> 分佈，觀察數據爲二項分佈時，事後概率分佈還是服從 <span class="math inline">\(\text{Beta}\)</span> 分佈，僅僅只是超參數發生了轉變（更新）。這就是<strong>共軛分佈</strong>的實例。<span class="math inline">\(\text{Beta}\)</span> 分佈是二項分佈的共軛先驗概率分佈 (the <span class="math inline">\(\text{Beta}(a,b)\)</span> is the conjugate prior for the binomial likelihood)。</p>
<p>在經典概率論的框架下，參數 <span class="math inline">\(\theta\)</span> 的估計就是極大似然估計 (MLE)。在二項分佈的例子中， <span class="math inline">\(\text{MLE}=\hat\theta=r/n\)</span>，當樣本量 <span class="math inline">\(n\rightarrow\infty\)</span> 時，事後概率分佈均值：</p>
<p><span class="math display">\[E[\theta|r]=\frac{a+r}{a+b+n}=\frac{\frac{r}{n}+\frac{a}{n}}{1+\frac{a+b}{n}}\approx\frac{r}{n}=\text{MLE}\]</span></p>
<p>事後概率分佈的衆數爲：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Mode}[\theta|r] &amp;=\frac{a+r-1}{n+a+b-2} \\
&amp;= \frac{\frac{r}{n}+\frac{a-1}{n}}{1+\frac{a+b-2}{n}}\\
&amp;\approx \frac{r}{n}
\end{aligned}
\]</span></p>
<p>事後概率分佈的方差爲：</p>
<p><span class="math display">\[\frac{(a+r)(b+n+r)}{(a+b+n)^2(a+b+n+1)}\approx0\]</span></p>
<p>當 <span class="math inline">\(n\)</span>，樣本越來越大時，我們獲得更多的來自數據的信息，所以來自數據的信息逐漸主導 (dominate) 了整個貝葉斯推斷的過程，事後均值等衆多統計結果都越來越趨近於概率論統計思想下的極大似然估計等結論。</p>
<p>我們也可以注意到，當 <span class="math inline">\(a\rightarrow0, b\rightarrow0\)</span> 時，事後概率分佈的均值 <span class="math inline">\(E[\theta|r] = \frac{a+r}{a+b+n} \rightarrow \frac{r}{n}\)</span>，方差也趨向於樣本漸進方差 (asymptotic sample variance)。但是當 <span class="math inline">\(a\rightarrow 0, b\rightarrow0\)</span> 時，先驗概率是沒有被定義的，可是此例下事後概率卻可以正常被定義。所以當先驗概率分佈無法被定義，或者被定義的不恰當時，事後概率分佈依然不受太大影響。所以特別是對於均值（或迴歸係數，regression coefficients）等參數，我們常常會使用均一分佈這樣的無信息先驗概率。</p>
</div>
</div>
<div id="附贈加量不加價" class="section level2">
<h2><span class="header-section-number">41.3</span> 附贈–加量不加價</h2>
<p><strong>當樣本數據服從二項分布時使用 <span class="math inline">\(\text{Beta}(a,b)\)</span> 作爲先驗概率分布，試推導事後概率分布。並且證明 Beta 分布是二項分布的共軛分布 (conjugate distribution)。</strong></p>
<ul>
<li><p>當數據服從二項分布時，其似然方程 (或概率方程) 爲: <br> <span class="math display">\[f(n,r|\theta) = \binom{n}{r}\theta^r(1-\theta)^{n-r}\]</span></p></li>
<li><p>用 <span class="math inline">\(\text{Beta}(a,b)\)</span> 做先驗概率分布 (<span class="math inline">\(a,b\)</span> 是 <span class="math inline">\(\theta\)</span> 的超參數)，那麼 <br> <span class="math display">\[\begin{aligned}\pi(\theta) &amp;= \text{Beta}(\theta|a,b) \\
&amp; =  \theta^{a-1}(1-\theta)^{b-1}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \\ 
&amp; = \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)} \\
\text{Where } B(a,b) &amp;=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \int_0^1\theta^{a-1}(1-\theta)^{b-1}\text{d}\theta
\end{aligned}\]</span></p></li>
<li><p>利用貝葉斯定理，後概率分布就可以推導爲 <br>
<span class="math display">\[
\begin{aligned}
\pi(\theta|n,r) &amp; = \frac{f(n,r|\theta)\pi(\theta)}{\int f(n,r |\theta)\pi(\theta)\text{d}\theta}   \\
              &amp; = \frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}\pi(\theta)}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \pi(\theta) \text{ d}\theta} \\
              &amp; = \frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}\frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)} \text{ d}\theta} \\
              &amp; = \frac{\binom{n}{r}\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{\int_0^1\binom{n}{r}\theta^{r+a-1}(1-\theta)^{n+b-r-1} \text{ d}\theta} \\
              &amp; = \frac{\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{B(r+a, n+b-r)} \\
              &amp; \sim \text{Beta}(r+a, n+b-r)
\end{aligned}
\]</span>
這個推導的結果告訴我們，先驗概率 <span class="math inline">\(\pi(\theta) = \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}\sim \text{Beta}(a,b)\)</span>，通過和二項分布的似然方程相乘，獲得後驗概率 <span class="math inline">\(\pi(\theta|n,r) = \frac{\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{B(r+a, n+b-r)}\sim\text{Beta}(r+a, n+b-r)\)</span>。這兩個概率都服從 <span class="math inline">\(\text{Beta}\)</span> 分布，也就是證明了 <span class="math inline">\(\text{Beta}\)</span> 分布，是二項分布的共軛分布。新產生的事後概率的性質有: <br></p></li>
</ul>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta\)</span> 的均值 mean <span class="math inline">\(\mu= \frac{a+r}{a+b+n}\)</span>;</li>
<li><span class="math inline">\(\theta\)</span> 的方差 variance <span class="math inline">\(\sigma^2 = \frac{(a+r)(n+b-r)}{(a+b+n)^2(a+b+n+1)}\)</span>;</li>
</ol>
</div>
<div id="練習題-6" class="section level2">
<h2><span class="header-section-number">41.4</span> 練習題</h2>
<div id="q1-4" class="section level3">
<h3><span class="header-section-number">41.4.1</span> Q1</h3>
<p>當先驗概率分佈服從 <span class="math inline">\(\text{Beta}(0.5,0.5)\)</span>，觀察數據記錄到 <span class="math inline">\(5\)</span> 個患者中 <span class="math inline">\(3\)</span> 人死亡的事件。
試求：
死亡發生概率 <span class="math inline">\(\theta\)</span> 的 95% 可信區間 (credible intervals)。</p>
<p><strong>解</strong></p>
<p>根據 Section <a href="#conjugate">41.2.2</a> 的公式，當先驗概率爲 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(a=0.5,b=0.5)\)</span> ，數據 <span class="math inline">\(n=5, r=3\)</span>。參數 <span class="math inline">\(\theta\)</span> 的事後概率分佈 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(a+r,b+n-r)=\text{Beta}(3.5,2.5)\)</span>。</p>
<p>在 <a href="https://www.r-project.org/">R</a> 裏進行貝葉斯計算十分簡便：</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb339-1" title="1"><span class="co"># 95% Credible Intervals</span></a>
<a class="sourceLine" id="cb339-2" title="2">L &lt;-<span class="st"> </span><span class="kw">qbeta</span>(<span class="fl">0.025</span>, <span class="fl">3.5</span>, <span class="fl">2.5</span>)</a>
<a class="sourceLine" id="cb339-3" title="3">U &lt;-<span class="st"> </span><span class="kw">qbeta</span>(<span class="fl">0.975</span>, <span class="fl">3.5</span>, <span class="fl">2.5</span>)</a>
<a class="sourceLine" id="cb339-4" title="4"></a>
<a class="sourceLine" id="cb339-5" title="5"><span class="kw">print</span>(<span class="kw">c</span>(L,U))</a></code></pre></div>
<pre><code>## [1] 0.20941666 0.90560967</code></pre>
<p>事後分佈 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(3.5,2.5)\)</span> 的分佈圖形如下：</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb341-1" title="1">post &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, <span class="fl">3.5</span>, <span class="fl">2.5</span>))</a>
<a class="sourceLine" id="cb341-2" title="2"></a>
<a class="sourceLine" id="cb341-3" title="3"><span class="co"># Illustration</span></a>
<a class="sourceLine" id="cb341-4" title="4">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span><span class="dv">10000</span>)</a>
<a class="sourceLine" id="cb341-5" title="5">y &lt;-<span class="st"> </span><span class="kw">post</span>(x)</a>
<a class="sourceLine" id="cb341-6" title="6"><span class="kw">plot</span>(x,y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">xlab=</span><span class="op">~</span>theta, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb341-7" title="7"></a>
<a class="sourceLine" id="cb341-8" title="8"><span class="kw">polygon</span>(<span class="kw">c</span>(L, x[x<span class="op">&gt;=</span>L <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="st"> </span>U], U), <span class="kw">c</span>(<span class="dv">0</span>, y[x<span class="op">&gt;=</span>L <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span>U], <span class="dv">0</span>), <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Bayes03"></span>
<img src="bookdown_files/figure-html/Bayes03-1.png" alt="Posterior distribution of Beta(3.5,2.5)" width="80%" />
<p class="caption">
圖 41.2: Posterior distribution of Beta(3.5,2.5)
</p>
</div>
<p>我們可以自己寫一個求可信區間的公式來計算：</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb342-1" title="1"><span class="co"># Credible Interval function:</span></a>
<a class="sourceLine" id="cb342-2" title="2"><span class="co"># a, b : shape / super parameters</span></a>
<a class="sourceLine" id="cb342-3" title="3"><span class="co"># level: probability level (0,1)</span></a>
<a class="sourceLine" id="cb342-4" title="4"></a>
<a class="sourceLine" id="cb342-5" title="5">cred.int &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,level){</a>
<a class="sourceLine" id="cb342-6" title="6">  L &lt;-<span class="st"> </span><span class="kw">qbeta</span>((<span class="dv">1</span><span class="op">-</span>level)<span class="op">/</span><span class="dv">2</span>, a, b) <span class="co"># Lower limit</span></a>
<a class="sourceLine" id="cb342-7" title="7">  U &lt;-<span class="st"> </span><span class="kw">qbeta</span>((<span class="dv">1</span><span class="op">+</span>level)<span class="op">/</span><span class="dv">2</span>, a, b) <span class="co"># Upper limit</span></a>
<a class="sourceLine" id="cb342-8" title="8">  <span class="kw">return</span>(<span class="kw">c</span>(L,U))</a>
<a class="sourceLine" id="cb342-9" title="9">}</a>
<a class="sourceLine" id="cb342-10" title="10"></a>
<a class="sourceLine" id="cb342-11" title="11"><span class="kw">cred.int</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>,<span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>## [1] 0.20941666 0.90560967</code></pre>
<p>95%可信區間 <span class="math inline">\((0.2094, 0.9056)\)</span> 告訴我們，參數 <span class="math inline">\(\theta\in(0.2094, 0.9056)\)</span> 的概率是 <span class="math inline">\(0.95\)</span>。</p>
<p>下面我們嘗試寫 Beta 分佈的其他統計量：均值，衆數，方差等。</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb344-1" title="1"><span class="co"># a, b: shape / super parameters</span></a>
<a class="sourceLine" id="cb344-2" title="2">MeanBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) a<span class="op">/</span>(a<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb344-3" title="3">ModeBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) {</a>
<a class="sourceLine" id="cb344-4" title="4">  m &lt;-<span class="st"> </span><span class="kw">ifelse</span>(a<span class="op">&gt;</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>b<span class="op">&gt;</span><span class="dv">1</span>, (a<span class="dv">-1</span>)<span class="op">/</span>(a<span class="op">+</span>b<span class="dv">-2</span>), <span class="ot">NA</span>)</a>
<a class="sourceLine" id="cb344-5" title="5">  <span class="kw">return</span>(m)</a>
<a class="sourceLine" id="cb344-6" title="6">}</a>
<a class="sourceLine" id="cb344-7" title="7">VarianceBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) (a<span class="op">*</span>b)<span class="op">/</span>((a<span class="op">+</span>b)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb344-8" title="8"></a>
<a class="sourceLine" id="cb344-9" title="9"><span class="co"># mean</span></a>
<a class="sourceLine" id="cb344-10" title="10"><span class="kw">MeanBeta</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.58333333</code></pre>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb346-1" title="1"><span class="co"># mode</span></a>
<a class="sourceLine" id="cb346-2" title="2"><span class="kw">ModeBeta</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.625</code></pre>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" title="1"><span class="co"># Variance</span></a>
<a class="sourceLine" id="cb348-2" title="2"><span class="kw">VarianceBeta</span>(<span class="fl">3.5</span>, <span class="fl">2.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.034722222</code></pre>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb350-1" title="1"><span class="co"># SD</span></a>
<a class="sourceLine" id="cb350-2" title="2"><span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(<span class="fl">3.5</span>, <span class="fl">2.5</span>))</a></code></pre></div>
<pre><code>## [1] 0.186339</code></pre>
</div>
<div id="q2-3" class="section level3">
<h3><span class="header-section-number">41.4.2</span> Q2</h3>
<p>假如數據還是 Q1 的數據，然而先驗概率讓我們認爲可能在 5 名受試對象中觀察到 1 次事件。</p>
<ol style="list-style-type: decimal">
<li>試求超參數 <span class="math inline">\((a,b)\)</span> 滿足先驗概率的 Beta 分佈。(不止一組)</li>
</ol>
<p><strong>解</strong></p>
<p>我們認爲最有可能發生 “5 名受試對象中觀察到 1 次事件” 的情況，那麼先驗概率的均值爲 <span class="math inline">\(\frac{a}{a+b}=0.2\)</span>。所以，在實數中有無數組超參數都可以用來模擬先驗概率分佈。例如 <span class="math inline">\(a=1, b=4; a=10, b=40; a=100, b=400; a=0.317, b=1.268, \cdots\)</span>。</p>
<ol start="2" style="list-style-type: decimal">
<li>假如觀察數據是 <span class="math inline">\(n=5, r=1\)</span>，計算事後概率分佈及其均值，標準差。</li>
</ol>
<p><strong>解</strong></p>
<p>先來嘗試寫一個計算貝葉斯二項分佈的方程：</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb352-1" title="1"><span class="co"># binbayes function in R</span></a>
<a class="sourceLine" id="cb352-2" title="2"><span class="co">#------------------------------</span></a>
<a class="sourceLine" id="cb352-3" title="3"><span class="co"># a, b: shape / super parameters</span></a>
<a class="sourceLine" id="cb352-4" title="4"><span class="co"># r   : number of successes</span></a>
<a class="sourceLine" id="cb352-5" title="5"><span class="co"># n   : number of trials</span></a>
<a class="sourceLine" id="cb352-6" title="6"></a>
<a class="sourceLine" id="cb352-7" title="7">binbayes &lt;-<span class="st"> </span><span class="cf">function</span>(a, b, r, n) {</a>
<a class="sourceLine" id="cb352-8" title="8">  prior &lt;-<span class="st"> </span><span class="kw">c</span>(a, b, <span class="ot">NA</span>, <span class="kw">MeanBeta</span>(a,b), <span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(a, b)), <span class="kw">qbeta</span>(<span class="fl">0.025</span>, a, b), <span class="kw">qbeta</span>(<span class="fl">0.5</span>, a, b), <span class="kw">qbeta</span>(<span class="fl">0.975</span>, a, b))</a>
<a class="sourceLine" id="cb352-9" title="9">  posterior &lt;-<span class="st"> </span><span class="kw">c</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r, r<span class="op">/</span>n, <span class="kw">MeanBeta</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r)), <span class="kw">qbeta</span>(<span class="fl">0.025</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">qbeta</span>(<span class="fl">0.5</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">qbeta</span>(<span class="fl">0.975</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r))</a>
<a class="sourceLine" id="cb352-10" title="10">  out &lt;-<span class="st"> </span><span class="kw">rbind</span>(prior, posterior)</a>
<a class="sourceLine" id="cb352-11" title="11">  out &lt;-<span class="st"> </span><span class="kw">round</span>(out, <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb352-12" title="12">  <span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;a&quot;</span>,<span class="st">&quot;b&quot;</span>,<span class="st">&quot;r/n&quot;</span>,<span class="st">&quot;Mean&quot;</span>, <span class="st">&quot;SD&quot;</span>, <span class="st">&quot;2.5%&quot;</span>, <span class="st">&quot;50%&quot;</span>, <span class="st">&quot;97.5%&quot;</span>)</a>
<a class="sourceLine" id="cb352-13" title="13">  <span class="kw">return</span>(out)</a>
<a class="sourceLine" id="cb352-14" title="14">}</a>
<a class="sourceLine" id="cb352-15" title="15"></a>
<a class="sourceLine" id="cb352-16" title="16"><span class="co"># a=1, b=4, r=1, n=5</span></a>
<a class="sourceLine" id="cb352-17" title="17"><span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">5</span>)</a></code></pre></div>
<pre><code>##           a b r/n Mean     SD   2.5%    50%  97.5%
## prior     1 4  NA  0.2 0.1633 0.0063 0.1591 0.6024
## posterior 2 8 0.2  0.2 0.1206 0.0281 0.1796 0.4825</code></pre>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb354-1" title="1"><span class="co"># a=10, b=40, r=1, n=5</span></a>
<a class="sourceLine" id="cb354-2" title="2"><span class="kw">binbayes</span>(<span class="dv">10</span>,<span class="dv">40</span>,<span class="dv">1</span>,<span class="dv">5</span>)</a></code></pre></div>
<pre><code>##            a  b r/n Mean     SD   2.5%    50%  97.5%
## prior     10 40  NA  0.2 0.0560 0.1024 0.1960 0.3202
## posterior 11 44 0.2  0.2 0.0535 0.1063 0.1963 0.3143</code></pre>
<p>通過繪製先驗概率分佈圖和事後概率分佈圖來比較二者的變化：</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb356-1" title="1"><span class="co"># Prior vs posterior graphs</span></a>
<a class="sourceLine" id="cb356-2" title="2"><span class="co"># a,b : shape / super parameters</span></a>
<a class="sourceLine" id="cb356-3" title="3"><span class="co"># r   : number of successes</span></a>
<a class="sourceLine" id="cb356-4" title="4"><span class="co"># n   : number of trials</span></a>
<a class="sourceLine" id="cb356-5" title="5">graph.binbayes &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,r,n) {</a>
<a class="sourceLine" id="cb356-6" title="6">  prior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a,b))</a>
<a class="sourceLine" id="cb356-7" title="7">  posterior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r))</a>
<a class="sourceLine" id="cb356-8" title="8">  YL &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">prior</span>(<span class="kw">seq</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>,<span class="dt">by=</span><span class="fl">0.001</span>)),<span class="kw">posterior</span>(<span class="kw">seq</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>,<span class="dt">by=</span><span class="fl">0.001</span>)))</a>
<a class="sourceLine" id="cb356-9" title="9">  <span class="kw">curve</span>(prior, <span class="dt">xlab=</span><span class="op">~</span>theta, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,YL), <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb356-10" title="10">  <span class="kw">curve</span>(posterior, <span class="dt">xlab=</span><span class="op">~</span>theta,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">add=</span>T,<span class="dt">n=</span><span class="dv">10000</span>)</a>
<a class="sourceLine" id="cb356-11" title="11">}</a>
<a class="sourceLine" id="cb356-12" title="12"></a>
<a class="sourceLine" id="cb356-13" title="13"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">5</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-2"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-2-1.png" alt="Prior (dashed) Beta(1,4) vs. Posterior (cont.) Beta(2,8)" width="80%" />
<p class="caption">
圖 41.3: Prior (dashed) Beta(1,4) vs. Posterior (cont.) Beta(2,8)
</p>
</div>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">10</span>,<span class="dv">40</span>,<span class="dv">1</span>,<span class="dv">5</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-3"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-3-1.png" alt="Prior (dashed) Beta(10,40) vs. Posterior (cont.) Beta(11, 44)" width="80%" />
<p class="caption">
圖 41.4: Prior (dashed) Beta(10,40) vs. Posterior (cont.) Beta(11, 44)
</p>
</div>
<p>我們可以很清楚的看見，先驗概率相同時，<span class="math inline">\(\text{Beta} (a,b)\)</span> 的超參數如果越大，先驗概率的分佈就越趨近與對稱圖形，且極大值也就越出現在均值的地方 (本例中是 <span class="math inline">\(0.2\)</span>)。而且也會使事後概率的 HPD (highest posterior density) 的區間更狹窄 (意爲對事後概率的預測越準確)，同時事後概率分佈也更加接近左右對稱。</p>
</div>
<div id="q3-2" class="section level3">
<h3><span class="header-section-number">41.4.3</span> Q3</h3>
<p>我們事先估計某個事件在 <span class="math inline">\(n=20\)</span> 名患者中發生的概率爲 <span class="math inline">\(15\%\)</span>。當實際觀察數據爲 <span class="math inline">\(n=15,r=3\)</span> 時，計算相應的事後概率。</p>
<p><strong>解</strong></p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb358-1" title="1"><span class="co"># because 15% events happened in 20 subjects, assuming prior Beta(a=3, b=17)</span></a>
<a class="sourceLine" id="cb358-2" title="2"><span class="co"># observed n=15, r=3</span></a>
<a class="sourceLine" id="cb358-3" title="3"><span class="kw">binbayes</span>(<span class="dv">3</span>,<span class="dv">17</span>,<span class="dv">3</span>,<span class="dv">15</span>)</a></code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     3 17  NA 0.1500 0.0779 0.0338 0.1383 0.3314
## posterior 6 29 0.2 0.1714 0.0628 0.0676 0.1651 0.3106</code></pre>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">3</span>,<span class="dv">17</span>,<span class="dv">3</span>,<span class="dv">15</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-5"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-5-1.png" alt="Prior (dashed) Beta(3,17) vs. Posterior (cont.) Beta(6,29)" width="80%" />
<p class="caption">
圖 41.5: Prior (dashed) Beta(3,17) vs. Posterior (cont.) Beta(6,29)
</p>
</div>
<p>試着繪製先驗概率服從 <span class="math inline">\(\text{Beta} (1,1)\)</span>，回憶之前本章開頭的圖 <a href="#fig:beta-distr">41.1</a>，這個先驗概率的含義就是我們沒有任何背景知識，對數據完全陌生的情況：</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb361-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">15</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-6"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-6-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4,13)" width="80%" />
<p class="caption">
圖 41.6: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4,13)
</p>
</div>
</div>
<div id="q4" class="section level3">
<h3><span class="header-section-number">41.4.4</span> Q4</h3>
<p>試給出上面各題中參數 <span class="math inline">\(\theta\)</span> 落在 <span class="math inline">\((0.1,0.25)\)</span> 之間的概率。</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" title="1"><span class="co"># function to calculate probabilities in a interval</span></a>
<a class="sourceLine" id="cb362-2" title="2"><span class="co"># a, b: super parameters</span></a>
<a class="sourceLine" id="cb362-3" title="3"><span class="co"># r   : number of successes</span></a>
<a class="sourceLine" id="cb362-4" title="4"><span class="co"># n   : number of trials</span></a>
<a class="sourceLine" id="cb362-5" title="5"><span class="co"># L   : Lower limit of the probability interval</span></a>
<a class="sourceLine" id="cb362-6" title="6"><span class="co"># U   : Upper limit of the probability interval</span></a>
<a class="sourceLine" id="cb362-7" title="7"></a>
<a class="sourceLine" id="cb362-8" title="8">prob.int &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,r,n,L,U){</a>
<a class="sourceLine" id="cb362-9" title="9">prior0 &lt;-<span class="st"> </span><span class="kw">pbeta</span>(U,a,b) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(L,a,b)</a>
<a class="sourceLine" id="cb362-10" title="10">posterior0 &lt;-<span class="st"> </span><span class="kw">pbeta</span>(U,a<span class="op">+</span>r,n<span class="op">-</span>r<span class="op">+</span>b) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(L,a<span class="op">+</span>r,n<span class="op">-</span>r<span class="op">+</span>b)</a>
<a class="sourceLine" id="cb362-11" title="11">prob &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">c</span>(prior0, posterior0))</a>
<a class="sourceLine" id="cb362-12" title="12">prob &lt;-<span class="st"> </span><span class="kw">round</span>(prob,<span class="dv">4</span>)</a>
<a class="sourceLine" id="cb362-13" title="13"><span class="kw">colnames</span>(prob) &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Probability of theta lies between the Interval&quot;</span>, L, U)</a>
<a class="sourceLine" id="cb362-14" title="14"><span class="kw">rownames</span>(prob) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Prior&quot;</span>,<span class="st">&quot;Posterior&quot;</span>)</a>
<a class="sourceLine" id="cb362-15" title="15">  <span class="kw">return</span>(prob)</a>
<a class="sourceLine" id="cb362-16" title="16">}</a>
<a class="sourceLine" id="cb362-17" title="17"></a>
<a class="sourceLine" id="cb362-18" title="18"><span class="co"># Prior Beta(0.317,1.286) n = 5, r=1</span></a>
<a class="sourceLine" id="cb362-19" title="19"><span class="kw">binbayes</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>##               a     b r/n   Mean     SD  2.5%    50%  97.5%
## prior     0.317 1.286  NA 0.1978 0.2469 0.000 0.0823 0.8516
## posterior 1.317 5.286 0.2 0.1995 0.1449 0.013 0.1684 0.5493</code></pre>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" title="1"><span class="kw">prob.int</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0.1 0.25
## Prior                                                      0.1711
## Posterior                                                  0.3911</code></pre>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb366-1" title="1"><span class="kw">graph.binbayes</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-8"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-8-1.png" alt="Prior (dashed) Beta(0.317,1.286) vs. Posterior (cont.) Beta(1.317, 5.286)" width="80%" />
<p class="caption">
圖 41.7: Prior (dashed) Beta(0.317,1.286) vs. Posterior (cont.) Beta(1.317, 5.286)
</p>
</div>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" title="1"><span class="co"># Prior Beta(10,40) n = 5, r=1</span></a>
<a class="sourceLine" id="cb367-2" title="2"><span class="kw">binbayes</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dv">1</span>, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>##            a  b r/n Mean     SD   2.5%    50%  97.5%
## prior     10 40  NA  0.2 0.0560 0.1024 0.1960 0.3202
## posterior 11 44 0.2  0.2 0.0535 0.1063 0.1963 0.3143</code></pre>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" title="1"><span class="kw">prob.int</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dv">1</span>, <span class="dv">5</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0.1 0.25
## Prior                                                      0.7951
## Posterior                                                  0.8099</code></pre>
<p>所以在範圍固定的時候，事後概率分佈總是能夠比先驗概率分佈給出更高的累計概率。</p>
</div>
<div id="q5" class="section level3">
<h3><span class="header-section-number">41.4.5</span> Q5</h3>
<p>一個臨牀試驗要進行兩個階段 (two phases)，第一階段我們觀察到 <span class="math inline">\(10\)</span> 個患者中 <span class="math inline">\(1\)</span> 個事件。第二階段，觀察到 <span class="math inline">\(n=50, r=5\)</span>。</p>
<ol style="list-style-type: decimal">
<li>兩個階段都使用 <span class="math inline">\(\text{Beta}(1,1)\)</span> 作先驗概率。求兩個實驗階段參數 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1"><span class="co"># Phase I</span></a>
<a class="sourceLine" id="cb371-2" title="2"><span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)</a></code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%   50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.500 0.9750
## posterior 2 10 0.1 0.1667 0.1034 0.0228 0.148 0.4128</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" title="1"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.3026</code></pre>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-11"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-11-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 10)" width="80%" />
<p class="caption">
圖 41.8: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 10)
</p>
</div>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" title="1"><span class="co"># Phase II</span></a>
<a class="sourceLine" id="cb376-2" title="2"><span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">50</span>)</a></code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.5000 0.9750
## posterior 6 46 0.1 0.1154 0.0439 0.0444 0.1105 0.2141</code></pre>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb378-1" title="1"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">50</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.4024</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">50</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-13"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-13-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(6, 46)" width="80%" />
<p class="caption">
圖 41.9: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(6, 46)
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>繼續使用先驗概率分佈 <span class="math inline">\(\text{Beta}(1,1)\)</span>，合併兩個實驗階段，求此時的事後概率分佈，以及參數 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" title="1"><span class="co"># Combining both phases</span></a>
<a class="sourceLine" id="cb381-2" title="2"><span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">60</span>)</a></code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.5000 0.9750
## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019</code></pre>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" title="1"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">6</span>,<span class="dv">60</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.4105</code></pre>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">60</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-15"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-15-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(7, 55)" width="80%" />
<p class="caption">
圖 41.10: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(7, 55)
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>用第一階段的實驗結果做第二階段實驗的先驗概率分佈，再計算事後概率分佈，以及 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb386-1" title="1"><span class="co"># Using Phase I results as a prior for Phase II</span></a>
<a class="sourceLine" id="cb386-2" title="2"><span class="kw">binbayes</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">50</span>)</a></code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     2 10  NA 0.1667 0.1034 0.0228 0.1480 0.4128
## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019</code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb388-1" title="1"><span class="kw">prob.int</span>(<span class="dv">2</span>,<span class="dv">10</span>,<span class="dv">5</span>,<span class="dv">50</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</a></code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.3026
## Posterior                                               0.4105</code></pre>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb390-1" title="1"><span class="kw">graph.binbayes</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">50</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-17"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-17-1.png" alt="Prior (dashed) Beta(2,10) vs. Posterior (cont.) Beta(7, 55)" width="80%" />
<p class="caption">
圖 41.11: Prior (dashed) Beta(2,10) vs. Posterior (cont.) Beta(7, 55)
</p>
</div>
<p>第2，3兩個小問題提示我們，無論是將第一階段實驗結果作爲第二階段實驗的先驗假設還是將兩次實驗合併，最終的結果是不會改變的。Both approaches are equivalent.</p>
</div>
<div id="q6" class="section level3">
<h3><span class="header-section-number">41.4.6</span> Q6</h3>
<p>藥物 A 和藥物 B 都被批准用於治療某種疾病。在 5000 例病例中使用藥物 A，發現有 3 人發生了不良副作用。在另外 7000 例病例中使用藥物 B，發現只有 1 例發生了副作用。</p>
<ol style="list-style-type: decimal">
<li>先使用單一分佈作爲先驗概率 (uniform prior: <span class="math inline">\(\text{Beta}(1,1)\)</span>)。求藥物 A 和藥物 B 各自發生不良反應的事後概率。</li>
</ol>
<p><strong>藥物 A</strong></p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" title="1"><span class="co"># Drug A</span></a>
<a class="sourceLine" id="cb391-2" title="2"><span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5000</span>)</a></code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD   2.5%    50%  97.5%
## prior     1    1     NA 0.5000 0.2887 0.0250 0.5000 0.9750
## posterior 4 4998 0.0006 0.0008 0.0004 0.0002 0.0007 0.0018</code></pre>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-19"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-19-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4, 4998)" width="80%" />
<p class="caption">
圖 41.12: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4, 4998)
</p>
</div>
<p><strong>藥物 B</strong></p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb393-1" title="1"><span class="co"># Drug B</span></a>
<a class="sourceLine" id="cb393-2" title="2"><span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">7000</span>)</a></code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD  2.5%    50%  97.5%
## prior     1    1     NA 0.5000 0.2887 0.025 0.5000 0.9750
## posterior 2 7000 0.0001 0.0003 0.0002 0.000 0.0002 0.0008</code></pre>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-21"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-21-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 7000)" width="80%" />
<p class="caption">
圖 41.13: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 7000)
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>使用 <span class="math inline">\(\text{Beta}(0.00001,0.00001)\)</span> 作爲先驗概率，重複上面的計算</li>
</ol>
<p><strong>藥物 A</strong></p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb395-1" title="1"><span class="co"># Drug A</span></a>
<a class="sourceLine" id="cb395-2" title="2"><span class="kw">binbayes</span>(<span class="fl">0.00001</span>, <span class="fl">0.00001</span>, <span class="dv">3</span>, <span class="dv">5000</span>)</a></code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD   2.5%    50%  97.5%
## prior     0    0     NA 0.5000 0.5000 0.0000 0.5000 1.0000
## posterior 3 4997 0.0006 0.0006 0.0003 0.0001 0.0005 0.0014</code></pre>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-23"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-23-1.png" alt="Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(3, 4997)" width="80%" />
<p class="caption">
圖 41.14: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(3, 4997)
</p>
</div>
<p><strong>藥物 B</strong></p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb397-1" title="1"><span class="co"># Drug B</span></a>
<a class="sourceLine" id="cb397-2" title="2"><span class="kw">binbayes</span>(<span class="fl">0.00001</span>, <span class="fl">0.00001</span>, <span class="dv">1</span>, <span class="dv">7000</span>)</a></code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD 2.5%    50%  97.5%
## prior     0    0     NA 0.5000 0.5000    0 0.5000 1.0000
## posterior 1 6999 0.0001 0.0001 0.0001    0 0.0001 0.0005</code></pre>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-25"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-25-1.png" alt="Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(1, 6999)" width="80%" />
<p class="caption">
圖 41.15: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(1, 6999)
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>現在使用概率論的計算信賴區間 (confidence intervals) 的方法，求上面數據的精確二項分佈 95% 信賴區間。之前兩問中使用的哪個先驗概率更加接近概率論算法？</li>
</ol>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb399-1" title="1"><span class="co">#------------------------------------------------</span></a>
<a class="sourceLine" id="cb399-2" title="2"><span class="co"># Binomial confidence intervals</span></a>
<a class="sourceLine" id="cb399-3" title="3"><span class="co">#------------------------------------------------</span></a>
<a class="sourceLine" id="cb399-4" title="4"><span class="co"># r    : number of successes</span></a>
<a class="sourceLine" id="cb399-5" title="5"><span class="co"># n    : number of trials</span></a>
<a class="sourceLine" id="cb399-6" title="6"><span class="co"># level: confidence level</span></a>
<a class="sourceLine" id="cb399-7" title="7">binom.confint &lt;-<span class="st"> </span><span class="cf">function</span>(r,n,level){</a>
<a class="sourceLine" id="cb399-8" title="8"> p &lt;-<span class="st"> </span>r<span class="op">/</span>n</a>
<a class="sourceLine" id="cb399-9" title="9">conf &lt;-<span class="st">  </span><span class="kw">as.vector</span>(<span class="kw">binom.test</span>(r,n,<span class="dt">conf.level =</span> <span class="fl">0.95</span>)<span class="op">$</span>conf.int)</a>
<a class="sourceLine" id="cb399-10" title="10">out &lt;-<span class="st"> </span><span class="kw">c</span>(p,conf)</a>
<a class="sourceLine" id="cb399-11" title="11">out &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">t</span>(<span class="kw">round</span>(out,<span class="dv">8</span>)))</a>
<a class="sourceLine" id="cb399-12" title="12"><span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MLE&quot;</span>, <span class="st">&quot;L&quot;</span>, <span class="st">&quot;U&quot;</span>)</a>
<a class="sourceLine" id="cb399-13" title="13"><span class="kw">return</span>(out)</a>
<a class="sourceLine" id="cb399-14" title="14">}</a>
<a class="sourceLine" id="cb399-15" title="15"></a>
<a class="sourceLine" id="cb399-16" title="16"><span class="co"># Drug A</span></a>
<a class="sourceLine" id="cb399-17" title="17"><span class="kw">binom.confint</span>(<span class="dv">3</span>,<span class="dv">5000</span>,<span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>##         MLE          L          U
## [1,] 0.0006 0.00012375 0.00175244</code></pre>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb401-1" title="1"><span class="co"># Drug B</span></a>
<a class="sourceLine" id="cb401-2" title="2"><span class="kw">binom.confint</span>(<span class="dv">1</span>,<span class="dv">7000</span>,<span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>##             MLE        L          U
## [1,] 0.00014286 3.62e-06 0.00079569</code></pre>
<p>明顯可以看到，先驗概率使用 <span class="math inline">\(\text{Beta}(0.00001,0.00001)\)</span> 時，事後概率的均值和可信區間的下限值更接近概率論算法。使用先驗概率 <span class="math inline">\(\text{Beta}(1,1)\)</span> 時，事後概率的可信區間的上限值更接近概率論算法。</p>
<ol start="4" style="list-style-type: decimal">
<li>如果需要你來下結論說，藥物 B 和藥物 A 哪個更加安全？ 求 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><strong>貝葉斯</strong></p>
<p>在計算機的輔助下，這是一個十分簡單的計算。我們從各自的事後分佈中採集大量隨機樣本，然後求 <span class="math inline">\(\theta_B-\theta_A\)</span> 然後看有多少比例這個數值是小於零的就可以得出結論：</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb403-1" title="1"><span class="co"># Simulating from each posterior</span></a>
<a class="sourceLine" id="cb403-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb403-3" title="3">post.thetaA &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">3</span>, <span class="dv">4997</span>)</a>
<a class="sourceLine" id="cb403-4" title="4">post.thetaB &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">1</span>, <span class="dv">6999</span>)</a>
<a class="sourceLine" id="cb403-5" title="5"></a>
<a class="sourceLine" id="cb403-6" title="6"><span class="co"># Taking the differences</span></a>
<a class="sourceLine" id="cb403-7" title="7">theta.diff0 &lt;-<span class="st"> </span>post.thetaB <span class="op">-</span><span class="st"> </span>post.thetaA</a></code></pre></div>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb404-1" title="1"><span class="co"># Histogram of the differences</span></a>
<a class="sourceLine" id="cb404-2" title="2"><span class="kw">hist</span>(theta.diff0,<span class="dt">probability =</span> <span class="ot">TRUE</span>, <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]),<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb404-3" title="3"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb404-4" title="4"><span class="kw">box</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-28"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-28-1.png" alt="Histogram of  Drug B - Drug A" width="80%" />
<p class="caption">
圖 41.16: Histogram of Drug B - Drug A
</p>
</div>
<p>也可以不採用直方圖而是使用連續曲線：</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb405-1" title="1"><span class="co"># Continuous version</span></a>
<a class="sourceLine" id="cb405-2" title="2"><span class="kw">plot</span>(<span class="kw">density</span>(theta.diff0), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">frame=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb405-3" title="3"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb405-4" title="4"><span class="kw">box</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-29"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-29-1.png" alt="Density of Drug B - Drug A" width="80%" />
<p class="caption">
圖 41.17: Density of Drug B - Drug A
</p>
</div>
<p>計算 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span> 和可信區間：</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb406-1" title="1"><span class="co"># P(theta[B] &lt; theta[A] | Data)</span></a>
<a class="sourceLine" id="cb406-2" title="2"><span class="kw">mean</span>(theta.diff0 <span class="op">&lt;</span><span class="dv">0</span>)</a></code></pre></div>
<pre><code>## [1] 0.927829</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb408-1" title="1"><span class="co"># Credible interval for theta[B] - theta[A]</span></a>
<a class="sourceLine" id="cb408-2" title="2"><span class="kw">quantile</span>(theta.diff0, <span class="kw">c</span>(<span class="fl">0.05</span>,<span class="fl">0.95</span>))</a></code></pre></div>
<pre><code>##              5%             95% 
## -0.001142862872  0.000052484912</code></pre>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb410-1" title="1"><span class="kw">quantile</span>(theta.diff0, <span class="kw">c</span>(<span class="fl">0.10</span>,<span class="fl">0.90</span>))</a></code></pre></div>
<pre><code>##            10%            90% 
## -0.00094605885 -0.00004674857</code></pre>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb412-1" title="1"><span class="co"># Simulating from each posterior</span></a>
<a class="sourceLine" id="cb412-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb412-3" title="3">post.thetaA &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">4</span>, <span class="dv">4998</span>)</a>
<a class="sourceLine" id="cb412-4" title="4">post.thetaB &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">2</span>, <span class="dv">7000</span>)</a>
<a class="sourceLine" id="cb412-5" title="5"></a>
<a class="sourceLine" id="cb412-6" title="6"><span class="co"># Taking the differences</span></a>
<a class="sourceLine" id="cb412-7" title="7">theta.diff1 &lt;-<span class="st"> </span>post.thetaB <span class="op">-</span><span class="st"> </span>post.thetaA</a></code></pre></div>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb413-1" title="1"><span class="kw">hist</span>(theta.diff1,<span class="dt">probability =</span> <span class="ot">TRUE</span>, <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]),<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb413-2" title="2"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb413-3" title="3"><span class="kw">box</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-32"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-32-1.png" alt="Histogram of  Drug B - Drug A" width="80%" />
<p class="caption">
圖 41.18: Histogram of Drug B - Drug A
</p>
</div>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb414-1" title="1"><span class="co"># Continuous version</span></a>
<a class="sourceLine" id="cb414-2" title="2"><span class="kw">plot</span>(<span class="kw">density</span>(theta.diff1), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb414-3" title="3"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb414-4" title="4"><span class="kw">box</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-33"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-33-1.png" alt="Density of  Drug B - Drug A" width="80%" />
<p class="caption">
圖 41.19: Density of Drug B - Drug A
</p>
</div>
<p>計算 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span> 和可信區間：</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb415-1" title="1"><span class="co"># P(theta[B] &lt; theta[A] | Data)</span></a>
<a class="sourceLine" id="cb415-2" title="2"></a>
<a class="sourceLine" id="cb415-3" title="3"><span class="kw">mean</span>(theta.diff1 <span class="op">&lt;</span><span class="dv">0</span>)</a></code></pre></div>
<pre><code>## [1] 0.899677</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb417-1" title="1"><span class="co"># Credible interval for theta[B] - theta[A]</span></a>
<a class="sourceLine" id="cb417-2" title="2"><span class="kw">quantile</span>(theta.diff1, <span class="kw">c</span>(<span class="fl">0.05</span>,<span class="fl">0.95</span>))</a></code></pre></div>
<pre><code>##             5%            95% 
## -0.00131289334  0.00013423126</code></pre>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb419-1" title="1"><span class="kw">quantile</span>(theta.diff1, <span class="kw">c</span>(<span class="fl">0.10</span>,<span class="fl">0.90</span>))</a></code></pre></div>
<pre><code>##            10%            90% 
## -1.0955252e-03  6.5146438e-07</code></pre>
<p><strong>概率論算法</strong></p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb421-1" title="1"><span class="co"># Normal Approximation</span></a>
<a class="sourceLine" id="cb421-2" title="2">diff_mle &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">7000</span>)<span class="op">-</span>(<span class="dv">3</span><span class="op">/</span><span class="dv">5000</span>)</a>
<a class="sourceLine" id="cb421-3" title="3">diff_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">*</span><span class="dv">6999</span><span class="op">/</span><span class="dv">7000</span><span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="dv">4997</span><span class="op">/</span><span class="dv">5000</span><span class="op">^</span><span class="dv">3</span> )</a>
<a class="sourceLine" id="cb421-4" title="4">U &lt;-<span class="st"> </span>diff_mle <span class="op">+</span><span class="st"> </span><span class="fl">1.28</span><span class="op">*</span>diff_se</a>
<a class="sourceLine" id="cb421-5" title="5">L &lt;-<span class="st"> </span>diff_mle <span class="op">-</span><span class="st"> </span><span class="fl">1.28</span><span class="op">*</span>diff_se</a>
<a class="sourceLine" id="cb421-6" title="6"><span class="kw">print</span>(<span class="kw">c</span>(U,L))</a></code></pre></div>
<pre><code>## [1]  0.000022358961 -0.000936644675</code></pre>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb423-1" title="1">norm.app &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(x) <span class="kw">dnorm</span>(x,diff_mle,diff_se))</a></code></pre></div>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb424-1" title="1"><span class="co"># Comparison</span></a>
<a class="sourceLine" id="cb424-2" title="2"><span class="kw">plot</span>(<span class="kw">density</span>(theta.diff0), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">xlim=</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.002</span>,<span class="fl">0.001</span>), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb424-3" title="3"><span class="kw">points</span>(<span class="kw">density</span>(theta.diff1), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb424-4" title="4"><span class="kw">curve</span>(norm.app,<span class="op">-</span><span class="fl">0.0045</span>,<span class="fl">0.002</span>,<span class="dt">add=</span>T,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">n=</span><span class="dv">10000</span>)</a>
<a class="sourceLine" id="cb424-5" title="5"><span class="kw">legend</span>(<span class="op">-</span><span class="fl">0.0021</span>, <span class="dv">1300</span>, <span class="kw">c</span>(<span class="st">&quot;Posterior with B(0,0)&quot;</span>,<span class="st">&quot;Posterior with B(1,1)&quot;</span>,<span class="st">&quot;Frequentist Normal App&quot;</span>), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb424-6" title="6">       <span class="dt">text.col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>),</a>
<a class="sourceLine" id="cb424-7" title="7">       <span class="dt">merge =</span> <span class="ot">TRUE</span>, <span class="dt">bg =</span> <span class="st">&quot;gray90&quot;</span>,<span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb424-8" title="8"><span class="kw">box</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:08-Intro-to-Bayes-36"></span>
<img src="bookdown_files/figure-html/08-Intro-to-Bayes-36-1.png" alt="Comparison of different prior distribution and frequentist approximation" width="80%" />
<p class="caption">
圖 41.20: Comparison of different prior distribution and frequentist approximation
</p>
</div>
</div>
</div>
</div>
<div id="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem" class="section level1">
<h1><span class="header-section-number">第 42 章</span> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</h1>
<blockquote>
<p>… every now and then delightful ideas spring to view; the idea that we shall all be Bayesian by 2020…</p>
<p>– D.V. Lindley (1973)<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</blockquote>
<div id="事後概率的總結方法" class="section level2">
<h2><span class="header-section-number">42.1</span> 事後概率的總結方法</h2>
<p>在貝葉斯統計推斷中，如何總結和報告計算獲得的事後概率分布呢？首先想到的大概是均值 (mean)，因爲均值不論在貝葉斯還是傳統的概率論統計學中都是十分有效的描述數據的一個指標，特別是當後驗概率分布本身是左右對稱的時候。事實上，類似概率論統計學觀點，貝葉斯學派裏中心極限定理同樣是適用的。也就是說，無論先驗概率是怎樣的分布，當收集的樣本足夠多，其事後概率的分布均可被認爲趨近於正態分布:</p>
<ul>
<li><strong>貝葉斯中心極限定理 Bayesian Central limit theorem</strong>:</li>
</ul>
<p><span class="math display">\[
(\frac{\theta - \text{E}[\theta|y]}{\sqrt{\text{Var}(\theta|y)}}) \rightarrow N(0,1)
\]</span></p>
<ul>
<li><strong>貝葉斯後驗概率獨立性定理 Berstein-von Mises theorem: 這條定理說的是，當樣本量十分巨大時，後驗概率其實和 “我們認爲” 的先驗概率之間是相互獨立的。也就是說，數據足夠多的時候，似然本身起到了最主導的作用，先驗概率的取值變得不再那麼重要。</strong></li>
</ul>
<p>所以，當你擁有足夠多的數據的時候，完全可以理直氣壯地直接使用這個中心極限定理，用均值方差就能準確地描述事後概率分布。</p>
<p>除了均值和方差可以用於描述事後概率分布。要記住，在寫報告的時候，我們應當先把事後概率分布給繪制出來，看看實際的圖形是怎樣的，計算一下其四分位數都是些怎樣的數值，如果這些描述提示計算獲得的事後概率分布不能被認爲是左右對稱的時候，僅僅只匯報均值和方差就顯得有些偏頗。如果事後概率分布的密度分布圖告訴我們它並不能用正態分布來近似的話，我們就應該報告包括均值在內的衆數，中位數，以及其他的百分位數，用於更加精確地描述事後概率分布。</p>
<p>除此之外，我們還可以報告可信區間 (credible intervals)。這個可信區間，和信賴區間相似地，是一個有上限和下限的範圍。用 <span class="math inline">\(\alpha \in (0,1)\)</span> 表示我們的可信程度，可信區間 <span class="math inline">\(I\)</span> 的上限和下線分別用 <span class="math inline">\(U, L\)</span> 來表示，那麼用某個參數 <span class="math inline">\(\theta\)</span> 描述的事後概率，以及 <span class="math inline">\(\alpha\)</span> 之間的關系就是:</p>
<p><span class="math display">\[
\text{Pr}(\theta \in I | \text{Data}) = \int_L^U\pi(\theta | \text{Data}) = \alpha
\]</span></p>
<p>但是值得注意的是，和概率論信賴區間的 “一次實驗只計算一個信賴區間” 不同，貝葉斯可以計算完整的事後概率分布曲線，所以整個分布上包含了 95% 曲線下面積我們其實可以獲得無數個不同長度大小的可信區間。在這些許許多多的可信區間裏面，我們可以找到一個上下限之間距離最短的可信區間，名之爲最高密度事後概率區間 (the Highest Posterior Density, HPD interval)。如果事後概率分布是標準正態分布，那麼其 95% HPD 區間就是 <span class="math inline">\((-1.96, 1.96)\)</span>。</p>
</div>
<div id="貝葉斯統計推斷中的正態分布" class="section level2">
<h2><span class="header-section-number">42.2</span> 貝葉斯統計推斷中的正態分布</h2>
<p>本章節我們只考慮最最簡單的情形，方差已知的正態分布數據。在這裏，只有一個參數–均值 <span class="math inline">\(\mu\)</span> ，且我們用另一個方式來標記方差: <span class="math inline">\(y \sim N(\mu, \sigma^2 = \tau^{-1})\)</span>。如果參數 <span class="math inline">\(\mu\)</span> 的先驗概率分布的均值是 <span class="math inline">\(\nu\)</span>，精確度 (precision, 等同於方差的倒數) 是 <span class="math inline">\(\gamma\)</span>。</p>
<p>那麼應用貝葉斯定理推導有:</p>
<p><span class="math display" id="eq:bayes5-1">\[
\begin{aligned}
\text{Posterior} &amp; = \text{Prior}\times\text{likelihood} \\
    \pi(\mu|y)   &amp; = \sqrt{\frac{\gamma}{2\pi}}\text{exp}\{ -\frac{\gamma}{2}(\mu - \nu)^2 \}  \times\sqrt{\frac{\tau}{2\pi}}\text{exp}\{ -\frac{\tau}{2}(y - \mu)^2 \} \\
                 &amp; \propto \text{exp}\{ -\frac{\tau}{2}(y - \mu)^2 - \frac{\gamma}{2}(\mu - \nu)^2\} \\
                 &amp; \propto \text{exp}\{ -\frac{1}{2}[(\tau + \gamma)\mu^2 - 2(\tau y + \nu\gamma)\mu] \} \\
                 &amp; \propto \text{exp}\{ -\frac{(\tau+\gamma)}{2}(\mu - \frac{\tau y + \nu\gamma}{\tau + \gamma})^2 \} \\
                 &amp; \propto N\{ \frac{\tau y+ \gamma\nu}{\tau + \gamma}, \text{precision} = (\tau + \gamma) \}
\end{aligned}
\tag{42.1}
\]</span></p>
<p>可以看出，正態分布本身是自己的共軛分布 (先驗概率分布是正態分布的，事後概率分布也服從正態分布)。事後概率分布的精確度 (precision) 就等於先驗概率的精確度和似然方程的精確度之和。其均值則等於數據本身的均值和先驗概率均值乘以權重之和，其各自的權重分別是彼此精確度在兩個精確度之和中所佔的比例。</p>
<p>現在假設手頭我們收集到的數據服從標準正態分布 <span class="math inline">\(N(\mu=0,\sigma^2 = \tau^{-1} = 1)\)</span>，圖 <a href="#fig:IntroBayes5-1">42.1</a> 展示了四種似然方程，先驗概率，和事後概率分布的組合圖。</p>
<ol style="list-style-type: decimal">
<li>圖 <a href="#fig:IntroBayes5-1">42.1</a> 的左上角中，先驗概率均值，精確度分別是 <span class="math inline">\(\nu = 0, \gamma = 1/16\)</span> (精確度 <span class="math inline">\(1/16\)</span> 等同於標準差等於 <span class="math inline">\(4\)</span>)。可以看出這個先驗概率幾乎對數據提供的似然方程毫無影響。事後概率分布計算的 HPD 可信區間，將會和數據提供的似然方程計算獲得的信賴區間十分地接近 (因爲他們二者的圖形幾乎是重疊的，<strong>不過要記得他們各自的含義不同</strong>)。</li>
<li>圖 <a href="#fig:IntroBayes5-1">42.1</a> 的右上角中，先驗概率均值被設定爲 <span class="math inline">\(\nu = 2\)</span>，精確度不變。可以確認就是和左上角圖顯示的類似，此時的先驗概率對事後概率的分布影響十分有限。</li>
<li>圖 <a href="#fig:IntroBayes5-1">42.1</a> 的左下角中，先驗概率分布的均值和精確度被設定爲 <span class="math inline">\(\nu = 2, \gamma = 1\)</span>，精確度變得和似然方程是相同的，所以，事後概率分布的均值，精確度分別是 <span class="math inline">\(1, 2\)</span>，所以此時事後概率分布的標準差是 <span class="math inline">\(1/\sqrt{2}\)</span>。由於先驗概率分布和數據的似然方程提供的信息旗鼓相當，事後概率分布就落在了二者之間，但是值得注意的是，事後概率分布估計的精確度比似然方程本身好了一些 (數據結合了先驗概率信息，所以用於估計的信息量增加，精確度自然就增加)。</li>
<li>圖 <a href="#fig:IntroBayes5-1">42.1</a> 的右下角中，先驗概率分布變成了主導，因爲它的均值和精確度分別是 <span class="math inline">\(\nu = 3, \gamma = 8\)</span>。可以看到事後概率分布由於先驗概率分布佔據了主導而被先驗概率分布拉向了右邊，此時的數據提供的信息相對先驗概率分布的信息權重較低。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:IntroBayes5-1"></span>
<img src="bookdown_files/figure-html/IntroBayes5-1-1.png" alt="Posterior for the normal distribution, when likelihood is N(0,1) with four different priors" width="90%" />
<p class="caption">
圖 42.1: Posterior for the normal distribution, when likelihood is N(0,1) with four different priors
</p>
</div>
<div id="n-independent-identically-distributed-observations" class="section level3">
<h3><span class="header-section-number">42.2.1</span> <span class="math inline">\(n\)</span> independent identically distributed observations</h3>
<p>假設觀察數據爲:</p>
<p><span class="math display">\[
y_i, \cdots, y_n  \stackrel{i.i.d}{\sim} N(\mu, \sigma^2 = \frac{1}{\tau})
\]</span></p>
<p><span class="math inline">\(\tau\)</span> 依然被定義爲精確度。那麼這組數據的均值的時候概率分布，可以有兩種計算手段:</p>
<ol style="list-style-type: decimal">
<li>利用公式 <a href="#eq:bayes5-1">(42.1)</a>: 根據正態分布的性質 <span class="math inline">\(\bar{y} \sim N(\mu, \frac{\sigma^2}{n} = \frac{1}{n\tau})\)</span>，我們可以直接計算均值的事後概率分布是均值爲 <span class="math inline">\(\frac{n\tau\bar{y} + \gamma\nu}{n\tau + \gamma}\)</span>，精確度爲 <span class="math inline">\(n\tau + \gamma\)</span> 的正態分布;</li>
<li>利用觀察數據推導:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
y_i, \cdots, y_n &amp; \stackrel{i.i.d}{\sim} N(\mu, \sigma^2=\frac{1}{\tau}) \\ 
\Rightarrow \text{The likelihood: }  &amp; (\frac{\tau}{2\pi})^{\frac{n}{2}}\text{exp}\{ -\frac{\tau}{2}\sum_{i=1}^n(y_i - \mu)^2 \} \\
\because \sum_{i=1}^n(y_i - \mu)^2 &amp; = \sum_{i=1}^n(y_i - \bar{y} + \bar{y} - \mu)^2 \\ 
                                   &amp; = \sum_{i=1}^n(y_i - \bar{y})^2 + n(\bar{y} - \mu)^2 \\
                                   &amp; = (n-1)s^2 + n(\bar{y} - \mu)^2 \\ 
\text{Where }                  s^2 &amp; = \frac{(y_i - \bar{y})^2}{n-1} \\
\Rightarrow \text{The   } &amp; \text{likelihood become: } \\
 &amp;  (\frac{\tau}{2\pi})^{\frac{n}{2}}\text{exp}\{ -\frac{\tau}{2}[(n-1)s^2 + n(\bar{y} - \mu)^2] \} \\ 
\text{Ignoring } &amp; \text{terms without }  \mu \\ 
&amp; \text{exp} \{ -\frac{n\tau}{2}(\bar{y} - \mu)^2 \} \\
\Rightarrow \text{Posterior } &amp; \text{mean distribution: }\\ 
&amp; N\{ \frac{n\tau\bar{y} + \gamma\nu}{n\tau + \gamma}, \text{precision} = (n\tau + \gamma) \}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="貝葉斯預測分布" class="section level2">
<h2><span class="header-section-number">42.3</span> 貝葉斯預測分布</h2>
<p>貝葉斯預測分布，是一種在用收集到的數據作爲條件，對未來的觀測作出的條件分布。這其實是在回答一個特別關鍵的問題: “目前爲止我們知道的信息，加上這一次實驗的結果，我們能對未來作什麼樣的預判？”</p>

</div>
</div>



<div id="重要概念複習" class="section level1">
<h1><span class="header-section-number">第 43 章</span> 重要概念複習</h1>
<blockquote>
<dl>
<dt>There are no routine statistical questions, only questionable statistical routines.</dt>
<dd>Sir David Cox
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Generalised Linear Regression lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/frost.chris">Chris Frost</a>.
</div>

<div id="概率論學派統計推斷要點複習" class="section level2">
<h2><span class="header-section-number">43.1</span> 概率論學派統計推斷要點複習</h2>
<p>下面我們一起用二項分佈的概念 (<span class="math inline">\(n\)</span> 個對象中 <span class="math inline">\(K\)</span> 個“事件”)，來複習概率論學派的統計推斷要點。</p>
<ol style="list-style-type: decimal">
<li>模型，the Model。一個統計模型，描述的不僅僅是我們研究的人羣的一些特徵，而且通常一個模型還可提供如何從人羣中收集該樣本的信息。<br> 用二項分佈的概念來解釋，人羣是衆多個體的集合，他們中的一部分佔比 <span class="math inline">\(\pi\)</span> 的人身上發生了某個事件。從這個人羣的集合中，我們隨機抽取 <span class="math inline">\(n\)</span> 個對象作爲<strong>研究樣本</strong>，該樣本中有 <span class="math inline">\(K\)</span> 個人身上發生了事件。此時，我們說 <span class="math inline">\(K\)</span> 服從人羣比例爲 <span class="math inline">\(\pi\)</span> 的二項分佈：<span class="math inline">\(K \sim \text{Bin}(n,\pi)\)</span>。</li>
<li>參數，parameters。模型中的參數反映了人羣的某些特徵。在實際應用中，從來沒有“人類”能知道人羣參數的真實值，渺小的我們從人羣中抽取樣本，用於推斷 “上帝才知道的” 這些代表了人羣特徵的參數。<br> 在二項分佈的情境下，有且只有一個人羣參數，人羣中事件的比例 <span class="math inline">\(\pi\)</span>。</li>
<li>參數估計量，parameter estimators。估計量是樣本的統計量，被用來估計未知的總體參數。估計量 estimator，是一個隨機變量，是我們計算估計值的一般形式。估計值 estimate，是每個樣本通過統計模型計算獲得的估計量的真實值，每採樣一次，計算獲得的估計值理論上會略有不同。<br> 二項分佈的上下文中，人羣事件比例 – 這一參數 <span class="math inline">\(\pi\)</span> 的天然估計量是 <span class="math inline">\(\hat\pi = \frac{K}{n}\)</span>，當一個樣本中發現 <span class="math inline">\(K = k\)</span>，該樣本給出的估計值是 <span class="math inline">\(\frac{k}{n}\)</span>。</li>
<li>研究假設，hypotheses。研究假設是實驗前我們提出的要被檢驗的一些關於人羣某些特徵參數的 “陳述 statement”。可以是猜想參數等於某個特定值，或者多個參數大小相同。<br> 二項分佈的數據裏，只有一個人羣參數，<span class="math inline">\(\pi\)</span>。可能提出的零假設和替代假設有很多，<span class="math inline">\(\pi = 0.5 \text{ v.s. } \pi \neq 0.5\)</span> 是其中之一的複合型假設。</li>
</ol>
</div>
<div id="似然" class="section level2">
<h2><span class="header-section-number">43.2</span> 似然</h2>
<p>如果一個模型只有一個參數 <span class="math inline">\(\theta\)</span>，樣本數據已知的話，該參數的似然爲：</p>
<p><span class="math display">\[\text{L}(\theta | \text{data}) = \text{Pr}(\text{data}|\theta)\]</span></p>
<p>其中，<span class="math inline">\(\text{Pr}(\text{data}|\theta)\)</span> 對於離散型變量，是概率方程 probability function；對於連續型變量，則是概率密度方程 probability density function (PDF)。</p>
<p>對數似然，就是上面的似然方程取自然底數的對數方程：</p>
<p><span class="math display">\[\ell(\theta | \text{data}) = \text{ln}\{ \text{L}(\theta | \text{data}) \}\]</span></p>
</div>
<div id="極大似然估計" class="section level2">
<h2><span class="header-section-number">43.3</span> 極大似然估計</h2>
<p>當數據收集完畢，從獲得的數據中計算獲得的能夠使似然方程/或對數似然方程取得極大值的 <span class="math inline">\(\theta\)</span> 的大小，被叫做極大似然估計 <span class="math inline">\(\text{(MLE)}\)</span>，且通常數學標記會在參數上加一頂帽子： <span class="math inline">\(\hat\theta\)</span>。收集不同的樣本，在相同的似然方程或對數似然方程下，極大似然估計不同。</p>
<ol style="list-style-type: decimal">
<li>許多問題，我們獲得極大似然估計的方法是先定義好模型的似然方程，然後求該方程的一階導數之後計算使之等於零的參數值大小就是 <span class="math inline">\(\text{MLE } \hat\theta\)</span>。此時，你還要記得再求一次二階導數，看是否小於零，以確保前一步計算獲得的值給出的似然方程是極大值。</li>
<li>更多的時候我們用對數似然方程以簡化計算過程：</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\left.\frac{\text{d}}{\text{d } \theta}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &amp;= \ell^\prime(\hat\theta) = 0 \\
\left.\frac{\text{d}^2}{\text{d } \theta^2}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &amp;= \ell^{\prime\prime}(\hat\theta) &lt; 0
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>我們只關心似然方程的形狀，所以方程中不包含參數的部分可全部忽略掉。</li>
<li><span class="math inline">\(\text{MLE}\)</span> 的一些關鍵性質：
<ol style="list-style-type: decimal">
<li>漸進無偏 asymptotically unbiased：當 <span class="math inline">\(n\rightarrow \infty\)</span> 時，<span class="math inline">\(E(\hat\theta) \rightarrow \theta\)</span>；</li>
<li>一致性 consistency：隨着樣本量的增加，<span class="math inline">\(\hat\theta\)</span> 收斂於 (converges) 總體參數 <span class="math inline">\(\theta\)</span>；</li>
<li>漸進正態分佈 asymptotically normality：隨着樣本量增加，<span class="math inline">\(\hat\theta\)</span> 的樣本分佈收斂於 (converges) 正態分佈，方差爲 <span class="math display">\[E[-\ell^{\prime\prime}(\theta)]^{-1}=[-\ell^{\prime\prime}(\hat\theta)]^{-1}\]</span></li>
<li>恆定性 invariance：如果 <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(\text{MLE}\)</span>，那麼 <span class="math inline">\(\theta\)</span> 被數學轉換以後 <span class="math inline">\(g(\theta)\)</span> 的方程的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(g(\hat\theta)\)</span></li>
</ol></li>
<li>似然理論可以直接拓展到多個參數的情況。一般地，如果一個模型有 <span class="math inline">\(p\)</span> 個參數 <span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T\)</span>，這些參數在給定數據的條件下的似然方程爲：<span class="math display">\[\text{L}(\mathbf{\theta} | \text{data}) = \text{Pr}(\text{data} | \mathbf{\theta})\]</span> 其中，概率 (密度) 方程在多個參數時變成聯合 (joint) 概率 (密度) 方程。似然，也是各個參數的聯合似然方程。此時，參數向量 <span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T\)</span> 的方差協方差矩陣的估計量爲：</li>
</ol>
<p><span class="math display">\[
\hat{\text{Var}}(\mathbf{\hat\theta}) = - \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)^{-1}_{\theta=\hat\theta}
\]</span></p>
<p>Tips: typing <code>vcov(Modelname)</code> command in R will display this estimated variance-covariance matrix for the parameter estimates.</p>
<p>回到二項分佈數據的例子：</p>
<p><span class="math display">\[
K \sim \text{Bin}(n, \pi)
\]</span></p>
<p>如果我們樣本的觀測數據是 <span class="math inline">\(K=k\)</span>，對數似然方程一次微分等於零以後求得的參數 <span class="math inline">\(\pi\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\pi = \frac{k}{n}\)</span>。所以參數 <span class="math inline">\(\pi\)</span> 的估計量是 <span class="math inline">\(\frac{K}{n}\)</span>。<span class="math inline">\(\hat\pi\)</span> 的方差估計量是：</p>
<p><span class="math display">\[
\hat{\text{Var}} (\hat\pi) = \frac{\hat\pi(1-\hat\pi)}{n} \text{ for } \hat\pi = \frac{k}{n}
\]</span></p>
</div>
<div id="關於假設檢驗的複習" class="section level2">
<h2><span class="header-section-number">43.4</span> 關於假設檢驗的複習</h2>
<p>極大似然估計可以有三大類檢驗方法：似然比檢驗法 likelihood ratio test；Wald 檢驗 Wald test；Score 檢驗 Score test。</p>
<ul>
<li>似然比檢驗法 likelihood ratio test (LRT) (Section <a href="#LRT">16.2</a>)：</li>
</ul>
<p><span class="math display">\[
-2llr(\theta_0) = -2\{ \ell(\theta_0) - \ell(\hat\theta) \}
\]</span></p>
<p>零假設條件下 (Under <span class="math inline">\(\text{H}_0\)</span>:)</p>
<p><span class="math display">\[
-2llr(\theta_0) \sim \chi_1^2
\]</span></p>
<p>這個對數似然比的統計量可以和自由度爲 1 的卡方分佈作比較，計算反對零假設的證據的強度大小。如果顯著性水平是 <span class="math inline">\(\alpha\)</span>，那麼下面條件成立時，可以認爲反對零假設的證據強度大到足以拒絕零假設。</p>
<p><span class="math display">\[
-2llr(\theta_0) &gt; \chi^2_{1, 1-\alpha}
\]</span></p>
<ul>
<li>Wald 檢驗 (Section <a href="#Wald">16.4</a>) 是一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
  (\frac{M-\theta_0}{S})^2 &amp; \sim \chi^2_1 \\
 \text{Where } M  &amp; = \hat\theta \\
              S^2 &amp; = \frac{1}{-\ell^{\prime\prime}(\hat\theta)}
\end{aligned}
\]</span></p>
<ul>
<li>Score 檢驗 (Section <a href="#Score">16.5</a>) 是另一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\frac{U^2}{V} &amp; \sim \chi^2_1 \\
\text{Where } U  &amp; = \ell^\prime(\theta_0) \\
             V &amp; = -\ell^{\prime\prime}(\theta_0)
\end{aligned}
\]</span></p>
<p>如果對數似然方程本身就是一個二次方程 (數據服從完美正態分佈狀態，且總體方差已知時)，這三大類的檢驗法其實計算獲得完全一樣的 <span class="math inline">\(p\)</span> 值，提供完全一致的證據。多數情況下，三大類檢驗法的結果是近似的。關於三種檢驗法的比較可以參考過去總結的章節 (Section <a href="#LRTwaldScore-Compare">16.6</a>)</p>
<div id="子集似然函數" class="section level3">
<h3><span class="header-section-number">43.4.1</span> 子集似然函數</h3>
<p>當統計模型中的部分參數是噪音參數 (nuisance parameters) 時，我們需要用到子集似然函數法 (Section <a href="#profile-log-likelihood">19</a>) 來去除噪音參數的影響,，只檢驗我們感興趣的那部分參數。</p>
</div>
</div>
<div id="線性迴歸複習" class="section level2">
<h2><span class="header-section-number">43.5</span> 線性迴歸複習</h2>
<div id="簡單線性迴歸" class="section level3">
<h3><span class="header-section-number">43.5.1</span> 簡單線性迴歸</h3>
<p>假設對於 <span class="math inline">\(n\)</span> 名研究對象，我們測量個兩個觀測值 <span class="math inline">\((y_i, x_i)\)</span>，那麼用線性迴歸模型來表示這兩個測量值估計的參數之間的關係就是：</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;  = \alpha + \beta x_i + \varepsilon_i \\
\text{Where } &amp; \varepsilon_i \sim \text{NID}(0,1)
\end{aligned}
\]</span></p>
<p>或者用另一個標記法：</p>
<p><span class="math display">\[
Y_i | x_i \sim N(\alpha + \beta x_i, \sigma^2)
\]</span></p>
</div>
<div id="多元線性迴歸" class="section level3">
<h3><span class="header-section-number">43.5.2</span> 多元線性迴歸</h3>
<p>如果預測變量有兩個或者兩個以上 <span class="math inline">\((x_i, \;\&amp;\; z_i)\)</span>，那麼描述這兩個預測變量和因變量之間的多元線性迴歸模型可以寫作：</p>
<p><span class="math display">\[
y_i = \alpha + \beta x_i + \gamma z_i + \varepsilon_i
\]</span></p>
<p>此時， <span class="math inline">\(\beta\)</span> 的含義是，當保持 <span class="math inline">\(z\)</span> 不變時，<span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量。用這個模型，我們默認 <span class="math inline">\(z\)</span> 保持不變的同時無論取值爲多少， <span class="math inline">\(x, y\)</span> 之間的關係是不會變化的，我們用這個模型來調整 (adjust) <span class="math inline">\(z\)</span> 的混雜效應 (confounding effect) (Section <a href="#confounding">29.5</a>)。</p>
<p>當然我們也可以考慮當 <span class="math inline">\(z\)</span> 取值不同時， <span class="math inline">\(x, y\)</span> 之間的關係發生改變，只要在上面的多元線性迴歸方程中加入一個交互作用項即可 (Section <a href="#interaction">32</a>)。</p>
<p><span class="math display">\[
y_i = \alpha + \beta x_i + \gamma z_i + \delta x_i z_i + \varepsilon_i
\]</span></p>
<p>增加了交互作用項最大的變化是，<span class="math inline">\(x_i\)</span> 的迴歸係數 <span class="math inline">\(\beta\)</span> 的含義發生了改變：當且僅當 <span class="math inline">\(z = 0\)</span> 且保持不變時，<span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量。如果 <span class="math inline">\(z = k \neq 0\)</span> 且保持不變，那麼 <span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量則是 <span class="math inline">\(\beta + k\delta\)</span>。</p>
</div>
<div id="score-equations" class="section level3">
<h3><span class="header-section-number">43.5.3</span> 簡單線性迴歸的統計推斷</h3>
<p>一個給定的樣本 <span class="math inline">\((y_i, x_i), i = 1, \cdots, n\)</span> ，其對數似然方程是</p>
<p><span class="math display">\[
\ell(\alpha, \beta, \sigma^2 | \mathbf{y, x}) = -\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \alpha - \beta x_i)^2
\]</span></p>
<p>分別對 <span class="math inline">\(\alpha, \beta\)</span> 求微分之後可以獲得他們各自的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
U(\alpha) &amp; = \ell^\prime(\alpha) = \frac{1}{\sigma^2}\sum_{i=1}^n (y_i - \alpha - \beta x_i) \\
U(\beta)  &amp; = \ell^{\prime}(\beta) = \frac{1}{\sigma^2}\sum_{i=1}^n x_i(y_i - \alpha - \beta x_i) \\
U(\hat\alpha) &amp; = 0 \Rightarrow \hat\alpha = \bar{y} - \hat\beta\bar{x} \\
U(\hat\beta)  &amp; = 0 \Rightarrow \hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2} = \frac{\sum x_iy_i - n\bar{x}\bar{y}}{\sum x_i^2 - n\bar{x}^2}
\end{aligned}
\]</span></p>
<p>注意到和線性迴歸章節中推導的過程不同 (Section <a href="#MLEalphabeta">26.4.1</a>)，當時我們用的是最小二乘法，這裏我們用的是光明正大的極大似然法，同時也證明了最小二乘法獲得的 <span class="math inline">\(\hat\alpha,\hat\beta\)</span> 是他們各自的 <span class="math inline">\(\text{MLE}\)</span>。</p>
<p>另外，殘差方差的 <span class="math inline">\(\text{MLE}\)</span> 也可以用上面的方法推導出來，同樣和之前的方法 (Section <a href="#ResidualVar">26.5</a>) 做個對比吧：</p>
<p><span class="math display">\[
\begin{aligned}
U(\sigma^2) &amp; = \ell^\prime(\sigma^2) = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n(y_i - \alpha - \beta x_i)^2 \\
U(\hat\sigma^2) = 0 &amp; \Rightarrow \hat\sigma^2 = \frac{\sum_{i=1}^n(y_i - \hat\alpha - \hat\beta x_i)^2}{n}
\end{aligned}
\]</span></p>
<p>這個殘差方差的 <span class="math inline">\(\text{MLE}\)</span> 其實不是一個無偏估計，它只是一個漸進無偏的估計 (需要除以 <span class="math inline">\(\frac{n-2}{n}\)</span>)，所以，當一個線性迴歸模型中有 <span class="math inline">\(p\)</span> 個參數時：</p>
<p><span class="math display">\[
\hat\sigma^2 = \frac{\sum_{i=1}^n(y_i - \hat\alpha - \hat\beta_1 x_{i1} - \hat\beta_2 x_{i2}\cdots)^2}{n - p}
\]</span></p>
<p>線性迴歸時殘差方差的檢驗統計量服從 <span class="math inline">\(F\)</span> 分佈 (Section <a href="#lm-Ftest">28.2.6</a>)。</p>
</div>
</div>
<div id="glm-practical-01" class="section level2">
<h2><span class="header-section-number">43.6</span> GLM-Practical 01</h2>
<div id="建立似然方程" class="section level3">
<h3><span class="header-section-number">43.6.1</span> 建立似然方程</h3>
<p>對下列不同的情形，寫下其</p>
<ol style="list-style-type: decimal">
<li>統計學模型</li>
<li>指明模型中的參數</li>
<li>推導該參數的對數似然方程</li>
</ol>
<div id="在-n-名對象中觀察到-k-個事件" class="section level4">
<h4><span class="header-section-number">43.6.1.1</span> 在 <span class="math inline">\(n\)</span> 名對象中觀察到 <span class="math inline">\(k\)</span> 個事件。</h4>
<ol style="list-style-type: decimal">
<li>統計學模型: <span class="math inline">\(K\)</span> 是隨機變量，指代事件的數量，<span class="math inline">\(K \sim \text{Bin}(n, \pi)\)</span>。每個觀察個體中發生事件的概率相互獨立且相同。</li>
<li>模型參數: <span class="math inline">\(\pi\)</span> 是模型參數，指代事件發生的概率。</li>
<li>對數似然的推導</li>
</ol>
<ul>
<li>概率方程 (probability function):</li>
</ul>
<p><span class="math display">\[
\text{Pr}(K = k) = \binom{n}{k}\pi^k(1-\pi)^{n-k}, k = 0,1,\cdots,n
\]</span></p>
<ul>
<li>似然方程 (likelihood function):</li>
</ul>
<p><span class="math display">\[
L(\pi|k) = \binom{n}{k}\pi^k(1-\pi)^{n-k}, 0&lt;\pi&lt;1
\]</span></p>
<ul>
<li>對數似然方程 (log-likelihood function):</li>
</ul>
<p><span class="math display">\[
\ell(\pi|k) = k\log\pi + (n-k)\log(1-\pi) + \text{terms not involving } \pi, 0&lt;\pi&lt;1
\]</span></p>
</div>
<div id="測量-n-名研究對象的總膽固醇濃度-mmoll已知人羣中總膽固醇的測量值呈正態分布且方差爲-4-mmoll2" class="section level4">
<h4><span class="header-section-number">43.6.1.2</span> 測量 <span class="math inline">\(n\)</span> 名研究對象的總膽固醇濃度 (mmol/l)，已知人羣中總膽固醇的測量值呈正態分布且方差爲 <span class="math inline">\(4\)</span> (mmol/l)<sup>2</sup>。</h4>
<ol style="list-style-type: decimal">
<li>統計學模型: 用 <span class="math inline">\(Y_i\)</span> 表示每個個體測量獲得的總膽固醇濃度值。它們是獨立同分布的隨機變量 (independent and indentically distributed, i.i.d. random variables): <span class="math inline">\(Y_i \sim N(\mu, 2^2 = 4)\)</span>。</li>
<li>模型參數: 總體均值 <span class="math inline">\(\mu\)</span>。</li>
<li>對數似然的推導:</li>
</ol>
<ul>
<li>概率密度方程 (probability density function):</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
f(y_1, \cdots, y_n) &amp; = f(\mathbf{y}|\mu) = \prod_{i = 1}^n f(y_i | \mu) \\
                    &amp; = \prod_{i=1}^n \frac{1}{\sqrt{2\pi2^2}}e^{-0.5(\frac{y_i-\mu}{2})^2} \\
                    &amp; = [\frac{1}{\sqrt{2\pi2^2}}]^ne^{-0.5\sum_{i=1}^n(\frac{y_i-\mu}{2})^2} \\
                    &amp; -\infty &lt; y_i &lt; + \infty
\end{aligned}
\]</span></p>
<ul>
<li>對數似然方程 (log-likelihood function):</li>
</ul>
<p><span class="math display">\[
\ell(\mu|\mathbf{y}) = -\frac{1}{2\times2^2}\sum_{i=1}^n(y_i - \mu)^2 + \text{terms not involving } \mu, -\infty &lt; \mu &lt; + \infty
\]</span></p>
</div>
</div>
<div id="建立對數似然方程" class="section level3">
<h3><span class="header-section-number">43.6.2</span> 建立對數似然方程</h3>
<p>對下列不同的情形，寫下其</p>
<ol style="list-style-type: decimal">
<li>參數的對數似然方程</li>
<li>推導極大似然估計</li>
<li>計算極大似然估計量</li>
<li>繪制對數似然方程的示意圖</li>
</ol>
<div id="在-10-名研究對象中觀察到-3-個事件" class="section level4">
<h4><span class="header-section-number">43.6.2.1</span> 在 10 名研究對象中觀察到 3 個事件</h4>
<ol style="list-style-type: decimal">
<li>對數似然方程是</li>
</ol>
<p><span class="math display">\[
\ell(\pi) = k\log\pi + (n-k)\log(1-\pi)
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>極大似然估計的推導</li>
</ol>
<p><span class="math display">\[
\ell^\prime(\pi) = 0 \Rightarrow \frac{k}{\pi} - \frac{n-k}{1-\pi} = 0 \\
\Rightarrow \hat\pi = \frac{k}{n}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>極大似然估計量 <span class="math inline">\(\hat\pi = 3/10 = 0.3\)</span></p></li>
<li><p>繪制對數似然方程的示意圖</p></li>
</ol>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb425-1" title="1">pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.0001</span>)</a>
<a class="sourceLine" id="cb425-2" title="2">likelihood &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="kw">log</span>(pi) <span class="op">+</span><span class="st"> </span><span class="dv">7</span><span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>pi)</a>
<a class="sourceLine" id="cb425-3" title="3"><span class="kw">plot</span>(pi, likelihood, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">40</span>, <span class="dv">0</span>), <span class="dt">frame.plot =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb425-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;log-likelihood(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:llr-GLM-exe01"></span>
<img src="bookdown_files/figure-html/llr-GLM-exe01-1.png" alt="Log-likelihood for binomial model." width="90%" />
<p class="caption">
圖 43.1: Log-likelihood for binomial model.
</p>
</div>
</div>
<div id="名研究對象測量的總膽固醇濃度分別是-6.0-6.2-6.8-5.3-5.9-6.1-6.0-7.0-5.9-6.3已知人羣中總膽固醇值服從方差爲-4-mmoll2-的正態分布" class="section level4">
<h4><span class="header-section-number">43.6.2.2</span> 10名研究對象測量的總膽固醇濃度分別是 6.0, 6.2, 6.8, 5.3, 5.9, 6.1, 6.0, 7.0, 5.9, 6.3。已知人羣中總膽固醇值服從方差爲 4 (mmol/l)<sup>2</sup> 的正態分布。</h4>
<ol style="list-style-type: decimal">
<li>對數似然方程是:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\ell(\mu) &amp; = -\frac{1}{2\times2^2}\sum_{i=1}^{10} (Y_i - \mu)^2 \\
          &amp; = -\frac{1}{8}\sum_{i=1}^{10} (Y_i - \bar{y} + \bar{y} - \mu)^2 \\
          &amp; = -\frac{1}{8}\sum_{i=1}^{10} (\bar{y} - \mu)^2 \\
          &amp; = -\frac{10}{8}(\bar{y} - \mu)^2
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>極大似然估計，和極大似然估計量是:</li>
</ol>
<p><span class="math display">\[
\ell^\prime(\mu) = 0 \Rightarrow \hat\mu = \bar{y} = 6.15
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>繪制對數似然方程的示意圖</li>
</ol>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb426-1" title="1">mu &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">5</span>,<span class="dv">7</span>, <span class="dt">by =</span> <span class="fl">0.0001</span>)</a>
<a class="sourceLine" id="cb426-2" title="2">likelihood &lt;-<span class="st"> </span><span class="op">-</span>(<span class="dv">5</span><span class="op">/</span><span class="dv">4</span>)<span class="op">*</span>(<span class="fl">6.16</span><span class="op">-</span>mu)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb426-3" title="3"><span class="kw">plot</span>(mu, likelihood, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">1.8</span>, <span class="dv">0</span>), <span class="dt">frame.plot =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb426-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;log-likelihood(\U03BC)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03BC&quot;</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:llr-GLM-exe02"></span>
<img src="bookdown_files/figure-html/llr-GLM-exe02-1.png" alt="Log-likelihood for normal model" width="90%" />
<p class="caption">
圖 43.2: Log-likelihood for normal model
</p>
</div>
</div>
</div>
<div id="線性回歸模型" class="section level3">
<h3><span class="header-section-number">43.6.3</span> 線性回歸模型</h3>
<p>某項RCT臨牀實驗的目的是比較注射嗎啡和安慰劑哪個對患者的精神醫學指徵的改變更加有效。每個實驗組隨機分配到24名患者，精神醫學指徵使用某種心理調查問卷，問卷有七道題，患者七道題的總得分被用於評價其精神醫學指徵，的分越高，指徵越明顯。下表是這兩組患者在注射相應藥物兩小時之後答題的的分:</p>
<div class="figure" style="text-align: center"><span id="fig:GLMexer1-3"></span>
<img src="img/Selection_122.png" alt="Mental activity scores recorded 2 hours after injection of the drug." width="90%" />
<p class="caption">
圖 43.3: Mental activity scores recorded 2 hours after injection of the drug.
</p>
</div>
<p>下面是 STATA 的計算結果，</p>
<p><img src="img/Selection_123.png" width="90%" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>寫下該模型的數學表達式，陳述該模型中用到的所有假設和前提條件。用手頭的計算器手動計算該簡單線性回歸模型的截距和斜率，確定你的結果和STATA的結果是一樣的。</li>
</ol>
<p><span class="math inline">\(Y_i\)</span> 用來表示第 <span class="math inline">\(i\)</span> 名對象的精神醫學指徵問卷的得分。該模型可以寫作:</p>
<p><span class="math inline">\(Y_1, Y_2, \cdots, Y_{48}\)</span> 是 48 個獨立同分布的隨機變量，且 <span class="math inline">\(Y_i \sim N(\mu, \sigma^2)\)</span>
<span class="math display">\[
y_i = \alpha + \beta x_i \text{ for } x_i = \left\{ \begin{array}{ll}  0 \text{ placebo}\\  1 \text{ morphine}\\ \end{array} \right.
\]</span></p>
<p>從表格數據中可得 <span class="math inline">\(\bar{x} = 0.5, \sum x_i^2 = 24, \bar{y}=4.604, \sum x_iy_i=88\)</span>，利用之前 <a href="#score-equations">43.5.3</a> 復習的簡單線性回歸公式:</p>
<p><span class="math display">\[
\hat\alpha = 5.542 \\
\hat\beta = -1.875
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>解釋截距和斜率的實際意義:</li>
</ol>
<ul>
<li><span class="math inline">\(\hat\alpha\)</span> 是安慰劑組的平均精神醫學指徵得分;</li>
<li><span class="math inline">\(\hat\beta\)</span> 是注射嗎啡組和安慰劑組兩組之間得分均值之差。</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>實驗研究同時還測量了兩組在注射藥物之前的精神醫學指徵得分，下面是在 STATA 裏對該數據進行擬合的另一個模型。其中 <code>prement</code> 是藥物注射前得分的變量:</li>
</ol>
<p><img src="img/Selection_124.png" width="90%" style="display: block; margin: auto;" /></p>
<ol start="4" style="list-style-type: decimal">
<li>寫下這個模型的數學表達式，並且解釋你會用怎樣的方法求各個參數的 MLE。</li>
</ol>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \beta_2 z_i + \beta_{12}x_iz_i \\
 \text{ for } x_i = \left\{ \begin{array}{ll}  0 \text{ placebo}\\  1 \text{ morphine}\\ \end{array} \right.
\]</span></p>
<p>該模型的對數似然方程是</p>
<p><span class="math display">\[
\ell(\beta_0, \beta_1, \beta_2, \beta_{12} | \mathbf{y, z, x}) = -\frac{1}{2\sigma^2}\sum_{i=1}^{48}(y_i - \beta_0 - \beta_1x_i - \beta_2z_i - \beta_{12}x_iz_i)^2
\]</span></p>
<p>把上面的對數似然方程等於零以後依次對 <span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_{12}\)</span> 求偏微分即可求得各自的 MLE。</p>
<ol start="5" style="list-style-type: decimal">
<li>解釋各參數估計的實際意義</li>
</ol>
<ul>
<li><span class="math inline">\(\hat\beta_0 =\)</span> <code>_cons</code> <span class="math inline">\(=1.978\)</span> 是<strong>當且僅當治療前得分爲零時</strong>，模型對安慰劑組得分均值的估計;</li>
<li><span class="math inline">\(\hat\beta_1 =\)</span> <code>2.treat</code> <span class="math inline">\(=-1.212\)</span> 是<strong>當且僅當治療前得分爲零時</strong>，嗎啡組和安慰劑組之間得分均值之差;</li>
<li><span class="math inline">\(\hat\beta_2 =\)</span> <code>prement</code> <span class="math inline">\(=0.594\)</span> 是<strong>對照組中，治療前得分每增加一個單位</strong>，治療後得分的變化;</li>
<li><span class="math inline">\(\hat\beta_{12} =\)</span> <code>2.treat#c.prement</code> <span class="math inline">\(=-0.0895\)</span> 是嗎啡組和安慰劑組兩組之間回歸斜率之差，也就是說
<span class="math display">\[\hat\beta_2 + \hat\beta_{12} = 0.505\]</span>
是<strong>嗎啡組中，治療錢得分沒增加一個單位</strong>，治療後得分的變化。</li>
</ul>
</div>
<div id="似然比檢驗wald-檢驗score-檢驗" class="section level3">
<h3><span class="header-section-number">43.6.4</span> 似然比檢驗，Wald 檢驗，Score 檢驗</h3>
<p>從服從正態分布 <span class="math inline">\(N(\mu, 1)\)</span> 的總體中抽樣 <span class="math inline">\(n\)</span> 個樣本，他們相互獨立同分布 (i.i.d)。推導用這個模型時的三種檢驗方法的檢驗統計量，證明在此特殊情況下，三種檢驗方法的檢驗統計量完全一致。</p>
<p>該數據的對數似然是</p>
<p><span class="math display">\[
\ell(\mu) = -\frac{1}{2}\sum_{i=1}^n(y_i - \mu)^2
\]</span></p>
<ol style="list-style-type: decimal">
<li>似然比檢驗 likelihood ratio test</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
-2llr &amp; = -2(\ell(\mu_0 - \ell(\hat\mu))) \\
      &amp; = -2(-\frac{1}{2}\sum_{i=1}^n(y_i - \mu_0)^2 + \frac{1}{2}\sum_{i=1}^n(y_i - \bar{y})^2) \\
      &amp; = \sum_{i=1}^n[(y_i - \mu_0)^2 - (y_i - \bar{y})^2] \\
      &amp; = \sum_{i=1}^n(y_i^2 + \mu_0^2 - 2\mu_0y_i - y_i^2 - \bar{y}^2 + 2\bar{y}y_i) \\
      &amp; = n(\mu_0^2 - 2\mu_0\bar{y} + \bar{y}^2) \\
      &amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Wald 檢驗:</li>
</ol>
<p>對數似然的一階導數和二階導數分別是:</p>
<p><span class="math display">\[
\ell^\prime = -\frac{1}{2}\sum_{i=1}^n-2(y_i-\mu) = \sum_{i=1}^n(y_i - \mu) \\
\ell^{\prime\prime} = -n
\]</span></p>
<p>所以，Fisher information <span class="math inline">\(S^2 = n^{-1}\)</span>，<span class="math inline">\(M = \hat\mu = \bar{y}\)</span>，</p>
<p><span class="math display">\[
\begin{aligned}
W^2 &amp; = (\frac{M - \theta_0}{S})^2 \\
    &amp; = (\frac{(\bar{y} - \mu_0)^2}{n^{-1}}) \\
    &amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Score 檢驗</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\frac{\ell^\prime(\mu_0)^2}{-\ell^{\prime\prime}(\mu_0)} &amp; = \frac{(n\bar{y} - n\mu_0)^2}{n}  \\
&amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<p>所以，在方差已知，均值未知，總體服從正態分布的數據條件下，三種檢驗方法獲得的實際檢驗統計量是完全一致的。</p>
</div>
</div>
</div>
<div id="廣義線性迴歸入門" class="section level1">
<h1><span class="header-section-number">第 44 章</span> 廣義線性迴歸入門</h1>
<p>線性迴歸方法是十分強大的建模工具，可惜的是它只能適用與因變量爲連續型變量的情況。廣義線性迴歸模型 (或者叫一般化線性迴歸模型 generalised linear models, GLM) 是一大類將線性迴歸模型拓展到因變量可以使用二分類，計數，分組型變量的建模工具。</p>
<div id="指數分佈家族" class="section level2">
<h2><span class="header-section-number">44.1</span> 指數分佈家族</h2>
<p>一個服從正態分佈的隨機變量 <span class="math inline">\(Y\)</span> 的概率密度方程 (probability density function, PDF) 可以寫作</p>
<p><span class="math display">\[
f(y) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y-\mu)^2}{2\sigma^2}}
\]</span></p>
<p>給 PDF 的左右兩邊同時取自然底數的對數，方程變形爲</p>
<p><span class="math display" id="eq:glm2-0">\[
\begin{aligned}
\text{ln}\{f(y)\} &amp; = -\frac{y^2}{2\sigma^2} + \frac{y\cdot\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2} -\frac{1}{2}\text{ln}(2\pi\sigma^2) \\
                &amp; = \frac{y\cdot\mu - \frac{\mu^2}{2}}{\sigma^2} - [\frac{y^2}{2\sigma^2} + \frac{1}{2}\text{ln}(2\pi\sigma^2) ]
\end{aligned}
\tag{44.1}
\]</span></p>
<p>如果令</p>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; = \mu  \\
\psi   &amp; = \sigma^2 \\
b(\theta) &amp; = \frac{\mu^2}{2} \\
c(y, \theta) &amp; = \frac{y^2}{2\sigma^2} + \frac{1}{2}\text{ln}(2\pi\sigma^2)
\end{aligned}
\]</span></p>
<p>那麼上面的式子 <a href="#eq:glm2-0">(44.1)</a> 可以被整理爲：</p>
<p><span class="math display" id="eq:glm2-1">\[
\begin{equation}
\text{ln}\{f(y)\} = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta)
\end{equation}
\tag{44.2}
\]</span></p>
<p><strong>此處有重要結論：</strong> 凡是分佈的概率密度方程的對數方程能夠轉換整理成 <a href="#eq:glm2-1">(44.2)</a> 形式的分佈，都隸屬於指數分佈家族 (the Exponential Family of distributions)。</p>
<div id="泊松分佈和二項分佈的指數分佈家族屬性" class="section level3">
<h3><span class="header-section-number">44.1.1</span> 泊松分佈和二項分佈的指數分佈家族屬性</h3>
<ul>
<li>泊松分佈 Poisson Distribution</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
     f(y) &amp; = \text{Pr}(Y = y) = \frac{\mu^y e^{-\mu}}{y!}, y = 0,1,2,\cdots \\
\text{ln}\{ f(y) \} &amp; = y\cdot\text{ln}(\mu) - \mu - \text{ln}(y!) \\
\text{Let } &amp;\color{red}{\boxed{\theta = \text{ln}(\mu), \psi = 1, b(\theta) = \mu, c(y,\psi) = \text{ln}(y!)}} \\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta) \\
\end{aligned}
\]</span></p>
<p>所以，<strong>泊松分佈屬於指數分佈家族成員</strong>。</p>
<ul>
<li>二項分佈 Binommial Distribution</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
f(y) &amp; = \text{Pr}(Y = y) = \binom{n}{y}\pi^y(1-\pi)^{n-y}, y = 0,1,2,\cdots\\
\text{ln}\{ f(y) \} &amp; = y\cdot \text{ln}(\pi) + (n - y)\text{ln}(1-\pi) + \text{ln}\{\binom{n}{y}\} \\
                    &amp; = y\cdot \text{ln}(\frac{\pi}{1-\pi}) + n\text{ln}(1-\pi) +  \text{ln}\{\binom{n}{y}\} \\
\text{Let } &amp;\color{red}{\boxed{\theta = \text{ln}(\frac{\pi}{1-\pi}), \psi = 1,}} \\
            &amp;\color{red}{\boxed{b(\theta) = -n\text{ln}(1-\pi), c(y, \psi) = -\text{ln}\{\binom{n}{y}\}}}\\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta) \\
\end{aligned}
\]</span></p>
<p>所以，<strong>二項分佈也屬於指數分佈家族成員</strong>。</p>
<p>指數分佈家族成員的數學表達式 <a href="#eq:glm2-1">(44.2)</a> 中，</p>
<ul>
<li><span class="math inline">\(\theta\)</span> 被叫做標準 (或者叫自然) 參數 (<strong>canonical or natural parameter</strong>)，相關的函數被叫做標準鏈接函數 (canonical link function)，如上面所列舉的例子中：泊松分佈時用的對數函數 <span class="math inline">\(\text{ln}(\mu)\)</span>，二項分佈時用的邏輯函數 (logit function) <span class="math inline">\(\text{ln}(\frac{\pi}{1-\pi})\)</span>，鏈接函數可能還有別的選擇，(例如，二項分佈數據的另一種標準鏈接函數是概率函数 (probit function <span class="math inline">\(\Phi^{-1}(P)\)</span>))，同時它對於條件推斷 conditional inference 至關重要，因爲它還提示我們應該用什麼樣的算法去估計我們苦苦尋找的人羣參數。</li>
<li><span class="math inline">\(\phi\)</span> 被命名爲<strong>尺度參數 (scale or dispersion parameter)</strong>，泊松分佈和二項分佈的尺度參數是 <span class="math inline">\(1\)</span>。但是正態分佈的尺度參數是方差 <span class="math inline">\(\sigma^2\)</span>，且常常是未知的，需要從樣本數據中估計。尺度參數是否需要從樣本中獲取其估計值，對於實際統計推斷或者假設檢驗的過程有重大影響。</li>
</ul>
<p>廣義線性迴歸就是這個指數分佈家族數據共通的一種統計建模過程，所以，在這一“屋檐”下，它衍生出衆多種類的統計模型。</p>
<hr />
</div>
<div id="exercise.-exponential-distribution" class="section level3">
<h3><span class="header-section-number">44.1.2</span> Exercise. Exponential distribution</h3>
<p>證明指數分佈本身也屬於指數分佈家族，定義其標準鏈接函數和標準參數。</p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
Y \sim \text{exp}(\lambda) &amp; \rightarrow f(y) = \lambda \text{exp}(-y\lambda), y &gt; 0\\
\Rightarrow \text{ln}\{ f(y) \} &amp; = - y \lambda + \text{ln}(\lambda) \\
\text{Let } &amp; \color{red}{\theta = -\lambda, b(\theta) = - \text{ln}(\lambda), \phi = 1, c(y, \phi) = 0} \\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\phi} - c(y, \theta) \\
\text{Because } E(Y) &amp; = \frac{1}{\lambda}, \text{ the canonical link is } g(\lambda) = -\frac{1}{\lambda}\\
\end{aligned}
\]</span></p>
<hr />
</div>
</div>
<div id="defineaGLM" class="section level2">
<h2><span class="header-section-number">44.2</span> 廣義線性迴歸模型之定義</h2>
<p>一個四肢健全的廣義線性模型包括三個部分：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈 (或者叫響應變量分佈，response distribution)：<span class="math inline">\(Y_i, i = 1,\cdots,n\)</span> 可以被認爲是互相獨立且服從指數家族分佈，設其期望值 (均值) <span class="math inline">\(E(Y_i) = \mu_i\)</span>；</li>
<li>線性預測方程 (linear predictor)：<strong>預測變量及其各自的參數以線性迴歸形式進入模型</strong>，其中第 <span class="math inline">\(i\)</span> 個觀測值的線性預測值爲：<br> <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接函數 (link function)：鏈接函數連接的是線性預測方程 <span class="math inline">\(\eta_i\)</span> 和其期待值 (均值) 之間 <span class="math inline">\(\mu_i\)</span> 的關係。<br> <span class="math display">\[g(\mu_i) = \eta_i\]</span></li>
</ol>
<p>簡單線性迴歸模型本身當然也數據廣義線性迴歸模型：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈是正態分佈；</li>
<li>線性預測值也是線性迴歸形式；</li>
<li>鏈接函數是它因變量本身 (the <strong>identity</strong> function)。</li>
</ol>
</div>
<div id="注意" class="section level2">
<h2><span class="header-section-number">44.3</span> 注意</h2>
<ol style="list-style-type: decimal">
<li>廣義線性迴歸的線性預測方程部分的意義，需要澄清的是它指的是 <strong>參數 parameter</strong> 之間呈線性關係，預測變量本身可以有二次方，三次方，多次方，因爲這些多項式線性迴歸本身仍然是<strong>線性的</strong>如： <span class="math display">\[\eta_i = \alpha + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_p x_i^p\]</span> <br> 然而，這樣的形式 <span class="math display">\[\eta_i = \alpha (1- e^{\beta_1 x_{i1}})\]</span> <br> 就不能說是一個線性預測方程。</li>
<li>除了有很少的特例。廣義線性迴歸擬合後的參數估計，推斷，模型評價和比較時使用的原理都一樣，不同的只有各自的分佈和鏈接函數。</li>
<li>通常選用的鏈接方程，要能夠使線性預測方程的取值範圍達到所有實數 <span class="math inline">\(-\infty,+\infty\)</span>。</li>
<li>“模型的似然函數 the log likelihood of the model”，只是我們偷懶縮短了原文 “在給定數據的前提下，當所有參數均爲 <span class="math inline">\(\text{MLE}\)</span> 時模型的對數似然函數 (the log likelihood function of the model for the given data evaluated at the MLE’s of the parameters)”，就是對數似然函數的極大值的意思 (i.e. the maximum of the log likelihood function)。</li>
<li>從本節開始往後的章節中 “模型，model”，“廣義線性模型，generalized linear model”，和 “GLM” 將被視爲同義詞。</li>
</ol>
</div>
<div id="如何在-r-裏擬合-glm" class="section level2">
<h2><span class="header-section-number">44.4</span> 如何在 R 裏擬合 “GLM”</h2>
<p>這裏討論用極大似然法擬合 “GLM” 模型的方法。前面一章節的複習也是在告訴我們，利用極大似然法簡單說就是找到模型參數，使得似然函數能夠取到極大值。對於線性迴歸來說， <span class="math inline">\(\text{MLE}\)</span> 可以用一個封閉式函數來計算；但是廣義線性迴歸模型則必須使用<a href="https://www.youtube.com/watch?v=JZIeX3eVyf4">迭代法計算 (iterative methods)</a>。</p>
<p>在 R 裏面擬合廣義線性模型的命令及其格式是：</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb427-1" title="1"><span class="kw">glm</span>(response variable <span class="op">~</span><span class="st"> </span>explanatory variables to form linear predictor, <span class="dt">family=</span>name of <span class="kw">distribution</span>(<span class="dt">link=</span>link <span class="cf">function</span>), <span class="dt">data=</span>dataset)</a></code></pre></div>
<p>Tips: See <code>help(glm)</code> for other modeling options. See <code>help(family)</code> for other allowable link functions for each family.</p>
<p>下面的數據來自一個心理學臨牀實驗，比較的是和安慰劑組相比，注射嗎啡組，注射海洛因組對象的精神病檢測指數的前後變化。</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb428-1" title="1">Mental &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/MENTAL.DAT&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;treatment&quot;</span>, <span class="st">&quot;Before&quot;</span>, <span class="st">&quot;After&quot;</span>))</a>
<a class="sourceLine" id="cb428-2" title="2">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;placebo&quot;</span></a>
<a class="sourceLine" id="cb428-3" title="3">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>] &lt;-<span class="st"> &quot;morphine&quot;</span></a>
<a class="sourceLine" id="cb428-4" title="4">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>] &lt;-<span class="st"> &quot;heroin&quot;</span></a>
<a class="sourceLine" id="cb428-5" title="5">Mental<span class="op">$</span>treatment &lt;-<span class="st"> </span><span class="kw">factor</span>(Mental<span class="op">$</span>treatment, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;morphine&quot;</span>, <span class="st">&quot;heroin&quot;</span>))</a>
<a class="sourceLine" id="cb428-6" title="6"><span class="kw">head</span>(Mental)</a></code></pre></div>
<pre><code>##   treatment Before After
## 1   placebo      0     7
## 2   placebo      2     1
## 3   placebo     14    10
## 4   placebo      5    10
## 5   placebo      5     6
## 6   placebo      4     2</code></pre>
<p>我們來比較一下簡單線性迴歸的代碼輸出結果和廣義線性迴歸代碼輸出結果是否一致：</p>
<p>用 <code>lm</code> 命令，擬合因變量爲注射後精神病檢測指數，預測變量爲治療方式和注射錢精神病檢測指數，及兩者的交互作用項：</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb430-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(After <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>Before, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb430-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = After ~ treatment * Before, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.82808 -1.93513 -0.51606  1.41607 11.36012 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)               1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine        -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin          -1.461968   1.771855 -0.8251 0.412284   
## Before                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:Before -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:Before   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3329 on 66 degrees of freedom
## Multiple R-squared:  0.34418,    Adjusted R-squared:  0.29449 
## F-statistic: 6.9274 on 5 and 66 DF,  p-value: 0.000029744</code></pre>
<p>同樣的模型也可以用 <code>glm</code> 命令擬合：</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb432-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(After <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>Before, <span class="dt">family =</span> <span class="kw">gaussian</span>(<span class="dt">link =</span> <span class="st">&quot;identity&quot;</span>), <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb432-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = After ~ treatment * Before, family = gaussian(link = &quot;identity&quot;), 
##     data = Mental)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -7.82808  -1.93513  -0.51606   1.41607  11.36012  
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)               1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine        -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin          -1.461968   1.771855 -0.8251 0.412284   
## Before                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:Before -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:Before   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 11.107994)
## 
##     Null deviance: 1117.875  on 71  degrees of freedom
## Residual deviance:  733.128  on 66  degrees of freedom
## AIC: 385.414
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>可以看到，<code>glm</code> 命令的輸出結果略多，但是參數估計的部分是完全相同的。<strong>但是如果你用的是坑爹的 STATA，那裏面的 <code>glm</code> 命令中的統計檢驗量和 <span class="math inline">\(p\)</span> 值用的則是正態分佈近似法。所以在 STATA 裏面簡單線性迴歸模型最好不要使用 <code>glm</code> 命令：</strong></p>
<pre><code> glm After i.treatt##c.Before, family(gaussian) link(identity)

Iteration 0:   log likelihood = -185.70711

Generalized linear models                         No. of obs      =         72
Optimization     : ML                             Residual df     =         66
                                                  Scale parameter =   11.10799
Deviance         =  733.1276068                   (1/df) Deviance =   11.10799
Pearson          =  733.1276068                   (1/df) Pearson  =   11.10799

Variance function: V(u) = 1                       [Gaussian]
Link function    : g(u) = u                       [Identity]

                                                  AIC             =   5.325197
Log likelihood   =  -185.707106                   BIC             =   450.8676

------------------------------------------------------------------------------
             |                 OIM
        After|      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       treat |
          2  |  -1.211742   1.750342    -0.69   0.489    -4.642349    2.218865
          3  |  -1.461968   1.771855    -0.83   0.409    -4.934741    2.010805
             |
      Before |   .5939394   .1834682     3.24   0.001     .2343483    .9535305
             |
 treat#Before|
          2  |  -.0895258   .2483459    -0.36   0.718    -.5762749    .3972233
          3  |  -.3129855   .2503829    -1.25   0.211     -.803727    .1777561
             |
       _cons |    1.97803   1.294069     1.53   0.126    -.5582981    4.514359
------------------------------------------------------------------------------</code></pre>
<p>回到 R 來， 當儲存了一個 <code>Model2</code> 向量在 R 裏之後，你可以用下面的各種命令獲取你想要的各種有用的信息。</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb435-1" title="1"><span class="kw">confint</span>(Model2) <span class="co"># 95% CI for the coefficients</span></a></code></pre></div>
<pre><code>##                                2.5 %     97.5 %
## (Intercept)              -0.55829809 4.51435869
## treatmentmorphine        -4.64234925 2.21886536
## treatmentheroin          -4.93474055 2.01080452
## Before                    0.23434829 0.95353050
## treatmentmorphine:Before -0.57627487 0.39722332
## treatmentheroin:Before   -0.80372697 0.17775605</code></pre>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb437-1" title="1"><span class="kw">exp</span>(<span class="kw">coef</span>(Model2)) <span class="co"># exponentiated coefficients</span></a></code></pre></div>
<pre><code>##              (Intercept)        treatmentmorphine          treatmentheroin                   Before 
##               7.22849102               0.29767829               0.23177968               1.81110905 
## treatmentmorphine:Before   treatmentheroin:Before 
##               0.91436470               0.73126055</code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb439-1" title="1"><span class="kw">exp</span>(<span class="kw">confint</span>(Model2)) <span class="co"># 95% CI for exponentiated coefficients</span></a></code></pre></div>
<pre><code>##                                 2.5 %     97.5 %
## (Intercept)              0.5721820406 91.3189836
## treatmentmorphine        0.0096350359  9.1968898
## treatmentheroin          0.0071923267  7.4693242
## Before                   1.2640846824  2.5948546
## treatmentmorphine:Before 0.5619879499  1.4876881
## treatmentheroin:Before   0.4476574460  1.1945339</code></pre>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb441-1" title="1"><span class="kw">head</span>(<span class="kw">predict</span>(Model2, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)) <span class="co"># predicted values</span></a></code></pre></div>
<pre><code>##          1          2          3          4          5          6 
##  1.9780303  3.1659091 10.2931818  4.9477273  4.9477273  4.3537879</code></pre>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb443-1" title="1"><span class="kw">head</span>(<span class="kw">residuals</span>(Model2, <span class="dt">type=</span><span class="st">&quot;deviance&quot;</span>)) <span class="co"># residuals</span></a></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  5.02196970 -2.16590909 -0.29318182  5.05227273  1.05227273 -2.35378788</code></pre>
<div id="margins-命令" class="section level3">
<h3><span class="header-section-number">44.4.1</span> <code>margins</code> 命令</h3>
<p>一個在 STATA 裏面十分有用的用於<strong>預測</strong>的命令 <code>margins</code>，在 R 裏，下載了 <code>margins</code> 包以後就可以調用和 STATA 的 <code>margins</code> 類似的命令。</p>
<p>假如我們用擬合的模型預測當注射前精神病檢測值分別是 0，6，12 分時三組之間的注射後精神病檢測值差，可以這樣求：</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb445-1" title="1"><span class="kw">summary</span>(<span class="kw">margins</span>(Model2, <span class="dt">at =</span> <span class="kw">list</span>(<span class="dt">Before=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">6</span>,<span class="dv">12</span>))))</a></code></pre></div>
<pre><code>##             factor  Before     AME     SE       z      p   lower   upper
##             Before  0.0000  0.4598 0.1004  4.5797 0.0000  0.2630  0.6565
##             Before  6.0000  0.4598 0.1004  4.5797 0.0000  0.2630  0.6565
##             Before 12.0000  0.4598 0.1004  4.5798 0.0000  0.2630  0.6565
##    treatmentheroin  0.0000 -1.4620 1.7719 -0.8251 0.4093 -4.9347  2.0108
##    treatmentheroin  6.0000 -3.3399 0.9624 -3.4705 0.0005 -5.2261 -1.4537
##    treatmentheroin 12.0000 -5.2178 1.7963 -2.9048 0.0037 -8.7384 -1.6972
##  treatmentmorphine  0.0000 -1.2117 1.7503 -0.6923 0.4888 -4.6423  2.2189
##  treatmentmorphine  6.0000 -1.7489 0.9630 -1.8160 0.0694 -3.6364  0.1386
##  treatmentmorphine 12.0000 -2.2861 1.7977 -1.2716 0.2035 -5.8095  1.2374</code></pre>
<p>對比 STATA 裏的結果：</p>
<pre><code> margins, dydx(trt) at(pre = (0 6 12))

Conditional marginal effects                    Number of obs     =         72
Model VCE    : OIM

Expression   : Predicted mean post, predict()
dy/dx w.r.t. : 2.trt 3.trt

1._at        : pre             =           0

2._at        : pre             =           6

3._at        : pre             =          12

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
1.trt        |  (base outcome)
-------------+----------------------------------------------------------------
2.trt        |
         _at |
          1  |  -1.211742   1.750342    -0.69   0.489    -4.642349    2.218865
          2  |  -1.748897    .963025    -1.82   0.069    -3.636391    .1385977
          3  |  -2.286051   1.797717    -1.27   0.204    -5.809513     1.23741
-------------+----------------------------------------------------------------
3.trt        |
         _at |
          1  |  -1.461968   1.771855    -0.83   0.409    -4.934741    2.010805
          2  |  -3.339881   .9623512    -3.47   0.001    -5.226054   -1.453707
          3  |  -5.217794   1.796264    -2.90   0.004    -8.738406   -1.697181
------------------------------------------------------------------------------
Note: dy/dx for factor levels is the discrete change from the base level.</code></pre>
</div>
<div id="ggplot2geom_smoothmethod-loess-命令" class="section level3">
<h3><span class="header-section-number">44.4.2</span> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</h3>
<p>類似 STATA 作散點圖時的 <code>lowess</code> 命令，在 R 裏，你可以用 <code>ggplot2</code> 包裏自帶的 <code>geom_smooth(method = "loess")</code> 選項命令，給散點圖添加平滑曲線。把觀測數據中變量之間的關係視覺化，用於輔助判斷一個模型是否可以被擬合爲線性關係。全稱是 “locally weighted scatterplot smoothing”，縮寫成 “lowess/loess”。<a href="https://en.wikipedia.org/wiki/Local_regression">LOWESS 的原理</a>簡略說是，通過把預測變量分成幾個部分，分別在各個小區間內擬合迴歸各自的迴歸曲線，如此便可以將<strong>每個觀測值都以各自不同的加權值放入整個模型</strong>中，然而正如我們在簡單線性模型中提到過的，這樣的曲線更加擬合觀測數據，而不能說明觀測值來自的人羣中，兩個變量之間的關係。此方法的靈活性在於，你可以選擇平滑的程度，該平滑程度用 <code>bandwith</code>(STATA) 或者 <code>span</code>(R) 表示，取值範圍是 <span class="math inline">\(0 \sim 1\)</span> 之間的任意值，越靠近 <span class="math inline">\(1\)</span>，Lowess 曲線越接近簡單線性直線，越靠近 <span class="math inline">\(0\)</span>，那麼每個觀測點本身的權重越大，擬合的 Lowess 曲線越接近觀測數據本身。下圖 <a href="#fig:loess-smoother1">44.1</a> 提示，選用的平滑程度 <span class="math inline">\(= 0.8\)</span> 時，精神病測量分數在 (安慰劑組中) 實驗前後的關係接近線性關係。當我們降低平滑程度，Lowess 曲線接近觀測數據本身，其實是太接近觀測數據本身，反而無法提供太多的信息。</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb448-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(Before, After)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb448-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb448-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess-smoother1"></span>
<img src="bookdown_files/figure-html/loess-smoother1-1.png" alt="Lowess smoother, with bandwith/span set to 0.8, for the mental data" width="100%" />
<p class="caption">
圖 44.1: Lowess smoother, with bandwith/span set to 0.8, for the mental data
</p>
</div>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb449-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(Before, After)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb449-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.4</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb449-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess-smoother2"></span>
<img src="bookdown_files/figure-html/loess-smoother2-1.png" alt="Lowess smoother, with bandwith/span set to 0.4, for the mental data" width="100%" />
<p class="caption">
圖 44.2: Lowess smoother, with bandwith/span set to 0.4, for the mental data
</p>
</div>
</div>
</div>
<div id="glm-practical-02" class="section level2">
<h2><span class="header-section-number">44.5</span> GLM-Practical 02</h2>
<div id="思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證" class="section level3">
<h3><span class="header-section-number">44.5.1</span> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</h3>
<ol style="list-style-type: decimal">
<li><p>MLE <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(b^\prime(\theta) = y\)</span> 的解;</p></li>
<li><p><span class="math inline">\(\theta\)</span> 的 MLE 的方差是 <span class="math inline">\(\frac{\phi}{b^{\prime\prime}(\theta)}\)</span>;</p></li>
<li><p>如果 <span class="math inline">\(Y\sim N(\mu, \sigma^2)\)</span>，試進一步證明 <span class="math inline">\(b^\prime(\theta) = \mu\)</span> 且 <span class="math inline">\(\frac{\phi}{b^{\prime\prime}(\theta)} = \sigma^2\)</span></p></li>
<li><p>當數據來自指數分布家族，它的對數似然可以寫作:</p></li>
</ol>
<p><span class="math display">\[
\frac{y\cdot\theta - b(\theta)}{\phi} - c(y, \phi)
\]</span></p>
<p>對這個對數似然方程取 <span class="math inline">\(\theta\)</span> 的偏微分方程可得:</p>
<p><span class="math display">\[
\frac{\partial}{\partial\theta}\ell(\theta,\phi) = \frac{y - b^\prime(\theta)}{\phi}
\]</span></p>
<p>令此偏微分方程等於零，那麼我們可以知道 <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(b^\prime(\theta) = y\)</span> 的解。</p>
<ol start="2" style="list-style-type: decimal">
<li>MLE 的方差可以用 Fisher information 來推導。</li>
</ol>
<p><span class="math display">\[
S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}} \\
\text{Because } \ell^{\prime\prime}(\theta) = -\frac{b^{\prime\prime}(\theta)}{\phi} \\
\Rightarrow  S^2 = \frac{\phi}{b^{\prime\prime}(\theta)}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>如果 <span class="math inline">\(Y\sim N(\mu, \sigma^2)\)</span>, 那麼，根據正態分布數據屬於指數家族的性質，</li>
</ol>
<p><span class="math display">\[
\phi = \sigma^2,\theta = \mu, b(\theta =\mu) = \frac{\mu^2}{2} \\
\Rightarrow b^\prime(\theta) = \mu \\
\Rightarrow S^2 = \frac{\phi}{b^{\prime\prime}(\theta)} = \sigma^2
\]</span></p>
</div>
<div id="r-練習" class="section level3">
<h3><span class="header-section-number">44.5.2</span> R 練習</h3>
<p>數據來自一個RCT臨牀試驗，比較嗎啡，海洛因和安慰劑在患者精神狀態評分上的影響，試分析數據回答下面的問題:</p>
<ol style="list-style-type: decimal">
<li>三組治療組之間注射後的評分均值不同嗎？</li>
<li>調整基線時精神狀態評分對你的模型結果有什麼影響？</li>
<li>基線時精神狀態評分的高低會影響不同藥物的效果嗎？</li>
</ol>
<div id="數據讀入-r作初步分析" class="section level4">
<h4><span class="header-section-number">44.5.2.1</span> 數據讀入 R，作初步分析</h4>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb450-1" title="1">Mental &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/MENTAL.DAT&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;treatment&quot;</span>, <span class="st">&quot;prement&quot;</span>, <span class="st">&quot;mentact&quot;</span>))</a>
<a class="sourceLine" id="cb450-2" title="2">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;placebo&quot;</span></a>
<a class="sourceLine" id="cb450-3" title="3">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>] &lt;-<span class="st"> &quot;morphine&quot;</span></a>
<a class="sourceLine" id="cb450-4" title="4">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>] &lt;-<span class="st"> &quot;heroin&quot;</span></a>
<a class="sourceLine" id="cb450-5" title="5">Mental<span class="op">$</span>treatment &lt;-<span class="st"> </span><span class="kw">factor</span>(Mental<span class="op">$</span>treatment, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;morphine&quot;</span>, <span class="st">&quot;heroin&quot;</span>))</a>
<a class="sourceLine" id="cb450-6" title="6"><span class="kw">head</span>(Mental)</a></code></pre></div>
<pre><code>##   treatment prement mentact
## 1   placebo       0       7
## 2   placebo       2       1
## 3   placebo      14      10
## 4   placebo       5      10
## 5   placebo       5       6
## 6   placebo       4       2</code></pre>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb452-1" title="1"><span class="co"># Use hsitograms and plots to look at the distributions of the pre- and post- injection scores.</span></a>
<a class="sourceLine" id="cb452-2" title="2"><span class="co"># with(Mental, hist(prement, breaks = 14, freq = F))</span></a>
<a class="sourceLine" id="cb452-3" title="3"><span class="co"># qplot(prement, data = Mental, binwidth = 1)</span></a>
<a class="sourceLine" id="cb452-4" title="4">hist1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> prement, <span class="dt">y =</span> ..density..)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-5" title="5">hist2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> mentact, <span class="dt">y =</span> ..density..)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-6" title="6">Scatter &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> prement, <span class="dt">y =</span> mentact)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()<span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-7" title="7"><span class="kw">grid.arrange</span>(hist1, hist2, Scatter, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pre-score"></span>
<img src="bookdown_files/figure-html/pre-score-1.png" alt="Histogram and plots " width="90%" />
<p class="caption">
圖 44.3: Histogram and plots
</p>
</div>
<p>可以看到柱狀圖暗示我們實驗前後的得分本身都不服從正態分布。但是這並不妨礙我們使用回歸模型來做推斷。畢竟，<strong>線性回歸模型只要求殘差服從正態分布</strong>。另外，散點圖提示實驗前後的得分之間可能呈正相關。</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb453-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(prement, mentact)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb453-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb453-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess1"></span>
<img src="bookdown_files/figure-html/loess1-1.png" alt="Lowess smoother, with bandwith/span set to 0.8, for the mental data" width="100%" />
<p class="caption">
圖 44.4: Lowess smoother, with bandwith/span set to 0.8, for the mental data
</p>
</div>
<p>對於每組實驗組來說，觀測值數量都很少，姑且可以認爲線性模型是合理的。</p>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exer-tab1">表 44.1: </span>Residual sums of squares and degress of freedom from five different models for post-injection mental activity scores (pre-inj = preinjection score)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Terms fitted
</th>
<th style="text-align:left;">
RSS
</th>
<th style="text-align:left;">
Residuals df
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: decimal">
<li>Overall mean
</td>
<td style="text-align:left;">
1117.875
</td>
<td style="text-align:left;">
71
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: decimal">
<li>Drugs
</td>
<td style="text-align:left;">
980.625
</td>
<td style="text-align:left;">
69
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="3" style="list-style-type: decimal">
<li>Pre-inj
</td>
<td style="text-align:left;">
884.328
</td>
<td style="text-align:left;">
70
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="4" style="list-style-type: decimal">
<li>Drugs + Pre-inj
</td>
<td style="text-align:left;">
752.055
</td>
<td style="text-align:left;">
68
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="5" style="list-style-type: decimal">
<li>Drugs + Pre-inj + Drugs×Pre-inj
</td>
<td style="text-align:left;">
733.127
</td>
<td style="text-align:left;">
66
</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol></li>
</ol></li>
</ol></li>
</ol>
</div>
<div id="寫下表格-reftabglm-exer-tab1-中五個線性回歸模型的數學表達式在-r-裏面擬合這5個模型在第二列第三列分別填寫各模型的統計信息-殘差平方和-residuals-sum-of-squares和-殘差自由度-reiduals-degrees-of-freedom利用該表格填寫完整以後的內容用筆和紙正式地比較模型-3-和-4-4-和-5-的擬合優度然後和-r-的輸出結果比較確認你會作出怎樣的結論另外爲什麼相似的比較模型的方法不適用於比較模型-2-和-3" class="section level4">
<h4><span class="header-section-number">44.5.2.2</span> 寫下表格 <a href="#tab:GLM-exer-tab1">44.1</a> 中五個線性回歸模型的數學表達式，在 R 裏面擬合這5個模型，在第二列第三列分別填寫各模型的統計信息 (殘差平方和 residuals sum of squares，和 殘差自由度 reiduals degrees of freedom)。利用該表格填寫完整以後的內容，用筆和紙正式地比較模型 3 和 4; 4 和 5 的擬合優度。然後和 R 的輸出結果比較確認。你會作出怎樣的結論？另外，爲什麼相似的比較模型的方法不適用於比較模型 2 和 3？</h4>
<p><strong>解</strong></p>
<p>用 <span class="math inline">\(z_i, y_i\)</span> 分別標記第 <span class="math inline">\(i\)</span> 名患者在藥物注射前，後兩次測量的精神醫學指徵評分。使用線性回歸模型的前提假設是 <span class="math inline">\(y_i \sim N(\mu_i, \sigma^2)\)</span> 且互相獨立。另外，預測變量的標記爲:</p>
<p><span class="math display">\[
x_{1i} = \left\{ \begin{array}{ll}  0 \text{ placebo or heroin }\\  1 \text{ morphine}\\ \end{array} \right.
x_{2i} = \left\{ \begin{array}{ll}  0 \text{ placebo or morphine }\\  1 \text{ heroin}\\ \end{array} \right. \\
\]</span></p>
<ol style="list-style-type: decimal">
<li>Overall mean model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0\)</span></p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb454-1" title="1"><span class="co">#1.  Overall mean model</span></a>
<a class="sourceLine" id="cb454-2" title="2">Overall &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb454-3" title="3"><span class="kw">summary</span>(Overall)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ 1, data = Mental)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7917 -3.7917 -1.7917  2.4583 10.2083 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  3.79167    0.46763  8.1083 1.053e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.968 on 71 degrees of freedom</code></pre>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb456-1" title="1"><span class="kw">anova</span>(Overall)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 71 1117.88 15.7447</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Drugs model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}\)</span></p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb458-1" title="1"><span class="co">#2.  Drugs model</span></a>
<a class="sourceLine" id="cb458-2" title="2">Drugs &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb458-3" title="3"><span class="kw">summary</span>(Drugs)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment, data = Mental)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.5417 -2.1667 -1.1667  1.9583 10.8333 
## 
## Coefficients:
##                   Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)        5.54167    0.76952  7.2014 5.732e-10 ***
## treatmentmorphine -1.87500    1.08827 -1.7229  0.089382 .  
## treatmentheroin   -3.37500    1.08827 -3.1013  0.002791 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.7699 on 69 degrees of freedom
## Multiple R-squared:  0.12278,    Adjusted R-squared:  0.097351 
## F-statistic: 4.8287 on 2 and 69 DF,  p-value: 0.010896</code></pre>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb460-1" title="1"><span class="kw">anova</span>(Drugs)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)  
## treatment  2 137.250  68.625 4.82868 0.010896 *
## Residuals 69 980.625  14.212                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Pre-inj model</li>
</ol>
<p>鏈接方程部分 <span class="math inline">\(\eta_i = \beta_0 + \beta_3 z_i\)</span></p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb462-1" title="1"><span class="co">#3.  Pre-inj model</span></a>
<a class="sourceLine" id="cb462-2" title="2">Pre_inj &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb462-3" title="3"><span class="kw">summary</span>(Pre_inj)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.51879 -2.32837 -0.89028  2.25419 10.06844 
## 
## Coefficients:
##             Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)  1.09667    0.75388  1.4547     0.1502    
## prement      0.45872    0.10669  4.2996 0.00005433 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.5543 on 70 degrees of freedom
## Multiple R-squared:  0.20892,    Adjusted R-squared:  0.19762 
## F-statistic: 18.487 on 1 and 70 DF,  p-value: 0.000054335</code></pre>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb464-1" title="1"><span class="kw">anova</span>(Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq  Mean Sq F value      Pr(&gt;F)    
## prement    1 233.547 233.5473 18.4867 0.000054335 ***
## Residuals 70 884.328  12.6333                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Drugs + pre-inj model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3z_i\)</span></p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb466-1" title="1"><span class="co">#4.  Drugs + Pre-inj model</span></a>
<a class="sourceLine" id="cb466-2" title="2">Drug_Pre_inj &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb466-3" title="3"><span class="kw">summary</span>(Drug_Pre_inj)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment + prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.41185 -2.05478 -0.22877  1.08012 11.68451 
## 
## Coefficients:
##                    Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)        2.817898   0.905424  3.1122  0.0027149 ** 
## treatmentmorphine -1.761510   0.960344 -1.8342  0.0709923 .  
## treatmentheroin   -3.318255   0.960100 -3.4562  0.0009488 ***
## prement            0.453961   0.099857  4.5461 0.00002308 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3256 on 68 degrees of freedom
## Multiple R-squared:  0.32725,    Adjusted R-squared:  0.29757 
## F-statistic: 11.026 on 3 and 68 DF,  p-value: 5.4921e-06</code></pre>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb468-1" title="1"><span class="kw">anova</span>(Drug_Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq  Mean Sq  F value     Pr(&gt;F)    
## treatment  2 137.250  68.6250  6.20499  0.0033478 ** 
## prement    1 228.570 228.5696 20.66700 0.00002308 ***
## Residuals 68 752.055  11.0596                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Drug + Pre-inj + Drug×Pre-inj</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 z_i + \beta_{13}x_{1i}z_i + \beta_{23}x_{2i}z_i\)</span></p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb470-1" title="1"><span class="co">#5.  Drugs + Pre-inj + Drug×Pre-inj model</span></a>
<a class="sourceLine" id="cb470-2" title="2">Model5 &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb470-3" title="3"><span class="kw">summary</span>(Model5)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment * prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.82808 -1.93513 -0.51606  1.41607 11.36012 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)                1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine         -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin           -1.461968   1.771855 -0.8251 0.412284   
## prement                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:prement -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:prement   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3329 on 66 degrees of freedom
## Multiple R-squared:  0.34418,    Adjusted R-squared:  0.29449 
## F-statistic: 6.9274 on 5 and 66 DF,  p-value: 0.000029744</code></pre>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb472-1" title="1"><span class="kw">anova</span>(Model5)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##                   Df  Sum Sq  Mean Sq  F value      Pr(&gt;F)    
## treatment          2 137.250  68.6250  6.17798   0.0034719 ** 
## prement            1 228.570 228.5696 20.57704 0.000024811 ***
## treatment:prement  2  18.928   9.4639  0.85199   0.4312025    
## Residuals         66 733.128  11.1080                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>比較模型 3 和 4 可以使用相關的 F 統計量 (Partial F tests)</p>
<p><span class="math display">\[
F=\frac{(844.328 - 752.055)/(70-68)}{752.055/68} = 5.98
\]</span></p>
<p>自由度爲 (2,68) 時 F 統計量爲 5.98 的概率是:</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb474-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pf</span>(<span class="fl">5.98</span>, <span class="dv">2</span>, <span class="dv">68</span>)</a></code></pre></div>
<pre><code>## [1] 0.0040516165</code></pre>
<p>所以我們有極強的證據證明這兩個模型顯著不同，且模型 4 擬合數據更好，且該證據也證明了注射藥物後三組之間的精神醫學指徵的分顯著不同。用 R 進行偏 F 檢驗如下，可見我們的計算是完全正確的:</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb476-1" title="1"><span class="kw">anova</span>(Pre_inj, Drug_Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mentact ~ prement
## Model 2: mentact ~ treatment + prement
##   Res.Df     RSS Df Sum of Sq       F    Pr(&gt;F)   
## 1     70 884.328                                  
## 2     68 752.055  2   132.272 5.97996 0.0040518 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>比較模型 4 和 5:</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb478-1" title="1"><span class="kw">anova</span>(Drug_Pre_inj, Model5)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mentact ~ treatment + prement
## Model 2: mentact ~ treatment * prement
##   Res.Df     RSS Df Sum of Sq       F Pr(&gt;F)
## 1     68 752.055                            
## 2     66 733.128  2   18.9278 0.85199 0.4312</code></pre>
<p>所以，模型 4 和 5 比較的結果告訴我們沒有證據證明實驗前的精神醫學指徵得分和不同治療組之間有交互作用。但是由於模型 2 和 3 本身不是互爲嵌套式結構的，所以他們無法通過相似的偏 F 檢驗來比較模型。</p>
</div>
<div id="用-glm-命令擬合模型-4試比較其輸出結果和-lm-之間的異同" class="section level4">
<h4><span class="header-section-number">44.5.2.3</span> 用 <code>glm</code> 命令擬合模型 4，試比較其輸出結果和 <code>lm</code> 之間的異同:</h4>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb480-1" title="1">Model4 &lt;-<span class="st"> </span><span class="kw">glm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>prement, <span class="dt">family =</span> <span class="kw">gaussian</span>(<span class="dt">link =</span> <span class="st">&quot;identity&quot;</span>), <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb480-2" title="2"><span class="kw">summary</span>(Model4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = mentact ~ treatment + prement, family = gaussian(link = &quot;identity&quot;), 
##     data = Mental)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -7.41185  -2.05478  -0.22877   1.08012  11.68451  
## 
## Coefficients:
##                    Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)        2.817898   0.905424  3.1122  0.0027149 ** 
## treatmentmorphine -1.761510   0.960344 -1.8342  0.0709923 .  
## treatmentheroin   -3.318255   0.960100 -3.4562  0.0009488 ***
## prement            0.453961   0.099857  4.5461 0.00002308 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 11.059638)
## 
##     Null deviance: 1117.875  on 71  degrees of freedom
## Residual deviance:  752.055  on 68  degrees of freedom
## AIC: 383.25
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>可以看出各個參數估計和標準誤估計都是完全相同的。但是當你使用 STATA 的 <code>glm</code> 命令時，它默認的高斯鏈接方程使用的不是 t 檢驗結果而是 z 檢驗結果，所以會給出略微不同的 95% 信賴區間。</p>
</div>
<div id="使用相關模型的結果填寫下列表格" class="section level4">
<h4><span class="header-section-number">44.5.2.4</span> 使用相關模型的結果填寫下列表格</h4>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exer-tab2">表 44.2: </span>Comparison of mean post-injection mental activity scores.
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Mean
</th>
<th style="text-align:center;">
Mean diff with Placebo
</th>
<th style="text-align:center;">
SE
</th>
<th style="text-align:center;">
Adj. mean diff with Placebo
</th>
<th style="text-align:center;">
SE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Placebo
</td>
<td style="text-align:center;">
5.542
</td>
<td style="text-align:center;">
0.000
</td>
<td style="text-align:center;">
–
</td>
<td style="text-align:center;">
0.000
</td>
<td style="text-align:center;">
–
</td>
</tr>
<tr>
<td style="text-align:center;">
Morphine
</td>
<td style="text-align:center;">
3.667
</td>
<td style="text-align:center;">
-1.875
</td>
<td style="text-align:center;">
1.08
</td>
<td style="text-align:center;">
-1.761
</td>
<td style="text-align:center;">
0.96
</td>
</tr>
<tr>
<td style="text-align:center;">
Heroin
</td>
<td style="text-align:center;">
2.167
</td>
<td style="text-align:center;">
-3.375
</td>
<td style="text-align:center;">
1.08
</td>
<td style="text-align:center;">
-3.310
</td>
<td style="text-align:center;">
0.96
</td>
</tr>
</tbody>
</table>
</div>
<div id="對分析的結果做簡短的總結" class="section level4">
<h4><span class="header-section-number">44.5.2.5</span> 對分析的結果做簡短的總結</h4>
<p>在模型 2 (drug model) 中，F 檢驗給出的 p = 0.0109，提供了較爲有力的證據證明每個治療組治療後的精神醫學指徵得分是不同的。但是，觀察每個回歸系數的檢驗結果，發現嗎啡組和安慰劑組之差其實沒有達到 5% 統計學意義 (p = 0.089)，海洛因組和安慰劑組之間的得分差則達到了 5% 的統計學意義 (p = 0.003)。</p>
<p>模型加入對實驗前精神醫學指徵得分的調整之後，組與組之間的估計差發生了些許(但是並不大)的變化。這其實也是我們事先估計的結果，因爲對於RCT來說，沒有混雜因素，之所以調整基線值，主要爲的是提升參數估計的精確度 (減小 SE，從而使95% 信賴區間更小)。</p>
<p>對交互作用實施了偏 F 檢驗得到的結果 (p = 0.43) 提示，沒有證據反對零假設 – 藥物作用效果不因爲實驗前患者的精神醫學指徵得分不同而不同。</p>
<p>最後，<code>glm</code> 和 <code>lm</code> 的模型結果輸出在 R 裏是幾乎完全相同的，在 STATA 裏面則有計算方法的不同導致不同的95%CI。</p>
</div>
</div>
</div>
</div>
<div id="二項分佈數據的廣義線性迴歸模型-logistic-regression-model" class="section level1">
<h1><span class="header-section-number">第 45 章</span> 二項分佈數據的廣義線性迴歸模型 logistic regression model</h1>
<p>二項分佈數據在醫學研究中很常見，例子有千千萬，下面這些只是作爲拋磚引玉：</p>
<ol style="list-style-type: decimal">
<li>心臟搭橋手術和血管成形術兩組病人比較療效時，結果變量可以是：死亡 (是/否)；心肌梗死發作 (是/否)；</li>
<li>機械心臟瓣膜手術結果：成功/失敗；</li>
<li>用小鼠作不同劑量二硫化碳暴露下的毒理學實驗，結果變量是：小鼠死亡 (是/否)；</li>
<li>隊列研究中追蹤對象中出現心肌梗死病例，結果變量是：心肌梗死發作 (是/否)。</li>
</ol>
<div id="彙總後個人-grouped-individual-的二項分佈數據" class="section level2">
<h2><span class="header-section-number">45.1</span> 彙總後/個人 (grouped / individual) 的二項分佈數據</h2>
<p>下面的數據，來自某個毒理學實驗，不同劑量的二硫化碳暴露下小鼠的死亡數和總數的數據：</p>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<p>很容易理解這是一個典型的彙總後二項分佈數據 (grouped binary data)。每組不同的劑量，第二列，第三列分別是死亡數和實驗總數。另外一種個人二項分佈數據 (individual binary data) 的形式是這樣的：</p>
<pre><code>##     dose death
## 1  49.06     1
## 2  49.06     1
## 3  49.06     1
## 4  49.06     1
## 5  49.06     1
## 6  49.06     1
## 7  49.06     0
## 8  49.06     0
## 9  49.06     0
## 10 49.06     0
## 11     .     .
## 12     .     .
## 13     .     .</code></pre>
<p>個人二項分佈數據其實就是把每個觀察對象的事件發生與否的信息都呈現出來。通常個人二項分佈數據又被稱爲<strong>伯努利數據</strong>，分組型的二項分佈數據被稱爲<strong>二項數據</strong>。兩種表達形式，但是存儲的是一樣的數據。</p>
</div>
<div id="二項分佈數據的廣義線性迴歸模型" class="section level2">
<h2><span class="header-section-number">45.2</span> 二項分佈數據的廣義線性迴歸模型</h2>
<p>而所有的 GLM 一樣，二項分佈的 GLM 包括三個部分：</p>
<ol style="list-style-type: decimal">
<li>因變量的分佈 Distribution：因變量應相互獨立，且服從二項分佈 <br> <span class="math display">\[\begin{aligned} Y_i &amp;\sim \text{Bin}(n_i, \pi_i), i = 1, \cdots, n \\ E(Y_i) &amp;= \mu_i = n_i\pi_i\end{aligned}\]</span></li>
<li>線性預測方程 Linear predictor：第 <span class="math inline">\(i\)</span> 名觀測對象的預測變量的線性迴歸模型 <br> <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接方程 Link function：鏈接方程連接的是 <span class="math inline">\(\mu_i = n\pi_i\)</span> 和線性預測方程。一個二項分佈因變量數據，可以有許多種鏈接方程：
<ul>
<li><span class="math inline">\(\mathbf{logit}:\)</span> <span class="math display">\[\text{logit}(\pi) = \text{ln}(\frac{\pi}{1-\pi})\]</span></li>
<li><span class="math inline">\(\mathbf{probit}:\)</span> <span class="math display">\[\text{probit}(\pi) = \Phi^{-1}(\pi)\]</span></li>
<li><span class="math inline">\(\mathbf{complementary\; log-log}:\)</span> <span class="math display">\[\text{cloglog}(\pi) = \text{ln}\{ - \text{ln}(1-\pi) \}\]</span></li>
<li><span class="math inline">\(\mathbf{log:}\)</span> <span class="math display">\[\text{log}(\pi) = \text{ln}(\pi)\]</span></li>
</ul></li>
</ol>
</div>
<div id="logit-or-log" class="section level2">
<h2><span class="header-section-number">45.3</span> 注</h2>
<ol style="list-style-type: decimal">
<li>概率鏈接方程 <span class="math inline">\(\text{probit}\)</span>，<span class="math inline">\(\Phi\)</span> 被定義爲標準正態分佈的累積概率方程 (Section <a href="#standardNormal">7.3</a>)： <span class="math display">\[\Phi(z) = \text{Pr}(Z \leqslant z), \text{ for } Z\sim N(0,1)\]</span></li>
<li>二項分佈數據的標準參數 (canonical parameter) <span class="math inline">\(\theta_i\)</span> 的標準鏈接方程是 <span class="math inline">\(\theta_i = \text{logit}(\pi_i)\)</span>。</li>
<li><span class="math inline">\(\text{logit, probit, complementary log-log}\)</span> 三種鏈接方程都能達到把閾值僅限於 <span class="math inline">\(0 \sim 1\)</span> 之間的因變量概率映射到線性預測方程的全實數閾值 <span class="math inline">\((-\infty,+\infty)\)</span> 的目的。但是最後一個 <span class="math inline">\(\text{log}\)</span> 鏈接方程只能映射全部的非零負實數 <span class="math inline">\((-\infty,0)\)</span>。</li>
<li><span class="math inline">\(\text{logit, probit}\)</span> 鏈接方程都是以 <span class="math inline">\(\pi= 0.5\)</span> 爲對稱軸左右對稱的。但是 <span class="math inline">\(\text{cloglog}\)</span> 則沒有對稱的性質。</li>
<li>鏈接方程 <span class="math inline">\(\text{log}\)</span> 具有可以直接被解讀爲對數危險度比 (log Risk Ratio) 的優點，所以也常常在應用中見到。對數鏈接方程還有其他的優點 (非塌陷性 non-collapsibility)，但是它的最大缺點是，有時候利用這個鏈接方程的模型無法收斂 (converge)。</li>
<li><span class="math inline">\(\text{logit}\)</span> 鏈接方程是我們最常見的，也最直觀易於理解。利用這個鏈接方程擬合的模型的迴歸係數能夠直接被理解爲對數比值比 (log Odds Ratio)。</li>
<li>如果是個人數據 (individual data)，那麼 <span class="math inline">\(n_i = 1\)</span>，<span class="math inline">\(i\)</span> 是每一個觀測對象的編碼。那麼 <span class="math inline">\(Y_i = 0\text{ or }1\)</span>，代表事件發生或沒發生/成功或者失敗。如果是分組數據 (grouped data)，<span class="math inline">\(i\)</span> 是每個組的編號，<span class="math inline">\(n_i\)</span> 指的是第 <span class="math inline">\(i\)</span> 組中觀測對象的人數，<span class="math inline">\(Y_i\)</span> 是第 <span class="math inline">\(i\)</span> 組的 <span class="math inline">\(n\)</span> 名對象中事件發生的次數/成功的次數。</li>
</ol>
<hr />
<div id="exercise.-link-functions." class="section level3">
<h3><span class="header-section-number">45.3.1</span> Exercise. Link functions.</h3>
<p>推導出鏈接參數分別是</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{log}\)</span></li>
<li><span class="math inline">\(\text{logit}\)</span></li>
<li><span class="math inline">\(\text{complementary log-log}\)</span></li>
</ol>
<p>時，用參數 <span class="math inline">\(\alpha, \beta_1, \cdots, \beta_p\)</span> 表達的參數 <span class="math inline">\(\pi_i=?, E(Y_i)=\mu_i=?\)</span></p>
<p><strong>解</strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\text{log}\)</span>
<span class="math display">\[
\begin{aligned}
\text{ln}(\pi_i) &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i &amp; = e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}} \\
         \mu_i &amp; = n_i\pi_i = n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}
\end{aligned}
\]</span></p></li>
<li><p><span class="math inline">\(\text{logit}\)</span></p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\pi_i) &amp; = \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i   &amp; = \frac{e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
              \mu_i &amp; = \frac{n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\text{complementary log-log}\)</span></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{cloglog}(\pi_i) &amp; = \text{ln}\{ - \text{ln}(1-\pi) \} \\
                      &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i     &amp; = 1 - e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
            \mu_i     &amp; = n_i\pi_i = n_i(1-e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}})
\end{aligned}
\]</span></p>
<hr />
</div>
</div>
<div id="邏輯迴歸模型迴歸係數的實際意義" class="section level2">
<h2><span class="header-section-number">45.4</span> 邏輯迴歸模型迴歸係數的實際意義</h2>
<p>邏輯迴歸 (logistic regression) 的模型可以寫成是</p>
<p><span class="math display">\[
\text{logist}(\pi_i) = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}
\]</span></p>
<p>假如觀察對象 <span class="math inline">\(j\)</span> 和 <span class="math inline">\(i\)</span> 兩人中，其餘的預測變量都相同，二者之間有且僅有最後一個預測變量相差一個單位：</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\pi_j) &amp; = \text{ln}(\frac{\pi_j}{1-\pi_j}) = \alpha + \beta_1 x_{j1} + \beta_2 x_{j2} + \cdots + \beta_p x_{jp} \\
\text{logit}(\pi_i) &amp; = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\text{Because they are} &amp; \text{ in the same model share the same parameters, and } \\
x_{jp} &amp; = x_{ip} + 1\\
\Rightarrow \text{logit}(\pi_j) - \text{logit}(\pi_i) &amp; = \beta_p (x_{jp} + 1 - x_{jp}) = \beta_p \\
\Rightarrow \beta_p &amp; =  \text{ln}(\frac{\pi_j}{1-\pi_j})  -  \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    &amp; = \text{ln}(\frac{\frac{\pi_j}{1-\pi_j}}{\frac{\pi_i}{1-\pi_i}}) \\
                    &amp; = \text{ln}(\text{Odds Ratio})
\end{aligned}
\]</span></p>
<p>所以迴歸係數 <span class="math inline">\(\beta_p\)</span> 可以被理解爲是 <span class="math inline">\(j\)</span> 與 <span class="math inline">\(i\)</span> 相比較時的對數比值比 log Odds Ratio。我們只要對迴歸係數求反函數，即可求得比值比。</p>
</div>
<div id="BSEinfection" class="section level2">
<h2><span class="header-section-number">45.5</span> 邏輯迴歸實際案例</h2>
<p>一組數據如下：</p>
<p>其中，牲畜來自兩大羣 (group)；每羣有五個組的牲畜被飼養五種不同濃度的飼料 (dfactor)；每組牲畜我們記錄了牲畜的總數 (cattle) 以及感染了瘋牛病的牲畜數量 (infect)：</p>
<pre><code>##    group dfactor cattle infect
## 1      1       1     11      8
## 2      1       2     10      7
## 3      1       3     12      5
## 4      1       4     11      3
## 5      1       5     12      2
## 6      2       1     10     10
## 7      2       2     10      9
## 8      2       3     12      8
## 9      2       4     11      6
## 10     2       5     10      4</code></pre>
<div id="分析目的" class="section level3">
<h3><span class="header-section-number">45.5.1</span> 分析目的</h3>
<p>通過對本數據的分析，回答如下的問題：</p>
<ol style="list-style-type: decimal">
<li>考慮了牲畜來自兩羣以後，不同的飼料 (dfactor) 是否和感染瘋牛病有關？</li>
<li>兩羣牲畜之間，飼料和瘋牛病感染之間的關係是否不同？</li>
</ol>
</div>
<div id="模型-1-飼料-羣" class="section level3">
<h3><span class="header-section-number">45.5.2</span> 模型 1 飼料 + 羣</h3>
<p><span class="math display">\[
\begin{aligned}
\text{Assume } Y_i &amp; \sim \text{Bin} (n_i, \pi_i) \\
\text{logit}(\pi_i) &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2}
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb485-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb485-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + 
##     dfactor, family = binomial(link = logit), data = Cattle)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.60847  -0.17831   0.10110   0.31150   1.16876  
## 
## Coefficients:
##                Estimate Std. Error z value   Pr(&gt;|z|)    
## (Intercept)     2.13104    0.61130  3.4861  0.0004902 ***
## factor(group)2  1.30590    0.46540  2.8060  0.0050163 ** 
## dfactor        -0.78744    0.18135 -4.3422 0.00001411 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.52556  on 9  degrees of freedom
## Residual deviance:  2.45082  on 7  degrees of freedom
## AIC: 32.2537
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb487-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model1)</a></code></pre></div>
<pre><code>##  
##                        OR  lower95ci  upper95ci       Pr(&gt;|Z|)
## factor(group)2 3.69102114 1.48251011 9.18957451 0.005016342395
## dfactor        0.45500721 0.31889988 0.64920551 0.000014109282</code></pre>
<p>於是，我們可以寫下這個邏輯迴歸的數學模型：</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\hat\pi_i) &amp; = \text{ln}(\frac{\hat\pi_i}{1-\hat\pi_i})  = \hat\alpha + \hat\beta_1 x_{i1} + \hat\beta_2 x_{i2} \\
                        &amp; = 2.1310 - 0.7874 \times \text{dfactor} + 1.3059 \times \text{group}
\end{aligned}
\]</span></p>
<p><strong>解讀這些參數估計的意義</strong></p>
<ul>
<li>截距 <span class="math inline">\(\hat\alpha = 2.1310\)</span> 的含義是，當 <span class="math inline">\(x_{1}, x_{2}\)</span> 都等於零，i.e. 飼料濃度 0，在第一羣的那些牲畜感染瘋牛病的<strong>對數比值 (log-odds)</strong>；</li>
<li>斜率 <span class="math inline">\(\hat\beta_1 = -0.7874\)</span> 的含義是，當牲畜羣不變時，飼料濃度每增加一個單位，牲畜感染瘋牛病的<strong>對數比值的估計變化量 (estimated increase in log odds of infection)</strong>；</li>
<li>迴歸係數 <span class="math inline">\(\hat\beta_2 = 1.3059\)</span> 的含義是，當飼料濃度不變時，兩羣牲畜之間感染瘋牛病的<strong>對數比值比 (log-Odds Ratio)</strong>，所以第二羣牲畜比第一羣牲畜感染瘋牛病的比值比的估計量，以及 <span class="math inline">\(95\%\text{CI}\)</span> 的計算方法就是：<br> <span class="math display">\[\begin{aligned} \text{exp}(\hat\beta_2) &amp; = \text{exp}(1.3059) = 3.69,\\ \text{ with 95% CI: } &amp; \text{exp}(\hat\beta_2 \pm 1.96\times \text{Std.Error}_{\hat\beta_2}) \\  &amp; = (1.48, 9.19) \end{aligned}\]</span></li>
</ul>
</div>
<div id="模型-2-增加交互作用項-飼料-times-羣" class="section level3">
<h3><span class="header-section-number">45.5.3</span> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</h3>
<p>飼料濃度與瘋牛病感染之間的關係，是否因爲牲畜所在的 “羣” 不同而發生改變？</p>
<p>定義增加了飼料和羣交互作用項的邏輯迴歸模型：</p>
<p><span class="math display">\[
\text{logit}(\pi_i) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1}\times x_{i2}
\]</span></p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb489-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(group)<span class="op">*</span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb489-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + 
##     dfactor + factor(group) * dfactor, family = binomial(link = logit), 
##     data = Cattle)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.71914  -0.16508  -0.02111   0.34451   1.00127  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)             1.89028    0.73584  2.5689 0.010203 * 
## factor(group)2          1.98867    1.34471  1.4789 0.139172   
## dfactor                -0.70508    0.22955 -3.0716 0.002129 **
## factor(group)2:dfactor -0.20583    0.37553 -0.5481 0.583619   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.52556  on 9  degrees of freedom
## Residual deviance:  2.14476  on 6  degrees of freedom
## AIC: 33.9477
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb491-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model2)</a></code></pre></div>
<pre><code>##  
##                                OR  lower95ci    upper95ci     Pr(&gt;|Z|)
## factor(group)2         7.30580425 0.52365757 101.92686809 0.1391720038
## dfactor                0.49406759 0.31506152   0.77477816 0.0021289774
## factor(group)2:dfactor 0.81396890 0.38989883   1.69927508 0.5836187644</code></pre>
<p>從輸出的報告來看，增加了交互作用項以後，在第一羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 是</p>
<p><span class="math display">\[
\text{exp}(-0.7051) = 0.49
\]</span></p>
<p>在第二羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 變成了</p>
<p><span class="math display">\[
\text{exp}(-0.7051 - 0.2058) = 0.40
\]</span></p>
<p>通過對 <span class="math inline">\(\hat\beta_3 = 0\)</span> 的假設檢驗，就可以推斷飼料濃度和感染瘋牛病之間的關係是否因爲不同牲畜 “羣” 而不同。所以上面的報告中也已經有了交互作用項的檢驗結果 <span class="math inline">\(p = 0.584\)</span>，所以，此處可以下的結論是：沒有足夠的證據證明交互作用存在。</p>
</div>
</div>
<div id="glm-practical-03" class="section level2">
<h2><span class="header-section-number">45.6</span> GLM-Practical 03</h2>
<p>數據來自一個毒理學實驗，該實驗中 8 組昆蟲在不同濃度的二硫化碳下暴露四個小時，實驗的目的是研究二硫化碳劑量和昆蟲死亡率之間的關系。</p>
<div id="昆蟲的死亡率" class="section level3">
<h3><span class="header-section-number">45.6.1</span> 昆蟲的死亡率</h3>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb493-1" title="1">Insect &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/INSECT.RAW&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;dose&quot;</span>, <span class="st">&quot;n_deaths&quot;</span>, <span class="st">&quot;n_subjects&quot;</span>))</a>
<a class="sourceLine" id="cb493-2" title="2"><span class="kw">print</span>(Insect)</a></code></pre></div>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<ol style="list-style-type: decimal">
<li>計算每組實驗濃度下死亡昆蟲的比例</li>
</ol>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb495-1" title="1">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb495-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> n_deaths<span class="op">/</span>n_subjects)</a>
<a class="sourceLine" id="cb495-3" title="3"><span class="kw">print</span>(Insect)</a></code></pre></div>
<pre><code>##    dose n_deaths n_subjects          p
## 1 49.06        6         59 0.10169492
## 2 52.99       13         60 0.21666667
## 3 56.91       18         62 0.29032258
## 4 60.84       28         56 0.50000000
## 5 64.76       52         63 0.82539683
## 6 68.69       53         59 0.89830508
## 7 72.61       60         62 0.96774194
## 8 76.54       59         60 0.98333333</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>將濃度和死亡比例做散點圖</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-3"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-3-1.png" alt="Scatter plot of CS2 dose and proportion killed." width="80%" />
<p class="caption">
圖 45.1: Scatter plot of CS2 dose and proportion killed.
</p>
</div>
<p>這裏如果使用<strong>線性回歸模型是不合適的</strong>，這是因爲:</p>
<ul>
<li>散點圖提示濃度和死亡比例之間不是線性關系;</li>
<li>“比例”這一數據被局限在 (0,1) 範圍之內，線性回歸的結果變量不會滿足這個條件;</li>
<li>觀察數據本身的方差不齊，也就是每個觀察點(死亡比例)的變化程度無法保證是相同的。</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>計算死亡比例的對數比值比 (log-odds)，再作相同的散點圖，你會得出什麼樣的結論？</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-4"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-4-1.png" alt="Scatter plot of CS2 dose and log-odds of proportion killed." width="80%" />
<p class="caption">
圖 45.2: Scatter plot of CS2 dose and log-odds of proportion killed.
</p>
</div>
<p>死亡比例的對數比值比和二硫化碳濃度之間更加接近線性關系。</p>
<ol start="4" style="list-style-type: decimal">
<li>寫下此模型的數學表達式，你的表達式必須指明數據的分布，線性預測方程，和鏈接方程三個部分。用 R 擬合你寫下的模型。</li>
</ol>
<p><strong>解</strong></p>
<p>本數據中，隨機變量是每組昆蟲中死亡的個數。用 <span class="math inline">\(Y_i\)</span> 標記第 <span class="math inline">\(i\)</span> 組昆蟲中死亡昆蟲數量，<span class="math inline">\(d_i\)</span> 表示第 <span class="math inline">\(i\)</span> 組昆蟲被暴露的二硫化碳濃度。對於所有的廣義線性回歸模型來說，它都由三個部分組成:
1) 反應量分布 the response distribution; 2) 鏈接方程 link function; 3) 線性預測方程 linear predictor.</p>
<p>反應量分布:</p>
<p><span class="math display">\[
Y_i \sim \text{Bin}(n_i, \pi_i),i = 1, \cdots, 8
\]</span></p>
<p><span class="math inline">\(Y_i\)</span> 的期望值是 <span class="math inline">\(\mu_i\)</span> 的話，鏈接方程是</p>
<p><span class="math display">\[
\eta_i = \log(\frac{\mu_i}{n_i - \mu_i}) = \log(\frac{\pi_i}{1- \pi_i}) = \text{logit}(\pi_i)
\]</span></p>
<p>線性預測方程是</p>
<p><span class="math display">\[
\eta_i = \beta_0 + \beta_1 d_i
\]</span></p>
<p>用 R 來擬合這個模型:</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb497-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb497-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose, 
##     family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.14983  -0.22403   0.25301   0.70846   0.99107  
## 
## Coefficients:
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -14.086403   1.228393 -11.467 &lt; 2.2e-16 ***
## dose          0.236593   0.020303  11.653 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   4.61548  on 6  degrees of freedom
## AIC: 37.394
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol style="list-style-type: decimal">
<li>計算 CS<sub>2</sub> 在 55mg/l 時該模型預測的昆蟲死亡概率是多少。</li>
</ol>
<p><span class="math display">\[
\text{logit}(\hat\pi_i) = -14.09 + 0.2366\times55 \\
\Rightarrow \hat\pi_i = \frac{\exp(-14.09 + 0.2366\times55)}{1+\exp(-14.09 + 0.2366\times55)} = 0.254
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>計算昆蟲死亡比例達到50%的CS<sub>2</sub>濃度(LD50)。</li>
</ol>
<p>當死亡比例達到一半時， <span class="math inline">\(\hat\pi = 0.5 \Rightarrow \text{logit}(\hat\pi) = 0\)</span></p>
<p><span class="math display">\[
0 = -14.09 + 0.2366 \times \text{LD50} \\
\Rightarrow \text{LD50} = 59.5 \text{mg/l}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>有證據證明昆蟲的死亡率隨着 CS<sub>2</sub> 濃度的增加而升高嗎？</li>
</ol>
<p>有極強的證據證明昆蟲死亡率隨着 CS<sub>2</sub> 濃度增加而升高 <span class="math inline">\((z = 11.65, P &lt; 0.001, \text{Wald test})\)</span>。</p>
<ol start="4" style="list-style-type: decimal">
<li>將參數轉換成比值比，並解釋其實際含義。</li>
</ol>
<p>CS<sub>2</sub> 濃每增加 1 個單位 (1 mg/l)，昆蟲死亡率的比值比是 <span class="math inline">\(\exp(0.2366) = 1.27\)</span>，95% 信賴區間下限: <span class="math inline">\(\exp(0.2366 - 1.96\times0.0203) = 1.22\)</span>，上限: <span class="math inline">\(\exp(0.2366 + 1.96\times0.0203) = 1.32\)</span>。</p>
<p>下面是在 R 裏計算的 OR 及其對應的信賴區間:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb499-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(n_deaths, n_subjects - n_deaths) 
##  
##                   OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## dose (cont. var.) 1.27 (1.22,1.32)  &lt; 0.001        &lt; 0.001   
##                                                              
## Log-likelihood = -16.697
## No. of observations = 8
## AIC value = 37.394</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>提取模型中擬合值 fitted value</li>
</ol>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb501-1" title="1"><span class="co"># the fitted values relate to the probability of the deaths in each group</span></a>
<a class="sourceLine" id="cb501-2" title="2">Model1<span class="op">$</span>fitted.values</a></code></pre></div>
<pre><code>##           1           2           3           4           5           6           7           8 
## 0.077332565 0.175181106 0.349349622 0.576375269 0.774754491 0.897077450 0.956586871 0.982405536</code></pre>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb503-1" title="1"><span class="co"># to calculate the counts of numbers of deaths in each group</span></a>
<a class="sourceLine" id="cb503-2" title="2">Model1<span class="op">$</span>fitted.values <span class="op">*</span><span class="st"> </span>Insect<span class="op">$</span>n_subjects</a></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7          8 
##  4.5626213 10.5108663 21.6596766 32.2770151 48.8095329 52.9275695 59.3083860 58.9443322</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>把模型擬合的概率和觀測概率放在同一個散點圖中比較:</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-8"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-8-1.png" alt="Observed (circles) and fitted (triangles) proportions are generally similar, with differences greatest in the third and fourth dose groups." width="80%" />
<p class="caption">
圖 45.3: Observed (circles) and fitted (triangles) proportions are generally similar, with differences greatest in the third and fourth dose groups.
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li>現在計算一個新的濃度值 dose2 = dose<sup>2</sup>。這個新的變量用於分析是否模型中使用濃度平方可以提升模型的擬合優度。1) 用 Wald 檢驗的結果說明濃度平方的回歸系數是否有意義。2) 新模型的擬合值是否有所改善？</li>
</ol>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb505-1" title="1">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb505-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dose2 =</span> dose<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb505-3" title="3">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose <span class="op">+</span><span class="st"> </span>dose2, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb505-4" title="4"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose + 
##     dose2, family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8  
## -0.004545   0.634377  -0.691056  -0.681962   1.223967  -0.154036  -0.029880  -0.561968  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.4881722  9.8677198 -0.2522   0.8009
## dose        -0.1500054  0.3291786 -0.4557   0.6486
## dose2        0.0031871  0.0027273  1.1686   0.2426
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   3.18361  on 5  degrees of freedom
## AIC: 37.9621
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>加入了濃度平方以後，該項本身的 Wald 檢驗結果告訴我們，沒有證據證明濃度和昆蟲死亡比例的對數比值比之間呈拋物線關系。</p>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-10"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-10-1.png" alt="Fitted probabilities for each dose from two models" width="80%" />
<p class="caption">
圖 45.4: Fitted probabilities for each dose from two models
</p>
</div>
<p>加入濃度平方二次項的模型在第三和第四組給出了比一次模型更加接近觀測值的估計。但是這種提升是極爲有限的，且統計學上加入的二次項的回歸系數並無意義。</p>
<p>所以，本數據分析的結論是，有很強的證據證明昆蟲死亡的概率隨着CS<sub>2</sub> 濃度的升高而升高 (P&lt;0.001)。死亡的比值 (odds)，隨着濃度每升高1個單位 (mg/l) 而升高 27% (95% CI: 22%-32%)。</p>
</div>
<div id="哮喘門診數據" class="section level3">
<h3><span class="header-section-number">45.6.2</span> 哮喘門診數據</h3>
<p>在一項橫斷面研究中，訪問哮喘門診連續達到 6 個月以上的全部患者被一一詢問其目前的用藥情況和症狀。下面的表格總結的是這些患者中，目前使用口服類固醇藥物與否，及患者報告夜間由於哮喘症狀而從睡眠中醒來的次數。</p>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exe-3-11">表 45.1: </span>Frequency of night waking due to asthma
</caption>
<thead>
<tr>
<th style="text-align:center;">
Corticosteroids
</th>
<th style="text-align:center;">
Never
</th>
<th style="text-align:center;">
Less.than.once.a.week
</th>
<th style="text-align:center;">
More.than.once.a.week
</th>
<th style="text-align:center;">
Every.night
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
User
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
44
</td>
<td style="text-align:center;">
38
</td>
</tr>
<tr>
<td style="text-align:center;">
Non-user
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
22
</td>
</tr>
</tbody>
</table>
<p>下面的 STATA 輸出報告，是對上述數據擬合的邏輯回歸的結果。其中變量 <code>user</code> 和 <code>never</code> 被編碼爲 0/1，1 代表該患者正在使用口服類固醇藥物，或者從未因爲哮喘而在夜間醒來。變量 <code>sev</code> 是患者自己報告的哮喘症狀嚴重程度 (0-3 分，分數越高症狀越嚴重)。</p>
<p><img src="img/Selection_125.png" width="90%" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>用表格的數據實施了一個總體的卡方檢驗還有一個卡方檢驗的傾向性檢驗。這兩個卡方檢驗的統計量分別是 12.87, 和 0.25。請解釋這兩個統計量的實際含義。</li>
</ol>
<p>在零假設 – 使用口服類固醇藥物和夜間因爲哮喘而醒來次數之間沒有關系 – 條件下，表格總體的卡方檢驗服從 <span class="math inline">\(\chi^2_3\)</span> 分布。查表或者在 R 裏使用</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb507-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="fl">12.87</span>, <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.0049263406</code></pre>
<p>可以知道 p = 0.005。這是極強的反對零假設的證據。</p>
<p>相反，卡方檢驗的傾向性檢驗結果是 p = 0.62，這個結果提示使用類固醇藥物所佔的比例沒有傾向性:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb509-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="fl">0.25</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.61707508</code></pre>
<p>兩個卡方檢驗的顯著不同應是因爲用類固醇藥物的患者比例在 “從不”, “低於每周一次”，“多餘每周一次” 中遞增，但是到了最後一組 “每天” 時又下降。傾向性檢驗比起總體的卡方檢驗在關系是單調遞增或者單調遞減時統計學效能更好，但是當關系變得復雜以後，傾向性卡方檢驗變得不再有優勢。傾向性檢驗其實等同於用一個變量 (用藥與否) 和另一個變量 (夜間因爲哮喘醒來次數) 做線性回歸。對於這個表格的數據來說，這是一個 U 型的關系，所以做線性回歸的結果也是會給出沒有意義的 p 值。</p>
<ol start="2" style="list-style-type: decimal">
<li>利用 STATA 的邏輯回歸報告，能對哮喘的嚴重程度和患者報告夜間從未因爲哮喘醒來(never wake up)之間的關系作出怎樣的結論？</li>
</ol>
<p>從 STATA 計算的結果來看，該數據提供了極強的證據證明哮喘的嚴重程度和報告從未因哮喘而醒來之間呈負相關。特別地，哮喘嚴重程度爲 2 的患者比 1 的患者報告從未醒來的比值比 (odds ratio) 是 0.077 (95% CI: 0.027, 0.224, p &lt; 0.001); 哮喘嚴重程度爲 3 的患者 比 1 的患者報告醒來的比值比是 0.0128 (95% CI: 0.0022, 0.0738, p &lt; 0.001)。所以，哮喘越嚴重，報告夜裏從未醒來的概率越低。</p>
<ol start="3" style="list-style-type: decimal">
<li>利用 STATA 的邏輯回歸報告，能對是否使用口服類固醇藥物和報告從未因哮喘而醒來之間的關系作出怎樣的結論？</li>
</ol>
<p>如果要計算未調整的比值比，我們可以把表格中第2-4列的數據合並，那麼在使用類固醇藥物的患者 (n = 150) 中 27 人報告從未醒來，在不使用類固醇藥物的患者中 (n = 60)，有 20 人報告從未醒來。這樣未調整的比值比就是 <span class="math inline">\(\frac{27 \times 40}{20 \times 123} = 0.44\)</span>。STATA 計算的邏輯回歸模型的結果顯示，這一數字在調整了哮喘症狀之後，發生了本質的變化:
<span class="math inline">\(e^{0.815} = 2.26\)</span>。雖然調整後的比值比並沒有統計學意義。但是它從小於 1 變成了大於 1，方向上發生了轉變。所以，調整了哮喘嚴重程度之後，數據似乎提示使用類固醇藥物和報告從不在夜間因哮喘醒來的概率呈正相關 (用藥者睡得更好)，但是這個相關性沒有統計學意義，其95%信賴區間很寬。</p>
<ol start="4" style="list-style-type: decimal">
<li>從這些分析來看，哮喘嚴重程度和是否口服類固醇藥物之間有什麼樣的關系？</li>
</ol>
<p>因爲用類固醇藥物和報告夜間不曾醒來在調整了哮喘嚴重程度之後從原先的負相關變成了正相關。又因爲哮喘嚴重程度本身和報告夜間不曾醒來之間是負相關，所以，是否口服類固醇藥物和哮喘嚴重程度之間呈正相關，也就是哮喘越嚴重，患者越傾向於使用類固醇藥物。</p>
</div>
</div>
</div>
<div id="模型比較和擬合優度" class="section level1">
<h1><span class="header-section-number">第 46 章</span> 模型比較和擬合優度</h1>
<p>我們用數據擬合廣義線性模型時其實有許多不同的目的和意義：</p>
<ol style="list-style-type: decimal">
<li>估計某些因素的暴露和因變量之間的相關程度，同時調整其餘的混雜因素；</li>
<li>確定能夠強有力的預測因變量變化的因子；</li>
<li>用於預測未來的事件或者病人的預後等等。</li>
</ol>
<p>但是一般情況下，我們拿到數據以後不可能立刻就能構建起來一個完美無缺的模型。我們常常會擬合兩三個甚至許多個模型，探索模型和數據的擬合程度，就成爲了比較哪個模型更優於其他模型的硬指標。本章的目的是介紹 GLM 嵌套式模型之間的兩兩比較方法，其中一個模型的預測變量是另一個模型的預測變量的子集。</p>
<p>對手裡的數據構建一個GLM的過程，其實就是在該數據的條件下(given the data)，對模型參數 <span class="math inline">\(\mathbf{\beta}\)</span> 定義其對數似然 (log-likelihood)，並尋找能給出極大值的那一系列極大似然估計 (maximum likelihood estimates, MLE) <span class="math inline">\(\mathbf{\hat\beta}\)</span> 的過程。每次構建一個模型，我們都會獲得該模型對應的極大對數似然，它其實是極爲依賴構建它的觀察數據的，意味着每次觀察數據發生變化，你即使用了相同的模型來擬合相同的GLM獲得的極大似然都會發生變化。所以其實我們並不會十分關心這個極大似然的絕對值大小。我們關心的其實是，當對相同數據，構建了包含不同變量的模型時，極大似然的<strong>變化量</strong>。因爲這個極大似然(或者常被略稱爲對數似然 log likelihood，甚至直接只叫做似然)的變化量本身確實會反應我們思考的模型，和觀察數據之間的擬合程度。一般來說，模型中變量較少的那個 (通常叫做更加一般化的模型 more general model)獲得的似然值和變量較多的那個模型獲得的似然值相比較都會比較小，我們關心的似然值在增加了新變量之後的複雜模型後獲得的<strong>增量</strong>，是否有價值，是否真的改善了模型的擬合度 (whether the difference in log likelihoods is large enough to indicate that the less general model provides a “real” improvement in fit)。</p>
<div id="嵌套式模型的比較-nested-models" class="section level2">
<h2><span class="header-section-number">46.1</span> 嵌套式模型的比較 nested models</h2>
<p>假如我們用相同的數據擬合兩個 GLM，<span class="math inline">\(\text{Model 1, Model 2}\)</span>。其中，當限制 <span class="math inline">\(\text{Model 2}\)</span> 中部分參數爲零之後會變成 <span class="math inline">\(\text{Model 1}\)</span>時， 我們說 <span class="math inline">\(\text{Model 1}\)</span> 是 <span class="math inline">\(\text{Model 2}\)</span> 的嵌套模型。</p>
<ul>
<li>例1：嵌套式模型 I
<br> 模型 1 的線性預測方程爲 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1}\]</span>
<br> 模型 2 和模型 1 的因變量相同 (分佈相同)，使用相同的鏈接方程 (link function) 和尺度參數 (scale parameter, <span class="math inline">\(\phi\)</span>)，但是它的線性預測方程爲 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i1} + \beta_3 x_{i3}\]</span>
<br> 此時我們說模型 1 是模型 2 的嵌套模型，因爲令 <span class="math inline">\(\beta_2 = \beta_3 = 0\)</span> 時，模型 2 就變成了 模型 1。</li>
<li>例2：嵌套式模型 II
<br> 模型 1 的線性預測方程爲 (此處默認 <span class="math inline">\(x_{i1}\)</span> 是連續型預測變量) <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1}\]</span>
<br> 模型 2 的線性預測方程如果是 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x^2_{i1}\]</span>
<br> 此時我們依然認爲 模型 1 是模型 2 的嵌套模型， 因爲令 <span class="math inline">\(\beta_2 = 0\)</span> 時，模型 2 就變成了 模型 1。</li>
</ul>
<p>關於嵌套式模型，更加一般性的定義是這樣的：<strong>標記模型 2 的參數向量是 <span class="math inline">\(\mathbf{(\psi, \lambda)}\)</span>，其中，當我們限制了參數向量的一部分例如 <span class="math inline">\(\mathbf{\psi = 0}\)</span>，模型 2 就變成了 模型 1 的話，模型 1 就是嵌套於 模型 2 的</strong>。所以比較嵌套模型之間的擬合度，我們可以比較較爲複雜的 模型 2 相較 模型 1 多出來的複雜的預測變量參數部分 <span class="math inline">\(\mathbf{\psi}\)</span> 是否是必要的。也就是說，比較嵌套模型哪個更優的情況下，零假設是 <span class="math inline">\(\mathbf{\psi = 0}\)</span>。</p>
<p>這是典型的多變量的模型比較，需要用到子集似然比檢驗 <a href="#profile-log-likelihood">19</a>，log-likelihood ratio test：</p>
<p><span class="math display">\[
\begin{aligned}
-2pllr(\psi = 0) &amp; = -2\{ \ell_p(\psi=0) - \ell_p(\hat\psi) \} \stackrel{\cdot}{\sim} \chi^2_{df}\\
\text{Where } \hat\psi &amp; \text{ denotes the MLE of } \psi \text{ in Model 2} \\
\text{With } df &amp; = \text{ the dimension of } \mathbf{\psi}
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\ell_p(\psi=0)\)</span>，其實是 模型 1 的極大對數似然，記爲 <span class="math inline">\(\ell_1\)</span>。<span class="math inline">\(\ell_p(\hat\psi)\)</span> 其實是 模型 2 的極大對數似然，記爲 <span class="math inline">\(\ell_2\)</span>。所以這個似然比檢驗統計量就變成了：</p>
<p><span class="math display">\[
-2pllr(\psi = 0) = -2(\ell_1-\ell_2)
\]</span></p>
<p>這個統計量在零假設的條件下服從自由度爲兩個模型參數數量之差的卡方分佈。如果 <span class="math inline">\(p\)</span> 值小於提前定義好的顯著性水平，將會提示有足夠證據證明 模型 2 比 模型 1 更好地擬合數據。</p>
</div>
<div id="嵌套式模型比較實例" class="section level2">
<h2><span class="header-section-number">46.2</span> 嵌套式模型比較實例</h2>
<p>回到之前用過的瘋牛病和牲畜羣的數據 <a href="#BSEinfection">45.5</a>。我們當時成功擬合了兩個 GLM 模型，模型 1 的預測變量只有 “飼料”，“羣”；模型 2 的預測變量在模型 1 的基礎上增加二者的交互作用項。並且我們當時發現交互作用項部分並無實際統計學意義 <span class="math inline">\(p = 0.584\)</span>。現在用對數似然比檢驗來進行類似的假設檢驗。</p>
<p>先用 <code>logLik(Model)</code> 的方式提取兩個模型各自的對數似然，然後計算對數似然比，再去和自由度爲 1 (因爲兩個模型只差了 1 個預測變量) 的卡方分佈做比較：</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb511-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb511-2" title="2">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(group)<span class="op">*</span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb511-3" title="3"><span class="kw">logLik</span>(Model1)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -13.12687 (df=3)</code></pre>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb513-1" title="1"><span class="kw">logLik</span>(Model2)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -12.973836 (df=4)</code></pre>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb515-1" title="1">LLR &lt;-<span class="st"> </span><span class="dv">-2</span><span class="op">*</span>(<span class="kw">logLik</span>(Model1) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(Model2))</a>
<a class="sourceLine" id="cb515-2" title="2"></a>
<a class="sourceLine" id="cb515-3" title="3"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(LLR), <span class="dt">df=</span><span class="dv">1</span>) <span class="co"># p value for the LLR test</span></a></code></pre></div>
<pre><code>## [1] 0.58010367</code></pre>
<p>再和 <code>lmtest::lrtest</code> 的輸出結果作比較。</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb517-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: cbind(infect, cattle - infect) ~ factor(group) + dfactor
## Model 2: cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group) * 
##     dfactor
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)
## 1   3 -13.1269                      
## 2   4 -12.9738  1 0.30607     0.5801</code></pre>
<p>結果跟我們手計算的結果完全吻合。AWESOME !!!</p>
<p>值得注意的是，此時進行的似然比檢驗結果獲得的 p 值，和模型中 Wald 檢驗結果獲得的 p 值十分接近 (0.5801 v.s. 0.584)，這也充分顯示了這兩個檢驗方法其實是漸進相同的 (asymptotically equivalent)。</p>
</div>
<div id="飽和模型模型的偏差擬合優度" class="section level2">
<h2><span class="header-section-number">46.3</span> 飽和模型，模型的偏差，擬合優度</h2>
<p>在簡單線性迴歸中，殘差平方和提供了模型擬合數據好壞的指標 – 決定係數 <span class="math inline">\(R^2\)</span> (Section <a href="#Rsquare">28.2.3</a>)，並且在 偏 F 檢驗 (Section <a href="#partialF">30.3.4</a>) 中得到模型比較的應用。</p>
<p>廣義線性迴歸模型中事情雖然沒有這麼簡單，但是思想可以借鑑。先介紹飽和模型 (saturated model) 的概念，再介紹其用於模型偏差 (deviance) 比較的方法。前文中介紹過的嵌套模型之間的對數似然比檢驗，也是測量兩個模型之間偏差大小的方法。</p>
<div id="飽和模型-saturated-model" class="section level3">
<h3><span class="header-section-number">46.3.1</span> 飽和模型 saturated model</h3>
<p>飽和模型 saturated model，是指一個模型中所有可能放入的參數都被放進去的時候，模型達到飽和，自由度爲零。其實就是模型中參數的數量和觀測值個數相等的情況。飽和模型的情況下，所有的擬合值和對應的觀測值相等。所以，對於給定的數據庫，飽和模型提供了所有模型中最 “完美” 的擬合值，因爲擬合值和觀測值完全一致，所以飽和模型的對數似然，比其他所有你建立的模型的對數似然都要大。但是多數情況下，飽和模型並不是合理的模型，不能用來預測也無法拿來解釋數據，因爲它本身就是數據。</p>
</div>
<div id="deviance" class="section level3">
<h3><span class="header-section-number">46.3.2</span> 模型偏差 deviance</h3>
<p>令 <span class="math inline">\(L_c\)</span> 是目前擬合模型的對數似然，<span class="math inline">\(L_s\)</span> 是數據的飽和模型的對數似然，所以兩個模型的對數似然比是 <span class="math inline">\(\frac{L_c}{L_s}\)</span>。那麼尺度化的模型偏差 (scaled deviance) <span class="math inline">\(S\)</span> 被定義爲：</p>
<p><span class="math display">\[
S=-2\text{ln}(\frac{L_c}{L_s}) = -2(\ell_c - \ell_s)
\]</span></p>
<p>值得注意的是，非尺度化偏差 (unscaled deviance) 被定義爲 <span class="math inline">\(\phi S\)</span>，其中的 <span class="math inline">\(\phi\)</span> 是尺度參數，由於泊松分佈和二項分佈的尺度參數都等於 1 (<span class="math inline">\(\phi = 1\)</span>)，所以尺度化偏差和非尺度化偏差才會在數值上相等。</p>
<p>這裏定義的模型偏差大小，可以反應一個模型擬合數據的程度，偏差越大，該模型對數據的擬合越差。“Deviance can be interpreted as Badness of fit”.</p>
<p><strong>但是，模型偏差只適用於彙總後的二項分佈數據(aggregated)。當數據是個人的二分類數據時 (inidividual binary data)，模型的偏差值變得不再適用，無法用來比較模型對數據的擬合程度。</strong> 這是因爲當你的觀測值 (個人數據) 有很多時，擬合飽和模型所需要的參數個數會趨向於無窮大，這違背了子集對數似然比檢驗的條件。</p>
</div>
<div id="彙總型二項分佈數據-aggregatedgrouped-binary-data" class="section level3">
<h3><span class="header-section-number">46.3.3</span> 彙總型二項分佈數據 aggregated/grouped binary data</h3>
<p>假如，觀察數據是互相獨立的，服從二項分佈的 <span class="math inline">\(n\)</span> 個觀測值: <span class="math inline">\(Y_i \sim Bin(n_i, \pi_i), i=1,\dots,n\)</span>。用彙總型的數據表達方法來描述它，那麼獲得的數據就是一個個分類變量在各自組中的人數或者百分比的數據 (如下面的數據所示)。這樣的數據的飽和模型，其實允許了每個分類變量的組中百分比變化 (The saturated model for this data allows the probability of “success” to be different in each group, so that <span class="math inline">\(\tilde{\pi} = \frac{y_i}{n_i}\)</span>)。也就是每組的模型擬合後百分比，等於觀察到的百分比。</p>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<p>那麼彙總型二項分佈數據，其飽和模型的對數似然其實就是</p>
<p><span class="math display">\[
\ell_s = \sum_{i = 1}^n\{ \log\binom{n_i}{y_i} + y_i\log(\tilde{\pi_i}) + (n_i - y_i)\log(1 - \tilde{\pi_i}) \}
\]</span></p>
<p>假設此時我們給這個數據擬合一個非飽和模型，該模型告訴我們每個分類組中的預測百分比是 <span class="math inline">\(\hat\pi_i, i = 1, \dots, n\)</span>，那麼這個非飽和模型的對數似然其實是</p>
<p><span class="math display">\[
\ell_c = \sum_{i = 1}^n\{ \binom{n_i}{y_i} + y_i\log(\hat\pi_i) + (n_i - y_i)\log(1-\hat\pi_i)\}
\]</span></p>
<p>那麼這個非飽和模型的模型偏差 (deviance) 就等於</p>
<p><span class="math display">\[
\begin{aligned}
S &amp; = -2(\ell_c - \ell_s) \\
  &amp; = 2\sum_{i = 1}^n\{ y_i\log(\frac{\tilde{\pi_i}}{\hat\pi_i}) + (n_i - y_i)\log(\frac{1-\tilde{\pi_i}}{1-\hat\pi_i}) \}
\end{aligned}
\]</span></p>
<p>從上面這個表達式不難看出，模型偏差值的大小，將會隨着模型預測值的變化而變化，如果它更加接近飽和模型的預測值 (飽和模型的預測值其實就等於觀測值)，那麼模型的偏差就會比較小。如果你的彙總型數據擬合了你認爲合適的模型以後，你發現它的模型偏差值很大，那麼就意味着你的模型預測值其實和觀測值相去甚遠，模型和觀測值的擬合度應該不理想。對於彙總型數據來說，模型偏差值，其實等價於將你擬合的模型和飽和模型之間做子集對數似然比檢驗 (profile log-likelihood ratio test)。漸進來說 (asymptotically)，這個子集對數似然比檢驗的結果，會服從自由度爲 <span class="math inline">\(n-p\)</span> 的 <span class="math inline">\(\chi^2\)</span> 分佈，其中 <span class="math inline">\(n, p\)</span> 分別是飽和模型和你擬合的模型中被估計參數的個數。</p>
</div>
</div>
<div id="gof" class="section level2">
<h2><span class="header-section-number">46.4</span> 個人數據擬合模型的優度檢驗</h2>
<p>在上文中已經提到了，當你的數據不再是彙總型二項分佈數據，而是個人二項分佈數據 (individual binary data) 時，模型偏差 (deviance) 無法用來評價你建立的模型。這樣的數據其實比彙總型二項分佈數據更加常見，當模型中一旦需要加入一個連續型變量時，數據就只能被表達爲個人二項分佈數據。對於個人二項分佈數據模型擬合度比較，最常用的方法是 <span class="citation">(Hosmer and Lemesbow <a href="#ref-hosmer1980goodness" role="doc-biblioref">1980</a>)</span> 提出的模型擬合優度檢驗法 (goodness of fit)。該方法的主要思想是，把個人二項分佈數據模型獲得的個人預測值 (model predicted probabilities) <span class="math inline">\(\hat\pi_i\)</span> 進行人爲的分組，把預測值數據強行變成彙總型二項分佈數據，那麼觀測值的樣本量即使增加到無窮大，也不會使得模型中組別增加到無窮大，從而可以規避</p>
<p>在 R 裏面，進行邏輯迴歸模型的擬合優度檢驗的自定義方程如下，參考<a href="http://data.princeton.edu/wws509/r/c3s8.html">網站</a>：</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb520-1" title="1">hosmer &lt;-<span class="st"> </span><span class="cf">function</span>(y, fv, <span class="dt">groups=</span><span class="dv">10</span>, <span class="dt">table=</span><span class="ot">TRUE</span>, <span class="dt">type=</span><span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb520-2" title="2"> <span class="co"># A simple implementation of the Hosmer-Lemeshow test</span></a>
<a class="sourceLine" id="cb520-3" title="3">   q &lt;-<span class="st"> </span><span class="kw">quantile</span>(fv, <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span><span class="op">/</span>groups), <span class="dt">type=</span>type)</a>
<a class="sourceLine" id="cb520-4" title="4">   fv.g &lt;-<span class="st"> </span><span class="kw">cut</span>(fv, <span class="dt">breaks=</span>q, <span class="dt">include.lowest=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb520-5" title="5">   obs &lt;-<span class="st"> </span><span class="kw">xtabs</span>( <span class="op">~</span><span class="st"> </span>fv.g <span class="op">+</span><span class="st"> </span>y)</a>
<a class="sourceLine" id="cb520-6" title="6">   fit &lt;-<span class="st"> </span><span class="kw">cbind</span>( <span class="dt">e.0 =</span> <span class="kw">tapply</span>(<span class="dv">1</span><span class="op">-</span>fv, fv.g, sum), <span class="dt">e.1 =</span> <span class="kw">tapply</span>(fv, fv.g, sum))</a>
<a class="sourceLine" id="cb520-7" title="7">   <span class="cf">if</span>(table) <span class="kw">print</span>(<span class="kw">cbind</span>(obs,fit))</a>
<a class="sourceLine" id="cb520-8" title="8">   chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((obs<span class="op">-</span>fit)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>fit)</a>
<a class="sourceLine" id="cb520-9" title="9">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, groups<span class="dv">-2</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb520-10" title="10">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Hosmer-Lemeshow&quot;</span>,<span class="dt">groups=</span>groups,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a>
<a class="sourceLine" id="cb520-11" title="11"> }</a></code></pre></div>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb521-1" title="1"><span class="co"># lbw &lt;- read_dta(&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;)</span></a>
<a class="sourceLine" id="cb521-2" title="2">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="dt">file =</span> <span class="st">&quot;backupfiles/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb521-3" title="3">lbw<span class="op">$</span>race &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>race)</a>
<a class="sourceLine" id="cb521-4" title="4">lbw<span class="op">$</span>smoke &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>smoke)</a>
<a class="sourceLine" id="cb521-5" title="5">lbw<span class="op">$</span>ht &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>ht)</a>
<a class="sourceLine" id="cb521-6" title="6">Modelgof &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>lwt <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>ptl <span class="op">+</span><span class="st"> </span>ht <span class="op">+</span><span class="st"> </span>ui, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</a>
<a class="sourceLine" id="cb521-7" title="7"><span class="kw">hosmer</span>(lbw<span class="op">$</span>low, <span class="kw">fitted</span>(Modelgof))</a></code></pre></div>
<pre><code>##                  0  1        e.0        e.1
## [0.0273,0.0827] 19  0 17.8222227  1.1777773
## (0.0827,0.128]  17  2 16.9739017  2.0260983
## (0.128,0.201]   13  6 15.8285445  3.1714555
## (0.201,0.243]   18  1 14.6957098  4.3042902
## (0.243,0.279]   12  7 14.1062047  4.8937953
## (0.279,0.314]   12  7 13.3601242  5.6398758
## (0.314,0.387]   13  6 12.4628053  6.5371947
## (0.387,0.483]   12  7 10.8241660  8.1758340
## (0.483,0.594]    9 10  8.6901416 10.3098584
## (0.594,0.839]    5 13  5.2361795 12.7638205</code></pre>
<pre><code>##              test groups    chi.sq     pvalue
## 1 Hosmer-Lemeshow     10 9.6506834 0.29040407</code></pre>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb524-1" title="1"><span class="kw">hosmer</span>(lbw<span class="op">$</span>low, <span class="kw">fitted</span>(Modelgof), <span class="dt">group=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>##                 0  1       e.0        e.1
## [0.0273,0.128] 36  2 34.796124  3.2038756
## (0.128,0.243]  31  7 30.524254  7.4757458
## (0.243,0.314]  24 14 27.466329 10.5336711
## (0.314,0.483]  25 13 23.286971 14.7130287
## (0.483,0.839]  14 23 13.926321 23.0736789</code></pre>
<pre><code>##              test groups   chi.sq     pvalue
## 1 Hosmer-Lemeshow      5 2.435921 0.48698297</code></pre>
</div>
<div id="glm-practical-04" class="section level2">
<h2><span class="header-section-number">46.5</span> GLM Practical 04</h2>
<div id="回到之前的昆蟲數據嘗試評價該模型的擬合優度" class="section level3">
<h3><span class="header-section-number">46.5.1</span> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</h3>
<ol style="list-style-type: decimal">
<li>重新讀入昆蟲數據，擬合前一個練習中擬合過的模型，使用 <code>glm()</code> 命令。</li>
</ol>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb527-1" title="1">Insect &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/INSECT.RAW&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;dose&quot;</span>, <span class="st">&quot;n_deaths&quot;</span>, <span class="st">&quot;n_subjects&quot;</span>))</a>
<a class="sourceLine" id="cb527-2" title="2"><span class="co"># print(Insect)</span></a>
<a class="sourceLine" id="cb527-3" title="3">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb527-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> n_deaths<span class="op">/</span>n_subjects)</a>
<a class="sourceLine" id="cb527-5" title="5"></a>
<a class="sourceLine" id="cb527-6" title="6">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb527-7" title="7"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose, 
##     family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.14983  -0.22403   0.25301   0.70846   0.99107  
## 
## Coefficients:
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -14.086403   1.228393 -11.467 &lt; 2.2e-16 ***
## dose          0.236593   0.020303  11.653 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   4.61548  on 6  degrees of freedom
## AIC: 37.394
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>根據上面模型輸出的結果，檢驗是否有證據證明該模型對數據的擬合不佳。</li>
</ol>
<p>上面模型擬合的輸出結果中，可以找到最下面的模型偏差值的大小和相應的自由度： <code>Residual deviance:   4.6155  on 6  degrees of freedom</code>。如果我們要檢驗該模型中假設的前提條件之一–昆蟲死亡的對數比值 (on a log-odds scale) 和藥物濃度 (dose) 之間是線性關係（或者你也可以說，檢驗是否有證據證明該模型對數據擬合不佳），我們可以比較計算獲得的模型偏差值在自由度為 6 的卡方分布 (<span class="math inline">\(\chi^2_6\)</span>) 中出現的概率。這裡自由度 6 是由 <span class="math inline">\(n - p = 8 - 2\)</span> 計算獲得，其中 <span class="math inline">\(n\)</span> 是數據中觀察值個數，<span class="math inline">\(p\)</span> 是模型中估計的參數的個數。檢驗方法很簡單：</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb529-1" title="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">4.6155</span>, <span class="dt">df =</span> <span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.59398469</code></pre>
<p>所以，檢驗的結果，P 值就是 0.594，沒有任何證據反對零假設（模型擬合數據合理）。</p>
<ol start="3" style="list-style-type: decimal">
<li>試比較兩個模型對數據的擬合效果孰優孰劣：模型1，上面的模型；模型2，加入劑量的平方 (dose<sup>2</sup>)，作為新增的模型解釋變量。嵌套式模型之間的比較使用的是似然比檢驗法 (profile likelihood ratio test)，試着解釋這個比較方法和 Wald 檢驗之間的區別。</li>
</ol>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb531-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(dose<span class="op">^</span><span class="dv">2</span>), <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb531-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose + 
##     I(dose^2), family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8  
## -0.004545   0.634377  -0.691056  -0.681962   1.223967  -0.154036  -0.029880  -0.561968  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.4881722  9.8677198 -0.2522   0.8009
## dose        -0.1500054  0.3291786 -0.4557   0.6486
## I(dose^2)    0.0031871  0.0027273  1.1686   0.2426
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   3.18361  on 5  degrees of freedom
## AIC: 37.9621
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb533-1" title="1"><span class="kw">anova</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cbind(n_deaths, n_subjects - n_deaths) ~ dose
## Model 2: cbind(n_deaths, n_subjects - n_deaths) ~ dose + I(dose^2)
##   Resid. Df Resid. Dev Df Deviance
## 1         6    4.61548            
## 2         5    3.18361  1  1.43188</code></pre>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb535-1" title="1"><span class="co"># P-value for model comparison</span></a>
<a class="sourceLine" id="cb535-2" title="2"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">1.43</span>, <span class="dt">df =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.23176444</code></pre>
<p>兩個模型比較的結果表明，無證據反對零假設（只用線性關係擬合數據是合理的），也就是說增加劑量的平方這一新的解釋變量並不能提升模型對數據的擬合程度。仔細觀察模型2的輸出結果中，可以發現 <code>I(dose^2)</code> 項的 Wald 檢驗結果是 <code>p = 0.24</code>，十分接近似然比檢驗的結果。因為它們兩者是漸近相同的 (asymptotically equivalent)。</p>
</div>
<div id="低出生體重數據" class="section level3">
<h3><span class="header-section-number">46.5.2</span> 低出生體重數據</h3>
<ol style="list-style-type: decimal">
<li>讀入該數據，試分析數據中和低出生體重可能相關的變量：</li>
</ol>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb537-1" title="1">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb537-2" title="2"><span class="kw">head</span>(lbw)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 11
##      id   low   age   lwt      race         smoke   ptl    ht    ui   ftv   bwt
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    85     0    19   182 2 [black] 0 [nonsmoker]     0     0     1     0  2523
## 2    86     0    33   155 3 [other] 0 [nonsmoker]     0     0     0     3  2551
## 3    87     0    20   105 1 [white] 1 [smoker]        0     0     0     1  2557
## 4    88     0    21   108 1 [white] 1 [smoker]        0     0     1     2  2594
## 5    89     0    18   107 1 [white] 1 [smoker]        0     0     1     0  2600
## 6    91     0    21   124 3 [other] 0 [nonsmoker]     0     0     0     0  2622</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>擬合一個這樣的邏輯回歸模型：結果變量使用低出生體重與否 <code>low</code>，解釋變量使用母親最後一次月經時體重 <code>lwt</code> (磅)。</li>
</ol>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb539-1" title="1">M &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</a>
<a class="sourceLine" id="cb539-2" title="2"><span class="kw">summary</span>(M)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ lwt, family = binomial(link = logit), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.09482  -0.90217  -0.80197   1.36105   1.98141  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  0.9957634  0.7852434  1.2681  0.20476  
## lwt         -0.0140371  0.0061685 -2.2756  0.02287 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 228.708  on 187  degrees of freedom
## AIC: 232.708
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb541-1" title="1"><span class="kw">logistic.display</span>(M)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## lwt (cont. var.) 0.99 (0.97,1)  0.023          0.015     
##                                                          
## Log-likelihood = -114.354
## No. of observations = 189
## AIC value = 232.7081</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>利用 <code>lowess</code> 平滑曲線作圖，評價在 logit 單位上，<code>lwt</code> 和 <code>low</code> 之間是否可以認為是線性關係。</li>
</ol>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb543-1" title="1">pi &lt;-<span class="st"> </span>M<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb543-2" title="2"></a>
<a class="sourceLine" id="cb543-3" title="3"><span class="co"># with(lbw, scatter.smooth(lwt, pi, pch = 20, span = 0.4, lpars =</span></a>
<a class="sourceLine" id="cb543-4" title="4"><span class="co">#                  list(col = &quot;blue&quot;, lwd = 3, lty = 1), col=rgb(0,0,0,0.004),</span></a>
<a class="sourceLine" id="cb543-5" title="5"><span class="co">#                  xlab = &quot;Mother&#39;s weight at last menstural period (lbs)&quot;,</span></a>
<a class="sourceLine" id="cb543-6" title="6"><span class="co">#                  ylab = &quot;Logit(probability) of being low birth weight&quot;,</span></a>
<a class="sourceLine" id="cb543-7" title="7"><span class="co">#                  frame = FALSE))</span></a>
<a class="sourceLine" id="cb543-8" title="8"></a>
<a class="sourceLine" id="cb543-9" title="9"><span class="kw">plot</span>(lbw<span class="op">$</span>lwt, lbw<span class="op">$</span>low, <span class="dt">main=</span><span class="st">&quot;Lowess smoother plot</span><span class="ch">\n</span><span class="st"> of the prob of having a low brith weight baby&quot;</span>, </a>
<a class="sourceLine" id="cb543-10" title="10">     <span class="dt">xlab =</span> <span class="st">&quot;Weight at at last menstural period (lbs)&quot;</span>, </a>
<a class="sourceLine" id="cb543-11" title="11">     <span class="dt">ylab =</span> <span class="st">&quot;Probability&quot;</span>)</a>
<a class="sourceLine" id="cb543-12" title="12"><span class="kw">lines</span>(<span class="kw">lowess</span>(lbw<span class="op">$</span>lwt, lbw<span class="op">$</span>low, <span class="dt">f =</span> <span class="fl">0.7</span>), <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb543-13" title="13"><span class="kw">points</span>(lbw<span class="op">$</span>lwt, pi)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:GLM-prac04-06"></span>
<img src="bookdown_files/figure-html/GLM-prac04-06-1.png" alt="The loess plot of the observed proportion with low birth weight against mother's weight at last menstural period. Span = 0.6" width="100%" />
<p class="caption">
圖 46.1: The loess plot of the observed proportion with low birth weight against mother’s weight at last menstural period. Span = 0.6
</p>
</div>
<p>Lowess 平滑曲線提示模型的擬合值(<code>fitted.values</code>)有一些變動，由於樣本採樣方法等原因，這是無法避免的。但是總體來說，擬合值和平滑曲線基本在同一個步調上，從該圖來看，認為母親的最後一次月經時體重和是否生下低出生體重兒的概率的 logit 之間的關係是線性的應該不是太大的問題。</p>
</div>
</div>
</div>
<div id="計數型因變量-poisson-regression" class="section level1">
<h1><span class="header-section-number">第 47 章</span> 計數型因變量 Poisson regression</h1>
<p>計數型變量在醫學研究中也十分常見，下面是一些例子：</p>
<ol style="list-style-type: decimal">
<li>某個呼吸科診所的患者中，每個人在過去一個月中哮喘發作的次數；</li>
<li>癲癇患者在過去一年中癲癇發作次數；</li>
<li>接受腦部 CT 掃描的患者中，每個人被診斷出顱內腫瘤個數。</li>
</ol>
<div id="泊松-glm" class="section level2">
<h2><span class="header-section-number">47.1</span> 泊松 GLM</h2>
<p>一個計數型的隨機變量，只能取大於等於零的正整數，<span class="math inline">\(0,1,\cdots\)</span>。泊松模型可以用於計數型數據的迴歸模型的構建：</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;\sim \text{Po}(\mu) \\
\text{P} (Y = y) &amp; = \frac{\mu^y e^{-\mu}}{y!}
\end{aligned}
\]</span></p>
<p>所以，一個泊松迴歸，默認的前提是因變量 <span class="math inline">\(Y\)</span> 服從一個以預測變量 <span class="math inline">\(x_1, \cdots, x_p\)</span> 爲條件的泊松分佈。其標準鏈接方程是 <span class="math inline">\(\theta=\text{log}(\mu)\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp; \sim \text{Po}(\mu_i) \\
\text{log}(\mu_i) &amp; = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>觀測對象 1，用模型中全部的預測變量 <span class="math inline">\(\mathbf{x_1}=(x_{11},\cdots,x_{1p})\)</span> 計算獲得的擬合值，和另一個觀測對象 0 的擬合值之比爲：</p>
<p><span class="math display">\[
\begin{aligned}
  &amp; \frac{\text{exp}(\alpha + \beta_1 x_{11} + \cdots + \beta_p x_{1p})}{\text{exp}(\alpha + \beta_1 x_{01} + \cdots + \beta_p x_{0p})} \\
= &amp; exp(\beta_1(x_{11}-x_{01}) + \cdots + \beta_p(x_{1p} - x_{0p}))
\end{aligned}
\]</span></p>
<p>其中，</p>
<ul>
<li>線性預測方程 linear predictor 中的截距 <span class="math inline">\(\alpha\)</span> 的含義是，<strong>當所有的預測變量均等於零 <span class="math inline">\(\mathbf{x_1} = 0\)</span></strong> 時，<strong>因變量 <span class="math inline">\(Y\)</span> 的均值之對數</strong>。</li>
<li><span class="math inline">\(\beta_1\)</span> 的含義是，<strong>其餘預測變量保持不變時，預測變量 <span class="math inline">\(x_1\)</span> 每增加一個單位時，因變量變化量的對數</strong>。</li>
<li>迴歸係數的指數 (自然底數) 大小，可以被理解爲是<strong>率比 (rate ratio)</strong> (詳見下一章率的 GLM)。</li>
</ul>
</div>
<div id="泊松迴歸實例" class="section level2">
<h2><span class="header-section-number">47.2</span> 泊松迴歸實例</h2>
<p>下列數據來自 <a href="https://stats.idre.ucla.edu/r/dae/poisson-regression/">UCLA 的統計學網站</a>。數據內容是某高中全部學生，獲獎的次數。預測變量包括，1) 獲獎種類 “一般 General”，“學術類 Academic”，“技能類 Vocational”；和所有學生期末數學考試分數。</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb544-1" title="1">p &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;backupfiles/poisson_sim.csv&quot;</span>)</a></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   id = col_double(),
##   num_awards = col_double(),
##   prog = col_double(),
##   math = col_double()
## )</code></pre>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb546-1" title="1">p &lt;-<span class="st"> </span><span class="kw">within</span>(p, {</a>
<a class="sourceLine" id="cb546-2" title="2">  prog &lt;-<span class="st"> </span><span class="kw">factor</span>(prog, <span class="dt">levels=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;General&quot;</span>, <span class="st">&quot;Academic&quot;</span>,</a>
<a class="sourceLine" id="cb546-3" title="3">                                                     <span class="st">&quot;Vocational&quot;</span>))</a>
<a class="sourceLine" id="cb546-4" title="4">  id &lt;-<span class="st"> </span><span class="kw">factor</span>(id)</a>
<a class="sourceLine" id="cb546-5" title="5">})</a>
<a class="sourceLine" id="cb546-6" title="6"><span class="kw">summary</span>(p)</a></code></pre></div>
<pre><code>##        id        num_awards           prog          math       
##  1      :  1   Min.   :0.00   General   : 45   Min.   :33.000  
##  2      :  1   1st Qu.:0.00   Academic  :105   1st Qu.:45.000  
##  3      :  1   Median :0.00   Vocational: 50   Median :52.000  
##  4      :  1   Mean   :0.63                    Mean   :52.645  
##  5      :  1   3rd Qu.:1.00                    3rd Qu.:59.000  
##  6      :  1   Max.   :6.00                    Max.   :75.000  
##  (Other):194</code></pre>
<p>下面的代碼擬合因變量爲獲獎次數，預測變量爲獲獎種類 (分類) 和數學成績 (連續) 的泊松分佈，泊松分佈默認的鏈接方程就是 <span class="math inline">\(\text{log}\)</span>，所以你可以像第一行那樣把鏈接方程部分省略。結果也是一樣的。</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb548-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>, <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb548-2" title="2">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb548-3" title="3"><span class="kw">summary</span>(m1); <span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = &quot;poisson&quot;, data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = poisson(link = log), 
##     data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>輸出結果的迴歸係數部分，</p>
<ul>
<li>該學校學生獲得學術類獎項的平均次數和獲得一般獎項的平均次數的比值是 <span class="math inline">\(\text{exp}(1.6094) = 4.999\)</span>，所以獲得的學術類獎平均次數要高於一般獎次數 <span class="math inline">\(390\%\)</span>；</li>
<li>獲得技能類獎的平均次數和一般獎平均次數的比值是 <span class="math inline">\(\text{exp}(0.1823) = 1.199\)</span>，也就是高出了 <span class="math inline">\(19.9\%\)</span>；</li>
<li>該校學生獲得一般類獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094) = 0.20\)</span> 次；</li>
<li>該校學生獲得學術獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094 + 1.6094) = 1\)</span> 次；(一人一次夠流弊)</li>
<li>該校學生獲得技能類獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094 + 0.182) = 0.24\)</span> 次。</li>
</ul>
<p>看來該校師生很重視學術。</p>
<p>當然也可以用下面定義的函數來幫助我們計算上面這些數值，及其信賴區間。</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb551-1" title="1">glm.RR &lt;-<span class="st"> </span><span class="cf">function</span>(GLM.RESULT, <span class="dt">digits =</span> <span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb551-2" title="2"></a>
<a class="sourceLine" id="cb551-3" title="3">    <span class="cf">if</span> (GLM.RESULT<span class="op">$</span>family<span class="op">$</span>family <span class="op">==</span><span class="st"> &quot;binomial&quot;</span>) {</a>
<a class="sourceLine" id="cb551-4" title="4">        LABEL &lt;-<span class="st"> &quot;OR&quot;</span></a>
<a class="sourceLine" id="cb551-5" title="5">    } <span class="cf">else</span> <span class="cf">if</span> (GLM.RESULT<span class="op">$</span>family<span class="op">$</span>family <span class="op">==</span><span class="st"> &quot;poisson&quot;</span>) {</a>
<a class="sourceLine" id="cb551-6" title="6">        LABEL &lt;-<span class="st"> &quot;RR&quot;</span></a>
<a class="sourceLine" id="cb551-7" title="7">    } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb551-8" title="8">        <span class="kw">stop</span>(<span class="st">&quot;Not logistic or Poisson model&quot;</span>)</a>
<a class="sourceLine" id="cb551-9" title="9">    }</a>
<a class="sourceLine" id="cb551-10" title="10"></a>
<a class="sourceLine" id="cb551-11" title="11">    COEF      &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw">coef</span>(GLM.RESULT)</a>
<a class="sourceLine" id="cb551-12" title="12">    CONFINT   &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw">confint</span>(GLM.RESULT)</a>
<a class="sourceLine" id="cb551-13" title="13">    TABLE     &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">coef=</span>COEF, CONFINT)</a>
<a class="sourceLine" id="cb551-14" title="14">    TABLE.EXP &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">exp</span>(TABLE), digits)</a>
<a class="sourceLine" id="cb551-15" title="15"></a>
<a class="sourceLine" id="cb551-16" title="16">    <span class="kw">colnames</span>(TABLE.EXP)[<span class="dv">1</span>] &lt;-<span class="st"> </span>LABEL</a>
<a class="sourceLine" id="cb551-17" title="17"></a>
<a class="sourceLine" id="cb551-18" title="18">    TABLE.EXP</a>
<a class="sourceLine" id="cb551-19" title="19">}</a></code></pre></div>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb552-1" title="1"><span class="kw">glm.RR</span>(m1)</a></code></pre></div>
<pre><code>##                 RR 2.5 % 97.5 %
## (Intercept)    0.2  0.10   0.36
## progAcademic   5.0  2.68  10.63
## progVocational 1.2  0.51   2.94</code></pre>
</div>
<div id="過度離散-overdispersion" class="section level2">
<h2><span class="header-section-number">47.3</span> 過度離散 overdispersion</h2>
<p>泊松分佈的前提條件之一是，方差和均值相等。這是一個<strong>非常強的假設</strong>，很多計數型數據其實是無法滿足這個條件的。許多時候 (包括上面的例子也是) 方差要大於或者小於均值：</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb554-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;Academic&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  105  1      1       1.279  0      6</code></pre>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb556-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;General&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  45   0.2    0       0.405  0      1</code></pre>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb558-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;Vocational&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  50   0.24   0       0.517  0      2</code></pre>
<p>試想一下，實際的數據中其實是經常出現這樣的違反泊松分佈前提的計數型數據的。例如某兩個觀測對象，如果他們二者的線性預測方程給出相等的結果 (他們各自的預測變量可以完全不同)，會被認爲服從相同均值，相同方差的泊松分佈，這顯然是不合理的。例如本章用到的學校學生獲獎的例子，有的學生成績好，那麼獲得學術類獎的平均次數 (及其方差) 自然和成績排在後面的學生不同，強制這樣的兩個學生服從相同均值，相同方差的泊松分佈顯然是不合情理的。手工好的學生，可能更傾向於獲得更多得技能類獎。實際情況下，還有許許多多其他的未知因素會影響學生獲獎的次數，例如家庭教育背景的不同，有些學生鋼琴獲獎多，因爲他每天都去練習彈鋼琴等等，這些都是沒有被收集到的數據。</p>
<p>真實情況應該是這樣的，當有其他的我們不知道的因素存在時，這些因素會導致某些人的均值高於其他人。如果對象 <span class="math inline">\(i\)</span> 的因變量 <span class="math inline">\(Y_i\)</span> 服從均值爲 <span class="math inline">\(\mu_i\)</span> 的泊松分佈，那麼對於所有的 <span class="math inline">\(\mu_i\)</span>，其均值 (overall mean) 是 <span class="math inline">\(\mu\)</span>，方差 (overall variance) 是 <span class="math inline">\(\sigma^2\)</span>。這是一個典型的隨機效應模型 random effect model，我們會在後面的 hierarchical data analysis 再深入討論，但是這裏的重點是，每個觀測對象自己的均值 <span class="math inline">\(\mu_i\)</span>，是我們在普通泊松迴歸中忽略掉的隨機共變量 (the effects of omitted covariates)。</p>
<p>所以樣本數據來自的人羣如果共同均值 (或者叫邊際效應均值，marginal mean) 爲 <span class="math inline">\(\mu\)</span>：</p>
<p><span class="math display">\[
E(Y_i) = E(E(Y_i | \mu_i)) = E(\mu_i) = \mu
\]</span></p>
<p>和共同方差 (邊際效應方差) ，需要用到 <a href="https://en.wikipedia.org/wiki/Law_of_total_variance">總體方差法則 (Law of total variance)</a> 概念：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(Y_i) &amp; = E(\text{Var}(Y_i | \mu_i)) + \text{Var}(E(Y_i | \mu_i)) \\
                &amp; = E(\mu_i) + \text{Var}(\mu_i) \\
                &amp; = \mu + \sigma^2
\end{aligned}
\]</span></p>
<div id="過度離散怎麼查" class="section level3">
<h3><span class="header-section-number">47.3.1</span> 過度離散怎麼查？</h3>
<p>如果，我們的泊松回歸模型中的共變量全部都是分類型變量，我們可以把觀測值 <span class="math inline">\(Y\)</span> 對每一個分類變量分別作簡單的數據總結，觀察其均值和方差是否可以認為大致相同。但是許多時候模型中不會只有分類型變量。</p>
<p>R 輸出的結果中的 模型偏差 deviance，可以用來初步判斷整體模型的擬合優度。如果模型偏差除以殘差獲得的殘差偏差 (residual deviance) 足夠小，說明擬合的模型跟數據本身比較接近，也就是模型和數據擬合程度較好，反之則提示模型本身具有較高的過度離散 overdispersion。另外，模型偏差由於在個人數據 (individual data) 情況下不適用 (因為模型偏差值就不再服從卡方分佈了)，下面的檢驗結果僅僅只能作為極為微弱的參考證據。此時應該推薦使用 Pearson 的模型擬合檢驗。如果 Pearson 統計量，除以殘差的自由度獲得的值遠大於 1，就提示存在過度離散。</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb560-1" title="1"><span class="kw">with</span>(m1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb560-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df           p
## [1,]    234.45997 197 0.034961171</code></pre>
<p>Goodness of fit 檢驗結果 提示本模型<strong>可能存在過度離散</strong>，數據擬合度不理想。值得注意的是如果樣本很大時，模型偏差的檢驗統計量<strong>將不再服從卡方分佈</strong>，應用的時候一定要慎重。</p>
</div>
<div id="負二項式分佈模型-negative-binomial-model" class="section level3">
<h3><span class="header-section-number">47.3.2</span> 負二項式分佈模型 negative binomial model</h3>
<p>如果普通泊松迴歸模型擬合數據時，發現數據本身有過度離散的嫌疑，那麼建議使用負二項式分佈模型來重新擬合數據。負二項式分佈模型其實是泊松分佈的擴展版本，即考慮了個體的方差和均值的隨機效應 subject-specific random effect。如果設每個觀測對象的隨機效應部分爲 <span class="math inline">\(a_i\)</span>，預測變量爲向量 <span class="math inline">\(\mathbf{x_i} = (x_{i1}, \cdots, x_{ip})\)</span>，那麼因變量 <span class="math inline">\(Y_i\)</span> 服從均值爲 <span class="math inline">\(\text{exp}(\beta^T\mathbf{x_i}+a_i)\)</span> 泊松分佈。在負二項式分佈中，個體的隨機效應部分的自然底數的指數 <span class="math inline">\(e^{a_i}\)</span> 其實是服從均值爲 1， 方差爲 <span class="math inline">\(\alpha\)</span> 的<a href="https://cosx.org/2013/01/lda-math-gamma-function/">伽馬分佈 (gamma distribution)</a>。<span class="math inline">\(\alpha\)</span> 越大，说明过度离散越明显。</p>
<p>接下來用相同的數據，使用負二項式分佈模型在 R 裏作模型的擬合，你就會看到差別：</p>
<p>R 裏擬合負二項式分佈模型的函數 <code>glm.nb</code> 在基本包 <code>MASS</code> 裏。</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb562-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">glm.nb</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">data =</span> p)</a>
<a class="sourceLine" id="cb562-2" title="2">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb562-3" title="3"><span class="kw">summary</span>(m1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm.nb(formula = num_awards ~ prog, data = p, init.theta = 1.72267107, 
##     link = log)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.25581  -0.67036  -0.61517   0.00000   2.32349  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.35215 -4.5703 4.87e-06 ***
## progAcademic    1.60944    0.37291  4.3159 1.59e-05 ***
## progVocational  0.18232    0.46793  0.3896   0.6968    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(1.7227) family taken to be 1)
## 
##     Null deviance: 211.264  on 199  degrees of freedom
## Residual deviance: 171.066  on 197  degrees of freedom
## AIC: 406.532
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  1.723 
##           Std. Err.:  0.717 
## 
##  2 x log-likelihood:  -398.532</code></pre>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb564-1" title="1"><span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = poisson(link = log), 
##     data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>仔細比較普通泊松分佈迴歸和負二項式分佈迴歸的輸出結果，你會發現</p>
<ol style="list-style-type: decimal">
<li>迴歸係數的計算是完全相同的 (由於我們只放了一個簡單的分類型變量作爲預測變量，一般來說泊松迴歸和負二項式分佈迴歸計算的迴歸係數會有些許不同)；</li>
<li>另外一個變化是標準誤的估計量在負二項式分佈模型中明顯變大了，這就是我們放寬了前提條件，允許模型考慮個體的隨機效應的體現。如果泊松模型被數據本身的過度離散影響顯著，那麼泊松迴歸計算獲得的參數標準無是偏低的；</li>
<li>負二項式分佈迴歸的結果最底下出現的 <code>Theta:  1.723</code> 部分，它的倒數是前面提到的歌廳效應部分 <span class="math inline">\(a_i\)</span> 服從的伽馬分佈的方差 <span class="math inline">\(\alpha\)</span>。它是關鍵的離散程度參數 (dispersion parameter)。在 STATA 裏，如果用 <code>nbreg</code> 擬合負二項式分佈迴歸的模型，輸出的結果最底下會有 <span class="math inline">\(\alpha\)</span> 值的報告，注意它和 R 輸出的 <code>Theta</code> 結果互爲倒數。另外，STATA 的輸出結果還會對 <span class="math inline">\(\alpha = 0\)</span> 直接進行檢驗。在 R 裏面則需要給兩個模型分別進行擬合優度檢驗，多數情況下你會發現負二項式分佈迴歸的模型更加擬合數據：</li>
</ol>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb566-1" title="1"><span class="kw">with</span>(m1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb566-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df          p
## [1,]    171.06608 197 0.90901874</code></pre>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb568-1" title="1"><span class="kw">with</span>(m2, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb568-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df           p
## [1,]    234.45997 197 0.034961171</code></pre>
<p>另一種獲取沒有被低估的迴歸係數的標準誤的方法來自穩健統計學手段。在 R 裏，擬合完普通泊松迴歸以後，用 <code>sandwich</code> 包裏的 <code>vcovHC()</code> 命令進行穩健的參數誤差估計 (具體說是夾心方差矩陣估計 sandwich estimator of variance)：</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb570-1" title="1">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb570-2" title="2">cov.m2 &lt;-<span class="st"> </span><span class="kw">vcovHC</span>(m2, <span class="dt">type =</span> <span class="st">&quot;HC0&quot;</span>)</a>
<a class="sourceLine" id="cb570-3" title="3">std.err &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(cov.m2))</a>
<a class="sourceLine" id="cb570-4" title="4">robust.est &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">Estimate=</span> <span class="kw">coef</span>(m2), <span class="st">&quot;Robust SE&quot;</span> =<span class="st"> </span>std.err,</a>
<a class="sourceLine" id="cb570-5" title="5"><span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(m2)<span class="op">/</span>std.err), <span class="dt">lower.tail=</span><span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb570-6" title="6"><span class="dt">LL =</span> <span class="kw">coef</span>(m1) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.err,</a>
<a class="sourceLine" id="cb570-7" title="7"><span class="dt">UL =</span> <span class="kw">coef</span>(m1) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.err)</a>
<a class="sourceLine" id="cb570-8" title="8">robust.est</a></code></pre></div>
<pre><code>##                   Estimate  Robust SE      Pr(&gt;|z|)          LL         UL
## (Intercept)    -1.60943791 0.29814240 6.7305731e-08 -2.19379701 -1.0250788
## progAcademic    1.60943791 0.32296809 6.2517920e-07  0.97642045  2.2424554
## progVocational  0.18232156 0.42426407 6.6738767e-01 -0.64923602  1.0138791</code></pre>
</div>
</div>
</div>
<div id="率的廣義線性迴歸-poisson-glm-for-rates" class="section level1">
<h1><span class="header-section-number">第 48 章</span> 率的廣義線性迴歸 Poisson GLM for rates</h1>
<div id="醫學中的率" class="section level2">
<h2><span class="header-section-number">48.1</span> 醫學中的率</h2>
<p>前章介紹的事件發生次數，使用的是泊松迴歸。本章介紹同樣利用泊松迴歸，對事件發生率類型數據的泊松迴歸模型。常見的率的數據例如：</p>
<ul>
<li>肺癌發病率</li>
<li>工廠職工的死亡率</li>
<li>術後後遺症的發生率</li>
</ul>
<p>下列數據來自英國醫生調查 (British doctors study)，研究的是男性醫生中吸菸與否和冠心病死亡之間的關係。最後一列是每組觀測對象被追蹤的人年 (person-year)。</p>
<pre><code>##    agegrp     smokes deaths  pyrs
## 1   35-44     Smoker     32 52407
## 2   45-54     Smoker    104 43248
## 3   55-64     Smoker    206 28612
## 4   65-74     Smoker    186 12663
## 5     75+     Smoker    102  5317
## 6   35-44 Non-smoker      2 18790
## 7   45-54 Non-smoker     12 10673
## 8   55-64 Non-smoker     28  5710
## 9   65-74 Non-smoker     28  2585
## 10    75+ Non-smoker     31  1462</code></pre>
<p>這是一個已經被整理過的數據，我們沒有辦法從這樣的數據還原到每個觀察對象的個人水平數據。冠心病的粗死亡率 (crude death rate) 可以被計算如下表 (忽略年齡分組)，此時默認的前提是死亡事件在追蹤的過程中發生的概率不發生改變。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:PoissonRates">表 48.1: </span>Death rates due to CHD in smokers and non-smokers, collapsed over age group
</caption>
<thead>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Person-years of follow-up
</th>
<th style="text-align:center;">
CHD deaths
</th>
<th style="text-align:center;">
Death Rate per 1000 person-years
</th>
<th style="text-align:center;">
Rate Ratios
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Non-smokers
</td>
<td style="text-align:center;">
39220
</td>
<td style="text-align:center;">
101
</td>
<td style="text-align:center;">
2.58
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
<tr>
<td style="text-align:center;">
Smokers
</td>
<td style="text-align:center;">
142247
</td>
<td style="text-align:center;">
630
</td>
<td style="text-align:center;">
4.43
</td>
<td style="text-align:center;">
1.72
</td>
</tr>
</tbody>
</table>
</div>
<div id="泊松過程" class="section level2">
<h2><span class="header-section-number">48.2</span> 泊松過程</h2>
<p>設 <span class="math inline">\(Y\)</span> 是代表某段時間 <span class="math inline">\(t\)</span> 內<strong>事件發生次數 (死亡)</strong> 的隨機變量。如果可以假設：</p>
<ul>
<li>每次事件的發生，是互相獨立的，即在沒有重疊的時間線上，每個事件的發生是隨機的。</li>
<li>在一個無限小的時間段 <span class="math inline">\(\delta t\)</span> 內，事件發生的概率是 <span class="math inline">\(\lambda\times\delta t\)</span>，其中 <span class="math inline">\(\delta t \rightarrow 0\)</span>。</li>
</ul>
<p>那麼根據泊松分佈 (Section <a href="#poisson">6</a>) 的定義，在這個時間段內，隨機變量 <span class="math inline">\(Y\)</span> 事件發生次數服從泊松分佈：</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp; \sim \text{Po}(\mu) \\
\text{Where } \mu &amp; = \lambda t, \text{ and } \lambda \text{ is the Rate}
\end{aligned}
\]</span></p>
<p>所以，從泊松過程可以看到，我們關心的參數是事件發生率 <span class="math inline">\(\lambda\)</span>。</p>
</div>
<div id="率的模型" class="section level2">
<h2><span class="header-section-number">48.3</span> 率的模型</h2>
<p>既然關心的參數只是發生率，且我們已知泊松分佈是指數分佈的家族成員，可以用廣義線性模型的概念來建模。</p>
<ol style="list-style-type: decimal">
<li>因變量分佈，distribution of dependent variable <span class="math display">\[Y_i \sim \text{Po}(\mu_i), \text{ where } \mu_i = \lambda_i t_i\]</span></li>
<li>線性預測方程，linear predictor <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>標準鏈接方程，canonical link function <span class="math display">\[\text{log}(\lambda_i) = \text{log}(\frac{\mu_i}{t_i})\]</span></li>
</ol>
<p>所以，將率的模型整理一下，就變成了</p>
<p><span class="math display">\[
\begin{aligned}
\text{log}(\mu_i) - \text{log}(t_i) &amp; = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip} \\
\text{log}(\mu_i) &amp; = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>你可以看到，時間項的對數部分 <span class="math inline">\(\text{log}(t_i)\)</span> 其實是被移到線性預測方程的右邊跟參數放在一起的，只是<strong>它的迴歸係數被強制爲 <span class="math inline">\(1\)</span></strong>。這個時間項被叫做 <strong>補償項 (offset)</strong>。這樣我們就成功地擬合了用於求事件發生率的一個泊松迴歸模型。在 R 裏，你可以用 <code>glm()</code> 命令的 <code>offset =</code> 選項功能，也可以把 <code>offset(log(Person-year))</code> 作爲線性預測方程的一部分把時間項取對數以後放進模型裏面。</p>
</div>
<div id="率的-glm" class="section level2">
<h2><span class="header-section-number">48.4</span> 率的 GLM</h2>
<p>所以我們一起來把率的 GLM 正式定義一下，它包含三個部分：</p>
<ol style="list-style-type: decimal">
<li>可被認爲互相獨立的因變量觀測值的分佈服從泊松分佈 <span class="math display">\[Y_i \sim \text{Po}(\mu_i)\]</span> <br> 其中 <span class="math inline">\(E(Y_i) = \mu_i = \lambda_i t_i\)</span>，<span class="math inline">\(t_i\)</span> 是第 <span class="math inline">\(i\)</span> 個觀察對象 (或者觀察組) 的追蹤人年 (person-time)。</li>
<li>線性預測方程 <span class="math display">\[\eta_i = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接方程是均值的對數方程 <span class="math display">\[\text{log}(\mu_i) = \eta_i\]</span></li>
</ol>
<p>和分組型二項分佈數據相似，如果泊松 GLM 擬合的數據也是分組型數據，如本章開頭的英國醫生隊列數據。那麼模型偏差值 (deviance) 可以用來衡量模型擬合的好壞。在零假設條件下，模型偏差值服從自由度爲 <span class="math inline">\(n-p\)</span> 的卡方分佈 (這裏的 <span class="math inline">\(n\)</span> 是分組型數據中的“組的數量”，也就是飽和模型中參數的數量，<span class="math inline">\(p\)</span> 是擬合的線性預測方程中參數的數量)。</p>
</div>
<div id="實戰演練" class="section level2">
<h2><span class="header-section-number">48.5</span> 實戰演練</h2>
<p>數據是本章開頭使用的英國醫生隊列</p>
<pre><code>##    agegrp     smokes deaths  pyrs
## 1   35-44     Smoker     32 52407
## 2   45-54     Smoker    104 43248
## 3   55-64     Smoker    206 28612
## 4   65-74     Smoker    186 12663
## 5     75+     Smoker    102  5317
## 6   35-44 Non-smoker      2 18790
## 7   45-54 Non-smoker     12 10673
## 8   55-64 Non-smoker     28  5710
## 9   65-74 Non-smoker     28  2585
## 10    75+ Non-smoker     31  1462</code></pre>
<ul>
<li>每組的死亡人數用 <span class="math inline">\(y_i, i=1,\cdots,10\)</span> 標記；</li>
<li>每組追蹤的人年用 <span class="math inline">\(t_i\)</span> 標記；</li>
<li><span class="math inline">\(x_{i1} = 0\)</span> 時對象是吸菸者，<span class="math inline">\(x_{i1} = 1\)</span> 時對象是非吸菸者；</li>
<li><span class="math inline">\(x_{i2}, x_{i3}, x_{i4}, x_{i5}\)</span> 作爲5個年齡組的啞變量。</li>
</ul>
<p>分析目的是：</p>
<ol style="list-style-type: decimal">
<li>調查吸菸與冠心病死亡率的關係 (不調整年齡)；</li>
<li>調查吸菸與冠心病死亡率的年齡調整後關係；</li>
<li>調查年齡是否對吸菸與冠心病死亡率的關係起到交互作用。</li>
</ol>
<div id="模型-1" class="section level3">
<h3><span class="header-section-number">48.5.1</span> 模型 1</h3>
<p>第一個模型可以用下面的數學表達式：</p>
<p><span class="math display">\[
\text{log}(\mu_i)  = \text{log}(t_i) + \alpha + \beta_1 x_{i1}
\]</span></p>
<p>在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb574-1" title="1"><span class="co"># the following 2 models are equivalent</span></a>
<a class="sourceLine" id="cb574-2" title="2">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb574-3" title="3">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes, <span class="dt">offset =</span> <span class="kw">log</span>(pyrs), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb574-4" title="4"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes, family = poisson(link = &quot;log&quot;), 
##     data = BritishD, offset = log(pyrs))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -16.5348   -6.0313    4.6116    8.1617   13.6441  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -5.961822   0.099504 -59.9157 &lt; 2.2e-16 ***
## smokesSmoker  0.542221   0.107183   5.0588 4.219e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 935.067  on 9  degrees of freedom
## Residual deviance: 905.976  on 8  degrees of freedom
## AIC: 965.044
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>輸出報告中的參數估計部分 <code>Estimate</code> 就是我們擬合模型中參數的估計 <span class="math inline">\(\hat\alpha, \hat\beta_1\)</span>，他們各自的含義是：</p>
<ul>
<li><span class="math inline">\(\hat\alpha = -5.96\)</span>：非吸菸者的冠心病估計死亡率的對數 (the estimated log rate for non-smokers)；</li>
<li><span class="math inline">\(\hat\beta_1 = 0.547\)</span>：非吸菸者和吸菸者兩組之間冠心病死亡率對數之差 (the estimated difference in log rate between non-smokers and smokers)。</li>
</ul>
<p>注意看報告中間部分模型偏差部分的數字 <code>Residual deviance: 905.98  on 8  degrees of freedom</code>，如果對 模型 1 進行擬合優度檢驗：</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb576-1" title="1"><span class="kw">with</span>(Model1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb576-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance df              p
## [1,]    905.97619  8 2.9024145e-190</code></pre>
<p>擬合優度檢驗結果提示，這個模型對數據的擬合非常差 (poor fit)。可能的原因是，模型 1 中忽略了“年齡”這一重要的因素，使得當僅僅使用 吸菸與否 的信息擬合的泊松迴歸模型的擬合值和觀察值之間的差異的波動非常大，大到很可能無法滿足泊松分佈的前提假設。</p>
</div>
<div id="模型-2" class="section level3">
<h3><span class="header-section-number">48.5.2</span> 模型 2</h3>
<p>第二個模型的線性預測方程可以寫作：</p>
<p><span class="math display">\[
\text{log}(\mu_i) = \text{ln}(t_i) + \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5}
\]</span></p>
<p>在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb578-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes <span class="op">+</span><span class="st"> </span>agegrp <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb578-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes + agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), 
##     data = BritishD)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8          9  
##  0.901600   0.510379   0.051347  -0.087318  -0.912369  -2.179780  -1.308000  -0.137907   0.228819  
##        10  
##  1.919020  
## 
## Coefficients:
##              Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -7.91933    0.19176 -41.2978 &lt; 2.2e-16 ***
## smokesSmoker  0.35454    0.10737   3.3019 0.0009604 ***
## agegrp45-54   1.48401    0.19510   7.6063 2.821e-14 ***
## agegrp55-64   2.62751    0.18373  14.3012 &lt; 2.2e-16 ***
## agegrp65-74   3.35049    0.18480  18.1305 &lt; 2.2e-16 ***
## agegrp75+     3.70010    0.19222  19.2494 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 935.0673  on 9  degrees of freedom
## Residual deviance:  12.1324  on 4  degrees of freedom
## AIC: 79.2003
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>此時可以計算吸菸者與非吸菸者相比時，年齡調整後冠心病死亡率的比爲：</p>
<p><span class="math display">\[
\begin{aligned}
e^{0.3545} &amp; = 1.43 \text{ with } 95\% \text{ CI: } \\
(e^{0.3545 - 1.96\times0.1074}, &amp; e^{0.3545 + 1.96\times0.1074}) = (1.16, 1.76)
\end{aligned}
\]</span></p>
<p>報告中還包含了對吸菸項迴歸係數的 Wald 檢驗結果 <code>smokesSmoker   0.3545     0.1074   3.302  0.00096 ***</code>，從這一結果來看，數據提供了強有力的證據證明了年齡調整以後，吸菸會引起冠心病死亡率的顯著升高。再利用模型擬合報告中模型偏差部分的數據 <code>Residual deviance: 905.98  on 8  degrees of freedom</code>，模型的擬合優度檢驗結果爲：</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb580-1" title="1"><span class="kw">with</span>(Model2, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb580-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance df           p
## [1,]    12.132366  4 0.016393625</code></pre>
<p>結果依然提示，即使把年齡組放入這個泊松迴歸，模型對數據的擬合程度依然非常的不好。所以，到這裏，在即使調整了年齡之後模型擬合度依然不理想的情況下 (這是需要加交互作用項的證據)，我們需要在模型中加入年齡和吸菸的交互作用項 (結果是加入交互作用項的模型就變成了飽和模型)。</p>
</div>
<div id="模型-3" class="section level3">
<h3><span class="header-section-number">48.5.3</span> 模型 3</h3>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb582-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes<span class="op">*</span>agegrp <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb582-2" title="2"><span class="kw">summary</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes * agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), 
##     data = BritishD)
## 
## Deviance Residuals: 
##  [1]  0  0  0  0  0  0  0  0  0  0
## 
## Coefficients:
##                          Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)              -9.14793    0.70711 -12.9371 &lt; 2.2e-16 ***
## smokesSmoker              1.74687    0.72887   2.3967  0.016544 *  
## agegrp45-54               2.35737    0.76376   3.0865  0.002025 ** 
## agegrp55-64               3.83016    0.73192   5.2330 1.668e-07 ***
## agegrp65-74               4.62266    0.73192   6.3158 2.688e-10 ***
## agegrp75+                 5.29436    0.72956   7.2569 3.960e-13 ***
## smokesSmoker:agegrp45-54 -0.98662    0.79006  -1.2488  0.211741    
## smokesSmoker:agegrp55-64 -1.36281    0.75619  -1.8022  0.071512 .  
## smokesSmoker:agegrp65-74 -1.44229    0.75653  -1.9065  0.056592 .  
## smokesSmoker:agegrp75+   -1.84699    0.75717  -2.4393  0.014715 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 9.35067e+02  on 9  degrees of freedom
## Residual deviance: 4.44089e-15  on 0  degrees of freedom
## AIC: 75.0679
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>此時你會看到模型的偏差已經幾乎接近於零，因爲這已經是一個飽和模型。</p>
</div>
</div>
</div>
<div id="混雜的調整交互作用和模型的可壓縮性" class="section level1">
<h1><span class="header-section-number">第 49 章</span> 混雜的調整，交互作用，和模型的可壓縮性</h1>
<p>臨牀醫學，流行病學研究的許多問題，需要我們通過數據來評估某些結果變量 (outcome) 和某些預測變量 (predictors/exposures) 之間的關係 (甚至是因果關係)。這些問題的最佳解決方法應該說是隨機臨牀試驗 (ramdomized clinical trial, RCT)。但是有更多的時候 (由於違反醫學倫理，或者現狀所困，甚至是知識有限) 我們無法設計 RCT 來解決這些問題，就只能藉助於觀察性研究 (observational study)。觀察性研究最大的侷限性在於無法像 RCT 那樣從實驗設計階段把混雜因素排除或者降到最低，所以觀察數據在分析的時候，混雜 (confounding) 是必須要加以考慮的一大要因。在簡單線性迴歸章節 (Section <a href="#confounding">29.5</a>)，詳細討論過混雜因素的定義及條件：</p>
<blockquote>
<p>對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件：</p>
<ul>
<li>與關心的預測變量相關 (i.e. <span class="math inline">\(\delta_1 \neq 0\)</span>)；</li>
<li>與因變量相關 (當關心的預測變量不變時，<span class="math inline">\(\beta_2\neq0\)</span> )；</li>
<li>不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable.</li>
</ul>
</blockquote>
<p>下面的統計數據來自一個比較手術和超聲碎石術對於腎結石治療結果的評價。已知大多數醫生都公認，腎結石的直徑小於 2 公分時治療成功的概率較高。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Lithotripsy">表 49.1: </span>Lithotripsy
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
&lt; 2cm Diameter
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
&gt;= 2cm Diameter
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81.00
</td>
<td style="text-align:center;">
234
</td>
<td style="text-align:center;">
192.00
</td>
<td style="text-align:center;">
55
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6.00
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
71.00
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87.00
</td>
<td style="text-align:center;">
270
</td>
<td style="text-align:center;">
263.00
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
2.08
</td>
<td style="text-align:center;">
NA
</td>
<td style="text-align:center;">
1.23
</td>
<td style="text-align:center;">
NA
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.1: Lithotripsy data
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(&lt;2\)</span> cm Diameter
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(\geqslant2\)</span> cm Diameter
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81
</td>
<td style="text-align:center;">
234
</td>
<td style="text-align:center;">
192
</td>
<td style="text-align:center;">
55
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
71
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87
</td>
<td style="text-align:center;">
270
</td>
<td style="text-align:center;">
263
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
2.08
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
1.23
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>可以看到，在上面的分組表格中，左右兩邊的四格表分別統計了腎結石尺寸小於 2 cm 和大於 2 cm 時，手術摘除腎結石的成功/失敗次數，以及超聲碎石術的成功/失敗次數。這個表格告訴我們，無論腎結石的尺寸是大於還是小於 2 cm，手術的成功的比值比都大於超聲碎石術。但是如果我們沒有把數據按照腎結石尺寸區分時，數據就被壓縮 (collapsed) 成了下面表格總結的樣子：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Lithotripsy-collapsed">表 49.2: </span>Lithotripsy collapsed
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
273 (78%)
</td>
<td style="text-align:center;">
289 (83%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
61
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
0.75
</td>
<td style="text-align:center;">
<ul>
<li></td>
</tr>
</tbody>
</table></li>
</ul>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.2: Lithotripsy data collapsed
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
273 (78%)
</td>
<td style="text-align:center;">
289 (83%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
61
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
0.75
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>當腎結石尺寸被忽略時，數據卻顯示超聲碎石術的成功比值比要高於手術，和之前的結果是矛盾的，你會信哪個？</p>
<p>不要慌，數據不會撒謊，撒謊的永遠是人類。我們來把手術次數，超聲碎石術次數，以及腎結石尺寸之間的關係再列個表格：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.3: Association between treatment and the size of the stone.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Size of the Stone
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</td>
<td style="text-align:center;">
87 (33%)
</td>
<td style="text-align:center;">
270 (77%)
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</td>
<td style="text-align:center;">
263
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
</tbody>
</table>
<p>可見醫生也都不是傻子，明明腎結石尺寸很大還要用超聲碎石術的人很少，有 77% 的腎結石尺寸小的患者選擇了超聲碎石術。然後我們再列一個表格來看看<strong>腎結石的尺寸大小和超聲碎石術</strong>成功與否有沒有關係：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.4: Among the <strong>lithotripsy patients</strong> higher percentage of success was observed when stones were small.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</th>
<th style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
234 (87%)
</td>
<td style="text-align:center;">
55 (69%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
370
</td>
<td style="text-align:center;">
80
</td>
</tr>
</tbody>
</table>
<p>可見結石尺寸較大時，超聲碎石術的成功率 (69%)，明顯低於尺寸小的時候的成功率 (87%)。在選擇做外科手術的患者中，大多數人的結石尺寸大於 2 cm，成功率仍然達到了 73%。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.5: Among the <strong>surgery patients</strong> higher percentage of success in both stones compared with lithotripsy
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</th>
<th style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81 (93%)
</td>
<td style="text-align:center;">
192 (73%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
71
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87
</td>
<td style="text-align:center;">
263
</td>
</tr>
</tbody>
</table>
<p>看到這裏，你是否也發現了，腎結石尺寸大小，同時和手術類型的選擇有關 (尺寸小的傾向於選擇超聲碎石術)，尺寸大小，同樣也和手術結果的成功與否，高度相關 (結石小的人成功率高)。所以，分析手術類型和結石手術的成功率的關係的時候，患者體內結石尺寸的大小，對這個關係是產生了混雜效應的。他們三者之間的關係，可以用下面的圖 <a href="#fig:confounding-kidney">49.1</a> 來理解：</p>
<div class="figure" style="text-align: center"><span id="fig:confounding-kidney"></span>
<img src="img/Selection_113.png" alt="Confounding in kidney stones example" width="90%" />
<p class="caption">
圖 49.1: Confounding in kidney stones example
</p>
</div>
<p>當數據被壓縮 (忽略了腎結石尺寸時)，比較兩種手術類型的成功率的時候，接受外科手術患者的尺寸大多數都較大的事實被“<strong>人爲的掩蓋住了</strong>”，但是當數據按照結石大小分層以後，你會看見外科手術不論是對付大的結石，還是小的結石，成功率都高於超聲碎石術。這個例子是混雜效應直接逆轉真實相關關係的極佳的實例。同時也提示我們，總體的比值比 (overall odds ratio) 不能通過簡單地把分層表格直接壓縮 (collapsed table) 獲得的數字來計算。</p>
<div id="混雜因素的調整" class="section level2">
<h2><span class="header-section-number">49.1</span> 混雜因素的調整</h2>
<p>在前面的腎結石手術的例子中，我們利用已有的背景知識 (小尺寸結石的成功率高)，和初步的統計分析 (變量之間兩兩列表分析其內在關係) 發現了混雜因素 (結石尺寸)，並且其結果也讓我們認定了要暴露因素和結果變量之間的關係，混雜因素必須被調整 (adjusted)。</p>
<p>如腎結石數據這樣簡單的情境下 (被認爲是混雜因素的變量和預測變量/暴露變量都只是一個二分類變量)，我們可以把變量兩兩捉對列表分析其相互關係，確定了混雜效應以後把暴露變量和結果變量按照混雜因素的有無列表之後，就可以求得混雜因素被<strong>調整後的分層的比值比</strong>。這些分層比值比，在暴露變量與結果變量的關係保持混雜因素的層之間保持不變的前提下，可以被“平均化”(簡單地說)以後求得總體/合併的比值比 (overall/pooled odds ratio)。這就是 Mantel-Haenszel 法或者 Woolf 法的合併比值比的思想出發點。我們來回顧一下 Woolf 法的全部計算過程：</p>
<p>現在假設我們關心的是某種疾病的患病與否 (是/否)，和某個暴露變量 (是/否) 之間的關係，但是同時想要調整另一個具有 <span class="math inline">\(k\)</span> 個分層的混雜因素變量。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.6: Woolf Method for estimating the stratified and pooled odds ratio
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Group
</div>
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(D=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
</tbody>
</table>
<div id="woolf-法估算合併比值比" class="section level3">
<h3><span class="header-section-number">49.1.1</span> Woolf 法估算合併比值比</h3>
<p>對想要調整的一個 <span class="math inline">\(k\)</span> 組的混雜因素，把數據按照它的分組分層整理以後，可以得到上面的 <span class="math inline">\(k\)</span> 個四格表 (每個分層四格表都是暴露變量和結果變量結合的四個觀察值 <span class="math inline">\(a_i, b_i, c_i, d_i, i=1,\cdots, k\)</span>)。每個分層四格表的觀測比值比爲 <span class="math inline">\(\hat\Psi_i = \frac{a_id_i}{c_ib_i}\)</span>，且可以證明方差爲</p>
<p><span class="math display">\[
\text{Var}(\text{log}\hat\Psi_i) \approx \frac{1}{a_i} + \frac{1}{b_i} + \frac{1}{c_i} + \frac{1}{d_i} = \frac{1}{w_i}
\]</span></p>
<p>合併比值比的對數 <span class="math inline">\(\text{log}\hat\Psi_w\)</span> 的 Woolf 的計算方法就是</p>
<p><span class="math display">\[
\text{log}\hat\Psi_w = \frac{\sum w_i\text{log}\hat\Psi_i}{\sum w_i}
\]</span></p>
<p>所以，每個分層的對數比值比乘以自己的<strong>方差的倒數</strong> (權重 weights) 之後求和，再除以所有權重之和，獲得的是合併後的對數比值比，然後再逆運算回來就是 Woolf 法計算合併比值比的原理是。</p>
<p>這個合併比值比的對數的方差是</p>
<p><span class="math display">\[
\text{Var}(\text{log}\hat\Psi_w) = \frac{1}{\sum w_i}
\]</span></p>
<p>有了加權後的合併比值比，和方差，就可以求加權後的合併比值比的信賴區間了。值得注意的是，分層之後每個分層四格表中的四個數字 (四個樣本量) 都不能太小。腎結石手術數據滿足這些條件，那麼不妨跟我一起手算一下結石尺寸調整後的手術與超聲碎石術成功與否的比值比：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\Psi_1 = 2.08 ;&amp;\; \hat\Psi_2 = 1.23 \\
\text{Var}(\text{log}\hat\Psi_1) = \frac{1}{81} &amp; + \frac{1}{234} + \frac{1}{6} + \frac{1}{36} = 0.2111 \\
\text{Var}(\text{log}\hat\Psi_2) = \frac{1}{192} &amp; + \frac{1}{55} + \frac{1}{71} + \frac{1}{25} = 0.0775 \\
w_1 = \frac{1}{\text{Var}(\text{log}\hat\Psi_1)} = 4.74 ; \;&amp; w_2 = \frac{1}{\text{Var}(\text{log}\hat\Psi_2)} = 12.91 \\
\text{log}\hat\Psi_w = &amp; \frac{4.74\times\text{log(2.08)} + 12.91\times\text{log(1.23)}}{4.74 + 12.91} \\
                     = &amp; 0.3481 \\
\Rightarrow \hat\Psi_w =&amp; e^{0.3481} = 1.42\\
\text{Var}(\hat\Psi_w) =&amp; \frac{1}{4.74+12.91} = 0.0567 \\
\Rightarrow 95\% \text{ CI} = &amp; e^{0.3481 \pm 1.96\times\sqrt{0.0567}} \\
                            = &amp; (0.89, 2.26)
\end{aligned}
\]</span></p>
<p>Woolf 的計算調整後的合併比值比的方法是<strong>在線性迴歸和廣義線性迴歸被發現之前誕生的</strong>，但是其想法之精妙，確實令人感嘆。可惜其最大的缺陷是無法用這樣的方法進行連續型變量的調整，也很難同時進行多個變量的調整，所以現在這一算法已經逐漸被淘汰。現在我們有了廣義線性迴歸模型這一更強大的工具，只要把變量加入廣義線性模型進行調整就可以計算曾經難以計算和擴展的調整後的合併比值比。從下面的代碼計算獲得的調整後比值比 <span class="math inline">\(1.43 (0.91, 2.34)\)</span> 也可以看出，Woolf 方法的計算結果也是足夠令人滿意的。</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb584-1" title="1">size &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;&lt; 2cm&quot;</span>, <span class="st">&quot;&lt; 2cm&quot;</span>, <span class="st">&quot;&gt;= 2cm&quot;</span>, <span class="st">&quot;&gt;= 2cm&quot;</span>)</a>
<a class="sourceLine" id="cb584-2" title="2">treatment &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Surgery&quot;</span>,<span class="st">&quot;Lithotripsy&quot;</span>,<span class="st">&quot;Surgery&quot;</span>,<span class="st">&quot;Lithotripsy&quot;</span>)</a>
<a class="sourceLine" id="cb584-3" title="3">n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">87</span>, <span class="dv">270</span>, <span class="dv">263</span>, <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb584-4" title="4">Success &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">81</span>, <span class="dv">234</span>, <span class="dv">192</span>, <span class="dv">55</span>)</a>
<a class="sourceLine" id="cb584-5" title="5">Stone &lt;-<span class="st"> </span><span class="kw">data.frame</span>(size, treatment, n, Success)</a>
<a class="sourceLine" id="cb584-6" title="6">ModelStone &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(Success, n <span class="op">-</span><span class="st"> </span>Success) <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>size, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Stone)</a>
<a class="sourceLine" id="cb584-7" title="7"><span class="kw">summary</span>(ModelStone)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Success, n - Success) ~ treatment + size, 
##     family = binomial(link = logit), data = Stone)
## 
## Deviance Residuals: 
##        1         2         3         4  
##  0.76357  -0.35881  -0.27563   0.46948  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       1.93655    0.17045 11.3614 &lt; 2.2e-16 ***
## treatmentSurgery  0.35723    0.22908  1.5594    0.1189    
## size&gt;= 2cm       -1.26057    0.23900 -5.2742 1.333e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.12395  on 3  degrees of freedom
## Residual deviance:  1.00816  on 1  degrees of freedom
## AIC: 26.3554
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb586-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(ModelStone)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(Success, n - Success) 
##  
##                                   crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09)  1.43 (0.91,2.24)  0.119          &lt; 0.001   
##                                                                                                
## size: &gt;= 2cm vs &lt; 2cm             0.34 (0.23,0.51)  0.28 (0.18,0.45)  &lt; 0.001        &lt; 0.001   
##                                                                                                
## Log-likelihood = -10.1777
## No. of observations = 4
## AIC value = 26.3554</code></pre>
<p>所以，此次分析的結論是，在 5% 的顯著性水平下，數據無法提供有效證據證明，當調整了結石尺寸之後，外科手術和超聲碎石術治療腎結石有差別。
We can conclude that there is no evidence at the 5% level for an effect of surgery, adjusted for stone size.</p>
</div>
</div>
<div id="交互作用" class="section level2">
<h2><span class="header-section-number">49.2</span> 交互作用</h2>
<p>我們決定調整一個混雜因素的時候，其實同時包含了 “在不同混雜因素的程度下，暴露變量和結果變量之間的關係不變/This implicitly assumes that the effect of the exposure is the same irrespective of the levels of the confounder.” 的假設。但是，一個混雜因素，它可能同時還扮演了改變暴露變量和結果變量之間關係的角色 (effect modifier/交互作用效應)。另外還有的情況下，某變量可能改變了暴露變量和結果變量之間的關係，卻不一定是一個混雜因素。此時我們說這個起到改變關係的變量和暴露變量之間發生了交互作用。</p>
<p>如果暴露變量在某個分組變量的不同層 (strata) 之間是不同質的 (hetergeneous, not constant)，我們建議<strong>要分析且報告不同層各自的</strong>比值比。惟一的例外是 RCT 臨牀試驗的時候，我們更加關心調整後合併比值比。因爲一項治療藥物對不同的 “個體” 有不同的療效是必然的，但是，RCT 的目的是要評價的其實是這個藥物或者新療法在整個人羣中的療效是怎樣的。</p>
<p>我們給腎結石數據加上治療方案和結石尺寸大小的交互作用項，結果如下：</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb588-1" title="1">ModelStone2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(Success, n <span class="op">-</span><span class="st"> </span>Success) <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>size, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Stone)</a>
<a class="sourceLine" id="cb588-2" title="2"><span class="kw">summary</span>(ModelStone2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Success, n - Success) ~ treatment * size, 
##     family = binomial(link = logit), data = Stone)
## 
## Deviance Residuals: 
## [1]  0  0  0  0
## 
## Coefficients:
##                             Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                  1.87180    0.17903 10.4553 &lt; 2.2e-16 ***
## treatmentSurgery             0.73089    0.45942  1.5909 0.1116310    
## size&gt;= 2cm                  -1.08334    0.30039 -3.6065 0.0003104 ***
## treatmentSurgery:size&gt;= 2cm -0.52453    0.53716 -0.9765 0.3288211    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 3.31239e+01  on 3  degrees of freedom
## Residual deviance: 3.66374e-14  on 0  degrees of freedom
## AIC: 27.3472
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb590-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(ModelStone2)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(Success, n - Success) 
##  
##                                   crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09)  2.08 (0.84,5.11)  0.112          &lt; 0.001   
##                                                                                                
## size: &gt;= 2cm vs &lt; 2cm             0.34 (0.23,0.51)  0.34 (0.19,0.61)  &lt; 0.001        &lt; 0.001   
##                                                                                                
## treatmentSurgery:size&gt;= 2cm       -                 0.59 (0.21,1.7)   0.329          &lt; 0.001   
##                                                                                                
## Log-likelihood = -9.6736
## No. of observations = 4
## AIC value = 27.3472</code></pre>
<p>交互作用項的迴歸係數是否爲零的檢驗結果是 <span class="math inline">\(p = 0.329\)</span>，提示數據無法提供足夠的證據證明結石尺寸對治療方案和手術成功與否之間的關係造成有意義的交互作用 (There is no evidence of an interaction between stone size and surgery)。所以此次的數據分析我們可以報告結石尺寸調整後的手術成功比值比就可以了。其中，交互作用項的迴歸係數 <span class="math inline">\(-0.5245 = \text{log}(0.59)\)</span>，的含義是當結石尺寸 <span class="math inline">\(\geqslant 2 \text{cm}\)</span> 時，外科手術和超聲碎石術成功<strong>比值比的對數的差</strong>。我們可以看到一開始我們計算的分層比值比的比值 <span class="math inline">\(\frac{1.23}{2.08} = 0.59\)</span>。還注意到這已經是一個飽和模型 (模型偏差爲零)，模型的擬合值和我們的觀測值是完全相同的。</p>
<p>另外一點不得不提的是，交互作用項的迴歸係數的點估計 <span class="math inline">\(0.59\)</span> 其實低於零假設時的 <span class="math inline">\(1\)</span> 挺多的，它的 <span class="math inline">\(95\%\)</span> 信賴區間也相當的寬 <span class="math inline">\((0.21,1.70)\)</span>，所以其實這裏我們沒有獲得足夠的證據證明替代假設 (有交互作用)，很難說不是因爲樣本量不足導致的統計效能較低，所以我們沒有辦法從這個數據完全排除結石尺寸對治療方案的選擇和手術成功的關係之間的交互作用。(We really cannot be sure that there is no interaction in truth - the data are consistent with quite large interactions between size and surgery effect.) 因此，<strong>有些統計學家可能會傾向於報告分層的比值比，因爲我們沒有辦法從這個樣本數據排除有較強交互作用存在的可能性</strong>。</p>
</div>
<div id="可壓縮性-collapsibility" class="section level2">
<h2><span class="header-section-number">49.3</span> 可壓縮性 collapsibility</h2>
<p>模型可壓縮性的概念可以這樣來理解：</p>
<p>當我們把一個 <strong>我們認爲很重要的混雜因子</strong> 加到模型中去時，自然而然我們會期待其對結果變量的 <strong>效果估計 (effect estimate)</strong> (迴歸係數)在調整前後發生變化。如果是反過來，當我們把一個 <strong>我們認爲不重要的非混雜因子</strong> 加到模型中去時，我們也會自然而然地期待其對結果變量的 <strong>效果估計 (effect estimate)</strong> 在調整前後不會發生改變才是。不幸的是，我們這種理想中的想當然，僅僅在某些情境下成立，其中之一是簡單線性迴歸 (Section <a href="#lm">26</a>)。</p>
<div id="線性迴歸的可壓縮性" class="section level3">
<h3><span class="header-section-number">49.3.1</span> 線性迴歸的可壓縮性</h3>
<p><strong>證明</strong></p>
<p>令 <span class="math inline">\(Y\)</span> 標記結果變量，<span class="math inline">\(X\)</span> 標記暴露變量，<span class="math inline">\(Z\)</span> 則標記我們想要調整的莫個混雜因子：</p>
<p><span class="math display">\[
Y = \alpha + \beta_X X + \beta_Z Z + \varepsilon, \text{ where } \varepsilon \sim N(0, \sigma^2)
\]</span></p>
<p>然後把等式兩邊同時取以暴露變量 <span class="math inline">\(X\)</span> 爲條件的期待值：</p>
<p><span class="math display">\[
E(Y | X) = \alpha + \beta_X X + \beta_Z E(Z|X)
\]</span></p>
<p>如果 <span class="math inline">\(Z\)</span> 和 <span class="math inline">\(X\)</span> 是相互獨立的 (即，不是 <span class="math inline">\(X, Y\)</span> 之間關係的混淆因子)，那麼 <span class="math inline">\(E(Z|X) = E(Z) = \mu_Z\)</span>，因爲 <span class="math inline">\(X\)</span> 不能提供任何 <span class="math inline">\(Z\)</span> 的有效信息。所以，等式就變爲：</p>
<p><span class="math display">\[
E(Y|X) = \alpha + \beta_Z \mu_Z + \beta_X X
\]</span></p>
<p>所以，當我們用簡單線性迴歸來擬合 <span class="math inline">\(X,Y\)</span> 之間的關係時，如果 <span class="math inline">\(Z,X\)</span> 是相互獨立的，模型中增加了 <span class="math inline">\(Z\)</span>，不會影響 <span class="math inline">\(X\)</span> 的迴歸係數。線性迴歸的這個性質被定義爲模型的可壓縮性 (linear regression models are collapsible)。</p>
</div>
<div id="collapsibility" class="section level3">
<h3><span class="header-section-number">49.3.2</span> 邏輯鏈接方程時的不可壓縮性</h3>
<p>使用對數鏈接方程 (<span class="math inline">\(\text{log link}\)</span>) 的迴歸模型，同樣具有和線性迴歸類似的可壓縮性。但是，邏輯鏈接方程 (<span class="math inline">\(\text{logit link}\)</span>) 的迴歸模型則不具有可壓縮性。下面舉例的分層表格和壓縮表格，證明了邏輯鏈接方程不具有可壓縮性：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.7: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(stratified data)</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 1
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 2
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
90
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
10
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
90
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>從表格的數據計算可知，要被調整的分組變量的兩層數據中，暴露變量和結果變量的關係相同，比值比都是 <span class="math inline">\(9\)</span>，沒有交互作用，也沒有混雜效應 (每一層中暴露與非暴露均佔相同的 <span class="math inline">\(50\%\)</span>)。但是，你如果把這個觀測數據合併：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.8: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(collapsed data)</strong>
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
140
</td>
<td style="text-align:center;">
60
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
140
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
200
</td>
<td style="text-align:center;">
200
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
5.4
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>既然已知我們拿來分層的變量對暴露和結果的關係既沒有交互作用，也沒有混雜效應，那麼壓縮數據以後的合併比值比應該和分層比值比一樣才說的通，可惜我們獲得了截然不同的合併比值比 (非調整的)。所以在應用邏輯鏈接方程建立廣義線性迴歸模型的時候，一定不能忘記其不可壓縮性的特徵。所以，<strong>即使加入一個非混淆因子，暴露變量的邏輯迴歸的效應估計 (係數) 也會發生改變</strong>。調整了 <span class="math inline">\(Z\)</span> 以後的比值比被叫做條件 (或直接使用分層) 比值比。如同表格中實例所示，條件比值比會比邊緣比值比 (非調整) 看起來要大一些。</p>
<p>邏輯迴歸的不可壓縮性給我們的啓示是，加入某個變量進入邏輯迴歸模型前後，其他預測變量的迴歸係數發生的變化可能僅僅是由於模型的不可壓縮性導致的變化，而非由於新加入的變量對原先變量與結果之間的關係起到了交互作用或者混雜效應。所以，<strong>擬合迴歸模型的時候，如果你要考慮對莫個因素進行調整，必須做的一件事是，先分析它和其他模型中已有的預測變量之間的關係，從而有助於分析，當把要調整的變量放進模型前後的迴歸係數變化是否是真的來自於交互作用或者混雜效應。</strong></p>
</div>
</div>
<div id="interaction-depend-scale" class="section level2">
<h2><span class="header-section-number">49.4</span> 交互作用對尺度的依賴性</h2>
<p>GLM 模型中的交互作用檢驗，對選用的尺度 (比值比 OR，還是危險度比 RR) 依賴性極高。用模型可壓縮性的數據例子也可以說明交互作用對尺度的依賴性。上文書說到，兩個分層中的比值比都是 9，該分層變量既沒有交互作用，也不是混淆因子 (當使用比值比的時候)。如果我們改用危險度比 (risk ratio, RR)，在分類變量的第一層 (Strata 1) 中，暴露的危險度比是 <span class="math inline">\(\frac{90/100}{50/100} = 1.8\)</span>；分類變量的第二層 (Strata 2) 中，暴露的危險度比是 <span class="math inline">\(\frac{50/100}{10/100} = 5\)</span>。所以使用危險度比作爲評價指標的時候，被調整的分類變量就突然搖身一變變成了有交互作用的因子。這裏，我們用數據，證明了交互作用的存在與否，對尺度的選用依賴性極高。<strong>這就導致我們在描述一個變量是否對我們關心的暴露和結果之間的關係有交互作用時，必須明確指出所使用的是比值比，還是危險度比進行的交互作用評價。</strong></p>
</div>
</div>
<div id="流行病學中的邏輯迴歸" class="section level1">
<h1><span class="header-section-number">第 50 章</span> 流行病學中的邏輯迴歸</h1>
<div id="流行病學研究最常用的實驗設計" class="section level2">
<h2><span class="header-section-number">50.1</span> 流行病學研究最常用的實驗設計</h2>
<p>在流行病學研究中，我們最關心的無非是 暴露變量 (治療方案的選用，或者一些對象的某些特徵如吸菸或飲酒等生活習慣) 與結果變量 (罹患某種我們關心的疾病與否，或者死亡與否) 之間的相關關係。爲了方便解釋本章暫且只考慮 <strong>單一的結果變量 (univariate)</strong> 的情況，不過不要忘了真實世界中的數據和實驗，我們常要 <strong>同時處理多個不同的結果變量 (multivariate)</strong>。</p>
<p>流行病學最常用的兩種研究設計是：</p>
<ul>
<li>隊列研究/前瞻性研究 cohort or prospective studies；</li>
<li>病例對照/回顧性研究 case-control or retrospective studies。</li>
</ul>
<p>無論是這兩種研究中的哪一種，都要從定義研究的人羣開始 (start by defining some population we wish to study)。例如某個年齡段的男性或者女性；某個特定時間段內，在某特定地區範圍內生活的所有人等。這被定義爲 <strong>潛在研究人羣 (underlying population of interest)</strong>。</p>
<p>如果是<strong>隊列研究</strong>，我們需要對這個潛在研究人羣取樣，選取具 <strong>有代表性的，且有足夠樣本量</strong> 的一羣個體 (隊列) 參與研究。那些我們要研究的 <strong>暴露變量 <span class="math inline">\((\mathbf{X})\)</span></strong> 被提前定義好，然後在開始研究的時候收集整理成數據庫。之後這個隊列的參與者不斷被隨訪，這個時間段可以是先定義好的 (一年，五年，十年…)，也可以因人而異，最終直至每個個體的結果變量被觀測到 <span class="math inline">\((D=1 \text{ or } D=0)\)</span>。更一般地，如果我們要研究的暴露因素是二分類的，甚至是多分類的，我們可能會使用一些取樣的技巧，從而保證取樣構成的隊列能夠真實地反應該暴露因子在人羣中的分佈情況，保證隊列的代表性。</p>
<p>如果是<strong>病例對照研究</strong>，從它的別名 – 回顧性研究 – 也可以看出，它的研究起點和隊列研究相反，是從收集到的病例開始的 <span class="math inline">\((D=1)\)</span>。有了病例以後，我們從人羣中沒有該結果變量 <span class="math inline">\((D=0)\)</span> 的人羣中，取適合樣本量的人作爲對照組。然後再分別對病例和對照組用採訪或者問卷，或者調取過去的病例記錄/數據庫記錄等等尋找他們是否接觸過我們要研究的暴露變量。</p>
<p>到這裏，如果你還沒暈，恭喜你應該能理解爲什麼說<strong>病例對照研究研究的是 “結果的原因/causes of effect”</strong>；<strong>隊列研究研究的是 “原因導致的結果/effect of causes”</strong>。二者的終極目標卻是一致的 – 尋找暴露和結果二者之間的關係/To investigate the association between exposures and the outcomes – 只是手段不同而已。</p>
<p>觀察性研究 (不論是隊列還是病例對照研究)，除了我們一定會測量並收集的暴露變量數據，在分析過程中還不可避免地需要把混雜效應考慮進來，也就是我們還必須測量並收集那些潛在的混雜因子的數據 <span class="math inline">\((W)\)</span>。圖 <a href="#fig:cohort-case-control">50.1</a> 用簡單示意圖總結了 <span class="math inline">\(W (\text{ confounders }), X (\text{ exposures }), D (\text{ outcomes })\)</span> 之間，在不同實驗設計下的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:cohort-case-control"></span>
<img src="img/Selection_114.png" alt="Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study." width="90%" />
<p class="caption">
圖 50.1: Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study.
</p>
</div>
</div>
<div id="GLM8-3" class="section level2">
<h2><span class="header-section-number">50.2</span> 以簡單二分類暴露變量爲例</h2>
<div id="先決條件" class="section level3">
<h3><span class="header-section-number">50.2.1</span> 先決條件</h3>
<p>我們以一個最簡單的二分類暴露變量 <span class="math inline">\((X)\)</span>，和一個二分類結果變量 <span class="math inline">\((D)\)</span> 爲例展開：</p>
<ul>
<li>觀察對象樣本量爲 <span class="math inline">\(n, i = 1,\cdots,n\)</span>；</li>
<li><span class="math inline">\(X_i\)</span> 爲一個二分類暴露變量 (是否接觸了某種化學試劑，<span class="math inline">\(1=\)</span>是，<span class="math inline">\(0=\)</span>否)；</li>
<li><span class="math inline">\(D_i\)</span> 爲一個二分類結果變量 (是否有食道癌，<span class="math inline">\(1=\)</span>是，<span class="math inline">\(0=\)</span>否)。</li>
</ul>
<p>所以，該研究的潛在研究人羣可以被分成四組：<span class="math inline">\((X=1,D=1),(X=1,D=0),(X=0,D=1),(X=0,D=0)\)</span>。如果用 <span class="math inline">\(\pi_{11}, \pi_{10}, \pi_{01}, \pi_{00}\)</span> 標記每組人在該潛在研究人羣中所佔的比例，那麼有：</p>
<p><span class="math display" id="eq:GLM8-123">\[
\begin{aligned}
\pi_{xd} &amp; = \text{Pr}(X=x, D=d) \\
\pi_{11} &amp;+ \pi_{10} + \pi_{01} + \pi_{00}  = 1
\end{aligned}
\tag{50.1}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.1: Probabilities associated with binary explanatory and binary response variables <strong>in the underlying population structure</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
</tr>
</tbody>
</table>
<p>應用概率標記法來輔助理解隊列研究：我們從潛在研究人羣中抽樣，觀察其暴露情況，再追蹤其結果變量。所以實際上，<strong>隊列研究的樣本，來自與對暴露與否 <span class="math inline">\((X=0, X=1)\)</span> 兩組人的抽樣</strong>，所以我們實際求的是，</p>
<p><span class="math display">\[
\begin{equation}
\text{Pr}(D=d|X=x) = \frac{\pi_{xd}}{\pi_{x0} + \pi_{x1}}
\end{equation}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.2: Probabilities associated with binary explanatory and binary response variables <strong>in a cohort study</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(D\)</span>
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(\text{Pr}(D=d|X=x)\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
<span class="math inline">\(X\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{01}}{\pi_{01} + \pi_{00}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{11}}{\pi_{10} + \pi_{11}}\)</span>
</td>
</tr>
</tbody>
</table>
<p>相反地，病例對照研究中我們從已有的病例 <span class="math inline">\((D=1)\)</span> 出發，這樣做的理由有很多，通常可能由於病例可能十分稀少，如果建立隊列研究可能需要龐大的樣本量 (即便如此也不一定能夠收集到足夠分析的數據，可能還要花費相當長的隨訪時間，吃力不討好)。所以，在病例對照研究的設計中，我們其實是獨立地從兩個人羣 (病例組，<span class="math inline">\(D=1\)</span>，對照組，<span class="math inline">\(D=0\)</span>) 中抽取樣本。所以，<strong>病例對照研究獲得的數據，只能用於計算暴露在病例組和對照組中的條件概率</strong>：</p>
<p><span class="math display">\[
\text{Pr}(X=x|D=d) = \frac{\pi_{xd}}{\pi_{0d}+\pi_{1d}}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.3: Separate samples from subpopulations <span class="math inline">\(D=0,1\)</span> with relavant conditional probabilities <strong>in a case-control study</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{Pr}(X=x|D=d)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{10}}{\pi_{10}+\pi_{00}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{11}}{\pi_{11}+\pi_{01}}\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="比值比-odds-ratios" class="section level3">
<h3><span class="header-section-number">50.2.2</span> 比值比 Odds ratios</h3>
<p>一項研究 二分類暴露變量 <span class="math inline">\(X\)</span>，和 二分類結果變量 <span class="math inline">\(D\)</span> 之間的關係的研究，我們其實最關心的問題是：結果變量的兩個分類 <span class="math inline">\(D=0, D=1\)</span>，在暴露變量 <span class="math inline">\(X=0, X=1\)</span> 兩組中到底個佔多少比例。用吸菸與肺癌的例子來解釋就是，我們最關心的是，在吸菸人羣中，發生肺癌的人的比例，是否顯著地高於非吸菸人羣中發生肺癌的人的比例，僅此而已。這句話用概率論的標記法來寫的話，則是兩個條件概率：<span class="math inline">\(\text{Pr}(D=1|X=1), \text{Pr}(D=1|X=0)\)</span>。此處，可以定義暴露變量 <span class="math inline">\(X=1\)</span> 的條件下，結果變量 <span class="math inline">\(D=1\)</span> 的概率的比值 (Odds)：</p>
<p><span class="math display">\[
\text{Odds}_1 = \frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)} = \frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}
\]</span></p>
<p>類似地，暴露變量 <span class="math inline">\(X=0\)</span> 的條件下，結果變量 <span class="math inline">\(D=1\)</span> 的概率的比值 (Odds)：</p>
<p><span class="math display">\[
\text{Odds}_2 = \frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)} = \frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}
\]</span></p>
<p>故，從隊列研究中，可以很自然的計算暴露變量和結果變量的比值比：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Odds Ratio}_{\text{cohort}} = \frac{\text{Odds}_1}{\text{Odds}_2} &amp; = \frac{\frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)}}{\frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)}}\\
 &amp; = \frac{\frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}}{\frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}} \\
 &amp; = \frac{\frac{\pi_{11}/(\pi_{10}+\pi_{11})}{\pi_{10}/(\pi_{10}+\pi_{11})}}{\frac{\pi_{01}/(\pi_{01}+\pi_{00})}{\pi_{00}/(\pi_{01}+\pi_{00})}} \\
 &amp; = \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
\]</span></p>
<p>從病例對照研究中，推算的暴露變量和結果變量的比值比是另外一個過程：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Odds Ratio}_{\text{case-control}} = \frac{\text{Odds}^\prime_1}{\text{Odds}^\prime_2} &amp; = \frac{\frac{\text{Pr}(X=1|D=1)}{1-\text{Pr}(X=1|D=1)}}{\frac{\text{Pr}(X=0|D=0)}{1-\text{Pr}(X=0|D=0)}} \\
&amp; = \frac{\frac{\pi_{11}/(\pi_{11} + \pi_{01})}{1-\pi_{11}/(\pi_{11} + \pi_{01})}}{\frac{\pi_{10}/(\pi_{10} + \pi_{00})}{1-\pi_{10}/(\pi_{10} + \pi_{00})}} \\
&amp; = \frac{\frac{\pi_{11}/(\pi_{11}+\pi_{01})}{\pi_{01}/(\pi_{11}+\pi_{01})}}{\frac{\pi_{10}/(\pi_{10}+\pi_{00})}{\pi_{00}/(\pi_{10}+\pi_{00})}} \\
&amp; =  \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
\]</span></p>
<p>經過上面的推演，我們發現用病例對照研究的數據，<strong>雖然不能像隊列研究一樣直接推算正確的暴露條件下的比值 (conditional odds given exposure)</strong>，<strong>卻能用較少的樣本量中獲得真實的比值比 (OR) </strong>。</p>
</div>
<div id="GLM8-3-4" class="section level3">
<h3><span class="header-section-number">50.2.3</span> 邏輯迴歸應用於病例對照研究的合理性</h3>
<p>在一個<strong>隊列研究</strong>中，當我們有不止一個暴露變量時，顯然就需要更加複雜的模型來輔助分析 (迴歸型分析法) 暴露變量和結果變量之間的關係。估計比值比最佳的模型是邏輯迴歸。如果 <span class="math inline">\(D\)</span>，表示一個隨機型結果變量，其中每個觀察對象的結果變量服從暴露變量的條件二項分佈 (繼續用單一的<strong>二分類暴露變量</strong> <span class="math inline">\(x_i\)</span>)：</p>
<p><span class="math display">\[
(D_i|X_i = x_i) \sim \text{Binomial}(1, \pi_i)
\]</span></p>
<p>所以，可以用邏輯迴歸來擬合：</p>
<p><span class="math display">\[
\text{logit}(\pi_i) = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta x_i
\]</span></p>
<p>把這個邏輯迴歸方程重新整理：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D=1|X=1) &amp; = \frac{e^{\alpha + \beta}}{1 + e^{\alpha + \beta}} \\
\text{Pr}(D=1|X=0) &amp; = \frac{e^\alpha}{1 + e^\alpha} \\
\text{Where, }\alpha &amp; =  \text{log}{\frac{\pi_{01}}{\pi_{00}}} \\
\beta &amp; = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
\]</span></p>
<p>在一個<strong>病例對照研究</strong>中，結果變量 <span class="math inline">\(D_i\)</span> 被鎖死，暴露變量成了服從結果變量的條件二項分佈的隨機變量：</p>
<p><span class="math display">\[
(X_i | D_i = d_i) \sim \text{Binomial}(1,\pi_i^*)
\]</span></p>
<p>繼續任性地用邏輯迴歸擬合的話：</p>
<p><span class="math display">\[
\text{logit}(\pi_i^*) = \text{log}(\frac{\pi_i^*}{1-\pi_i^*}) = \alpha^* + \beta d_i
\]</span></p>
<p>同樣整理成概率方程：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(X=1|D=1) &amp; = \frac{e^{\alpha^* + \beta}}{1 + e^{\alpha^* + \beta}} \\
\text{Pr}(X=1|D=0) &amp; = \frac{e^{\alpha^*}}{1 + e^{\alpha^*}} \\
\text{Where, }\alpha &amp; =  \text{log}{\frac{\pi_{10}}{\pi_{00}}} \\
\beta &amp; = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
\]</span></p>
<p>所以，用邏輯迴歸擬合病例對照研究的數據，同樣可以得到和隊列研究一樣正確的比值比估計。但是這個截距 <span class="math inline">\(\alpha\)</span>，<strong>在隊列研究中指的是，非暴露組中患病的比值的對數 (log odds of disease in the unexposed)</strong>；<strong>在病例對照研究中指的是，對照組中暴露的比值的對數 (log odds of exposure in the controls)</strong>。是兩個完全不同含義的估計量。</p>
<p>綜上所述，從一個<strong>隊列研究獲得的似然方程</strong>是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{cohort}} &amp; = \prod_{i=1}^n(\frac{e^{\alpha + \beta x_i}}{1+e^{\alpha + \beta x_i}})^{d_i}(\frac{1}{e^{\alpha + \beta x_i}})^{1-d_i} \\
\text{Where } d_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
\]</span></p>
<p>從一個<strong>病例對照研究獲得的似然方程</strong>是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{case-control}} &amp; = \prod_{i=1}^n(\frac{e^{\alpha + \beta d_i}}{1+e^{\alpha + \beta d_i}})^{x_i}(\frac{1}{e^{\alpha + \beta d_i}})^{1-x_i} \\
\text{Where } d_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
\]</span></p>
</div>
</div>
<div id="拓展到多個暴露變量的邏輯迴歸模型" class="section level2">
<h2><span class="header-section-number">50.3</span> 拓展到多個暴露變量的邏輯迴歸模型</h2>
<p>現在來考慮 <span class="math inline">\(p\)</span> 個暴露變量的情況：<span class="math inline">\(X_1, \cdots, X_p\)</span>，這些暴露變量可以是分類型變量，也可以是連續型變量，例如，</p>
<ul>
<li><span class="math inline">\(D_i = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象觀察到有 <span class="math inline">\((=1)\)</span>，或沒有 <span class="math inline">\((=0)\)</span> 結果變量 (如發生胰腺癌)；</li>
<li><span class="math inline">\(X_{i1} = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象有 <span class="math inline">\((=1)\)</span>，或沒有 <span class="math inline">\((=0)\)</span> 暴露變量 (如吸菸)；</li>
<li><span class="math inline">\(X_{i2} = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象是男性 <span class="math inline">\((=1)\)</span>，或女性 <span class="math inline">\((=0)\)</span>；</li>
<li><span class="math inline">\(X_{i3}\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象的年齡 (years)。</li>
</ul>
<div id="mantel-haenszel-法" class="section level3">
<h3><span class="header-section-number">50.3.1</span> Mantel Haenszel 法</h3>
<p>如果數據有且只有兩個暴露變量，<span class="math inline">\(X_1, X_2\)</span>，其中 <span class="math inline">\(X_1\)</span> 是一個二分類變量，<span class="math inline">\(X_2\)</span> 是一個可以分成 <span class="math inline">\(C\)</span> 組的分類變量。那麼如果樣本量足夠大，可以把數據整理成 <span class="math inline">\(C\)</span> 個四格表用於分析每一個 <span class="math inline">\(X_2\)</span> 的分層中 <span class="math inline">\(X_1\)</span> 和結果變量 <span class="math inline">\(D\)</span> 之間的關係。多層數據的合併比值比可以用 <a href="https://en.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics">Mantel Haenszel 法</a>。此法在兩個分類暴露變量的情況下還能適用，當某個(或兩個)分類變量的層數越來越多時，你會發現最終落到小格子裏的樣本量急劇下降，侷限性就體現了出來。另外，此法亦不能應用於連續型變量的調整，用處簡直就是捉襟見肘。迫切地我們需要有更加一般的 (藉助於迴歸的威力的) 方法來對多個暴露變量進行調整。</p>
</div>
<div id="隊列研究和病例對照研究的似然" class="section level3">
<h3><span class="header-section-number">50.3.2</span> 隊列研究和病例對照研究的似然</h3>
<p>一個<strong>隊列研究</strong>，用邏輯迴歸擬合其結果變量 (因變量) <span class="math inline">\(D\)</span> 和暴露變量 <span class="math inline">\(X_1, \cdots, X_p\)</span> 之間的關係時，可以寫作：</p>
<p><span class="math display">\[
\begin{aligned}
D_i=1 | (X_{i1} &amp; = x_{i1}, \cdots, X_{ip} = x_{ip}) \sim \text{Binomial}(1, \pi_i) \\
\text{logit} (\pi_i) &amp; = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>將這個迴歸方程重新整理成爲概率方程：</p>
<p><span class="math display">\[
\text{Pr}(D_i = 1 | X_{i1}  = x_{i1}, \cdots, X_{ip} = x_{ip}) = \frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}
\]</span></p>
<ul>
<li>截距 <span class="math inline">\(\alpha\)</span> 的含義是，當所有的暴露變量都取 <span class="math inline">\(0\)</span> 時，研究對象觀察到結果變量爲 <span class="math inline">\(1\)</span> 的對數比值 <span class="math inline">\((\text{log odds})\)</span>；</li>
<li>迴歸係數 <span class="math inline">\(\beta_k\)</span> 的含義是，當其餘的暴露變量保持不變時，<span class="math inline">\(x_k\)</span> 每增加一個單位，結果變量爲 <span class="math inline">\(1\)</span> 的對數比值比 <span class="math inline">\((\text{log odds-ratio})\)</span> (即，調整了其餘所有變量之後，<span class="math inline">\(x_k\)</span> 和結果變量之間的對數比值比)。</li>
</ul>
<p>所以，隊列研究的數據，其似然方程是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{cohort}} &amp; = \prod_{i=1}^n\text{Pr}(D_i = d_i |  X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip}) \\
                  &amp; = \prod_{i=1}^n\text{Pr}(\frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
\end{aligned}
\]</span></p>
<p>當數據變成了<strong>病例對照研究</strong>，其似然方程會變成怎樣呢？</p>
<p><span class="math display">\[
L_{\text{case-control}} = \prod_{i=1}^n\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = d_i)
\]</span></p>
<p>這裏，我們很難看出這到底是怎樣的一個條件概率，如果預測變量中同時包括了連續型變量和分類變量，情況就更加複雜，剪不斷理還亂。</p>
</div>
<div id="病例對照研究中的邏輯迴歸" class="section level3">
<h3><span class="header-section-number">50.3.3</span> 病例對照研究中的邏輯迴歸</h3>
<p>用 <span class="math inline">\(\text{Pr}(S_i=1 \text{ or } 0)\)</span> 表示在潛在研究人羣 (underlying study population) 中，被抽樣 (或者沒有被抽樣) 進入該隊列研究的概率。那麼，理想情況下，可認爲實施病例對照研究時，病例是稀少的，即我們收集到的病例，幾乎等價於我們關心的潛在研究人羣中全部的病例，且可以被證明：</p>
<p><span class="math display" id="eq:GLM8-2526">\[
\begin{aligned}
 &amp; \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1) \\
=&amp; \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1, S_i=1) \\
=&amp; \frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}  \\
 &amp; \;\;\;\; \times \frac{\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)}{\text{Pr}(D_i = 1 | S_i = 1)} \\
\text{Where } \alpha^* &amp; =  \alpha + \text{log}(\frac{\text{Pr}(D_i = 0)}{\text{Pr}(D_i = 1)}) + \text{log}(\frac{\text{Pr}(D_i = 1|S_i=1)}{\text{Pr}(D_i = 0|S_i=1)})
\end{aligned}
\tag{50.2}
\]</span></p>
<p>概率方程 <a href="#eq:GLM8-2526">(50.2)</a> 中，可以看出第一部分 <span class="math inline">\(\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}\)</span> 是一個邏輯迴歸模型。跟隊列研究的邏輯迴歸模型相比較，差別只是截距不同 <span class="math inline">\(\alpha \neq \alpha^*\)</span>。其餘的部分如 <span class="math inline">\(\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)\)</span> 的含義是潛在人羣中被取樣放入該隊列研究，且預測變量各自不同的隨機概率分佈，其實和我們尋找的參數 <span class="math inline">\(\beta_1,\cdots,\beta_p\)</span>，是沒有什麼關係的。最後一部分分母的 <span class="math inline">\(\text{Pr}(D_i = 1 | S_i = 1)\)</span> 的意思是，結果變量爲 <span class="math inline">\(1\)</span> 的人被選入本項病例對照研究的概率，理想的實驗設計下這被認爲是接近於 <span class="math inline">\(1\)</span> 的，即使不是，它也是一個固定不變的常數。所以，病例對照研究的似然方程中，我們關心的只有第一部分，邏輯迴歸模型：</p>
<p><span class="math display">\[
L_{\text{case-control}} \propto \prod_{i=1}^n(\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
\]</span></p>
<p>這裏必須明確的一點是，病例對照研究擬合的邏輯迴歸，其截距是 <span class="math inline">\(\alpha^*\)</span>，並非 <span class="math inline">\(\alpha\)</span>。這個 <span class="math inline">\(\alpha^*\)</span> 其實是包含了 <span class="math inline">\(\text{Pr}(D_i=1),\text{Pr}(D_i=0)\)</span> 的，可惜這些概率也無法用病例對照研究設計獲得。所以，<strong>病例對照研究數據擬合了邏輯迴歸模型以後的截距，其實沒有太多實際的含義</strong>。</p>
</div>
</div>
<div id="流行病學研究中變量的調整策略" class="section level2">
<h2><span class="header-section-number">50.4</span> 流行病學研究中變量的調整策略</h2>
<div class="figure" style="text-align: center"><span id="fig:epi-adjustment"></span>
<img src="img/Selection_115.png" alt="relationships between three variables in an underlying population of interest" width="90%" />
<p class="caption">
圖 50.2: relationships between three variables in an underlying population of interest
</p>
</div>
<p>圖 <a href="#fig:epi-adjustment">50.2</a> 展示的是在潛在研究人羣中 <span class="math inline">\(W (\text{potential confounder}),X (\text{exposure}),D (\text{outcome})\)</span> 三者之間可能存在的四種關係。</p>
<ul>
<li>圖 <a href="#fig:epi-adjustment">50.2</a> - (a) <span class="math inline">\(W\)</span> 和 <span class="math inline">\(X, D\)</span> 都沒有關係，那麼我們研究 <span class="math inline">\(X,D\)</span> 之間的關係時，完全可以忽略掉 <span class="math inline">\(W\)</span>，不用調整。<br> 但是，如果在邏輯迴歸模型中調整了一個和暴露變量結果變量之間無關的變量，獲得的比值比估計幾乎不會有太大改變，但是代價是會獲得較大的對數比值比的<strong>標準誤 (standard error)，降低了對比值比估計的精確程度</strong>。</li>
<li>圖 <a href="#fig:epi-adjustment">50.2</a> - (b) <span class="math inline">\(W\)</span> 和 <span class="math inline">\(X, D\)</span> 同時都相關，且不在 <span class="math inline">\(X\rightarrow D\)</span> 的因果關係通路上，此種情況下，必須對 <span class="math inline">\(W\)</span> 進行調整，否則獲得的比值比估計是帶有嚴重偏倚的。</li>
<li>圖 <a href="#fig:epi-adjustment">50.2</a> - (c) <span class="math inline">\(W\)</span> 僅僅和 <span class="math inline">\(X\)</span> 有關係，和結果變量 <span class="math inline">\(D\)</span> 沒有相關性。此時研究 <span class="math inline">\(X,D\)</span> 之間的關係時，忽略掉 <span class="math inline">\(W\)</span>，不需要對之進行任何調整。和 (a) 一樣，如果此時調整了 <span class="math inline">\(W\)</span>，估計的比值比不會發生質變，但是會損失估計的精確度。</li>
<li>圖 <a href="#fig:epi-adjustment">50.2</a> - (d) <span class="math inline">\(W\)</span> 僅僅和結果變量 <span class="math inline">\(D\)</span> 有關係，和暴露變量 <span class="math inline">\(X\)</span> 無關時，如果模型對 <span class="math inline">\(W\)</span> 進行調整，我們會獲得完全不同的比值比估計，因爲這種情況下其實調整 <span class="math inline">\(W\)</span> 前後的比值比估計的是具有不同含義的，二者都具有實際意義。調整前的估計量，是總體估計，有助於作總體的決策；調整後的估計量，是帶有某些特徵的部分人羣估計，有助於評價個人水平的 <span class="math inline">\(X,D\)</span> 之間的關係。</li>
</ul>
</div>
</div>
<div id="分析策略" class="section level1">
<h1><span class="header-section-number">第 51 章</span> 分析策略</h1>
<div id="明確分析目的" class="section level2">
<h2><span class="header-section-number">51.1</span> 明確分析目的</h2>
<p>作爲統計學家，着手分析數據之前，千萬記得，必須要制定一個儘可能詳盡的分析計劃。即使你的分析，可能並不一定受到第三方的監管或者調控，因爲同行評審的專家們，喜歡看到你分析的目的明確，假設檢驗的過程是經過仔細推敲的。同時，也可以避免陷入 “<a href="https://en.wikipedia.org/wiki/Data_dredging">玩弄數據 (data dredging)</a>” 指控的危險。</p>
<p>數據分析的目的，可以分成三大類：</p>
<ol style="list-style-type: decimal">
<li>估計一個或者幾個暴露變量，對結果變量的影響。以此目的的數據分析過程，需要我們有<a href="https://en.wikipedia.org/wiki/John_Snow">醫學偵探</a>一樣的眼光和見解，從數據中判斷那些需要被調整和控制的混雜因子，從而提高你的分析效率。最常見的例子是分析隨機對照臨牀實驗 (RCT) 中，療效的差異；或者流行病學研究中，分析某種生活習慣，和疾病的發生或者死亡之間的關係。</li>
<li>在現有的數據庫中，尋找並且建立 “最佳” 模型。以此目的的數據分析，需要我們對模型中的結果變量有極爲深入的瞭解，把與之相關的<strong>所有要因</strong>，儘可能多的納入你的分析模型。常見的例子如，在某個特定人羣的數據庫中尋找並確定能夠決定自殺這一結果變量的決定性因素，之所以有這樣的目的，背後可能有決策者希望尋找這些決定性因素後採取一些對策從而達到改善現狀的最終目的。所以找到和結果變量相關的因素，是此類研究的重中之重。</li>
<li>建立預測模型。例如，某項研究的目的是爲了能夠建立一個能夠預測孕期胎兒患有唐氏綜合症的預測模型，用能夠測量的一些指標(如血液指標，或者母親的一些健康指標)，通過模型的算法，去計算胎兒患病的概率是多大。這樣的模型，對與診斷醫學有重大意義。所以，此類研究的目的，不是爲了尋找確定和胎兒患病相關的全部要因，而是<strong>怎樣才能提高模型預測的準確度</strong>，提高診斷的效率，減少錯誤診斷，拯救生命。</li>
</ol>
<p>當然，上述目的中的 2 和 3 有時候易讓人混淆，因爲我們可能建立最佳模型，除了想要找到和 “自殺” 這一結果相關的所有要因，還可能希望通過該模型做出預測，尋找可能自殺的高危人羣，進行干預。這並不矛盾。</p>
</div>
<div id="分析目的-1.1-估計-rct-中治療效果-treatment-effect" class="section level2">
<h2><span class="header-section-number">51.2</span> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</h2>
<p>先揀最軟的柿子捏，RCT 的療效比較作爲數據分析的目的時，情況要比其他的目的相對簡單些。RCT 的隨機過程，確保了臨牀試驗不會受到混雜因素的影響。但是我們還會出於爲了<strong>提高統計分析效能</strong>，<strong>改善估計的精確度</strong>的目的，對參與臨牀試驗的受試者最初測量的一些特徵進行調整。當然，不是所有的數據專家，也不是所有的 RCT 實施者都同意進行這一調整的。如果確定要調整，放入模型中的變量，可能常常是一開始隨機分配時用到的那些用於將受試者分層歸類或者最小化 (minimisation) 的那些變量。</p>
<p>基線值調整 (baseline adjustment)，在結果變量爲<strong>連續型，同時模型是線性迴歸模型</strong>時，能夠顯著提高統計效能 (statistical efficiency)，降低估計值的標準誤。理論上，一個基線測量時的連續型變量，如果它和實驗後測量的連續型結果變量之間的 <strong>皮爾森相關係數 Pearson correlation coefficient</strong> 是 <span class="math inline">\(r\)</span>，那麼如果你用 ANCOVA 模型調整了這個基線值的話，療效差異估計值的標準誤會是沒有調整時的 <span class="math inline">\(\sqrt{1-r^2}\)</span> 倍 (也就是永遠比不調整時要小，大大提高精確度，縮小療效差異估計值的 95% 信賴區間)。</p>
<p>但是，但是，但是！如果一個 RCT 測量的結果變量是一個二分類變量 (死亡/存活)，線性迴歸模型不適用，只能使用邏輯迴歸時，模型中加入和結果變量相關 (和暴露變量無關) 的基線值的做法对分析效能的提高顯得十分有限，相反還会受到邏輯迴歸的不可壓縮性較大的影響 (Section <a href="#collapsibility">49.3.2</a>)。</p>
<p>再把之前講邏輯迴歸不可壓縮性時用过的例子拿过来这里解释这个现象：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 51.1: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(stratified data)</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 1
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 2
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
90
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
10
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
90
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>上面的數據表示，分層變量 (Strata 1-2) 本身和使用藥物和安慰劑無交互作用，也和藥物使用與臨牀試驗結果之間的關係無關。但是，即使這個分類變量無關，壓縮後的數據計算獲得的比值比和分層時的比值比差異巨大：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 51.2: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(collapsed data)</strong>
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
140
</td>
<td style="text-align:center;">
60
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
140
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
200
</td>
<td style="text-align:center;">
200
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
5.4
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>實際在 R 裏擬合邏輯迴歸模型的結果如下：</p>
<pre><code>## 
## Call:
## glm(formula = Result ~ Treatment, family = binomial(link = logit), 
##     data = RCT)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5518  -0.8446   0.0000   0.8446   1.5518  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       0.84730    0.15430  5.4911 3.994e-08 ***
## TreatmentPlacebo -1.69460    0.21822 -7.7656 8.125e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 554.518  on 399  degrees of freedom
## Residual deviance: 488.691  on 398  degrees of freedom
## AIC: 492.691
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Call:
## glm(formula = Result ~ Treatment + Strata, family = binomial(link = logit), 
##     data = RCT)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1460  -1.1774   0.0000   1.1774   2.1460  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       2.19722    0.26505  8.2898 &lt; 2.2e-16 ***
## TreatmentPlacebo -2.19722    0.27486 -7.9941 1.306e-15 ***
## Strata2          -2.19722    0.27486 -7.9941 1.306e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 554.518  on 399  degrees of freedom
## Residual deviance: 407.292  on 397  degrees of freedom
## AIC: 413.292
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>從結果的迴歸係數估計和計算的標準誤來看，調整了其他的變量會引起：</p>
<ol style="list-style-type: decimal">
<li>使對數比值比的估計量升高 (這是由於模型的不可壓縮性) <span class="math inline">\(1.69 \rightarrow 2.19\)</span>；</li>
<li>對數比值比的標準誤估計升高 (非但不能增加估計精確度，反而起到了反作用) <span class="math inline">\(0.22\rightarrow0.27\)</span>；</li>
<li>對數比值比的統計檢驗量升高 (由於對數比值比的升高比標準誤升高的更多一些) <span class="math inline">\(7.77\rightarrow7.99\)</span>。</li>
</ol>
<p>事實上，上面的現象在使用邏輯迴歸的時候基本上都會呈現。在經典論文 <span class="citation">(Robinson and Jewell <a href="#ref-Robinson1991" role="doc-biblioref">1991</a>)</span> 中給出了詳細的論證。所以其實使用邏輯迴歸擬合數據的 RCT 臨牀試驗，我們可以推論，<strong>當模型中加入第三個僅和結果變量有關的基線共變量</strong> (baseline covariates)，如果模型估計的對數比值比在調整前後變化不大 (即，不可壓縮性造成的影響很小)，那這樣的調整對於改善分析的統計效能上幾乎也沒有貢獻。(跟使用線性迴歸的 RCT 完全不同！)</p>
<p>由於邏輯迴歸受使用 <span class="math inline">\(\text{logit}\)</span> 鏈接方程時不可壓縮性的侷限，同時還由於使用 <span class="math inline">\(\text{log}\)</span> 鏈接方程時獲得的危險度比 (risk ratios) 比比值比 (odds ratios) 更加容易讓人理解，結果變量爲二分類的 RCT 臨牀試驗常常會選用 <span class="math inline">\(\text{log}\)</span> 鏈接方程的廣義線性迴歸模型 (見 Section <a href="#logit-or-log">45.3</a> 第 5 條討論)。選用 <span class="math inline">\(\text{log}\)</span> 鏈接方程的 GLM 最大的問題在於，當模型中<strong>加入過多的預測變量</strong>時，會導致模型<strong>無法收斂 (converge)–無法找到極大似然估計</strong>。</p>
<p>至於使用泊松迴歸模型的時候，預測變量如果放入不合理，那麼很容易違反泊松分佈的前提 (方差和均值相同)。對於違反了泊松分佈前提，模型變得過度離散 (over-dispersed) 的 GLM，加入適當的基線共變量 (baseline covariates) 則有助於減少模型的過度離散，減小參數估計的標準誤 (使之變得更精確些)。和線性迴歸相同的是，泊松迴歸模型不受不可壓縮性 (non-collapsibility) 的影響。</p>
<div id="rct-數據分析的一些不成熟的小建議" class="section level3">
<h3><span class="header-section-number">51.2.1</span> RCT 數據分析的一些不成熟的小建議</h3>
<ol style="list-style-type: decimal">
<li>RCT 臨牀試驗通常都有嚴格的數據管理和監控，且統計分析計劃 (statistical analysis plan, SAP) 在任何一個 RCT 都已經是必須條件。除此之外，還要在試驗進行前就制訂所有詳細的計劃，並寫成實驗實施計劃文件，以供參與的所有人及倫理審查委員會等各種第三方機構的監督。所以，RCT 的統計分析計劃必須儘量考慮到所有的可能情況，因爲一旦開始了試驗，分析計劃是很難改動的。</li>
<li>SAP 必須詳細記錄哪些共變量需要被調整，常見的是實驗設計階段用於實施隨機化過程的那些特徵變量。對於連續型結果變量，(還有過度離散的計數型變量)，基線共變量的調整許多時候會有助於改善參數估計的精確度，提高統計效能。對於使用邏輯迴歸模型的試驗，調整基線共變量則沒有太多的好處，且調整後的比值比的含義會發生較大的改變，需慎重。</li>
<li>有些統計學家支持調整基線共變量，認爲這樣做有助於減少萬一隨機化不徹底造成的治療組和對照組之間隨機產生的殘差偏倚 (residual bias)，但是你無法提前欲知那些變量可能會產生隨機的殘差偏倚，這樣便無法在事先需要準備的SAP計劃文件中明確到底哪些基線變量需要被調整。</li>
<li>另有許多研究者喜歡在 RCT 中尋找交互作用的存在，但是他們常常忽略掉的一點是，一個 RCT 本身的檢驗效能是 80%-90%，其用於檢驗交互作用的效能會更低。建議在 RCT 中儘量少 (甚至不建議) 進行任何交互作用的統計檢驗。</li>
</ol>
</div>
</div>
<div id="分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect" class="section level2">
<h2><span class="header-section-number">51.3</span> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</h2>
<p>前文討論的關於調整僅僅和結果變量相關 (與暴露變量無關) 的基線共變量的內容，同樣適用與一般的流行病學研究。流行病學研究中另一個 (應該是更加) 重要的點是，混雜因子的排查和調整。</p>
<p>實例：</p>
<ul>
<li><span class="math inline">\(Y\)</span> 標記結果變量，如嬰兒的出生體重；</li>
<li><span class="math inline">\(X_1\)</span> 標記最主要的 (想要分析其與結果變量之間的關係的) 預測變量，如母親孕期高血壓 (是/否)；</li>
<li><span class="math inline">\(X_2, X_3, \cdots, X_Q\)</span> 標記其他非主要預測變量，但是可能是 <span class="math inline">\(X_1, Y\)</span> 之間關係中重要的潛在混雜因子，如嬰兒的性別/母親孕前體重/嬰兒胎齡等等。</li>
</ul>
<p>在這個簡單流行病學研究實例中，我們關心的問題包括：</p>
<ol style="list-style-type: decimal">
<li>主要暴露變量–孕期高血壓，和結果變量–嬰兒出生體重二者的未调整前 (粗) 關係 (crude/before adjustment association) 是什麼樣的？</li>
<li>主要暴露變量和結果變量之間的關係是否被其他因素影響 (例如胎齡)？如果有，那麼調整後的關係會發生怎樣的變化？</li>
<li>有沒有其他的變量會改變 (modify) 主要暴露變量和結果變量之間的關係？也就是，有沒有那個變量和主要暴露變量有交互作用？</li>
<li>有沒有其他的變量和主要暴露變量無關，卻可能和結果變量有關係呢？如果存在這樣的變量，模型中調整它在一些情況下可能會改善擬合的結果提高模型的統計效能 (statistical power)。</li>
<li>收集的變量中，有沒有哪個變量可能是在主要暴露變量和結果變量之間因果關係 (如果存在因果關係的話) 的通路上 (on the causal pathway) 的呢？如果有，這樣的變量應該被認爲是媒介因子 (mediator)。</li>
</ol>
<div id="不成熟的小策略" class="section level3">
<h3><span class="header-section-number">51.3.1</span> 不成熟的小策略</h3>
<p>這是很常見的簡單流行病學數據分析。可以按照 (但不一定非要按照) 下面建議的步驟實施統計分析：</p>
<ol style="list-style-type: decimal">
<li>第一步，分析主要暴露變量和結果變量之間的未調整前 (粗) 關係： <br> <span class="math display">\[g\{ E(Y|X_1) \} = \alpha + \beta_1 X_1\]</span></li>
<li>第二步，逐個分析<strong>其餘的變量和主要暴露變量之間的關係</strong>，以及這些<strong>潛在的混雜因子和結果變量之間的關係</strong>。注意，這一步可能耗時較長，但是它並不是決定模型中是否要加入某個或某些非主要暴露變量的步驟，通過<strong>這一步過程有助於我們分析和理解，進一步分析中調整前後的參數估計變化</strong>。</li>
<li>第三步，建立主要暴露變量和這些潛在混雜因子同時放入模型中的 GLM，逐步放入，<strong>一次放入一個 (one at a time) 潛在混雜因子</strong>，和上一步分析的三者之間的關係相結合，分析調整該潛在混雜因子前後，主要暴露變量的迴歸係數的參數估計變化的原因。<br> <span class="math display">\[g\{ E(Y|X_1, X_k) \} = \alpha^* + \beta_1^*X_1 + \beta_kX_k,\; k= 1,\cdots,Q\]</span></li>
</ol>
<p>我們來分析這個可以從 <a href="http://www.stata-press.com/data/r12/lbw.dta">Stata 網站上下載的數據</a>：</p>
<ul>
<li>第一步，先看看暴露變量和結果變量之間的關係</li>
</ul>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb594-1" title="1">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb594-2" title="2">lbw<span class="op">$</span>race &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>race)</a>
<a class="sourceLine" id="cb594-3" title="3">lbw<span class="op">$</span>smoke &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>smoke)</a>
<a class="sourceLine" id="cb594-4" title="4">lbw<span class="op">$</span>ht &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>ht)</a>
<a class="sourceLine" id="cb594-5" title="5">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Birthweight &lt;2500g&quot;</span> =<span class="st"> </span>low, <span class="st">&quot;History of hypertension&quot;</span>=ht), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(low)), <span class="dt">data =</span> lbw, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb594-6" title="6"><span class="co"># We first tabulate the data</span></a>
<a class="sourceLine" id="cb594-7" title="7"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  -------------------------------------- 
##               -History of hypertension- 
##  Birthweight         0       1   Total  
##  &lt;2500g                                 
##  -------------------------------------- 
##  0                 125       5     130  
##                  70.62   41.67   68.78  
##                                         
##  1                  52       7      59  
##                  29.38   58.33   31.22  
##                                         
##                                         
##  Total             177      12     189  
##                 100.00  100.00  100.00  
##  --------------------------------------</code></pre>
<ul>
<li>第二步，分析母親高血壓病史和嬰兒低出生體重之間的調整前 (粗) 關係。</li>
</ul>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb596-1" title="1">Model0 &lt;-<span class="st"> </span><span class="kw">glm</span>(low<span class="op">~</span>ht, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb596-2" title="2"><span class="kw">summary</span>(Model0); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model0)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht, family = binomial(link = &quot;logit&quot;), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.32323  -0.83407  -0.83407   1.56519   1.56519  
## 
## Coefficients:
##             Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -0.87707    0.16502 -5.3150 1.066e-07 ***
## ht1          1.21354    0.60835  1.9948   0.04606 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 230.650  on 187  degrees of freedom
## AIC: 234.65
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##            OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0 3.37 (1.02,11.09)  0.046          0.045     
##                                                        
## Log-likelihood = -115.3249
## No. of observations = 189
## AIC value = 234.6499</code></pre>
<p>所以，數據提供了一些證據證明母親的高血壓病史和嬰兒低出生體重之間可能存在正關係，這個調整前的關係是，粗比值比 (crude odds ratio) 爲 3.37 (1.02, 11.09)。</p>
<ul>
<li>接下來，分析潛在的混雜因子是否和主要暴露變量相關：</li>
</ul>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb599-1" title="1"><span class="co"># lwt is the last weight of mothers before pregnancy</span></a>
<a class="sourceLine" id="cb599-2" title="2">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(lwt <span class="op">~</span><span class="st"> </span>ht, <span class="dt">data =</span> lbw)</a>
<a class="sourceLine" id="cb599-3" title="3"><span class="kw">summary</span>(Model1); epiDisplay<span class="op">::</span><span class="kw">regress.display</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lwt ~ ht, data = lbw)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -62.5000 -17.9435  -7.9435  10.0565 122.0565 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 127.9435     2.2390 57.1426  &lt; 2e-16 ***
## ht1          29.5565     8.8858  3.3262  0.00106 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29.788 on 187 degrees of freedom
## Multiple R-squared:  0.05586,    Adjusted R-squared:  0.050811 
## F-statistic: 11.064 on 1 and 187 DF,  p-value: 0.0010596</code></pre>
<pre><code>## Linear regression predicting lwt
##  
##            Coeff.(95%CI)        P(t-test) P(F-test)
## ht: 1 vs 0 29.56 (12.03,47.09)  0.001     0.001    
##                                                    
## No. of observations = 189</code></pre>
<p>可見，有高血壓病史的母親，孕前體重較高。再看其與結果變量是否有關係：</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb602-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb602-2" title="2"><span class="kw">summary</span>(Model2); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ lwt, family = binomial(link = &quot;logit&quot;), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.09482  -0.90217  -0.80197   1.36105   1.98141  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  0.9957634  0.7852434  1.2681  0.20476  
## lwt         -0.0140371  0.0061685 -2.2756  0.02287 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 228.708  on 187  degrees of freedom
## AIC: 232.708
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## lwt (cont. var.) 0.99 (0.97,1)  0.023          0.015     
##                                                          
## Log-likelihood = -114.354
## No. of observations = 189
## AIC value = 232.7081</code></pre>
<p>由此知，母親孕前體重較高的人，有較低的可能剩下低出生體重的嬰兒。這兩個單獨的關係，各自看都具有 5% 的統計學意義，但是這 (或者其他變量分析的結果沒有統計學意義時) 並不是決定模型中是否加入母親孕前體重這一潛在的混雜因子的理由。接下來，我們通過模型中加入母親孕前體重這一變量前後模型的參數估計變化來分析：</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb605-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>ht <span class="op">+</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb605-2" title="2"><span class="kw">summary</span>(Model3);epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht + lwt, family = binomial(link = &quot;logit&quot;), 
##     data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.85912  -0.87274  -0.73845   1.29224   2.17964  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  1.4478621  0.8208975  1.7638 0.077773 . 
## ht1          1.8544773  0.7008245  2.6461 0.008142 **
## lwt         -0.0186285  0.0065928 -2.8256 0.004720 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 221.165  on 186  degrees of freedom
## AIC: 227.165
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  crude OR(95%CI)    adj. OR(95%CI)     P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0       3.37 (1.02,11.09)  6.39 (1.62,25.23)  0.008          0.006     
##                                                                                 
## lwt (cont. var.) 0.99 (0.97,1)      0.98 (0.97,0.99)   0.005          0.002     
##                                                                                 
## Log-likelihood = -110.5827
## No. of observations = 189
## AIC value = 227.1654</code></pre>
<p>加入了孕前體重的模型給出的母親是否有高血壓病史對嬰兒的低出生體重關係的比值比估計爲 <span class="math inline">\(6.39\)</span>，這很明顯比調整孕前體重前的粗比值比 <span class="math inline">\((3.37)\)</span> 大了很多。這個比值比估計的變化有兩個原因：</p>
<ol style="list-style-type: decimal">
<li>(常被忽略的) 邏輯迴歸模型的不可壓縮性導致的；</li>
<li>母親孕前體重對高血壓病史和嬰兒的低出生體重之間的關係造成了混雜效應。</li>
</ol>
<p>上面的分析結果，告訴我們，數據提供了足夠的證據證明母親孕前體重和是否有高血壓病史，在調整了彼此之後，仍然獨立地和嬰兒低出生體重的發生有相關性。這裏，我們可以下結論認爲，模型中加入母親孕前體重作爲混雜因子，是合情合理的。</p>
<p>完成了目前爲止的初步分析和混雜因子的判斷以後，下一階段的分析側重於尋找有沒有任何第三方的預測變量，會對主要暴露變量 <span class="math inline">\(X_1\)</span> (孕期高血壓) 與結果變量 <span class="math inline">\(Y\)</span> (嬰兒出生體重過低) 之間的關係產生交互作用。如果數據中的預測變量有多個，那可能導致需要分析潛在的交互作用有許多對，通常建議在遇到多個預測變量之間的複雜關係需要討論的時候，建議不要一股腦全部作交互作用的分析，而是限定一個或者幾個最有可能有交互作用的變量就可以了。否則模型過於複雜，反而不利於理解。一般生物醫學的統計分析中考慮的重要交互作用分析，需要有重要的生物學意義，常見的例子是年齡，性別等。</p>
<p>本節使用的例子中，令人感興趣的是，母親的孕前體重，會不會對妊娠高血壓的有無與嬰兒出生體重過低之間的關係造成交互作用：</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb608-1" title="1">Model4 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>ht<span class="op">*</span>lwt, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), <span class="dt">data =</span> lbw)</a>
<a class="sourceLine" id="cb608-2" title="2"><span class="kw">summary</span>(Model4); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht * lwt, family = binomial(link = &quot;logit&quot;), 
##     data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.77338  -0.87349  -0.74658   1.28246   2.20403  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  1.5393115  0.9174755  1.6778 0.093392 . 
## ht1          1.2869895  2.5493528  0.5048 0.613678   
## lwt         -0.0193796  0.0074129 -2.6143 0.008941 **
## ht1:lwt      0.0037324  0.0161735  0.2308 0.817490   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 221.113  on 185  degrees of freedom
## AIC: 229.113
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  crude OR(95%CI)    adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0       3.37 (1.02,11.09)  3.62 (0.02,535.73)      0.614          0.605     
##                                                                                      
## lwt (cont. var.) 0.99 (0.97,1)      0.98 (0.97,1)           0.009          1         
##                                                                                      
## ht1:lwt          -                  1.0037 (0.9724,1.0361)  0.817          0.819     
##                                                                                      
## Log-likelihood = -110.5567
## No. of observations = 189
## AIC value = 229.1133</code></pre>
<p>由於交互作用項結果爲 <code>ht1:lwt      0.003732   0.016173   0.231  0.81749</code>，無足夠的證據證明孕前體重會對妊娠高血壓和嬰兒出生體重過低之間的關係造成交互作用。</p>
<p>如果確認沒有交互作用，建立本例最終模型前的幾個建議：</p>
<ol style="list-style-type: decimal">
<li>最終分析 <span class="math inline">\(X_1, Y\)</span> 之間關係的模型，需要加入我們逐一甄別之後確認過的混淆因子，此時稱爲<strong>模型 1</strong>；</li>
<li>對於確認不是 <span class="math inline">\(X_1, Y\)</span> 之間關係的混淆因子的那些剩餘變量，逐一加入<strong>模型 1</strong>，比較前後是否模型中各個混淆因子的參數估計是否發生了變化 (有沒有混淆因子的混淆因子？)；</li>
<li>最終模型中的變量，需要包含前兩步確認過的全部混淆因子；</li>
<li>在報告中把調整前後的參數估計整理成表格。</li>
</ol>
<p>如果在分析過程中發現了有重要意義的交互作用，那麼除了包含全部的混淆因子之外，你的最終模型中還需加入重要的交互作用項。此時需要報告的參數估計是有交互作用項部分的分層比值比/其他指標。</p>
</div>
<div id="補充" class="section level3">
<h3><span class="header-section-number">51.3.2</span> 補充</h3>
<p>除了使用二項分佈的邏輯迴歸之外，當結果變量是連續型或者計數型，也就是分析模型使用線性迴歸 (ANCOVA)，或者 (可能過度離散的) 泊松迴歸時，爲了提高模型的統計效能，減小參數估計的標準誤，模型可以選擇進一步調整一個或幾個<strong>只和結果變量有關的基線變量</strong>。此時，在你寫論文或者報告時，<strong>必須把這些變量和確認是混雜因子的變量加以區分</strong>，因爲加它們進入模型的目的不同。</p>
</div>
</div>
<div id="分析目的-2-和-3-建立預測模型-predictive-models" class="section level2">
<h2><span class="header-section-number">51.4</span> 分析目的 2 和 3 – 建立預測模型 (predictive models)</h2>
<p>建立預測模型的過程，其實就是選擇哪個或者那些變量進入模型的過程。方法有很多，可惜的是，沒有哪種是公認完美的。這裏只介紹兩種最常見，也最常被批評的方法 – 前/後 逐步選擇法 (forward stepwise selection/backward elimination)。強調一下，逐步法本身並不是神奇法術，不同的算法選擇的變量自然會有不同，如果你用了逐步選擇法，選出來的模型變量僅僅只能作爲參考，而不能作爲最終結論。</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb611-1" title="1">vitc &lt;-<span class="st"> </span>haven<span class="op">::</span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/vitC.dta&quot;</span>)</a>
<a class="sourceLine" id="cb611-2" title="2">vitc<span class="op">$</span>ctakers &lt;-<span class="st"> </span><span class="kw">factor</span>(vitc<span class="op">$</span>ctakers)</a>
<a class="sourceLine" id="cb611-3" title="3">vitc<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">factor</span>(vitc<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb611-4" title="4"></a>
<a class="sourceLine" id="cb611-5" title="5">stats<span class="op">::</span><span class="kw">step</span>(<span class="kw">lm</span>(seruvitc<span class="op">~</span><span class="dv">1</span>,<span class="dt">data=</span>vitc[<span class="kw">complete.cases</span>(vitc),]),<span class="dt">direction=</span><span class="st">&quot;forward&quot;</span>,<span class="dt">scope=</span><span class="op">~</span>age<span class="op">+</span>height<span class="op">+</span>weight<span class="op">+</span>sex<span class="op">+</span>cigs<span class="op">+</span>ctakers)</a></code></pre></div>
<pre><code>## Start:  AIC=575.43
## seruvitc ~ 1
## 
##           Df Sum of Sq     RSS     AIC
## + ctakers  1   6967.43 42659.6 563.663
## + sex      1   3688.53 45938.5 570.402
## + cigs     1   2470.90 47156.1 572.783
## + height   1   1243.73 48383.3 575.121
## &lt;none&gt;                 49627.0 575.430
## + age      1    273.59 49353.4 576.927
## + weight   1      1.53 49625.5 577.427
## 
## Step:  AIC=563.66
## seruvitc ~ ctakers
## 
##          Df Sum of Sq     RSS     AIC
## + sex     1  2713.526 39946.0 559.683
## + cigs    1  2150.581 40509.0 560.956
## + height  1  1049.000 41610.6 563.398
## &lt;none&gt;                42659.6 563.663
## + age     1   247.944 42411.6 565.133
## + weight  1    18.227 42641.3 565.625
## 
## Step:  AIC=559.68
## seruvitc ~ ctakers + sex
## 
##          Df Sum of Sq     RSS     AIC
## + cigs    1  1527.704 38418.3 558.134
## &lt;none&gt;                39946.0 559.683
## + weight  1   445.296 39500.7 560.663
## + age     1   183.277 39762.8 561.264
## + height  1   131.722 39814.3 561.382
## 
## Step:  AIC=558.13
## seruvitc ~ ctakers + sex + cigs
## 
##          Df Sum of Sq     RSS     AIC
## &lt;none&gt;                38418.3 558.134
## + weight  1  257.1523 38161.2 559.523
## + age     1  205.2889 38213.0 559.647
## + height  1   58.2745 38360.1 559.996</code></pre>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ ctakers + sex + cigs, data = vitc[complete.cases(vitc), 
##     ])
## 
## Coefficients:
## (Intercept)     ctakers1         sex1         cigs  
##     46.0283      19.8317       9.7642     -12.2550</code></pre>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb614-1" title="1">stats<span class="op">::</span><span class="kw">step</span>(<span class="kw">lm</span>(seruvitc<span class="op">~</span>.,<span class="dt">data=</span>vitc[<span class="kw">complete.cases</span>(vitc),]),<span class="dt">direction=</span><span class="st">&quot;backward&quot;</span>)</a></code></pre></div>
<pre><code>## Start:  AIC=563.38
## seruvitc ~ serial + age + height + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - height   1      1.48 37272.5 561.379
## - age      1     64.18 37335.2 561.532
## - weight   1    174.65 37445.7 561.801
## - serial   1    808.36 38079.4 563.328
## &lt;none&gt;                 37271.1 563.375
## - cigs     1    979.26 38250.3 563.735
## - sex      1   1123.50 38394.6 564.078
## - ctakers  1   6407.24 43678.3 575.811
## 
## Step:  AIC=561.38
## seruvitc ~ serial + age + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - age      1     65.27 37337.8 559.538
## - weight   1    217.51 37490.0 559.908
## - serial   1    807.51 38080.1 561.329
## &lt;none&gt;                 37272.5 561.379
## - cigs     1    977.97 38250.5 561.736
## - sex      1   2584.37 39856.9 565.479
## - ctakers  1   6442.37 43714.9 573.887
## 
## Step:  AIC=559.54
## seruvitc ~ serial + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - weight   1    366.60 37704.4 558.427
## - serial   1    823.37 38161.2 559.523
## &lt;none&gt;                 37337.8 559.538
## - cigs     1    944.21 38282.0 559.811
## - sex      1   2816.28 40154.1 564.155
## - ctakers  1   6462.15 43800.0 572.064
## 
## Step:  AIC=558.43
## seruvitc ~ serial + cigs + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - serial   1    713.92 38418.3 558.134
## &lt;none&gt;                 37704.4 558.427
## - cigs     1   1156.10 38860.5 559.176
## - sex      1   2451.95 40156.4 562.161
## - ctakers  1   6385.14 44089.5 570.664
## 
## Step:  AIC=558.13
## seruvitc ~ cigs + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## &lt;none&gt;                 38418.3 558.134
## - cigs     1   1527.70 39946.0 559.683
## - sex      1   2090.65 40509.0 560.956
## - ctakers  1   5841.01 44259.3 569.014</code></pre>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ cigs + sex + ctakers, data = vitc[complete.cases(vitc), 
##     ])
## 
## Coefficients:
## (Intercept)         cigs         sex1     ctakers1  
##     46.0283     -12.2550       9.7642      19.8317</code></pre>
</div>
</div>
<div id="檢查你的模型-model-checking---glm" class="section level1">
<h1><span class="header-section-number">第 52 章</span> 檢查你的模型 Model Checking - GLM</h1>
<p>每次定義一個 GLM 模型的時候 (Section <a href="#defineaGLM">44.2</a>)，均分三步走，所以一個模型會出錯的部分，就在這三步驟中的任何一步：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈定義錯誤 (或者分佈的假設不成立) mis-specified distribution: 因變量之間<strong>是否相互獨立</strong>，且<strong>服從某個已知的分佈</strong>，這兩個條件中的任意一個不能滿足，第一步都無法成立。例如，最常見的是我們用泊松迴歸模型來擬合計數型數據時，因爲缺乏一些關鍵變量，導致模型遇到過度離散的問題 (over-dispersed for a Poisson distribution due to an omitted covariate)；</li>
<li>線性預測方程定義錯誤 mis-specified linear predictor: 線性預測方程中放入的變量，有的可能需要被轉換 (連續型轉換成分類型，或者是需要數學轉換)。或者是應該加入的交互作用項被我們粗心忽略了；</li>
<li>鏈接方程錯誤 mis-specified link function: 對前一步定義好的線性預測方程，第三步的鏈接方程指定很可能出現錯誤。或者是，我們可以考慮選用別的鏈接方程 (<span class="math inline">\(\text{log instead of logit}\)</span>)，改變了鏈接方程之後，很可能原先認爲有交互作用的變量之間交互作用就消失了 (Section <a href="#interaction-depend-scale">49.4</a>)。</li>
</ol>
<p>本章介紹一些廣義線性迴歸模型診斷的方法，這些手段雖然偶爾有一些檢驗方法，但更多的診斷方法需要繪圖通過視覺判斷。介紹邏輯迴歸時解釋過模型比較時使用的模型偏差 (deviance) 概念 (Section <a href="#deviance">46.3.2</a>) Pearson 的擬合優度檢驗，以及使用 Hosmer-Lemeshow 檢驗法檢驗個人二分類變量數據的邏輯迴歸擬合優度 (Section <a href="#gof">46.4</a>) 法。值得注意的是，這些方法是一種整體檢驗 (global test)，其零假設是 “<strong>模型可以擬合數據</strong>”，如果擬合優度檢驗的結果是拒絕這個零假設，那麼可以認爲模型建立的不佳，即<strong>接受 “模型不能擬合數據” 的替代假設</strong>。如果擬合優度檢驗的結果是無法拒絕零假設，那麼我們僅僅只能認爲<strong>無證據證明 “模型不可以擬合數據”</strong>，而<strong>不能證明設計的模型可以良好的擬合數據</strong>。所以，擬合優度的檢驗結果可以警告我們模型擬合有沒有錯誤，卻不能證明這個模型到底是不是一個良好的模型 (個人感覺應把擬合優度檢驗 goodness of fit 的名稱改爲 <strong>擬合劣度檢驗 badness of fit</strong>)。</p>
<div id="線性預測方程的定義" class="section level2">
<h2><span class="header-section-number">52.1</span> 線性預測方程的定義</h2>
<p>線性預測方程定義錯誤的最常見的就是“忽略了不該忽略的交互作用”，及<strong>連續型變量可能被以不恰當的方式加入預測方程中</strong>。當然，你可以通過把一個變量放入模型前後，該變量本身的迴歸係數是否有意義 (Wald test) 或者你關心的<strong>預測變量的迴歸係數的變化程度</strong> (magnitude of the corresponding parameter estimate) 來判斷是否保留這個變量在你的模型裏。這麼做的時候，你要當心自己陷入多重比較 (multiple testing) 的陷阱 (某次或者某幾次出現的統計學有意義的結果，可以僅僅是由於偶然，而不是因爲它真的有意義)。</p>
<div id="殘差-1" class="section level3">
<h3><span class="header-section-number">52.1.1</span> 殘差</h3>
<p>觀測值跟擬合值之間的差距，就是我們常說的殘差。</p>
<p>以二項分佈數據爲例，</p>
<p><span class="math display">\[Y_i\sim\text{Bin}(n_i, \pi_i), \\
\text{where n is the number of subjects in one group} \\
\text{logit}(\pi_i) = \eta_i\]</span></p>
<p>其第 <span class="math inline">\(i\)</span> 個觀測值的原始殘差 (raw residual)，是</p>
<p><span class="math display">\[
\begin{aligned}
r_i &amp; = y_i - \hat\mu_i \\
    &amp; = y_i - n_i\hat\pi_i
\end{aligned}
\]</span></p>
<p>觀測值 <span class="math inline">\(Y_i\)</span> 的變化程度 (variability) 本身並不是一成不變的 (會根據模型中加入的共變量而改變)，其變化程度可能是觀測值 <span class="math inline">\(Y_i\)</span> 的方差導致的。二項分佈數據的方差已知是 <span class="math inline">\(\text{Var}(Y_i) = n_i\pi_i(1-\pi_i)\)</span>。舉個栗子，如果 <span class="math inline">\(n_i = 10, \hat\pi_i = 0.01, Y_i = 10\)</span>，那麼 <span class="math inline">\(r_i \approx 10\)</span>，這是一個很差的擬合效果。如果，<span class="math inline">\(n_i = 100000, \hat\pi_i = 0.5, Y_i = 5010\)</span>，那麼 <span class="math inline">\(r_i = 10\)</span>，此時的殘差也是 <span class="math inline">\(10\)</span> 又證明了這是一個擬合效果良好的模型。相同的殘差，由於方差不同，判斷則不一樣，所以我們需要有一個類似簡單線性迴歸中標準化殘差 (Section <a href="#standardres">31.6.1</a>) 的過程 – <strong>Pearson 殘差</strong>:</p>
<p><span class="math display">\[
p_i = \frac{r_i}{\sqrt{\hat{\text{Var}}}(Y_i)}
\]</span></p>
<p>所以，二項分佈數據的 Pearson 殘差公式爲</p>
<p><span class="math display">\[
p_i = \frac{r_i}{\sqrt{n_i\hat\pi_i(1-\hat\pi_i)}}
\]</span></p>
<p>Pearson 殘差的平方和，就是 Pearson 卡方統計量，在只有分類變量的邏輯迴歸模型中可以用於擬合度診斷 (Section <a href="#calibration">53.1</a>)，自由度爲 <span class="math inline">\(1\)</span>：</p>
<p><span class="math display">\[
\sum_i^Np^2_i = \text{Pearson&#39;s } \chi^2 \text{ statistic}
\]</span></p>
<p>和標準化 Pearson 殘差相似地，另一個選項是使用<strong>偏差殘差 (deviance residual)</strong>。只要使偏差殘差 <span class="math inline">\(d_i\)</span> 和原始殘差 <span class="math inline">\(r_i\)</span> 保持相同的符號，偏差殘差也可以被標準化用於模型診斷。</p>
<p>用二項分佈數據的例子，</p>
<p><span class="math display">\[
\begin{aligned}
d_i &amp; = \text{sign}(r_i)\sqrt{2\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i-y_i}{n_i - \hat\mu_i})\}} \\
\sum_{i=1}^n d^2 = D &amp; = 2\sum_{i=1}^N\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i - y_i}{n_i - \hat\mu_i}) \}
\end{aligned}
\]</span></p>
</div>
<div id="glm-在-r-裏獲取殘差" class="section level3">
<h3><span class="header-section-number">52.1.2</span> GLM 在 R 裏獲取殘差</h3>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb617-1" title="1">boot<span class="op">::</span><span class="kw">glm.diag</span>(modelname)<span class="op">$</span>rp       <span class="co">## 可以獲取 standardized Pearson residuals</span></a>
<a class="sourceLine" id="cb617-2" title="2"><span class="kw">resid</span>(modelname, <span class="dt">type =</span> <span class="st">&quot;pearson&quot;</span>) <span class="co">## 可以獲取 Pearson residuals</span></a>
<a class="sourceLine" id="cb617-3" title="3"><span class="kw">rstandard</span>(modelname)               <span class="co">## 可以獲取 standardized deviance residuals</span></a>
<a class="sourceLine" id="cb617-4" title="4"><span class="kw">resid</span>(modelname)                   <span class="co">## 可以獲取 deviance residuals</span></a></code></pre></div>
</div>
<div id="如何利用獲得的殘差" class="section level3">
<h3><span class="header-section-number">52.1.3</span> 如何利用獲得的殘差</h3>
<ol style="list-style-type: decimal">
<li>將殘差和觀測值的排序作散點圖–查看是否有觀測值擁有過大的標準化殘差；</li>
<li>作殘差和線性預測方程值的散點圖–如果模型合理的話，這兩者之間視覺上可以判斷是沒有關係的 (no systematic relationship)；</li>
<li>作殘差和模型中任意一個連續型變量 (如果有的話) – 可以判定該連續型變量的放入方式是否合理；</li>
<li>作殘差和數據中尚未加入模型的新變量之間的散點圖 (甚至是已有變量的二次/三次方值)–如果二者之間有明顯的相關性，需要考慮是否加入這個新變量到模型中去。</li>
</ol>
<p>做這些散點圖時，推薦都加上 <code>lowess</code> 的非線性平滑曲線，用於輔助判斷是否變量之間存在特殊關係。</p>
</div>
</div>
<div id="共變量模式殘差-covariate-pattern-residuals" class="section level2">
<h2><span class="header-section-number">52.2</span> 共變量模式殘差 covariate pattern residuals</h2>
</div>
<div id="鏈接方程" class="section level2">
<h2><span class="header-section-number">52.3</span> 鏈接方程</h2>
</div>
<div id="NHANESdrinker" class="section level2">
<h2><span class="header-section-number">52.4</span> NHANES 飲酒量數據實例</h2>
<p>數據的變量和每個變量的解釋如下表，總樣本量是 2548 人，飲酒量大於 5 杯每日者被定義爲重度飲酒者。</p>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>gender</code></td>
<td align="left">1=male, 2=female</td>
</tr>
<tr class="even">
<td align="left"><code>ageyrs</code></td>
<td align="left">Age in years at survey</td>
</tr>
<tr class="odd">
<td align="left"><code>bmi</code></td>
<td align="left">Body mass index <span class="math inline">\((\text{kg/m}^2)\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>sbp</code></td>
<td align="left">Systolic blood pressure <span class="math inline">\((\text{mmHg})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>ALQ130</code></td>
<td align="left">Reported average number of drinks per day</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb618-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb618-2" title="2">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb618-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb618-4" title="4"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb618-5" title="5"><span class="kw">with</span>(NHANES, <span class="kw">table</span>(gender))</a></code></pre></div>
<pre><code>## gender
##    1    2 
## 1391 1157</code></pre>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb620-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">Heavydrinker =</span> ALQ130 <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>)</a>
<a class="sourceLine" id="cb620-2" title="2">Model_NH &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb620-3" title="3"><span class="kw">logistic.display</span>(Model_NH);<span class="kw">summary</span>(Model_NH)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)  0.16 (0.11,0.23)  &lt; 0.001        &lt; 0.001   
##                                                                                  
## ageyrs (cont. var.) 0.97 (0.97,0.98)  0.97 (0.96,0.98)  &lt; 0.001        &lt; 0.001   
##                                                                                  
## Log-likelihood = -801.292
## No. of observations = 2548
## AIC value = 1608.5839</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.86408  -0.57154  -0.34828  -0.22281   2.85177  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  1.6410885  0.2755315   5.9561 2.584e-09 ***
## gender      -1.8249474  0.1736041 -10.5121 &lt; 2.2e-16 ***
## ageyrs      -0.0304506  0.0039882  -7.6351 2.257e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1602.58  on 2545  degrees of freedom
## AIC: 1608.58
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>當用邏輯迴歸模型擬合數據，線性迴歸方程加入年齡和性別時，數據給出了極強的證據證明性別和年齡和是否爲重度飲酒者都有很大的關係。但是，擬合完這樣一個邏輯迴歸模型之後，我們最大的擔心是，模型中的年齡變量和 <span class="math inline">\(\text{logit}(\text{P}(Y=1))\)</span> 之間的關係，用簡單線性是不是恰當？要檢驗這樣的擔憂，最好的方法是追加一個非線性轉換後的年齡值，去看看模型的擬合程度是否得到改善：</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb623-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">age2 =</span> ageyrs<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb623-2" title="2">Model_NH2 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>age2, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb623-3" title="3"><span class="kw">logistic.display</span>(Model_NH2) ; <span class="kw">summary</span>(Model_NH2)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.16 (0.11,0.23)    &lt; 0.001        &lt; 0.001   
##                                                                                          
## ageyrs (cont. var.) 0.9726 (0.9652,0.9801)  1.01 (0.966,1.056)  0.663          0.662     
##                                                                                          
## age2 (cont. var.)   0.9997 (0.9996,0.9998)  0.9996 (0.9991,1)   0.073          0.067     
##                                                                                          
## Log-likelihood = -799.6124
## No. of observations = 2548
## AIC value = 1607.2249</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + age2, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.80207  -0.60342  -0.32980  -0.23312   2.87272  
## 
## Coefficients:
##                Estimate  Std. Error  z value Pr(&gt;|z|)    
## (Intercept)  0.83418082  0.52440600   1.5907  0.11167    
## gender      -1.82748612  0.17346142 -10.5354  &lt; 2e-16 ***
## ageyrs       0.00991164  0.02272523   0.4362  0.66273    
## age2        -0.00043512  0.00024311  -1.7898  0.07348 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1599.22  on 2544  degrees of freedom
## AIC: 1607.22
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>擬合了年齡的平方 (<code>age2</code>) 進入邏輯迴歸模型中之後，<code>age2</code> 的迴歸係數的 Wald 檢驗結果是 <span class="math inline">\(p = 0.073\)</span>，這證明用簡單的線性關係把年齡放在模型裏<strong>並不算不妥當 (not unreasonable)</strong>。</p>
<p>另外，可以提取 <code>Model_NH</code> 的標準化 Pearson 殘差和年齡作如下的散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:stPearsonAge"></span>
<img src="bookdown_files/figure-html/stPearsonAge-1.png" alt="Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates" width="80%" />
<p class="caption">
圖 52.1: Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates
</p>
</div>
<p>圖 <a href="#fig:stPearsonAge">52.1</a> 中靠近橫軸的藍色實線是 LOWESS 平滑曲線，它十分接近平直的橫線，也證明了 Pearson 標準化殘差值和年齡本身並無關聯。這同時也佐證了，將年齡以連續型共變量的形式放入本次邏輯迴歸模型中<strong>並非不合理 (not unreasonable)</strong>。</p>
<p>下一步，我們再來考慮，模型中加入 <code>bmi</code> 是否合理 (能改善模型的擬合度)：</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb626-1" title="1">Model_NH3 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>bmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb626-2" title="2"><span class="kw">logistic.display</span>(Model_NH3) ; <span class="kw">summary</span>(Model_NH3)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.16 (0.11,0.23)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## ageyrs (cont. var.) 0.97 (0.97,0.98)        0.97 (0.96,0.98)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## bmi (cont. var.)    0.9965 (0.9756,1.0179)  1.0084 (0.9855,1.0318)  0.477          0.479     
##                                                                                              
## Log-likelihood = -801.0412
## No. of observations = 2548
## AIC value = 1610.0825</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + bmi, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.93712  -0.57479  -0.34466  -0.22359   2.82847  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  1.4251178  0.4096026   3.4793 0.0005028 ***
## gender      -1.8299784  0.1738183 -10.5281 &lt; 2.2e-16 ***
## ageyrs      -0.0306880  0.0040105  -7.6518 1.982e-14 ***
## bmi          0.0083460  0.0117336   0.7113 0.4769053    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1602.08  on 2544  degrees of freedom
## AIC: 1610.08
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>BMI的迴歸係數是否爲零的 Wald 檢驗 <span class="math inline">\(p=0.477\)</span>，提示數據無法提供證據去反對零假設：“調整了年齡和性別之後，BMI 和是否是重度飲酒者的概率的對數比值 <span class="math inline">\(\text{log-odds}\)</span> 之間無線性關係”，也就是二者之間可能有非線性關係。如果把 Pearson 標準化殘差和 BMI 作殘差散點圖，如下所示：</p>
<div class="figure" style="text-align: center"><span id="fig:stPearsonBMI"></span>
<img src="bookdown_files/figure-html/stPearsonBMI-1.png" alt="Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates" width="80%" />
<p class="caption">
圖 52.2: Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates
</p>
</div>
<p>此殘差圖 <a href="#fig:stPearsonBMI">52.2</a> 的 LOWESS 平滑曲線卻提示我們，BMI 和殘差之間不完全是毫無關係的 (應該是非線性的，拋物線關係？)。如果我們把 BMI 取平方放入模型中再看其結果：</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb629-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">bmi2 =</span> bmi<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb629-2" title="2">Model_NH4 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>bmi2, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb629-3" title="3"><span class="kw">summary</span>(Model_NH4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + bmi + bmi2, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.93349  -0.57566  -0.34335  -0.21636   2.85524  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept) -2.1277529  1.4806329  -1.4371   0.15070    
## gender      -1.7784430  0.1745978 -10.1859 &lt; 2.2e-16 ***
## ageyrs      -0.0323786  0.0040936  -7.9096 2.583e-15 ***
## bmi          0.2551992  0.1003287   2.5436   0.01097 *  
## bmi2        -0.0041230  0.0016854  -2.4464   0.01443 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1594.91  on 2543  degrees of freedom
## AIC: 1604.91
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb631-1" title="1"><span class="kw">logistic.display</span>(Model_NH4)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.17 (0.12,0.24)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## ageyrs (cont. var.) 0.97 (0.97,0.98)        0.97 (0.96,0.98)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## bmi (cont. var.)    1 (0.98,1.02)           1.29 (1.06,1.57)        0.011          0.006     
##                                                                                              
## bmi2 (cont. var.)   0.9999 (0.9995,1.0002)  0.9959 (0.9926,0.9992)  0.014          0.007     
##                                                                                              
## Log-likelihood = -797.4554
## No. of observations = 2548
## AIC value = 1604.9108</code></pre>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb633-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH, Model_NH4)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: Heavydrinker ~ gender + ageyrs
## Model 2: Heavydrinker ~ gender + ageyrs + bmi + bmi2
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)  
## 1   3 -801.292                        
## 2   5 -797.455  2 7.67309   0.021568 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>通過似然比檢驗比較加了 <code>bmi, bmi2</code> 兩個共變量的模型和只有 <code>gender, ageyrs</code> 兩個共變量的模型 <span class="math inline">\((p=0.022)\)</span>，提示我們 BMI 和是否是重度飲酒者 (概率的對數比值 <span class="math inline">\(\text{log-odds}\)</span>) 之間的關係並非簡單的線性關係。不過這樣的關係似乎並不是特別的明顯，圖 <a href="#fig:stPearsonBMI">52.2</a> 的平滑曲線的彎曲程度也沒有特別明顯。所以，在這樣的情況下，有的統計學家可能還是會選擇不放 BMI 進入模型裏。</p>
</div>
<div id="practical-10" class="section level2">
<h2><span class="header-section-number">52.5</span> Practical 10</h2>
<p>繼續沿用 NHANES 數據，此次練習我們把重點放在收集到的收縮期血壓數據上。定義收縮期血壓大於 140 <span class="math inline">\(\text{mmHg}\)</span> 者爲高血壓患者。</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb635-1" title="1"><span class="co"># 1. load the data and define a binary variable indicating whether</span></a>
<a class="sourceLine" id="cb635-2" title="2"><span class="co">#    each observation has hypertension (1) or not (0)</span></a>
<a class="sourceLine" id="cb635-3" title="3">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb635-4" title="4">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb635-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb635-6" title="6"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb635-7" title="7">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">hypertension =</span> sbp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">140</span>)</a>
<a class="sourceLine" id="cb635-8" title="8"><span class="kw">tab1</span>(NHANES<span class="op">$</span>hypertension, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## NHANES$hypertension : 
##         Frequency Percent Cum. percent
## FALSE        2116      83           83
## TRUE          432      17          100
##   Total      2548     100          100</code></pre>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb637-1" title="1"><span class="co"># 2. Bearing in mind that we know blood pressure increases with age</span></a>
<a class="sourceLine" id="cb637-2" title="2"><span class="co">#    we begin by including age into a logistic regression for the</span></a>
<a class="sourceLine" id="cb637-3" title="3"><span class="co">#    the binary hypertension variable. We can use a lowess smoother</span></a>
<a class="sourceLine" id="cb637-4" title="4"><span class="co">#    plot to examine how the probability of hypertension varies with</span></a>
<a class="sourceLine" id="cb637-5" title="5"><span class="co">#    age.</span></a>
<a class="sourceLine" id="cb637-6" title="6">pi &lt;-<span class="st"> </span><span class="kw">with</span>(NHANES, <span class="kw">predict</span>(<span class="kw">loess</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs)))</a>
<a class="sourceLine" id="cb637-7" title="7"></a>
<a class="sourceLine" id="cb637-8" title="8"><span class="kw">with</span>(NHANES, <span class="kw">scatter.smooth</span>(ageyrs, <span class="kw">logit</span>(pi), <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">span =</span> <span class="fl">0.6</span>, <span class="dt">lpars =</span></a>
<a class="sourceLine" id="cb637-9" title="9">                 <span class="kw">list</span>(<span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>), <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.004</span>),</a>
<a class="sourceLine" id="cb637-10" title="10">                 <span class="dt">xlab =</span> <span class="st">&quot;Age in years&quot;</span>,</a>
<a class="sourceLine" id="cb637-11" title="11">                 <span class="dt">ylab =</span> <span class="st">&quot;Logit(probability) of Hypertension&quot;</span>,</a>
<a class="sourceLine" id="cb637-12" title="12">                 <span class="dt">frame =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loesslogit"></span>
<img src="bookdown_files/figure-html/loesslogit-1.png" alt="The loess plot of the observed proportin with hypertension against age. Span = 0.6" width="100%" />
<p class="caption">
圖 52.3: The loess plot of the observed proportin with hypertension against age. Span = 0.6
</p>
</div>
<p>Lowess 平滑曲線圖提示，高血壓患病的可能性的 <span class="math inline">\(\text{logit}\)</span>，和年齡之間的關係似乎不是簡單直線關係。我們可能需要把<strong>年齡本身</strong>和<strong>年齡的平方</strong>放入邏輯迴歸模型中去看看。</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb638-1" title="1"><span class="co"># 3. Include age into the logistic regression in the way suggested by the lowess plot.</span></a>
<a class="sourceLine" id="cb638-2" title="2"><span class="co">#    do your results support your findings from the previous graph?</span></a>
<a class="sourceLine" id="cb638-3" title="3">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">agesq =</span> ageyrs<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb638-4" title="4">Model_NH5 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb638-5" title="5"><span class="kw">logistic.display</span>(Model_NH5) ; <span class="kw">summary</span>(Model_NH5)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.) 1.07 (1.06,1.07)        1.15 (1.1,1.21)         &lt; 0.001        &lt; 0.001   
##                                                                                              
## agesq (cont. var.)  1.0005 (1.0005,1.0006)  0.9993 (0.9989,0.9997)  0.001          &lt; 0.001   
##                                                                                              
## Log-likelihood = -943.7811
## No. of observations = 2548
## AIC value = 1893.5622</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.20772  -0.61574  -0.33152  -0.18319   2.97415  
## 
## Coefficients:
##                Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -6.92931228  0.67205641 -10.311 &lt; 2.2e-16 ***
## ageyrs       0.13933661  0.02419897   5.758 8.514e-09 ***
## agesq       -0.00067035  0.00020870  -3.212  0.001318 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1887.56  on 2545  degrees of freedom
## AIC: 1893.56
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>正如同 Lowess 平滑曲線建議的那樣，數據提供了極強的證據證明年齡和患有高血壓概率的對數比值 <span class="math inline">\((\text{log-odds})\)</span> 之間呈現的是拋物線關係。</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb641-1" title="1"><span class="co"># 4. Generate Pearson residuals and investigate whether the way in</span></a>
<a class="sourceLine" id="cb641-2" title="2"><span class="co">#    which you have included age in the logistic regression in the</span></a>
<a class="sourceLine" id="cb641-3" title="3"><span class="co">#    previous part is correct.</span></a>
<a class="sourceLine" id="cb641-4" title="4"></a>
<a class="sourceLine" id="cb641-5" title="5"><span class="co"># obtain the standardized Pearson residuals by covariate pattern</span></a>
<a class="sourceLine" id="cb641-6" title="6">Diag &lt;-<span class="st"> </span>LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_NH5)</a>
<a class="sourceLine" id="cb641-7" title="7"><span class="kw">ggplot</span>(Diag, <span class="kw">aes</span>(<span class="dt">x =</span> ageyrs, <span class="dt">y =</span> sPr)) <span class="op">+</span><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb641-8" title="8"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">span =</span> <span class="fl">0.9</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st">  </span><span class="kw">theme_bw</span>()  <span class="op">+</span></a>
<a class="sourceLine" id="cb641-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb641-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb641-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb641-12" title="12"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age in years&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;standardised Pearson residual&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb641-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb641-14" title="14">        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb641-15" title="15">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb641-16" title="16">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt2"></span>
<img src="bookdown_files/figure-html/NHANEhyt2-1.png" alt="Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates." width="100%" />
<p class="caption">
圖 52.4: Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates.
</p>
</div>
<p>標準化 Pearson 殘差 (共變量模式) 和年齡之間的散點圖 <a href="#fig:NHANEhyt2">52.4</a> 提示此時的殘差和年齡之間再無明顯的關係。也就是說，年齡作爲連續變量和高血壓患病概率的對數比值之間的關係，用拋物線 (二次方程) 擬合<strong>並非不合理 (not unreasonable)</strong>。</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb642-1" title="1"><span class="co"># 5. Next, use individual level residuals to examine whether BMI ought to be</span></a>
<a class="sourceLine" id="cb642-2" title="2"><span class="co">#    included in the model, and depending on what you find, continue with you</span></a>
<a class="sourceLine" id="cb642-3" title="3"><span class="co">#    previous model or add BMI. In the latter case, generate new residuals and</span></a>
<a class="sourceLine" id="cb642-4" title="4"><span class="co">#    assess if you have included BMI using the most appropriate functional form.</span></a>
<a class="sourceLine" id="cb642-5" title="5">NHANES<span class="op">$</span>stresPearson &lt;-<span class="st"> </span>boot<span class="op">::</span><span class="kw">glm.diag</span>(Model_NH5)<span class="op">$</span>rp</a>
<a class="sourceLine" id="cb642-6" title="6"><span class="kw">ggplot</span>(NHANES, <span class="kw">aes</span>(<span class="dt">x =</span> bmi, <span class="dt">y =</span> stresPearson)) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb642-8" title="8"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb642-9" title="9"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-10" title="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb642-11" title="11">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb642-12" title="12">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-13" title="13"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Body Mass Index&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Standardized Pearson residual&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb642-14" title="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb642-15" title="15">        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb642-16" title="16">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb642-17" title="17">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt3"></span>
<img src="bookdown_files/figure-html/NHANEhyt3-1.png" alt="Standardized Pearson residuals vs. BMI. Logistic mdoel with **just** linear and quadratic age as covariates." width="100%" />
<p class="caption">
圖 52.5: Standardized Pearson residuals vs. BMI. Logistic mdoel with <strong>just</strong> linear and quadratic age as covariates.
</p>
</div>
<p>圖 <a href="#fig:NHANEhyt3">52.5</a>，提示，標準化 Pearson 殘差和連續型 BMI 值之間應該存在相關性，也就是該圖提示需要加入連續型變量 BMI 進入邏輯迴歸模型中去！</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb643-1" title="1">Model_NH6 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb643-2" title="2"><span class="kw">logistic.display</span>(Model_NH6) ; <span class="kw">summary</span>(Model_NH6)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.) 1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                             
## agesq (cont. var.)  1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.005          0.004     
##                                                                                             
## bmi (cont. var.)    1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.007          0.007     
##                                                                                             
## Log-likelihood = -940.1583
## No. of observations = 2548
## AIC value = 1888.3166</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq + bmi, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.32095  -0.61276  -0.33033  -0.18260   2.85207  
## 
## Coefficients:
##                Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept) -7.54111034  0.71010300 -10.6197 &lt; 2.2e-16 ***
## ageyrs       0.13107997  0.02430813   5.3924 6.951e-08 ***
## agesq       -0.00059168  0.00021030  -2.8135  0.004900 ** 
## bmi          0.02840320  0.01046359   2.7145  0.006638 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1880.32  on 2544  degrees of freedom
## AIC: 1888.32
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>加入連續型變量 BMI 進入模型後，<code>bmi</code> 項的 Wald 檢驗結果果然證實了 之前殘差圖提示的 BMI 和高血壓患病概率之間存在相關性。再對 <code>Model_NH6</code> 的殘差和 <code>bmi</code> 作殘差散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt5"></span>
<img src="bookdown_files/figure-html/NHANEhyt5-1.png" alt="Standardized Pearson residuals vs. BMI. Logistic mdoel with **linear and quadratic age and BMI** as covariates." width="100%" />
<p class="caption">
圖 52.6: Standardized Pearson residuals vs. BMI. Logistic mdoel with <strong>linear and quadratic age and BMI</strong> as covariates.
</p>
</div>
<p>現在的殘差散點圖提示殘差和 <code>bmi</code> 之間不再有關係，所以之前把 <code>bmi</code> 加入邏輯迴歸模型是個<strong>並非不合理 (not unreasonable)</strong>的選擇。</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb646-1" title="1"><span class="co"># 6. So far we have ingored gender. Explore whether gender should be included</span></a>
<a class="sourceLine" id="cb646-2" title="2"><span class="co">#    in the model. including whether or not the other covariates included</span></a>
<a class="sourceLine" id="cb646-3" title="3"><span class="co">#    already interact with gender with their effects on hypertension.</span></a>
<a class="sourceLine" id="cb646-4" title="4">Model_NH7 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>Gender,</a>
<a class="sourceLine" id="cb646-5" title="5">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb646-6" title="6"><span class="kw">logistic.display</span>(Model_NH7) ; <span class="kw">summary</span>(Model_NH7)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.005          0.004     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.009          0.009     
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          1.24 (0.98,1.56)       0.07           0.07      
##                                                                                                
## Log-likelihood = -938.5164
## No. of observations = 2548
## AIC value = 1887.0328</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq + bmi + Gender, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.37006  -0.61503  -0.33044  -0.18099   2.89593  
## 
## Coefficients:
##                 Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -7.64411420  0.71405324 -10.7052 &lt; 2.2e-16 ***
## ageyrs        0.13206361  0.02435967   5.4214 5.913e-08 ***
## agesq        -0.00059709  0.00021066  -2.8344  0.004592 ** 
## bmi           0.02730943  0.01043204   2.6178  0.008849 ** 
## GenderFemale  0.21213190  0.11703954   1.8125  0.069912 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1877.03  on 2543  degrees of freedom
## AIC: 1887.03
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb649-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH6, Model_NH7)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi
## Model 2: hypertension ~ ageyrs + agesq + bmi + Gender
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)  
## 1   4 -940.158                        
## 2   5 -938.516  1 3.28378   0.069967 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb651-1" title="1"><span class="co"># some evidence of an effect of gender.</span></a>
<a class="sourceLine" id="cb651-2" title="2"><span class="co"># the Wald test and the likelihood ratio test are both borderline</span></a>
<a class="sourceLine" id="cb651-3" title="3"><span class="co"># statistically significant.</span></a>
<a class="sourceLine" id="cb651-4" title="4">Model_NH8 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi<span class="op">*</span>Gender,</a>
<a class="sourceLine" id="cb651-5" title="5">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb651-6" title="6"><span class="kw">logistic.display</span>(Model_NH8)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.006          0.005     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.05 (1.01,1.08)       0.005          1         
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          3.01 (0.9,10)          0.072          0.072     
##                                                                                                
## bmi:GenderFemale       -                       0.97 (0.93,1.01)       0.139          0.139     
##                                                                                                
## Log-likelihood = -937.423
## No. of observations = 2548
## AIC value = 1886.846</code></pre>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb653-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH7, Model_NH8)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender
## Model 2: hypertension ~ ageyrs + agesq + bmi * Gender
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)
## 1   5 -938.516                      
## 2   6 -937.423  1 2.18675     0.1392</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb655-1" title="1"><span class="co"># no strong evidence of an interaction between BMI and gender</span></a>
<a class="sourceLine" id="cb655-2" title="2"><span class="co"># from both wald test and likelihood ratio test.</span></a>
<a class="sourceLine" id="cb655-3" title="3">Model_NH9 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs<span class="op">*</span>Gender <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi,</a>
<a class="sourceLine" id="cb655-4" title="4">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb655-5" title="5"><span class="kw">logistic.display</span>(Model_NH9)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.13 (1.08,1.19)       &lt; 0.001        1         
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          0.34 (0.14,0.84)       0.02           0.018     
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.004          0.003     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.008          0.009     
##                                                                                                
## ageyrs:GenderFemale    -                       1.02 (1.01,1.04)       0.004          0.004     
##                                                                                                
## Log-likelihood = -934.2658
## No. of observations = 2548
## AIC value = 1880.5315</code></pre>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb657-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH7, Model_NH9)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender
## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)   
## 1   5 -938.516                         
## 2   6 -934.266  1 8.50127   0.003549 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb659-1" title="1"><span class="co"># strong evidence of an interaction between gender and age</span></a>
<a class="sourceLine" id="cb659-2" title="2">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH6, Model_NH9)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi
## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)   
## 1   4 -940.158                         
## 2   6 -934.266  2 11.7851    0.00276 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb661-1" title="1"><span class="co"># joint test of gender and its interaction with age is also significant</span></a></code></pre></div>
<p>增加性別項進入邏輯迴歸模型以後，數據提供了臨界有意義證據 <span class="math inline">\((p = 0.070)\)</span> 證明了調整了年齡和 BMI 以後，高血壓的患病概率依然和性別有關係。增加了 BMI 和性別的交互作用項之後發現，無證據證明性別和 BMI 之間存在有意義的交互作用 <span class="math inline">\((p=0.139)\)</span>。但是，增加了年齡和性別的交互作用項以後，發現了有很強的證據證明性別和年齡之間存在交互作用 <span class="math inline">\((p=0.004)\)</span>。增加性別以及性別和年齡的交互作用項，顯著提升了模型對數據的擬合度 <span class="math inline">\((p = 0.0028)\)</span>。此處，我們可以下結論認爲，雖然加入年齡本身，對模型擬合程度提升有有限的幫助，但是當模型考慮了年齡和性別的交互作用之後，擬合數據的程度得到極爲顯著的改善。</p>
<p>當然，想要繼續下去也是可以的，例如 <code>Model_NH9</code> 的前提下，再加入年齡平方與性別的交互作用項，會發現其 Wald 檢驗結果提示年齡平方，和性別的交互作用是沒有意義的 <span class="math inline">\((p=0.58)\)</span>。</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb662-1" title="1"><span class="co"># 7. Based on your final model, calculate fitted probabilities for an individual</span></a>
<a class="sourceLine" id="cb662-2" title="2"><span class="co">#    aged 60 years, at BMI values from 20 to 40 in increments of 5, separately</span></a>
<a class="sourceLine" id="cb662-3" title="3"><span class="co">#    for men and women, and plot the resulting values.</span></a>
<a class="sourceLine" id="cb662-4" title="4"></a>
<a class="sourceLine" id="cb662-5" title="5">a &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">bmi =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">5</span>), <span class="dt">ageyrs =</span> <span class="kw">rep</span>(<span class="dv">60</span>, <span class="dv">5</span>), <span class="dt">agesq =</span> <span class="kw">rep</span>(<span class="dv">3600</span>, <span class="dv">5</span>), <span class="dt">Gender =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="st">&quot;Male&quot;</span>, <span class="dv">5</span>)))</a>
<a class="sourceLine" id="cb662-6" title="6">b &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">bmi =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">5</span>), <span class="dt">ageyrs =</span> <span class="kw">rep</span>(<span class="dv">60</span>, <span class="dv">5</span>), <span class="dt">agesq =</span> <span class="kw">rep</span>(<span class="dv">3600</span>, <span class="dv">5</span>), <span class="dt">Gender =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="st">&quot;Female&quot;</span>, <span class="dv">5</span>)))</a>
<a class="sourceLine" id="cb662-7" title="7"></a>
<a class="sourceLine" id="cb662-8" title="8">Predict_men &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, a, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>fit</a>
<a class="sourceLine" id="cb662-9" title="9">Predict_men_se &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, a, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>se.fit</a>
<a class="sourceLine" id="cb662-10" title="10">Point_pred_men &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men))</a>
<a class="sourceLine" id="cb662-11" title="11">PredictCI_men_L &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men<span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se))</a>
<a class="sourceLine" id="cb662-12" title="12">PredictCI_men_U &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men<span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se))</a>
<a class="sourceLine" id="cb662-13" title="13"><span class="kw">cbind</span>(Point_pred_men, PredictCI_men_L, PredictCI_men_U)</a></code></pre></div>
<pre><code>##   Point_pred_men PredictCI_men_L PredictCI_men_U
## 1     0.20999989      0.16990237      0.25663492
## 2     0.23409879      0.19980473      0.27227618
## 3     0.26005285      0.22575914      0.29755387
## 4     0.28780311      0.24411252      0.33583907
## 5     0.31724500      0.25701542      0.38428866</code></pre>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb664-1" title="1">Predict_women &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, b, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>fit</a>
<a class="sourceLine" id="cb664-2" title="2">Predict_women_se &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, b, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>se.fit</a>
<a class="sourceLine" id="cb664-3" title="3">Point_pred_women &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women))</a>
<a class="sourceLine" id="cb664-4" title="4">PredictCI_women_L &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women<span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se))</a>
<a class="sourceLine" id="cb664-5" title="5">PredictCI_women_U &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women<span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se))</a>
<a class="sourceLine" id="cb664-6" title="6"><span class="kw">cbind</span>(Point_pred_women, PredictCI_women_L, PredictCI_women_U)</a></code></pre></div>
<pre><code>##   Point_pred_women PredictCI_women_L PredictCI_women_U
## 1       0.24913421        0.20076523        0.30471354
## 2       0.27615418        0.23478059        0.32175308
## 3       0.30491460        0.26477267        0.34825967
## 4       0.33528289        0.28659479        0.38774675
## 5       0.36707847        0.30191960        0.43748678</code></pre>
</div>
</div>
<div id="評價模型的表現-assessing-model-performance" class="section level1">
<h1><span class="header-section-number">第 53 章</span> 評價模型的表現 Assessing model performance</h1>
<p>在廣義線性迴歸的模型表現中，還有幾個重要的概念，<strong>精準度 (calibration)，變異度 (variation)，和分辨能力 (descrimination)</strong>，本章繼續用二分類結果變量和多個共變量的廣義線性迴歸模型來理解這幾個概念。本章使用邏輯迴歸，也就是 <span class="math inline">\(\text{logit}\)</span> 鏈接方程的 GLM 來解釋，但是實際上使用其他鏈接方程時，這些概念也是一樣通用的。</p>
<p>當用邏輯迴歸模型擬合了觀測數據。我們可以通過擬合的模型來計算每個觀測對象的預測“成功”概率 (the predicted probability of “success” for each subject)。當使用 <span class="math inline">\(\text{logit}\)</span> 作鏈接方程時，每個人的預測概率 (predicted probability) 爲：</p>
<p><span class="math display">\[
\hat\pi_i = \frac{\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}{1+\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}
\]</span></p>
<div id="calibration" class="section level2">
<h2><span class="header-section-number">53.1</span> 精準度 calibration</h2>
<p>模型具有良好的精準度時，其計算獲得的每個觀測對象的預測概率，和每個觀測對象本身“成功”的<strong>概率期望值</strong>保持一致。</p>
<p><span class="math display">\[
E(Y|\hat\pi = p) = p
\]</span></p>
<p>當一個 GLM 具有良好精準度時，我們可以利用它在臨牀醫學中發揮重要的作用 (如預測患者死亡，發病或療效等)。如果模型的精準度不佳，那可能導致的嚴重後果有：治療不必要治療的“健康人”，或者漏掉應該治療的“患者”。當一個模型的預測變量只包含了分類型變量，比較觀測概率和預測概率的過程較爲簡單，比較各個分類變量的排列組合後，不同共變量類型 (covariate pattern) 的患者的觀測值和預測值即可。</p>
<p>這裏再沿用之前 NHANES 的重度飲酒相關的數據 (Section <a href="#NHANESdrinker">52.4</a>)來繼續下面對精準度的說明，先擬合一個只有性別作爲預測變量的邏輯迴歸模型：</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb666-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb666-2" title="2">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb666-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb666-4" title="4"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb666-5" title="5"><span class="kw">with</span>(NHANES, <span class="kw">table</span>(Gender))</a></code></pre></div>
<pre><code>## Gender
##   Male Female 
##   1391   1157</code></pre>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb668-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">Heavydrinker =</span> ALQ130 <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>)</a>
<a class="sourceLine" id="cb668-2" title="2">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb668-3" title="3"><span class="kw">logistic.display</span>(Model_perf)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                        OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## Gender: Female vs Male 0.17 (0.12,0.24)  &lt; 0.001        &lt; 0.001   
##                                                                   
## Log-likelihood = -834.1079
## No. of observations = 2548
## AIC value = 1672.2158</code></pre>
<p>完成這個模型之後，在 STATA 裏可以用簡便的 <code>estat gof, table</code> 命令獲取模型擬合的觀測值和期待值表格，然而 R 裏面需要用到 <a href="https://cran.r-project.org/web/packages/LogisticDx/index.html"><code>LogisticDx</code></a> 包裏的診斷命令 <code>dx</code> 獲取 <del>(我花了好幾個小時才找到這個命令，不得不說 STATA 對於流行病的傳統計算真的是比較方便)</del>：</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb670-1" title="1">LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)[, <span class="dv">2</span><span class="op">:</span><span class="dv">6</span>]</a></code></pre></div>
<pre><code>##    GenderFemale   y           P    n yhat
## 1:            0 249 0.179007908 1391  249
## 2:            1  42 0.036300778 1157   42</code></pre>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb672-1" title="1"><span class="co"># obtain Pearson&#39;s test statistics</span></a>
<a class="sourceLine" id="cb672-2" title="2">chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)<span class="op">$</span>sPr)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb672-3" title="3">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb672-4" title="4">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Pearson chi2(1)&quot;</span>,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a></code></pre></div>
<pre><code>##              test        chi.sq pvalue
## 1 Pearson chi2(1) 7.5334682e-25      1</code></pre>
<p>在這個只有性別作預測變量的邏輯迴歸模型裏，當然只有男，女，兩種共變量模式 (covariate patterns)。此時，模型的精準度100% (<code>y</code> 是觀測值， <code>yhat</code> 是期待值)。接下來，再在模型中加入一個是否體重超重的二分類變量。再獲取其觀測值和期待值表格如下：</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb674-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">highbmi =</span> bmi <span class="op">&gt;</span><span class="st"> </span><span class="dv">25</span>)</a>
<a class="sourceLine" id="cb674-2" title="2">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>highbmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> binomial)</a>
<a class="sourceLine" id="cb674-3" title="3"><span class="kw">logistic.display</span>(Model_perf)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                        crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## Gender: Female vs Male 0.17 (0.12,0.24)  0.17 (0.12,0.24)  &lt; 0.001        &lt; 0.001   
##                                                                                     
## highbmi                1.21 (0.93,1.58)  1.11 (0.84,1.46)  0.456          0.453     
##                                                                                     
## Log-likelihood = -833.8269
## No. of observations = 2548
## AIC value = 1673.6539</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb676-1" title="1">LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)[,<span class="dv">2</span><span class="op">:</span><span class="dv">7</span>]</a></code></pre></div>
<pre><code>##    GenderFemale highbmiTRUE   y           P   n       yhat
## 1:            0           1 175 0.183662501 961 176.499664
## 2:            0           0  74 0.168605433 430  72.500336
## 3:            1           1  29 0.037620159 731  27.500336
## 4:            1           0  13 0.034036770 426  14.499664</code></pre>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb678-1" title="1"><span class="co"># obtain Pearson&#39;s test statistics</span></a>
<a class="sourceLine" id="cb678-2" title="2">chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)<span class="op">$</span>sPr)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb678-3" title="3">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb678-4" title="4">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Pearson chi2(1)&quot;</span>,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a></code></pre></div>
<pre><code>##              test     chi.sq     pvalue
## 1 Pearson chi2(1) 0.29881856 0.58462403</code></pre>
<p>此時的模型有 4 種共變量模式 (covariate patterns)，其實就是性別和超重與否的四種排列組合。這裏報告的 <code>Pearson's test statisitics</code>
我們在前一章講邏輯迴歸殘差的部分有講過，它就是 Pearson 標準化殘差的平方和。此處它的卡方檢驗，檢驗零假設是“模型制定正確”。所以，我們無足夠的證據 <span class="math inline">\((p=0.58)\)</span> 來反對零假設，數據觀測值和模型的期待值似乎也較爲吻合。</p>
<p>但是一旦模型裏加入了新的連續型變量，整個模型的共變量模式 (covariate patterns)，將會變得很難進行上面的觀測值和期待值的比較，由於加入的連續型變量會導致模型的共變量模式變得越來越多，甚至接近與樣本量個數 <span class="math inline">\(n\)</span>，也就是每個共變量模式的樣本越來越小，直至等於 <span class="math inline">\(1\)</span>。連續型變量的模型中我們 Hosmer-Lemeshow 檢驗 (Section <a href="#gof">46.4</a>) 而不是 Pearson 統計檢驗量。</p>
</div>
<div id="可解釋因變量的變異度及-r2-決定係數" class="section level2">
<h2><span class="header-section-number">53.2</span> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</h2>
<p>精準度的確重要，但是模型精準度好，只代表它和過去擬合它的觀測數據之間關係接近，不代表它能準確地預測其他的個體的概率。前文中只有性別作爲預測變量的邏輯迴歸模型就是實例，它和擬合的觀測數據做到了 100% 完美擬合，但是不用大腦思考也知道，除了性別還有其他更多的能預測一個人是否是重度飲酒者的變量，且擁有能提升模型的擬合程度的潛質。只有性別作預測變量的邏輯迴歸模型，最大的問題在於，它只能解釋個體之間<strong>重度飲酒者概率</strong>的<strong>變異度(variation)</strong>中極少的部分。事實上，它<strong>只能解釋能夠用性別解釋的個體之間重度飲酒者概率的變異度</strong>。所以，此處打算引伸出的概念就是類似簡單線性迴歸中的 <span class="math inline">\(R^2\)</span> 決定係數 (Section <a href="#Rsquare">28.2.3</a>) 的定義。</p>
<p>你應該還能記得，在簡單線性迴歸中決定係數 <span class="math inline">\(R^2\)</span> 的含義是因變量的平方和 (平方和) 中能被模型解釋的部分：</p>
<p><span class="math display">\[
R^2 = \frac{SS_{REG}}{SS_{yy}} = \frac{\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\]</span></p>
<p>許多前人嘗試過試圖將線性迴歸的決定係數概念擴展到廣義線性迴歸模型中來，但是目前爲止的嘗試都不太成功。所以，只有一些借鑑了簡單線性迴歸的的決定係數思想的概念，得到了擴展，但是要注意，他們本身和決定係數是有區別的。</p>
<p><strong>“假決定係數 (pseudo-R2)”</strong>，別名 McFadden 的似然比係數 (McFadden’s likelihood ratio index) <br> <span class="math display">\[R^r_{\text{McFadden}} = 1 - \frac{\ell_c}{\ell_\text{null}}\]</span> <br> 其中 <span class="math inline">\(\ell_c, \ell_{\text{null}}\)</span> 分別是模型的極大似然值 和零模型時的極大似然值。<br> 假決定係數，之所以被冠名“假”，因爲這個係數你也可以在簡單線性迴歸下計算，但是其大小常常和一般我們熟知的決定係數結果有些差距。所以，常有人質疑其到底是否可用 (因爲它在現實生活中根本不可能取到 <span class="math inline">\(0\)</span> 或 <span class="math inline">\(1\)</span>)。</p>
<p>在 R 裏，擬合了邏輯迴歸以後通常也不會報告假決定係數值的大小。所以想要獲得它，需要 <code>DescTools::PseudoR2()</code> 命令來獲取：</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb680-1" title="1"><span class="kw">PseudoR2</span>(Model_perf)</a></code></pre></div>
<pre><code>##    McFadden 
## 0.078752188</code></pre>
<p>上文中包含了性別和是否超重的模型的假決定係數只有區區 <span class="math inline">\(0.0785\)</span>，可見，只有性別和是否超重兩個變量只能解釋結果變量變異度中極少的部分。</p>
</div>
<div id="分辨能力-descrimination" class="section level2">
<h2><span class="header-section-number">53.3</span> 分辨能力 descrimination</h2>
<div id="敏感度和特異度" class="section level3">
<h3><span class="header-section-number">53.3.1</span> 敏感度和特異度</h3>
<p>評價一個邏輯迴歸的表現，最後的一個手段是，看這個模型對觀測對象的分辨能力。也就是，當我們人爲地指定一個概率值 <span class="math inline">\(p\)</span> 作爲是否患病的閾值，那麼，觀測對象通過模型計算獲得的概率，已經觀測對象本身的觀測概率之間，其實可以用診斷學的敏感度和特異度的概念來評價模型對於觀測對象的分別能力到底如何。所以邏輯迴歸模型的敏感度就是，病例中通過模型計算被判斷爲陽性的概率；特異度是，非病例中，通過模型計算本判斷爲陰性的概率。這個敏感度特異度當然會隨着我們選擇的閾值而變化。</p>
<p>圖 <a href="#fig:ROClogistic">53.1</a> 所示的是，將性別， BMI，和年齡三個變量放入邏輯迴歸模型之後，模型對於觀察對象的分辨能力的 ROC 示意圖。計算所得的 ROC 曲線下面積爲 0.7484。如果一個模型是失敗的，那麼其曲線下面積爲 (接近) 0.5。也就是會十分貼近 <span class="math inline">\(y=x\)</span> 的直線。</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb682-1" title="1">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>ageyrs, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> binomial)</a>
<a class="sourceLine" id="cb682-2" title="2">ROC_graph &lt;-<span class="st"> </span><span class="kw">lroc</span>(Model_perf, <span class="dt">grid.col =</span> <span class="st">&quot;grey&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">frame =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ROClogistic"></span>
<img src="bookdown_files/figure-html/ROClogistic-1.png" alt="Receiver operating curve for model for heavy drinking with gender, age, and BMI" width="100%" />
<p class="caption">
圖 53.1: Receiver operating curve for model for heavy drinking with gender, age, and BMI
</p>
</div>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb683-1" title="1">ROC_graph<span class="op">$</span>auc</a></code></pre></div>
<pre><code>## [1] 0.74835297</code></pre>
<p>曲線下面積，AUC 的另一個有用的意義是，從觀測對象中任意選取兩個人，一個是病例 <span class="math inline">\((y_i = 1)\)</span>，一個是非病例 <span class="math inline">\((y_j = 0)\)</span>，那麼曲線下面積就是模型能夠正確將這兩個對象按照是否患病的可能性進行排序的概率。 <span class="math inline">\(\text{AUC} = \text{Pr}(\pi_i &gt; \pi_j | y_i = 1 \&amp; y_j = 0)\)</span></p>
<p>ROC 曲線本身有自己的優點，也有許多侷限性。最近有另外一個用於診斷的新型曲線–預測曲線<span class="citation">(Pepe et al. <a href="#ref-Pepe2007" role="doc-biblioref">2007</a>)</span>。預測曲線繪製的是，觀測對象的擬合後概率 <span class="math inline">\(\hat\pi_i\)</span> 和這個概率在所有觀察對象的擬合後概率的百分位數 (percentile) 之間的曲線。一個模型，如果給許多對象相似的概率，那麼不能說這個模型的分辨能力足夠好。同時，此圖也能一目瞭然讓人看到大概多少對象的患病概率是大於一定水平的。</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb685-1" title="1">Predictive &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">fitted</span>(Model_perf), <span class="kw">rank</span>(<span class="kw">fitted</span>(Model_perf))<span class="op">/</span><span class="dv">2548</span>)</a>
<a class="sourceLine" id="cb685-2" title="2"><span class="kw">names</span>(Predictive) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;hatpi&quot;</span>, <span class="st">&quot;percentile&quot;</span>)</a>
<a class="sourceLine" id="cb685-3" title="3"><span class="kw">ggplot</span>(Predictive, <span class="kw">aes</span>(<span class="dt">x =</span> percentile, <span class="dt">y =</span> hatpi)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb685-4" title="4"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb685-5" title="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Risk percentile&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Heavy drinker risk&quot;</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb685-6" title="6"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>),</a>
<a class="sourceLine" id="cb685-7" title="7">       <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb685-8" title="8">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:predictiveness"></span>
<img src="bookdown_files/figure-html/predictiveness-1.png" alt="Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate" width="100%" />
<p class="caption">
圖 53.2: Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate
</p>
</div>
<p>圖 <a href="#fig:predictiveness">53.2</a> 所示的是，性別，年齡，BMI作爲共變量的邏輯迴歸模型的預測變量，預測重度飲酒概率的模型給出的預測曲線。從圖中可見，大多數人的概率值各不相同。而且，圖中也能告訴我們大約 20% 的觀測對象其重度飲酒的概率大於 0.2。</p>
</div>
</div>
</div>
<div id="配對實驗數據的分析法" class="section level1">
<h1><span class="header-section-number">第 54 章</span> 配對實驗數據的分析法</h1>
<p>配對實驗是指觀察對象中的一個以上 (通常是2-3個) 以事先確定的條件進行配對 (matched under conditions)。配對實驗中根據條件配對後的觀察對象常常被稱爲一個個區塊 (block)。</p>
<p><strong>例1：</strong> 配對交叉設計實驗，結果變量爲連續型。</p>
<p>給予五十名實驗對象抗高血壓藥物用於降低其舒張期血壓 (diastolic blood pressure)。舒張期血壓在實驗前 <span class="math inline">\((y_{i1})\)</span> 和實驗後 <span class="math inline">\((y_{i2})\)</span> 分別測量。此時的實驗區塊是每個患者的自身前後對照數據。</p>
<p><strong>例2：</strong> 干預實驗，結果變量爲二分類型。</p>
<p>77名已經有眼底病變的糖尿病患者被選爲實驗對象，每人隨機選取一隻眼睛接受最新的雷射激光治療，另一隻眼睛使用標準治療法。經過五年的隨訪，觀察患者的兩隻眼睛是病變爲全盲 (是/否)。此時的實驗區塊是每個患者自己，左右眼互爲對照。</p>
<p><strong>例3：</strong> 隊列研究中的配對設計，結果變量爲二分類型。</p>
<p>100 名觀察對像根據性別年齡和 100 名服他汀類藥物 (statin) 的患者，以高膽固醇血癥的有無作爲對照變量 (病例對照同時患病，或同時無病) 一一對應。這 200 名對象被追蹤隨訪 3 年，記錄他們是否罹患心血管疾病。此時的實驗區塊，是 100 個成對的實驗對象。</p>
<p><strong>例4：</strong> 配對病例對照實驗。</p>
<p>20 名肺癌患者，和另外 20 名沒有肺癌的對照以同年齡，同性別爲條件配對。研究人員詢問每個實驗參與者過去的吸菸史。本實驗的結果變量爲對象是否吸過香菸。此時的實驗區塊是一名肺癌患者和一名同年齡，同性別的對照。</p>
<p>配對實驗中，我們通常認爲在每個區塊裏的個人，或者他們的測量值應該比不同一區塊裏的觀察對象的測量值更加相似。</p>
<ul>
<li><strong>例1</strong> 中，每個個體實驗前後的血壓值，理論上會比另外一個個體的血壓值相比更加接近，無論他是否接受抗高血壓治療，故每個個體本身，構成了“完美”的病例 (實驗前) 和對照 (實驗後)。</li>
<li><strong>例3</strong> 中，無論一個人是否服用他汀類藥物，兩個同時都是高膽固醇血癥的人理論上會比無此症狀的人更加有可能罹患心血管疾病。</li>
<li><strong>例4</strong> 中，年齡和性別可能既和一個人是否患有肺癌有關係，也和一個人是否吸菸有關。所以，在考察吸菸和肺癌關係的時候，需要在相同年齡，性別的條件下才是公平的。</li>
</ul>
<div id="配對的原理" class="section level2">
<h2><span class="header-section-number">54.1</span> 配對的原理</h2>
<p>不同的實驗，配對的設計可能有不同的理由：</p>
<ul>
<li>在 RCT 設計中，配對實驗是爲了提升實驗數據對治療的真實效果的估計 (to improve the precision of the estimated effect of the treatment on the outcome)；</li>
<li>隊列研究和病例對照研究中，使用配對實驗設計 <strong>主要是爲了在實驗設計階段就控制已知的混雜因素</strong>。當然有時也有人使用配對設計去提升差異估計的精確度。</li>
</ul>
<div id="爲了提升估計的精確度" class="section level3">
<h3><span class="header-section-number">54.1.1</span> 爲了提升估計的精確度</h3>
<p>使用配對實驗設計，獲得數據以後就應使用相應的統計手法，從而達到提高差異估計的精確度的目的。因爲配對實驗設計允許我們在分析階段去除掉 “區塊差異 block variability”：</p>
<p><span class="math display">\[
\begin{aligned}
             Y_{ij} &amp; = C_j + P_i + O_{ij} \\
\text{Where } Y_{ij} &amp; = \text{outcome for block } i \text{ under treatment } j\\
                C_j &amp; = \text{component of outcome due to treatment } j \\
                P_i &amp; = \text{component of outcome due to characteristics of block } i\\
             O_{ij} &amp; = \text{residual component of outcome}
\end{aligned}
\]</span></p>
<p>在上述式子描述的配對實驗設計下，如果成對的觀察值是 <span class="math inline">\(Y_{i1}, Y_{i2} (i = 1,\cdots, n)\)</span>，那麼可以把二者的差用於估計治療效果：</p>
<p><span class="math display" id="eq:GLM12-1">\[
\begin{equation}
Y_{i2} - Y_{i1} = C_2 - C_1 + O_{i2} - O_{i1}
\end{equation}
\tag{54.1}
\]</span></p>
<p>所以，配對實驗中，由於區塊 <span class="math inline">\((P_i)\)</span> 造成的估計的方差被從隨機變異 (random variation) 中去除掉，<span class="math inline">\(C_j\)</span> 之間的差異的估計精確度得到提高。這一結論在結果變量是連續型或是二分類型中同樣適用。</p>
</div>
<div id="控制混雜因素" class="section level3">
<h3><span class="header-section-number">54.1.2</span> 控制混雜因素</h3>
<p>在病例對照實驗中，常常用配對設計來控制已知的混雜。但是必須強調的是，如果實驗設計中用了配對，那麼統計分析時，也必須用配對實驗的分析方法。</p>
<p><strong>隊列研究中</strong>： 暴露組對象和非暴露組對象之間的配對根據一些已知的混雜變量，常見的如年齡和性別配對。</p>
<p><strong>病例對照研究中</strong>：病例和對照之間通過某些特徵配對，從而控制這些特徵的混雜，常見的也是年齡和性別。另外還有的病例會從他/她居住的區域附近中尋找相似的對照，或者從他/她的家庭醫生的患者中尋找相似的對象，這時配對設計爲的是控制那些可能無法精確測量的如社會經濟條件，或環境因子。有些研究會尋找病例同一家族中的非患病者作爲對照，從而達到控制 “遺傳因素” 這一混雜因子的效果。</p>
</div>
</div>
<div id="結果變量爲連續型變量的配對實驗" class="section level2">
<h2><span class="header-section-number">54.2</span> 結果變量爲連續型變量的配對實驗</h2>
<p>用 <span class="math inline">\(Y_{i1}, Y_{i2}, (i = 1,\cdots, n)\)</span> 標記 <span class="math inline">\(n\)</span> 組配對實驗對象的結果變量的測量值。所以每對實驗對象中的兩個成員，分別被給予不同的實驗條件 (治療或安慰劑，暴露或非暴露)，用數字 <span class="math inline">\(1,2\)</span> 表示。所以，分析此種數據的策略是，計算每個實驗區塊的結果變量之差：</p>
<p><span class="math display" id="eq:GLM12-2">\[
\begin{equation}
Y_{i2} - Y_{i1}, (i = 1, \cdots, n)
\end{equation}
\tag{54.2}
\]</span></p>
<p>那麼，配對實驗的結果變量是連續型變量時，等同於單樣本的假設檢驗，零假設是結果變量在不同實驗條件下的差等於零。</p>
<div id="一般檢驗方法" class="section level3">
<h3><span class="header-section-number">54.2.1</span> 一般檢驗方法</h3>
<p>常用的有：</p>
<ol style="list-style-type: decimal">
<li>均值的配對 <span class="math inline">\(t\)</span> 檢驗。其實就是和 <span class="math inline">\(0\)</span> 作比較的單樣本 <span class="math inline">\(t\)</span> 檢驗 (Section <a href="#OneSampleT">22.6</a>)；</li>
<li>Wilcoxon 配對檢驗 (Wilcoxon matched pairs test)。此法其實是 Wilcoxon 符號秩和檢驗 (Wilcoxon signed rank test)，在零假設是兩組數據中位數之差等於零的條件下的假設檢驗 (Section <a href="#Wilcoxon-signed-rank-test">36.2</a>)。</li>
<li>符號檢驗 (Sign test) (Section <a href="#sign-test">36.1</a>)。</li>
</ol>
<p>例：17名實驗對象同時給予抗高血壓治療，數據記錄了實驗前後收縮壓的測量值：</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb686-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb686-2" title="2">sbp &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/sbp.dta&quot;</span>)</a>
<a class="sourceLine" id="cb686-3" title="3">sbp</a></code></pre></div>
<pre><code>## # A tibble: 17 x 4
##     ptid sbp_A sbp_B diff_AB
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1     1   148   132      16
##  2     2   128   120       8
##  3     3   152   148       4
##  4     4   135   134       1
##  5     5   150   128      22
##  6     6   165   140      25
##  7     7   155   138      17
##  8     8   132   136      -4
##  9     9   140   135       5
## 10    10   165   144      21
## 11    11   145   115      30
## 12    12   140   126      14
## 13    13   135   140      -5
## 14    14   135   130       5
## 15    15   122   132     -10
## 16    16   144   118      26
## 17    17   158   115      43</code></pre>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb688-1" title="1"><span class="co">## Wilcoxon signed-rank test</span></a>
<a class="sourceLine" id="cb688-2" title="2"><span class="kw">wilcox.test</span>(sbp<span class="op">$</span>sbp_A, sbp<span class="op">$</span>sbp_B, <span class="dt">paired =</span> <span class="ot">TRUE</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  sbp$sbp_A and sbp$sbp_B
## V = 137.5, p-value = 0.0038567
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb690-1" title="1"><span class="co">## 秩和檢驗結果提示，數據提供了顯著性水平低於 1% (0.0038567) 的證據</span></a>
<a class="sourceLine" id="cb690-2" title="2"><span class="co">## 證明實驗前後收縮期血壓值的變化的中位數不等於零。</span></a>
<a class="sourceLine" id="cb690-3" title="3"><span class="co">## 由此可以下結論，數據能夠提供足夠的證據證明實驗前後的收縮期血壓的</span></a>
<a class="sourceLine" id="cb690-4" title="4"><span class="co">## 分佈，是不同的。</span></a>
<a class="sourceLine" id="cb690-5" title="5"><span class="co">## 注意，這不是一個 RCT，所以，這樣的不同不一定是由於抗高血壓治療。</span></a>
<a class="sourceLine" id="cb690-6" title="6"></a>
<a class="sourceLine" id="cb690-7" title="7"><span class="co">## 3 different methods to conduct sign test</span></a>
<a class="sourceLine" id="cb690-8" title="8"></a>
<a class="sourceLine" id="cb690-9" title="9">Positive_n &lt;-<span class="st"> </span><span class="kw">sum</span>(sbp<span class="op">$</span>diff_AB <span class="op">&gt;</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb690-10" title="10">total_n &lt;-<span class="st"> </span><span class="kw">length</span>(sbp<span class="op">$</span>diff_AB)</a>
<a class="sourceLine" id="cb690-11" title="11"><span class="dv">2</span><span class="op">*</span><span class="kw">pbinom</span>(total_n<span class="op">-</span>Positive_n, total_n, <span class="fl">0.5</span>) <span class="co">## sign test -- just p-value</span></a></code></pre></div>
<pre><code>## [1] 0.01272583</code></pre>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb692-1" title="1"><span class="kw">binom.test</span>(Positive_n, total_n,<span class="fl">0.5</span>) <span class="co">## sign test through binomial test</span></a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  Positive_n and total_n
## number of successes = 14, number of trials = 17, p-value = 0.012726
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.56568213 0.96201493
## sample estimates:
## probability of success 
##             0.82352941</code></pre>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb694-1" title="1">BSDA<span class="op">::</span><span class="kw">SIGN.test</span>(sbp<span class="op">$</span>sbp_A, sbp<span class="op">$</span>sbp_B) <span class="co">## sign-test from BSDA package</span></a></code></pre></div>
<pre><code>## 
##  Dependent-samples Sign-Test
## 
## data:  sbp$sbp_A and sbp$sbp_B
## S = 14, p-value = 0.012726
## alternative hypothesis: true median difference is not equal to 0
## 95 percent confidence interval:
##   4.0101487 21.9898513
## sample estimates:
## median of x-y 
##            14 
## 
## Achieved and Interpolated Confidence Intervals: 
## 
##                   Conf.Level L.E.pt  U.E.pt
## Lower Achieved CI     0.8565 5.0000 21.0000
## Interpolated CI       0.9500 4.0101 21.9899
## Upper Achieved CI     0.9510 4.0000 22.0000</code></pre>
<p>符號檢驗的結果，相比 Wilcoxon 秩和檢驗的結果來說， P 值稍大，由於符號檢驗需要的假設前提比 Wilcoxon 秩和檢驗更少，更穩健 (檢驗效能更低, lacks power)。即便如此，數據依然提供足夠的證據 (p = 0.01273) 證明，實驗前後的收縮期血壓的中位數之差不等於零。</p>
<p>下面是 STATA 中同一數據的 Wilcoxon 秩和檢驗和符號檢驗的結果，和上面的 R 輸出結果作比較：</p>
<pre><code>. signrank sbp_A = sbp_B

Wilcoxon signed-rank test

        sign |      obs   sum ranks    expected
-------------+---------------------------------
    positive |       14       137.5        76.5
    negative |        3        15.5        76.5
        zero |        0           0           0
-------------+---------------------------------
         all |       17         153         153

unadjusted variance      446.25
adjustment for ties       -0.63
adjustment for zeros       0.00
                     ----------
adjusted variance        445.63

Ho: sbp_A = sbp_B
             z =   2.890
    Prob &gt; |z| =   0.0039

. signtest sbp_A = sbp_B

Sign test

        sign |    observed    expected
-------------+------------------------
    positive |          14         8.5
    negative |           3         8.5
        zero |           0           0
-------------+------------------------
         all |          17          17

One-sided tests:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B &gt; 0
      Pr(#positive &gt;= 14) =
         Binomial(n = 17, x &gt;= 14, p = 0.5) =  0.0064

  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B &lt; 0
      Pr(#negative &gt;= 3) =
         Binomial(n = 17, x &gt;= 3, p = 0.5) =  0.9988

Two-sided test:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B != 0
      Pr(#positive &gt;= 14 or #negative &gt;= 14) =
         min(1, 2*Binomial(n = 17, x &gt;= 14, p = 0.5)) =  0.0127</code></pre>
</div>
<div id="用迴歸法分析" class="section level3">
<h3><span class="header-section-number">54.2.2</span> 用迴歸法分析</h3>
<p>配對實驗數據還可以使用迴歸手段分析。使用迴歸分析時，需要考慮兩種不同的情形：</p>
<ol style="list-style-type: decimal">
<li>配對使用的特徵具有唯一性，即有且只有一個對照。
<ul>
<li>自己作自己的對照，如實驗前實驗後的觀測值變化；</li>
<li>同一個實驗對象，左右兩眼隨機抽取一隻作病例，一隻作對照；</li>
<li>病例和自己的配偶配對。</li>
</ul></li>
<li>配對使用的特徵不具有唯一性，病例可以有多個潛在對照。
<ul>
<li>病例和性別相同，年齡相近的對照；</li>
</ul></li>
</ol>
<p><strong>第 1 種情況：配對使用的特徵具有唯一性</strong></p>
<p>用 <span class="math inline">\(Y_{ij}\)</span> 標記第 <span class="math inline">\(j\)</span> 個配對實驗區塊中第 <span class="math inline">\(i\)</span> 個對象的觀測結果。我們可以使用下面的迴歸模型：</p>
<p><span class="math display" id="eq:GLM12-3">\[
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 X_{ij} + \gamma_j + \varepsilon_{ij}
\end{equation}
\tag{54.3}
\]</span></p>
<p>其中， <span class="math inline">\(\gamma_j\)</span> 是第 <span class="math inline">\(j\)</span> 個<strong>配對實驗區塊的固定效應</strong> (fixed effect)；<span class="math inline">\(\varepsilon_{ij}\)</span> 是殘差。這個模型可以在簡單線性迴歸中直接加入一個代表不同配對實驗區塊的變量 (分類型) 進行調整即可。用簡單線性迴歸擬合 <a href="#eq:GLM12-3">(54.3)</a> 是一個等同於配對 <span class="math inline">\(t\)</span> 檢驗的迴歸方程。</p>
<p>注意：在迴歸模型中加入代表實驗區塊的分類型變量調整<strong>僅適用</strong>與簡單線性迴歸。<strong>非線性迴歸例如邏輯迴歸，方程中試圖加入區塊變量作爲固定效應是不合適的。</strong></p>
<p>在模型中加入隨機效應 (random effect)，作爲另一種迴歸手段，則可以同時應用於線性迴歸和非線性迴歸。這種模型被叫做分層迴歸模型 (hierarchical models)，或混合效應模型 (mixed effect model)，或隨機效應模型 (random effect model)。這將會在等級線性回歸 (Section <a href="#Hierarchical">58</a>) 這一章節中詳細討論，此處且先按下不表。</p>
<p><strong>第 2 種情況：配對使用的特徵不具有唯一性</strong></p>
<p>用 <span class="math inline">\(Y_i\)</span> 標記第 <span class="math inline">\(i\)</span> 個個體的觀測結果， <span class="math inline">\(X_i\)</span> 標記主要關心的暴露變量，<span class="math inline">\(W_i\)</span> 標記用於配對的一系列變量的向量。那麼我們可以擬合兩種迴歸模型，差別在於是否調整配對變量向量：</p>
<p><span class="math display" id="eq:GLM12-4">\[
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i
\end{equation}
\tag{54.4}
\]</span></p>
<p><span class="math display" id="eq:GLM12-5">\[
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \beta_2^TW_i + \delta_i
\end{equation}
\tag{54.5}
\]</span></p>
<p>需要指出的是，這兩個模型，都是合理有效的迴歸模型，理論上會給出相同或者十分近似的 <span class="math inline">\(\beta_1\)</span> 估計。因爲配對，意味着在該樣本中，<span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(W_i\)</span> 是無關的，所以加入 <span class="math inline">\(W_i\)</span> 不會影響 <span class="math inline">\(\beta_1\)</span> 的估計值。即使，實驗樣本所來自的潛在人羣 (the unerlying population) 中，<span class="math inline">\(X_i, W_i\)</span> 是相關的 (也是最主要的要拿 <span class="math inline">\(W_i\)</span> 進行配對的動機所在)，兩個模型給出的 <span class="math inline">\(\beta_1\)</span> 估計理論上也不會有太大差距。但是，如果說配對是爲了控制混雜 (即人羣中 <span class="math inline">\(X_i, W_i\)</span> 是相關的)，建議應該使用模型 <a href="#eq:GLM12-5">(54.5)</a>。因爲模型 <a href="#eq:GLM12-5">(54.5)</a> 給出的 <span class="math inline">\(\beta_1\)</span> 的標準誤估計會比較小 (更小的信賴區間，更精確)。</p>
<p>前一節提到的一般檢驗法，是直接把“配對”這個條件放在檢驗過程中，它們只關心差異大小是否有意義。本小節討論的迴歸方法，則需要一些前提假設 (參考簡單線性迴歸的前提和邏輯迴歸的前提)。當前提條件可以滿足時，我們會更推薦使用迴歸方法對配對數據進行檢驗。因爲通常除了拿來配對的變量，我們對觀察對象還收集了其他的潛在混雜因子數據，使用迴歸方法可以進一步對其餘未用於配對的變量進行調整。</p>
</div>
</div>
<div id="結果變量是二分類變量的配對實驗" class="section level2">
<h2><span class="header-section-number">54.3</span> 結果變量是二分類變量的配對實驗</h2>
<p>用 <span class="math inline">\(Y_{i1}, Y_{i2} (i = 1,\cdots,n)\)</span> 標記 <span class="math inline">\(n\)</span> 個配對的二分類型的結果變量，其對應的暴露變量是 <span class="math inline">\(X_{i1}, X_{i2}\)</span>。</p>
<p>這樣的數據，有兩種方法來分析暴露和結果之間是否相關：</p>
<ol style="list-style-type: decimal">
<li>McNemar’s test;</li>
<li>Odds ratio.</li>
</ol>
<p>用前文中糖尿病患者眼底病變和是否變盲的例子來說明就是：第 <span class="math inline">\(i\)</span> 個實驗對象，他/她接受標準治療的眼睛是否變盲，決定了 <span class="math inline">\(Y_{i1} = 1 \text{ or } 0\)</span>；他/她接受新的治療的那隻眼睛是否變盲決定了 <span class="math inline">\(Y_{i2} = 1 \text{ or } 0\)</span>。</p>
<p>但是，用病例對照實驗 (肺癌例) 來解釋時，20 名肺癌患者被一一和同性別，年齡相近的 20 名非肺癌對象配對，每個實驗對象都被詢問其吸菸史。這樣的配對病例對照實驗的設計，決定了其實際上是把我們關心的問題 (吸菸是否導致肺癌) 逆轉了的 (肺癌患者中吸菸的比例是否大於沒有患肺癌的人)。此時應當使用 <strong>比值比 Odds ratio</strong> 來評價吸菸和肺癌之間的關係。</p>
<div id="第一步-對數據作表格" class="section level3">
<h3><span class="header-section-number">54.3.1</span> 第一步 對數據作表格</h3>
<p>有兩種方式對結果變量是二分類變量的實驗數據作表格歸納。其一，配對與否的信息被忽略掉 (表格 <a href="#tab:unmatchedGLM12-1a">54.1</a>)；其二，包含配對信息 (表格 <a href="#tab:matchedGLM12-1b">54.2</a>)。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unmatchedGLM12-1a">表 54.1: </span>Unmatched presentation of data from a study with binary outcome and binary treatment
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
New treatment
</th>
<th style="text-align:center;">
Standard treatment
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Blind
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;">
Not blind
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
43
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
77
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:matchedGLM12-1b">表 54.2: </span>Matched presentation of data from a study with binary outcome and binary treatment
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
New treatment
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Not blind
</th>
<th style="text-align:center;">
Blind
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Standard treatment
</td>
<td style="text-align:center;font-weight: bold;">
Not blind
</td>
<td style="text-align:center;">
39
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
43
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
Blind
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
77
</td>
</tr>
</tbody>
</table>
</div>
<div id="mcnemars-test" class="section level3">
<h3><span class="header-section-number">54.3.2</span> McNemar’s test</h3>
<p>下面的表格，是前面表格 <a href="#tab:matchedGLM12-1b">54.2</a> 的一般化形式。可以用於 McNemar 檢驗。在暴露對象中，結果變量等於 <span class="math inline">\(Y_{i1} = 1\)</span> 的配對數量的比例是 <span class="math inline">\(p_1 = (n_{10} + n_{11})/n\)</span>；在非暴露對象中，結果變量等於 <span class="math inline">\(Y_{i2} = 2\)</span> 的配對數量的比例是 <span class="math inline">\(p_2 = (n_{01} + n_{11})/n\)</span>。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 54.3 General arrangement of data for McNemar’s test
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Exposed <span class="math inline">\((j = 1)\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Failure <br> <span class="math inline">\((Y_{i1} = 0)\)</span>
</th>
<th style="text-align:center;">
Success <br> <span class="math inline">\((Y_{i1} = 1)\)</span>
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Unexposed <br><span class="math inline">\((j = 2)\)</span>
</td>
<td style="text-align:center;">
Failure <br> <span class="math inline">\((Y_{i2} = 0)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}+n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Success <br> <span class="math inline">\((Y_{i2} = 1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}+n_{11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}+n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}+n_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n\)</span>
</td>
</tr>
</tbody>
</table>
<p>McNemar 檢驗的零假設是，<span class="math inline">\(p_2 - p_1 = 0\)</span>，其實這等價於比較表格中 <span class="math inline">\(n_{10}, n_{01}\)</span> 是否相等。所以，在零假設條件下：</p>
<p><span class="math display">\[
n_{10} \sim \text{Binomial}(n_{10} + n_{01}, 0.5)
\]</span></p>
<p>此時既可以選用精確的二項分佈檢驗，也可以用正態分佈近似法進行假設檢驗。用表格 <a href="#tab:matchedGLM12-1b">54.2</a> 的數據進行的檢驗結果如下：</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb697-1" title="1"><span class="kw">binom.test</span>(<span class="dv">28</span>, <span class="dv">32</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  28 and 32
## number of successes = 28, number of trials = 32, p-value = 0.000019301
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.71005158 0.96486935
## sample estimates:
## probability of success 
##                  0.875</code></pre>
</div>
<div id="二分類型結果變量配對實驗的比值比" class="section level3">
<h3><span class="header-section-number">54.3.3</span> 二分類型結果變量配對實驗的比值比</h3>
<p>McNemar 檢驗只能用於判斷暴露和結果之間是否有關係。衡量這個關係的大小，還需要用比值比 (odds ratio)。我們已知可以用 Mantel Haenszel 方法來總結以某個分類變量爲條件的分層/合併比值比。同樣的方法也可以用於配對實驗數據的分析。此時的分層變量使用的是配對的實驗區塊 (blocks)。每個實驗區塊的數據可以歸納成下面的表格：</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 54.4 Example of matched data in stratum <span class="math inline">\(i\)</span>: numbers of individuals in stratum <span class="math inline">\(i\)</span> with each combination
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Unexposed (0)
</th>
<th style="text-align:center;">
Exposed (1)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Outcome 0
</td>
<td style="text-align:center;">
<span class="math inline">\(a_i\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_i\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Outcome 1
</td>
<td style="text-align:center;">
<span class="math inline">\(c_i\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(d_i\)</span>
</td>
</tr>
</tbody>
</table>
<p>實驗區塊 <span class="math inline">\(i\)</span> 的比值比 OR 是：</p>
<p><span class="math display">\[
\text{OR} = \frac{a_id_i}{b_ic_i}
\]</span></p>
<p>Mantel Haenszel 合併 OR 是：</p>
<p><span class="math display">\[
\Psi = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
\text{where } n_i = 2
\]</span></p>
<p>可以繼續推導：</p>
<p><span class="math display">\[
\begin{aligned}
\Psi &amp; = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
     &amp; = \frac{\text{number of blocks with } Y_{i1} = 1 \;\&amp;\; Y_{i2} = 0}{\text{number of blocks with } Y_{i1} = 0 \;\&amp;\; Y_{i2} = 1} \\
     &amp; = \frac{n_{10}}{n_{01}}
\end{aligned}
\]</span></p>
<p>所以，從上述推導可知，在配對實驗中，比值比只取決於那些配對中出現了不同結果的數據。這些結果不一致的配對被命名爲<strong>不一致配對 (discordant pairs)</strong>。那些結果變量相同的配對對最終的比值比估計毫無用處。</p>
</div>
<div id="配對實驗比值比的信賴區間" class="section level3">
<h3><span class="header-section-number">54.3.4</span> 配對實驗比值比的信賴區間</h3>
<p>配對實驗比值比信賴區間的精確計算步驟如下：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\pi\)</span> 標記暴露對象中，結果變量等於 <span class="math inline">\(Y_{i1} = 1\)</span>，且非暴露對象中，結果變量等於 <span class="math inline">\(Y_{i2} = 0\)</span> 的配對數在全部不一致配對數中所佔的比例：<span class="math display">\[\hat\pi = \frac{n_{10}}{n_{10} + n_{01}}\]</span></li>
<li><span class="math inline">\(\Psi\)</span> 爲不一致配對的比值比：<span class="math display">\[\hat\Psi = \frac{n_{10}}{n_{01}}\]</span></li>
<li><span class="math inline">\(\pi, \Psi\)</span> 之間的關係是：<span class="math display">\[\Psi = \frac{\pi}{1-\pi}\]</span></li>
<li><span class="math inline">\(n_{10}\)</span> 服從二項分佈：<span class="math display">\[n_{10}\sim \text{Binomial}(n_{10} + n_{01}, \pi)\]</span></li>
<li>根據二項分佈的性質計算 <span class="math inline">\(\pi\)</span> 的信賴區間： <span class="math display">\[\pi_L, \pi_U\]</span></li>
<li>所以 <span class="math inline">\(\Psi\)</span> 的信賴區間就可以計算爲：<span class="math display">\[(\frac{\pi_L}{1-\pi_L},\frac{\pi_U}{1-\pi_U})\]</span></li>
</ol>
<p>用表格<a href="#tab:matchedGLM12-1b">54.2</a> 的數據計算其比值比估計：</p>
<p><span class="math display">\[\hat{\text{OR}} = \frac{n_{10}}{n_{01}} = \frac{4}{28} = 0.14\]</span></p>
<p><span class="math inline">\(n_{10} = 4 \sim \text{Binomial}(32, \pi = 4/32 = 0.125)\)</span></p>
<p>所以 <span class="math inline">\(\pi\)</span> 的 95% 信賴區間爲：</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb699-1" title="1">FSA<span class="op">::</span><span class="kw">binCI</span>(<span class="dv">4</span>, <span class="dv">32</span>)</a></code></pre></div>
<pre><code>##                95% LCI    95% UCI
## Exact      0.035130653 0.28994842
## Wilson     0.049701344 0.28068305
## Asymptotic 0.010413848 0.23958615</code></pre>
<p>那麼該比值比的精確 95% 信賴區間爲：</p>
<p><span class="math display">\[
\begin{aligned}
 &amp; (\frac{0.03513065}{1-0.03513065},\frac{0.2899484}{1-0.2899484}) \\
=&amp; (0.036, 0.408)
\end{aligned}
\]</span></p>
<p>精確計算的結果和 R 裏獲得的結果一致：</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb701-1" title="1"><span class="kw">library</span>(exact2x2)</a>
<a class="sourceLine" id="cb701-2" title="2"><span class="kw">mcnemar.exact</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">39</span>, <span class="dv">28</span>, <span class="dv">4</span>, <span class="dv">6</span>),<span class="dv">2</span>,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## 
##  Exact McNemar test (with central confidence intervals)
## 
## data:  matrix(c(39, 28, 4, 6), 2, 2)
## b = 4, c = 28, p-value = 0.000019301
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.036409751 0.408348391
## sample estimates:
## odds ratio 
## 0.14285714</code></pre>
</div>
</div>
<div id="條件-conditional-比值比和邊際-marginal-比值比" class="section level2">
<h2><span class="header-section-number">54.4</span> 條件 (conditional) 比值比和邊際 (marginal) 比值比</h2>
<p>從配對實驗獲得的比值比是<strong>條件比值比 (conditional odds ratio)</strong>，所謂條件比值比，意思就是從配對實驗獲得的比值比是以配對的試驗區塊爲條件的。</p>
<p>用表格 <a href="#tab:matchedGLM12-1b">54.2</a> 的糖尿病患者眼底病變的數據來進一步解釋：該實驗獲得的條件比值比爲 0.143，實驗區塊是每位眼底發生病變的糖尿病患者本身。這個條件比值比應被正確解讀爲：<strong>每位眼底發生病變的患者中</strong>的兩隻眼睛中接受新療法的眼睛最終失明的機率 (odds)，和另一隻接受標準療法的眼睛最終失明的機率的比值是 0.143。數學表達式標記爲：</p>
<p><span class="math display">\[
\text{Conditional OR} = \frac{\frac{\text{Pr(Blind|new, individual) } i}{\text{Pr(Not Blind|new, individual) } i}}{\frac{\text{Pr(Blind|standard, individual) } i}{\text{Pr(Not blind|standard, individual) } i}}
\]</span></p>
<p>此<strong>條件比值比</strong>被認爲在<strong>不同的發生眼底病變的糖尿病患者<span class="math inline">\((i)\)</span>中保持不變</strong>。需要指出的是這個條件比值比<strong>不等同於認爲在糖尿病人羣中</strong>接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比爲 0.134 (邊際比值比 marginal odds ratio)。邊際比值比的數學表達式爲：</p>
<p><span class="math display">\[
\text{Marginal OR} = \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}}
\]</span></p>
<p>如果要估計上式的邊際比值比，我們需要有糖尿病人羣中失明的危險度 (the risk of blindness in the population)，以及失明高危人羣，低危人羣各自接受標準療法的失明概率。假如已知如下的信息：</p>
<ul>
<li>糖尿病人羣中有 50% 的人可以被歸類爲失明高危人羣 (high risk, HR)，另 50% 可以被歸類會失明低危人羣 (low risk, LR)；</li>
<li>接受標準療法時，高危人羣失明的概率是 90%，低危人羣失明的概率是 10%。</li>
</ul>
<p>上述信息告訴我們，總體糖尿病人羣中接受標準療法失明的概率 <span class="math inline">\(\text{Pr(Blind|standard)}\)</span> 是：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr(Blind|standard)}  &amp; = \text{Pr(Blind|standard,HR)Pr(HR)} \\
                           &amp; \;\;\;+ \text{Pr(Blind|standard, LR)Pr(LR)} \\
                           &amp; = 0.9\times0.5 + 0.1\times0.5 = 0.5
\end{aligned}
\]</span></p>
<p>再利用條件比值比 <span class="math inline">\(0.143\)</span> 我們可以計算糖尿病人羣中接受新療法失明的概率 <span class="math inline">\(\text{Pr(Blind | new)}\)</span> 是：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\text{Pr(Blind|new, HR)}}{\text{PR(Not blind | new, HR)}} &amp; = 0.143 \times \frac{\text{Pr(Blind|standard, HR)}}{\text{Pr(Not blind|standard, HR)}}  \\
 &amp; = 0.143 \times \frac{0.9}{0.1} = 1.287  \\
\frac{\text{Pr(Blind|new, LR)}}{\text{PR(Not blind | new, LR)}} &amp; = 0.143 \times \frac{\text{Pr(Blind|standard, LR)}}{\text{Pr(Not blind|standard, LR)}}  \\
 &amp; = 0.143 \times \frac{0.1}{0.9} = 0.016  \\
\Rightarrow \text{Pr(Blind|new, HR)} &amp; = 1.287/(1+1.287) = 0.563 \\
            \text{Pr(Blind|new, LR)} &amp; = 0/016/(1+0.016) = 0.016 \\
\Rightarrow\;\;\; \text{Pr(Blind | new)}   &amp; = \text{Pr(Blind|new, HR)Pr(HR)} + \text{Pr(Blind|new, LR)PR(LR)} \\
                                     &amp; = 0.563\times0.5 + 0.016\times0.5 =  0.290
\end{aligned}
\]</span></p>
<p>獲得了 <span class="math inline">\(\text{Pr(Blind|standard), Pr(Blind | new)}\)</span> 之後，邊際比值比 (糖尿病人羣中接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比)：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Marginal OR} &amp; =  \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}} \\
                   &amp; = \frac{0.5/(1-0.5)}{0.290/(1-0.290)} = 0.408
\end{aligned}
\]</span></p>
<p>比起條件比值比 (0.143)，邊際比值比 (0.408) 要大出許多來。</p>
</div>
</div>
<div id="條件邏輯迴歸-conditional-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 55 章</span> 條件邏輯迴歸 Conditional logistic regression</h1>
<p>配對實驗設計可以用於 RCT，隊列研究，病例對照研究：</p>
<ul>
<li>RCT實驗設計中，接受治療方案 A 的患者，和接受治療方案 B 的患者，以 1:1 的比例按照他們的某種醫學特徵配對。這種配對可以是同一個患者在交叉設計RCT 實驗中的觀測值，也可以是同一個患者接受治療的前後測量值，當然還可以是同一個患者的左右兩隻眼睛 (手臂，腿，等等)；</li>
<li>隊列研究裏，<strong>暴露和非暴露</strong>對象根據事先決定的配對原則配對 (相同性別，年齡接近，或者居住在同一社區，或者是同一家庭中暴露和非暴露的兩個個體)；</li>
<li>病例對照研究裏，<strong>病例和非病例</strong>按照事先決定的配對原則配對，一個病例可能和一個或者多個對照相匹配。</li>
</ul>
<p>本章節着重討論病例對照研究中，條件邏輯迴歸模型的使用。在病例對照研究中，配對設計極爲常見。如同前面提到的那樣，在病例對照研究的設計階段，研究者可能設計一個病例和一個或者多個對照進行配對。要研究的暴露因素變量可以是多種多樣的 (二分類，或連續型)，且可以考慮對多個不同的暴露進行觀察和分析時的調整。相反，隊列研究中能夠進行配對的暴露就只能僅限於二分類變量。所以，病例對照研究中<strong>對某個特徵進行的配對</strong>，其實是對病例-對照這樣的實驗設計本身與生俱來的特質進行了合理的利用。隊列研究則沒有了這樣的優勢，所以隊列研究中使用配對設計的其實不太常見。</p>
<p>配對病例對照研究中，研究者常用一些最常見的混雜因素作爲配對的變量 (如性別年齡)，且這些配對所使用的變量本身不是該實驗主要探討的話題。有些研究者還認爲配對是一個方便地尋找對照組的手段。當然，選取對照組的原則，可以是具有唯一性的配對原則 (使對照有且僅有1-2個)，或者是無唯一性的配對原則 (病例可以有多個潛在的對照)。<strong>唯一性配對原則導致的最大問題是，你可能根本找不到合適的對照</strong>，所以研究者會更傾向於把配對原則放寬一些，以獲取足夠的對照組樣本量，但是這也會帶來別的附加問題，那就是需要用匹配的數學模型來控制殘差之間的依賴性 (residual dependency)。在考慮了生存時間的一些病例對照研究中，原則上還會考慮選取和病例存活相同時間 (年齡) 的人作對照，詳細會繼續在生存分析中深入探討。</p>
<div id="配對實驗的邏輯迴歸模型" class="section level2">
<h2><span class="header-section-number">55.1</span> 配對實驗的邏輯迴歸模型</h2>
<p>定義 <span class="math inline">\(X_u\)</span> 是一個簡單的二分類暴露變量，<span class="math inline">\(D_u\)</span> 是一個簡單的二分類結果變量，<span class="math inline">\(u = 1, \cdots, n\)</span> 是配對的個數。第 <span class="math inline">\(u\text{th}\)</span> 組中的研究對象，互爲配對。在某些特殊場合，每組配對只有2個研究對象 (例如糖尿病患者的左右兩隻眼睛)。</p>
<p>用概率標記法定義每個患者的概率：</p>
<p><span class="math display" id="eq:GLM13-1">\[
\begin{equation}
\pi_{u;xd} = \text{Pr}(X_u = x, D_u = d)
\end{equation}
\tag{55.1}
\]</span></p>
<p>用 (Section <a href="#GLM8-3">50.2</a>) 中相似的表格來理解，第 <span class="math inline">\(u\)</span> 組 <span class="math inline">\((u = 1, \cdots, n)\)</span> 配對中的研究對象可以用下表來歸納其概率。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 55.1: Separate samples from subpopulations <span class="math inline">\(D=0,1\)</span> with relavant conditional probabilities <strong>in a matched case-control study within each pair</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{Pr}(X_u=x|D_u=d)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{u;10}}{\pi_{u;10}+\pi_{u;00}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{u;11}}{\pi_{u;11}+\pi_{u;01}}\)</span>
</td>
</tr>
</tbody>
</table>
<p>那麼第 <span class="math inline">\(u\)</span> 組配對中，暴露和結果之間真實的比值比 (odds ratio)是：</p>
<p><span class="math display" id="eq:GLM13-2">\[
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}}
\end{equation}
\tag{55.2}
\]</span></p>
<p>所以，在配對病例對照研究中，<strong>我們假設這樣的前提得到滿足：每個配對中的比值比是不變的 (we assume that the true log odds ratio relating exposure to disease is the same for all pairs)</strong>：</p>
<p><span class="math display" id="eq:GLM13-3">\[
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}} = e^\beta
\end{equation}
\tag{55.3}
\]</span></p>
<div id="配對病例對照研究" class="section level3">
<h3><span class="header-section-number">55.1.1</span> 配對病例對照研究</h3>
<p>在探討<strong>非配對的病例對照研究</strong>時，我們給二分類型暴露變量定義過下列邏輯迴歸模型 (Section <a href="#GLM8-3-4">50.2.3</a>)：</p>
<p><span class="math display" id="eq:GLM13-4">\[
\begin{equation}
\text{Pr}(X_i = 1 | D_i = d_i) = \frac{e^{\lambda^*+\beta d_i}}{1+e^{\lambda^*+\beta d_i}}\\
\text{Where } i \text{ refers to an individual}
\end{equation}
\tag{55.4}
\]</span></p>
<p>接下來，我們來把這個邏輯回歸模型擴展到配對實驗數據: 每對實驗數據包含一個病例，一個對照。用 <span class="math inline">\(X_{u;0}\)</span> 標記第 <span class="math inline">\(u\)</span> 對配對數據中，對照的某二分類解釋變量的值 (the binary explanatory variable <span class="math inline">\(X\)</span> for the control in the <span class="math inline">\(u\)</span>th matched pair)。<span class="math inline">\(X_{u;1}\)</span> 表示該對照的病例的相應二分類解釋變量的值。如此，一個包含了配對的病例和對照二者的邏輯回歸模型可以寫爲:</p>
<p><span class="math display" id="eq:GLM13-5">\[
\begin{equation}
\text{Pr}(X_{u;0} = 1) = \frac{e^{\lambda^*_u}}{1+e^{\lambda^*_u}} ; \text{Pr}(X_{u;1} = 1) = \frac{e^{\lambda^*_u + \beta}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
\tag{55.5}
\]</span></p>
<p>或者你如果願意，可以把它改寫成:</p>
<p><span class="math display" id="eq:GLM13-6">\[
\begin{equation}
\text{Pr}(X_{u;d} = 1)  = \frac{e^{\lambda^*_u + d\beta}}{1+e^{\lambda^*_u + d\beta}}, \;d = 0,1
\end{equation}
\tag{55.6}
\]</span></p>
<p>該模型的參數 <span class="math inline">\(\beta\)</span> 是第 <span class="math inline">\(u\)</span> 配對中的對數比值比 (log-odds ratio)。可是，我們使用它的前提是，默認這個對數比值比在所有的配對數據 <span class="math inline">\(u = 1, \cdots, n\)</span> 中都是相同的。另一個參數 <span class="math inline">\(\lambda^*_u\)</span> 是第 <span class="math inline">\(u\)</span> 組的特徵值。被定義爲第 <span class="math inline">\(u\)</span> 組配對中對照的暴露 <span class="math inline">\((X = 1)\)</span> 的對數幾率 (log odds of exposure for the exposure in the <span class="math inline">\(u\)</span>th pair):</p>
<p><span class="math display">\[
\lambda^*_u = \log(\frac{\pi_{u;10}}{\pi_{u;00}})
\]</span></p>
<p>在第 <span class="math inline">\(u\)</span> 組配對中，有且只有4種 <span class="math inline">\((x_{u;1},x_{u;0})\)</span> 結果: 也就是 <span class="math inline">\((0,0), (1,0), (0,1), (1,1)\)</span>。該對數據的似然方程是:</p>
<p><span class="math display" id="eq:GLM13-8">\[
\begin{equation}
\frac{e^{\lambda^*_ux_{u;0}}}{1+e^{\lambda^*_u}}\cdot\frac{e^{(\lambda^*_u + \beta)x_{u;1}}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
\tag{55.7}
\]</span></p>
<p>所以把所有配對的似然相乘可得整個數據的似然方程:</p>
<p><span class="math display" id="eq:GLM13-9">\[
\begin{equation}
\frac{\exp(\sum\lambda^*_ux_{u;0})}{\prod(1+e^{\lambda^*_u})}\cdot\frac{\exp(\sum(\lambda^*_u + \beta)x_{u;1})}{\prod(1+e^{\lambda^*_u+\beta})}
\end{equation}
\tag{55.8}
\]</span></p>
<p>整體數據的似然方程 <a href="#eq:GLM13-9">(55.8)</a> 中的和 <span class="math inline">\(\sum\)</span> 與積 <span class="math inline">\(\prod\)</span> 分別對應相加與相乘所有的病例與對照的 <span class="math inline">\(n\)</span> 組配對。對於第 <span class="math inline">\(u\)</span> 組來說，它對似然方程的貢獻的部分只是式子 <a href="#eq:GLM13-8">(55.7)</a> 中包含 <span class="math inline">\(\lambda_u^*\)</span> 的部分。該信息其實就是第 <span class="math inline">\(u\)</span> 組配對自有/特有的信息。但其實每組配對中的病例和對照又與其他組略微不同，他們各自提供的信息其實對於整體的似然來說雖然微小，但是當配對數量越來越多，就變得不可忽略。此時對 <a href="#eq:GLM13-9">(55.8)</a> 直接進行粗暴的取參數 <span class="math inline">\(\beta\)</span> 的極大值是錯誤的，其導致的後果會在下文中繼續討論。我們需要用另一種新的途徑來求參數 <span class="math inline">\(\beta\)</span>。</p>
</div>
<div id="配對隊列研究" class="section level3">
<h3><span class="header-section-number">55.1.2</span> 配對隊列研究</h3>
<p>這裏簡略地分析一下配對隊列研究中會遇見的和配對病例對照研究相似問題的過程。在配對隊列研究中，一個<strong>接受暴露的研究對象</strong>被配對給另一個<strong>沒有接受暴露的研究對象</strong> (注意在配對病例對照研究中，是一個病例和一個對照做配對)。在第 <span class="math inline">\(u\)</span> 組隊列配對中，用 <span class="math inline">\(D_{u;1}\)</span> 標記暴露對象的追蹤結果 (發病/死亡/事件發生的有無)，用 <span class="math inline">\(D_{u;0}\)</span> 標記非暴露對象的追蹤結果 (發病/死亡/事件發生的有無)。</p>
<p>隊列研究中已知暴露 <span class="math inline">\(X\)</span> 有無的前提下，結果 <span class="math inline">\(D\)</span> 發生的有無的邏輯回歸模型，加入對配對設計的考量是:</p>
<p><span class="math display" id="eq:GLM13-10">\[
\begin{equation}
\text{Pr}(D_{u;0} = 1) = \frac{e^{\lambda_u}}{1+e^{\lambda_u}}\;; \; \text{Pr}(D_{u;1} = 1) = \frac{e^{\lambda_u + \beta}}{1+e^{\lambda_u+\beta}}
\end{equation}
\tag{55.9}
\]</span></p>
<p>正如之前在無配對條件下的隊列研究和病例對照研究中的推導過的那樣 <a href="#GLM8-3-4">50.2.3</a>，<span class="math inline">\(\lambda_u\)</span> 和 <span class="math inline">\(\lambda_u^*\)</span> 是有<strong>不同涵義</strong>的，但是配對隊列研究和配對病例對照研究則具有相同的對數比值比–參數 <span class="math inline">\((\beta)\)</span>。這是基於一個重要的前提–相同人羣，相同暴露和相同疾病的結果在不同實驗設計 (病例對照和隊列研究) 時使用相同的配對變量。</p>
<p>在配對病例對照研究中，某對暴露和非暴露對象其實驗結果的可能性也只有四種 <span class="math inline">\((d_{u;1}, d_{u;0})\)</span>，該配對的似然是:</p>
<p><span class="math display" id="eq:GLM13-11">\[
\begin{equation}
\frac{e^{\lambda_ud_{u;0}}}{(1+e^{\lambda_ud_{u;0}})}\cdot\frac{e^{(\lambda_u+\beta)d_{u;1}}}{(1+e^{\lambda_u+\beta})}
\end{equation}
\tag{55.10}
\]</span></p>
<p>整體數據的似然方程就是和配對病例對照研究一樣的，將每對這樣的似然相乘。所以，我們就又遇見了和配對病例對照研究相似的問題，此時如果直接對整體似然方程中求極大似然獲得的 <span class="math inline">\(\beta\)</span> 將會是錯誤的。</p>
</div>
</div>
<div id="條件邏輯回歸-二分類暴露變量" class="section level2">
<h2><span class="header-section-number">55.2</span> 條件邏輯回歸 – 二分類暴露變量</h2>
<p>我們再回到簡單的一對一配對病例對照實驗設計，且研究的實驗暴露是一個簡單的二分類變量。這一節的目的是克服前面遇見的困難 (繞過不需要的 <span class="math inline">\(\lambda_u^*, u = 1, 2, \cdots, n\)</span>) ，找到能夠準確估計參數 <span class="math inline">\(\beta\)</span> 的數學方法。</p>
<div id="充分統計量-sufficient-statistics" class="section level3">
<h3><span class="header-section-number">55.2.1</span> 充分統計量 sufficient statistics</h3>
<p>繞過雜音變量(不需要的變量)，直接估計我們感興趣的參數的過程，需要利用<strong>充分統計量 (sufficient statistics)</strong> 的概念。這裏，噪音變量就是 <span class="math inline">\(\lambda_u^*, u = 1, 2, \cdots, n\)</span>。下面是對充分統計量的定義:</p>
<p>假設隨機變量 <span class="math inline">\(\mathbf{y}\)</span> 的概率(密度)方程中含有其他的雜音變量 <span class="math inline">\(\theta_1, \cdots, \theta_p\)</span>:</p>
<p><span class="math display">\[
f(\mathbf{y}|\theta_1, \cdots, \theta_9)
\]</span></p>
<p>如果統計量 <span class="math inline">\(T_k\)</span>，是實驗數據中得到的某方程，且 <span class="math inline">\(\mathbf{y}\)</span> 基於 <span class="math inline">\(T_k\)</span> 的條件分布與 <span class="math inline">\(\theta_k\)</span> 無關 (獨立)，那麼該方程被稱作參數 <span class="math inline">\(\theta_k\)</span> 的充分統計量。其實就是，如果 <span class="math inline">\(T_k\)</span> 可以給我們足夠估計 <span class="math inline">\(\theta_k\)</span> 的信息量，我們就稱 <span class="math inline">\(T_k\)</span> 是 <span class="math inline">\(\theta_k\)</span> 的充分統計量。</p>
<p>舉例來說，假設我們手頭的樣本數據 <span class="math inline">\(y_1, y_2, \cdots, y_n\)</span> 可以被認爲從正態分布的人羣中採集，我們希望通過這個樣本來估計總體人羣的均值 <span class="math inline">\(\mu\)</span>。此時常常(不自覺地)做總體方差已知的假設。該數據的似然方程是:</p>
<p><span class="math display">\[
\prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{ -\frac{(y_i-\mu)^2}{2\sigma^2} \}
\]</span></p>
<p>此時，估計要總體均值 <span class="math inline">\(\mu\)</span> 我們僅需要 <span class="math inline">\(\sum_i y_i\)</span> (或者只要 <span class="math inline">\(\bar{y}\)</span>) 就足夠了。這裏我們說 <span class="math inline">\(\sum_i y_i\)</span> 是參數總體均值 <span class="math inline">\(\mu\)</span> 的充分統計量。</p>
</div>
<div id="條件邏輯回歸的推導" class="section level3">
<h3><span class="header-section-number">55.2.2</span> 條件邏輯回歸的推導</h3>
<p>在簡單配對病例對照研究的實驗設定下，可以被證明的是，第 <span class="math inline">\(u\)</span> 對配對的暴露變量 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span> 是雜音變量 <span class="math inline">\(\lambda_u^*\)</span> 的充分統計量。值得注意的是，我們其實不需要知道 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span> 這一對暴露數據中哪個來自病例，哪個來自對照。對於一個二分類暴露變量，如果我們已知 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，那麼我們就知道了每個病例對照配對中暴露的個數。所以，我們完全可以用 <span class="math inline">\(T_u = x_{u;0} + x_{u;1}\)</span> 來替代 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，因爲它只有三種取值的可能:</p>
<ul>
<li>0: 病例對照都沒有暴露;</li>
<li>1: 病例或者對照其中之一有暴露;</li>
<li>2: 病例和對照均有暴露。</li>
</ul>
<p>利用已知的關於充分統計量的概念，在尋找第 <span class="math inline">\(u\)</span> 對配對對總體似然的貢獻時我們把 <span class="math inline">\(T_u = x_{u;0} + x_{u;1}\)</span> 作條件 (condition on)。有了這個條件，剩下的隨機現象就是暴露在病例和對照中的分布，也就是:</p>
<p><span class="math display" id="eq:GLM13-13">\[
\begin{equation}
\text{Pr}(X_{u;0} = x_{u;0}, X_{u;1} = x_{u;1} | T_u = x_{u;0} + x_{u;1})
\end{equation}
\tag{55.11}
\]</span></p>
<p>如果 <span class="math inline">\(x_{u;0}=x_{u;1}\)</span>，也就是當病例和對照同時爲暴露或非暴露時，我們有 100% 的把握對他們的暴露信息加以區分:</p>
<p><span class="math display" id="eq:GLM13-14">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 0| T_u = 0) =  1,\\
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 1| T_u = 2) =  1
\end{aligned}
\tag{55.12}
\]</span></p>
<p>如果 <span class="math inline">\(x_{u;0} \neq x_{u;1}\)</span>，也就是 <span class="math inline">\(T_u = 1\)</span>，那只有兩種可能性，要麼病例是暴露，對照非暴露，要麼病例是非暴露，對照是暴露:</p>
<p><span class="math display" id="eq:GLM13-15">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1),\\
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1)
\end{aligned}
\tag{55.13}
\]</span></p>
<p>這兩個概率可以被計算爲:</p>
<p><span class="math display" id="eq:GLM13-16">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) \\ &amp; =  \frac{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
\tag{55.14}
\]</span></p>
<p><span class="math display" id="eq:GLM13-17">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) \\ &amp; = \frac{\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
\tag{55.15}
\]</span></p>
<p>用前面推導過的邏輯回歸模型公式 <a href="#eq:GLM13-5">(55.5)</a> 可以推導出:</p>
<p><span class="math display" id="eq:GLM13-18">\[
\begin{aligned}
\text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) &amp; = \frac{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}}{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})} + \frac{e^{\lambda^*_u + \beta}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}} \\
 &amp; = \frac{1}{1+e^\beta}
\end{aligned}
\tag{55.16}
\]</span></p>
<p>類似地:</p>
<p><span class="math display" id="eq:GLM13-19">\[
\begin{aligned}
\text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) = \frac{e^\beta}{1+e^\beta}
\end{aligned}
\tag{55.17}
\]</span></p>
</div>
<div id="條件似然-conditional-likelihood" class="section level3">
<h3><span class="header-section-number">55.2.3</span> 條件似然 conditional likelihood</h3>
<p>一個簡單設計，暴露變量爲二分類變量的配對病例對照研究，可以用下面的四格表歸納收集的數據:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 55.2: Data from a matched case control study with a single binary
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D = 1\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(D=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
</tbody>
</table>
<p>用上之前推導的結論，和上面表格的總結，我們可以知道，對於 1:1 的配對病例對照研究，且暴露爲二分類變量來說，它的似然是:</p>
<p><span class="math display" id="eq:GLM13-20">\[
\begin{equation}
L = (\frac{e^\beta}{1+e^\beta})^{n_{10}}(\frac{1}{1+e^\beta})^{n_{01}}
\end{equation}
\tag{55.18}
\]</span></p>
<p>接下來用我們熟悉的極大似然法就可以推導出 <span class="math inline">\(\beta\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
\ell &amp; = n_{10}\beta - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \frac{\text{d}\ell}{\text{d}\beta} &amp; = n_{10} - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \hat\beta  &amp; = \log\frac{n_{10}}{n_{01}}
\end{aligned}
\]</span></p>
</div>
<div id="進一步擴展" class="section level3">
<h3><span class="header-section-number">55.2.4</span> 進一步擴展</h3>
<p>目前為止推導的條件邏輯回歸模型雖然只是簡單的一對一配對病例對照研究實驗設計，且暴露變量也只是二分類變量。但是經驗告訴我們，這樣的理論基礎可以被進一步擴展到更加復雜的實驗設計:</p>
<ul>
<li><p>上述理論很容易地可以擴展到一對一配對隊列研究和RCT實驗。我們需要做的只是修改 <span class="math inline">\(X_{u;d}\)</span> 成 <span class="math inline">\(D_{u;x}\)</span> 即可，推導獲得的條件似然是完全相同的。唯一不同的是 <span class="math inline">\(n_{10}, n_{01}\)</span> 在隊列研究和RCT臨牀試驗中的含義從<strong>病例中暴露和對照中非暴露的對數</strong>變成了<strong>暴露中病例和非暴露中對照</strong>的對數。(<span class="math inline">\(n_{10}\)</span> becomes the number of pairs in which the exposed individual becomse a case and the unexposed becomes a control, and vice versa for <span class="math inline">\(n_{01}\)</span>)。</p></li>
<li><p>配對病例對照研究常見的可以一個病例配對1-5個對照。</p></li>
<li><p>也可以在配對病例對照研究中研究(比二分類變量)更加復雜的暴露因素，既可以是非類型變量，也可以是連續型變量。</p></li>
</ul>
</div>
</div>
<div id="條件邏輯回歸模型的一般化" class="section level2">
<h2><span class="header-section-number">55.3</span> 條件邏輯回歸模型的一般化</h2>
<p>現在我們拋棄簡單實驗設計思維，考慮在配對實驗中需要研究一個一般的暴露變量 (可以是二分類，多分類，連續型)，或者是一個多種不同變量組成的預測變量的向量。此時我們關心的主要是這些預測變量在病例或者對照的條件下分布 (conditional distribution): <span class="math inline">\(P(X_{u;0} = x), P(X_{u;1} = x)\)</span>。假設，某對病例和對照對象中，對照被觀測到有預測變量 <span class="math inline">\(x_{u;0}\)</span>，病例則被觀察到的是 <span class="math inline">\(x_{u;1}\)</span>，那麼我們關心的條件概率其實是研究對象被觀測到預測變量 <span class="math inline">\(x_{u;0}\)</span> 且他/她本身正好是對照，且同時他/她的病例被觀測到預測變量 <span class="math inline">\(x_{u;1}\)</span> 的概率。此時，充分統計量就是 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，且聯合條件分布 (joint conditional distribution) 是:</p>
<p><span class="math display" id="eq:GLM13-24">\[
\begin{aligned}
&amp; \text{P}(X_{u;0} = x_{u;0}, X_{u; 1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
=&amp;  \frac{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1})}{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1}) + \text{P}(X_{u;0} = x_{u;1})\text{P}(X_{u;1} = x_{u;0})}
\end{aligned}
\tag{55.19}
\]</span></p>
<p>其實，當且僅當我們在研究<strong>一個簡單二分類預測變量</strong>時，一樣。這裏當我們需要把它一般化的時候，需要來點不太一樣的方法。先用 <span class="math inline">\(D_{u;x}\)</span> 標記第 <span class="math inline">\(u\)</span> 對配對中觀測到預測變量 <span class="math inline">\(x\)</span> 的研究對象的病例/對照狀態。那麼 <span class="math inline">\(D_{u;x}\)</span> 的邏輯回歸模型是:</p>
<p><span class="math display" id="eq:GLM13-25">\[
\begin{aligned}
\text{Pr}(D_{u;x} =1) &amp; = \frac{e^{\lambda_u+\beta^Tx}}{1+e^{\lambda_u+\beta^Tx}} \\
\text{Pr}(D_{u;x} =0) &amp; = \frac{1}{1+e^{\lambda_u+\beta^Tx}}
\end{aligned}
\tag{55.20}
\]</span></p>
<p>應用貝葉斯定理:</p>
<p><span class="math display" id="eq:GLM13-26">\[
\begin{equation}
\text{Pr}(X_{u;1} = x) = \frac{\text{Pr}(D_{u;x} = 1)\times\text{Pr}(X_{u;\cdot} = x)}{\text{Pr}(D_{u;\cdot} = 1)}
\end{equation}
\tag{55.21}
\]</span></p>
<p>其中,</p>
<ul>
<li><span class="math inline">\(\text{Pr}(X_{u;\cdot} = x)\)</span> 指的是預測變量 <span class="math inline">\(X\)</span> 在產生第 <span class="math inline">\(u\)</span> 對病例對照配對的人羣 (subpopulation which generates the <span class="math inline">\(u\)</span>th matched set) 中的邊際分布 (marginal distribution，或者叫做非條件分布 unconditional distribution);</li>
<li><span class="math inline">\(\text{Pr}(D_{u;\cdot} = 1)\)</span> 指的是在產生第 <span class="math inline">\(u\)</span> 對病例對照配對的人羣中，成爲病例的概率 (unconditional probability of being a case in that sub-population)。</li>
</ul>
<p>那麼將 <a href="#eq:GLM13-26">(55.21)</a> 代入 <a href="#eq:GLM13-24">(55.19)</a> 經過推導和精簡可以得到:</p>
<p><span class="math display" id="eq:GLM13-27">\[
\begin{aligned}
&amp; \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= &amp; \frac{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1)}{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1) + \text{Pr}(D_{u;x_{u;0}} = 1)\text{Pr}(D_{u;x_{u;1}} = 0)}
\end{aligned}
\tag{55.22}
\]</span></p>
<p>此時再帶入 <a href="#eq:GLM13-25">(55.20)</a>，推導精簡之後可以獲得:</p>
<p><span class="math display" id="eq:GLM13-28">\[
\begin{aligned}
  &amp; \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= &amp; \frac{e^{\beta^{T}x_{u;1}}}{e^{\beta^{T}x_{u;1}} + e^{\beta^{T}x_{u;0}}}
\end{aligned}
\tag{55.23}
\]</span></p>
<p>這就是第 <span class="math inline">\(u\)</span> 組病例對照配對數據對條件似然 (conditional likelihood) 的貢獻。那麼對於完整的整套數據來說，整體似然就是把所有的病例對照配對的似然相乘:</p>
<p><span class="math display" id="eq:GLM13-29">\[
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \exp{(\beta^{T}x_{u;0})}}
\end{equation}
\tag{55.24}
\]</span></p>
<p>這樣的一對一病例對照研究的似然可以擴展到 1:c 的情況，也就是一個病例和 c 個對照相配對的情況，其條件邏輯回歸的似然是:</p>
<p><span class="math display">\[
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \sum_{k=1}^c\exp{(\beta^{T}x_{u;0k})}}
\end{equation}
\]</span></p>
</div>
</div>
<div id="multinomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 56 章</span> Multinomial Logistic Regression</h1>
</div>
<div id="ordinal-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 57 章</span> Ordinal Logistic Regression</h1>

</div>



<div id="Hierarchical" class="section level1">
<h1><span class="header-section-number">第 58 章</span> 相互依賴數據及簡單的應對方案</h1>
<blockquote>
<dl>
<dt>To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.</dt>
<dd><p>Sir Ronald Aylmer Fisher</p>
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Analysis of Hierarchical and Other Dependent Data lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/sharples.linda">Linda Sharples</a>, and Dr. <a href="https://www.lshtm.ac.uk/aboutus/people/njagi.edmund-njeru">Edmund Njeru Njagi</a>.
</div>

<div id="相互依賴的數據" class="section level2">
<h2><span class="header-section-number">58.1</span> 相互依賴的數據</h2>
<p>線性回歸模型，廣義線性回歸模型，他們背後都有一個十分十分<strong>十分重要的假設–數據的相互獨立性</strong>。這個前提假設常常會在現實數據中得不到滿足，因爲數據與數據之間在背後很可能會有有所關聯，也許是已知的，也許是未知的因素讓某些數據顯得更加接近彼此。這個章節，主要的內容就是舉例說明分層數據在日常生活中的常見性，以及處理這個非獨立性質的必要性。</p>
<ul>
<li>圖 <a href="#fig:Hier01-1">58.1</a> 展示的箱式圖顯示的是六個不同醫院對各自 12 名患者收縮期血壓測量的結果。如果把醫院看做一個單位，取院內患者的平均值，那麼六所醫院的血壓均值最大爲 135.7 mmHg，最小是 117.7 mmHg，六所醫院測量的血壓總體均值爲 125.6 mmHg。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-1"></span>
<img src="bookdown_files/figure-html/Hier01-1-1.png" alt="Box and whiskers plot of measured SBP in patients from six hospitals" width="90%" />
<p class="caption">
圖 58.1: Box and whiskers plot of measured SBP in patients from six hospitals
</p>
</div>
<ul>
<li>圖 <a href="#fig:Hier01-2">58.2</a> 展示的是對 17 名患者使用兩種不同的測量方法測量的最大呼吸速率 (peak-expiratory-flow rate, PEFR)。兩種方法又測量了兩次，途中展示的是其中一種測量方法前後兩次測量結果的散點圖。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-2"></span>
<img src="bookdown_files/figure-html/Hier01-2-1.png" alt="Two recordings of PEFR taken with the Mini Wright meter" width="80%" />
<p class="caption">
圖 58.2: Two recordings of PEFR taken with the Mini Wright meter
</p>
</div>
<ul>
<li>圖 <a href="#fig:Hier01-3">58.3</a> 展示的來自全英 65 所學校的 4059 名學生入學前閱讀水平測試成績 (LRT) 和畢業時 GCSE 考試成績之間的散點圖關系。值得注意的是該圖其實無視了學校這個變量，把每個學生看成相互獨立的個體。但是當我們隨機選取四所學校，看它們各自的學生的成績表現 (圖 <a href="#fig:Hier01-4">58.4</a>)。很顯然，之前忽視了學校這一層級的變量是不恰當的，因爲不同學校學生的入學前和畢業時成績之間的相關性很明顯存在不同的模式 (四所學校的回歸線各自的截距和斜率各不相同)。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-3"></span>
<img src="bookdown_files/figure-html/Hier01-3-1.png" alt="GCSE by LRT in all 65 schools" width="80%" />
<p class="caption">
圖 58.3: GCSE by LRT in all 65 schools
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:Hier01-4"></span>
<img src="bookdown_files/figure-html/Hier01-4-1.png" alt="GCSE by LRT in four randomly selected schools" width="80%" />
<p class="caption">
圖 58.4: GCSE by LRT in four randomly selected schools
</p>
</div>
<ul>
<li>另一個特別好的例子展示在圖 <a href="#fig:Hier01-5">58.5</a> 中，是關於同一個母親的不同孩子的出生體重的數據。一個母親可以有多個孩子，每個母親的孩子之間的出生體重很明顯無法看作相互獨立。圖中展示的是，3300 名生了兩個孩子的母親的孩子們出生體重的散點圖。同一個母親的小孩用線相連。顯然，同一個母親生的孩子，其出生體重比不同母親的孩子出生體重差距更小，更接近彼此，因爲他們來自同一個母親。可以想象，一個母親如果身材高大，那麼她的孩子們可能都傾向於有比較高的出生體重。所以同一個母親的孩子之間體重是有相關關系的 (within correlation)。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-5"></span>
<img src="bookdown_files/figure-html/Hier01-5-1.png" alt="Birthweight of siblings by maternal identifier" width="80%" />
<p class="caption">
圖 58.5: Birthweight of siblings by maternal identifier
</p>
</div>
<ul>
<li>最後一個用於本章節的實例是，一項研究亞洲兒童生長狀況的調查分別記錄了 198 個數據點，68 個兒童在 0 到 3 歲之間的四個年齡點的體重數據。圖 <a href="#fig:Hier01-6">58.6</a> 展示的就是這個典型的隨訪數據的個人生長曲線。且圖中每個人的生長軌跡提示，男孩子的生長過程可能相互之間體重差異顯得較女孩子來得大。如果，我們用每個兒童自己的數據，給每個兒童擬合各自的回歸線，數據顯然不足，但是如果我們決定忽略個體的生長的隨機效應 (不均一性)，又顯得十分不妥當。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Hier01-6"></span>
<img src="bookdown_files/figure-html/Hier01-6-1.png" alt="Growth profiles of boys and girls in the Asian growth data" width="80%" />
<p class="caption">
圖 58.6: Growth profiles of boys and girls in the Asian growth data
</p>
</div>
</div>
<div id="依賴性的來源在哪裏" class="section level2">
<h2><span class="header-section-number">58.2</span> 依賴性的來源在哪裏</h2>
<p>上述例子中的數據，均提示我們數據與數據之間獨立性的假設，常常會遇到尷尬的局面。因爲數據與數據之間本身就不可能完全獨立。</p>
<ol style="list-style-type: decimal">
<li>同一個診所或者醫院的患者，他們之間可能有着某些相似的因素從而導致他們的血壓相比其他醫院的人彼此更加接近。這個原因可能是有同一家醫院的患者可能有類似的疾病。</li>
<li>同一患者身上反復抽取樣本，也就是說一個對象貢獻了多個數據的時候，這些來自同一對象的數據當然具有相對不同對象數據更高的均質性。</li>
<li>同一所學校的學生的成績或內部的相關性，很可能大於不同學校兩個學生之間成績的相關性。因爲同一學校的孩子可能共享某些共同的特徵，比如說相似的家庭經濟背景，或者是同樣的教學內容教學老師等環境因素。這樣，來自同一所學校的孩子的成績很可能就會更加相似。</li>
<li>至於說家庭數據就更加典型了。來自同一家庭的兄弟姐妹，有着極強的相關性，因爲他們共享着遺傳因素，或者是相似的家庭教育/飲食/生活習慣等環境因素。</li>
<li>同一個體身上的縱向 (時間) 隨訪數據很顯然會比不同患者有更強的內部相關性。</li>
</ol>
<p>目前位置介紹的這些常見實例中，可以發現它們有一個共通點。就是這些數據其實內部是有分層結構的 (hierarchy)。這些數據中，都有一個最底層單元 (elementary units/level 1)，還有一個聚合單元 (aggregate units/level 2)，聚合單元常被命名爲層級 (cluster)。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Hier01tab00">表 58.1: </span>Hierarchy in the data (5 examples in Chapter 1)
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Level
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Aggregate
</th>
<th style="text-align:left;">
Elementary
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
hospitals
</td>
<td style="text-align:left;">
patients
</td>
</tr>
<tr>
<td style="text-align:left;">
individuals
</td>
<td style="text-align:left;">
PEFR measures
</td>
</tr>
<tr>
<td style="text-align:left;">
schools
</td>
<td style="text-align:left;">
pupils
</td>
</tr>
<tr>
<td style="text-align:left;">
mothers
</td>
<td style="text-align:left;">
children
</td>
</tr>
<tr>
<td style="text-align:left;">
children
</td>
<td style="text-align:left;">
visits
</td>
</tr>
</tbody>
</table>
<p>正如表格 <a href="#tab:Hier01tab00">58.1</a> 總結的那樣，這些數據中存在這層級結構，這種數據被稱爲分層數據 (hierarchical)，或者叫嵌套式數據 (nested data)。根據你所在的知識領域，它可能還被命名爲多層結構數據 (multilevel and clustered data)。在一些研究中，你可能會遇見從實驗設計階段就存在分層結構的數據，比如使用分層抽樣 (multistage sampling) 的設計的實驗等。這樣的實驗設計最常在人口學，社會學的研究中看到。在大多數醫學研究中，每個數據點 (observation point, level 1)，所屬的層 (cluster) 本身可能是我們感興趣的研究點 (例如同屬於一個家庭，相同母親的後代)，又或者是同一個人/患者的隨着時間推移的隨訪健康狀態 (如生長曲線，體重變化，疾病康復情況)。</p>
<p>如果用前面用過的 圖 <a href="#fig:Hier01-6">58.6</a> 的生長曲線做例子，那麼每個被調查的兒童，就是該數據的第二級層，每個隨訪時刻測量的體重數據，則是觀察的數據點。這個數據還有一個特點是，觀察數據點是有前後的 (時間) 順序的，這是一個典型的<strong>縱向研究數據 (longitudinal data)</strong>。</p>
</div>
<div id="數據有依賴性導致的結果" class="section level2">
<h2><span class="header-section-number">58.3</span> 數據有依賴性導致的結果</h2>
<p>如果你手頭的數據，結構上是一種嵌套式結構數據，那麼任何無視了這一點作出的統計學推斷都是有瑕疵的。相互之間互不獨立這一特質，需要通過一種新的手段，把嵌套式的數據結構考慮進統計學模型裏來。</p>
<p>在一些情況下，數據的嵌套式結構可能可以被忽略掉，但是其結果是導致統計學的估計變得十分低效 (inefficient procedure)。你可能會聽說過一般化估計公式 (generalized estimating equations)，是其中一種備擇手段，因爲在這一公式中，你需要人爲地指定數據與數據之間可能的依賴關系是怎樣的。</p>
<p>其實，即使有人真的在分析過程中忽略了數據本身的嵌套式結構，他會發現最終在描述分析結果的時候，還是無法避免這一嚴重的問題。另外一些統計學家可能記得在穩健統計學法中，三明治標準誤估計法也是可以供選擇的一種處理相關數據的手段。</p>
</div>
<div id="邊際模型和條件模型-marginal-and-conditional-models" class="section level2">
<h2><span class="header-section-number">58.4</span> 邊際模型和條件模型 marginal and conditional models</h2>
<p>邊際模型和條件模型的概念其實不是分層模型特有的，卻在分析分層數據模型時十分有用。假如，對於某個結果變量 <span class="math inline">\(Y\)</span> 有它如下的回歸模型，其中我們把某個單一的共變量 <span class="math inline">\(Z\)</span> 從模型中分離出來，加以特別關注:</p>
<p><span class="math display">\[
g\{ \text{E}(Y|\textbf{X},Z) \} = \beta\textbf{X} +\gamma Z
\]</span></p>
<p>這是一個典型的條件模型，它描述了結果變量 <span class="math inline">\(Y\)</span> 的期望是以怎樣的<strong>條件</strong>和解釋變量 <span class="math inline">\(\textbf{X},Z\)</span> 之間建立關系的。每個解釋變量的回歸系數，其含義都是<strong>以其他同一模型中的共變量不變的條件下</strong>，和結果變量之間的關系。經過這樣的解讀，你會知道，其實本統計學教程目前爲止遇見過的所有的回歸模型都是條件模型。如果此時我們反過來思考，把上述模型中單獨分離出來的單一共變量 <span class="math inline">\(Z\)</span> 對於結果變量 <span class="math inline">\(Y\)</span> 均值的影響合並起來 (對共變量 <span class="math inline">\(Z\)</span> 積分即可)，此時我們得到的就是共變量 <span class="math inline">\(\textbf{X}\)</span> 和結果變量 <span class="math inline">\(Y\)</span> 之間，關於 <span class="math inline">\(Z\)</span> 的邊際模型 (Marginal model):</p>
<p><span class="math display">\[
\text{E}_Z\{ \text{E}(Y|\textbf{X}, Z) \} = \text{E}_Z\{ g^{-1}(\beta\textbf{X} + \gamma Z) \} \\
\text{Where } \text{E}(Z) = 0
\]</span></p>
<p>用<strong>線性回歸</strong>來舉例:</p>
<p><span class="math display">\[
\text{E}(Y| \textbf{X}, Z) = \beta\textbf{X} + \gamma Z
\]</span></p>
<p>那麼此時共變量 <span class="math inline">\(\textbf{X}\)</span> 的邊際模型回歸系數 <span class="math inline">\(\beta\)</span> 的含義，和條件模型時的回歸系數其實是相同的含義:</p>
<p><span class="math display">\[
\text{E}_Z\{\text{E}(Y|\textbf{X},Z)\} = \text{E}_Z(\beta\textbf{X} + \gamma Z) = \beta\textbf{X} + \gamma\text{E}(Z) = \beta\textbf{X}
\]</span></p>
<p>爲什麼這裏的邊際模型對於分層數據來說很重要呢？答案在於，嵌套式數據中，我們常常關心那第二個階層 (重復測量某個指標的患者，學生成績數據中的學校層級，等) 在它所在的那個階層中和結果變量之間的平均關系。(In models for hierarchical data we often use level effects to represent what is common among observations from one “cluster” or “group”. We may then want marginal conclusions: we need to average over these effects).</p>
<div id="標記法-notation" class="section level3">
<h3><span class="header-section-number">58.4.1</span> 標記法 notation</h3>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span> 標記第 <span class="math inline">\(j\)</span> 層的第 <span class="math inline">\(i\)</span> 個個體;</li>
<li><span class="math inline">\(i = 1, \cdots, n_j\)</span> 表示第 <span class="math inline">\(j\)</span> 層中共有 <span class="math inline">\(n_j\)</span> 個個體 (elements);</li>
<li><span class="math inline">\(j = 1, \cdots, J\)</span> 表示數據共有 <span class="math inline">\(J\)</span> 個第二階層 (clusters);</li>
<li><span class="math inline">\(N = \sum_{j=1}^J n_j\)</span> 表示總體樣本量等於各個階層樣本量之和;</li>
<li>特殊情況: 如果每個階層的個體數相同 <span class="math inline">\(n\)</span>，<span class="math inline">\(N=nJ\)</span>，這樣的數據被叫做均衡數據 (balanced data)。</li>
</ul>
</div>
<div id="合並每個階層" class="section level3">
<h3><span class="header-section-number">58.4.2</span> 合並每個階層</h3>
<p>過去常見的總結嵌套式數據的手段只是把每層數據取平均值，這樣的方法簡單粗暴但是偶爾是可以接受的，只要你能夠接受如此處理數據可能帶來的如下後果:</p>
<ul>
<li>各層數據均值，其可靠程度 (方差) 隨着各層的樣本量不同而不同 (depends on the number of elementary units per cluster);</li>
<li>變量的含義發生改變。如果是使用層水平 (cluster level) 的數據，本來測量給個體的那些變量，就變成了<strong>層的變量</strong>，從此作出的任何統計學推斷，只能限制在層水平 (ecological fallacy, as correlations at the macro level cannot be used to make assertions at the micro level);</li>
<li>由於無視了層內個體數據，導致大量信息損失。</li>
</ul>
<p>此處我們借用 <span class="citation">(Snijders and Bosker <a href="#ref-Snijders1999" role="doc-biblioref">1999</a>)</span> 書中第 28 頁的人造數據，如下表</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Artificial data
</caption>
<thead>
<tr>
<th style="text-align:center;">
Cluster <span class="math inline">\((j)\)</span>
</th>
<th style="text-align:center;">
id <span class="math inline">\((i)\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(Y\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\bar{X}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\bar{Y}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
4
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
2
</td>
</tr>
</tbody>
</table>
<p>這個表中的人造數據，其結構是一目了然的，它的第二層級數量是 5，每層的個體數量是 2。這是一個平衡數據。由於這是個我們人爲模擬的數據，圖 <a href="#fig:artificialdata00">58.7</a> 也顯示它沒有隨機誤差，所有數據都在各自的直線上。</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb703-1" title="1">dt &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;backupfiles/hierexample.csv&quot;</span>, <span class="dt">header =</span> T)</a>
<a class="sourceLine" id="cb703-2" title="2"><span class="kw">names</span>(dt) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Cluster&quot;</span>, <span class="st">&quot;id&quot;</span>, <span class="st">&quot;X&quot;</span>, <span class="st">&quot;Y&quot;</span>, <span class="st">&quot;Xbar&quot;</span>, <span class="st">&quot;Ybar&quot;</span>)</a>
<a class="sourceLine" id="cb703-3" title="3">dt<span class="op">$</span>Cluster &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dt<span class="op">$</span>Cluster)</a>
<a class="sourceLine" id="cb703-4" title="4"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb703-5" title="5"></a>
<a class="sourceLine" id="cb703-6" title="6"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y, <span class="dt">shape =</span> Cluster, <span class="dt">colour =</span> Cluster)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb703-7" title="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb703-8" title="8">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb703-9" title="9">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb703-10" title="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb703-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb703-12" title="12"><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="dt">legend.direction =</span> <span class="st">&quot;horizontal&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata00"></span>
<img src="bookdown_files/figure-html/artificialdata00-1.png" alt="Artificial data: scatter of clustered data" width="80%" />
<p class="caption">
圖 58.7: Artificial data: scatter of clustered data
</p>
</div>
<ul>
<li>如果我們無視其分層數據的嵌套式結構，把每個數據都看作是獨立的樣本，擬合一個<strong>整體回歸 (total regression) 圖 <a href="#fig:artificialdata01">58.8</a></strong>:</li>
</ul>
<p><span class="math display">\[
\hat Y_{ij} = 5.33 - 0.33 X_{ij}
\]</span></p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb704-1" title="1"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb704-2" title="2"></a>
<a class="sourceLine" id="cb704-3" title="3"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">shape =</span> <span class="dv">23</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb704-4" title="4"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb704-5" title="5"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb704-6" title="6">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb704-7" title="7">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb704-8" title="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb704-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb704-10" title="10"><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="dt">legend.direction =</span> <span class="st">&quot;horizontal&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata01"></span>
<img src="bookdown_files/figure-html/artificialdata01-1.png" alt="Artificial data: Total regression" width="80%" />
<p class="caption">
圖 58.8: Artificial data: Total regression
</p>
</div>
<ul>
<li>如果我們只保留層級數據本身，求了變量 <span class="math inline">\(X,Y\)</span> 在每層的均值的話，就得到了<strong>層間回歸 (between regression) 圖 <a href="#fig:artificialdata02">58.9</a></strong> – 變量 <span class="math inline">\(X,Y\)</span> 之間的回歸直線的斜率變得更大了:</li>
</ul>
<p><span class="math display">\[
\hat{\bar{Y}}_j = 8.0 - 1.0 \bar{X}_j
\]</span></p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb705-1" title="1"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>)</a>
<a class="sourceLine" id="cb705-2" title="2"></a>
<a class="sourceLine" id="cb705-3" title="3"><span class="kw">ggplot</span>(dt, <span class="kw">aes</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">23</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb705-4" title="4"><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-5" title="5"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">8</span>, <span class="dt">slope =</span> <span class="dv">-1</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb705-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Xbar, <span class="dt">y=</span>Ybar, <span class="dt">size =</span> <span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-7" title="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb705-8" title="8">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb705-9" title="9">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb705-10" title="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Y&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb705-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:artificialdata02"></span>
<img src="bookdown_files/figure-html/artificialdata02-1.png" alt="Artificial data: scatter of clustered data" width="80%" />
<p class="caption">
圖 58.9: Artificial data: scatter of clustered data
</p>
</div>
</div>
<div id="生物學悖論-ecological-fallacy" class="section level3">
<h3><span class="header-section-number">58.4.3</span> 生物學悖論 ecological fallacy</h3>
<p>生物學悖論常見於我們認爲某分層數據中層級變量之間的關系，同樣適用與層級中的個體之間: 例如比較 A 國 和 B 國之間心血管疾病的發病率，發現 A 國國民食鹽平均攝入量高於 B 國，很多人可能就會下結論說食鹽攝入量高的個體，心血管疾病發病的危險度較高。然而，這樣的推論很多時候是錯誤的。</p>
<p>曾經在 <span class="citation">(Robinson <a href="#ref-Robinson1950" role="doc-biblioref">1950</a>)</span> 論文中舉過的著名例子: 該研究調查美國每個州的移民比例，和該州相應的識字率之間的關系。研究者發現，移民比例較高的州，其識字率也較高 (相關系數 0.53)。由此就有人下結論說移民越多，那個州的教育水平會比較高。但是實際情況是，把每個個體的受教育水平和該個體本身是不是移民做了相關系數分析之後發現，這個關系其實是負相關 (-0.11)。所以說在州的水平作出的統計學推斷-移民多的州受教育水平高-是不正確的。之所以在州水平發現移民比例和受教育水平之間的正關系，是因爲移民傾向於居住在教育水平本來就比較高的本土出生美國人的州。</p>
</div>
<div id="分解層級數據" class="section level3">
<h3><span class="header-section-number">58.4.4</span> 分解層級數據</h3>
<p>如果是分析最初層級數據 (level 1) 的話，我們還需要考慮下列一些問題:</p>
<ul>
<li>當心數據被多次利用</li>
</ul>
<p>如果我們關心的變量其實是在第二層級的 (level 2/cluster level)，但是你卻把它當作是第一層級的數據，就會引起<strong>數據很多</strong>的錯覺，因爲同一層的個體他們的層屬變量都是一樣的，你擁有的數據其實並沒有你想的那麼多。</p>
<p>前文中用過的 GCSE 數據其實是一個很好的例子，下表中歸納了調查的學校類型 (男校，女校或者混合校)，以及按照每個學生個人所屬學校類型的總結，可以看出，當你嘗試使用個人 (elementary level) 水平的數據分析實際上是第二層級數據的特性時，你會被誤導。因爲個人數據告訴你， 34% 的學生在女校學習，然而正確的分析法應該是，學校中有 31% 的學校是女校。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Aggregated and disaggregated
</caption>
<thead>
<tr>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
School type
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Cluster Level
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Elementary Level
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
N
</th>
<th style="text-align:center;">
%
</th>
<th style="text-align:center;">
N
</th>
<th style="text-align:center;">
%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
mixed
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
2169
</td>
<td style="text-align:center;">
53
</td>
</tr>
<tr>
<td style="text-align:center;">
boys only
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
513
</td>
<td style="text-align:center;">
13
</td>
</tr>
<tr>
<td style="text-align:center;">
girls only
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
1377
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
4059
</td>
<td style="text-align:center;">
100
</td>
</tr>
</tbody>
</table>
<ul>
<li>分層數據分析法</li>
</ul>
<p>有人會說，既然如此，那麼我們就把數據放在每層當中分析就好了 (stratified analyses)。還是用前文中用過的人造 5 層數據來說明這樣做的弊端。前面用了兩種方法 (total regression, between regression) 來總結這個 5 層的人造數據 <a href="#fig:artificialdata02">58.9</a>。最後一種分析此數據的方法是，把 5 層數據分開分別做回歸線如圖 <a href="#fig:artificialdata03">58.10</a>。等同於我們的對數據擬合五次下面的回歸方程:</p>
<p><span class="math display">\[
\hat Y_{ij} - \bar{Y}_j = \beta(X_{ij} - \bar{X}_j)
\]</span></p>
<p>這種模型被叫做<strong>層內回歸 (within regression)</strong>。這 5 個線性回歸的斜率都是 1，是五條不同截距的平行直線。因爲我們自己編造的數據的緣故，現實數據不太可能恰好所有層內回歸的斜率都是完全相同的。這其實也是曾內回歸法的一個默認前提 – 每層數據中解釋變量和結果變量之間的關系是相同的。</p>
<div class="figure" style="text-align: center"><span id="fig:artificialdata03"></span>
<img src="bookdown_files/figure-html/artificialdata03-1.png" alt="Artificial data: within cluster regressions" width="80%" />
<p class="caption">
圖 58.10: Artificial data: within cluster regressions
</p>
</div>
</div>
<div id="固定效應模型-fixed-effect-model" class="section level3">
<h3><span class="header-section-number">58.4.5</span> 固定效應模型 fixed effect model</h3>
<p>無論數據中的分層結構是否有現實意義 (如果說是五種不同的民族，那就有顯著的現實意義)，在回歸模型中都<strong>有必要考慮這個分層結構對數據的變異的貢獻</strong> (the contribution of the clusters to the data variation)。</p>
<p>線性回歸章節中我們使用的是五個啞變量來代表不同組別加以分析:</p>
<p><span class="math display">\[
Y_{ij} = \alpha_1 I_{i, j = 1} + \alpha_2 I_{i, j=2} + \cdots + \alpha_5 I_{i, j=5} + \beta_1X_{ij} + \varepsilon_{ij}
\]</span></p>
<p>其中 <span class="math inline">\(j\)</span> 是所屬層級編號。該模型中的 <span class="math inline">\(\varepsilon_{ij}\)</span> 被認爲服從均值爲零，方差爲 <span class="math inline">\(\sigma_{\varepsilon}^2\)</span> 的正態分布。該模型也可以簡寫爲:</p>
<p><span class="math display">\[
Y_{ij} = \alpha_j + \beta_1X_{ij} + \epsilon_{ij}
\]</span>
一樣一預案
這樣的模型在等級線性回歸模型中被認爲是<strong>固定效應模型 fixed effect model</strong>。它其實是默認給五個層級五個不同的截距，每層內部 <span class="math inline">\(X,Y\)</span> 之間的關系 (斜率) 則被認爲是完全相同的 (namely the within cluster models are the same)。</p>
<p>本課剛開始的例子中有個數據是來自 6 所不同醫院 72 名患者的收縮期血壓的數據。我們現在來分析這些人中血壓和年齡之間的關系。下面的散點圖重現了六所醫院的72名患者的血壓和年齡。</p>
<pre><code>## Warning: New theme missing the following elements: axis.ticks.length.x, axis.ticks.length.x.top,
## axis.ticks.length.x.bottom, axis.ticks.length.y, axis.ticks.length.y.left, axis.ticks.length.y.right</code></pre>
<div class="figure" style="text-align: center"><span id="fig:Hier01-7"></span>
<img src="bookdown_files/figure-html/Hier01-7-1.png" alt="SBP versus age: different symbols identify the six hospitals" width="90%" />
<p class="caption">
圖 58.11: SBP versus age: different symbols identify the six hospitals
</p>
</div>
<p>下面在 R 裏擬合這個固定效應模型:</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb707-1" title="1">Bp &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/bp.dta&quot;</span>)</a>
<a class="sourceLine" id="cb707-2" title="2"></a>
<a class="sourceLine" id="cb707-3" title="3">Bp<span class="op">$</span>hosp &lt;-<span class="st"> </span><span class="kw">as.factor</span>(Bp<span class="op">$</span>hosp)</a>
<a class="sourceLine" id="cb707-4" title="4">Bp &lt;-<span class="st"> </span>Bp <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb707-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_age =</span> age <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(age))</a>
<a class="sourceLine" id="cb707-6" title="6"><span class="co"># 通過指定截距爲零，獲取每個醫院的回歸線的截距</span></a>
<a class="sourceLine" id="cb707-7" title="7">Model0 &lt;-<span class="st"> </span><span class="kw">lm</span>(bp <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st">  </span>c_age <span class="op">+</span><span class="st"> </span>hosp, <span class="dt">data =</span> Bp) </a>
<a class="sourceLine" id="cb707-8" title="8"></a>
<a class="sourceLine" id="cb707-9" title="9"><span class="kw">summary</span>(Model0)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bp ~ 0 + c_age + hosp, data = Bp)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -34.7803  -9.8106  -0.5285   7.4000  55.5287 
## 
## Coefficients:
##        Estimate Std. Error t value Pr(&gt;|t|)    
## c_age   1.00223    0.43766   2.290  0.02528 *  
## hosp1 139.15421    5.73015  24.285  &lt; 2e-16 ***
## hosp2 130.21017    5.86957  22.184  &lt; 2e-16 ***
## hosp3 129.58146    5.66881  22.859  &lt; 2e-16 ***
## hosp4 124.00188    5.70326  21.742  &lt; 2e-16 ***
## hosp5 114.58859    5.70289  20.093  &lt; 2e-16 ***
## hosp6 115.79702    5.85632  19.773  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19.136 on 65 degrees of freedom
## Multiple R-squared:  0.97954,    Adjusted R-squared:  0.97733 
## F-statistic: 444.46 on 7 and 65 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb709-1" title="1"><span class="co"># 先生成一個新的醫院變量 hops1 = 1。然後使用偏 F 檢驗法</span></a>
<a class="sourceLine" id="cb709-2" title="2"><span class="co"># 檢驗控制了患者的年齡以後，這六所醫院的截距是否各自不相同。</span></a>
<a class="sourceLine" id="cb709-3" title="3">Bp<span class="op">$</span>hosp1 &lt;-<span class="st"> </span>Bp<span class="op">$</span>hosp[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb709-4" title="4">mod2 &lt;-<span class="st"> </span><span class="kw">lm</span>(bp <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st">  </span>c_age <span class="op">+</span><span class="st"> </span><span class="kw">as.numeric</span>(hosp1), <span class="dt">data =</span> Bp)</a>
<a class="sourceLine" id="cb709-5" title="5"><span class="kw">anova</span>(Model0, mod2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: bp ~ 0 + c_age + hosp
## Model 2: bp ~ 0 + c_age + as.numeric(hosp1)
##   Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)  
## 1     65 23801.9                                
## 2     70 27751.6 -5  -3949.73 2.15725 0.069638 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>偏 F 檢驗法給出的結果 <span class="math inline">\(F(5, 65) = 2.16, P = 0.07\)</span>，所以說，數據其實告訴我們，調整了年齡之後，這六所醫院患者中年齡和血壓之間關系的回歸線有不同的截距。</p>
</div>
</div>
<div id="簡單線性迴歸複習" class="section level2">
<h2><span class="header-section-number">58.5</span> 簡單線性迴歸複習</h2>
<p>滾回線性回歸章節 <a href="#lm">26</a>。</p>
</div>
<div id="練習題-7" class="section level2">
<h2><span class="header-section-number">58.6</span> 練習題</h2>
<div id="數據" class="section level3">
<h3><span class="header-section-number">58.6.1</span> 數據</h3>
<ol style="list-style-type: decimal">
<li>High-School-and-Beyond 數據 <br> 本數據來自1982年美國國家教育統計中心 (National Center for Education Statistics, NCES) 對美國公立學校和天主教會學校的一項普查。曾經在 Hierarchical Linear Model <span class="citation">(Raudenbush and Bryk <a href="#ref-Raudenbush2002" role="doc-biblioref">2002</a>)</span> 一書中作爲範例使用。其數據的變量名和各自含義如下：</li>
</ol>
<pre><code>minority           indicatory of student ethinicity (1 = minority, 0 = other)
female             pupil&#39;s gender
ses                standardized socio-economic status score
mathach            measure of mathematics achievement
size               school&#39;s total number of pupils
sector             school&#39;s sector: 1 = catholic, 0 = not catholic
schoolid           school identifier</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>PEFR 數據 <br> 數據本身是 17 名研究對象用兩種不同的測量方法測量兩次每個人的最大呼氣流速 (peak-expiratory-flow rate, PEFR)。最早在1986年的柳葉刀雜誌發表 <span class="citation">(Bland and Altman <a href="#ref-Bland1986" role="doc-biblioref">1986</a>)</span>。兩種測量法的名稱分別是 “Standard Wright” 和 “Mini Wright” peak flow meter。變量名和個字含義如下：</li>
</ol>
<pre><code>id                 participant identifier
wp1                standard wright measure at 1st occasion
wp2                standard wright measure at 2nd occasion
wm1                mini wright measure at 1st occasion
wm2                mini wright measure at 2nd occasion</code></pre>
</div>
<div id="問題" class="section level3">
<h3><span class="header-section-number">58.6.2</span> 問題</h3>
</div>
<div id="將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵" class="section level3">
<h3><span class="header-section-number">58.6.3</span> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</h3>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb713-1" title="1">hsb_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/hsb_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb713-2" title="2"><span class="kw">length</span>(<span class="kw">unique</span>(hsb_selected<span class="op">$</span>schoolid)) <span class="co">## number of school = 160</span></a></code></pre></div>
<pre><code>## [1] 160</code></pre>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb715-1" title="1"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb715-2" title="2">hsb &lt;-<span class="st"> </span>hsb_selected[<span class="op">!</span><span class="kw">duplicated</span>(hsb_selected<span class="op">$</span>schoolid), ]</a>
<a class="sourceLine" id="cb715-3" title="3"></a>
<a class="sourceLine" id="cb715-4" title="4"><span class="co">## about 44 % of the schools are Catholic schools</span></a>
<a class="sourceLine" id="cb715-5" title="5"><span class="kw">with</span>(hsb, <span class="kw">tab1</span>(sector, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## sector : 
##         Frequency Percent Cum. percent
## 0              90   56.25        56.25
## 1              70   43.75       100.00
##   Total       160  100.00       100.00</code></pre>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb717-1" title="1"><span class="co">## among all the pupils, about 53% are females</span></a>
<a class="sourceLine" id="cb717-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(female, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## female : 
##         Frequency Percent Cum. percent
## 0            3390   47.18        47.18
## 1            3795   52.82       100.00
##   Total      7185  100.00       100.00</code></pre>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb719-1" title="1"><span class="co">## among all the pupils, about 27.5% are from ethnic minorities</span></a>
<a class="sourceLine" id="cb719-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## minority : 
##         Frequency Percent Cum. percent
## 0            5211   72.53        72.53
## 1            1974   27.47       100.00
##   Total      7185  100.00       100.00</code></pre>
</div>
<div id="爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值" class="section level3">
<h3><span class="header-section-number">58.6.4</span> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</h3>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb721-1" title="1">hsb5 &lt;-<span class="st"> </span><span class="kw">subset</span>(hsb_selected, schoolid <span class="op">&lt;</span><span class="st"> </span><span class="dv">1320</span>)</a>
<a class="sourceLine" id="cb721-2" title="2">Mean_ses_math &lt;-<span class="st"> </span><span class="kw">ddply</span>(hsb5,<span class="op">~</span>schoolid,summarise,<span class="dt">mean_ses=</span><span class="kw">mean</span>(ses),<span class="dt">mean_math=</span><span class="kw">mean</span>(mathach))</a>
<a class="sourceLine" id="cb721-3" title="3"><span class="co">## the mean SES score ranges from -0.4255 to +0.5280</span></a>
<a class="sourceLine" id="cb721-4" title="4"><span class="co">## the mean Maths score ranges from 7.636 to 16.255</span></a>
<a class="sourceLine" id="cb721-5" title="5">Mean_ses_math</a></code></pre></div>
<pre><code>##   schoolid    mean_ses  mean_math
## 1     1224 -0.43438298  9.7154468
## 2     1288  0.12159999 13.5108000
## 3     1296 -0.42550000  7.6359583
## 4     1308  0.52800000 16.2554999
## 5     1317  0.34533333 13.1776875</code></pre>
</div>
<div id="先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中" class="section level3">
<h3><span class="header-section-number">58.6.5</span> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</h3>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb723-1" title="1"><span class="co">## plot the scatter of mathach and ses among these 5 schools</span></a>
<a class="sourceLine" id="cb723-2" title="2"></a>
<a class="sourceLine" id="cb723-3" title="3"><span class="kw">ggplot</span>(hsb5, <span class="kw">aes</span>(<span class="dt">x =</span> ses, <span class="dt">y =</span> mathach)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb723-4" title="4"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb723-5" title="5"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb723-6" title="6">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb723-7" title="7">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb723-8" title="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;SES&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math achievement&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb723-9" title="9"><span class="st">  </span><span class="kw">xlim</span>(<span class="op">-</span><span class="fl">2.05</span>, <span class="fl">2.05</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb723-10" title="10"><span class="st">  </span><span class="kw">ylim</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">30</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb723-11" title="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mathses"></span>
<img src="bookdown_files/figure-html/mathses-1.png" alt="Scatter plot of SES and math achievements among all pupils from first 5 schools, assuming that they are all independent" width="80%" />
<p class="caption">
圖 58.12: Scatter plot of SES and math achievements among all pupils from first 5 schools, assuming that they are all independent
</p>
</div>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb724-1" title="1">Total_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5)</a>
<a class="sourceLine" id="cb724-2" title="2"><span class="co">## the total regression model gives an estimated regression coefficient for the SES</span></a>
<a class="sourceLine" id="cb724-3" title="3"><span class="co">## of each pupil equal to 3.31 (SE=0.66)</span></a>
<a class="sourceLine" id="cb724-4" title="4"><span class="kw">summary</span>(Total_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses, data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -15.23022  -5.08316  -0.68614   5.11170  14.68513 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 11.45652    0.47342 24.1997 &lt; 2.2e-16 ***
## ses          3.30696    0.66021  5.0089 1.267e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.4708 on 186 degrees of freedom
## Multiple R-squared:  0.11886,    Adjusted R-squared:  0.11412 
## F-statistic:  25.09 on 1 and 186 DF,  p-value: 1.2667e-06</code></pre>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb726-1" title="1">hsb5<span class="op">$</span>Pred_T &lt;-<span class="st"> </span>Total_reg<span class="op">$</span>fitted.values <span class="co"># save the fitted values to the dataset</span></a></code></pre></div>
</div>
<div id="用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model" class="section level3">
<h3><span class="header-section-number">58.6.6</span> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</h3>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb727-1" title="1">Btw_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mean_math <span class="op">~</span><span class="st"> </span>mean_ses, <span class="dt">data =</span> Mean_ses_math)</a>
<a class="sourceLine" id="cb727-2" title="2"><span class="co">## the regression model for the school level variables (between model) gives</span></a>
<a class="sourceLine" id="cb727-3" title="3"><span class="co">## an estimated regression coefficient of 7.29 (SE=1.41)</span></a>
<a class="sourceLine" id="cb727-4" title="4"><span class="kw">summary</span>(Btw_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mean_math ~ mean_ses, data = Mean_ses_math)
## 
## Residuals:
##        1        2        3        4        5 
##  1.02010  0.76212 -1.12415  0.54401 -1.20209 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 11.86216    0.55664 21.3102 0.0002261 ***
## mean_ses     7.29039    1.40703  5.1814 0.0139557 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.2418 on 3 degrees of freedom
## Multiple R-squared:  0.89949,    Adjusted R-squared:  0.86598 
## F-statistic: 26.847 on 1 and 3 DF,  p-value: 0.013956</code></pre>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb729-1" title="1">Mean_ses_math<span class="op">$</span>Pred_B &lt;-<span class="st"> </span>Btw_reg<span class="op">$</span>fitted.values <span class="co"># save the fitted values to the dataset</span></a></code></pre></div>
</div>
<div id="分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型" class="section level3">
<h3><span class="header-section-number">58.6.7</span> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</h3>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb730-1" title="1">Within_schl1 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1224</span>,])</a>
<a class="sourceLine" id="cb730-2" title="2">Within_schl2 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1288</span>,])</a>
<a class="sourceLine" id="cb730-3" title="3">Within_schl3 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1296</span>,])</a>
<a class="sourceLine" id="cb730-4" title="4">Within_schl4 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1308</span>,])</a>
<a class="sourceLine" id="cb730-5" title="5">Within_schl5 &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses, <span class="dt">data =</span> hsb5[hsb5<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span><span class="dv">1317</span>,])</a>
<a class="sourceLine" id="cb730-6" title="6"><span class="co"># the within school regressions gives estimated slopes which have a mean of 1.65</span></a>
<a class="sourceLine" id="cb730-7" title="7"><span class="co"># and which ranges between 0.126 and 3.255</span></a>
<a class="sourceLine" id="cb730-8" title="8"><span class="kw">summary</span>(<span class="kw">c</span>(Within_schl1<span class="op">$</span>coefficients[<span class="dv">2</span>], Within_schl2<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb730-9" title="9">      Within_schl3<span class="op">$</span>coefficients[<span class="dv">2</span>], Within_schl4<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb730-10" title="10">      Within_schl5<span class="op">$</span>coefficients[<span class="dv">2</span>]))</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.12602 1.07596 1.27391 1.64799 2.50858 3.25545</code></pre>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb732-1" title="1"><span class="co"># the SEs ranging between 1.21 and 3.00</span></a>
<a class="sourceLine" id="cb732-2" title="2"><span class="kw">summary</span>(<span class="kw">c</span>(<span class="kw">summary</span>(Within_schl1)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-3" title="3">          <span class="kw">summary</span>(Within_schl2)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-4" title="4">          <span class="kw">summary</span>(Within_schl3)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-5" title="5">          <span class="kw">summary</span>(Within_schl4)<span class="op">$</span>coefficients[<span class="dv">4</span>],</a>
<a class="sourceLine" id="cb732-6" title="6">          <span class="kw">summary</span>(Within_schl5)<span class="op">$</span>coefficients[<span class="dv">4</span>]))</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  1.2090  1.4359  1.7652  1.8987  2.0797  3.0034</code></pre>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb734-1" title="1">hsb5<span class="op">$</span>Pred_W &lt;-<span class="st"> </span><span class="kw">c</span>(Within_schl1<span class="op">$</span>fitted.values, Within_schl2<span class="op">$</span>fitted.values,</a>
<a class="sourceLine" id="cb734-2" title="2">      Within_schl3<span class="op">$</span>fitted.values, Within_schl4<span class="op">$</span>fitted.values,</a>
<a class="sourceLine" id="cb734-3" title="3">      Within_schl5<span class="op">$</span>fitted.values) <span class="co">## save the predicted value into the dataset</span></a></code></pre></div>
</div>
<div id="比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同" class="section level3">
<h3><span class="header-section-number">58.6.8</span> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</h3>
<ul>
<li>總體模型 (Total regression model) 實際上無視了學生的性別，種族等可能帶來的混雜效果；</li>
<li>學校間模型 (Between model) 估計的實際上是<strong>SES均值</strong>每增加一個單位，與之對應的<strong>數學平均成績</strong>的改變量，<strong>這個模型絕對不可用與評估個人的 SES 與數學成績之間的關係</strong>；</li>
<li>學校內模型 (Within model) 擬合的 SES 與數學成績之間的關係變得十分地不精確 (SEs are fairly large)，變化幅度也很大。</li>
</ul>
</div>
<div id="把三種模型的數學成績擬合值散點圖繪製在同一張圖內" class="section level3">
<h3><span class="header-section-number">58.6.9</span> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</h3>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb735-1" title="1">Mean &lt;-<span class="st"> </span>Mean_ses_math[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]</a>
<a class="sourceLine" id="cb735-2" title="2"><span class="kw">names</span>(Mean) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;schoolid&quot;</span>, <span class="st">&quot;ses&quot;</span>, <span class="st">&quot;Pred_W&quot;</span>)</a>
<a class="sourceLine" id="cb735-3" title="3"></a>
<a class="sourceLine" id="cb735-4" title="4"></a>
<a class="sourceLine" id="cb735-5" title="5"><span class="kw">ggplot</span>(hsb5, <span class="kw">aes</span>(<span class="dt">x =</span> ses, <span class="dt">y =</span> Pred_W, <span class="dt">group =</span> schoolid)) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-6" title="6"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-7" title="7"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> Total_reg<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">slope =</span> Total_reg<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb735-8" title="8">               <span class="dt">colour =</span> <span class="st">&quot;dark blue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-9" title="9"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> Btw_reg<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">slope =</span> Btw_reg<span class="op">$</span>coefficients[<span class="dv">2</span>],</a>
<a class="sourceLine" id="cb735-10" title="10">               <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-11" title="11"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Mean, <span class="dt">shape =</span> <span class="dv">17</span>, <span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">colour =</span> <span class="st">&quot;Red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-12" title="12"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb735-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb735-14" title="14">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb735-15" title="15">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-16" title="16"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;SES&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Fitted regression lines (Maths achievement)&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb735-17" title="17"><span class="st">  </span><span class="kw">xlim</span>(<span class="op">-</span><span class="fl">2.05</span>, <span class="fl">2.05</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb735-18" title="18"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">5</span>, <span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb735-19" title="19"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb735-20" title="20"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>,</a>
<a class="sourceLine" id="cb735-21" title="21">  <span class="dt">hjust =</span> <span class="dv">0</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">caption =</span> <span class="st">&quot;Black dash line: Within regression model;</span></a>
<a class="sourceLine" id="cb735-22" title="22"><span class="st">Blue solid line: Total regression model;</span></a>
<a class="sourceLine" id="cb735-23" title="23"><span class="st">Red solid line: Between regression model;</span></a>
<a class="sourceLine" id="cb735-24" title="24"><span class="st">Red triangle: School mean values&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mathses-3models"></span>
<img src="bookdown_files/figure-html/mathses-3models-1.png" alt="High-school-and-beyond data: Predicted values by Total, Between, and Within regression models" width="80%" />
<p class="caption">
圖 58.13: High-school-and-beyond data: Predicted values by Total, Between, and Within regression models
</p>
</div>
</div>
<div id="用這-5-個學校的數據擬合一個固定效應線性迴歸模型" class="section level3">
<h3><span class="header-section-number">58.6.10</span> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</h3>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb736-1" title="1">Fixed_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(schoolid), <span class="dt">data =</span> hsb5)</a>
<a class="sourceLine" id="cb736-2" title="2"></a>
<a class="sourceLine" id="cb736-3" title="3"><span class="co">## Fitting a fixed effect model to these data is equivalent to forcing</span></a>
<a class="sourceLine" id="cb736-4" title="4"><span class="co">## a common slope onto the five within regression models. It gives an</span></a>
<a class="sourceLine" id="cb736-5" title="5"><span class="co">## estimated slope of 1.789 (SE=0.76), close to their average of 1.64799.</span></a>
<a class="sourceLine" id="cb736-6" title="6"><span class="co">## Note that controlling for female, minority, and sector but not for</span></a>
<a class="sourceLine" id="cb736-7" title="7"><span class="co">## schoolid leads to roughly the same estimate (slope = 1.68, SE=0.75)</span></a>
<a class="sourceLine" id="cb736-8" title="8"></a>
<a class="sourceLine" id="cb736-9" title="9"><span class="kw">summary</span>(Fixed_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses + factor(schoolid), data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -13.97593  -4.19683  -0.75189   5.22088  16.38133 
## 
## Coefficients:
##                      Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)          10.49254    0.96761 10.8438 &lt; 2.2e-16 ***
## ses                   1.78896    0.75939  2.3558  0.019548 *  
## factor(schoolid)1288  2.80072    1.60041  1.7500  0.081803 .  
## factor(schoolid)1296 -2.09538    1.27973 -1.6374  0.103283    
## factor(schoolid)1308  4.81839    1.81826  2.6500  0.008758 ** 
## factor(schoolid)1317  2.06736    1.41005  1.4662  0.144332    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.2362 on 182 degrees of freedom
## Multiple R-squared:  0.1992, Adjusted R-squared:  0.1772 
## F-statistic: 9.0544 on 5 and 182 DF,  p-value: 1.0512e-07</code></pre>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb738-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>minority <span class="op">+</span><span class="st"> </span>sector, <span class="dt">data =</span> hsb5))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mathach ~ ses + female + minority + sector, data = hsb5)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -13.09128  -4.17332  -0.46306   4.50807  15.33205 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 12.54543    0.86027 14.5831 &lt; 2.2e-16 ***
## ses          1.68055    0.74489  2.2561 0.0252480 *  
## female      -1.54861    0.94857 -1.6326 0.1042780    
## minority    -3.19635    0.95450 -3.3487 0.0009857 ***
## sector       3.98121    1.11941  3.5565 0.0004785 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.1696 on 183 degrees of freedom
## Multiple R-squared:  0.2119, Adjusted R-squared:  0.19467 
## F-statistic: 12.301 on 4 and 183 DF,  p-value: 7.0265e-09</code></pre>
</div>
<div id="讀入-pefr-數據" class="section level3">
<h3><span class="header-section-number">58.6.11</span> 讀入 PEFR 數據。</h3>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb740-1" title="1">pefr &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pefr.dta&quot;</span>)</a>
<a class="sourceLine" id="cb740-2" title="2"><span class="co"># the data are in wide format</span></a>
<a class="sourceLine" id="cb740-3" title="3">pefr</a></code></pre></div>
<pre><code>## # A tibble: 17 x 5
##       id   wp1   wp2   wm1   wm2
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1   494   490   512   525
##  2     2   395   397   430   415
##  3     3   516   512   520   508
##  4     4   434   401   428   444
##  5     5   476   470   500   500
##  6     6   557   611   600   625
##  7     7   413   415   364   460
##  8     8   442   431   380   390
##  9     9   650   638   658   642
## 10    10   433   429   445   432
## 11    11   417   420   432   420
## 12    12   656   633   626   605
## 13    13   267   275   260   227
## 14    14   478   492   477   467
## 15    15   178   165   259   268
## 16    16   423   372   350   370
## 17    17   427   421   451   443</code></pre>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb742-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb742-2" title="2">pefr_long &lt;-<span class="st"> </span>pefr <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb742-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb742-7" title="7">pefr_long</a></code></pre></div>
<pre><code>## # A tibble: 34 x 4
##       id occasion    wm    wp
##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1 1          512   494
##  2     1 2          525   490
##  3     2 1          430   395
##  4     2 2          415   397
##  5     3 1          520   516
##  6     3 2          508   512
##  7     4 1          428   434
##  8     4 2          444   401
##  9     5 1          500   476
## 10     5 2          500   470
## # ... with 24 more rows</code></pre>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb744-1" title="1"><span class="co">## figure shows slightly closer agreement between the repeated measures of standard Wright,</span></a>
<a class="sourceLine" id="cb744-2" title="2"><span class="co">## than between those of Mini Wright</span></a>
<a class="sourceLine" id="cb744-3" title="3"></a>
<a class="sourceLine" id="cb744-4" title="4"><span class="kw">ggplot</span>(pefr_long, <span class="kw">aes</span>(<span class="dt">x =</span> id, <span class="dt">y =</span> wp, <span class="dt">fill =</span> occasion)) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-5" title="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-6" title="6"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">mean</span>(pefr_long<span class="op">$</span>wp), <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-7" title="7"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb744-8" title="8"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">17</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb744-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb744-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb744-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb744-12" title="12"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Subject ID&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;W Measurements&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb744-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb744-14" title="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), </a>
<a class="sourceLine" id="cb744-15" title="15">  <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tworecordings"></span>
<img src="bookdown_files/figure-html/tworecordings-1.png" alt="Two recordings of PEFR taken with the standard Wright meter" width="80%" />
<p class="caption">
圖 58.14: Two recordings of PEFR taken with the standard Wright meter
</p>
</div>
</div>
<div id="求每個患者的-wp-兩次測量平均值" class="section level3">
<h3><span class="header-section-number">58.6.12</span> 求每個患者的 <code>wp</code> 兩次測量平均值</h3>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb745-1" title="1"><span class="co"># the means range from 171.5 to 644.5</span></a>
<a class="sourceLine" id="cb745-2" title="2"></a>
<a class="sourceLine" id="cb745-3" title="3"><span class="kw">with</span>(pefr_long, <span class="kw">summ</span>(wp, <span class="dt">by =</span> id, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## For id = 1 
##  obs. mean   median  s.d.   min.   max.  
##  2    492    492     2.828  490    494   
## 
## For id = 2 
##  obs. mean   median  s.d.   min.   max.  
##  2    396    396     1.414  395    397   
## 
## For id = 3 
##  obs. mean   median  s.d.   min.   max.  
##  2    514    514     2.828  512    516   
## 
## For id = 4 
##  obs. mean   median  s.d.   min.   max.  
##  2    417.5  417.5   23.335 401    434   
## 
## For id = 5 
##  obs. mean   median  s.d.   min.   max.  
##  2    473    473     4.243  470    476   
## 
## For id = 6 
##  obs. mean   median  s.d.   min.   max.  
##  2    584    584     38.184 557    611   
## 
## For id = 7 
##  obs. mean   median  s.d.   min.   max.  
##  2    414    414     1.414  413    415   
## 
## For id = 8 
##  obs. mean   median  s.d.   min.   max.  
##  2    436.5  436.5   7.778  431    442   
## 
## For id = 9 
##  obs. mean   median  s.d.   min.   max.  
##  2    644    644     8.485  638    650   
## 
## For id = 10 
##  obs. mean   median  s.d.   min.   max.  
##  2    431    431     2.828  429    433   
## 
## For id = 11 
##  obs. mean   median  s.d.   min.   max.  
##  2    418.5  418.5   2.121  417    420   
## 
## For id = 12 
##  obs. mean   median  s.d.   min.   max.  
##  2    644.5  644.5   16.263 633    656   
## 
## For id = 13 
##  obs. mean   median  s.d.   min.   max.  
##  2    271    271     5.657  267    275   
## 
## For id = 14 
##  obs. mean   median  s.d.   min.   max.  
##  2    485    485     9.899  478    492   
## 
## For id = 15 
##  obs. mean   median  s.d.   min.   max.  
##  2    171.5  171.5   9.192  165    178   
## 
## For id = 16 
##  obs. mean   median  s.d.   min.   max.  
##  2    397.5  397.5   36.062 372    423   
## 
## For id = 17 
##  obs. mean   median  s.d.   min.   max.  
##  2    424    424     4.243  421    427</code></pre>
</div>
<div id="在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數" class="section level3">
<h3><span class="header-section-number">58.6.13</span> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</h3>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb747-1" title="1"><span class="kw">with</span>(pefr_long, <span class="kw">anova</span>(<span class="kw">lm</span>(wp<span class="op">~</span><span class="kw">factor</span>(id))))</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wp
##            Df Sum Sq  Mean Sq F value    Pr(&gt;F)    
## factor(id) 16 441599 27599.91   117.8 3.145e-14 ***
## Residuals  17   3983   234.29                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb749-1" title="1"><span class="co">#library(lme4)</span></a>
<a class="sourceLine" id="cb749-2" title="2">( fit &lt;-<span class="st"> </span><span class="kw">lmer</span>(wp <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data=</span>pefr_long) )</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerModLmerTest&#39;]
## Formula: wp ~ (1 | id)
##    Data: pefr_long
## REML criterion at convergence: 353.5472
## Random effects:
##  Groups   Name        Std.Dev.
##  id       (Intercept) 116.974 
##  Residual              15.307 
## Number of obs: 34, groups:  id, 17
## Fixed Effects:
## (Intercept)  
##      447.88</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb751-1" title="1"><span class="kw">sqrt</span>((<span class="dv">27600</span> <span class="op">-</span><span class="st"> </span><span class="dv">234</span>)<span class="op">/</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 116.97436</code></pre>
</div>
<div id="擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型" class="section level3">
<h3><span class="header-section-number">58.6.14</span> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</h3>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb753-1" title="1">Reg &lt;-<span class="st"> </span><span class="kw">lm</span>(wp <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb753-2" title="2"></a>
<a class="sourceLine" id="cb753-3" title="3"><span class="co"># The fixed effect regression model leads to the same ANOVA</span></a>
<a class="sourceLine" id="cb753-4" title="4"><span class="co"># table. To the same estimate of the residual SD = (15.307)</span></a>
<a class="sourceLine" id="cb753-5" title="5"><span class="co"># However, it does not give an estimate of the &quot;SD of id effect&quot;</span></a>
<a class="sourceLine" id="cb753-6" title="6"><span class="co"># Instead it gives estimates of mean PEFR for participant number 1</span></a>
<a class="sourceLine" id="cb753-7" title="7"><span class="co"># = 492 and estimates of the difference in means from him/her</span></a>
<a class="sourceLine" id="cb753-8" title="8"><span class="co"># for all the other 16 pariticipants</span></a>
<a class="sourceLine" id="cb753-9" title="9"><span class="kw">anova</span>(Reg)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wp
##            Df Sum Sq  Mean Sq F value    Pr(&gt;F)    
## factor(id) 16 441599 27599.91   117.8 3.145e-14 ***
## Residuals  17   3983   234.29                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb755-1" title="1"><span class="kw">summary</span>(Reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wp ~ factor(id), data = pefr_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -27.00  -3.75   0.00   3.75  27.00 
## 
## Coefficients:
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)   492.000     10.823  45.4569 &lt; 2.2e-16 ***
## factor(id)2   -96.000     15.307  -6.2718 8.435e-06 ***
## factor(id)3    22.000     15.307   1.4373 0.1687894    
## factor(id)4   -74.500     15.307  -4.8672 0.0001448 ***
## factor(id)5   -19.000     15.307  -1.2413 0.2313547    
## factor(id)6    92.000     15.307   6.0105 1.405e-05 ***
## factor(id)7   -78.000     15.307  -5.0958 8.972e-05 ***
## factor(id)8   -55.500     15.307  -3.6259 0.0020883 ** 
## factor(id)9   152.000     15.307   9.9303 1.715e-08 ***
## factor(id)10  -61.000     15.307  -3.9852 0.0009574 ***
## factor(id)11  -73.500     15.307  -4.8018 0.0001662 ***
## factor(id)12  152.500     15.307   9.9630 1.635e-08 ***
## factor(id)13 -221.000     15.307 -14.4382 5.665e-11 ***
## factor(id)14   -7.000     15.307  -0.4573 0.6532334    
## factor(id)15 -320.500     15.307 -20.9386 1.413e-13 ***
## factor(id)16  -94.500     15.307  -6.1738 1.020e-05 ***
## factor(id)17  -68.000     15.307  -4.4425 0.0003571 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.307 on 17 degrees of freedom
## Multiple R-squared:  0.99106,    Adjusted R-squared:  0.98265 
## F-statistic:  117.8 on 16 and 17 DF,  p-value: 3.145e-14</code></pre>
<p>上面的模型用數學表達式來描述就是：</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = \alpha_1 + \delta_i + \varepsilon_{ij} \\
\text{Where } \delta_j &amp; = \alpha_j - \alpha_1 \\
\text{and } \delta_1   &amp; = 0
\end{aligned}
\]</span></p>
</div>
<div id="將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式" class="section level3">
<h3><span class="header-section-number">58.6.15</span> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</h3>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb757-1" title="1">Reg1 &lt;-<span class="st"> </span><span class="kw">lm</span>((wp <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(wp)) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb757-2" title="2"></a>
<a class="sourceLine" id="cb757-3" title="3"><span class="co"># it leads to the same ANOVA table again, same residual SD</span></a>
<a class="sourceLine" id="cb757-4" title="4"><span class="kw">anova</span>(Reg1)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: (wp - mean(wp))
##            Df Sum Sq  Mean Sq F value     Pr(&gt;F)    
## factor(id) 17 441599 25976.38 110.871 4.5349e-14 ***
## Residuals  17   3983   234.29                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb759-1" title="1"><span class="kw">summary</span>(Reg1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = (wp - mean(wp)) ~ 0 + factor(id), data = pefr_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -27.00  -3.75   0.00   3.75  27.00 
## 
## Coefficients:
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## factor(id)1    44.118     10.823   4.0761 0.0007863 ***
## factor(id)2   -51.882     10.823  -4.7935 0.0001692 ***
## factor(id)3    66.118     10.823   6.1087 1.158e-05 ***
## factor(id)4   -30.382     10.823  -2.8071 0.0121232 *  
## factor(id)5    25.118     10.823   2.3207 0.0329951 *  
## factor(id)6   136.118     10.823  12.5762 4.894e-10 ***
## factor(id)7   -33.882     10.823  -3.1305 0.0060933 ** 
## factor(id)8   -11.382     10.823  -1.0516 0.3076854    
## factor(id)9   196.118     10.823  18.1197 1.493e-12 ***
## factor(id)10  -16.882     10.823  -1.5598 0.1372300    
## factor(id)11  -29.382     10.823  -2.7147 0.0147164 *  
## factor(id)12  196.618     10.823  18.1659 1.432e-12 ***
## factor(id)13 -176.882     10.823 -16.3425 7.887e-12 ***
## factor(id)14   37.118     10.823   3.4294 0.0031978 ** 
## factor(id)15 -276.382     10.823 -25.5355 5.342e-15 ***
## factor(id)16  -50.382     10.823  -4.6549 0.0002269 ***
## factor(id)17  -23.882     10.823  -2.2065 0.0413886 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.307 on 17 degrees of freedom
## Multiple R-squared:  0.99106,    Adjusted R-squared:  0.98212 
## F-statistic: 110.87 on 17 and 17 DF,  p-value: 4.5349e-14</code></pre>
<p>上面的模型用數學表達式來描述就是：</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} - \mu &amp; = \gamma_j + \varepsilon_{ij} \\
      Y_{ij} &amp; = \mu +  \gamma_j + \varepsilon_{ij} \\
\text{Where } \mu &amp; \text{ is the overall mean} \\
\text{and } \sum_{j=1}^J\gamma_j &amp; = 0\\
\end{aligned}
\]</span></p>
</div>
<div id="計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差" class="section level3">
<h3><span class="header-section-number">58.6.16</span> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</h3>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb761-1" title="1"><span class="co"># the individual level intercepts have mean zero and SD = 117.47, larger than the estimated</span></a>
<a class="sourceLine" id="cb761-2" title="2"><span class="co"># Std.Dev for id effect.</span></a>
<a class="sourceLine" id="cb761-3" title="3">Reg1<span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>##  factor(id)1  factor(id)2  factor(id)3  factor(id)4  factor(id)5  factor(id)6  factor(id)7 
##    44.117647   -51.882353    66.117647   -30.382353    25.117647   136.117647   -33.882353 
##  factor(id)8  factor(id)9 factor(id)10 factor(id)11 factor(id)12 factor(id)13 factor(id)14 
##   -11.382353   196.117647   -16.882353   -29.382353   196.617647  -176.882353    37.117647 
## factor(id)15 factor(id)16 factor(id)17 
##  -276.382353   -50.382353   -23.882353</code></pre>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb763-1" title="1"><span class="kw">summ</span>(Reg1<span class="op">$</span>coefficients, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.    min.     max.   
##  17   0      -16.882 117.473 -276.382 196.618</code></pre>
</div>
</div>
</div>
<div id="隨機截距模型-random-intercept-model" class="section level1">
<h1><span class="header-section-number">第 59 章</span> 隨機截距模型 random intercept model</h1>
<p>最簡單的隨機效應模型 – 隨機截距模型 random intercept model。</p>
<div id="隨機截距模型的定義" class="section level2">
<h2><span class="header-section-number">59.1</span> 隨機截距模型的定義</h2>
<p>有時，我們對每個分層各自的截距大小並不那麼感興趣，且如果只有固定效應的話，其實我們從某種程度上忽略掉了數據層與層之間變異的方差 (between cluster variation)。於是，在模型中考慮這些問題的解決方案就是 – 我們讓各層的截距呈現隨機效應 (treat the variation in cluster intercepts not as fixed)，<strong>把這些截距視爲來自與某種分布的隨機呈現 (randomly draws from some distribution)</strong>。於是原先的只有固定效應部分的模型，就增加了隨機截距部分:</p>
<p><span class="math display" id="eq:hier2-1">\[
\begin{aligned}
Y_{ij} &amp; = \mu + u_j + \varepsilon_{ij} \\
\text{where } u_j  &amp; \stackrel{N.I.D}{\sim} N(0, \sigma_u^2) \\
              \varepsilon_{ij} &amp; \stackrel{N.I.D}{\sim} N(0, \sigma_\varepsilon^2) \\
        u_j  &amp; \text{ are independent from } \varepsilon_{ij} \\
\end{aligned}
\tag{59.1}
\]</span></p>
<p>這個混合效應模型中，</p>
<ul>
<li><span class="math inline">\(\mu\)</span> 是總體均值;</li>
<li><span class="math inline">\(u_j\)</span> 是一個服從均值 0, 方差 (the population between cluster variance) 爲 <span class="math inline">\(\sigma_u^2\)</span> 的正態分布的隨機變量;</li>
<li><span class="math inline">\(\varepsilon_{ij}\)</span> 是隨機誤差，它也被認爲服從均值爲 0, 方差爲 <span class="math inline">\(\sigma_\varepsilon^2\)</span> 的正太分布，且這兩個隨機效應部分之間也是<strong>相互獨立的</strong>。</li>
<li>從該模型估算的結果變量 <span class="math inline">\(Y_{ij}\)</span> 的方差是 <span class="math inline">\(\sigma_u^2 + \sigma_\varepsilon^2\)</span>。</li>
<li>隨機截距模型又被叫做是 <strong>方差成分模型 (variance-component model)</strong>，或者是<strong>單向隨機效應方差模型 (one-way random effects ANOVA model)</strong>。</li>
</ul>
<p>這個模型和僅有固定效應的模型，有顯著的不同:</p>
<p><span class="math display">\[
Y_{ij} = \mu + \gamma_j + \varepsilon_{ij}
\]</span></p>
<p>固定效應模型裏，</p>
<ul>
<li><span class="math inline">\(\mu\)</span> 也是總體均值;</li>
<li><span class="math inline">\(\sum_{j=1}^J \gamma_j = 0\)</span> 是<strong>將各組不同截距之和強制爲零</strong>的過程;</li>
</ul>
<p>所以隨機截距模型打破了這個限制，使得隨機的截距 <span class="math inline">\(\mu_j\)</span> 成爲一個服從均值爲 0，方差爲 <span class="math inline">\(\sigma_u^2\)</span> 的 <strong>隨機變量</strong>。</p>
<p>隨機效應部分 <span class="math inline">\(u_j\)</span> 和隨機誤差 <span class="math inline">\(\varepsilon_{ij}\)</span> 之間相互獨立的前提，意味着兩個裏屬於不同層級的觀察之間是相互獨立的，但是反過來，同屬於一個層級的個體之間就變成了有相關性的了 (within cluster correlation):</p>
<p><span class="math display">\[
\begin{aligned}
\because Y_{1j} &amp; = \mu + u_j + \varepsilon_{1j} \\
         Y_{2j} &amp; = \mu + u_j + \varepsilon_{2j}  \\
\therefore \text{Cov}(Y_{1j}, Y_{2j}) &amp; =  \text{Cov}(u_j, u_j) + \text{Cov}(u_j, \varepsilon_{2j}) + \text{Cov}(\varepsilon_{1j}, u_j) + \text{Cov}(\varepsilon_{1j}, \varepsilon_{2j}) \\
                                      &amp; = \text{Cov}(u_j, u_j) = V(u_j, u_j)\\
                                      &amp; = \sigma_u^2
\end{aligned}
\]</span></p>
<p>由於 <span class="math inline">\(\text{Var}(Y_{1j}) = \text{Var}(Y_{2j}) = \sigma_u^2 + \sigma_\varepsilon^2\)</span>，所以，同屬一層的兩個個體之間的<strong>層內相關系數 (intra-class correlation)</strong>:</p>
<p><span class="math display">\[
\lambda = \frac{\text{Cov}(Y_{1j}, Y_{2j})}{\text{SD}(Y_{1j})\text{SD}(Y_{2j})} = \frac{\sigma_u^2}{\sigma_\varepsilon^2 + \sigma_u^2}
\]</span></p>
<p>從層內相關系數的公式也可看出，該相關系數可以同時被理解爲結果變量 <span class="math inline">\(Y_{ij}\)</span> 的方差中歸咎與層(cluster)結構的部分的百分比。</p>
<p>This is the within-cluster or intra-class correlation, that we will denote <span class="math inline">\(\lambda\)</span>. Note that it is also the proportion of total variance that is accounted for by the cluster.</p>
</div>
<div id="隨機截距模型的參數估計" class="section level2">
<h2><span class="header-section-number">59.2</span> 隨機截距模型的參數估計</h2>
<p>如此，我們就知道在隨機截距模型裏，有三個需要被估計的參數 <span class="math inline">\(\mu, \sigma_u^2, \sigma^2_\varepsilon\)</span>。我們可以利用熟悉的極大似然估計法估計這些參數 (Maximum Likelihood, ML)。當且進當嵌套式結構數據是<strong>平衡數據 (balanced)</strong>時 (即，每層中的個體數量相同)，這三個參數的 <span class="math inline">\(\text{MLE}\)</span> 分別是:</p>
<p><span class="math display" id="eq:hier02-2">\[
\begin{aligned}
\hat\mu &amp; = \bar{Y} \\
\hat\sigma_\varepsilon^2 &amp; = \text{Mean square error, MSE} \\ 
\hat\sigma_u^2 &amp; = \frac{\text{Model Sum of Squares, MSS}}{Jn} - \frac{\hat\sigma^2_\varepsilon}{n}
\end{aligned}
\tag{59.2}
\]</span></p>
<p>只要模型指定正確無誤，前兩個極大似然估計是他們各自的無偏估計。但第三個，也就是層內方差的估計量確實際上是低估了的 (downward biased)。這裏常用的另一種對層內方差參數的估計法被叫做<strong>矩估計量 (moment estimator, or ANOVA estimator)</strong>:</p>
<p><span class="math display">\[
\begin{aligned}
\widetilde{\sigma}_u^2 &amp; = \frac{\text{MSS}}{(J-1)n}- \frac{\hat\sigma_\varepsilon^2}{n} \\ 
                       &amp; = \frac{\text{MSS} - \text{MSE}(J-1)}{(J-1)n} \\
                       &amp; = \frac{\text{MMS}(J-1) - \text{MSE}(J-1)}{(J-1)n} \\
                       &amp; = \frac{\text{MMS} - \text{MSE}}{n}
\end{aligned}
\]</span></p>
<p>對於平衡數據 (balanced data)，這個矩估計量又被叫做<strong>限制性極大似然 (Restricted Maximum Likelihood, REML)</strong>。限制性極大似然法，是一個真極大似然過程 (genuine maximum likelihood procedure)，但是它每次進行估計的時候，會先“去除掉”固定效應部分，所以每次用於估計參數的數據其實是對數據的線性轉換後 <span class="math inline">\(Y_{ij} - \mu = u_j + \varepsilon_{ij}\)</span>，它使用的數據是這個等式右半部分的轉換後數據。在 REML 過程中，先估計層內方差 <span class="math inline">\(\sigma_u^2\)</span> 再對固定效應部分的總體均值估計，所以是個兩步走的過程。另外除了這裏討論的 ML, REML這兩種對層內方差進行參數估計的方法之外，在計量經濟學 (econometrics) 中常用的是 (本課不深入探討) <strong>廣義最小二乘法 (Generalized Least Squares, GLS)</strong>。GLS 使用的是一種加權的最小二乘法 (OLS)，該加權法根據層與隨機誤差的方差成分 (variance components) 不同而給不同的層以不同的截距權重。當數據本身是平衡數據時，GLS給出的估計結果等同於 REML法。當數據不是平衡數據的時候，ML/REML 其實背後使用的原理也是 GLS。</p>
</div>
<div id="如何在-r-中進行隨機截距模型的擬合" class="section level2">
<h2><span class="header-section-number">59.3</span> 如何在 R 中進行隨機截距模型的擬合</h2>
<p>在 R 或 STATA 中擬合隨機截距模型，需要數據爲“長 (long)” 數據，下面的代碼可以在 R 裏面把 “寬 (wide)” 的數據調整成爲 <strong>長</strong> 數據:</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb765-1" title="1">pefr &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pefr.dta&quot;</span>)</a>
<a class="sourceLine" id="cb765-2" title="2"><span class="co"># the data are in wide format</span></a>
<a class="sourceLine" id="cb765-3" title="3"><span class="kw">head</span>(pefr)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##      id   wp1   wp2   wm1   wm2
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1   494   490   512   525
## 2     2   395   397   430   415
## 3     3   516   512   520   508
## 4     4   434   401   428   444
## 5     5   476   470   500   500
## 6     6   557   611   600   625</code></pre>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb767-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb767-2" title="2">pefr_long &lt;-<span class="st"> </span>pefr <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb767-7" title="7">pefr_long</a></code></pre></div>
<pre><code>## # A tibble: 34 x 4
##       id occasion    wm    wp
##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1 1          512   494
##  2     1 2          525   490
##  3     2 1          430   395
##  4     2 2          415   397
##  5     3 1          520   516
##  6     3 2          508   512
##  7     4 1          428   434
##  8     4 2          444   401
##  9     5 1          500   476
## 10     5 2          500   470
## # ... with 24 more rows</code></pre>
<p>在 R 裏面，有兩個包 (<code>lme4::lmer</code> 或 <code>nlme::lme</code>) 的各自兩種代碼以供選用:</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb769-1" title="1">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> pefr_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb769-2" title="2"><span class="kw">summary</span>(M0)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: pefr_long 
##         AIC       BIC     logLik
##   366.75843 371.24795 -180.37921
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   110.39701 19.910835
## 
## Fixed effects: wm ~ 1 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 453.91176 26.992068 17 16.816487       0
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.444435579 -0.335076940  0.037044891  0.350983659  2.377059741 
## 
## Number of Observations: 34
## Number of Groups: 17</code></pre>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb771-1" title="1">M1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(wm <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data =</span> pefr_long, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb771-2" title="2"><span class="kw">summary</span>(M1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: wm ~ (1 | id)
##    Data: pefr_long
## 
## REML criterion at convergence: 360.8
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -2.444436 -0.335077  0.037045  0.350984  2.377060 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 12187.51 110.397 
##  Residual               396.44  19.911 
## Number of obs: 34, groups:  id, 17
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  453.912     26.992  16.000  16.817 1.36e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>不知道爲什麼在 R 裏有這兩種完全不同的方式來擬合混合效應模型。還好他們的結果基本完全一致。在這個極爲簡單的例子裏，我們可以利用模型擬合的結果中 <code>Random effects</code> 的部分來計算<strong>層內相關系數 (intra-class correlation)</strong>:</p>
<p><span class="math display">\[
\hat\lambda = \frac{\hat\sigma_u^2}{(\hat\sigma_u^2 + \hat\sigma_\varepsilon^2)} = \frac{110.40^2}{110.40^2 + 19.91^2} = 0.97
\]</span></p>
<p>這是對 Mini Wright meter 測量方法可靠性的一個評價指標。其中 <span class="math inline">\(\sigma_u^2\)</span> 是患者最大呼吸速率 (PEFR) 測量值的方差，<span class="math inline">\(\sigma_\varepsilon^2\)</span> 是測量的隨機誤差，所以這裏的測量方法的可靠度是 97%，是可信度十分高的測量準確度。</p>
</div>
<div id="隨機截距模型中的統計推斷" class="section level2">
<h2><span class="header-section-number">59.4</span> 隨機截距模型中的統計推斷</h2>
<div id="fixed-inference" class="section level3">
<h3><span class="header-section-number">59.4.1</span> 固定效應部分的推斷</h3>
<p>當數據是平衡數據時，固定效應的 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是總體的均值 (overall mean)。它的估計標準誤是:</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu) = \sqrt{\frac{n\hat\sigma_u^2 + \hat\sigma_\varepsilon^2}{Jn}}
\]</span></p>
<p>記得線性回歸中(固定效應模型中)，<span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 也還是總體的均值 (overall mean)。它的估計標準誤卻是:</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu^F) = \sqrt{\frac{\hat\sigma_\varepsilon^2}{Jn}}
\]</span></p>
<p>所以，僅有固定效應模型時的總體均值的標準誤總是要比混合效應模型下估計的總體均值標準誤要小</p>
<p><span class="math display">\[
\hat{\text{SE}}(\hat\mu^F) &lt; \hat{\text{SE}}(\hat\mu)
\]</span></p>
<p>如果數據不是平衡數據，那麼隨機截距模型中 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是每層均值的加權均值 (a weighted mean of the cluster specific means):</p>
<p><span class="math display">\[
\begin{aligned}
\hat\mu &amp; = \frac{\sum_jw_j\bar{Y}_{\cdot j}}{\sum_j w_j} \\
\text{Where } w_j &amp; = \frac{1}{\sigma_u^2 + \sigma_\varepsilon^2/n_j}
\end{aligned}
\]</span></p>
<p>從加權的方式來看，如果樣本量少的層級數據本身的誤差方差 <span class="math inline">\(\sigma_\varepsilon^2\)</span> 也較小，那麼層樣本量較小的層也會和層樣本量較大的層獲得相似的均值權重。</p>
<p>零假設是 <span class="math inline">\(\mu = 0\)</span> 的檢驗，就計算 <span class="math inline">\(z\)</span> 檢驗統計量就可以 (或者 <span class="math inline">\(z^2\)</span> 的 Wald 檢驗):</p>
<p><span class="math display">\[
z = \frac{\hat\mu}{\hat{\text{SE}}(\hat\mu)}
\]</span>
總體均值的 95% 信賴區間的計算式就是:</p>
<p><span class="math display">\[
\hat\mu \pm z_{0.975}\hat{\text{SE}}(\hat\mu)
\]</span></p>
</div>
<div id="隨機效應部分的推斷" class="section level3">
<h3><span class="header-section-number">59.4.2</span> 隨機效應部分的推斷</h3>
<p>總體均值的假設檢驗搞定了之後，我們肯定還想對隨機截距模型擬合的隨機效應方差作出是否有意義的假設檢驗。也就是我們希望能檢驗零假設 <span class="math inline">\(\sigma_u^2 = 0\)</span>，和替代假設 <span class="math inline">\(\sigma_u^2 &gt; 0\)</span>。一般情況下大家肯定會想到對含有隨機效應的模型和只有固定效應的模型使用 LRT (似然比檢驗)，然後把檢驗統計量拿去和自由度爲 1 的卡方分布做比較。但是其實方差本身永遠都是大於等於零的，所以傳統的 LRT 在這個零假設時並不適用。</p>
<p>在零假設條件下 <span class="math inline">\(\sigma_u^2 = 0\)</span>，也就是說層內相關在一半的數據中是正相關，另一半數據中是正好相反的負相關，以此相互抵消，方差爲零。所以其實這裏的 LRT 檢驗統計量應該服從的不是自由度爲 1 的卡方分布那麼簡單，而是一種混合卡方分布 (自由度 1 和 自由度爲 0 的混合卡方分布 <span class="math inline">\(\chi_{0,1}^2\)</span>)。所以應該把模型比較之後計算獲得的 <span class="math inline">\(p\)</span> 值除以2，以獲得準確的對 <span class="math inline">\(\sigma_u^2 = 0\)</span> 檢驗的 <span class="math inline">\(p\)</span> 值。</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb773-1" title="1">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> pefr_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb773-2" title="2">M0_fixed&lt;-<span class="st"> </span><span class="kw">lm</span>(wm <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pefr_long)</a>
<a class="sourceLine" id="cb773-3" title="3"><span class="kw">anova</span>(M0, M0_fixed)</a></code></pre></div>
<pre><code>##          Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M0           1  3 366.75843 371.24795 -180.37921                         
## M0_fixed     2  2 411.71916 414.71217 -203.85958 1 vs 2 46.960731  &lt;.0001</code></pre>
<p>回到本例中的混合效應模型和固定效應模型的比較來看，LRT本身的 P 值已經 <span class="math inline">\(&lt;0.0001\)</span>，所以除不除以二對推斷結果都沒有太大影響。也就是本例中的隨即截距模型是比固定效應的簡單線性回歸模型更加適合該數據的模型。</p>
<p>其他注意點:</p>
<ul>
<li>在坑爹的 STATA 裏面混合效應模型居然還會輸出隨機效應方差的 “標準誤”，該數字請你無視之。</li>
<li>當樣本擁有足夠多的樣本量 (其實是第二階層的層數)，極大似然法 (ML) 和限制性極大似然法 (REML) 給出的結果會相當接近。</li>
<li>當你比較兩個不是互爲嵌套 (nested) 的模型時，可以使用 AIC/BIC 指標。</li>
</ul>
</div>
</div>
<div id="練習題-8" class="section level2">
<h2><span class="header-section-number">59.5</span> 練習題</h2>
<div id="數據-1" class="section level3">
<h3><span class="header-section-number">59.5.1</span> 數據</h3>
<ol style="list-style-type: decimal">
<li>GHQ 數據 <br> 該數據包含 12 名學生前後兩次回答 General Health Questionnaire (GHQ) 問卷獲得的數據。該問卷用於測量學生的心理壓力，其變量名和含義如下：</li>
</ol>
<pre><code>id        Student identifier
GHQ1      General Health Questionnaire score- 1st occasion
GHQ2      General Health Questionnaire score- 2nd occasion</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Siblings 數據 <br> 該數據是來自一項對 3978 名媽媽關於她們 8604 名孩子的出生體重及健康狀況的問卷調查。該數據的變量名和含義如下：</li>
</ol>
<pre><code>momid     Mother identifier
idx       Baby identifier
mage      Maternal age (years)
meduc     Maternal education
gestat    gestational age (weeks)
birwt     Birth weight (g)
smoke     Maternal smoking (0 = no, 1 = yes)
male      Baby boy (0 = no, 1 = yes)
year      Year of birth
married   Maternal marital status (0 = no, 1 = yes)
hsgrad    Maternal high school education (0 = no, 1 = yes)
black     Maternal race (1 = black, 0 = other)</code></pre>
</div>
<div id="讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分" class="section level3">
<h3><span class="header-section-number">59.5.2</span> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</h3>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb777-1" title="1">ghq &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/ghq.dta&quot;</span>)</a>
<a class="sourceLine" id="cb777-2" title="2">ghq</a></code></pre></div>
<pre><code>## # A tibble: 12 x 3
##       id  GHQ1  GHQ2
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1    12    12
##  2     2     8     7
##  3     3    22    24
##  4     4    10    14
##  5     5    10     8
##  6     6     6     4
##  7     7     8     5
##  8     8     4     6
##  9     9    14    14
## 10    10     6     5
## 11    11     2     5
## 12    12    22    16</code></pre>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb779-1" title="1">ghq &lt;-<span class="st"> </span>ghq <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb779-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean =</span> (GHQ1 <span class="op">+</span><span class="st"> </span>GHQ2)<span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb779-3" title="3"></a>
<a class="sourceLine" id="cb779-4" title="4"><span class="co"># each student has 2 observations (i.e. n_j = n = 2)</span></a>
<a class="sourceLine" id="cb779-5" title="5"><span class="co"># and therefore the data are balanced.</span></a>
<a class="sourceLine" id="cb779-6" title="6"><span class="co"># the overall mean is 10.167 and its SD is 6.073</span></a>
<a class="sourceLine" id="cb779-7" title="7"><span class="kw">with</span>(ghq, <span class="kw">summ</span>(mean, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   10.167 8.25    6.073  3.5    23</code></pre>
</div>
<div id="把數據從寬-wide-改變成長-long-的形式" class="section level3">
<h3><span class="header-section-number">59.5.3</span> 把數據從寬 (wide) 改變成長 (long) 的形式</h3>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb781-1" title="1"><span class="co"># transform data into long format</span></a>
<a class="sourceLine" id="cb781-2" title="2">ghq_long &lt;-<span class="st"> </span>ghq <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id, <span class="op">-</span>mean) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-4" title="4"><span class="st">  </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;measurement&quot;</span>, <span class="st">&quot;occasion&quot;</span>), <span class="dt">sep =</span> <span class="dv">3</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(id, occasion) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb781-6" title="6"><span class="st">  </span><span class="kw">spread</span>(measurement, value)</a>
<a class="sourceLine" id="cb781-7" title="7">ghq_long</a></code></pre></div>
<pre><code>## # A tibble: 24 x 4
##       id  mean occasion   GHQ
##    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;
##  1     1  12   1           12
##  2     1  12   2           12
##  3     2   7.5 1            8
##  4     2   7.5 2            7
##  5     3  23   1           22
##  6     3  23   2           24
##  7     4  12   1           10
##  8     4  12   2           14
##  9     5   9   1           10
## 10     5   9   2            8
## # ... with 14 more rows</code></pre>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb783-1" title="1"><span class="co"># after reshaping there are 24 records. the summary statistics are</span></a>
<a class="sourceLine" id="cb783-2" title="2"><span class="co"># overall mean sd and min max</span></a>
<a class="sourceLine" id="cb783-3" title="3"><span class="kw">with</span>(ghq_long, <span class="kw">summ</span>(GHQ, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  24   10.167 8       6.098  2      24</code></pre>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb785-1" title="1"><span class="co"># between groups mean sd and min</span></a>
<a class="sourceLine" id="cb785-2" title="2"><span class="kw">summ</span>(ghq_long[<span class="op">!</span><span class="kw">duplicated</span>(ghq_long<span class="op">$</span>id), ]<span class="op">$</span>mean, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   10.167 8.25    6.073  3.5    23</code></pre>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb787-1" title="1"><span class="co"># within groups mean sd and min (came from the difference between</span></a>
<a class="sourceLine" id="cb787-2" title="2"><span class="co"># the overall mean and the within difference) observations for</span></a>
<a class="sourceLine" id="cb787-3" title="3"><span class="co"># each group = 2</span></a>
<a class="sourceLine" id="cb787-4" title="4">ghq_long &lt;-<span class="st"> </span>ghq_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb787-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif_GHQ =</span> <span class="kw">mean</span>(GHQ) <span class="op">-</span><span class="st"> </span>(GHQ <span class="op">-</span><span class="st"> </span>mean))</a>
<a class="sourceLine" id="cb787-6" title="6"><span class="kw">with</span>(ghq_long, <span class="kw">summ</span>(dif_GHQ, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  24   10.167 10.167  1.383  7.167  13.167</code></pre>
<p>GHQ 的分佈並不左右對稱。</p>
<div class="figure" style="text-align: center"><span id="fig:histGHQ"></span>
<img src="bookdown_files/figure-html/histGHQ-1.png" alt="Histogram of GHQ by occasion" width="80%" />
<p class="caption">
圖 59.1: Histogram of GHQ by occasion
</p>
</div>
</div>
<div id="對數據按照-id-分層進行-anova" class="section level3">
<h3><span class="header-section-number">59.5.4</span> 對數據按照 <code>id</code> 分層進行 ANOVA</h3>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb789-1" title="1"><span class="kw">with</span>(ghq_long, <span class="kw">anova</span>(<span class="kw">lm</span>(GHQ<span class="op">~</span><span class="kw">factor</span>(id))))</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: GHQ
##            Df  Sum Sq Mean Sq F value     Pr(&gt;F)    
## factor(id) 11 811.333 73.7576 20.1157 4.7782e-06 ***
## Residuals  12  44.000  3.6667                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb791-1" title="1"><span class="co">#library(lme4)</span></a>
<a class="sourceLine" id="cb791-2" title="2">( fit &lt;-<span class="st"> </span><span class="kw">lmer</span>(GHQ <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>id), <span class="dt">data=</span>ghq_long) )</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerModLmerTest&#39;]
## Formula: GHQ ~ (1 | id)
##    Data: ghq_long
## REML criterion at convergence: 131.3492
## Random effects:
##  Groups   Name        Std.Dev.
##  id       (Intercept) 5.9199  
##  Residual             1.9149  
## Number of obs: 24, groups:  id, 12
## Fixed Effects:
## (Intercept)  
##      10.167</code></pre>
<p><span class="math inline">\(\sigma_u, \sigma_e\)</span> 的估計值分別是 5.92 (between)， 1.91 (within)。可以計算層間相關係數 (intra-class correlation) <span class="math inline">\(\hat\lambda = \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_e} = 0.905\)</span>。且 <span class="math inline">\(\hat\sigma_u = \sqrt{\frac{73.8 - 3.7}{2}} = 5.92\)</span>，和前一次練習一樣地，這個隨機效應的方差，可以通過方差分析表格來直接手動計算 (當且僅當分層數據是<strong>平衡狀態</strong>的)。和前面計算的樣本數據比較，樣本層間標準差是高估了的 (sample between variance = 6.073 &gt; 5.92)，相反樣本層內標準差 (within sd) 則是低估了的 (sample within sd = 1.383 &lt; 1.91)。兩個層內標準差的關係是：</p>
<p><span class="math display">\[
\sqrt{1.383^2\times\frac{23}{12}} = 1.91
\]</span></p>
</div>
<div id="用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果" class="section level3">
<h3><span class="header-section-number">59.5.5</span> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</h3>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb793-1" title="1"><span class="kw">summary</span>(nlme<span class="op">::</span><span class="kw">lme</span>(<span class="dt">fixed =</span> GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> ghq_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>))</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: ghq_long 
##         AIC       BIC     logLik
##   137.34924 140.75573 -65.674622
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   5.9199181 1.9148548
## 
## Fixed effects: GHQ ~ 1 
##                 Value Std.Error DF   t-value p-value
## (Intercept) 10.166667 1.7530632 12 5.7993727  0.0001
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -1.337372043 -0.578482697  0.073557531  0.414059981  1.796024881 
## 
## Number of Observations: 24
## Number of Groups: 12</code></pre>
<p>截距混合效應模型的參數估計和隨機效應 ANOVA 的參數估計是一樣的。</p>
</div>
<div id="用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同" class="section level3">
<h3><span class="header-section-number">59.5.6</span> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</h3>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb795-1" title="1"><span class="co">#( fit &lt;- lmer(GHQ ~ (1|id), data=ghq_long, REML = FALSE) ) # same but from `lme4` package</span></a>
<a class="sourceLine" id="cb795-2" title="2"></a>
<a class="sourceLine" id="cb795-3" title="3"><span class="kw">summary</span>(<span class="kw">lme</span>(<span class="dt">fixed =</span> GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> ghq_long, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>))</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: ghq_long 
##         AIC       BIC     logLik
##   140.26571 143.79987 -67.132857
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)  Residual
## StdDev:   5.6543976 1.9148545
## 
## Fixed effects: GHQ ~ 1 
##                 Value Std.Error DF  t-value p-value
## (Intercept) 10.166667 1.7145299 12 5.929711  0.0001
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.31652454 -0.58359637  0.08024454  0.40422622  1.81687284 
## 
## Number of Observations: 24
## Number of Groups: 12</code></pre>
<p>用極大似然法估計的隨機殘差標準差 <span class="math inline">\(\sigma_e\)</span> 和 REML/ANOVA 法估計的相同，但是隨機效應標準差 <span class="math inline">\(\sigma_u\)</span> 略小 5.65 &lt; 5.92。</p>
</div>
<div id="用簡單線性迴歸擬合一個固定效應模型" class="section level3">
<h3><span class="header-section-number">59.5.7</span> 用簡單線性迴歸擬合一個固定效應模型</h3>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb797-1" title="1">Fixed_reg &lt;-<span class="st"> </span><span class="kw">lm</span>(GHQ<span class="op">-</span><span class="kw">mean</span>(GHQ) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(id), <span class="dt">data =</span> ghq_long)</a>
<a class="sourceLine" id="cb797-2" title="2"><span class="kw">summary</span>(Fixed_reg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = GHQ - mean(GHQ) ~ 0 + factor(id), data = ghq_long)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -3     -1      0      1      3 
## 
## Coefficients:
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## factor(id)1    1.8333     1.3540  1.3540 0.2006847    
## factor(id)2   -2.6667     1.3540 -1.9695 0.0724256 .  
## factor(id)3   12.8333     1.3540  9.4780 6.371e-07 ***
## factor(id)4    1.8333     1.3540  1.3540 0.2006847    
## factor(id)5   -1.1667     1.3540 -0.8616 0.4057744    
## factor(id)6   -5.1667     1.3540 -3.8158 0.0024580 ** 
## factor(id)7   -3.6667     1.3540 -2.7080 0.0190252 *  
## factor(id)8   -5.1667     1.3540 -3.8158 0.0024580 ** 
## factor(id)9    3.8333     1.3540  2.8311 0.0151447 *  
## factor(id)10  -4.6667     1.3540 -3.4466 0.0048356 ** 
## factor(id)11  -6.6667     1.3540 -4.9237 0.0003516 ***
## factor(id)12   8.8333     1.3540  6.5238 2.836e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.9149 on 12 degrees of freedom
## Multiple R-squared:  0.94856,    Adjusted R-squared:  0.89712 
## F-statistic: 18.439 on 12 and 12 DF,  p-value: 6.8362e-06</code></pre>
<p>可以看到輸出報告最底段部分 <code>Residual standard error: 1.91 on 12 degrees of freedom</code> 就是前文三種不同模型擬合的隨機殘差效應的標準差。在 STATA 裏被叫做 <code>Root MSE</code>。</p>
</div>
<div id="計算這些隨機截距的均值和標準差" class="section level3">
<h3><span class="header-section-number">59.5.8</span> 計算這些隨機截距的均值和標準差</h3>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb799-1" title="1"><span class="kw">summ</span>(Fixed_reg<span class="op">$</span>coefficients, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  12   0      -1.917  6.073  -6.667 12.833</code></pre>
<p>這裏僅僅用固定效應模型時，不同羣截距的均值雖然和用混合效應模型估計的一樣爲零，但是其估計的標準差要大於無論是 REML (5.92) 或者是 ML (5.65) 估計值的大小，其實這裏簡單線性迴歸給出的截距均值，就是本練習一開始讓你計算的樣本均值的標準差 (between group sd)。這是因爲<strong>簡單線性迴歸 (固定效應模型) 忽視了這些不同組的均值的不確定性</strong>。</p>
</div>
<div id="忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸" class="section level3">
<h3><span class="header-section-number">59.5.9</span> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</h3>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb801-1" title="1">Fixed_simple &lt;-<span class="st"> </span><span class="kw">lm</span>(GHQ <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> ghq_long)</a>
<a class="sourceLine" id="cb801-2" title="2"><span class="kw">summary</span>(Fixed_simple)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = GHQ ~ 1, data = ghq_long)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.1667 -4.4167 -2.1667  3.8333 13.8333 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  10.1667     1.2448  8.1673 3.001e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.0982 on 23 degrees of freedom</code></pre>
<p>此時的模型估計的 <code>Residual standard error: 6.09 on 23 degrees of freedom</code> 其實就是一開始讓你計算的樣本整體的標準差 (overall sd)</p>
</div>
<div id="用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較" class="section level3">
<h3><span class="header-section-number">59.5.10</span> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</h3>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb803-1" title="1"><span class="co"># sandwich robust method with cluster id</span></a>
<a class="sourceLine" id="cb803-2" title="2"></a>
<a class="sourceLine" id="cb803-3" title="3">robustReg &lt;-<span class="st"> </span>clubSandwich<span class="op">::</span><span class="kw">coef_test</span>(Fixed_simple, <span class="dt">vcov =</span> <span class="st">&quot;CR1&quot;</span>, <span class="dt">cluster =</span> ghq_long<span class="op">$</span>id)</a>
<a class="sourceLine" id="cb803-4" title="4"></a>
<a class="sourceLine" id="cb803-5" title="5">rob.std.err &lt;-<span class="st"> </span>robustReg<span class="op">$</span>SE</a>
<a class="sourceLine" id="cb803-6" title="6">naive.std.err&lt;-<span class="kw">summary</span>(Fixed_simple)<span class="op">$</span>coefficients[,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb803-7" title="7">better.table &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;Estimate&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple),</a>
<a class="sourceLine" id="cb803-8" title="8">                      <span class="st">&quot;Naive SE&quot;</span> =<span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-9" title="9">                      <span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(Fixed_simple)<span class="op">/</span>naive.std.err), <span class="dt">df=</span><span class="kw">nrow</span>(ghq_long)<span class="op">-</span><span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb803-10" title="10">                      <span class="st">&quot;LL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-11" title="11">                      <span class="st">&quot;UL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>naive.std.err,</a>
<a class="sourceLine" id="cb803-12" title="12">                      <span class="st">&quot;Robust SE&quot;</span> =<span class="st"> </span>rob.std.err,</a>
<a class="sourceLine" id="cb803-13" title="13">                      <span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(Fixed_simple)<span class="op">/</span>rob.std.err), <span class="dt">df=</span><span class="kw">nrow</span>(ghq_long)<span class="op">-</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb803-14" title="14"><span class="dt">lower.tail =</span> <span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb803-15" title="15">                      <span class="st">&quot;LL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="dt">df=</span>robustReg<span class="op">$</span>df, <span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob.std.err,</a>
<a class="sourceLine" id="cb803-16" title="16">                      <span class="st">&quot;UL&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(Fixed_simple) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="dt">df=</span>robustReg<span class="op">$</span>df, <span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob.std.err)</a>
<a class="sourceLine" id="cb803-17" title="17"><span class="kw">rownames</span>(better.table)&lt;-<span class="kw">c</span>(<span class="st">&quot;Constant&quot;</span>)</a>
<a class="sourceLine" id="cb803-18" title="18">better.table</a></code></pre></div>
<pre><code>##           Estimate  Naive SE      Pr(&gt;|z|)        LL        UL Robust SE      Pr(&gt;|z|)        LL
## Constant 10.166667 1.2447959 4.1792464e-08 7.7268666 12.606467 1.7530637 7.7968698e-06 6.3081995
##                 UL
## Constant 14.025134</code></pre>
</div>
<div id="讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量" class="section level3">
<h3><span class="header-section-number">59.5.11</span> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</h3>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb805-1" title="1">siblings &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/siblings.dta&quot;</span>)</a>
<a class="sourceLine" id="cb805-2" title="2">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>)</a>
<a class="sourceLine" id="cb805-3" title="3"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: siblings 
##         AIC       BIC     logLik
##   130956.97 130978.15 -65475.486
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.28656 377.65778
## 
## Fixed effects: birwt ~ 1 
##                Value Std.Error   DF   t-value p-value
## (Intercept) 3467.969 7.1380683 4626 485.84138       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2745852602 -0.4860398560  0.0036050084  0.5054348663  4.0506129253 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb807-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb807-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: siblings 
##        AIC       BIC     logLik
##   130951.2 130972.38 -65472.601
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.35596 377.65768
## 
## Fixed effects: birwt ~ 1 
##                 Value Std.Error   DF   t-value p-value
## (Intercept) 3467.9688 7.1385551 4626 485.80822       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2743063820 -0.4860194138  0.0035299824  0.5053550416  4.0503923643 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<p>由於該數據樣本量足夠大 (混合效應模型中等同於說數據的層數足夠多)，你可以看到其實 ML 法和 REML 法估計的參數結果十分地接近。</p>
</div>
</div>
</div>
<div id="隨機截距模型中加入共變量-random-intercept-model-with-covariates" class="section level1">
<h1><span class="header-section-number">第 60 章</span> 隨機截距模型中加入共變量 random intercept model with covariates</h1>
<p>這一章我們來把隨機截距模型加以擴展，在固定效應部分增加想要調整的共變量。</p>
<div id="多元線性回歸模型的延伸" class="section level2">
<h2><span class="header-section-number">60.1</span> 多元線性回歸模型的延伸</h2>
<p>如果有一個含有兩個預測變量的多元線性回歸模型:</p>
<p><span class="math display" id="eq:hier03-1">\[
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 X_{1ij} + \beta_2 X_{2ij} + \epsilon_{ij}
\end{equation}
\tag{60.1}
\]</span></p>
<p>如果觀測數據內部具有嵌套式結構，也就是有些對象之間有相關性，有些對象之間沒有，那麼上面這個多元線性回歸模型的誤差項 <span class="math inline">\(\epsilon_{ij}\)</span> 其實是不能被認爲相互獨立的，因爲數據中處以同一層的個體之間互相有關聯性 (屬於同一所學校的學生之間，同一所醫院的病人之間)。但是於此同時，我們不妨把最後的誤差項分成兩個部分</p>
<p><span class="math display">\[
\epsilon_{ij} = u_j + e_{ij}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(u_j\)</span>，是在隨機截距模型中用到的隨機截距部分，<span class="math inline">\(u_j \sim N(0, \sigma_u^2)\)</span>，它允許不同層的數據有自己的截距;</li>
<li><span class="math inline">\(e_{ij}\)</span>，是剝離掉層內相關 (等同於層間相異，intra-class correlation = between-class heterogeneity) 之後，剩餘的隨機殘差;</li>
</ul>
<p>之後把式子 <a href="#eq:hier03-1">(60.1)</a> 重新整理，就遇到了我們似曾相識的隨機截距模型:</p>
<p><span class="math display" id="eq:Hier03-01">\[
\begin{equation}
Y_{ij} = (\beta_0 + u_j) + \beta_1 X_{1ij} + \beta_2 X_{2ij} + e_{ij}
\end{equation}
\tag{60.2}
\]</span></p>
<p>這就是一個混合效應線性回歸模型 (linear mixed model)。其中，</p>
<ul>
<li>固定效應部分的參數有 fixed effect parameters: <span class="math inline">\(\beta_0, \beta_1, \beta_2\)</span>;</li>
<li>隨機效應部分的參數有 random effect parameters: <span class="math inline">\(u_j, e_{ij}\)</span>。</li>
</ul>
<p>但是和之前的隨機截距模型不同的是，這裏我們在固定效應部分增加了兩個共變量 <span class="math inline">\(X_1, X_2\)</span>，所以從該模型作出的所有統計推斷，都是建立在以這兩個共變量爲條件的基礎之上的 (conditionally on <span class="math inline">\(\mathbf{X} = \{ X_1, X_2\}\)</span>)。所以對於 <span class="math inline">\(u_j, e_{ij}\)</span>，他們的前提條件就變成了:</p>
<ul>
<li><span class="math inline">\(\text{E}(u_j|\mathbf{X} = \{ X_1, X_2\}) = 0\)</span>;</li>
<li><span class="math inline">\(\text{E}(e_{ij}|\mathbf{X} = \{ X_1, X_2, u_j\}) = 0\)</span>。</li>
</ul>
<p>根據這兩個條件，我們可以繼續得到:</p>
<ul>
<li><span class="math inline">\(\text{E}(e_{ij} | \mathbf{X} = \{ X_1, X_2\}) = 0\)</span>;</li>
<li><span class="math inline">\(\text{E}(Y_{ij} | \mathbf{X} = \{ X_1, X_2\}) = \beta_0 + \beta_1X_{1ij} + \beta_2X_{2ij}\)</span></li>
</ul>
<p>也就是說，這個包含了 <span class="math inline">\(u_j, e_{ij}\)</span> 的多元線性回歸模型，其邊際模型 (marginal regression over <span class="math inline">\(u_j, e_{ij}\)</span>) 還是一個線性回歸。</p>
<p><strong>注意</strong></p>
<ul>
<li>模型的固定效應部分加入了多個共變量 <span class="math inline">\(\mathbf{X} = \{ X_1, X_2\}\)</span> 之後，模型所估計的層內相關系數 (intra-class correlation, <span class="math inline">\(\lambda\)</span>) 也成了以這些共變量爲條件的層內相關系數。</li>
<li><span class="math inline">\(u_j\)</span> 這個層別隨機截距 (cluster-specific random intercept) 此時會囊括已知/未知的層水平的特徵 (class-level characteristics, i.e. unmeasured heterogeneity between clusters)。它會隨着你在模型中加入層水平的解釋變量而逐漸變小 (Its size will decrease as more explanatory variables for the <strong>cluster difference</strong> are included in the model)。</li>
</ul>
</div>
<div id="siblings-數據中新生兒體重的實例" class="section level2">
<h2><span class="header-section-number">60.2</span> <code>siblings</code> 數據中新生兒體重的實例</h2>
<p>在數據 <code>silblings</code> 中，研究者收集了來自 3978 名母親，8604 名新生兒出生體重 (g) 的數據。此外，該數據中還收集了這些新生兒的胎齡 (week)，新生兒的性別，母親孕期的吸煙狀況，以及懷孕時母親的年齡。在這個數據裏，每個母親是該數據的第二階層 (level 2)，每個母親的相關信息，就是屬於第二階層的層水平數據。每個新生兒的體重和相關數據，就是第一階層 (level 1) 數據，一個母親可能生 1-3 個嬰兒，這些來自同一個母親的新生兒之間很顯然不能視之爲相互獨立。研究者關心一個固定效應部分不包含其他共變量的隨機截距模型 (the Null Model)，和固定效應部分增加了其他共變量的隨機截距模型 (the Full Model) 哪個更能解釋這個數據或者更好的擬合這個數據 (better fitting the data)。</p>
<p>下面就先把數據讀入 R，然後建立一個零模型 (the Null Model):</p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb809-1" title="1">siblings &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/siblings.dta&quot;</span>)</a>
<a class="sourceLine" id="cb809-2" title="2">M0 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb809-3" title="3"><span class="kw">summary</span>(M0)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: siblings 
##        AIC       BIC     logLik
##   130951.2 130972.38 -65472.601
## 
## Random effects:
##  Formula: ~1 | momid
##         (Intercept)  Residual
## StdDev:   368.35596 377.65768
## 
## Fixed effects: birwt ~ 1 
##                 Value Std.Error   DF   t-value p-value
## (Intercept) 3467.9688 7.1385551 4626 485.80822       0
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -6.2743063820 -0.4860194138  0.0035299824  0.5053550416  4.0503923643 
## 
## Number of Observations: 8604
## Number of Groups: 3978</code></pre>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb811-1" title="1">M0_fixed &lt;-<span class="st"> </span><span class="kw">lm</span>(birwt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> siblings)</a>
<a class="sourceLine" id="cb811-2" title="2"><span class="kw">anova</span>(M0, M0_fixed)</a></code></pre></div>
<pre><code>##          Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M0           1  3 130951.20 130972.38 -65472.601                         
## M0_fixed     2  2 132265.32 132279.44 -66130.660 1 vs 2 1316.1174  &lt;.0001</code></pre>
<p>下一步，我們來對該數據擬合一個全模型 (the Full Model)，我們可以先對兩個連續型變量 (胎齡，gestational age 和母親懷孕時年齡，maternal age) 進行適當的轉換，比方說把胎齡標準化成 38 周，懷孕時年齡標準化成 30 歲:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb813-1" title="1">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb813-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_gestat =</span> gestat <span class="op">-</span><span class="st"> </span><span class="dv">38</span>, <span class="co"># centering gestational age to 38 weeks</span></a>
<a class="sourceLine" id="cb813-3" title="3">         <span class="dt">c_mage =</span> mage <span class="op">-</span><span class="st"> </span><span class="dv">30</span>,  <span class="co"># centering maternal age to 30 years old</span></a>
<a class="sourceLine" id="cb813-4" title="4">         <span class="dt">male =</span> <span class="kw">factor</span>(male, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)), </a>
<a class="sourceLine" id="cb813-5" title="5">         <span class="dt">smoke =</span> <span class="kw">factor</span>(smoke, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Nonsmoker&quot;</span>, <span class="st">&quot;Smoker&quot;</span>)))</a>
<a class="sourceLine" id="cb813-6" title="6"><span class="co">#M_full &lt;- lme(fixed = birwt ~ c_gestat + male + smoke + c_mage, random  = ~ 1 | momid, data = siblings, method = &quot;REML&quot;)</span></a>
<a class="sourceLine" id="cb813-7" title="7">M_full &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb813-8" title="8"><span class="kw">library</span>(lmerTest)</a>
<a class="sourceLine" id="cb813-9" title="9"><span class="kw">summary</span>(M_full)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + male + smoke + c_mage + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 128984.9
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.14590 -0.52884 -0.00868  0.53594  3.63288 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept)  99784   315.89  
##  Residual             118012   343.53  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3341.0957     8.6642 7084.5208 385.620 &lt; 2.2e-16 ***
## c_gestat      85.4241     2.1607 7868.3663  39.535 &lt; 2.2e-16 ***
## malemale     133.9476     8.8694 7121.4202  15.102 &lt; 2.2e-16 ***
## smokeSmoker -239.9993    15.9794 7543.5486 -15.019 &lt; 2.2e-16 ***
## c_mage        13.1579     1.0903 5400.3042  12.068 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) c_gstt maleml smkSmk
## c_gestat    -0.347                     
## malemale    -0.535  0.038              
## smokeSmoker -0.244  0.017  0.006       
## c_mage       0.137  0.020 -0.001  0.145</code></pre>
<p>從全模型的結果報告中可以看出，固定效應部分加入的所有解釋變量都是有意義的。他們的含義如下:</p>
<ul>
<li><code>c_gestat 85.42</code>: 當模型中的其他變量保持不變時 (當模型中其他的變量被調整時)，胎齡每增加一周，<strong>無論是同一個媽媽還是不同媽媽 (either from the same or another mother, i.e. in any cluster)</strong> 生下的新生兒的出生體重增加的期待值是 85.42 g。</li>
<li><code>male 133.95</code>: 新生兒的性別如果是男孩，<strong>無論是同一個媽媽還是不同媽媽</strong>生下的新生兒，他的出生體重會比女孩增加 133.95 g。</li>
</ul>
<p>再看這兩個模型的隨機效應部分，無論是第二層級水平的層標準差 (cluster-level) 還是第一層級 (elementary-level) 的標準差都隨着固定效應部分加入新的解釋變量而變小。我們同樣可以用極大似然法 (ML) 擬合這兩個模型，其方差大小總結成下面的表格:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 60.1: Summary of estimates of the variation of the random effects of the null and full model using REML or ML
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
REML
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
ML
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Random Effect
</th>
<th style="text-align:center;">
Null Model
</th>
<th style="text-align:center;">
Full Model
</th>
<th style="text-align:center;">
Null Model
</th>
<th style="text-align:center;">
Full Model
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\hat\sigma_u\)</span>
</td>
<td style="text-align:center;">
368.3558
</td>
<td style="text-align:center;">
315.8853
</td>
<td style="text-align:center;">
368.2864
</td>
<td style="text-align:center;">
315.7320
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\hat\sigma_e\)</span>
</td>
<td style="text-align:center;">
377.6577
</td>
<td style="text-align:center;">
343.5296
</td>
<td style="text-align:center;">
377.6579
</td>
<td style="text-align:center;">
343.4581
</td>
</tr>
</tbody>
</table>
<p>表格的右半部分總結的是使用極大似然法 (會偏小估計隨機效應方差)，其實它們和 REML 法估計的結果相差不大。<strong>值得強調的是，由於 REML 法每次估計的數據是去除掉固定效應部分以後的隨機誤差部分的數據，所以當兩個用 REML 法估計的混合效應模型其固定效應部分不一致的時候，這兩個模型實際擬合了不同的數據，是不能使用 LRT 來比較兩個模型哪個更好的。</strong></p>
</div>
<div id="賦值予隨機效應成分" class="section level2">
<h2><span class="header-section-number">60.3</span> 賦值予隨機效應成分</h2>
<p>值得建議地，擬合了任何一個混合效應模型以後，需要盡量避免直接跳入結論陳述階段，而應當先對模型是否符合其假定的前提條件進行模型診斷。而且，對模型的擬合後截距及其層級隨機效應 (cluster random effect) 進行視覺化展現變得十分有用。</p>
<p>總體來說，有兩種方法可以用於估計並提取這些擬合值 – ML 和 Empirical Bayes (EB)。</p>
<div id="簡單預測-simple-prediction" class="section level3">
<h3><span class="header-section-number">60.3.1</span> 簡單預測 simple prediction</h3>
<p>和簡單線性回歸模型一樣，我們可以計_算模型的預測值和觀測值之間的差，獲得一個包含了兩個隨機效應成分的量:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = \beta_0 + \beta_1X_{1ij} + u_j + e_{ij} \\
\Rightarrow Y_{ij} &amp; =  \beta_0 + \beta_1X_{1ij} + \epsilon_{ij} \\
\Rightarrow \hat\epsilon_{ij} &amp; = Y_{ij} - (\hat\beta_0 + \beta_1X_{1ij})
\end{aligned}
\]</span></p>
<p>那麼最簡單的方法就是計算了這個隨機效應成分的混合體之後，對其取平均值，作爲 <span class="math inline">\(u_j\)</span> 的簡單估計:</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb815-1" title="1">M_full &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage, <span class="dt">random  =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid, <span class="dt">data =</span> siblings, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb815-2" title="2"></a>
<a class="sourceLine" id="cb815-3" title="3">siblings<span class="op">$</span>yhat &lt;-<span class="st"> </span>M_full<span class="op">$</span>fitted[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb815-4" title="4">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb815-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">res =</span> birwt<span class="op">-</span><span class="st"> </span>yhat)</a>
<a class="sourceLine" id="cb815-6" title="6">Mean_siblings &lt;-<span class="st"> </span><span class="kw">ddply</span>(siblings, <span class="op">~</span>momid, summarise, <span class="dt">uhat =</span> <span class="kw">mean</span>(res))</a>
<a class="sourceLine" id="cb815-7" title="7">Mean_siblings[Mean_siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,]</a></code></pre></div>
<pre><code>##   momid    uhat
## 1    14 105.124</code></pre>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb817-1" title="1">siblings[siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">15</span>,<span class="dv">16</span>)]</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   momid gestat birwt  yhat   res
##   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    14     24  2790 1961.  829.
## 2    14     42  2693 3512. -819.
## 3    14     39  3600 3295.  305.</code></pre>
<p>找到編號 14 號的母親，她有三個孩子被研究者記錄到，他們中有的孩子使用該模型計算的擬合值 (fitted value = <code>yhat</code>) 並不準確。在調整了胎齡，嬰兒性別，母親的吸煙狀況，和母親懷孕時年齡後，該母親生的孩子，和該隊列的總體平均值 (overall mean) 相比較，其偏差達到了 105.12 g。</p>
<p>我們可以對每個母親的擬合偏差做總結歸納:</p>
<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb819-1" title="1"><span class="kw">summ</span>(Mean_siblings<span class="op">$</span>uhat, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.    min.      max.    
##  3978 -0.512 -10.349 395.068 -1386.937 1772.721</code></pre>
<p>可見這 3978 名母親總體的擬合偏差的均值爲 -0.511，接近零。且它的標準差接近 400。這樣一種直接利用觀測值和擬合值之差做曾內平均的方法被叫做極大似然法 ML，這樣計算獲得的平均偏差被標記爲 <span class="math inline">\(\hat u_j^{\text{ML}}\)</span></p>
</div>
<div id="eb-預測值" class="section level3">
<h3><span class="header-section-number">60.3.2</span> EB 預測值</h3>
<p>EB 法 (經驗貝葉斯法) 也一樣要利用擬合模型後的 <span class="math inline">\(\beta\)</span> 來計算獲得層殘差 (cluster level residuals)。但是用 EB 法時我們還再使用層殘差的一個前提條件: <span class="math inline">\(u_j \sim N(0, \sigma_u^2)\)</span>。在線性隨機截距模型中，EB 法計算的層級殘差和簡單法計算的層殘差之間有如下的簡單轉換關系:</p>
<p><span class="math display">\[
\hat u_j^{\text{EB}} = \hat R_j\hat u_j^{\text{ML}}
\]</span></p>
<p>其中 <span class="math inline">\(\hat R_j\)</span> 被定義爲 ML 法計算層級殘差的可靠性 (reliability of <span class="math inline">\(\hat u_j^{\text{ML}}\)</span>)，它是一個包含了層級方差和個人水平方差的方程:</p>
<p><span class="math display">\[
\hat R_j = \frac{\hat\sigma_u^2}{\hat\sigma_u^2 + \sigma_e^2/n_j} = \hat w_j \hat \sigma_u^2
\]</span></p>
<p>其中 <span class="math inline">\(\hat w_j\)</span> 是之前在章節 <a href="#fixed-inference">59.4.1</a> 定義的權重。這個 <span class="math inline">\(\hat R_j\)</span> 又被叫做是<strong>收縮因子 (shrinkage factor)</strong>，因爲它取值是在 0 到 1 之間，所以它會把 ML 法計算獲得的層級誤差按照收縮銀子比例收縮變小。當 <span class="math inline">\(\sigma_u\)</span> 本身比較小，或者個體的隨機誤差大 <span class="math inline">\(\sigma_e\)</span>，或者層內樣本量小 <span class="math inline">\(n_j\)</span> 時收縮因子的作用更大。</p>
<p>此時，預測誤差 <span class="math inline">\((\hat u_j^{\text{EB}} - u_j)\)</span> 才是我們能夠從觀測數據以及模型中獲得的均值爲零方差又最小的殘差。所以 <span class="math inline">\(\hat u_j^{\text{EB}}\)</span> 又被稱爲 <span class="math inline">\(\text{Best linear unbiased predictors, BLUP}\)</span>。</p>
<p>第二層級殘差的方差是:</p>
<p><span class="math display">\[
R_j\hat \sigma_u^2
\]</span></p>
</div>
</div>
<div id="混合效應模型的診斷" class="section level2">
<h2><span class="header-section-number">60.4</span> 混合效應模型的診斷</h2>
<p>辛苦計算了 BLUP 之後，就可以拿它，和模型的標準化殘差來對模型作出一定的診斷。由於計算獲得的 BLUP 方差不齊，要先對其標準化之後再作正態圖:</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb821-1" title="1"><span class="co"># the standardized </span></a>
<a class="sourceLine" id="cb821-2" title="2"></a>
<a class="sourceLine" id="cb821-3" title="3">n_child &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(momid, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb821-4" title="4">Mean_siblings &lt;-<span class="st"> </span><span class="kw">merge</span>(Mean_siblings, n_child, <span class="dt">by =</span> <span class="st">&quot;momid&quot;</span>)  </a>
<a class="sourceLine" id="cb821-5" title="5"></a>
<a class="sourceLine" id="cb821-6" title="6">Mean_siblings &lt;-<span class="st"> </span>Mean_siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb821-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="co"># extract the random effect (EB) residuals at level 2</span></a>
<a class="sourceLine" id="cb821-8" title="8">         <span class="dt">uhat_eb =</span> <span class="kw">ranef</span>(M_full)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, </a>
<a class="sourceLine" id="cb821-9" title="9">         <span class="co"># shrinkage factor </span></a>
<a class="sourceLine" id="cb821-10" title="10">         <span class="dt">R =</span> <span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="fl">343.4572</span><span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n), </a>
<a class="sourceLine" id="cb821-11" title="11">         <span class="co"># Empirical Bayes prediction of variance of uhat</span></a>
<a class="sourceLine" id="cb821-12" title="12">         <span class="dt">var_eb =</span> R<span class="op">*</span>(<span class="fl">315.7338</span><span class="op">^</span><span class="dv">2</span>),</a>
<a class="sourceLine" id="cb821-13" title="13">         <span class="co"># standardize the EB uhat</span></a>
<a class="sourceLine" id="cb821-14" title="14">         <span class="dt">uhat_st =</span> uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb)</a>
<a class="sourceLine" id="cb821-15" title="15">  )</a>
<a class="sourceLine" id="cb821-16" title="16"></a>
<a class="sourceLine" id="cb821-17" title="17"><span class="co"># 計算每個個體的標準化殘差</span></a>
<a class="sourceLine" id="cb821-18" title="18"></a>
<a class="sourceLine" id="cb821-19" title="19">siblings<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(M_full, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals-unst"></span>
<img src="bookdown_files/figure-html/level2-residuals-unst-1.png" alt="Histogram and Q-Q plot of cluster (mother) level unstandardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.1: Histogram and Q-Q plot of cluster (mother) level unstandardized residuals for the intercept
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals-st"></span>
<img src="bookdown_files/figure-html/level2-residuals-st-1.png" alt="Histogram and Q-Q plot of cluster (mother) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.2: Histogram and Q-Q plot of cluster (mother) level standardized residuals for the intercept
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:level1-residuals-baby"></span>
<img src="bookdown_files/figure-html/level1-residuals-baby-1.png" alt="Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.3: Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept
</p>
</div>
<p>這些正態圖，主要用於輔助尋找看哪裏有異常值 (outliers)。</p>
</div>
<div id="第二層級-cluster-levellevel-2-的協方差" class="section level2">
<h2><span class="header-section-number">60.5</span> 第二層級 (cluster level/level 2) 的協方差</h2>
<p>還是這個 <code>siblings</code> 數據中，關於母親的數據在該母親生的孩子中是保持不變的，比如有人種 (<code>black</code>)，母親受教育情況 (<code>hsgrad</code>)，和母親的婚姻狀況 (<code>married</code>)。因爲這些變量屬於解釋第二層級 (level 2) 的變量，加入這些變量在固定效應部分只能解釋層間的方差 (between clusters variance):</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb822-1" title="1">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb822-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">black =</span> <span class="kw">factor</span>(black, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)), </a>
<a class="sourceLine" id="cb822-3" title="3">         <span class="dt">hsgrad =</span> <span class="kw">factor</span>(hsgrad, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)),</a>
<a class="sourceLine" id="cb822-4" title="4">         <span class="dt">married =</span> <span class="kw">factor</span>(married, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;No&quot;</span>, <span class="st">&quot;yes&quot;</span>)))</a>
<a class="sourceLine" id="cb822-5" title="5"></a>
<a class="sourceLine" id="cb822-6" title="6">M_full1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>c_mage <span class="op">+</span><span class="st"> </span>black <span class="op">+</span><span class="st"> </span>married <span class="op">+</span><span class="st"> </span>hsgrad <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), </a>
<a class="sourceLine" id="cb822-7" title="7">                <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb822-8" title="8"><span class="kw">summary</span>(M_full1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + male + smoke + c_mage + black + married +      hsgrad + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 128884.7
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.19306 -0.53217 -0.01244  0.54116  3.65296 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept)  96846   311.20  
##  Residual             118053   343.59  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df  t value  Pr(&gt;|t|)    
## (Intercept) 3297.4611    23.3036 4601.1760 141.4998 &lt; 2.2e-16 ***
## c_gestat      84.4555     2.1584 7887.4033  39.1281 &lt; 2.2e-16 ***
## malemale     133.7891     8.8514 7160.4073  15.1150 &lt; 2.2e-16 ***
## smokeSmoker -227.9418    16.3323 7674.0013 -13.9565 &lt; 2.2e-16 ***
## c_mage        11.0375     1.1412 5488.4090   9.6716 &lt; 2.2e-16 ***
## blackYes    -177.8954    25.9709 3912.4116  -6.8498 8.554e-12 ***
## marriedyes    61.1716    22.2791 4164.2316   2.7457  0.006064 ** 
## hsgradYes     -4.2118    13.9792 3949.6037  -0.3013  0.763211    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) c_gstt maleml smkSmk c_mage blckYs mrrdys
## c_gestat    -0.111                                          
## malemale    -0.204  0.038                                   
## smokeSmoker -0.287  0.009  0.008                            
## c_mage       0.222  0.034 -0.004  0.071                     
## blackYes    -0.377  0.041  0.007  0.064  0.036              
## marriedyes  -0.914 -0.025  0.007  0.227 -0.230  0.348       
## hsgradYes   -0.165  0.011 -0.012 -0.044  0.172 -0.046  0.016</code></pre>
<p>加入了第二層級協變量之後， <span class="math inline">\(\sigma^2_u = 96845.79\)</span>，相比沒加之前的小了一些 <span class="math inline">\((\sigma^2_{u} = 99784)\)</span>。但是 <span class="math inline">\(\sigma^2_e\)</span> 幾乎保持不變。</p>
</div>
<div id="層內層間效應估計" class="section level2">
<h2><span class="header-section-number">60.6</span> 層內層間效應估計</h2>
<p>如有某個想加入模型的變量是屬於第一層級的，例如 <code>siblings</code> 數據中的胎齡，即使是同一個媽媽生的嬰兒，其出生時的胎齡也是各不相同。但是這樣在模型輸出的報告中，胎齡這一變量的估計量其實是其他變量保持不變時，<strong>每增加一周胎兒對不論是同一個母親還是不同母親生的嬰兒的出生體重的影響</strong>，怎樣才能把同一母親不同胎齡的影響 (within effect) 和不同母親不同胎齡的影響 (between effect) 給區分出來呢？</p>
<p>其實很簡單，我們來把胎齡這個變量做個分解:</p>
<p><span class="math display">\[
Y_{ij} = \beta_0 + \beta_{1B} \bar{X}_{\cdot j} + \beta_{1W} (X_{ij} - \bar{X}_{\cdot j}) + u_j + e_{ij}
\]</span></p>
<p>把胎齡這個變量分解成 <span class="math inline">\(\bar{X}_{\cdot j}\)</span> (每個母親生的嬰兒的平均胎齡)，和 <span class="math inline">\(X_{ij} - \bar{X}_{\cdot j}\)</span> (每個母親內，每個胎兒的胎齡和平均胎齡之差) 兩個部分，就解決了區分層間效應 <span class="math inline">\((\beta_{1B})\)</span> 和層內效應 <span class="math inline">\((\beta_{1W})\)</span>。 的方法。下面的模型在固定效應部分只使用了胎齡一個變量 (爲了這裏輸出報告簡潔明了):</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb824-1" title="1">M_gestat &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_gestat <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb824-2" title="2"><span class="kw">summary</span>(M_gestat)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_gestat + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 129638.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.95662 -0.52950  0.00662  0.52638  3.98718 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept) 113073   336.26  
##  Residual             124282   352.54  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3358.5435     7.1841 4956.3651 467.497 &lt; 2.2e-16 ***
## c_gestat      83.7325     2.2314 7785.2519  37.525 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr)
## c_gestat -0.406</code></pre>
<p>當把胎齡作爲一個變量放進模型的固定效應部分時，不論是不是同一個母親生下的胎兒，只要胎齡每增加一周，出生體重就增加 83.7 g。下一個模型中，我們來把胎齡這個變量分解成層間變量和層內變量:</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb826-1" title="1">Mean_gestat &lt;-<span class="st"> </span><span class="kw">ddply</span>(siblings, <span class="op">~</span><span class="st"> </span>momid, summarise, <span class="dt">mean_gestat =</span> <span class="kw">mean</span>(gestat))</a>
<a class="sourceLine" id="cb826-2" title="2"><span class="co"># 把每個母親的胎兒胎齡均值 (level 2 mean) 賦予原有的數據中</span></a>
<a class="sourceLine" id="cb826-3" title="3">avegest &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb826-4" title="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3978</span>){</a>
<a class="sourceLine" id="cb826-5" title="5">  avegest &lt;-<span class="st"> </span><span class="kw">c</span>(avegest, <span class="kw">rep</span>(Mean_gestat<span class="op">$</span>mean_gestat[i], <span class="kw">with</span>(siblings, <span class="kw">table</span>(momid))[i]))</a>
<a class="sourceLine" id="cb826-6" title="6">}</a>
<a class="sourceLine" id="cb826-7" title="7">siblings<span class="op">$</span>avegest &lt;-<span class="st"> </span>avegest</a>
<a class="sourceLine" id="cb826-8" title="8"><span class="kw">rm</span>(avegest)</a>
<a class="sourceLine" id="cb826-9" title="9"><span class="co"># 計算層內胎兒胎齡與其層均值的差異</span></a>
<a class="sourceLine" id="cb826-10" title="10">siblings &lt;-<span class="st"> </span>siblings <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb826-11" title="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_avegest =</span> avegest <span class="op">-</span><span class="st"> </span><span class="dv">38</span>, </a>
<a class="sourceLine" id="cb826-12" title="12">         <span class="dt">difgest =</span> gestat <span class="op">-</span><span class="st"> </span>avegest)</a>
<a class="sourceLine" id="cb826-13" title="13"></a>
<a class="sourceLine" id="cb826-14" title="14">siblings[siblings<span class="op">$</span>momid <span class="op">==</span><span class="st"> </span><span class="dv">14</span>,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">18</span><span class="op">:</span><span class="dv">20</span>)]</a></code></pre></div>
<pre><code>## # A tibble: 3 x 7
##   momid   idx gestat birwt avegest c_avegest difgest
##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1    14     1     24  2790      35        -3     -11
## 2    14     2     42  2693      35        -3       7
## 3    14     3     39  3600      35        -3       4</code></pre>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb828-1" title="1"><span class="co"># 下面用 c_avegest 和 difgest 代替 gestat 放入同樣模型的固定效應部分</span></a>
<a class="sourceLine" id="cb828-2" title="2"></a>
<a class="sourceLine" id="cb828-3" title="3">M_gestat_sep &lt;-<span class="st"> </span><span class="kw">lmer</span>(birwt <span class="op">~</span><span class="st"> </span>c_avegest <span class="op">+</span><span class="st"> </span>difgest <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>momid), <span class="dt">data =</span> siblings, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb828-4" title="4"><span class="kw">summary</span>(M_gestat_sep)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: birwt ~ c_avegest + difgest + (1 | momid)
##    Data: siblings
## 
## REML criterion at convergence: 129557.3
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.02183 -0.52451  0.00937  0.52315  3.98953 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  momid    (Intercept) 111117   333.34  
##  Residual             123670   351.67  
## Number of obs: 8604, groups:  momid, 3978
## 
## Fixed effects:
##              Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept) 3320.0084     8.3833 3974.3077 396.026 &lt; 2.2e-16 ***
## c_avegest    113.2183     4.0294 3996.5078  28.098 &lt; 2.2e-16 ***
## difgest       70.9350     2.6655 4626.8919  26.613 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) c_vgst
## c_avegest -0.628       
## difgest    0.000  0.000</code></pre>
<p>把胎齡分解了以後，從模型的輸出結果可以看出，層間效應 113 g (不同的母親)，要大於層內效應 70.9 g (同一母親不同胎兒)。</p>
<p>比較分解胎齡以後的模型 <code>M_gestat_sep</code> 和把胎齡作爲一個變量的模型 <code>M_gestat</code> 哪個更優，可以有兩種檢驗法:</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb830-1" title="1"><span class="co"># 1. 用 ML 法重新擬合兩個模型後進行 LRT 檢驗比較 R 可以自動幫你</span></a>
<a class="sourceLine" id="cb830-2" title="2"><span class="kw">anova</span>(M_gestat_sep, M_gestat)</a></code></pre></div>
<pre><code>## Data: siblings
## Models:
## M_gestat: birwt ~ c_gestat + (1 | momid)
## M_gestat_sep: birwt ~ c_avegest + difgest + (1 | momid)
##              Df    AIC    BIC   logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    
## M_gestat      4 129656 129684 -64823.7   129648                             
## M_gestat_sep  5 129581 129617 -64785.6   129571 76.219      1 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb832-1" title="1"><span class="co"># 2. 用 Wald 檢驗比較 Beta_1W 和 Beta_1B 是不是不同</span></a>
<a class="sourceLine" id="cb832-2" title="2"><span class="kw">linearHypothesis</span>(M_gestat_sep, <span class="st">&quot;c_avegest = difgest&quot;</span>)</a></code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## c_avegest - difgest = 0
## 
## Model 1: restricted model
## Model 2: birwt ~ c_avegest + difgest + (1 | momid)
## 
##   Df   Chisq Pr(&gt;Chisq)    
## 1                          
## 2  1 76.5998 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>無論是哪種檢驗，都告訴我們把胎齡分解了的模型更好。了解更多層內層間回歸模型，參照 <span class="citation">(Mann, De Stavola, and Leon <a href="#ref-Mann2004" role="doc-biblioref">2004</a>)</span>。</p>
</div>
<div id="到底選擇固定還是混合模型" class="section level2">
<h2><span class="header-section-number">60.7</span> 到底選擇固定還是混合模型？</h2>
<p>目前爲止我們討論了嵌套式數據可以使用固定效應模型分析，也可以使用混合效應模型來擬合，那麼到底你該選擇哪個來解釋你的數據呢？ 選擇模型永遠是一個很難回答的問題。哪種模型更加恰當 (appropriate) 其實要取決於你的數據結構，分層的數據的話層的數量是不是足夠多？以及最重要的，你的**分析目的*。</p>
<ol style="list-style-type: decimal">
<li>如果模型中想分析的層/羣組，可以被視爲唯一的實體 (uniqe entity，例如不同的種族)，而且我們希望從模型來獲得對不同種羣或者不同個體中每一個個體的估計，那麼固定效應模型是合適的。</li>
<li>如果層/羣組其實是人羣中的樣本 (samples from a real population，如例題中的母親層級，人羣衆可以有許許多多的母親)，我們打算從這個模型的結果去推論整個人羣，那麼隨機效應模型才是最合適的。</li>
<li>如果說層級本身的樣本量 (n of clusters) 太小，那麼強行使用混合效應模型的話會導致隨機效應的估計結果十分地低效，甚至沒有意義; 當然如果你的混合效應模型關心的是固定效應部分，那麼增加一些層級隨機效應應該也能達到提升統計估計效率的目的。</li>
<li>如果我們關心的是層級協變量的效應，那麼隨機效應模型是唯一的選擇。</li>
</ol>
</div>
<div id="練習題目" class="section level2">
<h2><span class="header-section-number">60.8</span> 練習題目</h2>
<div id="把-high-school-and-beyond-數據讀入-r-中" class="section level3">
<h3><span class="header-section-number">60.8.1</span> 把 High-school-and-Beyond 數據讀入 R 中。</h3>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb834-1" title="1">hsb_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/hsb_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb834-2" title="2"><span class="kw">length</span>(<span class="kw">unique</span>(hsb_selected<span class="op">$</span>schoolid)) <span class="co">## number of school = 160</span></a></code></pre></div>
<pre><code>## [1] 160</code></pre>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb836-1" title="1"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb836-2" title="2">hsb &lt;-<span class="st"> </span>hsb_selected[<span class="op">!</span><span class="kw">duplicated</span>(hsb_selected<span class="op">$</span>schoolid), ]</a>
<a class="sourceLine" id="cb836-3" title="3"></a>
<a class="sourceLine" id="cb836-4" title="4"><span class="co">## about 44 % of the schools are Catholic schools</span></a>
<a class="sourceLine" id="cb836-5" title="5"><span class="kw">with</span>(hsb, <span class="kw">tab1</span>(sector, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## sector : 
##         Frequency Percent Cum. percent
## 0              90   56.25        56.25
## 1              70   43.75       100.00
##   Total       160  100.00       100.00</code></pre>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb838-1" title="1"><span class="co">## among all the schools, average school size is 1098</span></a>
<a class="sourceLine" id="cb838-2" title="2"><span class="kw">with</span>(hsb, <span class="kw">summ</span>(size, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  obs. mean     median  s.d.    min.   max.  
##  160  1097.825 1061    629.506 100    2713</code></pre>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb840-1" title="1"><span class="co">## among all the pupils, about 53% are females</span></a>
<a class="sourceLine" id="cb840-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(female, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## female : 
##         Frequency Percent Cum. percent
## 0            3390   47.18        47.18
## 1            3795   52.82       100.00
##   Total      7185  100.00       100.00</code></pre>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" title="1"><span class="co">## among all the pupils, about 27.5% are from ethnic minorities</span></a>
<a class="sourceLine" id="cb842-2" title="2"><span class="kw">with</span>(hsb_selected, <span class="kw">tab1</span>(minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>, <span class="dt">decimal =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## minority : 
##         Frequency Percent Cum. percent
## 0            5211   72.53        72.53
## 1            1974   27.47       100.00
##   Total      7185  100.00       100.00</code></pre>
</div>
<div id="擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同" class="section level3">
<h3><span class="header-section-number">60.8.2</span> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</h3>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb844-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb844-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46645.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.126073 -0.727203  0.021883  0.757717  2.919116 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7682  2.1836  
##  Residual             37.0344  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65748    0.18799  148.30225  67.332 &lt; 2.2e-16 ***
## ses            2.39020    0.10572 6838.07757  22.609 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb846-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb846-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46649.0  46676.5 -23320.5  46641.0     7181 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.12631 -0.72766  0.02200  0.75781  2.91860 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7285  2.1745  
##  Residual             37.0298  6.0852  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65762    0.18732  149.17601  67.572 &lt; 2.2e-16 ***
## ses            2.39150    0.10569 6837.30521  22.627 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<p>其實由於樣本量 (層數) 足夠多，兩個隨機截距模型給出的參數估計十分接近。</p>
</div>
<div id="觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎" class="section level3">
<h3><span class="header-section-number">60.8.3</span> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</h3>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb848-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb848-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46611.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.148567 -0.731004  0.019288  0.753657  2.926345 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.685   1.9196  
##  Residual             37.037   6.0858  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                   Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)       11.71891    0.22806  153.58417 51.3855 &lt; 2.2e-16 ***
## ses                2.37471    0.10549 6738.85825 22.5110 &lt; 2.2e-16 ***
## factor(sector)1    2.10084    0.34112  147.35739  6.1586 6.638e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses   
## ses          0.063       
## fctr(sctr)1 -0.672 -0.091</code></pre>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb850-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb850-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46616.4  46650.8 -23303.2  46606.4     7180 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.149152 -0.730912  0.019585  0.754184  2.925231 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.6219  1.9031  
##  Residual             37.0328  6.0855  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                   Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)       11.71927    0.22651  155.49785 51.7396 &lt; 2.2e-16 ***
## ses                2.37710    0.10544 6735.02962 22.5440 &lt; 2.2e-16 ***
## factor(sector)1    2.10005    0.33875  149.11328  6.1994 5.285e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses   
## ses          0.064       
## fctr(sctr)1 -0.672 -0.092</code></pre>
<p>可以看出，<code>sector</code> 變量在學校層面上都是沒有變化的，所以加它進入混合效應的固定部分，只會對隨機效應標準差 (within level/cluster/group error) <span class="math inline">\(\hat\sigma_u\)</span> 的估計造成影響，隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span> 則幾乎不受影響。同樣的 “ML, REML” 兩種方法對結果的影響微乎其微。</p>
</div>
<div id="現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化" class="section level3">
<h3><span class="header-section-number">60.8.4</span> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</h3>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" title="1">hsb_selected &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb852-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_size =</span> (size <span class="op">-</span><span class="st"> </span><span class="kw">with</span>(hsb, <span class="kw">mean</span>(size)))<span class="op">/</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb852-3" title="3"></a>
<a class="sourceLine" id="cb852-4" title="4">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb852-5" title="5"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + c_size + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46613.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.142084 -0.732778  0.018257  0.755374  2.922664 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.6367  1.9070  
##  Residual             37.0345  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                    Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)       11.588378    0.238560  151.299117 48.5764 &lt; 2.2e-16 ***
## ses                2.374876    0.105459 6721.908756 22.5194 &lt; 2.2e-16 ***
## factor(sector)1    2.401175    0.379378  145.265476  6.3292 2.885e-09 ***
## c_size             0.053553    0.030198  148.968765  1.7734   0.07821 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1
## ses          0.063              
## fctr(sctr)1 -0.710 -0.086       
## c_size      -0.309 -0.009  0.447</code></pre>
<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb854-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + c_size + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46615.3  46656.5 -23301.6  46603.3     7179 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.142725 -0.733277  0.018426  0.756191  2.920849 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.5444  1.8827  
##  Residual             37.0307  6.0853  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                    Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)       11.589234    0.236144  154.101375 49.0769 &lt; 2.2e-16 ***
## ses                2.378431    0.105389 6715.629474 22.5680 &lt; 2.2e-16 ***
## factor(sector)1    2.399344    0.375458  147.837153  6.3904 2.035e-09 ***
## c_size             0.053456    0.029890  151.673272  1.7884    0.0757 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1
## ses          0.064              
## fctr(sctr)1 -0.710 -0.087       
## c_size      -0.309 -0.009  0.447</code></pre>
<p>增加了 <code>size</code> 進入混合效應模型的固定效應部分，對兩種參數估計方法輸出的結果 <span class="math inline">\((\hat\sigma_u, \hat\sigma_e)\)</span> 並沒有太大的影響。</p>
</div>
<div id="在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據" class="section level3">
<h3><span class="header-section-number">60.8.5</span> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</h3>
<div class="sourceCode" id="cb856"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb856-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb856-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * c_size + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46613.5
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.130458 -0.730487  0.018183  0.753342  2.922402 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.5594  1.8866  
##  Residual             37.0370  6.0858  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                           Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)              11.665327    0.240290  149.376496 48.5469 &lt; 2.2e-16 ***
## ses                       2.377719    0.105409 6689.156858 22.5572 &lt; 2.2e-16 ***
## factor(sector)1           2.618912    0.395270  140.853920  6.6256 6.788e-10 ***
## c_size                    0.022185    0.034603  151.266433  0.6411   0.52241    
## factor(sector)1:c_size    0.124462    0.069016  139.397371  1.8034   0.07349 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1 c_size
## ses          0.063                     
## fctr(sctr)1 -0.611 -0.083              
## c_size      -0.351 -0.007  0.214       
## fctr(sc)1:_  0.176 -0.001  0.308 -0.501</code></pre>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb858-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span>c_size <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb858-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) * c_size + (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##  46614.0  46662.1 -23300.0  46600.0     7178 
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.130886 -0.730494  0.017706  0.753635  2.919879 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  3.4378  1.8541  
##  Residual             37.0338  6.0855  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                           Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)              11.666606    0.237019  153.063389 49.2222 &lt; 2.2e-16 ***
## ses                       2.382601    0.105316 6679.214135 22.6234 &lt; 2.2e-16 ***
## factor(sector)1           2.616394    0.389730  144.122856  6.7134 4.063e-10 ***
## c_size                    0.021983    0.034135  155.039559  0.6440   0.52052    
## factor(sector)1:c_size    0.124598    0.068044  142.600213  1.8311   0.06917 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fct()1 c_size
## ses          0.064                     
## fctr(sctr)1 -0.611 -0.084              
## c_size      -0.351 -0.007  0.214       
## fctr(sc)1:_  0.176 -0.001  0.307 -0.502</code></pre>
<p>在兩個估計方法的報告中，交互作用項均不具有統計學意義。</p>
</div>
<div id="把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎" class="section level3">
<h3><span class="header-section-number">60.8.6</span> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</h3>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Random effect sd and random residual sd from previous 8 mixed effect models
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
REML
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
ML
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Model with
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_u\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_e\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_u\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\sigma_e\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
ses
</td>
<td style="text-align:center;">
2.184
</td>
<td style="text-align:center;">
6.085
</td>
<td style="text-align:center;">
2.175
</td>
<td style="text-align:center;">
6.085
</td>
</tr>
<tr>
<td style="text-align:center;">
ses &amp; sector
</td>
<td style="text-align:center;">
1.920
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.903
</td>
<td style="text-align:center;">
6.086
</td>
</tr>
<tr>
<td style="text-align:center;">
ses, size &amp; sector
</td>
<td style="text-align:center;">
1.907
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.883
</td>
<td style="text-align:center;">
6.085
</td>
</tr>
<tr>
<td style="text-align:center;">
ses, size &amp; sector <br> &amp; size*sector
</td>
<td style="text-align:center;">
1.887
</td>
<td style="text-align:center;">
6.086
</td>
<td style="text-align:center;">
1.854
</td>
<td style="text-align:center;">
6.086
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\hat\sigma_e\)</span> 幾乎在所有模型的估計中都保持不變。因爲我們在固定效應中增加的共變量在學校層面 (level 2) 都是一樣的。也就是說對於同一學校的學生，新增的共變量是一模一樣沒有變化的，所以在個人水平 (level 1) 的隨機效應幾乎不會發生變化。且注意到 “ML” 極大似然法估計的隨機效應標準差比 “REML” 限制性極大似然估計法給出的結果略小 1% 左右。</p>
</div>
<div id="在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化" class="section level3">
<h3><span class="header-section-number">60.8.7</span> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</h3>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb860-1" title="1">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb860-2" title="2"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46336.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.28599 -0.71963  0.03760  0.75553  2.88323 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1693  1.4728  
##  Residual             35.9184  5.9932  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)         12.944772    0.217832  217.525947  59.4254 &lt; 2.2e-16 ***
## ses                  2.059675    0.105073 6543.507619  19.6024 &lt; 2.2e-16 ***
## factor(sector)1      2.731292    0.310817  143.786789   8.7875 4.206e-15 ***
## c_size               0.076372    0.024802  148.489526   3.0793  0.002472 ** 
## factor(female)1     -1.252053    0.160241 5716.967171  -7.8135 6.572e-15 ***
## factor(minority)1   -3.098421    0.200627 3527.352578 -15.4437 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 c_size fctr(f)1
## ses          0.000                                
## fctr(sctr)1 -0.624 -0.116                         
## c_size      -0.265 -0.025  0.448                  
## factr(fml)1 -0.390  0.060  0.005    0.018         
## fctr(mnrt)1 -0.206  0.212 -0.080   -0.074  0.011</code></pre>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb862-1" title="1">Fixed_ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector) <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb862-2" title="2"><span class="kw">summary</span>(Fixed_ml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest]
## Formula: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
##      AIC      BIC   logLik deviance df.resid 
##    46338    46393   -23161    46322     7177 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.28718 -0.71993  0.03838  0.75632  2.88308 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1013  1.4496  
##  Residual             35.9062  5.9922  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)         12.947113    0.215801  222.800978  59.9956 &lt; 2.2e-16 ***
## ses                  2.062690    0.104976 6533.709343  19.6491 &lt; 2.2e-16 ***
## factor(sector)1      2.729839    0.307263  146.376477   8.8844 2.149e-15 ***
## c_size               0.076268    0.024522  151.247816   3.1102  0.002235 ** 
## factor(female)1     -1.253783    0.160045 5688.833343  -7.8339 5.602e-15 ***
## factor(minority)1   -3.101155    0.200217 3493.548744 -15.4890 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 c_size fctr(f)1
## ses          0.000                                
## fctr(sctr)1 -0.623 -0.117                         
## c_size      -0.264 -0.025  0.448                  
## factr(fml)1 -0.393  0.060  0.005    0.018         
## fctr(mnrt)1 -0.208  0.213 -0.080   -0.075  0.011</code></pre>
<p>混合效應模型的固定效應部分增加了學生性別，以及是否是少數族裔以後，“ML/REML” 估計的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 均發生了顯著變化。因爲它們在個人水平都不一樣 (level 1, within group random residuals)。</p>
</div>
<div id="檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e" class="section level3">
<h3><span class="header-section-number">60.8.8</span> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></h3>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb864-1" title="1"><span class="co"># Only minority is associated with sector. There are more pupils from</span></a>
<a class="sourceLine" id="cb864-2" title="2"><span class="co"># ethnic minorities attending catholic schools</span></a>
<a class="sourceLine" id="cb864-3" title="3"><span class="kw">with</span>(hsb_selected, <span class="kw">tabpct</span>( sector, minority, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        minority
## sector      0     1  Total
##   0      2721   921   3642
##   1      2490  1053   3543
##   Total  5211  1974   7185
## 
## Row percent 
##       minority
## sector       0       1  Total
##      0    2721     921   3642
##         (74.7)  (25.3)  (100)
##      1    2490    1053   3543
##         (70.3)  (29.7)  (100)
## 
## Column percent 
##        minority
## sector      0       %     1       %
##   0      2721  (52.2)   921  (46.7)
##   1      2490  (47.8)  1053  (53.3)
##   Total  5211   (100)  1974   (100)</code></pre>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb866-1" title="1"><span class="kw">with</span>(hsb_selected, <span class="kw">tabpct</span>( sector, female, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        female
## sector      0     1  Total
##   0      1730  1912   3642
##   1      1660  1883   3543
##   Total  3390  3795   7185
## 
## Row percent 
##       female
## sector       0       1  Total
##      0    1730    1912   3642
##         (47.5)  (52.5)  (100)
##      1    1660    1883   3543
##         (46.9)  (53.1)  (100)
## 
## Column percent 
##        female
## sector      0      %     1       %
##   0      1730   (51)  1912  (50.4)
##   1      1660   (49)  1883  (49.6)
##   Total  3390  (100)  3795   (100)</code></pre>
<div class="sourceCode" id="cb868"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb868-1" title="1"><span class="co">## there was no significant interaction between female sex and sector so</span></a>
<a class="sourceLine" id="cb868-2" title="2"><span class="co">## this is deleted from the final model</span></a>
<a class="sourceLine" id="cb868-3" title="3">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(female)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(minority) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb868-4" title="4"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * factor(female) + c_size + factor(minority) +  
##     (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46336.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.27886 -0.72057  0.03699  0.75622  2.87920 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1834  1.4776  
##  Residual             35.9191  5.9933  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                                    Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)                       12.966256    0.226778  258.535057  57.1761 &lt; 2.2e-16 ***
## ses                                2.058832    0.105092 6543.813324  19.5908 &lt; 2.2e-16 ***
## factor(sector)1                    2.671501    0.354202  219.966839   7.5423 1.203e-12 ***
## factor(female)1                   -1.294931    0.200965 7102.454639  -6.4436 1.243e-10 ***
## c_size                             0.076686    0.024873  147.469390   3.0831  0.002446 ** 
## factor(minority)1                 -3.097826    0.200706 3526.876210 -15.4347 &lt; 2.2e-16 ***
## factor(sector)1:factor(female)1    0.118573    0.332499 3731.139999   0.3566  0.721402    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 fctr(f)1 c_size fctr(m)1
## ses         -0.001                                         
## fctr(sctr)1 -0.658 -0.099                                  
## factr(fml)1 -0.463  0.051  0.291                           
## c_size      -0.246 -0.025  0.378   -0.006                  
## fctr(mnrt)1 -0.198  0.212 -0.070    0.009   -0.074         
## fctr()1:()1  0.272 -0.006 -0.476   -0.603    0.033  0.000</code></pre>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb870-1" title="1"><span class="co">## There is an interaction between minority and sector</span></a>
<a class="sourceLine" id="cb870-2" title="2">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(minority)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb870-3" title="3"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + factor(sector) * factor(minority) + c_size +  
##     factor(female) + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46306.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.25845 -0.71873  0.03640  0.76239  2.93045 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.1745  1.4746  
##  Residual             35.7700  5.9808  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##                                      Estimate  Std. Error          df  t value  Pr(&gt;|t|)    
## (Intercept)                         13.183015    0.222112  230.832589  59.3529 &lt; 2.2e-16 ***
## ses                                  2.006866    0.105303 6576.742333  19.0580 &lt; 2.2e-16 ***
## factor(sector)1                      2.249566    0.323107  163.059561   6.9623 7.782e-11 ***
## factor(minority)1                   -4.226834    0.287298 3674.763010 -14.7123 &lt; 2.2e-16 ***
## c_size                               0.094335    0.025023  153.264958   3.7699 0.0002326 ***
## factor(female)1                     -1.250756    0.159945 5731.205525  -7.8199 6.248e-15 ***
## factor(sector)1:factor(minority)1    2.167447    0.395431 3399.174556   5.4812 4.532e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) ses    fctr(s)1 fctr(m)1 c_size fctr(f)1
## ses         -0.017                                         
## fctr(sctr)1 -0.642 -0.086                                  
## fctr(mnrt)1 -0.281  0.212  0.142                           
## c_size      -0.232 -0.036  0.392   -0.145                  
## factr(fml)1 -0.382  0.059  0.005    0.007    0.018         
## fctr()1:()1  0.196 -0.090 -0.272   -0.717    0.131  0.001</code></pre>
<p>數據顯示，少數族裔更多地選擇天主教會學校學習。學生性別則與是否是天主教會學校之間沒有顯著的關係。少數族裔和教會學校之間的交互作用同時也被發現具有統計學意義。</p>
</div>
<div id="對上面最後一個模型進行殘差分析和模型的診斷" class="section level3">
<h3><span class="header-section-number">60.8.9</span> 對上面最後一個模型進行殘差分析和模型的診斷。</h3>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb872-1" title="1"><span class="co">#fit &lt;- lmer(mathach ~ ses + factor(sector)*factor(minority) + c_size + </span></a>
<a class="sourceLine" id="cb872-2" title="2"><span class="co">#              factor(female) + (1| schoolid), data=hsb_selected)</span></a>
<a class="sourceLine" id="cb872-3" title="3"><span class="co">#summary(fit)</span></a>
<a class="sourceLine" id="cb872-4" title="4">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sector)<span class="op">*</span><span class="kw">factor</span>(minority)  <span class="op">+</span><span class="st"> </span>c_size <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(female),  <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid, <span class="dt">data =</span> hsb_selected, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb872-5" title="5"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: hsb_selected 
##         AIC       BIC     logLik
##   46324.414 46386.323 -23153.207
## 
## Random effects:
##  Formula: ~1 | schoolid
##         (Intercept)  Residual
## StdDev:   1.4746055 5.9807998
## 
## Fixed effects: mathach ~ ses + factor(sector) * factor(minority) + c_size +      factor(female) 
##                                        Value  Std.Error   DF    t-value p-value
## (Intercept)                       13.1830150 0.22211246 7021  59.352884  0.0000
## ses                                2.0068664 0.10530291 7021  19.058033  0.0000
## factor(sector)1                    2.2495661 0.32310709  157   6.962293  0.0000
## factor(minority)1                 -4.2268343 0.28729849 7021 -14.712344  0.0000
## c_size                             0.0943352 0.02502303  157   3.769937  0.0002
## factor(female)1                   -1.2507559 0.15994509 7021  -7.819908  0.0000
## factor(sector)1:factor(minority)1  2.1674475 0.39543102 7021   5.481228  0.0000
##  Correlation: 
##                                   (Intr) ses    fctr(s)1 fctr(m)1 c_size fctr(f)1
## ses                               -0.017                                         
## factor(sector)1                   -0.642 -0.086                                  
## factor(minority)1                 -0.281  0.212  0.142                           
## c_size                            -0.232 -0.036  0.392   -0.145                  
## factor(female)1                   -0.382  0.059  0.005    0.007    0.018         
## factor(sector)1:factor(minority)1  0.196 -0.090 -0.272   -0.717    0.131  0.001  
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -3.258450948 -0.718733897  0.036399219  0.762392656  2.930454863 
## 
## Number of Observations: 7185
## Number of Groups: 160</code></pre>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" title="1"><span class="co"># number of students in each school</span></a>
<a class="sourceLine" id="cb874-2" title="2">n_pupil &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(schoolid, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb874-3" title="3">hsb &lt;-<span class="st"> </span><span class="kw">merge</span>(hsb, n_pupil, <span class="dt">by =</span> <span class="st">&quot;schoolid&quot;</span>)  </a>
<a class="sourceLine" id="cb874-4" title="4"></a>
<a class="sourceLine" id="cb874-5" title="5"></a>
<a class="sourceLine" id="cb874-6" title="6">hsb &lt;-<span class="st"> </span>hsb <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb874-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="co"># extract the random effect (EB) residuals (at school level)</span></a>
<a class="sourceLine" id="cb874-8" title="8">         <span class="dt">uhat_eb =</span> <span class="kw">ranef</span>(Fixed_reml)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, </a>
<a class="sourceLine" id="cb874-9" title="9">         <span class="co"># number of students in each school</span></a>
<a class="sourceLine" id="cb874-10" title="10">         <span class="co"># npupil = count(hsb_selected$schoolid)[2]$freq, </span></a>
<a class="sourceLine" id="cb874-11" title="11">         <span class="co"># shrinkage factor = sigma_u^2/(sigma_u^2+sigma_e^2/n_j)</span></a>
<a class="sourceLine" id="cb874-12" title="12">         <span class="dt">R =</span> <span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="fl">5.981</span><span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n),</a>
<a class="sourceLine" id="cb874-13" title="13">         <span class="co"># Empirical Bayes prediction of variance of uhat</span></a>
<a class="sourceLine" id="cb874-14" title="14">         <span class="dt">var_eb =</span> R<span class="op">*</span><span class="fl">1.474</span><span class="op">^</span><span class="dv">2</span>, </a>
<a class="sourceLine" id="cb874-15" title="15">         <span class="co"># standardize the uhat</span></a>
<a class="sourceLine" id="cb874-16" title="16">         <span class="dt">uhat_st =</span> uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb))</a>
<a class="sourceLine" id="cb874-17" title="17"></a>
<a class="sourceLine" id="cb874-18" title="18"><span class="co"># extract the standardized random residuals (at pupil level)</span></a>
<a class="sourceLine" id="cb874-19" title="19">hsb_selected<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(Fixed_reml, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb875-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb875-2" title="2"><span class="kw">hist</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">breaks =</span> <span class="dv">12</span>, <span class="dt">col=</span><span class="st">&#39;lightblue&#39;</span>)</a>
<a class="sourceLine" id="cb875-3" title="3"><span class="kw">qqnorm</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">ylab =</span> <span class="st">&quot;Standardized level 2 (school) residuals&quot;</span>); <span class="kw">qqline</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">col=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level2-residuals"></span>
<img src="bookdown_files/figure-html/level2-residuals-1.png" alt="Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.4: Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept
</p>
</div>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb876-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb876-2" title="2"><span class="kw">hist</span>(hsb_selected<span class="op">$</span>ehat, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">breaks =</span> <span class="dv">38</span>, <span class="dt">col=</span><span class="st">&#39;lightblue&#39;</span>)</a>
<a class="sourceLine" id="cb876-3" title="3"><span class="kw">qqnorm</span>(hsb_selected<span class="op">$</span>ehat,  <span class="dt">ylab =</span> <span class="st">&quot;Standardized level 1 (pupil) residuals&quot;</span>); <span class="kw">qqline</span>(hsb_selected<span class="op">$</span>ehat, <span class="dt">col=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:level1-residuals"></span>
<img src="bookdown_files/figure-html/level1-residuals-1.png" alt="Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept" width="80%" />
<p class="caption">
圖 60.5: Histogram and Q-Q plot of individual (pupil) level standardized residuals for the intercept
</p>
</div>
</div>
<div id="通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值" class="section level3">
<h3><span class="header-section-number">60.8.10</span> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</h3>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb877-1" title="1"><span class="kw">summ</span>(hsb<span class="op">$</span>uhat_st, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  160  -0.001 -0.004  1.007  -3.107 2.71</code></pre>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb879-1" title="1">hsb[<span class="kw">with</span>(hsb, <span class="kw">which</span>(uhat_st <span class="op">&gt;</span><span class="st"> </span><span class="fl">2.5</span>)),  <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">12</span>)]</a></code></pre></div>
<pre><code>##    sector mathach size   uhat_st
## 48      1  13.874  687 2.7097312</code></pre>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb881-1" title="1">hsb[<span class="kw">with</span>(hsb, <span class="kw">which</span>(uhat_st <span class="op">&lt;</span><span class="st"> </span><span class="fl">-2.5</span>)), <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">12</span>)]</a></code></pre></div>
<pre><code>##     sector    mathach size    uhat_st
## 135      0 15.9359999  153 -3.0189027
## 143      0 -2.0810001  745 -3.1071846</code></pre>
<p>所以，此處可以看出，隨機效應殘差下提示的隨機效應標準差可能比較極端的有上面這三所規模較小的學校。其中一所是天主教會學校，另外兩所是非天主教會學校。</p>
</div>
<div id="計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差" class="section level3">
<h3><span class="header-section-number">60.8.11</span> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</h3>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb883-1" title="1">Mean_ses_math &lt;-<span class="st"> </span><span class="kw">ddply</span>(hsb_selected,<span class="op">~</span>schoolid,summarise,<span class="dt">mean_ses=</span><span class="kw">mean</span>(ses),<span class="dt">mean_math=</span><span class="kw">mean</span>(mathach))</a>
<a class="sourceLine" id="cb883-2" title="2"></a>
<a class="sourceLine" id="cb883-3" title="3"></a>
<a class="sourceLine" id="cb883-4" title="4">hsb_selected<span class="op">$</span>dif_ses &lt;-<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb883-5" title="5"><span class="cf">for</span> (i <span class="cf">in</span> Mean_ses_math<span class="op">$</span>schoolid) {</a>
<a class="sourceLine" id="cb883-6" title="6">hsb_selected<span class="op">$</span>dif_ses[<span class="kw">which</span>(hsb_selected<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)] &lt;-<span class="st">  </span>hsb_selected<span class="op">$</span>ses[<span class="kw">which</span>(hsb_selected<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)] <span class="op">-</span><span class="st"> </span></a>
<a class="sourceLine" id="cb883-7" title="7"><span class="st">  </span>Mean_ses_math<span class="op">$</span>mean_ses[<span class="kw">which</span>(Mean_ses_math<span class="op">$</span>schoolid <span class="op">==</span><span class="st"> </span>i)]</a>
<a class="sourceLine" id="cb883-8" title="8">}</a>
<a class="sourceLine" id="cb883-9" title="9"></a>
<a class="sourceLine" id="cb883-10" title="10">hsb_selected &lt;-<span class="st"> </span>hsb_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb883-11" title="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean_ses =</span> ses <span class="op">-</span><span class="st"> </span>dif_ses)</a>
<a class="sourceLine" id="cb883-12" title="12"></a>
<a class="sourceLine" id="cb883-13" title="13"><span class="co">## total simple model with ses only </span></a>
<a class="sourceLine" id="cb883-14" title="14">Simple_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb883-15" title="15"><span class="kw">summary</span>(Simple_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46645.2
## 
## Scaled residuals: 
##       Min        1Q    Median        3Q       Max 
## -3.126073 -0.727203  0.021883  0.757717  2.919116 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  4.7682  2.1836  
##  Residual             37.0344  6.0856  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.65748    0.18799  148.30225  67.332 &lt; 2.2e-16 ***
## ses            2.39020    0.10572 6838.07757  22.609 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## ses 0.003</code></pre>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb885-1" title="1"><span class="co">## fit the extended model within and between effect separated</span></a>
<a class="sourceLine" id="cb885-2" title="2">Extend_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(mathach <span class="op">~</span><span class="st"> </span>dif_ses <span class="op">+</span><span class="st"> </span>mean_ses <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>schoolid), <span class="dt">data =</span> hsb_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb885-3" title="3"><span class="co">## the between schools effect (5.87) seems much larger than the within school effect (2.19) </span></a>
<a class="sourceLine" id="cb885-4" title="4"><span class="kw">summary</span>(Extend_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: mathach ~ dif_ses + mean_ses + (1 | schoolid)
##    Data: hsb_selected
## 
## REML criterion at convergence: 46568.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.16665 -0.72543  0.01744  0.75578  2.94540 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  schoolid (Intercept)  2.6925  1.6409  
##  Residual             37.0191  6.0843  
## Number of obs: 7185, groups:  schoolid, 160
## 
## Fixed effects:
##               Estimate Std. Error         df t value  Pr(&gt;|t|)    
## (Intercept)   12.68331    0.14938  153.65182  84.906 &lt; 2.2e-16 ***
## dif_ses        2.19117    0.10867 7021.50918  20.164 &lt; 2.2e-16 ***
## mean_ses       5.86617    0.36170  153.36659  16.218 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) dif_ss
## dif_ses  0.000        
## mean_ses 0.010  0.000</code></pre>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb887-1" title="1"><span class="co">## We find strong evidence to support that the second model gives a better fit to the data</span></a>
<a class="sourceLine" id="cb887-2" title="2">mod2&lt;-<span class="st"> </span><span class="kw">update</span>(Extend_reml, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>dif_ses <span class="op">-</span><span class="st"> </span>mean_ses)</a>
<a class="sourceLine" id="cb887-3" title="3"><span class="kw">anova</span>(Extend_reml, mod2)</a></code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: hsb_selected
## Models:
## mod2: mathach ~ (1 | schoolid)
## Extend_reml: mathach ~ dif_ses + mean_ses + (1 | schoolid)
##             Df     AIC     BIC   logLik deviance   Chisq Chi Df Pr(&gt;Chisq)    
## mod2         3 47121.8 47142.4 -23557.9  47115.8                              
## Extend_reml  5 46573.8 46608.2 -23281.9  46563.8 552.001      2 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
</div>
<div id="隨機回歸系數模型-random-coefficient-model" class="section level1">
<h1><span class="header-section-number">第 61 章</span> 隨機回歸系數模型 random coefficient model</h1>
<p>這一章節我們把隨機截距模型進一步擴展，在隨機效應部分增加隨機斜率成分 (random slope)。這樣的模型又稱隨機系數模型 (random coefficient model) 或 隨機斜率模型 (random slope model)。</p>
<div id="gcse-scores-實例" class="section level2">
<h2><span class="header-section-number">61.1</span> GCSE scores 實例</h2>
<p>第一章介紹過的 65 所中學學生在入學前的閱讀水平成績和畢業時的考試成績的 GCSE 數據，用來作爲本章介紹概念的實例。我們先對其中學校編號爲 1 的學生做兩個成績的線性回歸:</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb890-1" title="1">gcse_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/gcse_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb890-2" title="2">M_sch1 &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ])</a>
<a class="sourceLine" id="cb890-3" title="3"></a>
<a class="sourceLine" id="cb890-4" title="4"><span class="kw">summary</span>(M_sch1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt, data = gcse_selected[gcse_selected$school == 
##     1, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -22.4876  -5.4427  -1.0177   6.1932  15.4687 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 3.833302   0.982238  3.9026 0.0002141 ***
## lrt         0.709341   0.092006  7.7097 5.771e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.29 on 71 degrees of freedom
## Multiple R-squared:  0.45569,    Adjusted R-squared:  0.44802 
## F-statistic:  59.44 on 1 and 71 DF,  p-value: 5.7708e-11</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig1"></span>
<img src="bookdown_files/figure-html/hier04-fig1-1.png" alt="GCSE versus LRT in school 1" width="80%" />
<p class="caption">
圖 61.1: GCSE versus LRT in school 1
</p>
</div>
<p>當我們重復同樣的實驗，給 65 所學校 (48號學校除外，它只有兩個學生) 一一繪制回歸直線的時候，你得到的一簇直線是這樣紙的:</p>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig2"></span>
<img src="bookdown_files/figure-html/hier04-fig2-1.png" alt="Predicted regression lines of GCSE versus LRT scores: separate estimates from each school" width="80%" />
<p class="caption">
圖 61.2: Predicted regression lines of GCSE versus LRT scores: separate estimates from each school
</p>
</div>
<p>實際上這麼多學校學生的成績前後回歸線，其截距和斜率各不相同 (圖<a href="#fig:hier04-fig2">61.2</a>)。這些斜率和截距的總結歸納如下:</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb892-1" title="1"><span class="kw">summ</span>(Coefs[<span class="op">-</span><span class="dv">48</span>,])</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   -0.18  -0.33   3.29   -8.52  6.84  
## 2 lrt         64   0.54   0.54    0.18   0.04   1.08</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier04-fig3"></span>
<img src="bookdown_files/figure-html/hier04-fig3-1.png" alt="School specific slopes and intercepts" width="80%" />
<p class="caption">
圖 61.3: School specific slopes and intercepts
</p>
</div>
<p>圖 <a href="#fig:hier04-fig3">61.3</a> 展示的是這些回歸直線各自的截距 (x 軸) 和斜率 (y 軸) 的散點圖。縱橫添加的兩條直線分別是截距和斜率的均值的位置。很明顯，截距和斜率之間本身是呈現正相關的 (相關系數 0.36): <strong>如果一個學校學生入學時成績一般，但是畢業時 GCSE 成績較高，說明那所學校本身對學生成績的提升作用明顯</strong>。</p>
<p>經過擬合64個線性回歸模型，獲得 <span class="math inline">\(64\times3\)</span> 個不同的回歸線的參數 (截距，斜率，和殘差方差)。所以我們可以提出的關於 “學校” 這個個體，它們各自的入學前後成績作出的回歸線獲得的三個參數，在它的 <strong>“人羣 (可以是英國國內的中學，全歐洲的中學，或者是全世界的中學)”</strong> 中是隨機分布在一些 “均值” 附近的。</p>
</div>
<div id="隨機回歸系數的實質" class="section level2">
<h2><span class="header-section-number">61.2</span> 隨機回歸系數的實質</h2>
<p>在隨機截距模型中，截距可以隨機分布在某個均值周圍，但是每條回歸直線我們默認其解釋變量和結果變量之間的關系是一樣的 (相同斜率的一簇直線)。現在，我們來把這個模型擴展，放寬它對斜率的限制，允許不同的層與層之間不僅僅可以有不同的截距，還可以有不同的斜率:</p>
<p><span class="math display" id="eq:hier04-1">\[
\begin{equation}
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})X_{1ij} + e_{ij}
\end{equation}
\tag{61.1}
\]</span></p>
<p>其中:</p>
<ul>
<li><span class="math inline">\(u_{0j}:\)</span> 是隨機截距成分 (第 <span class="math inline">\(j\)</span> 層數據和總體均值 <span class="math inline">\(\beta_0\)</span> 之間的差異)</li>
<li><span class="math inline">\(u_{1j}:\)</span> 是隨機斜率成分 (第 <span class="math inline">\(j\)</span> 層數據和總體寫率 <span class="math inline">\(\beta_1\)</span> 之間的差異)</li>
<li><span class="math inline">\(\text{E}(u_{0j}|X_{1ij}) = 0\)</span></li>
<li><span class="math inline">\(\text{E}(u_{1j}|X_{1ij}) = 0\)</span></li>
<li><span class="math inline">\(\text{E}(e_{ij}|X_{1ij},u_{0j}, u_{1j}) = 0\)</span></li>
<li><span class="math inline">\(u_0, u_1 \perp X_{1ij}\)</span> (兩個隨機部分和解釋變量之間獨立不相關)</li>
<li><span class="math inline">\(u_0, u_1 \perp e_{ij}\)</span> (兩個隨機部分和總體的隨機誤差獨立不相關)</li>
</ul>
<p>另外，<span class="math inline">\(\mathbf{u}_j = \{u_0, u_1\}\)</span> 服從分布:</p>
<p><span class="math display">\[
\mathbf{u}_j | X_{1ij} \sim N(\mathbf{0}, \mathbf{\sum}_{\mathbf{u}})
\]</span></p>
<p>其中的 <span class="math inline">\(\mathbf{\sum}_{\mathbf{u}}\)</span> 是一個 <span class="math inline">\(2\times2\)</span> 的方差協方差矩陣:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Where } \mathbf{u}_j &amp; = (u_{0j}, u_{1j})^T \\ 
              \mathbf{0}   &amp; = (0, 0)^T \\ 
              \mathbf{\sum}_{\mathbf{u}} &amp; =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} &amp; \sigma_{u_{01}} \\
              \sigma_{u_{01}}   &amp; \sigma^2_{u_{11}} \\
              \end{array} \right)
\end{aligned}
\]</span></p>
<p><span class="math inline">\(e_{ij}\)</span> 則服從下列分布:</p>
<p><span class="math display">\[
e_{ij} | X_{1ij}, u_{0j}, u_{1j} \sim N(0, \sigma^2_e)
\]</span></p>
</div>
<div id="繼續-gcse-scores-實例" class="section level2">
<h2><span class="header-section-number">61.3</span> 繼續 GCSE scores 實例</h2>
<p>繼續用 GCSE 數據，去除掉 48 號學校以後，擬合一個固定效應模型 (相同斜率，但是不同的固定截距):</p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb894-1" title="1">FIX_inter &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ])</a></code></pre></div>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb895-1" title="1"><span class="kw">summary</span>(FIX_inter)</a></code></pre></div>
<pre><code>Call:
lm(formula = gcse ~ 0 + lrt + factor(school), data = gcse_selected[gcse_selected$school != 
    48, ])

Residuals:
   Min     1Q Median     3Q    Max 
-28.32  -4.77   0.22   5.08  24.41 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
lrt                0.5595     0.0125   44.63  &lt; 2e-16 ***
factor(school)1    4.0823     0.8806    4.64  3.7e-06 ***
factor(school)2    5.6202     1.0154    5.53  3.3e-08 ***
   ...................                  ............
   ................... &lt;Output ommited&gt; ............
   ...................                  ............
factor(school)62  -0.5566     0.8929   -0.62  0.53306    
factor(school)63   6.4827     1.3734    4.72  2.4e-06 ***
factor(school)64   1.0089     0.9808    1.03  0.30368    
factor(school)65  -1.7701     0.8415   -2.10  0.03547 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.52 on 3992 degrees of freedom
Multiple R-squared:  0.442, Adjusted R-squared:  0.433 
F-statistic: 48.7 on 65 and 3992 DF,  p-value: &lt;2e-16</code></pre>
<p>該固定效應模型 (簡單線性回歸模型) 估計的共同斜率是 0.56 (se = 0.01)，和 64 個不同的固定斜率。這些固定斜率的範圍是 -9,63 到 7.91，均值是 0.03，標準差是 3.38。估計的殘差標準差是 <code>Residual standard error: 7.52</code>。</p>
<p>如果用相同的數據，我們允許截距發生隨機變動的話 (隨機截距模型):</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb897-1" title="1">MIX_inter &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb897-2" title="2"><span class="kw">summary</span>(MIX_inter)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28044.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71619 -0.63094  0.02920  0.68478  3.26661 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  9.4273  3.0704  
##  Residual             56.6047  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                Estimate  Std. Error          df t value Pr(&gt;|t|)    
## (Intercept)    0.031006    0.405263   59.922917  0.0765   0.9393    
## lrt            0.563268    0.012471 4048.045047 45.1676   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.007</code></pre>
<p>隨機截距模型估計的共同斜率還是不變 (0.56, se = 0.01)，總體平均截距是 0.03 (無統計學意義)。截距的 (正態) 分布的標準差是 3.07。殘差標準差，和剛才簡單現行回歸計算的殘差標準差是一樣的 (=7.52)。幾乎所有我們關心的參數估計，都接近簡單線性回歸的結果，但是隨機截距模型使用的參數個數只有 4 個，固定效應模型則用到了 66 個 (很顯然隨機截距模型更加高效)。</p>
<p>接下來，我們進一步擬合本章的重點模型 – 隨機參數模型:</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb899-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb899-2" title="2"><span class="kw">summary</span>(MIX_coef)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28003
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83179 -0.63196  0.03373  0.68330  3.45517 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  school   (Intercept)  9.24988 3.04136       
##           lrt          0.01496 0.12231  0.493
##  Residual             55.38239 7.44193       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept) -0.109181   0.402637 59.913249 -0.2712   0.7872    
## lrt          0.556600   0.020114 56.334162 27.6722   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.365 
## convergence code: 0
## Model failed to converge with max|grad| = 0.00928374 (tol = 0.002, component 1)</code></pre>
<p>這個模型，不僅允許了隨機的截距，還允許每個直線的斜率成爲隨機的斜率。此時的總體平均截距被估計爲 -0.11 (依然沒有統計學意義)，標準差略微變小 (3.07 變成了 3.04)。總體平均斜率是 0.56，現在也被允許有變動，其標準差是 0.12。此時這些許許多多的估計回歸方程中，斜率和截距的相關系數是 0.49，這十分接近我們在一開始的簡單回歸64次計算獲得的斜率和截距的相關系數 (0.36)。此隨機系數模型的殘差標準差變成了 7.44，略微小於之前的 7.52。這三個模型的結果總結如下表:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 61.1: Comparison of fixed, random intercept, and random coefficient models: school data
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="6">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Model
</div>
</th>
</tr>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Fixed effect
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Random intercept
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Random coeff.
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Parameter
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
<th style="text-align:left;">
est
</th>
<th style="text-align:left;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(Fixed\; part\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\beta_0\)</span>
</td>
<td style="text-align:left;">
-0.03
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.031
</td>
<td style="text-align:left;">
0.405
</td>
<td style="text-align:left;">
-0.109
</td>
<td style="text-align:left;">
0.403
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\beta_1\)</span>
</td>
<td style="text-align:left;">
0.56
</td>
<td style="text-align:left;">
0.013
</td>
<td style="text-align:left;">
0.563
</td>
<td style="text-align:left;">
0.013
</td>
<td style="text-align:left;">
0.557
</td>
<td style="text-align:left;">
0.020
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(Random\; part\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_{u_{00}}\)</span>
</td>
<td style="text-align:left;">
3.38
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
3.07
</td>
<td style="text-align:left;">
0.312
</td>
<td style="text-align:left;">
3.041
</td>
<td style="text-align:left;">
0.311
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_{u_{11}}\)</span>
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.122
</td>
<td style="text-align:left;">
0.019
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\text{Corr}(0,1)\)</span>
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
0.494
</td>
<td style="text-align:left;">
0.149
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\sigma_e\)</span>
</td>
<td style="text-align:left;">
7.522
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
7.524
</td>
<td style="text-align:left;">
0.084
</td>
<td style="text-align:left;">
7.442
</td>
<td style="text-align:left;">
0.084
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="使用模型結果推斷" class="section level2">
<h2><span class="header-section-number">61.4</span> 使用模型結果推斷</h2>
<p>接下來，我們討論如何比較隨機系數模型，隨機截距模型，也就是如何選擇一個更優的模型。如果只是比較相同數據下，隨機系數模型和隨機截距模型的優劣，那麼只需要同時檢驗 <span class="math inline">\(u_{1j} = 0; \text{Cov}(u_{0j}, u_{1j}) = 0\)</span>。</p>
<p>就用剛剛擬合好的 <code>MIX_inter</code> 和 <code>MIX_coef</code> 來比較:</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb901-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">random =</span>  <span class="op">~</span><span class="st"> </span>lrt <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb901-2" title="2">MIX_inter &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>)</a>
<a class="sourceLine" id="cb901-3" title="3"></a>
<a class="sourceLine" id="cb901-4" title="4"><span class="kw">anova</span>(MIX_inter, MIX_coef)</a></code></pre></div>
<pre><code>##           Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## MIX_inter     1  4 28052.050 28077.281 -14022.025                         
## MIX_coef      2  6 28014.963 28052.809 -14001.482 1 vs 2 41.087068  &lt;.0001</code></pre>
<p>值得注意的是，這裏計算的 似然比的檢驗統計量服從的是一個 自由度爲 2 的卡方分布和一個 自由度爲 1 的卡方分布的混合分布。所以報告中給出的 p 值是一個保守估計，正確的 p 值可以這樣計算:</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb903-1" title="1">likelihood &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">logLik</span>(MIX_inter) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(MIX_coef)))</a>
<a class="sourceLine" id="cb903-2" title="2"><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 6.7124634e-10</code></pre>
<p>另一個重要的問題是該如何去真正理解這裏隨機系數模型給出的結果呢？</p>
<p>該模型的結果說，“人羣”中的總體均值是 -0.11，總體斜率是 0.56 (se = 0.02, 95%CI: 0.52, 0.60)。這裏的“人羣”指的是全英國/或者全世界這樣的學校。學校水平的截距和斜率服從以這兩個數字爲均值，標準差分別是 3.04 和 0.12 的正態分布。且截距和斜率之間的相關系數接近 0.50。第一層級 (學生的) 個體隨機誤差的標準差爲 7.44。這些結果可以拿來估計“學校人羣”的 95% 截距/斜率: <span class="math inline">\(-0.11 \pm 1.96 \times3.04\)</span> 和 <span class="math inline">\(0.56 \pm 1.96\times0.12\)</span>，所以人羣的截距的 95% 信賴區間是: <span class="math inline">\(-6.07, 5.85\)</span>，斜率的 95% 信賴區間是: <span class="math inline">\(0.33, 0.80\)</span>。與此形成對比的是，我們開頭給 64 所學校建立的 64 個模型的 截距和斜率拿來估計的 95% 截距信賴區間是 <span class="math inline">\(-0.18 \pm 1.96\times3.29: -6.63, 6.27\)</span>，95% 斜率信賴區間是 <span class="math inline">\(0.54 \pm 1.96 \times 0.18: 0.19, 0.89\)</span>。所以，隨機系數模型對截距和斜率的人羣估計及推斷更加精準。</p>
</div>
<div id="random-var" class="section level2">
<h2><span class="header-section-number">61.5</span> 隨機效應的方差</h2>
<p>在解釋混合效應模型的隨機效應部分的時候，有幾點需要注意。首先，隨機截距的方差，和隨機斜率的方差，是具有不同單位的。<strong>隨機截距的方差的單位是結果變量 <span class="math inline">\(Y\)</span> 的單位的平方</strong>。<strong>隨機斜率的方差，是結果變量和解釋變量的單位的商的平方</strong>。</p>
<p>另一個要注意的點是，<span class="math inline">\(Y_{ij}\)</span> 在 <span class="math inline">\(X_{1ij}\)</span> 的條件下的殘差的標準差，不是恆定不變的 (隨着 <span class="math inline">\(X_1\)</span> 的變化而變化):</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} &amp; = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j}) X_{1ij} + e_{ij}  \\ 
       &amp; = (\beta_0 + \beta_1X_{1ij}) + (u_{0j} + u_{1j}X_{1ij} + e_{ij}) \\ 
       &amp; = (\beta_0 + \beta_1X_{1ij}) + \epsilon_{ij}
\end{aligned}
\]</span></p>
<p>所以從上面的式子可看出，隨機參數模型的<strong>總體殘差 (total residuals)</strong>，<span class="math inline">\(\epsilon_{ij} = u_{0j} + u_{1j}X_{1ij} + e_{ij}\)</span>，是隨着你想給斜率隨機性的那個解釋變量的變化而變化的。也正因爲如此，總體殘差的方差，也是隨着解釋變量變化而變化的 (和解釋變量成二次方程關系，如果繪制總體慘差的方差和解釋變量之間的關系會是一個拋物線):</p>
<p><span class="math display" id="eq:hier04-3">\[
\begin{aligned}
\text{Var}(Y_{ij} | X_{1ij}) &amp; = \text{Var}( u_{0j} + u_{1j}X_{1ij} + e_{ij}) \\ 
                             &amp; = \sigma^2_{u_{00}} + X_{1ij}^2\sigma^2_{u_{11}} + 2X_{1ij}\sigma_{u_{01}} + \sigma^2_e
\end{aligned}
\tag{61.2}
\]</span></p>
</div>
<div id="模型效果評估" class="section level2">
<h2><span class="header-section-number">61.6</span> 模型效果評估</h2>
<p>擬合模型的評估中，另一個重要的事是分析第一階層殘差和第二階層殘差是不是符合其前提條件 (正態分布)。記得第二階層殘差獲取之後需要被標準化。</p>
<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb905-1" title="1">MIX_coef &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="st"> </span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.00928374 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb907-1" title="1">School_res0 &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(MIX_coef, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;EB&quot;</span>, <span class="dt">standardize =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb907-2" title="2"><span class="kw">summ</span>(School_res0)</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   0      -0.11   2.87   -7.19  6.45  
## 2 lrt         64   0      0       0.1    -0.19  0.35</code></pre>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb909-1" title="1">School_res1 &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(MIX_coef, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;EB&quot;</span>, <span class="dt">standardize =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in ranef.merMod(object, postVar = TRUE): &#39;postVar&#39; is deprecated: please use &#39;condVar&#39;
## instead</code></pre>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb911-1" title="1"><span class="kw">summ</span>(School_res1)</a></code></pre></div>
<pre><code>## 
## No. of observations = 64
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 64   0.04   -0.14   3      -6.74  7.53  
## 2 lrt         64   0.04   -0.03   1.31   -2.35  5.07</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hier4-level2-residuals"></span>
<img src="bookdown_files/figure-html/hier4-level2-residuals-1.png" alt="Q-Q plots of school level intercept and slope residuals (unstandardized)" width="80%" />
<p class="caption">
圖 61.4: Q-Q plots of school level intercept and slope residuals (unstandardized)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:4-level2sta-residuals"></span>
<img src="bookdown_files/figure-html/4-level2sta-residuals-1.png" alt="Q-Q plots of school level intercept and slope residuals (standardized)" width="80%" />
<p class="caption">
圖 61.5: Q-Q plots of school level intercept and slope residuals (standardized)
</p>
</div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  4057 0      0.034   0.989  -3.832 3.455</code></pre>
<div class="figure" style="text-align: center"><span id="fig:4-level1sta-residuals"></span>
<img src="bookdown_files/figure-html/4-level1sta-residuals-1.png" alt="Histogram and Q-Qf plots of elementary level (pupil) standardized residuals" width="80%" />
<p class="caption">
圖 61.6: Histogram and Q-Qf plots of elementary level (pupil) standardized residuals
</p>
</div>
</div>
<div id="練習題-9" class="section level2">
<h2><span class="header-section-number">61.7</span> 練習題</h2>
<ol style="list-style-type: decimal">
<li>GCSE data: 數據來自65所中學的學生畢業成績 “the Graduate Certificate of Secondary Education (GCSE) score”，和這些學生在剛剛入學時接受閱讀能力水平測試 (LRT score) 的成績。其變量和各自含義爲：</li>
</ol>
<pre><code>school          school identifier
student         student identifier
gcse            GCSE score (multiplied by 10)
lrt             LRT score (multiplied by 10)
girl            Student female gender (1 = yes, 0 = no)
schgend         type of school (1: mixed gender; 2: boys only; 3: girls only)</code></pre>
<p>###　將數據導入軟件裏，</p>
<div class="sourceCode" id="cb915"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb915-1" title="1">gcse_selected &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/gcse_selected.dta&quot;</span>)</a>
<a class="sourceLine" id="cb915-2" title="2"></a>
<a class="sourceLine" id="cb915-3" title="3"><span class="kw">length</span>(<span class="kw">unique</span>(gcse_selected<span class="op">$</span>school)) <span class="co">## number of school = 65</span></a></code></pre></div>
<pre><code>## [1] 65</code></pre>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb917-1" title="1">gcse_selected &lt;-<span class="st"> </span>gcse_selected <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb917-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">schgend =</span> <span class="kw">factor</span>(schgend, <span class="dt">labels  =</span> <span class="kw">c</span>(<span class="st">&quot;mixed geder&quot;</span>, <span class="st">&quot;boys only&quot;</span>, <span class="st">&quot;girls only&quot;</span>)))</a>
<a class="sourceLine" id="cb917-3" title="3"></a>
<a class="sourceLine" id="cb917-4" title="4"></a>
<a class="sourceLine" id="cb917-5" title="5"><span class="co">## create a subset data with only the first observation of each school</span></a>
<a class="sourceLine" id="cb917-6" title="6">gcse &lt;-<span class="st"> </span>gcse_selected[<span class="op">!</span><span class="kw">duplicated</span>(gcse_selected<span class="op">$</span>school), ]</a>
<a class="sourceLine" id="cb917-7" title="7"></a>
<a class="sourceLine" id="cb917-8" title="8"><span class="co"># 一共有 65 所學校，54% 是混合校，15% 是男校，31% 是女校</span></a>
<a class="sourceLine" id="cb917-9" title="9"><span class="kw">with</span>(gcse, <span class="kw">tab1</span>(schgend, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## schgend : 
##             Frequency Percent Cum. percent
## mixed geder        35    53.8         53.8
## boys only          10    15.4         69.2
## girls only         20    30.8        100.0
##   Total            65   100.0        100.0</code></pre>
<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb919-1" title="1"><span class="co"># 計算每所學校兩種成績的平均分，計算一個包含每所學校的平均女生人數的變量</span></a>
<a class="sourceLine" id="cb919-2" title="2">Mean_gcse_lrt &lt;-<span class="st"> </span><span class="kw">ddply</span>(gcse_selected,<span class="op">~</span>school,summarise,<span class="dt">mean_gcse=</span><span class="kw">mean</span>(gcse),<span class="dt">mean_lrt=</span><span class="kw">mean</span>(lrt), <span class="dt">mean_girl=</span><span class="kw">mean</span>(girl)) </a>
<a class="sourceLine" id="cb919-3" title="3"></a>
<a class="sourceLine" id="cb919-4" title="4"><span class="co"># 整體來說，GCSE 分數的分布比起入學前 LRT 分數的分布更加寬泛，標準差更大。</span></a>
<a class="sourceLine" id="cb919-5" title="5"><span class="co"># 意味着入學時學生閱讀成績的差異，比起畢業時成績的差異要小。</span></a>
<a class="sourceLine" id="cb919-6" title="6"><span class="co"># 或者反過來說，畢業時成績差異，比起入學時閱讀成績的差異要大。</span></a>
<a class="sourceLine" id="cb919-7" title="7"><span class="kw">summ</span>(Mean_gcse_lrt[,<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>])</a></code></pre></div>
<pre><code>## 
## No. of observations = 65
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 mean_gcse 65   -0.23  -0.34   4.39   -10.49 10.04 
## 2 mean_lrt  65   -0.31  -0.41   3.44   -7.56  6.38  
## 3 mean_girl 65   0.57   0.5     0.36   0      1</code></pre>
<div id="先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校" class="section level3">
<h3><span class="header-section-number">61.7.1</span> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</h3>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb921-1" title="1">Fix &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb921-2" title="2"><span class="kw">anova</span>(Fix)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: gcse
##                  Df   Sum Sq  Mean Sq  F value     Pr(&gt;F)    
## lrt               1 141723.2 141723.2 2505.000 &lt; 2.22e-16 ***
## factor(school)   63  37314.7    592.3   10.469 &lt; 2.22e-16 ***
## Residuals      3992 225851.9     56.6                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb923-1" title="1"><span class="kw">summary</span>(Fix) <span class="co"># 輸出結果太長，中間被省略掉</span></a></code></pre></div>
<p>LRT 的回歸系數 (直線斜率 = 0.56, se = 0.01)，殘差的標準差 <span class="math inline">\(\hat\sigma_e =\)</span> 7.52。</p>
<pre><code>Call:
lm(formula = gcse ~ lrt + factor(school), data = gcse_selected[gcse_selected$school != 
    48, ])

Residuals:
   Min     1Q Median     3Q    Max 
-28.32  -4.77   0.22   5.08  24.41 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        4.08232    0.88060    4.64  3.7e-06 ***
lrt                0.55948    0.01253   44.63  &lt; 2e-16 ***
factor(school)2    1.53785    1.34332    1.14  0.25235    
                         ...
                         ...&lt;OMITTED OUTPUT&gt;
                         ...
                         ...
factor(school)65  -5.85245    1.21850   -4.80  1.6e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.52 on 3992 degrees of freedom
Multiple R-squared:  0.442, Adjusted R-squared:  0.433 
F-statistic: 49.4 on 64 and 3992 DF,  p-value: &lt;2e-16</code></pre>
</div>
<div id="僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化" class="section level3">
<h3><span class="header-section-number">61.7.2</span> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</h3>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb925-1" title="1">Fix1 &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb925-2" title="2"><span class="kw">anova</span>(Fix1)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: gcse
##             Df   Sum Sq  Mean Sq   F value     Pr(&gt;F)    
## lrt          1 141723.2 141723.2 2222.6017 &lt; 2.22e-16 ***
## schgend      2   4728.9   2364.4   37.0807 &lt; 2.22e-16 ***
## Residuals 4053 258437.7     63.8                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb927-1" title="1"><span class="kw">summary</span>(Fix1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt + schgend, data = gcse_selected[gcse_selected$school != 
##     48, ])
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -26.17545  -5.12410   0.19171   5.35399  28.32233 
## 
## Coefficients:
##                    Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       -0.960872   0.171460 -5.6041 2.233e-08 ***
## lrt                0.594272   0.012622 47.0836 &lt; 2.2e-16 ***
## schgendboys only   1.177713   0.392041  3.0041   0.00268 ** 
## schgendgirls only  2.362920   0.275274  8.5839 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.9853 on 4053 degrees of freedom
## Multiple R-squared:  0.36171,    Adjusted R-squared:  0.36124 
## F-statistic: 765.59 on 3 and 4053 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>新的模型 <code>Fix1</code> 參數明顯減少很多，殘差標準差估計 <span class="math inline">\(\hat\sigma_u =\)</span> 7.99。LRT 的回歸系數估計僅發生了不太明顯的變化 0.59 (0.01)</p>
</div>
<div id="使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義" class="section level3">
<h3><span class="header-section-number">61.7.3</span> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</h3>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb929-1" title="1"><span class="kw">library</span>(lmerTest)</a>
<a class="sourceLine" id="cb929-2" title="2">Fixed_reml &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb929-3" title="3"><span class="kw">summary</span>(Fixed_reml)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28044.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71619 -0.63094  0.02920  0.68478  3.26661 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  9.4273  3.0704  
##  Residual             56.6047  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                Estimate  Std. Error          df t value Pr(&gt;|t|)    
## (Intercept)    0.031006    0.405263   59.922917  0.0765   0.9393    
## lrt            0.563268    0.012471 4048.045047 45.1676   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr)
## lrt 0.007</code></pre>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb931-1" title="1"><span class="kw">ranova</span>(Fixed_reml) <span class="co">## random effect test</span></a></code></pre></div>
<pre><code>## ANOVA-like table for random-effects: Single term deletions
## 
## Model:
## gcse ~ lrt + (1 | school)
##              npar   logLik     AIC     LRT Df Pr(&gt;Chisq)    
## &lt;none&gt;          4 -14022.0 28052.0                          
## (1 | school)    3 -14224.8 28455.7 405.601  1 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>隨機截距模型的輸出結果可以看出，這裏的混合模型估計的 LRT 的回歸系數跟僅有固定效應的簡單線性回歸模型估計的值完全一樣 (0.56, se=0.01)。隨機效應部分 <span class="math inline">\(\hat\sigma_e = 7.524, \hat\sigma_u = 3.07\)</span>，此時的限制性似然 (restricted log-likelihood) 是 -14022。最晚部分的隨機效應檢驗的零假設是 <span class="math inline">\(\sigma_u = 0\)</span>，且值得注意的是，由於方差本身不可能小於零，故本次檢驗只用到自由度爲 1 的卡方分布的右半側(單側)。也就是說，其替代假設有且只有 <span class="math inline">\(\sigma_u &gt; 0\)</span> 的單側假設。這裏的檢驗結果提示高度有意義 (highly significant)。</p>
</div>
<div id="在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然" class="section level3">
<h3><span class="header-section-number">61.7.4</span> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</h3>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb933-1" title="1">Fixed_reml1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>) </a>
<a class="sourceLine" id="cb933-2" title="2"><span class="co">#Fixed_reml1 &lt;- lme(fixed = gcse ~ lrt + schgend , random =  ~ 1 | school, data = gcse_selected[gcse_selected$school !=48, ], method = &quot;REML&quot;) </span></a>
<a class="sourceLine" id="cb933-3" title="3"></a>
<a class="sourceLine" id="cb933-4" title="4"><span class="kw">summary</span>(Fixed_reml1)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (1 | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 28032.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.71222 -0.63023  0.02647  0.68064  3.24445 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept)  8.4961  2.9148  
##  Residual             56.6045  7.5236  
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                      Estimate  Std. Error          df t value  Pr(&gt;|t|)    
## (Intercept)         -0.872660    0.524979   58.504248 -1.6623  0.101807    
## lrt                  0.563512    0.012465 4049.316274 45.2087 &lt; 2.2e-16 ***
## schgendboys only     0.968683    1.118170   59.752787  0.8663  0.389785    
## schgendgirls only    2.497825    0.876614   56.676553  2.8494  0.006096 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.006                
## schgndbyson -0.469  0.006         
## schgndgrlso -0.599 -0.004  0.281</code></pre>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb935-1" title="1"><span class="co">## 檢驗新增的學校種類 schgend 是否對應該加入模型。</span></a>
<a class="sourceLine" id="cb935-2" title="2"></a>
<a class="sourceLine" id="cb935-3" title="3">mod2&lt;-<span class="st"> </span><span class="kw">update</span>(Fixed_reml1, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>schgend)</a>
<a class="sourceLine" id="cb935-4" title="4"><span class="kw">anova</span>(Fixed_reml1, mod2)</a></code></pre></div>
<pre><code>## Data: gcse_selected[gcse_selected$school != 48, ]
## Models:
## mod2: gcse ~ lrt + (1 | school)
## Fixed_reml1: gcse ~ lrt + schgend + (1 | school)
##             Df     AIC     BIC   logLik deviance   Chisq Chi Df Pr(&gt;Chisq)  
## mod2         4 28045.1 28070.4 -14018.6  28037.1                            
## Fixed_reml1  6 28041.1 28079.0 -14014.6  28029.1 8.01852      2   0.018147 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb937-1" title="1"><span class="co">## 求 Fixed_reml1 的似然</span></a>
<a class="sourceLine" id="cb937-2" title="2"></a>
<a class="sourceLine" id="cb937-3" title="3"><span class="kw">logLik</span>(Fixed_reml1)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -14016.32 (df=6)</code></pre>
<p>增加了學校類型在固定效應部分時，隨機效應的標準差從錢一個模型的 3.07 降低到這裏的 2.92。這個變量本身，從最後的模型比較也能看出，對模型的貢獻是有意義的 (p=0.018)。當然從隨機截距模型的輸出結果可以看出，學校類型的這一變量中，可能只有“女校”這一細分部分提供了足夠的效應。這裏的隨機截距模型的REML似然是 (restricted log-likelihood = -14016)</p>
</div>
<div id="擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分" class="section level3">
<h3><span class="header-section-number">61.7.5</span> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</h3>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb939-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb939-2" title="2"><span class="kw">summary</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 27988.8
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83073 -0.63015  0.03252  0.68505  3.41664 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.273191 2.87632       
##           lrt          0.014941 0.12223  0.582
##  Residual             55.394026 7.44272       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##                    Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept)       -1.097818   0.497543 63.009861 -2.2065  0.031003 *  
## lrt                0.558197   0.020074 56.238393 27.8070 &lt; 2.2e-16 ***
## schgendboys only   1.041523   0.998851 57.084009  1.0427  0.301473    
## schgendgirls only  2.712024   0.783490 53.763667  3.4615  0.001061 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.321                
## schgndbyson -0.443  0.011         
## schgndgrlso -0.566  0.011  0.284</code></pre>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb941-1" title="1"><span class="kw">logLik</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -13994.393 (df=8)</code></pre>
<p>當截距 (不同學校之間， gcse 的起點)，斜率 (不同學校之間 lrt 和 gcse 之間的關系的斜率) 均可以有隨機性以後，<code>lrt</code> 的斜率雖然仍然保持不變 <span class="math inline">\(=0.56\)</span>，但是它的隨機效應標準差變成了 <span class="math inline">\(=0.12\)</span>，隨機截距的標準差也保持不變 <span class="math inline">\(=2.88\)</span>，這二者之間的相關系數是 <span class="math inline">\(=0.58\)</span>。第一階層隨機殘差標準也有了微妙的變化 <span class="math inline">\(7.52 \rightarrow 7.44\)</span>，此模型的限制性對數似然 (restricted log-likelihood) 是 <code>-13994.393 (df=8)</code>。</p>
</div>
<div id="通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義" class="section level3">
<h3><span class="header-section-number">61.7.6</span> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</h3>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb943-1" title="1"><span class="kw">ranova</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## ANOVA-like table for random-effects: Single term deletions
## 
## Model:
## gcse ~ lrt + schgend + (lrt | school)
##                       npar   logLik     AIC     LRT Df Pr(&gt;Chisq)    
## &lt;none&gt;                   8 -13994.4 28004.8                          
## lrt in (lrt | school)    6 -14016.3 28044.6 43.8549  2 2.9994e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb945-1" title="1"><span class="co"># 手算的方法是這樣的</span></a>
<a class="sourceLine" id="cb945-2" title="2">likelihood &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">logLik</span>(Fixed_reml1) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(Fixed_reml2)))</a>
<a class="sourceLine" id="cb945-3" title="3"><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(likelihood), <span class="dt">df =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 1.6765206e-10</code></pre>
<p>似然比檢驗的統計量是 43.8，不用檢驗也知道肯定是有意義的。手算也是可以達到相同的效果。值得注意的是，R計算給出的基於自由度爲 2 的卡方分布，其實是偏保守的。注意看手算部分，其實用到了自由度爲 1 自由度爲 2 兩個卡方分布換算獲得的 p 值。</p>
</div>
<div id="模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢" class="section level3">
<h3><span class="header-section-number">61.7.7</span> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</h3>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb947-1" title="1"><span class="co">## 把女生平均值放回整體數據中去</span></a>
<a class="sourceLine" id="cb947-2" title="2">Mean_girl &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb947-3" title="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">65</span>) {</a>
<a class="sourceLine" id="cb947-4" title="4">  Mean_girl &lt;-<span class="st"> </span><span class="kw">c</span>(Mean_girl, <span class="kw">rep</span>(Mean_gcse_lrt<span class="op">$</span>mean_girl[i], <span class="kw">with</span>(gcse_selected, <span class="kw">table</span>(school))[i]))</a>
<a class="sourceLine" id="cb947-5" title="5">  }</a>
<a class="sourceLine" id="cb947-6" title="6">gcse_selected<span class="op">$</span>mean_girl &lt;-<span class="st"> </span>Mean_girl</a>
<a class="sourceLine" id="cb947-7" title="7">  <span class="kw">rm</span>(Mean_girl)</a>
<a class="sourceLine" id="cb947-8" title="8"></a>
<a class="sourceLine" id="cb947-9" title="9"></a>
<a class="sourceLine" id="cb947-10" title="10">Fixed_reml3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>mean_girl <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">!=</span><span class="dv">48</span>, ], <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.0133708 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb949-1" title="1"><span class="kw">summary</span>(Fixed_reml3)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + mean_girl + (lrt | school)
##    Data: gcse_selected[gcse_selected$school != 48, ]
## 
## REML criterion at convergence: 27997.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.81956 -0.63168  0.02994  0.68439  3.43510 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.910687 2.98508       
##           lrt          0.014913 0.12212  0.524
##  Residual             55.388585 7.44235       
## Number of obs: 4057, groups:  school, 64
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept) -1.280012   0.705470 63.122621 -1.8144  0.07437 .  
## lrt          0.556711   0.020084 56.134006 27.7190  &lt; 2e-16 ***
## mean_girl    2.066161   1.031544 56.693987  2.0030  0.04997 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) lrt   
## lrt        0.220       
## mean_girl -0.828 -0.004
## convergence code: 0
## Model failed to converge with max|grad| = 0.0133708 (tol = 0.002, component 1)</code></pre>
<p>由於 <code>mean_girl</code> 其實是和 <code>schgend</code> 非常相似的表示學校層面的男女生性別比例的變量，所以這個模型的結果其實和前一個給出的隨機效應標準差的估計都很接近。</p>
</div>
<div id="現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt" class="section level3">
<h3><span class="header-section-number">61.7.8</span> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</h3>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb951-1" title="1">gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="dv">48</span>, ]</a></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   school student  gcse   lrt  girl schgend    mean_girl
##    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt;
## 1     48       1 -7.00 -3.73     1 girls only         1
## 2     48       2 -1.29 -4.55     1 girls only         1</code></pre>
<div class="sourceCode" id="cb953"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb953-1" title="1">school48lm &lt;-<span class="st"> </span><span class="kw">lm</span>(gcse <span class="op">~</span><span class="st"> </span>lrt, <span class="dt">data =</span> gcse_selected[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="dv">48</span>, ])</a>
<a class="sourceLine" id="cb953-2" title="2"><span class="kw">summary</span>(school48lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gcse ~ lrt, data = gcse_selected[gcse_selected$school == 
##     48, ])
## 
## Residuals:
## ALL 2 residuals are 0: no residual degrees of freedom!
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -32.7221         NA      NA       NA
## lrt          -6.9018         NA      NA       NA
## 
## Residual standard error: NaN on 0 degrees of freedom
## Multiple R-squared:       1, Adjusted R-squared:     NaN 
## F-statistic:    NaN on 1 and 0 DF,  p-value: NA</code></pre>
<p>由於 48 號學校只有兩個數據點，所以強行進行簡單線性回歸的結果，就是擬合了一條通過這兩個點的直線，截距是-32.7，斜率是 -6.9，且沒有任何估計的誤差。</p>
</div>
<div id="這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎" class="section level3">
<h3><span class="header-section-number">61.7.9</span> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</h3>
<div class="sourceCode" id="cb955"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb955-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend <span class="op">+</span><span class="st">  </span>(lrt <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> gcse_selected, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model failed to
## converge with max|grad| = 0.00818763 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb957-1" title="1"><span class="kw">summary</span>(Fixed_reml2)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: gcse ~ lrt + schgend + (lrt | school)
##    Data: gcse_selected
## 
## REML criterion at convergence: 28001.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -3.83122 -0.63095  0.03275  0.68533  3.41855 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. Corr 
##  school   (Intercept)  8.248850 2.87208       
##           lrt          0.014968 0.12234  0.581
##  Residual             55.376791 7.44156       
## Number of obs: 4059, groups:  school, 65
## 
## Fixed effects:
##                    Estimate Std. Error        df t value  Pr(&gt;|t|)    
## (Intercept)       -1.099128   0.496903 63.306305 -2.2120  0.030586 *  
## lrt                0.558013   0.020081 56.230723 27.7876 &lt; 2.2e-16 ***
## schgendboys only   1.041049   0.997646 57.338679  1.0435  0.301094    
## schgendgirls only  2.672800   0.779708 54.625681  3.4280  0.001163 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) lrt    schgndbo
## lrt          0.321                
## schgndbyson -0.443  0.011         
## schgndgrlso -0.569  0.010  0.285  
## convergence code: 0
## Model failed to converge with max|grad| = 0.00818763 (tol = 0.002, component 1)</code></pre>
<p>可以看到，即使我們加入這個數據量極少的一個學校的數據，對結果也沒有太大的影響。</p>
</div>
<div id="計算這個模型的第二階級level-2-school-level的殘差" class="section level3">
<h3><span class="header-section-number">61.7.10</span> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</h3>
<div class="sourceCode" id="cb959"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb959-1" title="1">School_res &lt;-<span class="st"> </span>HLMdiag<span class="op">::</span><span class="kw">HLMresid</span>(Fixed_reml2, <span class="dt">level =</span> <span class="st">&quot;school&quot;</span>)</a>
<a class="sourceLine" id="cb959-2" title="2"><span class="kw">summ</span>(School_res)</a></code></pre></div>
<pre><code>## 
## No. of observations = 65
## 
##   Var. name   obs. mean   median  s.d.   min.   max.  
## 1 (Intercept) 65   0      0.11    2.65   -6.25  5.83  
## 2 lrt         65   0      0       0.1    -0.19  0.33</code></pre>
<div class="sourceCode" id="cb961"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb961-1" title="1">School_res[<span class="dv">48</span>, ] </a></code></pre></div>
<pre><code>##    (Intercept)          lrt
## 48 -0.73877885 -0.014709819</code></pre>
<p>隨機截距的殘差估計範圍在 -6.25 和 5.83 之間，隨機斜率殘差估計範圍在 -0.19 和 0.33 之間。其中 48 號學校的擬合後截距和斜率分別是 -0.74 和 -0.02。48 號學校在這個模型中估計的截距和斜率，與我們單獨對它一所學校擬合模型時的結果大相徑庭。這是因爲在總體的混合效應模型中，該學校的數據被拉近與總體的平均水平。</p>
<div class="figure" style="text-align: center"><span id="fig:4-level2-residuals"></span>
<img src="bookdown_files/figure-html/4-level2-residuals-1.png" alt="Q-Q plots of school level intercept and slope (unstandardized) residuals" width="80%" />
<p class="caption">
圖 61.7: Q-Q plots of school level intercept and slope (unstandardized) residuals
</p>
</div>
<p>圖 <a href="#fig:4-level2-residuals">61.7</a> 顯示標準化前的隨機效應部分的殘差表現尚可接受。</p>
</div>
<div id="計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何" class="section level3">
<h3><span class="header-section-number">61.7.11</span> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</h3>
<div class="sourceCode" id="cb963"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb963-1" title="1">Fixed_reml2 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> gcse <span class="op">~</span><span class="st"> </span>lrt <span class="op">+</span><span class="st"> </span>schgend, <span class="dt">random =</span> <span class="op">~</span><span class="st">  </span>lrt <span class="op">|</span><span class="st"> </span>school, <span class="dt">data =</span> gcse_selected, <span class="dt">method=</span><span class="st">&quot;REML&quot;</span>) <span class="co"># for extracting standardized level 2 error</span></a>
<a class="sourceLine" id="cb963-2" title="2"></a>
<a class="sourceLine" id="cb963-3" title="3">gcse_selected<span class="op">$</span>ehat &lt;-<span class="st"> </span><span class="kw">residuals</span>(Fixed_reml2, <span class="dt">level =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>)</a>
<a class="sourceLine" id="cb963-4" title="4"><span class="kw">with</span>(gcse_selected, <span class="kw">summ</span>(ehat, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  4059 0      0.033   0.989  -3.831 3.419</code></pre>
<div class="sourceCode" id="cb965"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb965-1" title="1"><span class="co">#  48 號學校的標準化殘差並不顯得異常</span></a>
<a class="sourceLine" id="cb965-2" title="2">gcse_selected<span class="op">$</span>ehat[gcse_selected<span class="op">$</span>school <span class="op">==</span><span class="st"> </span><span class="dv">48</span>]</a></code></pre></div>
<pre><code>## [1] -0.780061331  0.046827706</code></pre>
<div class="figure" style="text-align: center"><span id="fig:4-level1-residuals"></span>
<img src="bookdown_files/figure-html/4-level1-residuals-1.png" alt="Histogram and Q-Q plots of elementary level (pupil) standardized residuals" width="80%" />
<p class="caption">
圖 61.8: Histogram and Q-Q plots of elementary level (pupil) standardized residuals
</p>
</div>
</div>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-1" class="section level1">
<h1><span class="header-section-number">第 62 章</span> 縱向研究數據 longitudinal data 1</h1>
<p>本章我們來把目前爲止了解的混合效應 (截距/斜率) 模型應用到一種特殊形態的數據 – 縱向研究數據 – 中去。</p>
<p>縱向數據，是一種前瞻性收集的來的數據，它隨着時間的推移，在不同的時間點對相同的觀察對象進行數據的採集。每個研究對象被收集數據時的時間點，可以是相同的，也可以是不同的。在很多臨牀實驗中，患者被觀察隨訪，並且常常在同樣的時間點收集數據，所以在臨牀實驗的特殊形態下，每個患者收集數據的時間點可以做到統一，這樣的縱向研究數據是屬於<strong>固定測量時刻的類型 (fixed occasions)</strong>。但是在流行病學等觀察性研究中獲得的數據，就沒有這麼幸運，他們通常測量收集數據的時間點就不太可能保持一致，收集時間點不一致的縱向數據屬於<strong>不固定測量時刻的類型 (variable occasions)</strong>。</p>
<p>縱向數據英文名是 longitudinal data，它的常見別的名稱是 重復測量數據 (repeated measures data)，計量經濟學中叫做面板型數據 (panel data)，或者是時間序列橫斷面研究數據 (cross sectional time series data)。所以在縱向數據這種特殊形態的的嵌套式數據結構中，第二層級結構就是一個個的個體，第一層級結構，就是每個個體在不同的時間點獲得的測量值。除了和前面幾章討論過的嵌套式數據結構相似可以應用混合效應模型，縱向數據還有一些自己獨特的性質需要加以考量:</p>
<ul>
<li>層內數據的相關性結構是有測量時間的先後順序的;</li>
<li>之前討論的嵌套式結構數據在層內的觀察值則沒有嚴格的時間或者大小的排序 (例如同一所學校的不同學生);</li>
<li>換句話說，層內相關系數 (intra-class correlation) 很難被認爲是相似或者相同的。</li>
</ul>
<div id="固定測量時刻-fixed-occasions" class="section level2">
<h2><span class="header-section-number">62.1</span> 固定測量時刻 fixed occasions</h2>
<p>對於臨牀試驗中固定時刻隨訪收集到的病人數據，理想狀態下應該是一種平衡數據 (balanced data)。也就是在不同時間 <span class="math inline">\(t_i , i = 1, \cdots, n\)</span> 我們成功收集到所有患者的所有數據，所以每層 (名患者) 擁有的時間序列數據的樣本量是相同的 <span class="math inline">\(n_j = n, \forall j\)</span>。</p>
<p>如同分析其他類型的數據一樣，分析縱向數據也要從描述數據開始。如果是平衡數據，描述性分析就很容易，當有缺失值時，分析就變得有些棘手。例如，我們可以計算每個時間點的平均值作爲所有患者的 “平均特質 average profiles”。或者也可以用每個人的時間序列數據對時間做簡單線性回歸模型，從而獲取每個個體的截距和斜率。</p>
<div id="缺失值-missing-data" class="section level3">
<h3><span class="header-section-number">62.1.1</span> 缺失值 Missing data</h3>
<p>當縱向數據中存在一些缺失值，即使你在計算一些簡單的歸納性分析，也要<strong>特別特別特別</strong>地小心。如果不是所有人都有全部測量時間點的數據的話，總體的平均特徵數據分析了也沒有太大的卵用，因爲缺失值導致這樣計算獲得的並不是真實的平均值 (也因爲不同的患者，貢獻了不同時間點的數據，沒辦法平均)。</p>
<p>如果存在缺失值，那麼當且僅當這些缺失值和觀測值 <span class="math inline">\(Y\)</span> 之間沒有關系時，才能認爲這些簡單計算和簡單模型的建立是不帶有偏倚的。如果說，有些缺失值確實是根據觀測數據有選擇性地缺失 (the mechanism driving the selection depends on measured data)，隨機效應模型的建立可以自動化校正這樣的缺失，從而保證估計無偏。</p>
<p>根據觀測數據選擇性地出現缺失值的機制被叫做隨機缺失 (Missing at random, MAR)。</p>
<div id="隨機截距模型-random-intercept-model-1" class="section level4">
<h4><span class="header-section-number">62.1.1.1</span> 隨機截距模型 random intercept model</h4>
<p><strong>復合對稱模型 compound symmetry model</strong>， 是常見的一種用於重復測量數據的模型，它是基於隨機截距模型的一種擴展模型。</p>
<p>當模型中沒有解釋變量時，</p>
<p><span class="math display" id="eq:hier05-1">\[
\begin{equation}
Y_{ij} = \mu_i + u_{0j} + e_{ij}
\end{equation}
\tag{62.1}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(i\)</span> 是測量時刻;</li>
<li><span class="math inline">\(j\)</span> 是實驗的個體;</li>
<li><span class="math inline">\(\mu_i\)</span> 是測量時刻 <span class="math inline">\(i\)</span> 時的平均截距 – 這是一個固定效應。</li>
</ul>
<p>爲了擬合這個模型，我們需要先生成一系列的啞變量用來表示不同的測量時刻:</p>
<p><span class="math display">\[
Y_{ij} = \sum_{h=1}^n\beta_{0h} I_{i = h,j} + u_{0j} + e_{ij}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(I_{i = h,j}\)</span> 是用於表示第 <span class="math inline">\(j\)</span> 名患者的 <span class="math inline">\(i\)</span> 次觀測值，在第 <span class="math inline">\(h\)</span> 次測量時是否被測量到的啞變量。</li>
<li>該模型暗示同一個患者收集到的不同時刻的觀察數據是可以互換的，有相同的協方差
<span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j} , Y_{2j}) &amp; = \text{Cov}(u_{0j} + e_{1j}, u_{0j} + e_{2j}) \\ 
                          &amp; = \sigma^2_{u_{00}}
\end{aligned}
\]</span></li>
<li>該模型還有另一個暗示是，不同患者之間任意時間點的兩個觀察數據之間是相互獨立的
<span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j*}) &amp; = \text{Cov}(u_{0j} + e_{1j}, u_{0j*} + e_{2j*}) \\ 
                          &amp; = 0
\end{aligned}
\]</span></li>
</ul>
<p>所以當沒有缺失值時，數據是固定測量時刻 (fixed occation) 的數據也是是平衡數據，那麼每一個患者 (第二層級數據) 的觀察值可以寫作是一個向量 <span class="math inline">\(\{ \mathbf{Y}_{ij} \}\)</span>，每名患者的觀察值向量的長度都是相同的 <span class="math inline">\(n\)</span>。所以，它們的 <span class="math inline">\(n\times n\)</span> 協方差矩陣就是:</p>
<p><span class="math display">\[
\Omega_y = \left( \begin{array}{cccc} 
 \sigma^2_{u_{00}} + \sigma^2_e &amp; \sigma^2_{u_{00}}  &amp; \cdots &amp; \sigma^2_{u_{00}} \\
 \sigma_{u_{00}}   &amp; \sigma^2_{u_{00}} + \sigma^2_e    &amp; \cdots &amp; \sigma^2_{u_{00}} \\
 \vdots            &amp; \vdots                            &amp; \vdots &amp; \vdots \\
 \sigma^2_{u_{00}} &amp; \sigma^2_{u_{00}}                &amp;  \cdots &amp; \sigma^2_{u_{00}} + \sigma^2_e\\
\end{array} \right)
\]</span></p>
<p>也正是由於觀測值的協方差矩陣是如此地對稱，該模型被命名爲復合對稱模型 compound symmetric model。</p>
<p><strong>Adult height measures 數據</strong></p>
<p>有(閒人)花了數十年時間追蹤隨訪了近2000名女性在 26 歲，36歲，43歲，53歲時的身高。忽略掉可能存在的測量誤差，研究者想知道是否隨着年齡增加，女性的身高會縮水。這些女性在這些年齡時的身高數據總結如下:</p>
<div class="sourceCode" id="cb967"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb967-1" title="1">height &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/height.dta&quot;</span>)</a>
<a class="sourceLine" id="cb967-2" title="2"><span class="kw">summ</span>(height[, <span class="dv">2</span><span class="op">:</span><span class="dv">5</span>])</a></code></pre></div>
<pre><code>## 
## No. of observations = 2187
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 ht26      1758 162.33 162.6   6.36   142.2  180.3 
## 2 ht36      1610 162.26 162.2   6.05   135.2  180   
## 3 ht43      1567 162.28 162.1   5.96   140    180   
## 4 ht53      1462 161.56 161.5   5.96   134.3  179.6</code></pre>
<p>原則上每個女性在所有的時間應該都有身高測量值才對，我們暫且認爲擁有缺失測量值的時間點是完全隨機的。先計算樣本中數據完整部分的女性身高在四個時間點時的方差協方差矩陣:</p>
<div class="sourceCode" id="cb969"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb969-1" title="1"><span class="kw">var</span>(height[, <span class="dv">2</span><span class="op">:</span><span class="dv">5</span>], <span class="dt">use =</span> <span class="st">&quot;complete.obs&quot;</span>)</a></code></pre></div>
<pre><code>##           ht26      ht36      ht43      ht53
## ht26 39.813400 34.758457 34.478981 34.128167
## ht36 34.758457 34.455060 33.360413 33.086680
## ht43 34.478981 33.360413 34.331501 32.948850
## ht53 34.128167 33.086680 32.948850 34.215187</code></pre>
<p>要給這個數據擬合混合對稱模型 (compound symmetry model)，需要先把數據從寬變長，之後爲每個測量身高的時間點生成一個啞變量，然後擬合無截距式的隨機截距模型:</p>
<div class="sourceCode" id="cb971"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb971-1" title="1"><span class="co"># 把數據格式從寬變長</span></a>
<a class="sourceLine" id="cb971-2" title="2">hei_long &lt;-<span class="st"> </span>height <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-3" title="3"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>id, <span class="op">-</span>bw, <span class="op">-</span>mht) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-4" title="4"><span class="st">    </span><span class="kw">separate</span>(key, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;Height&quot;</span>, <span class="st">&quot;H_Age&quot;</span>), <span class="dt">sep =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-5" title="5"><span class="st">      </span><span class="kw">arrange</span>(id, H_Age, bw, mht) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-6" title="6"><span class="st">        </span><span class="kw">spread</span>(Height, value)</a>
<a class="sourceLine" id="cb971-7" title="7"></a>
<a class="sourceLine" id="cb971-8" title="8"><span class="co"># 生成四個年齡時間點數據的啞變量</span></a>
<a class="sourceLine" id="cb971-9" title="9">hei_long &lt;-<span class="st"> </span>hei_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb971-10" title="10"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Age_1 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">26</span>, <span class="dv">1</span>, <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb971-11" title="11">         <span class="dt">Age_2 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">36</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb971-12" title="12">         <span class="dt">Age_3 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">43</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb971-13" title="13">         <span class="dt">Age_4 =</span> <span class="kw">ifelse</span>(H_Age <span class="op">==</span><span class="st"> </span><span class="dv">53</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb971-14" title="14">M_hei &lt;-<span class="st"> </span><span class="kw">lmer</span>(ht <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">3</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">4</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> hei_long, <span class="dt">REML =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb971-15" title="15"><span class="kw">summary</span>(M_hei)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;]
## Formula: ht ~ 0 + Age_1 + Age_2 + Age_3 + Age_4 + (1 | id)
##    Data: hei_long
## 
## REML criterion at convergence: 30475.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -4.69990 -0.46089 -0.00475  0.45917  8.26749 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 35.9056  5.9921  
##  Residual              1.9862  1.4093  
## Number of obs: 6397, groups:  id, 1980
## 
## Fixed effects:
##         Estimate Std. Error         df t value  Pr(&gt;|t|)    
## Age_1  162.34141    0.13903 2151.19114  1167.7 &lt; 2.2e-16 ***
## Age_2  162.31738    0.13977 2195.10608  1161.3 &lt; 2.2e-16 ***
## Age_3  162.19431    0.13997 2207.43550  1158.8 &lt; 2.2e-16 ***
## Age_4  161.45320    0.14041 2234.23204  1149.9 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##       Age_1 Age_2 Age_3
## Age_2 0.933            
## Age_3 0.931 0.933      
## Age_4 0.928 0.930 0.931</code></pre>
<div class="sourceCode" id="cb973"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb973-1" title="1"><span class="co"># 檢驗三個年齡點的身高均值是否相同用下面的方法: </span></a>
<a class="sourceLine" id="cb973-2" title="2"><span class="kw">linearHypothesis</span>(M_hei, <span class="kw">c</span>(<span class="st">&quot;Age_1 - Age_2 = 0&quot;</span>, </a>
<a class="sourceLine" id="cb973-3" title="3">                          <span class="st">&quot;Age_1 - Age_3 = 0&quot;</span>, </a>
<a class="sourceLine" id="cb973-4" title="4">                          <span class="st">&quot;Age_1 - Age_4 = 0&quot;</span>))</a></code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## Age_1 - Age_2 = 0
## Age_1 - Age_3 = 0
## Age_1 - Age_4 = 0
## 
## Model 1: restricted model
## Model 2: ht ~ 0 + Age_1 + Age_2 + Age_3 + Age_4 + (1 | id)
## 
##   Df   Chisq Pr(&gt;Chisq)    
## 1                          
## 2  3 374.564 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>所以，用這個模型 (符合對稱模型 compound symmetry model)，其實我是在告訴 R 軟件說，我認爲，這個數據中的女性四次測量的身高之間的方差協方差矩陣是這樣紙的 (因爲 <span class="math inline">\(5.992^2 = 35.91; 1.409^2 = 1.99\)</span>):</p>
<p><span class="math display">\[
\Omega_y = \left( \begin{array}{cccc} 
 37.90 &amp; 35.91  &amp; 35.91 &amp; 35.91 \\
 35.91 &amp; 37.90  &amp; 35.91 &amp; 35.91 \\
 35.91 &amp; 35.91  &amp; 37.90 &amp; 35.91 \\
 35.91 &amp; 35.91  &amp; 35.91 &amp; 37.90\\
\end{array} \right)
\]</span></p>
<p>分析這個模型第二層階級殘差，和第一層階級殘差可以計算並做圖 <a href="#fig:5-level2-res">62.1</a> <a href="#fig:5-level1-res">62.2</a> 如下:</p>
<div class="sourceCode" id="cb975"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb975-1" title="1"><span class="co"># refit the model with lme</span></a>
<a class="sourceLine" id="cb975-2" title="2">M_hei &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> ht <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">3</span> <span class="op">+</span><span class="st"> </span>Age_<span class="dv">4</span>, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, </a>
<a class="sourceLine" id="cb975-3" title="3">             <span class="dt">data =</span> hei_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action=</span>na.omit)</a>
<a class="sourceLine" id="cb975-4" title="4"><span class="co"># individual level standardized residuals</span></a>
<a class="sourceLine" id="cb975-5" title="5">ehat_st &lt;-<span class="st"> </span><span class="kw">residuals</span>(M_hei, <span class="dt">type =</span> <span class="st">&quot;normalized&quot;</span>, <span class="dt">level =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb975-6" title="6"></a>
<a class="sourceLine" id="cb975-7" title="7"><span class="co"># extract the EB uhat (level 2 EB residual)</span></a>
<a class="sourceLine" id="cb975-8" title="8">uhat_eb &lt;-<span class="st"> </span><span class="kw">ranef</span>(M_hei)<span class="op">$</span><span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span></a>
<a class="sourceLine" id="cb975-9" title="9"></a>
<a class="sourceLine" id="cb975-10" title="10"><span class="co"># standardized level 2 residuals</span></a>
<a class="sourceLine" id="cb975-11" title="11"><span class="co">### count number of measures for each women</span></a>
<a class="sourceLine" id="cb975-12" title="12">Nmeas &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb975-13" title="13"><span class="co">### shrinkage factor </span></a>
<a class="sourceLine" id="cb975-14" title="14">R =<span class="st"> </span><span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">1.409</span><span class="op">^</span><span class="dv">2</span><span class="op">/</span>Nmeas)</a>
<a class="sourceLine" id="cb975-15" title="15"><span class="co">### use shrinkage factor calculate variance of uhat_eb</span></a>
<a class="sourceLine" id="cb975-16" title="16">var_eb &lt;-<span class="st"> </span>R <span class="op">*</span><span class="st"> </span><span class="fl">5.992</span><span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb975-17" title="17"><span class="co">### standardize uhat</span></a>
<a class="sourceLine" id="cb975-18" title="18">uhat_st &lt;-<span class="st"> </span>uhat_eb<span class="op">/</span><span class="kw">sqrt</span>(var_eb)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:5-level2-res"></span>
<img src="bookdown_files/figure-html/5-level2-res-1.png" alt="Standardized cluster level residuals (intercept) from the compound symmetry model" width="80%" />
<p class="caption">
圖 62.1: Standardized cluster level residuals (intercept) from the compound symmetry model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:5-level1-res"></span>
<img src="bookdown_files/figure-html/5-level1-res-1.png" alt="Standardized elementary level residuals from the compound symmetry model" width="80%" />
<p class="caption">
圖 62.2: Standardized elementary level residuals from the compound symmetry model
</p>
</div>
<p>混合對稱模型的前提假設實在是太強了 (它假定個體內的方差保持不變，且個體間的協方差也保持不變)。你我都清楚，當考慮了時間以後，同一個體在時間上比較接近的點測量之間會更相似，也更相關。</p>
</div>
<div id="隨機參數模型-random-intercept-and-slope-model" class="section level4">
<h4><span class="header-section-number">62.1.1.2</span> 隨機參數模型 random intercept and slope model</h4>
<p>實際上有多種方法可以放鬆混合對稱模型對方差和協方差的約束性前提，其中之一是在隨機截距模型中允許有隨機斜率成分。</p>
<p>使用隨機參數模型擬合縱向數據時的簡單模型如下:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})t_i +e_{ij}
\]</span></p>
<p>前一章討論過 (滾回 <a href="#random-var">61.5</a>)，這裏隨機參數模型的解釋變量是時間 <span class="math inline">\(t_i\)</span>，導致的結果之一是觀測值的方差其實是隨着時間變化而變化的 (拋物線關系):</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(Y_{ij}) &amp; = \text{Cov}(u_{0j} + u_{ij}t_i + e_{ij}, u_{0j} + u_{ij}t_i + e_{ij})  \\ 
                   &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_i^2 + 2t_i\sigma_{u_{01}} + \sigma^2_e
\end{aligned}
\]</span></p>
<p>同時，同一患者不同時間測量的觀測值之間的協方差是:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_1 + e_{1j}, u_{0j} + u_{2j}t_2 + e_{2j}) \\ 
&amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1t_2 + \sigma_{u_{01}}(t_1 + t_2)
\end{aligned}
\]</span></p>
<p>不同患者任意測量時刻之間的協方差是:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(Y_{1j}, Y_{2j*}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_1 + e_{1j}, u_{0j*} + u_{2j*}t_2 + e_{2j*}) \\ 
&amp; = 0
\end{aligned}
\]</span></p>
<p><strong>Adult height measures 數據</strong></p>
<p>利用上面的理論，來對身高數據擬合另一個混合效應模型:</p>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb976-1" title="1"><span class="co"># 對年齡中心化到以 26 歲爲起點</span></a>
<a class="sourceLine" id="cb976-2" title="2">hei_long &lt;-<span class="st"> </span>hei_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb976-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age =</span> <span class="kw">as.numeric</span>(H_Age) <span class="op">-</span><span class="st"> </span><span class="dv">26</span>)</a>
<a class="sourceLine" id="cb976-4" title="4">M_hei_ran &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> ht <span class="op">~</span><span class="st"> </span>age, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> hei_long, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb976-5" title="5"><span class="co">#M_hei_ran &lt;- lmer(ht ~ age + (age | id), data = hei_long, REML = TRUE)</span></a>
<a class="sourceLine" id="cb976-6" title="6"><span class="kw">summary</span>(M_hei_ran)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: hei_long 
##         AIC       BIC     logLik
##   30382.427 30423.006 -15185.213
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev      Corr  
## (Intercept) 6.158844448 (Intr)
## age         0.059929578 -0.281
## Residual    1.259210714       
## 
## Fixed effects: ht ~ age 
##                 Value   Std.Error   DF    t-value p-value
## (Intercept) 162.49616 0.141129788 4416 1151.39521       0
## age          -0.03158 0.002273653 4416  -13.88951       0
##  Correlation: 
##     (Intr)
## age -0.279
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -3.9386996996 -0.4542383385 -0.0066047392  0.4297466638  5.5051618893 
## 
## Number of Observations: 6397
## Number of Groups: 1980</code></pre>
<p>這個混合效應模型同時包含了隨機截距和隨機斜率兩個部分。你可以用 LRT 比較它和一個只有隨機截距的模型哪個更好，但是我們沒有辦法比較它和混合對稱模型哪個更優於擬合這個數據 (因爲他們的固定效應部分不同，在 REML 方法下實際二者擬合的數據是不同的)。這個隨機系數模型和前一個混合對稱模型都給出了身高隨着年齡增加而減少的相同結論。不同的是，隨機系數模型把同一對象內不同時間觀測值之間的等協方差的約束條件給放開了，因爲用腳趾頭想也知道<strong>同一個人不同時間測量的數據之間的協方差會隨着時間跨度不同而發生改變</strong>。</p>
<p>根據隨機系數模型給出的報告，計算模型估計的觀測值 (身高的4個時間點) 的方差協方差矩陣:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\text{Cov}}(Y_{1j}, Y_{2j}) &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1t_2 +\sigma_{u_{01}} (t_1 + t_2) \\
 &amp; = 6.1588^2 + 0.0599^2t_1t_2 + (-0.28)\times6.1588\times0.0599 (t_1 + t_2)\\ 
 &amp; = 37.93 + 0.004\times t_2 \times t_2 - 0.104 \times(t_1 + t_2) \\
\hat{\text{Var}} (Y_1j) &amp; = \sigma^2_{u_{00}} + \sigma^2_{u_{11}}t_1^2 - 2\sigma_{u_{01}}t_1 + \sigma_e^2 \\ 
&amp; = 37.93 + 0.004 \times t_1^2 - 0.104\times2\times t_1 + 1.59
\end{aligned}
\]</span></p>
<p>所以，當 <span class="math inline">\(t_1 = 0, t_2 = 10, t_3 = 17, t_4 = 27\)</span> 時，</p>
<p><span class="math display">\[
\mathbf{\hat{\Sigma}_u} =  \left( \begin{array}{cccc} 
 39.52 &amp; 36.90  &amp; 36.17 &amp; 35.14 \\
 36.90 &amp; 37.81  &amp; 35.75 &amp; 35.07 \\
 36.17 &amp; 35.75  &amp; 37.03 &amp; 35.03 \\
 35.14 &amp; 35.07  &amp; 35.03 &amp; 36.54 \\
\end{array} \right)
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:5-level2-ress"></span>
<img src="bookdown_files/figure-html/5-level2-ress-1.png" alt="UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.3: UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:5-level1-res0"></span>
<img src="bookdown_files/figure-html/5-level1-res0-1.png" alt="Standardized elementary level residuals from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.4: Standardized elementary level residuals from the random intercept and slope model
</p>
</div>
</div>
</div>
</div>
<div id="不固定測量時刻-variable-occasions" class="section level2">
<h2><span class="header-section-number">62.2</span> 不固定測量時刻 variable occasions</h2>
<p>當重復收集的數據不是平衡數據時，意味着不同的人數據的收集時間點不一樣，我們就無法像前面那樣用協方差矩陣的方式來描述不同人不同時間點之間測量值可能存在的相關性，也沒有辦法給每個時間點所有人的數據做平均值作爲全部人的平均特質。</p>
<p>但是我們可以把不固定測量時刻的不平衡數據看作是受缺失值數據影響的平衡數據 (unbalanced data can be thought of as balanced data affected by missingness)。所以需要特別小心謹慎，因爲用線性混合效應模型擬合這樣的數據，其實是在含蓄地假設那些應該出現但是沒有出現的測量值的缺失是隨機的。</p>
<p><strong>Asian growth data 實例</strong></p>
<p>在本部分開頭的章節介紹過，這是一個收集了亞洲兒童在 6 周，8 個月，12 個月，和 27 個月大時的體重數據。</p>
<div class="figure" style="text-align: center"><span id="fig:Hier05-07"></span>
<img src="bookdown_files/figure-html/Hier05-07-1.png" alt="Growth profiles of boys and girls in the Asian growth data" width="80%" />
<p class="caption">
圖 62.5: Growth profiles of boys and girls in the Asian growth data
</p>
</div>
<p>如圖 <a href="#fig:Hier05-07">62.5</a> 所示，觀察男孩女孩的體重隨着時間的變化，似乎暗示男孩子體重增加的速度較高，且男孩中體重增加的差異 (方差) 似乎也較女孩子的體重增加曲線來得大。另外，體重和年齡的關系並不是線性的，而且，這些數據中有缺失值。</p>
<p><strong>隨機截距模型</strong></p>
<p>第一個想到的合適模型應該包括一個隨機截距，一個固定效應的線性和拋物線性的年齡項，還有最後一個啞變量用以區分男孩和女孩:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + \beta_1t_{ij} + \beta_2 t_{ij}^2 + \beta_3 \text{girl}_j + e_{ij}
\]</span></p>
<p>在 R 裏擬合這個模型:</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb978-1" title="1">growth &lt;-<span class="st"> </span>growth <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb978-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age2 =</span> age<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb978-3" title="3"></a>
<a class="sourceLine" id="cb978-4" title="4">M_growth &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb978-5" title="5"><span class="kw">summary</span>(M_growth)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   565.93442 585.54157 -276.96721
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)   Residual
## StdDev:  0.85945071 0.73940625
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value  Std.Error  DF     t-value p-value
## (Intercept)  3.7992533 0.21210411 128  17.9122095  0.0000
## age          7.8173952 0.29051698 128  26.9085652  0.0000
## age2        -1.7054785 0.10891077 128 -15.6594104  0.0000
## genderGirls -0.7341374 0.23590992  66  -3.1119397  0.0027
##  Correlation: 
##             (Intr) age    age2  
## age         -0.579              
## age2         0.509 -0.970       
## genderGirls -0.549 -0.009  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.320321237 -0.444855166  0.024075779  0.446113187  3.991809168 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb980"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb980-1" title="1"><span class="co">## 由於樣本量較小，這裏如果使用極大似然法估計 ML，結果就和 REML 估計的隨機效應的方差部分不太相同</span></a>
<a class="sourceLine" id="cb980-2" title="2">M_growthml &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;ML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb980-3" title="3"><span class="kw">summary</span>(M_growthml)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##  Data: growth 
##         AIC       BIC     logLik
##   556.32603 576.05563 -272.16301
## 
## Random effects:
##  Formula: ~1 | id
##         (Intercept)   Residual
## StdDev:  0.84433851 0.73390172
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value  Std.Error  DF     t-value p-value
## (Intercept)  3.7997442 0.21160249 128  17.9569922  0.0000
## age          7.8161949 0.29116479 128  26.8445748  0.0000
## age2        -1.7050759 0.10915202 128 -15.6211122  0.0000
## genderGirls -0.7340920 0.23465616  66  -3.1283729  0.0026
##  Correlation: 
##             (Intr) age    age2  
## age         -0.582              
## age2         0.511 -0.970       
## genderGirls -0.548 -0.009  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.340993892 -0.446771161  0.028578899  0.450565995  4.026706851 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<p><strong>隨機截距和斜率模型</strong></p>
<p>此時我們再來用相同的數據擬合混合效應模型，現在允許線性年齡的斜率有隨機變化:</p>
<div class="sourceCode" id="cb982"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb982-1" title="1">M_growth_mix &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb982-2" title="2"><span class="kw">summary</span>(M_growth_mix)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC      BIC     logLik
##   533.95003 560.0929 -258.97502
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 0.61487769 (Intr)
## age         0.51776878 0.135 
## Residual    0.57411956       
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.7954977 0.168145176 128  22.572742  0.0000
## age          7.6984362 0.239853311 128  32.096435  0.0000
## age2        -1.6577339 0.088594491 128 -18.711478  0.0000
## genderGirls -0.5983844 0.199974765  66  -2.992300  0.0039
##  Correlation: 
##             (Intr) age    age2  
## age         -0.543              
## age2         0.502 -0.929       
## genderGirls -0.588 -0.008  0.007
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -2.041884180 -0.442600563 -0.032412546  0.419399620  2.669681965 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<p>這裏可以看到隨機殘差 (residuals) 的標準差 (<code>StdDev</code>) 部分在後者(混合系數模型)中明顯變小了 <span class="math inline">\((0.74\rightarrow 0.54)\)</span>。另外，第二層級殘差和第一層級殘差 (未標準化) 如圖 <a href="#fig:hier05-10">62.6</a> 和 <a href="#fig:hier05-11">62.7</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:hier05-10"></span>
<img src="bookdown_files/figure-html/hier05-10-1.png" alt="UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.6: UN-Standardized cluster level residuals (intercept and slope) from the random intercept and slope model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:hier05-11"></span>
<img src="bookdown_files/figure-html/hier05-11-1.png" alt="Standardized elementary level residuals from the random intercept and slope model" width="80%" />
<p class="caption">
圖 62.7: Standardized elementary level residuals from the random intercept and slope model
</p>
</div>
</div>
<div id="預測軌跡-predicting-trajectories" class="section level2">
<h2><span class="header-section-number">62.3</span> 預測軌跡 predicting trajectories</h2>
<p>比較只有隨機截距模型，和隨機系數模型給出的擬合曲線是否有差異 如圖<a href="#fig:hier05-12">62.8</a>，其實差異十分微小。可以用下面的 R 代碼:</p>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb984-1" title="1">growth<span class="op">$</span>traj2 &lt;-<span class="st"> </span><span class="kw">fitted</span>(M_growth_mix) </a>
<a class="sourceLine" id="cb984-2" title="2">growth<span class="op">$</span>traj1 &lt;-<span class="st"> </span><span class="kw">fitted</span>(M_growth) </a>
<a class="sourceLine" id="cb984-3" title="3"></a>
<a class="sourceLine" id="cb984-4" title="4">G &lt;-<span class="st"> </span><span class="kw">ggplot</span>(growth[growth<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">258</span>,<span class="dv">1141</span>,<span class="dv">3148</span>,<span class="dv">287</span>),], <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">19</span>, <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-5" title="5"><span class="st"> </span><span class="co"># geom_line(aes(y = traj1)) + </span></a>
<a class="sourceLine" id="cb984-6" title="6"><span class="co">#  geom_line(aes(y = traj2), linetype = 2) +</span></a>
<a class="sourceLine" id="cb984-7" title="7"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="kw">aes</span>(<span class="dt">y =</span> traj1), <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), <span class="dt">se =</span> F, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-8" title="8"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="kw">aes</span>(<span class="dt">y =</span> traj2), <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), <span class="dt">se =</span> F)  <span class="op">+</span></a>
<a class="sourceLine" id="cb984-9" title="9"><span class="st">   </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb984-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb984-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb984-12" title="12"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>))</a>
<a class="sourceLine" id="cb984-13" title="13"></a>
<a class="sourceLine" id="cb984-14" title="14"></a>
<a class="sourceLine" id="cb984-15" title="15">G <span class="op">+</span><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>id, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb984-16" title="16"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">face =</span> <span class="st">&quot;bold&quot;</span>, <span class="dt">size =</span> <span class="kw">rel</span>(<span class="fl">1.5</span>)))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:hier05-12"></span>
<img src="bookdown_files/figure-html/hier05-12-1.png" alt="Observed weight and predicted growth profiles of four babies in the Asian growth data" width="80%" />
<p class="caption">
圖 62.8: Observed weight and predicted growth profiles of four babies in the Asian growth data
</p>
</div>
</div>
<div id="practical-05-hier" class="section level2">
<h2><span class="header-section-number">62.4</span> Practical 05-Hier</h2>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-2" class="section level1">
<h1><span class="header-section-number">第 63 章</span> 縱向研究數據 longitudinal data 2</h1>
<p>本章沒有代碼，學會如何用矩陣標記法寫下你的多元混合效應模型。</p>
<div id="邊際結構-marginal-structures" class="section level2">
<h2><span class="header-section-number">63.1</span> 邊際結構 marginal structures</h2>
<p>至此，我們接觸過的各種混合效應模型其實代表的是數據不同的邊際結構關系 (marginal relations)。</p>
<div id="隨機截距模型" class="section level3">
<h3><span class="header-section-number">63.1.1</span> 隨機截距模型</h3>
<p>縱向數據中，數據可能是平衡或不平衡數據，簡單的隨機截距模型可以標記如下:</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + \beta_1 t_{ij} + e_{ij}
\]</span></p>
<p>這個模型隱含着如下的條件關系 (conditional relation):</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ij} | t_{ij}, u_{0j} &amp; \sim N(\beta_0 + \beta_1t_{ij} + u_{0j}, \sigma^2_e)\\ 
 u_{0j}|t_{ij} &amp; \sim N(0, \sigma^2_u) \\
 \text{Var}(Y_{ij} | t_{ij}, u_{0j})  &amp; = \sigma^2_e
\end{aligned}
\]</span></p>
<p>也就是說，觀測值 <span class="math inline">\(Y_{ij}\)</span> 以時間 <span class="math inline">\(t\)</span>，和隨機截距 <span class="math inline">\(u_0\)</span> 爲條件的方差，只取決於 <span class="math inline">\(\sigma^2_e\)</span>。所以，屬於同一層 (同一患者不同測量時間) 的測量值，以該層 (患者) 的截距爲條件 (conditional on <span class="math inline">\(u_j\)</span>) 的協方差是 <span class="math inline">\(\text{Cov} (Y_{ij}, Y_{i*j}|t_{ij}, t_{i*j}, u_j) = 0\)</span>。</p>
<p><span class="math inline">\(Y_{ij}\)</span> 針對 <span class="math inline">\(u_j\)</span> 的邊際期望 (marginal espectation with respect to <span class="math inline">\(u_j\)</span>):</p>
<p><span class="math display">\[
E(Y_{ij}|t_{ij}) = \beta_0 + \beta_1 t_{ij}
\]</span></p>
<p>其方差爲 <span class="math inline">\(\text{Var}(Y_{ij}|t_{ij}) = \sigma^2_u + \sigma^2_e\)</span>，同一層 (同一患者) 的兩個不同時刻測量值之間的邊際協方差就是 <span class="math inline">\(\text{Cov}(Y_{ij}, Y_{i*j}|t_{ij},t_{i*j}) = \sigma^2_u\)</span>。</p>
</div>
<div id="隨機系數模型" class="section level3">
<h3><span class="header-section-number">63.1.2</span> 隨機系數模型</h3>
<p>模型的數學標記是</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j})t_{ij} + e_{ij}
\]</span></p>
<p>等同於</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + \beta_1t_{ij}) + (u_{0j} + u_{1j}t_{ij}) + e_{ij}
\]</span></p>
<p>其<strong>條件關系</strong>是</p>
<p><span class="math display">\[
Y_{ij}|t_{ij},u_{0j},u_{1j} \sim N( \beta_0 + \beta_1t_{ij} + u_{0j} + u_{1j}t_{ij}, \sigma^2_e)
\]</span></p>
<p>其中， <span class="math inline">\(\mathbf{u}_j|t_{ij} \sim N(0, \mathbf{\Sigma}_u)\)</span>，且</p>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} &amp; \sigma_{u_{01}} \\
              \sigma_{u_{01}}   &amp; \sigma^2_{u_{11}} \\
              \end{array} \right)
\\
\text{Cov} (Y_{ij}, Y_{i*j}|t_{ij}, t_{i*j}, u_{oj}, u_{1j}) = 0
\]</span></p>
<p>其所指的<span class="math inline">\(Y_{ij}\)</span>的邊際分布:</p>
<p><span class="math display">\[
\begin{aligned}
E(Y_{ij}|t_{ij})   &amp; = \beta_0 + \beta_1t_{ij} \\
\text{Var}(Y_{ij}) &amp; = \sigma^2_{u_{00}}  +2\sigma_{u_{01}}t_{ij} + \sigma^2_{u_{11}}t_{ij}^2 + \sigma^2_e \\
\text{Cov}(Y_{ij}, Y_{i*j}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_{ij} + e_{ij}, u_{0j} + u_{1j}t_{i*j} + e_{i*j}) \\
                   &amp; = \sigma^2_{u_{00}} + \sigma_{u_{01}}(t_{ij} + t_{i*j}) + \sigma^2_{u_{11}}t_{ij}t_{i*j} \text{ (for } i \neq i*) \\
\text{Cov}(Y_{ij}, Y_{i*j*}) &amp; = \text{Cov}(u_{0j} + u_{1j}t_{ij} + e_{ij}, u_{0j*} + u_{1j*}t_{i*j*} + e_{i*j*}) \\ 
&amp; = 0 \text{ (for } j \neq j*) 
\end{aligned}
\]</span></p>
<p>也就是說<strong>同一層 (同一患者) 的不同測量值之間的協方差不爲零，是時間的函數</strong>。</p>
</div>
</div>
<div id="矩陣記法" class="section level2">
<h2><span class="header-section-number">63.2</span> 矩陣記法</h2>
<p>如果數據本身是<strong>平衡數據</strong>，可以用如下的矩陣標記混合效應模型，</p>
<ul>
<li><span class="math inline">\(j\)</span> 是每個患者 (第二層級)，<span class="math inline">\(\mathbf{Y}_j, \mathbf{e}_j\)</span> 向量被定義爲:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_j &amp; =  \left( \begin{array}{c}
Y_{1j} \\
Y_{2j} \\
\cdots \\
\cdots \\
Y_{nj}
\end{array}
\right) \\
\mathbf{e}_j &amp; =  \left( \begin{array}{c}
e_{1j} \\
e_{2j} \\
\cdots \\
\cdots \\
e_{nj}
\end{array}
\right) \\
\end{aligned}
\]</span></p>
<p>用三次測量時間 <span class="math inline">\(t_1, t_2, t_3\)</span> (以簡便標記) 來繼續接下來的推導，定義矩陣 <span class="math inline">\(\mathbf{T}, \mathbf{\beta}, \mathbf{u}_j\)</span>:</p>
<p><span class="math display">\[
\mathbf{T} = \left(\begin{array}{c}
1 &amp; t_1 \\
1 &amp; t_2 \\
1 &amp; t_3 
\end{array}
\right) \\
\mathbf{\beta} = \left( \begin{array}{c}
\beta_0 \\
\beta_1 
\end{array}
\right) \\
\mathbf{u}_j = \left(\begin{array}{c}
u_{0j} \\
u_{1j} 
\end{array}
\right)
\]</span></p>
<p>如此經過利用定義好的向量，我們就可以把模型用矩陣標記來記錄，從無窮無盡的下標中解放出來:</p>
<p><span class="math display">\[
\mathbf{Y = T\beta + Tu + e} \\ 
\text{Where } \mathbf{u} \sim N(0, \mathbf{\Sigma}_u) \\ 
              \mathbf{e} \sim N(0, \sigma^2_e\mathbf{I})
\]</span></p>
<p>那麼</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Y}) = \mathbf{T\Sigma}_u\mathbf{T}^T + \sigma^2_e \mathbf{I}
\]</span></p>
</div>
<div id="混合效應模型的一般化公式" class="section level2">
<h2><span class="header-section-number">63.3</span> 混合效應模型的一般化公式</h2>
<p>前面的例子用的雖然是時間做解釋變量 (縱向數據)，但是也可以推廣到一般的混合效應模型:</p>
<p><span class="math display">\[
\mathbf{Y = T\beta + Zu + e}
\]</span></p>
<p>其中 <span class="math inline">\(\mathbf{Z}\)</span> 是類似 <span class="math inline">\(\mathbf{T}\)</span> 的共變量矩陣。類似地，<span class="math inline">\(\mathbf{Y}\)</span> 的方差是:</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Y}) = \mathbf{Z\Sigma}_u\mathbf{Z}^T + \mathbf{\Sigma}_e \\
\mathbf{Y} \sim N(\mathbf{T\beta}, \mathbf{Z\Sigma}_u\mathbf{Z}^T + \mathbf{\Sigma}_e )
\]</span></p>
<p>這就是一個多元線性混合效應回歸模型，大多數情況下，<span class="math inline">\(\mathbf{\Sigma}_e = \sigma^2_e\mathbf{I}\)</span>。</p>
</div>
<div id="其他可選擇的方差協方差矩陣特徵" class="section level2">
<h2><span class="header-section-number">63.4</span> 其他可選擇的方差協方差矩陣特徵</h2>
<p>學會了上面的矩陣標記以後，就應該了解在這樣的多元混合效應模型中，對於層內方差，協方差矩陣的 <span class="math inline">\(\mathbf{\Sigma_u}\)</span> 結構初步假設是相當重要的。目前爲止我們接觸過的模型的方差協方差矩陣結構列舉如下 (爲了簡便標記都用<span class="math inline">\(3\times3\)</span> 的矩陣來表示):</p>
<ul>
<li>復合對稱結構 (compound symmetry structure - compound symmetry model) 又名爲可交換結構 (exchangeable structure)</li>
</ul>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u} + \sigma^2_e &amp; \sigma^2_{u}             &amp;  \sigma^2_{u} \\
              \sigma^2_{u}              &amp; \sigma^2_{u} + \sigma^2_e&amp; \sigma^2_{u}  \\
              \sigma^2_{u}              &amp; \sigma^2_{u} &amp; \sigma^2_{u} + \sigma^2_e \\
              \end{array} \right)
\]</span></p>
<ul>
<li>隨機系數結構 random coefficient (RC) structure</li>
</ul>
<p><span class="math display">\[
\mathbf{\sum}_{\mathbf{u}}  =\left( \begin{array}{cc}
              \sigma^2_{u_{00}} + \sigma^2_e       &amp; \sigma^2_{u_{00}} + \sigma_{u_{01}} &amp;  \sigma^2_{u_{00}} + 2\sigma_{u_{01}} \\
              \sigma^2_{u_{00}} + \sigma_{u_{01}}  &amp; \sigma^2_{u_{00}} + 2\sigma_{u_{01}} + \sigma^2_{u_{11}} + \sigma^2_e&amp; \sigma^2_{u_{00}} + 3\sigma_{u_{01}} + 2\sigma^2_{u_{11}}  \\
              \sigma^2_{u_{00}} + 2\sigma_{u_{01}} &amp; \sigma^2_{u_{00}} + 3\sigma_{u_{01}} + 2\sigma^2_{u_{11}} &amp; \sigma^2_{u_{00}} + 4\sigma_{u_{01}} + 4\sigma^2_{u_{11}}+\sigma^2_e \\
              \end{array} \right)
\]</span></p>
<p>除了這兩個結構以外其他常見方差寫方差結構還有:</p>
<ul>
<li>自回歸結構 (autoregressive structure):</li>
</ul>
<p><span class="math display">\[
\frac{\phi}{1-\alpha^2} \left(\begin{array}{ccc}
1 &amp; \alpha &amp; \alpha^2 \\
\alpha &amp; 1  &amp; \alpha \\
\alpha^2 &amp; \alpha  &amp; 1
\end{array}
\right)
\]</span></p>
<ul>
<li>無固定結構 (unstructure):</li>
</ul>
<p><span class="math display">\[
\left(\begin{array}{ccc}
\sigma_{11} &amp; \sigma_{12}  &amp;\sigma_{13} \\
\sigma_{21} &amp; \sigma_{22}  &amp;\sigma_{23} \\
\sigma_{31} &amp; \sigma_{32}  &amp;\sigma_{33}
\end{array}
\right)
\]</span></p>
<p>最後不要忘記了還有完全獨立結構 (不需要任何復雜模型或校正其數據間的依賴性):</p>
<p><span class="math display">\[
\sigma^2\left(\begin{array}{ccc}
1 &amp; 0  &amp; 0 \\
0 &amp; 1  &amp; 0 \\
0 &amp; 0  &amp; 1
\end{array}
\right)
\]</span></p>
</div>
<div id="其他要點評論" class="section level2">
<h2><span class="header-section-number">63.5</span> 其他要點評論</h2>
<ul>
<li><p>各種結構模型之間的相互比較</p>
<ul>
<li>似然比檢驗法 the likelihood ratio test (LRT) <br> 前提是模型的固定結構不發生改變，兩個嵌套式模型之間的比較是可以使用死然比檢驗的。缺點是統計學效能可能不太理想 (low power)</li>
<li>模型的比較指標 information criteria <br> 就算是同一個數據，如果不同的協方差結構矩陣模型的固定效應部分也不同，似然比檢驗也不使用，這時候應該求助於赤池信息量 (Akaike’s Information Criterion, AIC)，或者貝葉斯信息量 (Bayesian Criterion, BIC) 的比較。這兩個信息量都是使用的模型的似然減去相應模型的參數數量作爲評判標準。差別是 BIC 對參數的調整更加大些。但是，沒人可以保證這些信息會永遠相互認證，他們可能出現互相矛盾，也沒人可以保證使用這些信息的比較可以證明你的模型是“最佳”模型。</li>
</ul></li>
</ul>
</div>
<div id="不平衡數據" class="section level2">
<h2><span class="header-section-number">63.6</span> 不平衡數據</h2>
<ul>
<li>有缺失值的數據，我們無法使用已知的協方差結構矩陣;</li>
<li>隨機效應模型，隨機系數模型可以用於不平衡數據，所以即使有缺失值，我們可以從混合效應模型的結果來推測數據暗示我們數據中存在着怎樣的協方差結構;</li>
</ul>
</div>
<div id="practical-06-hier" class="section level2">
<h2><span class="header-section-number">63.7</span> Practical 06-Hier</h2>
</div>
</div>
<div id="縱向研究數據-longitudinal-data-3" class="section level1">
<h1><span class="header-section-number">第 64 章</span> 縱向研究數據 longitudinal data 3</h1>
<div id="第一層級的異質性-level-1-heterogeneity" class="section level2">
<h2><span class="header-section-number">64.1</span> 第一層級的異質性 level 1 heterogeneity</h2>
<p>目前爲止，我們使用討論過的模型，其實還默認另一個前提條件: 第一層級和第二層級的隨機誤差的方差是固定不變的 (level 1 and level 2 error variance are constant)。但是實際上我們可以把這個條件放寬，讓模型允許第一層級隨機誤差的方差根據某個解釋變量而不同，使得模型更加接近數據，這種模型被命名爲 <strong>復雜第一層級方差模型 (complex level 1 variation)</strong>。下面繼續使用 Asian growth data 來做說明。該數據測量了幾百名亞洲兒童在0-3歲之間幾個時間點的體重。現在我們來允許其第一層級 (每一個兒童在不同時間點測量的體重) 誤差方差隨着性別的不同而變化: <span class="math inline">\(\sigma_e = f(\text{gender})\)</span>。這裏的方程爲了防止標準差變成負的而使用對數函數:</p>
<p><span class="math display">\[
\text{log} (\sigma_e) = \delta_1I_{\text{gender = boy}} + \delta_2I_{\text{gender=girl}}
\]</span></p>
<p>這個加入了第一層級方差隨機性的模型在 R 裏可以這樣擬合:</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb985-1" title="1">M_growth_l1 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>id, <span class="dt">weights =</span> <span class="kw">varIdent</span>(<span class="dt">form=</span><span class="op">~</span><span class="dv">1</span><span class="op">|</span>gender), <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb985-2" title="2"><span class="kw">summary</span>(M_growth_l1)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   533.06033 562.47105 -257.53016
## 
## Random effects:
##  Formula: ~age | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 0.64492252 (Intr)
## age         0.49336369 0.129 
## Residual    0.64221188       
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | gender 
##  Parameter estimates:
##       Boys      Girls 
## 1.00000000 0.77212879 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.8294125 0.175581146 128  21.809930  0.0000
## age          7.6297282 0.234375558 128  32.553429  0.0000
## age2        -1.6350689 0.086535221 128 -18.894837  0.0000
## genderGirls -0.6043805 0.204516567  66  -2.955166  0.0043
##  Correlation: 
##             (Intr) age    age2  
## age         -0.523              
## age2         0.471 -0.930       
## genderGirls -0.630  0.011  0.008
## 
## Standardized Within-Group Residuals:
##          Min           Q1          Med           Q3          Max 
## -1.972411175 -0.451503129 -0.063192138  0.468697082  2.959946133 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb987"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb987-1" title="1"><span class="co"># 和之間默認男女兒童的誤差方差相等時的模型做比較</span></a>
<a class="sourceLine" id="cb987-2" title="2"><span class="co"># 沒有顯著差異 (p = 0.09)</span></a>
<a class="sourceLine" id="cb987-3" title="3"><span class="kw">anova</span>(M_growth_l1, M_growth_mix)</a></code></pre></div>
<pre><code>##              Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M_growth_l1      1  9 533.06033 562.47105 -257.53017                         
## M_growth_mix     2  8 533.95003 560.09290 -258.97501 1 vs 2 2.8897013  0.0891</code></pre>
</div>
<div id="第二層級異質性-level-2-heterogeneity" class="section level2">
<h2><span class="header-section-number">64.2</span> 第二層級異質性 level 2 heterogeneity</h2>
<p>我們還可以在模型中允許第二層級的結構不一樣，這等同於認爲這是一個三個層級的模型，其中第二層級分裂成男孩和女孩。</p>
<div class="sourceCode" id="cb989"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb989-1" title="1">M_growth_l2 &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, </a>
<a class="sourceLine" id="cb989-2" title="2">                   <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age<span class="op">*</span>gender <span class="op">|</span><span class="st"> </span>id,</a>
<a class="sourceLine" id="cb989-3" title="3">                   <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>, <span class="dt">na.action =</span> na.omit)</a>
<a class="sourceLine" id="cb989-4" title="4"><span class="kw">summary</span>(M_growth_l2)</a></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##  Data: growth 
##         AIC       BIC     logLik
##   539.92465 588.94252 -254.96233
## 
## Random effects:
##  Formula: ~age * gender | id
##  Structure: General positive-definite, Log-Cholesky parametrization
##                 StdDev     Corr                
## (Intercept)     0.55670427 (Intr) age    gndrGr
## age             0.69451364  0.037              
## genderGirls     0.85251527 -0.550 -0.002       
## age:genderGirls 0.72515659 -0.095 -0.948  0.130
## Residual        0.56947533                     
## 
## Fixed effects: weight ~ age + age2 + gender 
##                  Value   Std.Error  DF    t-value p-value
## (Intercept)  3.8204364 0.160115147 128  23.860556  0.0000
## age          7.6149745 0.235176590 128  32.379815  0.0000
## age2        -1.6464243 0.087451604 128 -18.826691  0.0000
## genderGirls -0.6088237 0.203186658  66  -2.996376  0.0038
##  Correlation: 
##             (Intr) age    age2  
## age         -0.543              
## age2         0.520 -0.945       
## genderGirls -0.531 -0.048  0.011
## 
## Standardized Within-Group Residuals:
##           Min            Q1           Med            Q3           Max 
## -2.0240475942 -0.4399956901 -0.0095445889  0.4564973181  2.7439585111 
## 
## Number of Observations: 198
## Number of Groups: 68</code></pre>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb991-1" title="1">growth &lt;-<span class="st"> </span>growth <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb991-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boy =</span> <span class="kw">as.numeric</span>(gender <span class="op">==</span><span class="st"> &quot;Boys&quot;</span>), </a>
<a class="sourceLine" id="cb991-3" title="3">         <span class="dt">girl =</span> <span class="kw">as.numeric</span>(gender <span class="op">==</span><span class="st"> &quot;Girls&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb991-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age_boy =</span> age<span class="op">*</span>boy, </a>
<a class="sourceLine" id="cb991-5" title="5">         <span class="dt">age_girl =</span> age<span class="op">*</span>girl)         </a>
<a class="sourceLine" id="cb991-6" title="6"></a>
<a class="sourceLine" id="cb991-7" title="7"><span class="co">#M &lt;- lmer(weight ~ age + age2 + girl + (age_boy |id) + (age_girl| id), data = growth, REML = TRUE)</span></a>
<a class="sourceLine" id="cb991-8" title="8"></a>
<a class="sourceLine" id="cb991-9" title="9"><span class="co">#growth &lt;- growth %&gt;%</span></a>
<a class="sourceLine" id="cb991-10" title="10"><span class="co">#  mutate(boy = ifelse(gender == &quot;Boys&quot;, 1, 0), </span></a>
<a class="sourceLine" id="cb991-11" title="11"><span class="co">#         girl = ifelse(gender == &quot;Girls&quot;, 1, 0), </span></a>
<a class="sourceLine" id="cb991-12" title="12"><span class="co">#         age_boy = age*boy, </span></a>
<a class="sourceLine" id="cb991-13" title="13"><span class="co">#         age_girl = age*girl)</span></a>
<a class="sourceLine" id="cb991-14" title="14"><span class="co">#M_growth_l22 &lt;- lme(fixed = weight ~ age + age2 + girl, </span></a>
<a class="sourceLine" id="cb991-15" title="15"><span class="co">#                    random = list( ~ girl + age_girl | id, </span></a>
<a class="sourceLine" id="cb991-16" title="16"><span class="co">#                                   ~ boy + age_boy | id),</span></a>
<a class="sourceLine" id="cb991-17" title="17"><span class="co">#                   data = growth, method = &quot;REML&quot;, na.action = na.omit)</span></a>
<a class="sourceLine" id="cb991-18" title="18"><span class="co">#summary(M_growth_l22)</span></a>
<a class="sourceLine" id="cb991-19" title="19">M_growth &lt;-<span class="st"> </span><span class="kw">lme</span>(<span class="dt">fixed =</span> weight <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>age2 <span class="op">+</span><span class="st"> </span>gender, <span class="dt">random =</span> <span class="op">~</span><span class="st"> </span>age<span class="op">|</span>id, <span class="dt">data =</span> growth, <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>,<span class="dt">na.action =</span> na.omit) </a>
<a class="sourceLine" id="cb991-20" title="20"><span class="kw">anova</span>(M_growth_l2, M_growth)</a></code></pre></div>
<pre><code>##             Model df       AIC       BIC     logLik   Test   L.Ratio p-value
## M_growth_l2     1 15 539.92465 588.94252 -254.96233                         
## M_growth        2  8 533.95003 560.09290 -258.97501 1 vs 2 8.0253784  0.3304</code></pre>
</div>
<div id="分析策略-1" class="section level2">
<h2><span class="header-section-number">64.3</span> 分析策略</h2>
<p>進行統計建模之前，請思考你想從數據中探尋什麼問題的答案?</p>
<ol style="list-style-type: decimal">
<li>是想了解某一個共變量在層內 (同一個體不同時間，或者統一學校不同學生之間) 的條件效應 (conditional effect)?</li>
<li>是想探索層內和層間數據的變化程度?</li>
<li>是想了解一個共變量的邊際效應 (marginal effect) 嗎?</li>
</ol>
<p>如果是 1 或 2 兩個問題的話，請使用混合效應模型。如果是 1，但是那個共變量卻不是定義於層水平的，那就只好放棄回到簡單的固定效應模型。如果是 3，需要考慮使用 GEE。</p>
<div id="模型選擇和建模步驟" class="section level3">
<h3><span class="header-section-number">64.3.1</span> 模型選擇和建模步驟</h3>
<p>詳細請參考 <span class="citation">(Verbeke <a href="#ref-Verbeke1997" role="doc-biblioref">1997</a>)</span>。</p>
<p>當擬合一個混合效應模型時，意味着均值的結構和協方差的結構可以被確定 (an appropriate mean structure as well as covariance structure is specified)。協方差結構，解釋了均值結構無法解釋的數據隨機變化，所以二者之間彼此高度互相依賴。另外，適當的協方差模型對於用數據進行人羣參數的有效統計推斷過程是必不可少的。</p>
<ul>
<li>第一步:</li>
</ul>
<p>由於固定效應部分不能完美解釋數據的變異，所以協方差結構就是用來輔助解釋這部分數據變異的輔助工具。建模的起點就應該是，先建立一個飽和 (甚至是過飽和 overelaborated) 的模型給均值結構 (固定效應部分)，從而確保之後要增加的隨機效應部分不受固定效應部分的擬合錯誤影響。所以，開始建模時，要先把所有可能考慮到的固定效應全部加入模型中去 (包括連續變量的二次方形式/或其他非線性關系，包括所有變量之間的交互作用)。這樣做其實是使用過度飽和的參數使得均值結構在模型中盡量在後面加入隨機效應之前保持不變。在可選的那些數據結構中，我們也應當考慮到數據中不同層級結構可能存在的異質性。要注意的是，隨機效應部分，不能也不應該在沒有把所有可能的一次方程結構都考慮進去之後 (a random effect for the linear effect of time)，就上馬二次方程/或更高次方程的隨機效應(a random effect for the quadratic effect of time)。
然後我們把飽和模型的殘差 (residuals)，異常值 (outliers)，擬合值 (fitted values)，和可能的 (potential) 隨機效應模型作出的這些殘差，異常值，擬合值之間進行比較。</p>
<ul>
<li>第二步:</li>
</ul>
<p>一旦你在飽和模型的條件下，確認好了隨機效應應該有的形式，接下來就是逐步精簡模型固定效應部分的過程:</p>
<ol style="list-style-type: decimal">
<li>用 Wald 檢驗 (當使用 REML 時)，或者 LRT (使用 ML 時) 來精簡化固定效應部分。</li>
<li>反復檢查殘差，異常值，以及擬合值跟觀測值</li>
<li>使用模型的預測軌跡和觀測值的點做視覺比較</li>
<li>用人話把你的模型解釋給老奶奶聽懂</li>
</ol>
</div>
</div>
</div>
<div id="generalized-estimating-equation" class="section level1">
<h1><span class="header-section-number">第 65 章</span> Generalized Estimating Equation</h1>
</div>
<div id="cluster-analysisunsupervised-learning-聚類分析" class="section level1">
<h1><span class="header-section-number">第 66 章</span> Cluster analysis/unsupervised learning 聚類分析</h1>
<p>目前爲止，在等級回歸模型部分中，我們接觸到的回歸模型和可能存在相互依賴性的數據，都是建立在我們能夠觀察到或者實驗設計上已知的數據層級結構的前提下的。這樣的層級可以是空間上的，或者時間上的。處在相同層級的研究對象之間存在相關性，換句話說就是：層級內部的對象之間，比起層級之間的對象具有更多的相似性。</p>
<p>但是，在許多情況下，我們其實是無法事先知道數據的內部層級（聚類）結構的。而且我們可能需要儘可能多的獲取數據，並且從測量的數據中學習。學習數據變量與變量之間的相關性(correlation)，變量與變量之間的協方差(covariance)，個體與個體之間的相似性，從而根據獲取的數據來判斷數據內部是否存在不同的層級結構。這樣的一種對數據結構進行探索的過程，在機器學習(maching learning)中也是常常使用的，它又被叫做<strong>非監督學習 (unsupervised learning)</strong>。</p>
<p>之所以把這類尋找數據分類分層結構的過程叫做非監督學習，其實，是爲了和現在越來越豐富，多到令人髮指的那些被歸類於<strong>監督學習(supervised learning)</strong>的方法作爲相互對照。在監督學習中，數據內部的分層，聚類結構是事先知道的，也就是事先能夠測量或者被定義好的。事先被定義好了的數據層級結構中，我們可以使用多元變量分析，來對某些個體的特徵加以分類，也就是給數據中的未知成員分配<strong>已知的分組</strong>的過程。</p>
<p>在醫學中常見的非監督學習過程實例之一是，對於一個（全部相同疾病的）隊列研究中的受試者進行了大量的生物標幟物(biomarker)的測量與收集，可以是血液樣本的 biomarker 的測量，也可以是每名受試者的全部DNA信息。研究者希望通過這些患者的信息對他們進行同一疾病不同等級（類別，或者進程）的分類。那麼研究者需要利用這些收集來的患者信息，建立一套儘可能完善的分類的系統。</p>
<p>另外一個例子是，我們收集了前列腺癌患者的前列腺組織，利用基因轉錄組學 (transcriptomics) 的方法測量了每名患者成千上萬的組織內基因表達。研究者希望通過這些數據來分析，提取，並且分辨這些前列腺癌患者中可能存在的分類，或者亞型。研究者也希望知道這些分析獲得的亞型，是否會和某些已知的癌症的亞型相似或者相重合。</p>
<p>在商業領域中，聚類分析也是不罕見的。例如你爲某商業公司工作，那麼食品供應商可能會上門來要求你把購買食物的顧客進行類別區分，從而提供給食物供應商們一些線索，讓他們能夠更加精準的定位廣告投放人羣。</p>
<p>在統計學，和機器學習領域中，有許多不同的手法，可以用來輔助建立這種分類的規則，它們通常又被叫做判別分析法(discriminant analysis methods)。我們這一章和下一章着重討論</p>
<ol style="list-style-type: decimal">
<li>聚類分析法 (cluster analysis)</li>
<li>主成分分析法 (principal component analysis)</li>
</ol>
<div id="聚類分析過程" class="section level2">
<h2><span class="header-section-number">66.1</span> 聚類分析過程</h2>
<p>聚類分析法是一種分析不同統計測量值之間相似/差異程度的描述性分析過程。</p>
<p>爲什麼我們總是想對具有相似性質的事物進行歸類？其實，對事物進行區分和歸類，或者打上一些標籤，是人類文明在學習並且理解周圍的世界，從而促進科學發展的核心問題之一。在原始社會，對相似事物進行歸類有時候甚至事關生死。例如人類最初需要判定某些食物的共同特徵，區分哪些是含有毒性的，哪類動物可能是兇猛殘忍的。我們從嬰兒時期開始學習語言，學習事物/事件/人物的名稱，這其實也是一個學習對周圍的世界進行區分的學習過程。古代希臘文明的先賢哲學家亞里士多德曾經主張，人類的本能之一，就是不停地想對這個我們生活的世界發生的事情看到的事物進行類別的區分，尋找相似的特徵，區別不一樣的性質。在生物學中，甚至有由亞里士多德的學生<a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%A5%A7%E5%BC%97%E6%8B%89%E6%96%AF%E6%89%98%E6%96%AF">泰奧夫拉斯托斯(Theophrastos)</a>創立的專門對生物進行分類的學科，生物分類學 (taxonomy)，後被瑞典人生物學家<a href="https://en.wikipedia.org/wiki/Carl_Linnaeus">卡爾林納斯 (Carl Linnaeus)</a>進一步發揚光大。18世紀末，<a href="https://en.wikipedia.org/wiki/Michel_Adanson">Michel Adanson</a>又爲人類引入了多元分析(polythetic)的分類系統概念，取代了之前使用單一因素(monothetic)對事物進行簡單分類的思想。很顯然，生物分類學在人類文明史中扮演了重要的角色。你應該很容易能想到達爾文提出的進化論，就是建立在前人對動植物進行了事無鉅細的分類和整理的基礎之上建立起來的重大理論突破。俄國科學家<a href="https://zh.wikipedia.org/wiki/%E5%BE%B7%E7%B1%B3%E7%89%B9%E9%87%8C%C2%B7%E4%BC%8A%E4%B8%87%E8%AF%BA%E7%BB%B4%E5%A5%87%C2%B7%E9%97%A8%E6%8D%B7%E5%88%97%E5%A4%AB">門捷列夫</a>發現化學元素週期性，並且製作出了世界上第一章元素週期表，也爲人類理解原子世界奠定了基石。</p>
<p>在對事物進行分類這個任務上，聚類分析(cluster analysis)，和判別分析是相同的。有時候在已知對象的分類情況時我們仍然傾向於使用聚類分析的方法，用它來描述數據的一些特徵。同時也能有助於判定之後可能進行的判別分析是否準確。</p>
<p>簡單歸納，對分類描述過程進行量化的主要步驟有以下幾個：</p>
<ol style="list-style-type: decimal">
<li><p>對於採集來的樣本數據 (statistical sample)，我們儘可能多的對它們的特徵變量進行測量。</p></li>
<li><p>根據第一步獲得的變量信息，定義一個能夠幫助我們判定對象與對象之間相似點或者不同程度的測量指標。</p></li>
<li><p>對這個測量指標制定一個區分的規則，或者叫做歸類的標準。</p></li>
<li><p>對樣本進行分類。</p></li>
<li><p>採集更多的樣本，對分類規則進行調整和完善。</p></li>
</ol>
<div id="連續型變量-continuous-variables-in-cluster-analysis" class="section level3">
<h3><span class="header-section-number">66.1.1</span> 連續型變量 continuous variables in cluster analysis</h3>
<p>我們想象手裏的數據是一個矩陣 <span class="math inline">\(X\)</span>，它的維度是 <span class="math inline">\(n \times p\)</span>，用 <span class="math inline">\(x_{ik}\)</span>，來表示第 <span class="math inline">\(i\)</span> 名觀察對象 <span class="math inline">\((i = 1, \dots, n)\)</span> 的第 <span class="math inline">\(k\)</span> 個變量 <span class="math inline">\((k = 1, \dots, p)\)</span> 的值。如果這些被測量的變量全部都是連續型變量的話，每個變量可以被使用幾何學的形式表達的 <span class="math inline">\(p\)</span> 個維度的其中一個平面上。當然，當維度超過3時，人類的無知大腦常常就無法進行有效的想象和推理，我們這裏使用簡單的三個變量，也就是三維空間來表示三個測量獲得的連續型變量：</p>
<p>例如我們測量了三名學生的身高，體重，以及前臂長。數據分別是：Angelo (190, 75, 30)；Dimitris (170, 75, 25)；Soren (170, 65, 30)。</p>
<div class="figure" style="text-align: center"><span id="fig:cluster00"></span>
<div id="htmlwidget-2f81be8bd94dc946f0a7" style="width:80%;height:403.2px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2f81be8bd94dc946f0a7">{"x":{"visdat":{"31d469235a0":["function () ","plotlyVisDat"]},"cur_data":"31d469235a0","attrs":{"31d469235a0":{"x":{},"y":{},"z":{},"color":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"xaxis":{"range":[0,200]},"scene":{"xaxis":{"title":"Height (cm)"},"yaxis":{"title":"Weight (cm)"},"zaxis":{"title":"Forearm (cm)"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[190],"y":[75],"z":[30],"type":"scatter3d","mode":"markers","name":"Angelo","marker":{"color":"rgba(102,194,165,1)","line":{"color":"rgba(102,194,165,1)"}},"textfont":{"color":"rgba(102,194,165,1)"},"error_y":{"color":"rgba(102,194,165,1)"},"error_x":{"color":"rgba(102,194,165,1)"},"line":{"color":"rgba(102,194,165,1)"},"frame":null},{"x":[175],"y":[75],"z":[25],"type":"scatter3d","mode":"markers","name":"Dimitris","marker":{"color":"rgba(252,141,98,1)","line":{"color":"rgba(252,141,98,1)"}},"textfont":{"color":"rgba(252,141,98,1)"},"error_y":{"color":"rgba(252,141,98,1)"},"error_x":{"color":"rgba(252,141,98,1)"},"line":{"color":"rgba(252,141,98,1)"},"frame":null},{"x":[170],"y":[65],"z":[30],"type":"scatter3d","mode":"markers","name":"Soren","marker":{"color":"rgba(141,160,203,1)","line":{"color":"rgba(141,160,203,1)"}},"textfont":{"color":"rgba(141,160,203,1)"},"error_y":{"color":"rgba(141,160,203,1)"},"error_x":{"color":"rgba(141,160,203,1)"},"line":{"color":"rgba(141,160,203,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
圖 66.1: A physical 3D space showing measurements of three variables.
</p>
</div>
<p>在這個三維立體空間，我們需要定義一個變量用於丈量點與點之間的距離。其中最自然的就是歐幾里德(Euclidean)幾何距離:</p>
<p><span class="math display">\[
d_{ij} = \{\sum_{k = 1}^p(x_{ik} - x_{jk})^2\}^{\frac{1}{2}} 
\]</span></p>
<ul>
<li>歐幾里德幾何距離又被稱爲 <strong>L2 度量衡 (L2 metric)</strong>。按照這個距離的定義，那麼 Angelo 和 Dimitris 之間的歐幾里德幾何距離就是：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \{(190 - 175)^2 + (75 - 75)^2 + (30 - 25)^2 \}^{\frac{1}{2}} \\
= &amp; \sqrt{15^2 + 0^2 + 5^2} \\ 
= &amp; \sqrt{240} = 15.5
\end{aligned}
\]</span></p>
<ul>
<li>曼哈頓距離 (Manhattan distance)：別名城市區塊度量衡 (cityblock metric)，或者<strong>L1 度量衡</strong></li>
</ul>
<p><span class="math display">\[
d_{ij} = \sum_{k = 1}^p |x_{ik} - x_{jk}|
\]</span></p>
<p>按照曼哈頓距離來定義的話，Angelo 和 Dimitris 之間的距離就是：</p>
<p><span class="math display">\[
|190 - 175| + |75 - 75| + |30 - 25| = 15 + 0 + 5 = 20
\]</span></p>
<p>後來人們發現上面提到的這兩種幾何學距離其實是閔科夫斯基度量衡 (Minkowski metric) 在 L=1 和 L=2 時的特殊情況。</p>
<p>閔科夫斯基度量衡的一般形式表達爲:</p>
<p><span class="math display">\[
d_{ij} = \{ \sum_{k = 1}^p |x_{ik} - x_{jk}|^\ell \}^\frac{1}{\ell}
\]</span></p>
<p>閔科夫斯基度量衡試圖給差距較大的測量值之間增加權重用於區分彼此。不論是使用那種距離定義，這些測量距離的度量衡都具有如下的數學性質 (mathematical properties)：</p>
<ol style="list-style-type: decimal">
<li>兩點之間的距離大於等於零, positivity <br> <span class="math inline">\(d_{ij} \geqslant 0\)</span>，如果 <span class="math inline">\(d_{ij} = 0\)</span>，那麼對於任何一個 <span class="math inline">\(k = 1, \dots, p\)</span>，它們都是相等的 <span class="math inline">\(x_{ik} = x_{jk}\)</span>。</li>
<li>對稱性, symmetry <br> <span class="math inline">\(d_{ij} = d_{ji}\)</span></li>
<li>三角形不等性, triangle inequality <br> <span class="math inline">\(d_{ij} \leqslant d_{ih} + d_{hj}\)</span></li>
</ol>
</div>
<div id="二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables" class="section level3">
<h3><span class="header-section-number">66.1.2</span> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</h3>
<p>假如變量本身並不是連續型的，那麼閔科夫斯基度量衡並不適用，因爲二分量只能取0或者1。如下表所表示的，我們把 <strong>i,j</strong> 兩名對象的所有二分類變量進行下面的歸納總結：</p>
<table>
<thead>
<tr class="header">
<th align="center">i/j</th>
<th align="center">1</th>
<th align="center">0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">a</td>
<td align="center">b</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">c</td>
<td align="center">d</td>
</tr>
</tbody>
</table>
<p>其中，</p>
<ul>
<li>a 表示 i, j 兩名研究對象的二分類變量中，同時取 1 的變量的個數，</li>
<li>b 表示 i, j 兩名研究對象的二分類變量中，i 取 1 但是 j 取 0 的變量的個數，</li>
<li>c 表示 i, j 兩名研究對象的二分類變量中，j 取 1 但是 i 取 0 的變量的個數，</li>
<li>d 表示 i, j 兩名研究對象的二分類變量中，同時取 0 的變量的個數。</li>
</ul>
<p>根據這個總結表格，常用的表示兩個對象之間距離的數學度量是：</p>
<ol style="list-style-type: decimal">
<li><p>簡單匹配係數 (simple matching coefficient, SMC)，單純地計算所有的變量之中互相不一致的變量所佔的百分比： <span class="math display">\[d_{ij} = \frac{b + c}{a+b+c+d}\]</span></p></li>
<li><p>亞卡爾距離係數 (Jaccard coefficient)，則是把簡單匹配係數的分母中，d 的部分拿掉：<span class="math display">\[d_{ij} = \frac{b + c}{a + b + c}\]</span></p></li>
</ol>
<p><a href="https://en.wikipedia.org/wiki/Jaccard_index">其中亞卡爾距離係數更適合用於測量一些表達某些特質存在/不存在時兩名對象之間的距離測量 (see the “Difference with the simple matching coefficient (SMC)” session in the Wikipedia)</a>。</p>
<p>另外值得注意的是，在測量二分類變量距離的時候，三角形不等性的特質不一定會得到滿足。 (Please note that in general for dichotomous variables, the triangle inequality does not hold.)</p>
<p>用來計算測量對象之間距離的方法，和度量衡其實層出不窮，這裏只是簡單介紹了幾種。其餘的還有比如說由 <span class="citation">(Gower <a href="#ref-Gower1971" role="doc-biblioref">1971</a>)</span> 提出的 <a href="https://cran.r-project.org/web/packages/gower/vignettes/intro.html">Gower Index</a>，該指標可以同時把測量有連續型變量和分類型變量，二分類變量等都包含進來。值得提醒的是，如果是討論非連續型測量值的對象距離，我們常常用它們之間的相似性(similarities) <span class="math inline">\(s_{ij}\)</span>，而不太關注異質性 (dissimilarities) <span class="math inline">\(d_{ij}\)</span>，但其是它們之間的簡單轉換關係就是 <span class="math inline">\(d_{ij} = 1 - s_{ij}\)</span>。</p>
</div>
<div id="定義分類方法" class="section level3">
<h3><span class="header-section-number">66.1.3</span> 定義分類方法</h3>
<p>確定了用於衡量異質性 (dissimilarity) 距離的指標之後，我們就需要來定義分類的方法。首先把這個事先定下來的距離指標應用到我們的多元變量數據矩陣 (multivariate data matrix <span class="math inline">\(\mathbf{X}\)</span>) (dimension: <span class="math inline">\(n\times p\)</span>, where n indicates number of people, p indicates number of observed variables). 獲得一個形狀爲 <span class="math inline">\(n\times n\)</span> 的距離矩陣 <span class="math inline">\(\mathbf{D}\)</span> (對應上面三條數學性質中的第二條，對稱性 <span class="math inline">\(d_{ij} = d_{ji}\)</span>)。獲得觀察對象的距離矩陣 <span class="math inline">\(\mathbf{D}\)</span> 之後需要決定的就是如何給對象進行分組的策略。該分組策略需要能使觀察對象被分組後，組內的對象相對組外對象更加相似，或者組外對象相對組內對象更加不同 (a sensible strategy would be to look for sets of units such that all units in that set are relatively similar to each other but relatively different from all units outside that set)。所以，用於分組策略的算法要有一定的可行性，它還要能夠量化對象之間的相對相似性 (relative similarity) 從而能夠完成以下任務：</p>
<ol style="list-style-type: decimal">
<li><p>決定哪些人/對象被聚類到同一組中 (which pairs of units to join together into a cluster)</p></li>
<li><p>每次聚類過程完成以後，重複相同的策略和算法，也就是重新計算新組成的聚類和剩餘的對象之間的距離。</p></li>
<li><p>循環往復前兩個步驟直至全部的對象/個體都被分到各自的聚類 (cluster)。</p></li>
</ol>
<p>事實上重複上述步驟，最終會把每個個體都分配到一個單獨的聚類中，也就是每個個體本身，那其實就跟沒有做聚類分析沒有區別，也沒有意義了。於是我們需要把聚類分析的過程通過圖形的方式展示出來。這樣的圖形被叫做<strong>樹狀圖 (dendrogram)</strong>，可以在視覺上輔助我們做出要給對象分成多少個聚類的決定。在希臘語中(Greek)，dendron 是樹的意思，樹狀圖的形狀常見的如下圖 (<a href="#fig:cluster01">66.2</a>) 所示，座標軸之一是所有的觀測對象的編號，另一個座標軸則是度量每個聚類或者觀測對象個體之間的距離。</p>
<div class="figure" style="text-align: center"><span id="fig:cluster01"></span>
<img src="bookdown_files/figure-html/cluster01-1.png" alt="Example of dendrogram vertically oriented, with 50 statistical units (average linkage method and Euclidean distance measure)." width="80%" />
<p class="caption">
圖 66.2: Example of dendrogram vertically oriented, with 50 statistical units (average linkage method and Euclidean distance measure).
</p>
</div>
<p>那麼回到之前如何決定聚類數量的問題上來，我們有兩種手段來輔助：</p>
<ol style="list-style-type: decimal">
<li>層級法 (hierarchical methods)：聚合法，agglomerative； 或者分裂法， divisive。</li>
<li>分區算法 (partitioning methods)。</li>
</ol>
<p>層級法中的<strong>聚合法 (agglomerative)</strong>是指，從聚類分析的開始階段，每個獨立的對象自成一個聚類 (cluster)，所以起步於 n 個統計單位 (n statistical units)，之後的每一步聚類過程則是將度量距離相近的對象合併成爲一個聚類，直至最終所有個體歸爲唯一一個聚類。所以可以想象爲從各個枝葉彙總到一個樹幹走向各個枝葉的過程。</p>
<p>層級法中的<strong>分裂法 (divisive)</strong>則是和聚合法的聚類方向反過來，它起始於將所有觀察對象視爲唯一一個聚類，之後每一步聚類過程是將和大部分對象不太相似的個體從聚類中分裂出去，直至最終每個獨立的對象自成一個聚類。所以可以想象成從一個樹幹走向枝葉的過程。</p>
<p>分裂法其實十分消耗計算機的運算能力，因爲當樣本量較大時，一個 <span class="math inline">\(k\)</span> 種聚類的步驟就需要比較 <span class="math inline">\(2^{k-1} -1\)</span> 種不同的分區之間的距離。</p>
</div>
</div>
</div>
<div id="missing-data-1" class="section level1">
<h1><span class="header-section-number">第 67 章</span> Missing data 1</h1>
</div>
<div id="principal-component-analysis-主成分分析" class="section level1">
<h1><span class="header-section-number">第 68 章</span> Principal Component Analysis 主成分分析</h1>
<blockquote>
<dl>
<dt>A big computer, a complex algorithm and a long time does not equal science.</dt>
<dd>Robert Gentleman
</dd>
</dl>
</blockquote>

<div class="rmdnote">
PCA lecture was taught by Professor <a href="https://scholar.google.co.uk/citations?hl=en&amp;user=p-cHaf0AAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Luigi Palla</a>.
</div>

<div id="數據有相關性時產生的問題" class="section level2">
<h2><span class="header-section-number">68.1</span> 數據有相關性時產生的問題</h2>
<p>假設我們有 <span class="math inline">\(n\)</span> 個研究對象作爲樣本，我們從這些對象身上採集儘可能多的數據，假設我們一共收集了 <span class="math inline">\(p\)</span> 個不同的變量。那麼這個數據的維度 (dimension) 是 <span class="math inline">\(n \times p\)</span>。</p>
<p>如果說，我們在這個樣本中獲取到的 <span class="math inline">\(p\)</span> 個變量中，有一些是相互有依存性的，或者說相關的 (correlated)。我們有沒有辦法描述並展示這些具有相關性的變量在這個數據中扮演的角色，並且保留整個數據本身的變化特徵 (variability)？</p>
<p>Edgeworth (1891) 最早試圖用下面的方程來歸納一組從男性樣本身上測量獲得的存在相關性的變量：身高(H)，前臂長(F)，腿長(L)：</p>
<p><span class="math display">\[
\begin{aligned}
Y_1 &amp; = 0.16H + 0.51F + 0.39L \\ 
Y_2 &amp; = -0.17H + 0.69F + 0.09L \\
Y_3 &amp; = -0.15H + 0.25F + 0.52L
\end{aligned}
\]</span></p>
<p>這恐怕是最早嘗試將一組有相關性的身體測量數據整理成“不相關”的三個新變量，作爲男性身體測量指標，用於描述樣本個體的身體結構的過程。</p>
<p>下圖 <a href="#fig:PCA00">68.1</a> 中展示的兩個變量，<span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(x_2\)</span> 分別是身高和體重。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA00"></span>
<img src="img/PCA00.png" alt="Standardised data of height and weight" width="70%" />
<p class="caption">
圖 68.1: Standardised data of height and weight
</p>
</div>
<p>變量經過標準化處理之後，均值 <span class="math inline">\(\mu = 0\)</span>，方差 <span class="math inline">\(\sigma^2 =1\)</span>。如果此時已知身高和體重之間的協方差 (covariance, 概念參考 Section <a href="#covariance">8.1</a>) 是 <span class="math inline">\(0.3\)</span>。</p>
<p>那麼，可以推導證明的是，他們的相關係數 (correlation, 概念參考 Section <a href="#correlation">8.2</a>) 是：</p>
<p><span class="math display">\[
\begin{aligned}
Corr(X_1,X_2) &amp; = \frac{Cov(X_1,X_2)}{SD(X_1)SD(X_2)} \\
          &amp; =\frac{Cov(X_1,X_2)}{\sqrt{Var(X_1)Var(X_2)}}\\ 
          &amp; = Cov(X_1,X_2) \\
          &amp; = 0.3
\end{aligned}          
\]</span></p>
<p>以 <span class="math inline">\(x_2\)</span> (體重) 爲結果變量，<span class="math inline">\(X_1\)</span> (身高) 爲單一解釋變量的線性回歸模型的回歸係數 (regression coefficient <span class="math inline">\(\hat\beta\)</span>, 概念參考 Section <a href="#beta">27.2</a>) 是：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp; = \frac{S_{x_1x_2}}{SS_{x_1x_2}} \\ 
          &amp; = \frac{CV_{x_1x_2}}{SD_{x_1}^2} \\ 
          &amp; = 0.3
\end{aligned}
\]</span></p>
<p>如果我們有另外一個座標系如下圖 <a href="#fig:PCA01">68.2</a>，從原先的座標系進行了一定角度的旋轉獲得 <span class="math inline">\(y_1, y_2\)</span>。你會認爲哪個座標系更適合這個標準化之後身高體重的數據呢？</p>
<div class="figure" style="text-align: center"><span id="fig:PCA01"></span>
<img src="img/PCA01.png" alt="Standardised data of height and weight, with a new reference system (y_1, y_2)" width="70%" />
<p class="caption">
圖 68.2: Standardised data of height and weight, with a new reference system (y_1, y_2)
</p>
</div>
<p>其實原先 <span class="math inline">\(x_1, x_2\)</span> 座標系之間存在一定的相關性，我們希望經過旋轉之後的新座標系 <span class="math inline">\(y_1, y_2\)</span> 之間是垂直的 (orthogonal)，這一數學上的概念被翻譯成爲統計學的語言就是，希望旋轉之後的新座標(變量)之間沒有相關性 (uncorrelated)。爲了消滅變量之間的相關性，我們要尋找到一個旋轉的角度 <span class="math inline">\(\theta\)</span>，使得所有數據的點 <span class="math inline">\(P_j\)</span> 到新的座標軸 <span class="math inline">\(y_1\)</span> 之間的<strong>垂直距離(perpendicualr)</strong> <span class="math inline">\(P_jP_j^\prime\)</span> <strong>之和最小</strong> (minimise the distances between points and the reference axes)。如圖 <a href="#fig:PCA02">68.3</a> 顯示的那樣，從原點到每個數據點 <span class="math inline">\(P_j\)</span> 之間的距離 <span class="math inline">\(OP_j\)</span> 其實是固定不變的。我們希望找到新的座標使得 <span class="math inline">\(P_jP_j^\prime\)</span> 的距離最短。其中 <span class="math inline">\(OP_j^\prime\)</span> 就是數據點在新座標軸上投影的長度。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA02"></span>
<img src="img/PCA02.png" alt="Minimise the distance between the points and the reference axes." width="70%" />
<p class="caption">
圖 68.3: Minimise the distance between the points and the reference axes.
</p>
</div>
<p>根據<a href="https://en.wikipedia.org/wiki/Pythagorean_theorem">勾股定理 (Pythagorean theorem)</a>。圖 <a href="#fig:PCA02">68.3</a> 中直角三角形的三邊的長度關係可以描述爲：</p>
<p><span class="math display">\[
(OP_j)^2 = (P_jP_j^\prime)^2 + (OP_j^\prime)^2
\]</span></p>
<p>把勾股定理應用到全部的數據點上的話，我們會得到一個關於所有數據點到新的座標軸距離，以及原點之間距離的方程：</p>
<p><span class="math display" id="eq:PCAeq1">\[
\begin{equation}
\sum_j (OP_j)^2 = \sum_j(P_jP_j^\prime)^2 + \sum_j(OP_j^\prime)^2
\end{equation}
\tag{68.1}
\]</span></p>
</div>
<div id="最大化方差等價於最大化數據點到新座標軸投影projection的長度" class="section level2">
<h2><span class="header-section-number">68.2</span> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</h2>
<p>把等式 <a href="#eq:PCAeq1">(68.1)</a> 兩邊同時除以數據樣本量，我們獲得等式 <a href="#eq:PCAeq2">(68.2)</a>：</p>
<p><span class="math display" id="eq:PCAeq2">\[
\begin{equation}
\sum_j (OP_j)^2/n = \sum_j(P_jP_j^\prime)^2/n + \sum_j(OP_j^\prime)^2/n
\end{equation}
\tag{68.2}
\]</span></p>
<p>其中值得注意的是，等式 <a href="#eq:PCAeq2">(68.2)</a> 左邊的部分 <span class="math inline">\(\sum_j (OP_j)^2/n\)</span> 對於一個樣本來說是固定不變的 (constant)。於是，等式右邊的部分，當我們的目標是最小化 <span class="math inline">\(\sum_j(P_jP_j^\prime)^2/n\)</span> 垂線 (perpendicular) 長度之和時，就等價於把數據點在新座標軸上的投影之和 <span class="math inline">\(\sum_j(OP_j^\prime)^2/n\)</span> 最大化。說白了，數據點在新座標軸上的投影，就是新座標軸上的變量大小。所以，旋轉座標軸之後，我們希望產生的新變量 <span class="math inline">\(y_1,y_2\)</span> 的方差取最大值(maximising the variance of the new data <span class="math inline">\(\sum_j(OP_j^\prime)^2/n\)</span>)。利用三角函數(假設座標軸的旋轉角度是<span class="math inline">\(\theta\)</span>)，你很容易就能得到新座標軸上新變量的值：</p>
<p><span class="math display" id="eq:PCAeq3">\[
\begin{equation}
\begin{aligned}
y_1  &amp; = x_1\cos\theta + x_2\sin\theta \\ 
y_2  &amp; = -x_1\sin\theta  + x_2\cos\theta
\end{aligned}
\end{equation}
\tag{68.3}
\]</span></p>
<p><strong>證明</strong></p>
<p>如圖 <a href="#fig:PCA03">68.4</a> 所示，設座標軸 <span class="math inline">\(X_1,X_2\)</span> 逆時針旋轉角度爲 <span class="math inline">\(\theta\)</span>，設新座標爲 <span class="math inline">\((y_1, y_2)\)</span>，且原點於點 <span class="math inline">\(P_j (x_1, x_2)\)</span> 之間的連線 <span class="math inline">\(OP_j\)</span> 長度爲 <span class="math inline">\(r\)</span>，<span class="math inline">\(OP_j\)</span> 和新座標軸 <span class="math inline">\(y_1\)</span> 之間的角度爲 <span class="math inline">\(\alpha\)</span>。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA03"></span>
<img src="img/PCA03.png" alt="Rotation of the coordinates, and the new variables calculation." width="70%" />
<p class="caption">
圖 68.4: Rotation of the coordinates, and the new variables calculation.
</p>
</div>
<p><span class="math display">\[
\begin{aligned}
(OP_j)^2 &amp; = x_1^2 + x_2^2 = y_1^2 + y_2^2 \\
         &amp; = r^2 \\ 
\because  x_1 &amp; = r\times\cos(\alpha +\theta) \\ 
          x_2 &amp; = r\times\sin(\alpha + \theta) \\
          y_1 &amp; = r\times\cos(\alpha) \\
          y_2 &amp; = r\times\sin(\alpha) \\ 
\therefore x_1 &amp; = r[\cos\alpha\cos\theta - \sin\alpha\sin\theta] \\
               &amp; = y_1\cos\theta - y_2\sin\theta \\ 
           x_2 &amp; = r[\sin\alpha\cos\theta + \cos\alpha\sin\theta] \\
               &amp; = y_2\cos\theta+y_1\sin\theta \\
\Rightarrow x_1\cos\theta &amp; = y_1\cos^2\theta -y_2 \sin\theta\cos\theta \\ 
            x_2\sin\theta &amp; = y_2\cos\theta\sin\theta + y_1\sin^2\theta \\ 
\textbf{Sum the}&amp; \textbf{ above two equations} \\
\Rightarrow y_1 &amp; = \frac{x_1\cos\theta + x_2 \sin\theta}{(\cos^2\theta + \sin^2\theta)} \\ 
            y_1 &amp; = x_1\cos\theta + x_2 \sin\theta \\ 
\textbf{Similarly}&amp; \\
\Rightarrow x_1\sin\theta &amp; = y_1\cos\theta\sin\theta -y_2 \sin^2\theta \\ 
            x_2\cos\theta &amp; = y_2\cos^2\theta + y_1\sin\theta\cos\theta \\ 
\textbf{Take substraction}&amp; \textbf{ between the above two equations} \\
\Rightarrow y_2 &amp; = \frac{-x_1\sin\theta + x_2\cos\theta}{(\cos^2\theta + \sin^2\theta)} \\
            y_2 &amp; = -x_1\sin\theta + x_2\cos\theta
\end{aligned}
\]</span></p>
<p><span class="math inline">\(y_1, y_2\)</span>就是旋轉後新的座標軸的變量。在這個簡單實例中，我們從原始數據 <span class="math inline">\(x_1, x_2\)</span> 經過旋轉，獲得新的數據 <span class="math inline">\(y_1, y_2\)</span>，他們二者之間其實只是經過了線性轉換 (linear transformation)。一般地，我們如果要給原始數據矩陣 (維度 <span class="math inline">\(n\times p\)</span>)進行座標軸的數據轉換，只需要給原始數據矩陣乘以一個正方形的投影矩陣 <span class="math inline">\(\mathbf{P}\)</span> (projection matrix) (維度 <span class="math inline">\(p\times p\)</span>) (<span class="math inline">\(p\)</span> 是變量的個數)即可。</p>
<p>當變量只有兩個 <span class="math inline">\((p =2)\)</span> 時，我們很容易使用一個平面圖來理解這個轉換過程其實就是對座標軸進行幾何旋轉的過程，這時候的投影矩陣是：</p>
<p><span class="math display" id="eq:PCAeq4">\[
\left[
\begin{array}
\cos\cos\theta &amp; \sin\theta \\
-\sin\theta &amp; \cos\theta
\end{array}
\right]
\tag{68.4}
\]</span></p>
<p>經過旋轉之後獲得的新變量 <span class="math inline">\(y_1, y_2\)</span> 被叫做主成分 (principal components)。主成分有什麼特徵呢？如圖 <a href="#fig:PCA04">68.5</a> 所表示的那樣，當兩個原始變量 <span class="math inline">\(x_1, x_2\)</span> 之間相關係數很高，由於已知方差總和不變 <span class="math inline">\(\text{Var}(x_1)+\text{Var}(x_2) = \text{Var}(y_1) + \text{Var}(y_2)\)</span>，座標旋轉之後的第一個主成分 <span class="math inline">\(y_1\)</span>，將會擁有原始數據 <span class="math inline">\(x_1, x_2\)</span> 的方差 (variance) 中的絕大部分。那麼理論上，我們就完成了保留數據本身的整體方差，但是把大部分方差歸納到第一個主成分中去的過程。所以，當對樣本測量了很多很多的變量的時候，我們會發現很多變量之間存在內部相關性，於是我們可以通過主成分分析來留下幾個能解釋整體數據的最主要的成分，並且保留數據的整體信息，也就是整體的方差，這是一個把數據降維 (dimension reduction) 的過程，去除掉那些冗餘的不需要的變量 (redundancy removed)。</p>
<div class="figure" style="text-align: center"><span id="fig:PCA04"></span>
<img src="img/PCA04.png" alt="Variance of the new axis/prin" width="70%" />
<p class="caption">
圖 68.5: Variance of the new axis/prin
</p>
</div>
<p>所以，PCA的過程可以描述如下：</p>
<p>數據如果有 <span class="math inline">\(p\)</span> 個存在內部相關性的連續型變量 <span class="math inline">\(x_1, x_2, \dots, x_p\)</span>，那麼一定存在 <span class="math inline">\(p\)</span> 個相互獨立的變量 (principal components)，滿足下面的條件：</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(p\)</span> 個相互獨立的變量分別都是原始變量 <span class="math inline">\(x_1, x_2, \dots, x_p\)</span> 的線性轉換：
<span class="math display">\[
\begin{aligned}
y_1 &amp; = a_{11}x_1 + a_{12}x_2 + \cdots + a_{1p}x_p \\
y_2 &amp; = a_{21}x_1 + a_{22}x_2 + \cdots + a_{2p}x_p \\
\vdots &amp; \\
y_p &amp; = a_{p1}x_1 + a_{p2}x_2 + \cdots + a_{pp}x_p \\
\end{aligned}
\]</span></p></li>
<li><p>這 <span class="math inline">\(p\)</span> 個相互獨立的變量通過最大化它們對數據整體方差的貢獻獲得。</p></li>
<li><p>這 <span class="math inline">\(p\)</span> 個相互獨立的變量被叫做這個數據的主成分變量。</p></li>
<li><p>這些主成分變量之間相互獨立 (uncorrelated)，並且按照他們各自對數據總體方差的貢獻度從大到小排列 (the principal components are uncorrelated and are ordered by the amount of the total system variability that they explain)：</p></li>
</ol>
<p><span class="math display">\[
\text{Cov}(y_j, y_k) = 0 \text{ for any } j, k \in [1, p] \\
\text{Var}(y_1) \geqslant \text{Var}(y_2) \geqslant \text{Var}(y_3) \geqslant \dots \geqslant \text{Var}(y_p)
\]</span></p>
</div>
<div id="數學推導" class="section level2">
<h2><span class="header-section-number">68.3</span> 數學推導</h2>
<p>如果，</p>
<ul>
<li><span class="math inline">\(\textbf{S}\)</span> 是數據的<strong>方差協方差矩陣 (variance, covriance matrix)</strong>；</li>
<li><span class="math inline">\(\textbf{P}\)</span> 是<strong>直角投影矩陣 (orthogonal projection matrix)</strong>，該矩陣的每一列，是旋轉之後的新變量的座標，也就是主成分變量，它們又被叫做<strong>特徵向量 (eigenvectors)</strong>；</li>
<li><span class="math inline">\(\bf{\Lambda}\)</span> 是一個<strong>對角矩陣 (diagonal matrix)</strong>，它的對角線上是每個主成分變量的方差，它們又被叫做<strong>特徵值 (eigenvalues)</strong>。特徵值常常又被叫做慣性 (inertia)，特徵值從對角線左上角起往右下角是從大到小排列，每一個特徵值是每個特徵向量的方差，也就是數據整體方差投射在這個主成分變量上的慣性，可以理解爲該主成分能夠解釋多少整個數據的方差 (explained variance)。</li>
</ul>

<div class="theorem">
<span id="thm:unnamed-chunk-1" class="theorem"><strong>Theorem 68.1  (Spectral decomposition)  </strong></span>根據<strong>譜定理 Spectral decomposition</strong>：如果矩陣 <span class="math inline">\(\textbf{S}\)</span> 是對稱的，它總是可以被分解爲：
<span class="math display">\[
\textbf{S} = \textbf{P}\bf{\Lambda}\textbf{P}^t
\]</span>
</div>

<p>值得注意的是，首先，分解方差協方差矩陣的時候，並沒有任何統計學或者概率論上的前提條件；其次，這樣的矩陣分解不一定只用於方差協方差矩陣，你可以對任何對稱矩陣 (symmetrix matrix) 進行分解，它被叫做矩陣縮放 (matrix scaling)；最後，其實數據矩陣本身不一定非要是連續型變量，也不一定要有相似的刻度/取值範圍 (same scale)，如果你願意，對二分類變量或者是計數型變量，均可以進行主成分分析。但是，當變量之間的刻度相差巨大時，可能會產生一些意想不到的假象。所以，在實施主成分分析之前，通常的建議是對原始數據的變量進行標準化，或者直接用其相關係數矩陣 (correlation matrix)。</p>
<div id="超越對稱矩陣奇異值分解-singular-value-decomposition-svd" class="section level3">
<h3><span class="header-section-number">68.3.1</span> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</h3>
<p>主成分分析使用的矩陣分解方法，只能應用在方差協方差矩陣或者相關係數矩陣這樣的對稱的正方形矩陣。假如矩陣並非對稱，另一種矩陣分解方法叫做奇異值分解法 (singular value decomposition, SVD)。此時就可以直接應用在原始數據矩陣 <span class="math inline">\(\mathbf{X}_{n\times p}\)</span> 本身，而不需要侷限於數據的方差協方差矩陣/相關係數矩陣：</p>
<p><span class="math display">\[
\mathbf{X}_{n\times p} = \mathbf{U}_{n\times n}\bf{\Sigma}_{n \times p} \mathbf{W}_{p\times p}^t
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(\mathbf{U}_{n\times n}\)</span> 是含有<strong>左奇異向量 (left singular vectors)</strong> 的矩陣；</li>
<li><span class="math inline">\(\Sigma_{n \times p}\)</span> 是含有<strong>奇異值 (singular values)</strong>的矩陣；</li>
<li><span class="math inline">\(\mathbf{W}_{p\times p}\)</span> 則是含有<strong>右奇異向量 (right singular vectors)</strong> 的矩陣。</li>
</ul>
<p>所以你看到任意的形狀都可以被分解，此時分解出來的 <span class="math inline">\(\mathbf{U}_{n\times n}\)</span> 和 <span class="math inline">\(\mathbf{W}_{p\times p}\)</span> 是形狀維度不同的正方形矩陣。</p>
<p>另外，根據這樣的分解我們可以推導：</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{X}^t \mathbf{X} &amp; = \mathbf{W}\bf{\Sigma}\mathbf{U}^t\times\mathbf{U}\bf{\Sigma}\mathbf{W}^t \\
                        &amp; = \mathbf{W}\bf{\Sigma}^2\mathbf{W}^t \\ 
\Rightarrow \bf{\Sigma}^2 &amp; = \bf{\Lambda}                      
\end{aligned}
\]</span></p>
<p>所以，<span class="math inline">\(\bf{\Sigma}^2 = \bf{\Lambda}\)</span> ，也就是說在奇異值分解中獲得的中間矩陣 <span class="math inline">\(\bf{\Sigma}_{n \times p}\)</span>，它對角線上的數值的平方，就是每個原始變量的方差，或者說它們本身是原始數據的標準差。奇異值分解矩陣的方法最常見被用於實施對應分析 (Correspondence Analysis)。</p>
</div>
</div>
<div id="主成分分析數據實例" class="section level2">
<h2><span class="header-section-number">68.4</span> 主成分分析數據實例</h2>
<p><a href="http://factominer.free.fr/bookV2/orange.csv">橙汁數據</a>，是邀請美食家對產自世界各地的六種品牌的橙汁進行一個一個的味道/品質描述，並給每個項目打分後彙總獲得的評價數據。你可以用下面的代碼下載這個數據並觀察每個描述的變量，且很容易觀察的到的是，這些變量之間並不完全獨立，有些變量可能和另一些變量相關：</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Odour.intensity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Odour.typicality
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Pulpiness
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Intensity.of.taste
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Acidity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Bitterness
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Sweetness
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pampryl amb.
</td>
<td style="text-align:right;">
2.82
</td>
<td style="text-align:right;">
2.53
</td>
<td style="text-align:right;">
1.66
</td>
<td style="text-align:right;">
3.46
</td>
<td style="text-align:right;">
3.15
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
2.60
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana amb.
</td>
<td style="text-align:right;">
2.76
</td>
<td style="text-align:right;">
2.82
</td>
<td style="text-align:right;">
1.91
</td>
<td style="text-align:right;">
3.23
</td>
<td style="text-align:right;">
2.55
</td>
<td style="text-align:right;">
2.08
</td>
<td style="text-align:right;">
3.32
</td>
</tr>
<tr>
<td style="text-align:left;">
Fruvita fr.
</td>
<td style="text-align:right;">
2.83
</td>
<td style="text-align:right;">
2.88
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
3.45
</td>
<td style="text-align:right;">
2.42
</td>
<td style="text-align:right;">
1.76
</td>
<td style="text-align:right;">
3.38
</td>
</tr>
<tr>
<td style="text-align:left;">
Joker amb.
</td>
<td style="text-align:right;">
2.76
</td>
<td style="text-align:right;">
2.59
</td>
<td style="text-align:right;">
1.66
</td>
<td style="text-align:right;">
3.37
</td>
<td style="text-align:right;">
3.05
</td>
<td style="text-align:right;">
2.56
</td>
<td style="text-align:right;">
2.80
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana fr.
</td>
<td style="text-align:right;">
3.20
</td>
<td style="text-align:right;">
3.02
</td>
<td style="text-align:right;">
3.69
</td>
<td style="text-align:right;">
3.12
</td>
<td style="text-align:right;">
2.33
</td>
<td style="text-align:right;">
1.97
</td>
<td style="text-align:right;">
3.34
</td>
</tr>
<tr>
<td style="text-align:left;">
Pampryl fr.
</td>
<td style="text-align:right;">
3.07
</td>
<td style="text-align:right;">
2.73
</td>
<td style="text-align:right;">
3.34
</td>
<td style="text-align:right;">
3.54
</td>
<td style="text-align:right;">
3.31
</td>
<td style="text-align:right;">
2.63
</td>
<td style="text-align:right;">
2.90
</td>
</tr>
</tbody>
</table>
</div>
<p>進行主成分分析在Stata只需要這樣一行代碼：</p>
<pre><code>insheet using &quot;http://factominer.free.fr/bookV2/orange.csv&quot; , delimiter(&quot;;&quot;) clear
pca odour* pulp* intens* acid* bitter* sweetness, cor</code></pre>
<p>你就會獲得十分直觀的結果：</p>
<pre><code>
Principal components/correlation                 Number of obs    =          6
                                                 Number of comp.  =          5
                                                 Trace            =          7
    Rotation: (unrotated = principal)            Rho              =     1.0000

    --------------------------------------------------------------------------
       Component |   Eigenvalue   Difference         Proportion   Cumulative
    -------------+------------------------------------------------------------
           Comp1 |      4.74369       3.4104             0.6777       0.6777
           Comp2 |      1.33329      .513448             0.1905       0.8681
           Comp3 |      .819842      .735818             0.1171       0.9853
           Comp4 |     .0840232     .0648702             0.0120       0.9973
           Comp5 |      .019153      .019153             0.0027       1.0000
           Comp6 |            0            0             0.0000       1.0000
           Comp7 |            0            .             0.0000       1.0000
    --------------------------------------------------------------------------

Principal components (eigenvectors) 

    ------------------------------------------------------------------------------
        Variable |    Comp1     Comp2     Comp3     Comp4     Comp5 | Unexplained 
    -------------+--------------------------------------------------+-------------
    odourinten~y |   0.2110    0.6534   -0.5174    0.0286    0.0310 |           0 
    odourtypic~y |   0.4524    0.1162   -0.0646    0.2668    0.2952 |           0 
       pulpiness |   0.3313    0.5340    0.3290   -0.3327   -0.2250 |           0 
    intensityo~e |  -0.2984    0.3714    0.6910    0.0189    0.3456 |           0 
         acidity |  -0.4191    0.3017   -0.0237    0.7065   -0.4106 |           0 
      bitterness |  -0.4292    0.1628   -0.3152   -0.0974    0.6712 |           0 
       sweetness |   0.4384   -0.1374    0.2061    0.5553    0.3503 |           0 
    ------------------------------------------------------------------------------</code></pre>
<p>根據方差協方差矩陣進行的主成分分析結果，我們發現主成分 6 和 7 可以忽略不計。相同的計算結果可以在R裏面通過方便的計算包 <a href="http://factominer.free.fr/"><code>FactoMineR</code></a> 來計算並用 <a href="http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization"><code>factoextra</code></a> 來實現其分析圖形的美觀展示：</p>
<div class="sourceCode" id="cb995"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb995-1" title="1"><span class="co"># library(FactoMineR)</span></a>
<a class="sourceLine" id="cb995-2" title="2">org.pca &lt;-<span class="st"> </span><span class="kw">PCA</span>(orange[, <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>], <span class="dt">ncp =</span> <span class="dv">7</span>, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb995-3" title="3"></a>
<a class="sourceLine" id="cb995-4" title="4"><span class="co"># library(factoextra)</span></a>
<a class="sourceLine" id="cb995-5" title="5">eig.val &lt;-<span class="st"> </span><span class="kw">get_eigenvalue</span>(org.pca)</a>
<a class="sourceLine" id="cb995-6" title="6">eig.val <span class="co"># eigenvalue (variances of each principal components)</span></a></code></pre></div>
<pre><code>##        eigenvalue variance.percent cumulative.variance.percent
## Dim.1 4.743692688      67.76703840                   67.767038
## Dim.2 1.333289855      19.04699793                   86.814036
## Dim.3 0.819841150      11.71201643                   98.526053
## Dim.4 0.084023297       1.20033282                   99.726386
## Dim.5 0.019153009       0.27361442                  100.000000</code></pre>
<div class="sourceCode" id="cb997"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb997-1" title="1"><span class="co"># eigen vectors:</span></a>
<a class="sourceLine" id="cb997-2" title="2">org.pca<span class="op">$</span>svd<span class="op">$</span>V</a></code></pre></div>
<pre><code>##             [,1]        [,2]         [,3]         [,4]         [,5]
## [1,]  0.21100074  0.65340689 -0.517409852  0.028573070  0.030958154
## [2,]  0.45241413  0.11618305 -0.064606287  0.266760192  0.295222955
## [3,]  0.33132165  0.53403262  0.329025446 -0.332685134 -0.225026986
## [4,] -0.29836065  0.37144476  0.690990232  0.018942515  0.345597119
## [5,] -0.41905731  0.30166462 -0.023688451  0.706533003 -0.410644925
## [6,] -0.42917948  0.16282112 -0.315220908 -0.097425116  0.671196644
## [7,]  0.43840960 -0.13742859  0.206064224  0.555251136  0.350251763</code></pre>
<p>於是根據計算獲得的特徵值向量，我們可以寫下這5個主成分變量和原始變量之間的轉換關係方程：</p>
<p><span class="math display">\[
\begin{aligned}
y_1 &amp; = 0.2110x_1 + 0.4524x_2 + 0.3313x_3 - 0.2984x_4 - 0.4191x_5 - 0.4292x_6 + 0.4384x_7 \\
y_2 &amp; = 0.6534x_1 + 0.1162x_2 + 0.5340x_3 + 0.3714x_4 + 0.3017x_5 + 0.1628x_6 - 0.1374x_7 \\
y_3 &amp; =-0.5174x_1 - 0.0646x_2 + 0.3290x_3 + 0.6910x_4 - 0.0237x_5 - 0.3152x_6 + 0.2061x_7 \\
y_4 &amp; = 0.0286x_1 + 0.2668x_2 - 0.3327x_3 + 0.0189x_4 + 0.7065x_5 - 0.0974x_6 + 0.5553x_7 \\
y_5 &amp; = 0.0310x_1 + 0.2952x_2 - 0.2250x_3 + 0.3456x_4 - 0.4106x_5 + 0.6712x_6 + 0.3503x_7 \\
\end{aligned}
\]</span></p>
<p>於是，解釋完了如何從原始數據變量根據計算獲得的特徵值向量轉換成爲新的變量之後，要面對的問題是，我們要保留多少主成分？
我們通常會使用圖 <a href="#fig:PCAorangeScreeplot">68.6</a> 那樣的碎石圖 (Scree plot) 來輔助判斷。碎石圖通常縱軸是每個主成分能夠解釋的數據總體方差的百分比，然後橫軸是主成分的個數。所以我們會期待出現一個像手肘一樣的形狀提示應該在第幾個主成分的地方停下。通常在統計分析中，我們默認的準則是，至少保留的主成分個數要能夠解釋總體方差的 70%/80% 以上才較爲理想。<a href="https://en.wikipedia.org/wiki/Exploratory_factor_analysis#Kaiser&#39;s_(1960)_eigenvalue-greater-than-one_rule_(K1_or_Kaiser_criterion)">Kaiser 準則</a> 建議的是，最好保留下特徵值大於等於1(也就是標準化數據之後獲得的主成分變量方差大於等於1)的主成分變量。在我們的橙汁數據實例中，顯然保留前兩個主成分就已經能夠解釋 86.81% 的總體方差，我們認爲這是理想的主成分個數。</p>
<div class="figure" style="text-align: center"><span id="fig:PCAorangeScreeplot"></span>
<img src="bookdown_files/figure-html/PCAorangeScreeplot-1.png" alt="Orange data: eigenvalues among all variances (varaince explained) by each dimension (principle component) provided by PCA" width="70%" />
<p class="caption">
圖 68.6: Orange data: eigenvalues among all variances (varaince explained) by each dimension (principle component) provided by PCA
</p>
</div>
<p>另外一種輔助的圖形是叫做分數圖 (score plot)，又名個人圖 (graph of individuals)，如果個體的變量特徵相近，他們會在圖中聚在較爲靠近的地方：</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb999-1" title="1"><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">pointsize =</span> <span class="st">&quot;cos2&quot;</span>, <span class="dt">pointshape =</span> <span class="dv">21</span>, </a>
<a class="sourceLine" id="cb999-2" title="2">             <span class="dt">fill =</span> <span class="st">&quot;#E7B800&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangeScoreplot"></span>
<img src="bookdown_files/figure-html/PCAorangeScoreplot-1.png" alt="Score plot/individual plot of the orange data." width="70%" />
<p class="caption">
圖 68.7: Score plot/individual plot of the orange data.
</p>
</div>
<p>細心觀察的話，你會發現圖 <a href="#fig:PCAorangeScoreplot">68.7</a> 中各個橙汁 (個體,individual) 的座標其實是來自於PCA分析結果中第一和第二主成分變量的結果，展示在第一和第二主成分變量構成的平面。該平面解釋了總體數據慣性 (inertia) 的 86.82% (= 67.77% + 19.05%)。其中第一個主成分 <code>Dim.1</code> 把 <code>Tropicana fr.</code> 和 <code>Pampryl amb.</code> 兩種橙汁分別歸類在最右邊和最左邊。這是因爲原始數據中 <code>Tropicana fr.</code> 是 <code>Odour.typicality</code> 得分最高 <code>Bitternes</code> 得分倒數第二低，同時 <code>Pampryl amb.</code> 則是在這兩個項目上得分分別是最低和最高。也就是說這兩種橙汁在這兩個項目上得分分別是左右兩種極端，所以首先在第一主成分中把這兩中橙汁分離開來。接下來，第二主成分變量 <code>Dim.2</code> 則是將第一主成分成功分離開的兩個個體(橙汁)從數據中拿掉以後，剩下的四種橙汁的分類。可以看到第二個主成分軸，把 <code>Pampryl fr.</code> 和 <code>Tropicana amb.</code> 兩種橙汁放在了該軸的兩個極端，這是因爲 <code>Pampryl fr.</code> 在 <code>Intensity.of.taste</code> 項目上得分最高，而 <code>Tropicana amb.</code> 在拿掉了第一主成分分離的兩種橙汁之後，在 <code>Odour.intensity</code> 項目上得分最低。</p>
<p>回到 R 幫忙分析的主成分結果報告來：</p>
<div class="sourceCode" id="cb1000"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1000-1" title="1"><span class="kw">summary</span>(org.pca)</a></code></pre></div>
<pre><code>## 
## Call:
## PCA(X = orange[, 1:7], ncp = 7, graph = FALSE) 
## 
## 
## Eigenvalues
##                        Dim.1   Dim.2   Dim.3   Dim.4   Dim.5
## Variance               4.744   1.333   0.820   0.084   0.019
## % of var.             67.767  19.047  11.712   1.200   0.274
## Cumulative % of var.  67.767  86.814  98.526  99.726 100.000
## 
## Individuals
##                        Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
## Pampryl amb.       |  3.029 | -2.984 31.288  0.970 | -0.082  0.085  0.001 | -0.333  2.254  0.012 |
## Tropicana amb.     |  1.976 |  0.886  2.761  0.201 | -1.715 36.771  0.753 | -0.087  0.154  0.002 |
## Fruvita fr.        |  2.595 |  1.937 13.182  0.557 |  0.040  0.020  0.000 |  1.710 59.450  0.434 |
## Joker amb.         |  2.094 | -1.896 12.631  0.820 | -0.834  8.686  0.158 | -0.154  0.481  0.005 |
## Tropicana fr.      |  3.512 |  3.186 35.660  0.823 |  0.589  4.335  0.028 | -1.345 36.774  0.147 |
## Pampryl fr.        |  2.338 | -1.129  4.479  0.233 |  2.002 50.102  0.733 |  0.209  0.887  0.008 |
## 
## Variables
##                       Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
## Odour.intensity    |  0.460  4.452  0.211 |  0.754 42.694  0.569 | -0.468 26.771  0.219 |
## Odour.typicality   |  0.985 20.468  0.971 |  0.134  1.350  0.018 | -0.058  0.417  0.003 |
## Pulpiness          |  0.722 10.977  0.521 |  0.617 28.519  0.380 |  0.298 10.826  0.089 |
## Intensity.of.taste | -0.650  8.902  0.422 |  0.429 13.797  0.184 |  0.626 47.747  0.391 |
## Acidity            | -0.913 17.561  0.833 |  0.348  9.100  0.121 | -0.021  0.056  0.000 |
## Bitterness         | -0.935 18.420  0.874 |  0.188  2.651  0.035 | -0.285  9.936  0.081 |
## Sweetness          |  0.955 19.220  0.912 | -0.159  1.889  0.025 |  0.187  4.246  0.035 |</code></pre>
<p>可以看到第一部分是特徵值(eigenvalue)的結果描述，第二部分是個人 (individual) 的分析報告：</p>
<pre><code>...{omitted}...
Individuals
                       Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2 
Pampryl amb.       |  3.029 | -2.984 31.288  0.970 | -0.082  0.085  0.001
Tropicana amb.     |  1.976 |  0.886  2.761  0.201 | -1.715 36.771  0.753 
Fruvita fr.        |  2.595 |  1.937 13.182  0.557 |  0.040  0.020  0.000 
Joker amb.         |  2.094 | -1.896 12.631  0.820 | -0.834  8.686  0.158 
Tropicana fr.      |  3.512 |  3.186 35.660  0.823 |  0.589  4.335  0.028 
Pampryl fr.        |  2.338 | -1.129  4.479  0.233 |  2.002 50.102  0.733 
...{omitted}...</code></pre>
<p>其中，</p>
<ul>
<li><code>Dist</code> 是每個個體(行數據)，到座標軸原點 (平均重心位置) 的距離。此數據中距離原點最遠的兩種橙汁是 <code>Pampryl amb.</code> (最左邊) 和 <code>Tropicana fr.</code> (最右邊)。</li>
<li><code>Dim.1</code> 是該個體，在第一個主成分變量座標軸上的座標。</li>
<li><code>ctr</code> 是該個體在第一個主成分變量提取時貢獻的百分比。</li>
<li><code>cos2</code> 是該個體在該主成分變量上投影的慣性除以該個體本身的慣性所佔的比例，又叫做該個體對相應主成分變量的代表性評價 (the quality of representation of an individual <span class="math inline">\(i\)</span> on the principle component <span class="math inline">\(s\)</span> is measured by the distance between the point within the space <span class="math inline">\(u_s\)</span> and the projection on the component)。</li>
</ul>
<p><span class="math display">\[
\text{quality of representation}_s(i) = \frac{\text{Projected inertia of }i \text{ on } u_s}{\text{Total inertia of }i} = \cos^2\theta_i^s 
\]</span></p>
<p>PCA報告的下半部分，是關於數據中變量與變量之間關係的分析結果。</p>
<pre><code>Variables
                      Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2  
Odour.intensity    |  0.460  4.452  0.211 |  0.754 42.694  0.569 | -0.468 26.771  0.219 |
Odour.typicality   |  0.985 20.468  0.971 |  0.134  1.350  0.018 | -0.058  0.417  0.003 |
Pulpiness          |  0.722 10.977  0.521 |  0.617 28.519  0.380 |  0.298 10.826  0.089 |
Intensity.of.taste | -0.650  8.902  0.422 |  0.429 13.797  0.184 |  0.626 47.747  0.391 |
Acidity            | -0.913 17.561  0.833 |  0.348  9.100  0.121 | -0.021  0.056  0.000 |
Bitterness         | -0.935 18.420  0.874 |  0.188  2.651  0.035 | -0.285  9.936  0.081 |
Sweetness          |  0.955 19.220  0.912 | -0.159  1.889  0.025 |  0.187  4.246  0.035 |</code></pre>
<p>根據這個結果繪製的變量相關關係圖如下：</p>
<div class="sourceCode" id="cb1004"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1004-1" title="1"><span class="kw">fviz_pca_var</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangevariableplot"></span>
<img src="bookdown_files/figure-html/PCAorangevariableplot-1.png" alt="Variable plot of the orange data." width="70%" />
<p class="caption">
圖 68.8: Variable plot of the orange data.
</p>
</div>
<ul>
<li>在第一個主成分軸上 (<code>Dim.1</code>)，正相關的變量 <code>Odour.intensity, Odour.typicality, Pulpiness, Sweetness</code> 被歸類在右半球，而負相關的變量 <code>Intensity.of.taste, Acidity, Bitterness</code> 則被歸類在第一主成分軸的左半球。</li>
<li>相似地，在第二個主成分軸上 (<code>Dim.2</code>)，只有負相關的 <code>Sweetness</code> 被歸類在下半球。</li>
<li>每個變量從原點出發時的箭頭長度越長 <code>cos2</code>，代表它在該主成分軸上代表質量更好 (the quality of representation of the variable on the component)</li>
</ul>
<p>如果你願意，且數據和變量不至於多到眼花繚亂，我們還可以把個體圖和變量圖結合起來觀察：</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1005-1" title="1"><span class="kw">fviz_pca_biplot</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>, <span class="dt">pointsize =</span> <span class="st">&quot;cos2&quot;</span>, <span class="dt">pointshape =</span> <span class="dv">21</span>, </a>
<a class="sourceLine" id="cb1005-2" title="2">             <span class="dt">labelsize =</span> <span class="dv">2</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAorangebiplot"></span>
<img src="bookdown_files/figure-html/PCAorangebiplot-1.png" alt="Biplot of the orange data." width="70%" />
<p class="caption">
圖 68.9: Biplot of the orange data.
</p>
</div>
</div>
<div id="在pca圖形中加入補充變量和補充個體-supplementary-elements" class="section level2">
<h2><span class="header-section-number">68.5</span> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</h2>
<p>在橙汁數據中，除了有美食家給出的各個味道項目的評分之外，其實還有各個橙汁的物理化學特性數據。</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Glucose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Fructose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Saccharose
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Sweetening.power
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
pH
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Citric.acid
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Vitamin.C
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Way.of.preserving
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Origin
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pampryl amb.
</td>
<td style="text-align:right;">
25.32
</td>
<td style="text-align:right;">
27.36
</td>
<td style="text-align:right;">
36.45
</td>
<td style="text-align:right;">
89.95
</td>
<td style="text-align:right;">
3.59
</td>
<td style="text-align:right;">
0.84
</td>
<td style="text-align:right;">
43.44
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Other
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana amb.
</td>
<td style="text-align:right;">
17.33
</td>
<td style="text-align:right;">
20.00
</td>
<td style="text-align:right;">
44.15
</td>
<td style="text-align:right;">
82.55
</td>
<td style="text-align:right;">
3.89
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:right;">
32.70
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Fruvita fr.
</td>
<td style="text-align:right;">
23.65
</td>
<td style="text-align:right;">
25.65
</td>
<td style="text-align:right;">
52.12
</td>
<td style="text-align:right;">
102.22
</td>
<td style="text-align:right;">
3.85
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
37.00
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Joker amb.
</td>
<td style="text-align:right;">
32.42
</td>
<td style="text-align:right;">
34.54
</td>
<td style="text-align:right;">
22.92
</td>
<td style="text-align:right;">
90.71
</td>
<td style="text-align:right;">
3.60
</td>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
36.60
</td>
<td style="text-align:left;">
Ambient
</td>
<td style="text-align:left;">
Other
</td>
</tr>
<tr>
<td style="text-align:left;">
Tropicana fr.
</td>
<td style="text-align:right;">
22.70
</td>
<td style="text-align:right;">
25.32
</td>
<td style="text-align:right;">
45.80
</td>
<td style="text-align:right;">
94.87
</td>
<td style="text-align:right;">
3.82
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
39.50
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Florida
</td>
</tr>
<tr>
<td style="text-align:left;">
Pampryl fr.
</td>
<td style="text-align:right;">
27.16
</td>
<td style="text-align:right;">
29.48
</td>
<td style="text-align:right;">
38.94
</td>
<td style="text-align:right;">
96.51
</td>
<td style="text-align:right;">
3.68
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
27.00
</td>
<td style="text-align:left;">
Fresh
</td>
<td style="text-align:left;">
Other
</td>
</tr>
</tbody>
</table>
</div>
<p>我們可以把這些沒有用於計算主成分分析的變量 (active variables)，和其餘的輔助性變量 (supplementary variables) 同時繪製在變量相關係數圓盤圖中。此時我們只需要在進行PCA運算的時候告訴R這些變量是輔助性的連續/分類變量即可：</p>
<div class="sourceCode" id="cb1006"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1006-1" title="1">org.pca &lt;-<span class="st"> </span><span class="kw">PCA</span>(orange, <span class="dt">quanti.sup =</span> <span class="dv">8</span><span class="op">:</span><span class="dv">14</span>, <span class="dt">quali.sup =</span> <span class="dv">15</span><span class="op">:</span><span class="dv">16</span>,</a>
<a class="sourceLine" id="cb1006-2" title="2">               <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1006-3" title="3">org.pca<span class="op">$</span>quanti.sup</a></code></pre></div>
<pre><code>## $coord
##                         Dim.1       Dim.2         Dim.3        Dim.4       Dim.5
## Glucose          -0.572454497  0.31123036  0.0263849025 -0.208332016 -0.72892600
## Fructose         -0.561054870  0.31451133 -0.0084203081 -0.181973281 -0.74371694
## Saccharose        0.750440168  0.14492075  0.3246761207 -0.075192796  0.55205886
## Sweetening.power  0.300767457  0.67471255  0.4895557731 -0.389880490 -0.25026037
## pH                0.879663611 -0.23629707  0.1935892274  0.245926101  0.26907097
## Citric.acid      -0.739370266 -0.12160048 -0.1957416737 -0.278669842 -0.56795532
## Vitamin.C        -0.044575912 -0.31698263 -0.2545161911 -0.905066399  0.11666756
## 
## $cor
##                         Dim.1       Dim.2         Dim.3        Dim.4       Dim.5
## Glucose          -0.572454497  0.31123036  0.0263849025 -0.208332016 -0.72892600
## Fructose         -0.561054870  0.31451133 -0.0084203081 -0.181973281 -0.74371694
## Saccharose        0.750440168  0.14492075  0.3246761207 -0.075192796  0.55205886
## Sweetening.power  0.300767457  0.67471255  0.4895557731 -0.389880490 -0.25026037
## pH                0.879663611 -0.23629707  0.1935892274  0.245926101  0.26907097
## Citric.acid      -0.739370266 -0.12160048 -0.1957416737 -0.278669842 -0.56795532
## Vitamin.C        -0.044575912 -0.31698263 -0.2545161911 -0.905066399  0.11666756
## 
## $cos2
##                         Dim.1       Dim.2          Dim.3        Dim.4       Dim.5
## Glucose          0.3277041510 0.096864337 0.000696163079 0.0434022288 0.531333120
## Fructose         0.3147825674 0.098917374 0.000070901589 0.0331142749 0.553114882
## Saccharose       0.5631604458 0.021002025 0.105414583332 0.0056539566 0.304768989
## Sweetening.power 0.0904610632 0.455237031 0.239664854983 0.1520067964 0.062630255
## pH               0.7738080690 0.055836307 0.037476788962 0.0604796473 0.072399188
## Citric.acid      0.5466683910 0.014786677 0.038314802810 0.0776568810 0.322573248
## Vitamin.C        0.0019870119 0.100477991 0.064778491512 0.8191451868 0.013611319</code></pre>
<p>然後用下面的代碼繪製包含了輔助性變量的變量相關圓盤圖：</p>
<div class="sourceCode" id="cb1008"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1008-1" title="1"><span class="kw">fviz_pca_var</span>(org.pca, <span class="dt">repel =</span> <span class="ot">TRUE</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAvarsuppplot"></span>
<img src="bookdown_files/figure-html/PCAvarsuppplot-1.png" alt="Orange juice data: representation of the active and supplementary variables (in blue)." width="90%" />
<p class="caption">
圖 68.10: Orange juice data: representation of the active and supplementary variables (in blue).
</p>
</div>
<p>如圖 <a href="#fig:PCAvarsuppplot">68.10</a> 所示，第一個主成分變量分離的左右半球的橙汁味道特徵，和他們的物理特性其實是相呼應的。例如，<code>pH</code> 值出現在了圓盤的右半邊，靠近 <code>Sweetness</code> 這一變量。因爲 <code>pH</code> 越高，酸度越低，那麼味道也就越甜，這是合理的。另外一個有趣的現象是，蔗糖 <code>saccharose</code> 含量高的橙汁，<code>pH</code> 越高，味道越甜。在圓盤的左邊，是蔗糖在酸環境下分解之後產生的果糖和葡萄糖，所以果糖葡萄糖反而和酸度 <code>Acidity</code> 相關性高，因爲橙汁中果糖葡萄糖含量高意味着蔗糖被酸分解。</p>
<p>由此可見，PCA是一個對數據進行初步描述和探索時十分有力的工具。所以，在回歸模型選擇變量之前，建議可以對數據先進行主成分分析，並且把預備考慮放在回歸模型的解釋變量部分的變量用於PCA主成分分析，把想要做預測的變量作爲輔助性變量投射到主成分分析的變量相關圖中，觀察解釋變量之間可能存在的相關性，有助於選取合適的解釋變量。</p>
<div id="展示分類輔助性變量和個體的關係" class="section level3">
<h3><span class="header-section-number">68.5.1</span> 展示分類輔助性變量和個體的關係</h3>
<p>根據不同的儲存方式，兩類的橙汁區別很清楚。</p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1009-1" title="1">p &lt;-<span class="st"> </span><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">habillage =</span> <span class="dv">15</span>, </a>
<a class="sourceLine" id="cb1009-2" title="2">             <span class="dt">palette =</span> <span class="st">&quot;jco&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1009-3" title="3">p</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAindplotsupp"></span>
<img src="bookdown_files/figure-html/PCAindplotsupp-1.png" alt="Plane representation of the scatterplot of individuals with a supplementary categorical variable (way of preserving)." width="70%" />
<p class="caption">
圖 68.11: Plane representation of the scatterplot of individuals with a supplementary categorical variable (way of preserving).
</p>
</div>
<p>根據橙子的產地區分繪製的個人圖：</p>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1010-1" title="1">p &lt;-<span class="st"> </span><span class="kw">fviz_pca_ind</span>(org.pca, <span class="dt">habillage =</span> <span class="dv">16</span>, </a>
<a class="sourceLine" id="cb1010-2" title="2">             <span class="dt">palette =</span> <span class="st">&quot;jco&quot;</span>, <span class="dt">repel =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1010-3" title="3">p</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PCAindplotsupp2"></span>
<img src="bookdown_files/figure-html/PCAindplotsupp2-1.png" alt="Plane representation of the scatterplot of individuals with a supplementary categorical variable (origin)." width="70%" />
<p class="caption">
圖 68.12: Plane representation of the scatterplot of individuals with a supplementary categorical variable (origin).
</p>
</div>
</div>
</div>
<div id="cluster-analysispca-practical" class="section level2">
<h2><span class="header-section-number">68.6</span> Cluster analysis/PCA practical</h2>
<p>本次練習完成時，你將學會：</p>
<ol style="list-style-type: decimal">
<li>如何使用聚類分析，和主成分分析法來探索一組多變量數據之間的關係；</li>
<li>理解並懂得如何選取合適的距離測量尺度，和聚類分析方法；</li>
<li>繪製並能夠解釋由多層聚類分析算法 (hierarchical clustering algorithm) 獲得的樹狀圖；</li>
<li>使用主成分分析法對數據進行座標轉換，計算多個變量之間的方差，協方差矩陣，懂得如何判斷保留主成分的個數；</li>
<li>通過把數據繪製在較低維度的主成分座標軸上來判斷數據中可能存在的潛在分層/分組。</li>
</ol>
<div id="使用的數據和簡單背景知識" class="section level3">
<h3><span class="header-section-number">68.6.1</span> 使用的數據和簡單背景知識</h3>
<p>假設你是一名生物測量技術公司的統計師，現在有這樣一組數據，包含了對某植物測量的4種生物標幟物(biomarkers)。據報道，這四種成分或許能減少你公司生產的某藥物引起的副作用。爲了嘗試分析該植物的生物特性，從該植物的50個不同樣本中，測量了這4種生物標幟物的濃度。你的任務之一是對數據進行初步分析，彙報任何你找到的可能存在的顯著特徵差異。</p>
<ol style="list-style-type: decimal">
<li>在R裏讀入你的數據，看看這4種生物標幟物的簡單統計量和分佈，它們用的是相同的測量單位嗎？</li>
</ol>
<div class="sourceCode" id="cb1011"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1011-1" title="1">plant &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/plant.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1011-2" title="2">plant &lt;-<span class="st"> </span>plant[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]</a>
<a class="sourceLine" id="cb1011-3" title="3"><span class="kw">head</span>(plant)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##       bm1     bm2     bm3     bm4
##     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1  17.4    78.6   101.    109.   
## 2  87      30.1    79.1     6.60 
## 3   0.100   0.600   0.900   0.200
## 4 106      10      44.6    57.6  
## 5 141.    122     115.    123.   
## 6   0.5     0.800   0.200   0.5</code></pre>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1013-1" title="1"><span class="kw">summ</span>(plant)</a></code></pre></div>
<pre><code>## 
## No. of observations = 50
## 
##   Var. name obs. mean   median  s.d.   min.   max.  
## 1 bm1       50   56.6   47.55   48.05  0      143   
## 2 bm2       50   53.21  52.7    45.13  0      143.6 
## 3 bm3       50   61.43  55.25   51.47  0.2    147.9 
## 4 bm4       50   57.43  56.75   45.45  0.1    146.1</code></pre>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1015-1" title="1">psych<span class="op">::</span><span class="kw">describe</span>(plant)</a></code></pre></div>
<pre><code>##     vars  n  mean    sd median trimmed   mad min   max range skew kurtosis   se
## bm1    1 50 56.60 48.05  47.55   53.36 66.05 0.0 143.0 143.0 0.27    -1.38 6.80
## bm2    2 50 53.21 45.13  52.70   49.62 59.45 0.0 143.6 143.6 0.43    -1.07 6.38
## bm3    3 50 61.43 51.47  55.25   58.86 69.76 0.2 147.9 147.7 0.27    -1.47 7.28
## bm4    4 50 57.43 45.45  56.75   54.71 52.41 0.1 146.1 146.0 0.32    -1.12 6.43</code></pre>
<p>觀察這四個生物標幟物的簡單統計量，似乎可以認爲它們使用的應該是相似或者相同的測量單位。它們的均值在53至61之間，標準差分佈在45-51之間，而且最大值最小值之間的範圍也十分接近。</p>
<ol start="2" style="list-style-type: decimal">
<li>這些生物標幟物能否單獨提供關於該植物的某部分特徵信息呢？思考我們該如何回答這個問題（提示：計算這些指標直接的相關係數）</li>
</ol>
<p>我們可以通過計算這四個生物標幟物濃度測量值之間的相關係數，來觀察它們之間是否具有相似性或者是否提供了部分相似的信息。</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1017-1" title="1"><span class="kw">cor</span>(plant)</a></code></pre></div>
<pre><code>##            bm1        bm2        bm3        bm4
## bm1 1.00000000 0.49826220 0.59414820 0.26769269
## bm2 0.49826220 1.00000000 0.50574946 0.33347350
## bm3 0.59414820 0.50574946 1.00000000 0.32094816
## bm4 0.26769269 0.33347350 0.32094816 1.00000000</code></pre>
<p>從相關係數矩陣的計算結果來看，平均地，這四個生物標幟物濃度之間具有一定程度的相關性。其中，生物標幟物1和3之間呈現了四者之間最高的樣本相關係數 <span class="math inline">\((r_{13} = 0.5941)\)</span>，生物標幟物1和4之間的相關係數則最小 <span class="math inline">\((r_{14} = 0.2677)\)</span>。</p>
<ol start="3" style="list-style-type: decimal">
<li>請描述前一步中我們計算的相關係數矩陣的維度(dimension)。</li>
</ol>
<p>該相關係數矩陣的維度是 <span class="math inline">\(4\times4\)</span>，事實上，這個矩陣的維度是由我們想要觀察分析的樣本中測量變量的個數決定的（在這裏就是四個生物標幟物）。但是這個相關係數的矩陣並不適合用於做聚類分析 (cluster analysis)，因爲相關係數本身反映的是變量之間的關係 (between variables)，並非觀察對象 (between subjects) 之間的距離(即，不是我們關心的用來把50個樣本進行分組歸類的距離變量)。</p>
<ol start="4" style="list-style-type: decimal">
<li>再次思考問題1.的答案，思考並選擇合適的測量不同樣本個體之間距離 (distance) 的度量衡。嘗試使用簡單的聚類分析命令對樣本進行分類。</li>
</ol>
<p>由於每個生物標記物在所有樣本中的數值基本在相似的比例或者刻度，每個標幟物在這個樣本中的標準差/方差數值也較爲相近。我們嘗試用連續變量最常見的均值測量距離指標:</p>
<div class="sourceCode" id="cb1019"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1019-1" title="1"><span class="co"># prepare hierarchical cluster</span></a>
<a class="sourceLine" id="cb1019-2" title="2">hc &lt;-<span class="st">  </span><span class="kw">hclust</span>(<span class="kw">dist</span>(plant), <span class="st">&quot;ave&quot;</span>)</a>
<a class="sourceLine" id="cb1019-3" title="3"></a>
<a class="sourceLine" id="cb1019-4" title="4"></a>
<a class="sourceLine" id="cb1019-5" title="5"><span class="kw">plot</span>(hc, <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1019-6" title="6">     <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L2 dissimilarity measure&quot;</span>, </a>
<a class="sourceLine" id="cb1019-7" title="7">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-3"></span>
<img src="bookdown_files/figure-html/pca-3-1.png" alt="Dendrogram for L2_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.13: Dendrogram for L2_avlink cluster analysis
</p>
</div>
<p>可以觀察到，樣本編號 31, 27, 17, 48, 8, 30, 3, 14, 6, 42 很快就聚合成爲一組。且這些樣本和其他樣本被聚類在不同組的過程一直維持到差異性達到100以上。我們還可以注意到，聚類過程中其他的分支呈現相對對稱的形狀。</p>
<ol start="5" style="list-style-type: decimal">
<li>從簡單的歐幾里得距離改成歐幾里得距離平方來測量樣本之間的距離的話，圖形會變成什麼樣？</li>
</ol>
<div class="sourceCode" id="cb1020"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1020-1" title="1">hc &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">dist</span>(plant)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1020-2" title="2"></a>
<a class="sourceLine" id="cb1020-3" title="3"><span class="kw">plot</span>(hc, <span class="dt">cex =</span> <span class="fl">0.8</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1020-4" title="4">     <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L2squared dissimilarity measure&quot;</span>, </a>
<a class="sourceLine" id="cb1020-5" title="5">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>, <span class="dt">sub =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-4"></span>
<img src="bookdown_files/figure-html/pca-4-1.png" alt="Dendrogram for L2sq_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.14: Dendrogram for L2sq_avlink cluster analysis
</p>
</div>
<p>當使用歐幾里得距離的平方作爲樣本間隔的度量衡時，我們發現聚類的過程其實總體來說和使用歐幾里得距離本身並無本質上的區別。只是在差異性較低的地方聚類加速 (squeeze the dissimilarities at the lower end)，並且在較大的聚類區分之間變得更加明顯，視覺效果上更容易區分。</p>
<p>如果說，不用歐幾里得平方，而是使用簡單的曼哈頓距離 (L1 度量衡)，那麼圖形則又會呈現爲:</p>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1021-1" title="1"><span class="kw">plot</span>(cluster<span class="op">::</span><span class="kw">agnes</span>(plant, <span class="dt">metric =</span> <span class="st">&quot;manhattan&quot;</span>, <span class="dt">stand =</span> F), <span class="dt">which.plots =</span> <span class="dv">2</span>, <span class="dt">hang =</span> <span class="dv">-1</span>, </a>
<a class="sourceLine" id="cb1021-2" title="2">     <span class="dt">xlab =</span> <span class="st">&quot;No. of specimen&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;L1 dissimilarity measure&quot;</span>, <span class="dt">sub =</span> <span class="st">&quot;&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pca-5"></span>
<img src="bookdown_files/figure-html/pca-5-1.png" alt="Dendrogram for L1_avlink cluster analysis" width="80%" />
<p class="caption">
圖 68.15: Dendrogram for L1_avlink cluster analysis
</p>
</div>
<p>可以看出，當使用曼哈頓距離做度量衡時，聚類的過程和之前的沒有本質上的區別，但是圖形的樹狀分支上似乎不再左右對稱。</p>
<ol start="6" style="list-style-type: decimal">
<li>接下來使用歐幾里得距離做度量衡，與上面的嘗試不同，這裏我們嘗試用完全連接，和單連接</li>
</ol>
</div>
</div>
</div>
<div id="missing-data-2" class="section level1">
<h1><span class="header-section-number">第 69 章</span> Missing data 2</h1>
</div>
<div id="further-issues" class="section level1">
<h1><span class="header-section-number">第 70 章</span> Further issues</h1>

</div>



<div id="生存分析入門" class="section level1">
<h1><span class="header-section-number">第 71 章</span> 生存分析入門</h1>
<blockquote>
<dl>
<dt>The best thing about being a statistician is that you get to play in everyone’s backyard.</dt>
<dd>John Tukey
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Survival Analysis lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/keogh.ruth">Ruth Keogh</a>, and Professor <a href="https://aurelienbelot.netlify.com">Aurélien Belot</a>.
</div>

<div id="什麼是生存分析" class="section level2">
<h2><span class="header-section-number">71.1</span> 什麼是生存分析</h2>
<p>生存分析，研究的是隨訪中研究對象發生我們關心的事件與否，以及比較發生該事件之前時間的長短 (生存時間) 的一種分析方法。生存數據的常見例子如下:</p>
<ul>
<li>死亡 (all cause);</li>
<li>診斷/治療後直至死亡發生的時間;</li>
<li>孕婦的懷孕時間 (孕期長短);</li>
<li>對象以健康狀態進入研究時開始，直至其診斷爲患有某種疾病的時間。</li>
</ul>
<p>生存分析中的常見術語:</p>
<ul>
<li>生存時間 survival time = 失敗時間 failure time = 事件時間 event time。</li>
<li>生存分析本身常被叫做事件史分析 time-to-event analysis。</li>
</ul>
<p>生存分析的結果，可以用來回答很多我們關心的問題:</p>
<ol style="list-style-type: decimal">
<li>研究特定人羣中，在某段時間內人口生存 (或死亡) 的模式 (平均壽命): 在英國，某年 (例如 1970 年) 出生的人，能夠生存到 5 歲，40 歲，100 歲的概率是多大？ (關心的是死亡在某人身上發生的概率)</li>
<li>比較兩組或多組人羣之間，不同的特徵導致的死亡時間的差異大小的估計: 某種新療法對於同時被診斷爲相同程度肺癌的患者，和標準療法相比是否能有效延長其生存時間？</li>
<li>研究多種變量 (例如體重，年齡，性別，吸煙，飲食等) 和事件發生時間長短之間的關系: 例如收集健康對象，研究其體質指數 (BMI) 和最終發生二型糖尿病幾率之間的關系，同時要調整其他已知的混雜因素。</li>
<li>預測特定患者的存活幾率: 肝癌患者診斷後的 5 年生存率，10 年生存率的推算。</li>
</ol>
</div>
<div id="生存數據在哪裏" class="section level2">
<h2><span class="header-section-number">71.2</span> 生存數據在哪裏</h2>
<p>生存數據其實很常見，下面是幾個例子:</p>
<ol style="list-style-type: decimal">
<li>特定國家特定時間內對人口出生死亡的登記數據;</li>
<li>在隨機雙盲對照臨牀試驗中，治療組和安慰劑組相比，治療組的生存時間是否真的較長;</li>
<li>前瞻性隊列研究;</li>
<li>非醫學的例子也有很多，例如分析暴風雪降臨之前的時間，或者推測地震可能發生的幾率。</li>
</ol>
</div>
<div id="生存數據分析之前要理清楚的問題" class="section level2">
<h2><span class="header-section-number">71.3</span> 生存數據分析之前要理清楚的問題</h2>
<ol style="list-style-type: decimal">
<li>對於結果/事件的定義;</li>
<li>研究的時間起點;</li>
<li>研究的時間單位是用的月份，周，還是年，是觀察時間，還是患者的實際年齡 (實際年齡就是實際生存時間);</li>
<li>事件發生時的時間，是否被精確定義了？</li>
</ol>
</div>
<div id="生存數據的左右截尾" class="section level2">
<h2><span class="header-section-number">71.4</span> 生存數據的左右截尾</h2>
<p>沒有哪個研究能保證觀察隨訪到所有的研究對象最終是否發生了事件 (死亡)，有些對象在研究中途就會退出實驗。所以這些沒有觀察到事件發生，但是在研究的過程中貢獻了生存時間數據的對象，被稱爲刪失數據 (censored)。刪失數據又根據其發生原因的不同被分爲下面幾種:</p>
<ol style="list-style-type: decimal">
<li><strong>行政刪失 (administrative censoring)</strong>: 如果最終事件，被定義爲死亡的話，研究者不大可能等到所有的觀察對象都死亡 (可能耗時幾十年) 之後再分析數據，而是認爲地定義某個時間點作爲研究結束，不再隨訪的時間。</li>
<li><strong>隨訪失敗 (loss to follow-up)</strong>: 無論是幹預型實驗，還是觀察性實驗，有些觀察對象中途無法聯系上，或者改變主義推出實驗的人並不少見。這些對象的出現都意味着研究者無法再對他們進行事件發生與否的觀察了。</li>
<li><strong>死於其他原因 (death from other causes)</strong>: 可能某些研究只關心患者吸煙習慣與死於肺癌的時間長短的關系，當某些觀察對象確實發生了死亡事件，但是死因並不是肺癌時 (肝癌，或者自殺，車禍等)，這些人也被認爲是刪失數據。</li>
</ol>
<p>上述幾種可能發生的刪失數據，這幾種類型的刪失數據，被叫做<strong>右側刪失數據 (right censoring)，在分析中不能被刪除，因爲他們在未離開研究之前，我們確定他們是沒有發生事件的，他們的觀察時間也應當被放入統計模型中加以考慮。</strong></p>
<div id="左側截尾數據-left-truncation" class="section level3">
<h3><span class="header-section-number">71.4.1</span> 左側截尾數據 left-truncation</h3>
<p>左側截尾現象，又被叫做<strong>延時進入 (delayed entry)</strong>: 由於觀察對象實際進入研究時的年齡各不相同，對所有人的觀察時間，都從出生日開始算起的研究，實施難度極大。此時，應當注意把進入研究之前的生存時間 (進入實驗時的年齡)，考慮進來，因爲這些人至少活到了進入研究的年齡。這也是一種生存偏倚現象，因爲人羣中被觀察到的人，只是一小部分樣本，所以把所有人都當作相同概率進入研究是不恰當的，有許多對象沒有活到進入研究的時間。</p>
</div>
</div>
<div id="初步分析生存數據" class="section level2">
<h2><span class="header-section-number">71.5</span> 初步分析生存數據</h2>
<p>生存數據，比較的是生存時間。由於時間本身是連續型變量，我們可能會想到利用處理連續型變量時的方法來進行初步的比較:</p>
<ol style="list-style-type: decimal">
<li>每個人生存時間的柱狀圖 (histogram);</li>
<li>計算生存時間的簡單統計量: 中位數 (median)。</li>
</ol>
<p>即使是拿穩健統計學方法比較治療組和對照組的中位數是否不同，也無法解決刪失數據的問題。我們需要新的方法來處理生存數據。</p>
</div>
<div id="初步描述生存數據" class="section level2">
<h2><span class="header-section-number">71.6</span> 初步描述生存數據</h2>
<p>描述生存數據的統計學正式方案是:</p>
<ol style="list-style-type: decimal">
<li>生存方程 the survival function</li>
<li>風險度方程和累積風險度 the hazard function and the cumulative hazard</li>
<li>概率密度方程 the probability density function</li>
</ol>
<div id="生存方程" class="section level3">
<h3><span class="header-section-number">71.6.1</span> 生存方程</h3>
<p>生存方程的定義是，觀測生存時間 <span class="math inline">\(T\)</span>，大於某個時間 <span class="math inline">\(t\)</span> 的概率:</p>
<p><span class="math display">\[
S(t) = \text{Pr}(T &gt; t)
\]</span></p>
<p>累計概率方程是</p>
<p><span class="math display">\[
F(t) = \text{Pr}(T \leqslant t) = 1 - S(t)
\]</span></p>
</div>
<div id="風險度方程" class="section level3">
<h3><span class="header-section-number">71.6.2</span> 風險度方程</h3>
<p>風險度有時候就只叫做風險 (hazard)，時間 <span class="math inline">\(t\)</span> 時的風險度爲 <span class="math inline">\(h(t)\)</span>。風險度方程被定義爲:</p>
<p><span class="math display">\[
h(t) = \lim_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t\leqslant T &lt; t + \delta | T\geqslant t)
\]</span></p>
<p>風險度利用的是數學中的極限理論，表示在時間 <span class="math inline">\(t\)</span> 和時間 <span class="math inline">\(t+\delta\)</span> (其中<span class="math inline">\(\delta \rightarrow 0\)</span>) 之間，觀察對象沒有發生事件的概率。風險度的概念明白了以後，風險度在時間軸上的積分，就被叫做<strong>累積風險度</strong>:</p>
<p><span class="math display">\[
H(t) = \int_0^th(u)\text{d}u
\]</span></p>
</div>
<div id="概率密度方程" class="section level3">
<h3><span class="header-section-number">71.6.3</span> 概率密度方程</h3>
<p>和其他的方程類似，常用 <span class="math inline">\(f(t)\)</span> 標記生存時間的概率密度方程:</p>
<p><span class="math display">\[
f(t) = \frac{\text{d}}{\text{d}t}F(t) = \lim_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t\leqslant T &lt; t + \delta)
\]</span></p>
</div>
<div id="各方程之間的關系" class="section level3">
<h3><span class="header-section-number">71.6.4</span> 各方程之間的關系</h3>
<p><span class="math display">\[
\begin{aligned}
f(t) &amp; = \frac{\text{d}}{\text{d}t}F(t)  = \frac{\text{d}}{\text{d}t}\{ 1-S(t) \} = - \frac{\text{d}}{\text{d}t}S(t) \\
S(t) &amp; = 1 - F(t)  = 1 - \int_0^t f(u)\text{d}u = \int_t^\infty f(u)\text{d}u \\
h(t) &amp; = \lim_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t \leqslant T &lt; t+ \delta | T &gt; t) \\
     &amp; = \lim_{\delta\rightarrow0}\frac{1}{\delta}\frac{\text{Pr}(t \leqslant T &lt; t+ \delta, T &gt; t)}{\text{Pr}(T &gt; t)} (\text{Bayes&#39; Theroem}) \\
     &amp; = \lim_{\delta\rightarrow0}\frac{1}{\delta}\frac{\text{Pr}(t \leqslant T &lt; t+ \delta)}{\text{Pr}(T &gt; t)} \\
     &amp; = \frac{f(t)}{S(t)} \\
h(t) &amp; = \frac{f(t)}{S(t)} = \frac{\frac{\text{d}}{\text{d}t}F(t)}{S(t)} = \frac{- \frac{\text{d}}{\text{d}t}S(t)}{S(t)} = - \frac{\text{d}}{\text{d}t}\text{log}[S(t)] \\
\end{aligned}
\]</span></p>
<p><strong>推導</strong> <span class="math inline">\(S(t), H(t)\)</span> 之間的關系:</p>
<p><span class="math display">\[
\begin{aligned}
\because h(t) &amp; = - \frac{\text{d}}{\text{d}t}\text{log}[S(t)] \\
\text{intergrate both} &amp; \text{ sides over the range from 0 to }t: \\
\int_0^th(u)\text{d}u &amp; = - \int_0^t\frac{\text{d}}{\text{d}u}\text{log}[S(t)]\text{d}u \\
                      &amp; = -[\text{log } S(u)]_{u = 0}^{u = t} \\
                      &amp; = -[\text{log } S(t) - \text{log } S(0)] \\
                      &amp; = -\text{log }S(t) \\
\Rightarrow S(t)      &amp; = \exp\{ - \int_0^th(u)\text{d}u\} = \exp\{ -H(t) \}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="生存時間的參數分布" class="section level2">
<h2><span class="header-section-number">71.7</span> 生存時間的參數分布</h2>
<div id="指數分布" class="section level3">
<h3><span class="header-section-number">71.7.1</span> 指數分布</h3>
<p>適用於生存時間最簡單的分布是指數分布 (exponentiential distribution)。指數分布默認風險率 (hazard rate，<span class="math inline">\(\lambda\)</span>) 不隨時間變化。在指數分布中，風險度方程，生存方程和概率密度方程分別是:</p>
<p><span class="math display" id="eq:survival01-11">\[
\begin{aligned}
h(t) &amp; = \lambda, \\
S(t) &amp; = e^{-\lambda t} \\
f(t) &amp; = h(t)S(t) \\
     &amp; = \lambda e^{-\lambda t}
\end{aligned}
\tag{71.1}
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:Surv-fig1-4"></span>
<img src="img/Selection_117.png" alt="The hazard function, survivor function and probability density function under an exponential distribution for survival times" width="90%" />
<p class="caption">
圖 71.1: The hazard function, survivor function and probability density function under an exponential distribution for survival times
</p>
</div>
</div>
<div id="weibull-分布" class="section level3">
<h3><span class="header-section-number">71.7.2</span> Weibull 分布</h3>
<p>指數分布的前提 – 事件發生率相同的假設過於強硬，許多真實數據，都不能滿足這個前提條件。另一個比指數分布靈活的分布是 Weibull 分布。它包含兩個參數，其風險度方程，生存方程和概率密度方程分別是:</p>
<p><span class="math display" id="eq:survival01-12">\[
\begin{aligned}
h(t) &amp; = \kappa\lambda t^{\kappa - 1}  \\
S(t) &amp; = \exp(-\lambda t^\kappa) \\
f(t) &amp; = \kappa \lambda t^{\kappa - 1} \exp(-\lambda t^\kappa)
\end{aligned}
\tag{71.2}
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:Surv-fig1-6"></span>
<img src="img/Selection_118.png" alt="Illustrations of the hazard function under a Weibull distribution with different shape (kappa) and scale (lambda)." width="90%" />
<p class="caption">
圖 71.2: Illustrations of the hazard function under a Weibull distribution with different shape (kappa) and scale (lambda).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:Surv-fig1-7"></span>
<img src="img/Selection_119.png" alt="Illustrations of the survival function and probability function under a Weibull distribution with different shape (kappa) and scale parameter lambda = 0.2." width="90%" />
<p class="caption">
圖 71.3: Illustrations of the survival function and probability function under a Weibull distribution with different shape (kappa) and scale parameter lambda = 0.2.
</p>
</div>
<p>當 <span class="math inline">\(\kappa = 1\)</span> 時，Weibull 分布就降級爲簡單指數分布。從圖中也可以看出，<strong>Weibull 分布只允許風險度隨着時間單調遞增/遞減</strong>。</p>
<p>除了這兩個常見的生存時間分布，另外還有許多不同類型的分布。練習題中也會再探索 log-logistic 分布的應用。</p>
</div>
</div>
<div id="極大似然法估計" class="section level2">
<h2><span class="header-section-number">71.8</span> 極大似然法估計</h2>
<p>假設，我們決定使用上面描述的簡單分布 - 指數分布來做爲生存時間的分布。接下來，就可以利用學習過的統計推斷的知識，對其做極大似然估計。</p>
<p>假設 <span class="math inline">\(n\)</span> 名研究對象編號各自爲 <span class="math inline">\(i = 1, \cdots,n\)</span>，研究者對他們完成了從起點時間 (time origin) 起的隨訪。有些人發生了相關事件 (Event)，所以，他們的生存時間 <span class="math inline">\(t_{E_i}\)</span>。有些人則由於各種原因變成了刪失值，他們的生存時間是 <span class="math inline">\(t_{C_i}\)</span>。關於刪失對象我們確切知道在時間 <span class="math inline">\(t_{C_i}\)</span> 之內，他們沒有發生相關事件，且他們退出研究之後是否發生了事件不得而知。我們再根據觀察對象是否發生相關事件，在模型中生成一個啞變量 <span class="math inline">\(\delta_i\)</span>，當 <span class="math inline">\(\delta_i = 1\)</span> 時，該對象的觀察生存時間是 <span class="math inline">\(t_{E_i}\)</span>，當 <span class="math inline">\(\delta_i = 0\)</span> 時，該對象的觀察生存時間就是 <span class="math inline">\(t_{C_i}\)</span>:</p>
<p><span class="math display">\[
\delta_{i}=\left\{ \begin{array}{ll}
1 \text{ if } t_{E_i} \text{ observed} \\
0 \text{ if }  t_{C_i} \text{ observed}\\ \end{array} \right.
t_{i}=\left\{ \begin{array}{ll}
t_{E_i} \text{ if } \delta_i = 1 \\
t_{C_i} \text{ if } \delta_i = 0 \\ \end{array} \right.
\]</span></p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 71.1: Data on survival and censoring times for n individuals
</caption>
<thead>
<tr>
<th style="text-align:left;">
Individual
</th>
<th style="text-align:left;">
Survival or censoring time
</th>
<th style="text-align:left;">
Indicator of outcome or censoring
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(t_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\delta_1\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(t_2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\delta_2\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(t_3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\delta_3\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
</tr>
<tr>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
</tr>
<tr>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
<td style="text-align:left;">
.
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(n\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(t_n\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\delta_n\)</span>
</td>
</tr>
</tbody>
</table>
<p>對於那些觀察到事件的人，他們各自對似然的貢獻是 <span class="math inline">\(f(t_{E_i})\)</span>; 對於那些成爲刪失值的人，他們各自對似然的貢獻是 <span class="math inline">\(S(t_{C_i})\)</span>，所以該數據的似然就是:</p>
<p><span class="math display">\[
\begin{aligned}
L &amp; = \prod_{\text{Events}}f(t_{E_i})\prod_{\text{Censorings}}S(t_{C_i}) \\
  &amp; = \prod_i f(t_i)^{\delta_i} S(t_i)^{1-\delta_i} \\
  &amp; = \prod_i \{ h(t_i)S(t_i) \}^{\delta_i}S(t_i)^{1-\delta_i} \text{ because } h(t) = \frac{f(t)}{S(t)} \\
  &amp; = \prod_i h(t_i)^{\delta_i} S(t_i)
\end{aligned}
\]</span></p>
<p>極大似然法對各個參數的估計就可以用我們在統計推斷中使用的求對數極大似然的方法:</p>
<p><span class="math display">\[
\begin{aligned}
\ell &amp; = \sum_i[\delta_i\text{log}f(t_i) + (1-\delta_i)\text{log}S(t_i)] \\
     &amp; = \sum_i\{\delta_i\text{log}(\lambda e^{-\lambda t_i}) + (1-\delta_i)\text{log}(e^{-\lambda t_i}) \} \\
     &amp; = \sum_i\{ \delta_i\text{log}\lambda - \delta_i\lambda t_i -\lambda t_i + \delta_i\lambda t_i \} \\
     &amp; = \sum_i[\delta_i \text{log}\lambda - \lambda t_i] \\
     &amp; = \sum_i\delta_i\text{log}\lambda - \lambda\sum_it_i \\
\Rightarrow \ell^\prime &amp; = \frac{\sum_i\delta_i}{\lambda} - \sum_i t_i \\
\text{let } \ell^\prime &amp; =0 \Rightarrow \hat\lambda = \frac{\sum_i\delta_i}{\sum_i t_i}\\
\text{Because }\ell^{\prime\prime} &amp; = -\frac{\sum_i\delta_i}{\lambda^2} &lt; 0 \\
\text{Therefore } \hat\lambda &amp; = \frac{\sum_i\delta_i}{\sum_it_i} \\
\text{ is the MLE for} &amp; \text{  survival time follows exponential distribution.}
\end{aligned}
\]</span></p>
</div>
<div id="practical-survival-01" class="section level2">
<h2><span class="header-section-number">71.9</span> Practical Survival 01</h2>
<div id="生存分析的時間尺度" class="section level3">
<h3><span class="header-section-number">71.9.1</span> 生存分析的時間尺度</h3>
<div id="把-pbc-數據讀入-r-中d-time-datein-dateout-是什麼含義" class="section level4">
<h4><span class="header-section-number">71.9.1.1</span> 把 PBC 數據讀入 R 中，<code>d, time, datein, dateout</code> 是什麼含義？</h4>
<div class="sourceCode" id="cb1022"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1022-1" title="1">pbcbase &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pbcbase.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1022-2" title="2"><span class="co"># d 是表示是否發神事件的變量</span></a>
<a class="sourceLine" id="cb1022-3" title="3"><span class="co"># d = 0 表示該觀察對象是刪失值</span></a>
<a class="sourceLine" id="cb1022-4" title="4"><span class="co"># d = 1 表示該觀察對象在研究隨訪中死亡</span></a>
<a class="sourceLine" id="cb1022-5" title="5"></a>
<a class="sourceLine" id="cb1022-6" title="6"><span class="co"># datein 是該觀察對象進入臨牀試驗的日期</span></a>
<a class="sourceLine" id="cb1022-7" title="7"><span class="co"># dateout 是該觀察對象發生死亡事件/變成刪失值的日期</span></a>
<a class="sourceLine" id="cb1022-8" title="8"></a>
<a class="sourceLine" id="cb1022-9" title="9"><span class="co"># time 是從進入臨牀試驗到發生死亡時間或者變成刪失值這段時間的長度，以年爲單位</span></a>
<a class="sourceLine" id="cb1022-10" title="10"></a>
<a class="sourceLine" id="cb1022-11" title="11"><span class="kw">head</span>(pbcbase[,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])</a></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##      id datein     dateout     time     d
##   &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1     5 1980-02-19 1981-09-19  1.58     1
## 2    22 1980-08-22 1980-08-22  0        0
## 3    23 1980-07-22 1989-08-02  9.03     0
## 4    40 1980-08-08 1982-11-21  2.29     1
## 5    42 1980-09-06 1982-10-05  2.08     1
## 6    45 1980-02-09 1985-06-02  5.31     1</code></pre>
</div>
<div id="你認爲該研究應該使用哪種時間尺度" class="section level4">
<h4><span class="header-section-number">71.9.1.2</span> 你認爲該研究應該使用哪種時間尺度？</h4>
<p>這是一個比較兩種治療方案哪個更能延長患者生命時間的臨牀實驗，正確的時間尺度應該是從進入試驗開始，直至發生事件 (死亡) 或者離開試驗的這段時間 (隨訪時間 follow-up time)。</p>
</div>
<div id="試驗中多少患者發生了死亡事件又有多少患者是刪失值" class="section level4">
<h4><span class="header-section-number">71.9.1.3</span> 試驗中，多少患者發生了死亡事件，又有多少患者是刪失值？</h4>
<div class="sourceCode" id="cb1024"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1024-1" title="1"><span class="co"># 患者中 96 人 (50.3%) 發生了死亡事件; 95 人是刪失值。</span></a>
<a class="sourceLine" id="cb1024-2" title="2"><span class="kw">with</span>(pbcbase, <span class="kw">tab1</span>(d, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## d : 
##         Frequency Percent Cum. percent
## 0              95    49.7         49.7
## 1              96    50.3        100.0
##   Total       191   100.0        100.0</code></pre>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1026-1" title="1"><span class="co"># 第一例死亡發生在隨訪開始的 0.025 年，最後一例死亡發生在隨訪開始的 9.26 年;</span></a>
<a class="sourceLine" id="cb1026-2" title="2"><span class="co"># 所有對象中隨訪時間最長達到 11.64 年。</span></a>
<a class="sourceLine" id="cb1026-3" title="3"><span class="co"># 死亡事件發生的病例中，隨訪時間的中位數是 2.85 年</span></a>
<a class="sourceLine" id="cb1026-4" title="4"><span class="co"># 刪失對象的病例中，隨訪時間的中位數是 4.62 年。</span></a>
<a class="sourceLine" id="cb1026-5" title="5"><span class="kw">with</span>(pbcbase, <span class="kw">summ</span>(time[d<span class="op">==</span><span class="dv">1</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  96   3.243  2.847   2.357  0.025  9.259</code></pre>
<div class="sourceCode" id="cb1028"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1028-1" title="1"><span class="kw">with</span>(pbcbase, <span class="kw">summ</span>(time[d<span class="op">==</span><span class="dv">0</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  95   4.587  4.616   3.052  0      11.644</code></pre>
</div>
<div id="讀入另一個數據-whitehall.csv使用是否發生冠心病-chd-變量作爲事件變量仔細觀察其時間的格式timein-timeout-timebth各自是什麼含義1987-年-1-月-30-日發生了什麼事件" class="section level4">
<h4><span class="header-section-number">71.9.1.4</span> 讀入另一個數據 <code>whitehall.csv</code>，使用是否發生冠心病 <code>chd</code> 變量作爲事件變量。仔細觀察其時間的格式，<code>timein, timeout, timebth</code>，各自是什麼含義？1987 年 1 月 30 日發生了什麼事件？</h4>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1030-1" title="1">whitehall &lt;-<span class="st">  </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/whitehall.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1030-2" title="2"><span class="co"># timebth 是每個患者的出生日期</span></a>
<a class="sourceLine" id="cb1030-3" title="3"><span class="co"># timein  是每個患者進入試驗的日期，且注意到許多患者的進入試驗日期是相同的</span></a>
<a class="sourceLine" id="cb1030-4" title="4"><span class="co"># timeout 是隨訪結束的日期，對於 chd = 1 的人，這個日期是其死於冠心病的日期，</span></a>
<a class="sourceLine" id="cb1030-5" title="5"><span class="co"># 其餘的人則是刪失日期，且注意到許多刪失日期都是1987年1月30日，推測這是行政刪失日期。</span></a>
<a class="sourceLine" id="cb1030-6" title="6">whitehall[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">12</span><span class="op">:</span><span class="dv">14</span>)]</a></code></pre></div>
<pre><code>## # A tibble: 1,677 x 5
##       id   chd timein     timeout    timebth   
##    &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    
##  1  5001     0 1967-09-13 1987-01-30 1920-03-20
##  2  5019     0 1967-09-13 1987-01-30 1911-08-06
##  3  5038     0 1967-09-13 1987-01-30 1916-04-03
##  4  5039     0 1967-09-13 1987-01-30 1916-08-02
##  5  5042     0 1967-09-13 1983-04-12 1912-03-20
##  6  5052     0 1967-09-13 1984-07-10 1913-04-07
##  7  5064     0 1967-09-15 1984-05-13 1921-04-30
##  8  5078     1 1967-09-15 1983-11-29 1919-12-25
##  9  5089     0 1967-09-15 1987-01-30 1919-10-11
## 10  5090     0 1967-09-15 1987-01-30 1908-03-31
## # ... with 1,667 more rows</code></pre>
</div>
<div id="應該使用哪種時間尺度作爲此研究的時間呢" class="section level4">
<h4><span class="header-section-number">71.9.1.5</span> 應該使用哪種時間尺度作爲此研究的時間呢？</h4>
<p>很顯然，本實驗可以使用隨訪時間，作爲時間尺度。當然，考慮到不同的人進入實驗時的年齡不同，也可以用隨訪年齡作爲時間尺度。需要注意的是，如果使用年齡作爲時間尺度，不能使用 <code>timeout - timebth</code> 也就是隨訪結束減去出生日期作爲時間變量。因爲這樣的做法默認了所有人從出生時，就進入了實驗，這是無論如何也無法做到的。所以我們要用下面的第二個計算時間的代碼 <code>M1</code>，來考慮進入實驗時的年齡。因爲，進入實驗時，該觀察對象沒有發生事件，這已經是一個生存偏倚，需要告訴軟件加以考慮。注意比較三種方法計算的時間的最小值最大值的差別。</p>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1032-1" title="1"><span class="co"># 用隨訪時間做時間尺度</span></a>
<a class="sourceLine" id="cb1032-2" title="2">M0 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(<span class="dt">time =</span> (timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd)<span class="op">~</span><span class="dv">1</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1032-3" title="3"><span class="kw">summ</span>(M0<span class="op">$</span>time, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  702  13.96  16.678  5.307  0.151  19.381</code></pre>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1034-1" title="1"><span class="co"># 考慮了左側截尾的時間尺度</span></a>
<a class="sourceLine" id="cb1034-2" title="2">M1 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(agein, agein <span class="op">+</span><span class="st"> </span>(timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1034-3" title="3"><span class="kw">summ</span>(M1<span class="op">$</span>time, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  1670 68.568 67.888  6.582  44.391 85.766</code></pre>
<div class="sourceCode" id="cb1036"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1036-1" title="1"><span class="co"># 錯誤地認爲所有人都從出生日期開始進入試驗的時間尺度</span></a>
<a class="sourceLine" id="cb1036-2" title="2">M2 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>((timeout <span class="op">-</span><span class="st"> </span>timebth)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1036-3" title="3"><span class="kw">summ</span>(M2<span class="op">$</span>time, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  1563 68.638 67.986  6.651  44.391 85.766</code></pre>
</div>
</div>
<div id="擬合最簡單的指數分布生存數據" class="section level3">
<h3><span class="header-section-number">71.9.2</span> 擬合最簡單的指數分布生存數據</h3>
<div class="sourceCode" id="cb1038"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1038-1" title="1">mydata &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;backupfiles/surv_data_practical1.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1038-2" title="2">mydata</a></code></pre></div>
<pre><code>## # A tibble: 100 x 1
##    surv.times
##         &lt;dbl&gt;
##  1      0.442
##  2      2.01 
##  3      2.26 
##  4      1.64 
##  5      9.88 
##  6      1.19 
##  7      3.72 
##  8      7.14 
##  9     11.3  
## 10      6.69 
## # ... with 90 more rows</code></pre>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1040-1" title="1">exp.model &lt;-<span class="st"> </span><span class="kw">survreg</span>(<span class="kw">Surv</span>(surv.times) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">dist =</span> <span class="st">&quot;exponential&quot;</span>, <span class="dt">data =</span> mydata)</a>
<a class="sourceLine" id="cb1040-2" title="2"><span class="co"># 值得注意的是，在 R 裏擬合指數分布的生存數據時，計算獲得的是 -log(lambda)</span></a>
<a class="sourceLine" id="cb1040-3" title="3"><span class="kw">summary</span>(exp.model)</a></code></pre></div>
<pre><code>## 
## Call:
## survreg(formula = Surv(surv.times) ~ 1, data = mydata, dist = &quot;exponential&quot;)
##             Value Std. Error     z      p
## (Intercept) 1.527      0.100 15.27 &lt;2e-16
## 
## Scale fixed at 1 
## 
## Exponential distribution
## Loglik(model)= -252.7   Loglik(intercept only)= -252.7
## Number of Newton-Raphson Iterations: 5 
## n= 100</code></pre>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1042-1" title="1"><span class="co"># 風險度比 HR</span></a>
<a class="sourceLine" id="cb1042-2" title="2"><span class="kw">exp</span>(<span class="op">-</span>exp.model<span class="op">$</span>coefficients)</a></code></pre></div>
<pre><code>## (Intercept) 
##  0.21727013</code></pre>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1044-1" title="1"><span class="co"># HR 的 95% 信賴區間</span></a>
<a class="sourceLine" id="cb1044-2" title="2"><span class="kw">exp</span>(<span class="op">-</span>exp.model<span class="op">$</span>coefficients <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">summary</span>(exp.model)<span class="op">$</span>table[<span class="dv">2</span>])</a></code></pre></div>
<pre><code>## (Intercept) 
##   0.1785987</code></pre>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1046-1" title="1"><span class="kw">exp</span>(<span class="op">-</span>exp.model<span class="op">$</span>coefficients <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span><span class="kw">summary</span>(exp.model)<span class="op">$</span>table[<span class="dv">2</span>])</a></code></pre></div>
<pre><code>## (Intercept) 
##  0.26431495</code></pre>
</div>
<div id="探索服從-weibull-分布時風險度方程的曲線" class="section level3">
<h3><span class="header-section-number">71.9.3</span> 探索服從 Weibull 分布時風險度方程的曲線</h3>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1048-1" title="1">wei.haz &lt;-<span class="st"> </span><span class="cf">function</span>(x, lambda, kappa) {</a>
<a class="sourceLine" id="cb1048-2" title="2">  kappa<span class="op">*</span>lambda<span class="op">*</span>x<span class="op">^</span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1048-3" title="3">}</a>
<a class="sourceLine" id="cb1048-4" title="4"><span class="kw">curve</span>(<span class="kw">wei.haz</span>(x, <span class="fl">0.2</span>, <span class="fl">0.5</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.8</span>), <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Hazard function&quot;</span>)</a>
<a class="sourceLine" id="cb1048-5" title="5"><span class="kw">curve</span>(<span class="kw">wei.haz</span>(x, <span class="fl">0.2</span>, <span class="fl">1.5</span>), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb1048-6" title="6"><span class="kw">curve</span>(<span class="kw">wei.haz</span>(x, <span class="fl">0.2</span>, <span class="dv">1</span>), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1048-7" title="7"><span class="kw">curve</span>(<span class="kw">wei.haz</span>(x, <span class="fl">0.2</span>, <span class="dv">2</span>), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1048-8" title="8"><span class="kw">curve</span>(<span class="kw">wei.haz</span>(x, <span class="fl">0.2</span>, <span class="dv">5</span>), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:SurvPrac01-06"></span>
<img src="bookdown_files/figure-html/SurvPrac01-06-1.png" alt="Illustrations of the hazard function under a Weibull distribution with lambda = 0.2, and different shape (kappa)" width="80%" />
<p class="caption">
圖 71.4: Illustrations of the hazard function under a Weibull distribution with lambda = 0.2, and different shape (kappa)
</p>
</div>
<p>在 Weibull 分布下，參數 <span class="math inline">\(\kappa\)</span> 決定了風險度曲線的形狀。 <span class="math inline">\(\kappa &lt; 1\)</span> 時，風險度隨着時間下降，<span class="math inline">\(\kappa &gt; 1\)</span> 時，風險度隨着時間上升。當 <span class="math inline">\(\kappa = 1\)</span> 時，Weibull 分布降級爲簡單的指數分布 (圖中點狀直線)。當 <span class="math inline">\(\kappa = 2\)</span> 時，風險度和時間成線性關系。</p>
</div>
<div id="探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性" class="section level3">
<h3><span class="header-section-number">71.9.4</span> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</h3>
<p><span class="math display">\[
h(t) = \frac{e^\theta \kappa t^{\kappa -1}}{1 + e^\theta t^\kappa}
\]</span></p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1049-1" title="1">loglog.haz &lt;-<span class="st"> </span><span class="cf">function</span>(x, theta, kappa) {</a>
<a class="sourceLine" id="cb1049-2" title="2">  <span class="kw">exp</span>(theta)<span class="op">*</span>kappa<span class="op">*</span>x<span class="op">^</span>(kappa <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(theta)<span class="op">*</span>x<span class="op">^</span>kappa)</a>
<a class="sourceLine" id="cb1049-3" title="3">}</a>
<a class="sourceLine" id="cb1049-4" title="4"></a>
<a class="sourceLine" id="cb1049-5" title="5"><span class="kw">curve</span>(<span class="kw">loglog.haz</span>(x, <span class="dv">1</span>, <span class="fl">0.2</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Hazard function&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1049-6" title="6"><span class="kw">curve</span>(<span class="kw">loglog.haz</span>(x, <span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">add =</span> T, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb1049-7" title="7"><span class="kw">curve</span>(<span class="kw">loglog.haz</span>(x, <span class="dv">3</span>, <span class="dv">2</span>), <span class="dt">add =</span> T, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:SurvPrac01-07"></span>
<img src="bookdown_files/figure-html/SurvPrac01-07-1.png" alt="Illustrations of the hazard function under a log-logistic distribution with different theta, and different shape (kappa)" width="80%" />
<p class="caption">
圖 71.5: Illustrations of the hazard function under a log-logistic distribution with different theta, and different shape (kappa)
</p>
</div>
<p>在 Weibull 分布下，風險度只能隨着時間單調遞增或者遞減。但是，在對數邏輯分布下，風險度就可以跟隨時間有增有減。</p>
</div>
</div>
</div>
<div id="nonparametric" class="section level1">
<h1><span class="header-section-number">第 72 章</span> 非參數法分析生存數據</h1>
<div id="生存分析中的非參數分析法" class="section level2">
<h2><span class="header-section-number">72.1</span> 生存分析中的非參數分析法</h2>
<p>非參數法分析生存數據其實是所有人在分析生存數據時應該着手做的第一件事。</p>
<ul>
<li>非參數法可以對生存時間不必進行任何參數分布 (parametric assumption) 的假設，初步地估計生存方程和累積風險度方程;</li>
<li>使用非參數法可以用生存曲線圖的方式直觀地展示生存數據，包括刪失值在數據中的存在也可以通過圖表來表現出來;</li>
<li>非參數法可以初步地對不同組/羣之間生存曲線的變化進行比較;</li>
<li>通過非參數法對生存數據進行初步分析之後，可以對接下來的生存數據建模過程提供有參考價值的背景信息。</li>
</ul>
</div>
<div id="kaplan-meier-法分析生存方程" class="section level2">
<h2><span class="header-section-number">72.2</span> Kaplan-Meier 法分析生存方程</h2>
<div id="當數據中沒有刪失值" class="section level3">
<h3><span class="header-section-number">72.2.1</span> 當數據中沒有刪失值</h3>
<p>如果，研究對象裏的每個人都發生了事件，那麼研究對象裏的每個人身上都觀察到了生存時間，自然而然地特定時間 <span class="math inline">\(t\)</span> 時的生存方程是:</p>
<p><span class="math display">\[
\hat{S}(t) = \frac{\text{number of individuals with survival time} &gt; t}{\text{total number of individuals}}
\]</span></p>
<p>在每個觀察到事件的時間點 <span class="math inline">\(t_1 &lt; t_2 &lt; t_3 &lt; \cdots &lt; t_K\)</span>，我們可以計算該時間點的生存方程，然後假定兩個事件的時間點之間的生存概率保持不變，就可以繪制出一個階梯形狀的生存曲線。</p>
</div>
<div id="當數據中有刪失值" class="section level3">
<h3><span class="header-section-number">72.2.2</span> 當數據中有刪失值</h3>
<p>前一小節提到的非參數法繪制生存時間曲線的方法，其實完全可以拓展到含有刪失值的生存數據中。同樣地，用 <span class="math inline">\(t_1 &lt; t_2 &lt; t_3 &lt; \cdots &lt; t_K\)</span> 表示<strong>發生事件的觀察對象的生存時間</strong>。我們可以用以下的步驟來拓展生存時間曲線的繪制思路:</p>
<ol style="list-style-type: decimal">
<li>首先定義 <span class="math inline">\(h_j\)</span> 作爲時間 <span class="math inline">\(t_j\)</span> 時期的風險率 (hazard rate)，那麼每個發生事件的對象的風險和生存時間就有了各自的關聯 <span class="math inline">\(h_1, h_2, \cdots, h_k\)</span>;</li>
<li>在時間點 <span class="math inline">\(t_1\)</span> 時，隊列中的全部對象中，沒有發生事件的概率是 <span class="math inline">\(1-h_1\)</span>;</li>
<li>在時間點 <span class="math inline">\(t_2\)</span> 時，隊列中的全部對象中，在時間 <span class="math inline">\(t_1, t_2\)</span> 時都沒有發生事件的概率是 <span class="math inline">\((1-h_1)(1-h_2)\)</span>;</li>
<li>所以，生存方程就是，任何一個人，在任何一個時間點，在隊列中，且不發生事件的概率 <span class="math display">\[S(t_j) = \prod_{k=1}^j(1-h_k)\]</span></li>
</ol>
<p>此時，每個時間點風險度方程的無偏估計爲，該時間點中在隊列中發生事件的人數 <span class="math inline">\(d_j\)</span> 除以當時在隊列中的人數 <span class="math inline">\(n_j\)</span>:</p>
<p><span class="math display">\[
\hat h_j  = \frac{d_j}{n_j}
\]</span></p>
<p>用上面的這些初步結果，可以推導出在時間點 <span class="math inline">\(t_j\)</span> 時，隊列中的生存方程是:</p>
<p><span class="math display">\[
\hat S(t_j) = \prod_{k=1}^j (1-\hat h_k) = \prod_{k=1}^j ( 1- \frac{d_k}{n_k})
\]</span></p>
<p>它的更加一般化形式就是我們常常念叨的那個<strong>生存方程的 Kaplan-Meier 估計量</strong>，它的別名是 “the product limit estimate”:</p>
<p><span class="math display" id="eq:surv-2-6">\[
\begin{equation}
\hat S(t) = \prod_{j|t_j \leqslant t} (1 - \frac{d_j}{n_j})
\end{equation}
\tag{72.1}
\]</span></p>
<p><strong>例子:</strong> 下表羅列了某個白血病患者治療組生存數據的 Kaplan-Meier 生存方程估計和他們的計算過程，其中值得注意的是，如果生存表格中某時間點 (年或月或日，取決於你的研究使用的時間刻度) 同時有事件 (event) 和刪失 (censoring)，習慣上是默認刪失發生在事件發生之前:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 72.1: Time to remission for leukaemia patients in the treatment group: Kaplan-Meier estimates of the survivor function
</caption>
<thead>
<tr>
<th style="text-align:left;">
Survival time <span class="math inline">\((t_j)\)</span> and censoring time
</th>
<th style="text-align:left;">
Number at risk
</th>
<th style="text-align:left;">
Number of events
</th>
<th style="text-align:left;">
Number of censorings
</th>
<th style="text-align:left;">
<span class="math inline">\(\hat{S}(t_j)\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
21
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
(1-3/21) = 0.857
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
17
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
(1-3/21)(1-1/17) = 0.807
</td>
</tr>
<tr>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
(1-3/21)(1-1/17)(1-1/15) = 0.753
</td>
</tr>
<tr>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
12
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.69
</td>
</tr>
<tr>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.627
</td>
</tr>
<tr>
<td style="text-align:left;">
17
</td>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
19
</td>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
22
</td>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.538
</td>
</tr>
<tr>
<td style="text-align:left;">
23
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
0.448
</td>
</tr>
<tr>
<td style="text-align:left;">
25
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
32
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
–
</td>
</tr>
<tr>
<td style="text-align:left;">
34
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
<tr>
<td style="text-align:left;">
35
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul>
</div>
</div>
<div id="kaplan-meier-數據的不確定性" class="section level2">
<h2><span class="header-section-number">72.3</span> Kaplan-Meier 數據的不確定性</h2>
<p><strong>Greenwood’s 公式的推導:</strong></p>
<p>如何推導獲得生存估計 <span class="math inline">\(\hat{S}(t_j)\)</span> 的方差呢？</p>
<p>利用方程 <a href="#eq:surv-2-6">(72.1)</a> 的對數:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}\{ \text{log}\hat{S}(t) \} &amp; = \text{Var}\{ \text{log}\prod_{j|t_j \leqslant t} (1 - \hat{h}_j)\} \\
                                     &amp; = \text{Var}\{ \sum_{j|t_j \leqslant t} \text{log}(1-\hat{h}_j)\} \\
                                     &amp; = \sum_{j|t_j \leqslant t}\text{Var}\{ \text{log}(1-\hat{h}_j) \}
\end{aligned}
\]</span></p>
<p>接下來利用線性近似原則 (linear approximation)，也就是英国数学家<strong><a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0">泰勒的一次近似泰勒展开法 (first order Taylor series approximation)</a>:</strong></p>
<p><span class="math display" id="eq:surv2-7">\[
\begin{equation}
\text{log} (1-\hat{h}_j) \approx \text{log}(1-h_j) + (\hat{h}_j - h_j)/(1-h_j)
\end{equation}
\tag{72.2}
\]</span></p>
<p>這個近似公式可以讓我們得到其方差爲:</p>
<p><span class="math display">\[
\text{Var}\{ \text{log}(1-\hat{h}_j) \} \approx \frac{\text{Var}(\hat{h}_j)}{(1-h_j)^2}
\]</span></p>
<p>这个就是大名鼎鼎的 <strong><a href="https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html">Delta 法</a></strong>。</p>
<p>接下來需要推導風險 (hazard) <span class="math inline">\(\hat{h}_j\)</span> 的方差，注意，在時間 <span class="math inline">\(t_j\)</span> 時， 事件發生次數 <span class="math inline">\(d_j\)</span> 其實是服從如下的二項分布:</p>
<p><span class="math display">\[
d_j \sim \text{Binomial}(n_j, h_j)
\]</span></p>
<p>所以，</p>
<p><span class="math display">\[
\text{Var}(\hat{h}_j) = \frac{\text{Var}(d_j)}{n_j^2}
\]</span></p>
<p>根據伯努利分布  和二項分布  的性質:</p>
<p><span class="math display">\[
\text{Var}(\hat{h}_j) = \frac{\text{Var}(d_j)}{n_j^2} = \frac{n_jh_j(1-h_j)}{n_j^2} = \frac{h_j(1-h_j)}{n_j}
\]</span></p>
<p>綜上可得:</p>
<p><span class="math display">\[
\text{Var}\{ \text{log}(\hat{S}(t)) \} = \sum_{j|t_j \leqslant t}\frac{h_j}{n_j(1-h_j)}
\]</span></p>
<p>這裏再對 <span class="math inline">\(\log(\hat{S}(t))\)</span> 用一次線性近似:</p>
<p><span class="math display">\[
\log\hat{S}(t) \approx \log S(t) + \frac{\hat{S}(t) - S(t)}{S(t)}
\]</span></p>
<p>所以其實</p>
<p><span class="math display">\[
\text{Var}\{ \log (\hat{S}(t)) \} = \frac{\text{Var}\{ \hat{S}(t) \}}{S(t)^2}
\]</span></p>
<p>最終我們獲得 Greenwood’s 公式:</p>
<p><span class="math display" id="eq:surv2-14">\[
\begin{equation}
\text{Var}\{ \hat{S}(t) \} = \hat{S}(t)^2\sum_{j|t_j \leqslant t}\frac{h_j}{n_j(1-h_j)}
\end{equation}
\tag{72.3}
\]</span></p>
<p>獲得生存方程的方差以後，接下來就是 95% 信賴區間的推導:</p>
<p><span class="math display">\[
\hat{S}(t) \pm 1.96 \sqrt{\text{Var}\{ \hat{S}(t) \}}
\]</span></p>
<p>這裏獲得的 Kaplan-Meier 信賴區間是沒有錯的，但是在某些較爲極端的生存數據中 (時間接近 0, 或者時間接近追蹤結束)，這個公式可能導致計算獲得的信賴區間超過 <span class="math inline">\((0,1)\)</span>。因爲這裏我們假定的是生存概率近似服從正態分布時，才能使用的信賴區間公式。另一個改良版本的區間公式可以避免出現不正常的信賴區間。它需要對生存數據進行數學轉換。常用的生存數據的數學轉換是 <span class="math inline">\(\log\{-\log \hat{S}(t) \}\)</span>。利用上面推導 Greenwood’s 公式 @ref{eq:surv2-14} 時相似的過程，我們可以獲得該轉換過後的方差是:</p>
<p><span class="math display" id="eq:surv2-16">\[
\begin{equation}
\text{Var}\{ \log\{-\log \hat{S}(t)\} \} \approx \frac{\text{Var}\{\log\hat{S}(t) \}}{\{ \log S(t) \}^2}
\end{equation}
\tag{72.4}
\]</span></p>
<p>如果使用 <span class="math inline">\(v^2(t)\)</span> 來標記上式 @ref{eq:surv2-16} 時，有</p>
<p><span class="math display">\[
\begin{aligned}
\log\{- \log \hat{S}(t) \} - 1.96v(t) &amp; &lt; \log\{-\log S(t) \} &lt; \log\{- \log \hat{S}(t) \} + 1.96v(t) \\
\text{Taking the exponential:} &amp; \\
\{ -\log \hat{S}(t) \} \exp(-1.96v(t)) &amp; &lt; -\log S(t) &lt; \{ -\log \hat{S}(t) \} \exp(1.96v(t)) \\
\text{Multiply everything by } &amp; -1: \\
\{ \log \hat{S}(t) \} \exp(1.96v(t)) &amp; &lt; \log S(t) &lt; \{ \log \hat{S}(t) \} \exp(-1.96v(t)) \\
\text{Take the exponential again:} &amp; \\
\hat{S}(t)^{\exp(1.96v(t))} &amp; &lt; S(t) &lt; \hat{S}(t)^{\exp(-1.96v(t))}
\end{aligned}
\]</span></p>
<p>所以，這個校正版本的生存方程信賴區間公式就是:</p>
<p><span class="math display">\[\hat{S}(t)^{\exp\{ \mp1.96 v(t)\}}\]</span></p>
</div>
<div id="另一種非參數法分析-生命表格估計" class="section level2">
<h2><span class="header-section-number">72.4</span> 另一種非參數法分析 – 生命表格估計</h2>
<p>Kaplan-Meier 估計的生存方程過程中，我們假定的是觀察到事件的時間點是間斷的，也就是哪個事件發生在哪個時間點，是可以被精確觀察到的。然而，現實比較骨感的時候，你的數據可能只有生命表格，也就是常見的如一年內本市死亡人口多少多少人這樣，事件發生在某個時間區間內的類型數據。因爲此時無法特定每個死亡人口發生死亡時的確切時間日期。此時可以利用生命表格計算。</p>
<p>我們假定，某個隨訪時間可以被分爲許許多多的時間區間 <span class="math inline">\(I_1, I_2, \cdots, I_K\)</span>，且這些時間區間並不一定需要等距。另外，用 <span class="math inline">\(d_j\)</span> 表示在時間區間 <span class="math inline">\(I_j\)</span> 中發生的事件次數，在該時間段的開始時，有 <span class="math inline">\(n_j\)</span> 個觀察對象 (number of individuals at risk at the start of interval <span class="math inline">\(I_j\)</span>)，其中在下一段時間開始之前，有 <span class="math inline">\(m_j\)</span> 個刪失值。用這些數學標記來表示時間段 <span class="math inline">\(I_j\)</span> 中發生事件的概率 (前提是這 <span class="math inline">\(n_j\)</span> 個觀察對象在時間段 <span class="math inline">\(I_j\)</span> 開始前還沒有發生事件):</p>
<p><span class="math display">\[p_j = \frac{d_j}{n_j - m_j/2}\]</span></p>
<p>分母中使用了 <span class="math inline">\(m_j/2\)</span> 是由於我們無法確定事件發生和刪失值發生的時間在這個時間段 <span class="math inline">\(I_j\)</span> 中是如何分布的，所以我們只能假定他們平均的分布在時間段 <span class="math inline">\(I_j\)</span> 中點的兩側。如此，生命表法計算的生存方程公式就是:</p>
<p><span class="math display">\[
\hat{S}(t) = \prod_{k = 1}^j(1-p_k) \text{ for } t_j \leqslant t &lt; t_{j+1}
\]</span></p>
<p>你可以看出，生命表的推算生存方程，其實和 Kaplan-Meier 法很接近，你同樣可以使用 Greewood’s 的公式 (用 <span class="math inline">\(n_j - m_j/2\)</span> 替換掉 <span class="math inline">\(n_j\)</span> 即可) 獲取生命表生存方程的方差用於計算其信賴區間。</p>

<div class="example">
<span id="exm:11-Survival-analysis-1" class="example"><strong>Example 72.1  </strong></span>心絞痛患者死亡追蹤: 生命表格的制作例子 (選自 <span class="citation">(Belle et al. <a href="#ref-van2004biostatistics" role="doc-biblioref">2004</a>)</span>)。本例子中，2418 名男性心絞痛患者被收入研究中並追蹤其死亡結果，記錄數據中包括患者死亡的日期和患者離開研究的時間。下面的表格是追蹤前十年的數據:
</div>

<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 72.2: Men with angina: Numbers of deaths <span class="math inline">\((d_j)\)</span>, cencorings <span class="math inline">\((m_j)\)</span>, total numbers at risk <span class="math inline">\((n_j)\)</span>, and the life-table estimate of the survivor function by year.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Year
</th>
<th style="text-align:center;">
<span class="math inline">\(n_j\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(d_j\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(m_j\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(p_j\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1-p_j\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\hat S(t)\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0-1
</td>
<td style="text-align:center;">
2418
</td>
<td style="text-align:center;">
456
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
456/2418 = 0.188
</td>
<td style="text-align:center;">
0.812
</td>
<td style="text-align:center;">
0.812
</td>
</tr>
<tr>
<td style="text-align:center;">
1-2
</td>
<td style="text-align:center;">
1962
</td>
<td style="text-align:center;">
226
</td>
<td style="text-align:center;">
39
</td>
<td style="text-align:center;">
226/(1962 - 39/2) = 0.116 </d0>
</td>
<td style="text-align:center;">
0.884
</td>
<td style="text-align:center;">
0.718
</td>
</tr>
<tr>
<td style="text-align:center;">
2-3
</td>
<td style="text-align:center;">
1697
</td>
<td style="text-align:center;">
152
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
152/(1697 - 22/2) = 0.090 </d0>
</td>
<td style="text-align:center;">
0.910
</td>
<td style="text-align:center;">
0.653
</td>
</tr>
<tr>
<td style="text-align:center;">
3-4
</td>
<td style="text-align:center;">
1523
</td>
<td style="text-align:center;">
171
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
171/(1523 - 23/2) = 0.113 </d0>
</td>
<td style="text-align:center;">
0.887
</td>
<td style="text-align:center;">
0.579
</td>
</tr>
<tr>
<td style="text-align:center;">
4-5
</td>
<td style="text-align:center;">
1329
</td>
<td style="text-align:center;">
135
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
135/(1329 - 24/2) = 0.103 </d0>
</td>
<td style="text-align:center;">
0.897
</td>
<td style="text-align:center;">
0.519
</td>
</tr>
<tr>
<td style="text-align:center;">
5-6
</td>
<td style="text-align:center;">
1170
</td>
<td style="text-align:center;">
125
</td>
<td style="text-align:center;">
107
</td>
<td style="text-align:center;">
125/(1170 - 107/2) = 0.112 </d0>
</td>
<td style="text-align:center;">
0.888
</td>
<td style="text-align:center;">
0.461
</td>
</tr>
<tr>
<td style="text-align:center;">
6-7
</td>
<td style="text-align:center;">
938
</td>
<td style="text-align:center;">
83
</td>
<td style="text-align:center;">
133
</td>
<td style="text-align:center;">
83/(938 - 133/2) = 0.095 </d0>
</td>
<td style="text-align:center;">
0.905
</td>
<td style="text-align:center;">
0.417
</td>
</tr>
<tr>
<td style="text-align:center;">
7-8
</td>
<td style="text-align:center;">
722
</td>
<td style="text-align:center;">
74
</td>
<td style="text-align:center;">
102
</td>
<td style="text-align:center;">
74/(722 - 102/2) = 0.110 </d0>
</td>
<td style="text-align:center;">
0.890
</td>
<td style="text-align:center;">
0.371
</td>
</tr>
<tr>
<td style="text-align:center;">
8-9
</td>
<td style="text-align:center;">
546
</td>
<td style="text-align:center;">
51
</td>
<td style="text-align:center;">
68
</td>
<td style="text-align:center;">
51/(546 - 68/2) = 0.100 </d0>
</td>
<td style="text-align:center;">
0.900
</td>
<td style="text-align:center;">
0.334
</td>
</tr>
<tr>
<td style="text-align:center;">
9-10
</td>
<td style="text-align:center;">
427
</td>
<td style="text-align:center;">
42
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:center;">
42/(427 - 64/2) = 0.106 </d0>
</td>
<td style="text-align:center;">
0.894
</td>
<td style="text-align:center;">
0.299
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span id="fig:SurvExample2-3"></span>
<img src="img/Selection_131.png" alt="Men with angina data: Life table estimate of the survivor function." width="90%" />
<p class="caption">
圖 72.1: Men with angina data: Life table estimate of the survivor function.
</p>
</div>
<p>看圖 <a href="#fig:SurvExample2-3">72.1</a> 和上面估計的生存概率估計表格，請回答:</p>
<ol style="list-style-type: decimal">
<li>患者的 5 年以上生存概率是多少？ (51.9% 表格第五行)</li>
<li>患者的 2.5 年以上生存概率是多少？ (71.8% 記住在 2-3 年這段時間內生存概率被假定是不變的)</li>
</ol>
</div>
<div id="兩組之間生存概率的比較" class="section level2">
<h2><span class="header-section-number">72.5</span> 兩組之間生存概率的比較</h2>
<p>本章目前爲止介紹的非參數法可以用於初步地對生存數據中不同組之間生存概率的比較。我們當然可以給不同組的患者/研究對象估計各自的生存曲線 (和信賴區間) 繪圖比較。</p>

<div class="example">
<span id="exm:11-Survival-analysis-2" class="example"><strong>Example 72.2  </strong></span><strong>治療組和對照組白血病患者的生存曲線比較</strong>: (本例中，時間是從發病到症狀緩解的時間，所以時間越短，說明療法越好) 下圖繪制的是治療組21名患者和對照組21名患者的生存概率曲線和它們各自的信賴區間。治療組的症狀緩解時間明顯比對照組要長，暗示治療方案可能對患者有不太好的影響。且途中的兩條生存曲線的95%信賴區間也基本沒有重疊。
</div>

<div class="figure" style="text-align: center"><span id="fig:SurvExample2-4"></span>
<img src="img/Selection_132.png" alt="Kaplain-Meier time-to-remission survival curves (solid lines) in leukemia patients in treatment and control groups, with corresponding 95% confidence limits(dotted lines)" width="90%" />
<p class="caption">
圖 72.2: Kaplain-Meier time-to-remission survival curves (solid lines) in leukemia patients in treatment and control groups, with corresponding 95% confidence limits(dotted lines)
</p>
</div>
<p>看圖中的生存曲線，目測第十周時，治療組和對照組各自的生存率大概是多少，你的結論是怎樣的？</p>
<p>從圖上看，在對照組，第十周時患者的生存概率在 40% 左右; 在治療組，第十周時患者的生存概率是 75% 左右。所以，治療組中的患者傾向於需要更多的時間才能達到症狀緩解。在第十周時，對照組患者有 60% 已經症狀緩解，然而治療組只有 25% 的患者症狀緩解，所以我們認爲數據提示治療方法可能對患者是有副作用的。</p>
<div id="the-log-rank-test" class="section level3">
<h3><span class="header-section-number">72.5.1</span> The log rank test</h3>
<p>兩組 (或者更多組) 之間生存概率曲線其實是可以用統計學檢驗方法來檢驗的。用 <span class="math inline">\(S_1(t),S_2(t)\)</span> 分別表示兩組研究對象的生存概率。那麼在時間點 <span class="math inline">\(u\)</span> 時，兩組時間生存概率的比較可以用下面的檢驗統計量:</p>
<p><span class="math display" id="eq:surv2-20">\[
\begin{equation}
\frac{\hat S_1(u) - \hat S_2(u)}{\sqrt{var \hat S_1(u) + var \hat S_2(u)}}
\end{equation}
\tag{72.5}
\]</span></p>
<p>然後把這個統計量拿去和標準正態分布做比較 (z-test)。</p>
<p>但是其實我們可以做得檢驗可以更多，比如比較兩組患者之間生存概率的分布，而不是只看某個時間點的生存概率之差。這種檢驗方法叫做 log rank test，或者 Mantel-Haenszel 檢驗。該檢驗的零假設是，兩組患者的生存曲線相同，它比較的是兩組患者的總體生存概率 (the whole survivor curves)。</p>
<p>接下來我們來推導這個檢驗方法。首先，先列出兩組患者在特定時間點時的數據:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 72.2: Summary of numbers at risk and number of events at time <span class="math inline">\(t_j\)</span> in two groups.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Events at <span class="math inline">\(t_j\)</span>
</th>
<th style="text-align:center;">
Number of surviving beyond <span class="math inline">\(t_j\)</span>
</th>
<th style="text-align:center;">
Total number at risk at <span class="math inline">\(t_j\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
<span class="math inline">\(d_{1j}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{1j} - d_{1j}\)</span> </d0>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{1j}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
<span class="math inline">\(d_{2j}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{2j} - d_{2j}\)</span> </d0>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{2j}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(d_j\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_j\)</span> <d0> dj </d0>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_j\)</span>
</td>
</tr>
</tbody>
</table>
<p>在零假設 – 不同的組之間，在該時間點時事件發生次數沒有差別 – 的條件下，第一組患者中事件發生次數服從超幾何分布 (hypergeometric distribution) (章節: <a href="#hyperdist">5.2</a>)。在超幾何分布下，組樣本量 <span class="math inline">\(n_{1j}\)</span> 中發生事件次數 <span class="math inline">\(d_{1j}\)</span> 在全體 (總樣本量 <span class="math inline">\(n_j\)</span>，事件次數 <span class="math inline">\(d_j\)</span>) 中的概率是:</p>
<p><span class="math display">\[
\begin{equation}
\frac{\binom{d_{j}}{d_{1j}}\binom{n_j - d_j}{n_{1j} - d_{1j}}}{\binom{n_j}{n_1j}}
\end{equation}
\]</span></p>
<p>對於第二組的患者，發生 <span class="math inline">\(d_{2j}\)</span> 次事件的概率也可以用相同的公式。那麼在給定的時間點 <span class="math inline">\(t_j\)</span>，在零假設 – 不同的組之間，在該時間點時事件發生次數沒有差別 – 的條件下， 第一組患者中發生事件次數的期望值 (expectation):</p>
<p><span class="math display" id="eq:surv2-22">\[
\begin{aligned}
e_{1j} = \frac{n_{1j}d_j}{n_j}
\end{aligned}
\tag{72.6}
\]</span></p>
<p>套用這個公式 <a href="#eq:surv2-22">(72.6)</a>，我們可以計算每個時間點上事件發生次數的期望值和實際觀測值之間的差: <span class="math inline">\(d_{1j}-e_{1j}\)</span> 然後把每個時間點上事件次數的觀測值和期望值之間的差求和:</p>
<p><span class="math display" id="eq:surv2-23">\[
\begin{equation}
\sum_j (d_{1j} - e_{1j})
\end{equation}
\tag{72.7}
\]</span></p>
<p>如果零假設成立，統計量 <a href="#eq:surv2-23">(72.7)</a> 應該等於零或者接近等於零。根據超幾何分布的方差，</p>
<p><span class="math display">\[
v_{1j}^2 = \text{var}(d_{1j}) = \frac{n_{1j}n_{2j}d_{j}(n_j - d_j)}{n_j^2 (n_j - 1)}
\]</span></p>
<p>所以，log-rank test 的檢驗統計量是</p>
<p><span class="math display">\[
\frac{\{ \sum_j(d_{1j} - e_{1j}) \}^2}{\sum_jv^2_{1j}} \sim \chi_1^2
\]</span></p>
<p>因此，在零假設條件下，這裏<strong>是兩組對象生存曲線的比較，所以它服從的是自由度爲 1 的卡方分布，如果比較的是兩組以上 (n) 的生存概率曲線，那麼這個統計量將會服從自由度爲 (n-1) 的卡方分布</strong> <span class="math inline">\(\chi^2_{n-1}\)</span>。</p>
</div>
</div>
<div id="計算累積風險度-cumulative-hazard" class="section level2">
<h2><span class="header-section-number">72.6</span> 計算累積風險度 cumulative hazard</h2>
<p>累積風險度的定義爲:</p>
<p><span class="math display">\[
H(t) = \int_0^t h(t)\text{d}t
\]</span></p>
<p>它和生存概率方程之間的關系爲:</p>
<p><span class="math display">\[
H(t) = -\log S(t)
\]</span></p>
<p>所以，非參數類型的累積風險度可以利用這個公式，套入 Kaplan-Meier 法估計的生存概率:</p>
<p><span class="math display">\[
\hat H(t) = - \log \hat S(t)
\]</span></p>
<p>另一個科學家 Nelson-Aalen 發現另一個更簡單的公式:</p>
<p><span class="math display" id="eq:surv2-29">\[
\begin{equation}
\tilde{H}(t) = \sum_{j|t_j \leqslant t}\hat h_j =  \sum_{j|t_j \leqslant t} \frac{d_j}{n_j}
\end{equation}
\tag{72.8}
\]</span></p>
<p>這個公式 <a href="#eq:surv2-29">(72.8)</a> 的估算結果和 Kaplan-Meier 估計的累積生存曲線會非常接近，且可以被認爲漸進相同 (symptotically equivalent)。</p>
</div>
<div id="practical-02---survival-analysis" class="section level2">
<h2><span class="header-section-number">72.7</span> Practical 02 - survival analysis</h2>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1050-1" title="1"><span class="co"># summarize and explore the data</span></a>
<a class="sourceLine" id="cb1050-2" title="2"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb1050-3" title="3">pbcbase &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/pbcbase.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1050-4" title="4"><span class="kw">with</span>(pbcbase, <span class="kw">tabpct</span>(treat, d, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        d
## treat      0    1  Total
##   1       45   49     94
##   2       50   47     97
##   Total   95   96    191
## 
## Row percent 
##      d
## treat       0       1  Total
##     1      45      49     94
##        (47.9)  (52.1)  (100)
##     2      50      47     97
##        (51.5)  (48.5)  (100)
## 
## Column percent 
##        d
## treat     0       %   1      %
##   1      45  (47.4)  49   (51)
##   2      50  (52.6)  47   (49)
##   Total  95   (100)  96  (100)</code></pre>
<div class="sourceCode" id="cb1052"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1052-1" title="1"><span class="co">#### median time</span></a>
<a class="sourceLine" id="cb1052-2" title="2">Median_t &lt;-<span class="st"> </span><span class="kw">ddply</span>(pbcbase,<span class="kw">c</span>(<span class="st">&quot;treat&quot;</span>,<span class="st">&quot;d&quot;</span>),summarise,<span class="dt">Median=</span><span class="kw">median</span>(time))</a>
<a class="sourceLine" id="cb1052-3" title="3">Median_t</a></code></pre></div>
<pre><code>##   treat d    Median
## 1     1 0 3.7426419
## 2     1 1 3.0006845
## 3     2 0 5.4483230
## 4     2 1 2.2012320</code></pre>
<pre><code>sts list if treat==2 &amp; cir0==1

         failure _d:  d
   analysis time _t:  (dateout-origin)/365.25
             origin:  time datein

           Beg.          Net            Survivor      Std.
  Time    Total   Fail   Lost           Function     Error     [95% Conf. Int.]
-------------------------------------------------------------------------------
  .104       26      1      0             0.9615    0.0377     0.7569    0.9945
 .2628       25      1      0             0.9231    0.0523     0.7260    0.9802
 .4572       24      1      0             0.8846    0.0627     0.6836    0.9613
 .4846       23      1      0             0.8462    0.0708     0.6404    0.9393
 .9172       22      0      1             0.8462    0.0708     0.6404    0.9393
 1.164       21      1      0             0.8059    0.0780     0.5946    0.9143
 1.369       20      1      0             0.7656    0.0839     0.5505    0.8873
 1.572       19      0      1             0.7656    0.0839     0.5505    0.8873
 1.687       18      1      0             0.7230    0.0894     0.5044    0.8576
 1.725       17      1      0             0.6805    0.0937     0.4603    0.8262
 2.182       16      1      0             0.6380    0.0970     0.4180    0.7933
 2.201       15      1      0             0.5954    0.0994     0.3773    0.7590
 2.634       14      0      1             0.5954    0.0994     0.3773    0.7590
 2.667       13      1      0             0.5496    0.1018     0.3337    0.7215
 3.047       12      0      1             0.5496    0.1018     0.3337    0.7215
  3.45       11      1      0             0.4997    0.1041     0.2866    0.6803
 3.472       10      1      0             0.4497    0.1050     0.2425    0.6371
 3.855        9      1      0             0.3997    0.1045     0.2012    0.5920
 4.249        8      1      0             0.3498    0.1027     0.1625    0.5448
  5.47        7      0      1             0.3498    0.1027     0.1625    0.5448
 5.541        6      0      1             0.3498    0.1027     0.1625    0.5448
 6.762        5      1      0             0.2798    0.1033     0.1056    0.4859
 6.905        4      1      0             0.2099    0.0983     0.0601    0.4202
 8.019        3      1      0             0.1399    0.0869     0.0259    0.3469
  8.89        2      0      1             0.1399    0.0869     0.0259    0.3469
 11.25        1      0      1             0.1399    0.0869     0.0259    0.3469
-------------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1055-1" title="1">pbc.km &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(time, d) <span class="op">~</span><span class="st"> </span>treat, <span class="dt">data =</span> pbcbase)</a>
<a class="sourceLine" id="cb1055-2" title="2"><span class="kw">summary</span>(pbc.km)</a></code></pre></div>
<pre><code>## Call: survfit(formula = Surv(time, d) ~ treat, data = pbcbase)
## 
##                 treat=1 
##     time n.risk n.event survival std.err lower 95% CI upper 95% CI
##  0.02464     90       1   0.9889 0.01105      0.96747       1.0000
##  0.05202     89       1   0.9778 0.01554      0.94779       1.0000
##  0.10404     88       1   0.9667 0.01892      0.93028       1.0000
##  0.13142     87       1   0.9556 0.02172      0.91391       0.9991
##  0.41068     86       1   0.9444 0.02415      0.89829       0.9930
##  0.67077     84       1   0.9332 0.02635      0.88297       0.9863
##  0.70089     83       1   0.9220 0.02833      0.86808       0.9792
##  0.93361     81       1   0.9106 0.03018      0.85331       0.9717
##  1.08145     79       1   0.8990 0.03192      0.83861       0.9638
##  1.21287     77       1   0.8874 0.03357      0.82395       0.9557
##  1.24846     76       1   0.8757 0.03510      0.80953       0.9473
##  1.25120     75       1   0.8640 0.03653      0.79532       0.9387
##  1.32512     74       1   0.8523 0.03785      0.78129       0.9299
##  1.42916     73       1   0.8407 0.03909      0.76744       0.9209
##  1.45927     72       1   0.8290 0.04026      0.75373       0.9118
##  1.46475     71       1   0.8173 0.04135      0.74017       0.9025
##  1.58248     70       1   0.8056 0.04237      0.72673       0.8931
##  2.07803     66       1   0.7934 0.04345      0.71268       0.8833
##  2.28611     64       1   0.7810 0.04451      0.69850       0.8733
##  2.63655     63       1   0.7686 0.04550      0.68445       0.8632
##  2.80082     61       1   0.7560 0.04646      0.67025       0.8528
##  2.80356     60       1   0.7434 0.04737      0.65617       0.8423
##  2.89117     58       1   0.7306 0.04825      0.64191       0.8316
##  2.90212     57       1   0.7178 0.04908      0.62778       0.8207
##  3.00068     56       1   0.7050 0.04985      0.61375       0.8098
##  3.25530     51       1   0.6912 0.05075      0.59852       0.7981
##  3.29090     50       1   0.6773 0.05158      0.58342       0.7864
##  3.33196     49       1   0.6635 0.05235      0.56845       0.7745
##  4.18344     43       1   0.6481 0.05336      0.55150       0.7616
##  4.27105     42       1   0.6327 0.05427      0.53474       0.7485
##  4.33676     41       1   0.6172 0.05510      0.51815       0.7352
##  4.55852     40       1   0.6018 0.05584      0.50172       0.7218
##  4.63518     38       1   0.5860 0.05657      0.48493       0.7080
##  4.77481     36       1   0.5697 0.05730      0.46776       0.6938
##  4.87611     34       1   0.5529 0.05801      0.45016       0.6792
##  4.93635     33       1   0.5362 0.05862      0.43275       0.6643
##  4.99658     31       1   0.5189 0.05923      0.41486       0.6490
##  5.14990     30       1   0.5016 0.05972      0.39718       0.6334
##  5.27584     28       1   0.4837 0.06022      0.37894       0.6173
##  5.31143     27       1   0.4658 0.06059      0.36092       0.6010
##  5.40726     26       1   0.4478 0.06085      0.34313       0.5845
##  6.05613     19       1   0.4243 0.06205      0.31853       0.5651
##  6.20671     18       1   0.4007 0.06292      0.29455       0.5451
##  6.41478     16       1   0.3757 0.06378      0.26933       0.5240
##  6.92950     12       1   0.3443 0.06570      0.23692       0.5005
##  6.94593     11       1   0.3130 0.06677      0.20609       0.4755
##  7.12663      8       1   0.2739 0.06894      0.16725       0.4486
##  7.78371      6       1   0.2283 0.07097      0.12410       0.4199
##  9.25941      2       1   0.1141 0.08816      0.02511       0.5187
## 
##                 treat=2 
##     time n.risk n.event survival std.err lower 95% CI upper 95% CI
##  0.02464     93       1   0.9892 0.01069       0.9685       1.0000
##  0.10404     92       1   0.9785 0.01504       0.9495       1.0000
##  0.26283     91       1   0.9677 0.01832       0.9325       1.0000
##  0.39425     90       1   0.9570 0.02104       0.9166       0.9991
##  0.45722     89       1   0.9462 0.02339       0.9015       0.9932
##  0.48460     88       1   0.9355 0.02547       0.8869       0.9868
##  0.52841     86       1   0.9246 0.02740       0.8724       0.9799
##  0.55031     85       1   0.9137 0.02916       0.8583       0.9727
##  0.56674     84       1   0.9029 0.03077       0.8445       0.9652
##  0.68720     83       1   0.8920 0.03227       0.8309       0.9575
##  1.15264     79       1   0.8807 0.03378       0.8169       0.9494
##  1.16359     78       1   0.8694 0.03518       0.8031       0.9412
##  1.27036     77       1   0.8581 0.03649       0.7895       0.9327
##  1.36893     75       1   0.8467 0.03776       0.7758       0.9240
##  1.60438     72       1   0.8349 0.03902       0.7618       0.9150
##  1.68652     71       1   0.8231 0.04020       0.7480       0.9058
##  1.72485     70       1   0.8114 0.04131       0.7343       0.8965
##  1.74127     69       1   0.7996 0.04235       0.7208       0.8871
##  1.77139     68       1   0.7879 0.04333       0.7073       0.8775
##  1.88364     66       1   0.7759 0.04429       0.6938       0.8678
##  2.03422     65       1   0.7640 0.04519       0.6804       0.8579
##  2.06434     64       1   0.7521 0.04603       0.6670       0.8479
##  2.18207     62       1   0.7399 0.04686       0.6535       0.8377
##  2.20123     60       1   0.7276 0.04768       0.6399       0.8273
##  2.59274     56       1   0.7146 0.04856       0.6255       0.8164
##  2.66667     54       1   0.7014 0.04943       0.6109       0.8053
##  3.33744     52       1   0.6879 0.05029       0.5960       0.7939
##  3.41410     51       1   0.6744 0.05108       0.5814       0.7823
##  3.44969     50       1   0.6609 0.05181       0.5668       0.7707
##  3.47159     49       1   0.6474 0.05248       0.5523       0.7589
##  3.85489     47       1   0.6336 0.05314       0.5376       0.7468
##  4.10404     45       1   0.6196 0.05379       0.5226       0.7345
##  4.10678     44       1   0.6055 0.05438       0.5077       0.7220
##  4.16701     43       1   0.5914 0.05491       0.4930       0.7094
##  4.24914     42       1   0.5773 0.05538       0.4784       0.6967
##  4.25462     41       1   0.5632 0.05579       0.4639       0.6839
##  5.31691     37       1   0.5480 0.05632       0.4480       0.6703
##  5.40726     36       1   0.5328 0.05677       0.4324       0.6565
##  5.88090     28       1   0.5138 0.05785       0.4120       0.6406
##  6.04791     27       1   0.4947 0.05875       0.3920       0.6244
##  6.64203     21       1   0.4712 0.06049       0.3664       0.6060
##  6.76249     19       1   0.4464 0.06218       0.3397       0.5865
##  6.84463     17       1   0.4201 0.06383       0.3119       0.5658
##  6.90486     16       1   0.3939 0.06502       0.2850       0.5443
##  7.82204     13       1   0.3636 0.06670       0.2538       0.5209
##  8.01917     12       1   0.3333 0.06768       0.2238       0.4962
##  8.27926     11       1   0.3030 0.06797       0.1952       0.4703</code></pre>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1057-1" title="1"><span class="kw">plot</span>(pbc.km, <span class="dt">conf.int =</span> F, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">mark.time =</span> F, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-03"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-03-1.png" alt="Rplots of the Kaplan-Meier survivor functions" width="70%" />
<p class="caption">
圖 72.3: Rplots of the Kaplan-Meier survivor functions
</p>
</div>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1058-1" title="1"><span class="kw">plot</span>(pbc.km, <span class="dt">conf.int =</span> T, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">mark.time =</span> T, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-04"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-04-1.png" alt="Rplots of the Kaplan-Meier survivor functions with confidence intervals" width="70%" />
<p class="caption">
圖 72.4: Rplots of the Kaplan-Meier survivor functions with confidence intervals
</p>
</div>
<p>在追蹤前兩年，兩組患者的生存方程沒有太大區別，兩年之後，到大約第五年之間，藥物治療組的生存概率曲線似乎要低於對照組，暗示藥物治療在這段時間內可能導致患者較高的死亡率。患者隨訪達到第五年之後，可以看到藥物治療組患者的生存概率曲線一直都處在對照組的上方，提示我們患者被隨訪達到五年之後，藥物治療組的患者死亡率開始低於對照組死亡率。但是，這兩條生存概率曲線的 95% 信賴區間彼此重疊部分很大，且在臨近隨訪達到12年的時候，信賴區間太寬，因爲此時已經沒有多少死亡病例。這兩組患者都有大約 50% 左右的患者的生存率超過五年。</p>
<div class="sourceCode" id="cb1059"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1059-1" title="1">pbc.km1 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(time, d) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span><span class="kw">subset</span>(pbcbase, pbcbase<span class="op">$</span>treat <span class="op">==</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1059-2" title="2">pbc.km2 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(time, d) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span><span class="kw">subset</span>(pbcbase, pbcbase<span class="op">$</span>treat <span class="op">==</span><span class="st"> </span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1059-3" title="3">cumhaz<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">cumsum</span>(pbc.km1<span class="op">$</span>n.event<span class="op">/</span>pbc.km1<span class="op">$</span>n.risk)</a>
<a class="sourceLine" id="cb1059-4" title="4">cumhaz<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">cumsum</span>(pbc.km2<span class="op">$</span>n.event<span class="op">/</span>pbc.km2<span class="op">$</span>n.risk)</a>
<a class="sourceLine" id="cb1059-5" title="5"><span class="kw">plot</span>(pbc.km1<span class="op">$</span>time, cumhaz<span class="fl">.1</span>, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Cumulative hazard&quot;</span>)</a>
<a class="sourceLine" id="cb1059-6" title="6"><span class="kw">lines</span>(pbc.km2<span class="op">$</span>time, cumhaz<span class="fl">.2</span>, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-05"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-05-1.png" alt="Rplots of the Nelson-Aalen estimates of the cumulative hazard" width="70%" />
<p class="caption">
圖 72.5: Rplots of the Nelson-Aalen estimates of the cumulative hazard
</p>
</div>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1060-1" title="1"><span class="kw">plot</span>(pbc.km, <span class="dt">conf.int=</span> F, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">mark.time =</span>F,<span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Cumulative hazard&quot;</span>, <span class="dt">fun =</span> <span class="st">&quot;cumhaz&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-06"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-06-1.png" alt="Rplots of the Kaplan-Meier estimates of the cumulative hazard" width="70%" />
<p class="caption">
圖 72.6: Rplots of the Kaplan-Meier estimates of the cumulative hazard
</p>
</div>
<p>從兩個生存累積概率曲線來看，治療組的生存累計概率似乎隨着時間更加呈線性變化。在對照組，風險在5年以後的累計速率陡然升高了。</p>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1061-1" title="1"><span class="co"># the log rank test</span></a>
<a class="sourceLine" id="cb1061-2" title="2"></a>
<a class="sourceLine" id="cb1061-3" title="3"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(time, d) <span class="op">~</span><span class="st"> </span>treat, <span class="dt">data =</span> pbcbase)</a></code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(time, d) ~ treat, data = pbcbase)
## 
##          N Observed Expected (O-E)^2/E (O-E)^2/V
## treat=1 94       49    45.33    0.2966    0.5696
## treat=2 97       47    50.67    0.2654    0.5696
## 
##  Chisq= 0.6  on 1 degrees of freedom, p= 0.45</code></pre>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1063-1" title="1">whitehall &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/whitehall.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1063-2" title="2">whl.km &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(<span class="dt">time=</span>(timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1063-3" title="3"><span class="kw">plot</span>(whl.km, <span class="dt">conf.int =</span> T, <span class="dt">mark.time =</span> F, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="fl">0.8</span>,<span class="dv">1</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-08"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-08-1.png" alt="Rplots of the Kaplan-Meier estimates of the survivor curve" width="70%" />
<p class="caption">
圖 72.7: Rplots of the Kaplan-Meier estimates of the survivor curve
</p>
</div>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1064-1" title="1">whl.km &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(<span class="dt">time =</span> (timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span>sbpgrp, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1064-2" title="2"><span class="kw">plot</span>(whl.km, <span class="dt">conf.int =</span> F, <span class="dt">mark.time =</span> F, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.75</span>, <span class="dv">1</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;orange&quot;</span>))</a>
<a class="sourceLine" id="cb1064-3" title="3"><span class="kw">legend</span>(<span class="dv">1</span>, <span class="fl">0.85</span>, <span class="kw">c</span>(<span class="st">&quot;Group 1&quot;</span>, <span class="st">&quot;Group 2&quot;</span>, <span class="st">&quot;Group 3&quot;</span>, <span class="st">&quot;Group 4&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;orange&quot;</span>), <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-02-09"></span>
<img src="bookdown_files/figure-html/Surv-prac-02-09-1.png" alt="Rplots of the Kaplan-Meier estimates of the survivor curve" width="70%" />
<p class="caption">
圖 72.8: Rplots of the Kaplan-Meier estimates of the survivor curve
</p>
</div>
<p>所以，第四組患者的生存率最差， 第一組，第二組患者幾乎沒有差別。</p>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1065-1" title="1"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(<span class="dt">time =</span> (timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span>sbpgrp, <span class="dt">data =</span> whitehall)</a></code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(time = (timeout - timein)/365.25, event = chd) ~ 
##     sbpgrp, data = whitehall)
## 
##            N Observed Expected (O-E)^2/E (O-E)^2/V
## sbpgrp=1 383       28    36.81    2.1101     2.776
## sbpgrp=2 664       44    62.90    5.6786     9.602
## sbpgrp=3 417       43    37.09    0.9411     1.240
## sbpgrp=4 213       39    17.20   27.6494    31.153
## 
##  Chisq= 36.4  on 3 degrees of freedom, p= 6.1e-08</code></pre>
</div>
</div>
<div id="生存數據中的回歸模型" class="section level1">
<h1><span class="header-section-number">第 73 章</span> 生存數據中的回歸模型</h1>
<div id="生存數據的似然方程" class="section level2">
<h2><span class="header-section-number">73.1</span> 生存數據的似然方程</h2>
<p><span class="math display">\[
L = \prod_i f(t_i)^{\delta_i}S(t_i)^{1-\delta_i}
\]</span></p>
<ul>
<li><span class="math inline">\(i = 1, \cdots, n\)</span> 是患者的編號</li>
<li><span class="math inline">\(t_i\)</span> 是 <span class="math inline">\(i\)</span> 號患者的生存/刪失時間</li>
<li><span class="math inline">\(\delta_i\)</span> 是表示 <span class="math inline">\(i\)</span> 號患者的生存/刪失狀態的啞變量 (indicator/dummy variable)</li>
<li><span class="math inline">\(f(t_i)\)</span> 是生存數據(死亡/事件發生患者的)的概率密度方程 probablity density function</li>
<li><span class="math inline">\(S(t_i)\)</span> 是生存數據(生存/刪失患者的)生存概率方程 survivor function</li>
</ul>
</div>
<div id="如何加入解釋變量" class="section level2">
<h2><span class="header-section-number">73.2</span> 如何加入解釋變量</h2>
<p>先考慮一個二分類變量 (binary explanatory variable <span class="math inline">\(X = 0 \text{ or } 1\)</span>)，可以是治療組對照組等簡單的二分類變量。可以認爲其中一組 <span class="math inline">\((X=1)\)</span> 患者在時間點 <span class="math inline">\(t\)</span> 時的風險度 (hazard) <span class="math inline">\(h_1(t)\)</span> 和另一個被看作是對照的基準組 (baseline group <span class="math inline">\(X=0\)</span>) 的風險度 <span class="math inline">\(h_0(t)\)</span> 之間的關系是相乘的話:</p>
<p><span class="math display">\[
h_1(t) = \psi h_0 (t)
\]</span></p>
<p>那麼這裏的 <span class="math inline">\(\psi\)</span> 就是我們關心的參數。注意這裏兩組患者的風險度，等式左右兩邊都必須是大於零的，因此 <span class="math inline">\(psi\)</span> 的取值要被限制在 <span class="math inline">\(&gt;0\)</span> 範圍。所以，我們常常直接寫成:</p>
<p><span class="math display">\[
h_1(t) = e^\beta h_0(t)
\]</span></p>
<p>那麼參數 <span class="math inline">\(\beta\)</span> 就沒有了取值的限制。這就是大名鼎鼎的<strong>比例風險度模型 (proportional hazard model)</strong>。<span class="math inline">\(e^\beta\)</span> 就是風險度比 (Hazard ratio):</p>
<p><span class="math display">\[
\frac{h_1(t)}{h_0(t)} = e^\beta
\]</span></p>
<p><span class="math inline">\(\beta\)</span> 是對數風險度比 (log-hazard ratio)，這個風險度比，不隨着時間推進而變化。所以在生存分析的參數模型中，<strong>前提條件–比例風險度 (proportional hazard assumption)，是必須被滿足的假設</strong>。當你認爲治療組對照組之間的療效差 (treatment effect) 會隨着時間發生變化的話，這個前提條件就被違反了。用於生存分析的這些參數模型，都需要比例風險度這一重要的前提條件被滿足。</p>
</div>
<div id="指數模型-exponential-model" class="section level2">
<h2><span class="header-section-number">73.3</span> 指數模型 exponential model</h2>
<p>指數模型是最簡單的生存時間分析參數模型。</p>
<p><strong>風險度方程 hazard function:</strong></p>
<p><span class="math display">\[
h(t) = \lim_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t\leqslant T &lt;t + \delta | T&gt;t) = \lambda
\]</span></p>
<p><strong>生存概率方程 survivor function:</strong></p>
<p><span class="math display">\[
S(t) = \text{Pr}(T&gt;t) = \exp\{-\lambda t\}
\]</span></p>
<p><strong>概率密度方程 probability density function:</strong></p>
<p><span class="math display">\[
f(t) = \lambda \exp\{ - \lambda t\}
\]</span></p>
<p>在指數分布時，風險度本身 (而不是比例) 保持不變。這也意味着事件發生的率 (rate of the event) 不隨時間發生變化 (constant over time)。</p>
<p>在指數分布模型下加入解釋變量:</p>
<p><span class="math display">\[
\left\{
  \begin{array}{ll}
  h(t;0) = \lambda &amp; X=0  \\
  h(t;1) = \lambda e^\beta &amp; X=1
  \end{array}
\right.
\]</span></p>
<p>這個聯立方程等價於:</p>
<p><span class="math display">\[
h(t;x) = \lambda e^{\beta x}
\]</span></p>
<p>類似地，風險度方程已知了的話，概率密度方程和生存方程可以寫作:</p>
<p><span class="math display">\[
f(t;x) = \lambda e^{\beta x} \exp({-\lambda t^{\beta x}}); \\
S(t;x) = \exp(-\lambda t^{\beta x})
\]</span></p>
<p>此時的似然方程就是</p>
<p><span class="math display">\[
L = \prod_{i = 1}^n\{\lambda e^{\beta x} \exp({-\lambda t^{\beta x}}) \}^{\delta_i}\{ \exp(-\lambda t^{\beta x})\}^{1-\delta_i}
\]</span></p>
<p>此時，似然方程中兩個參數 <span class="math inline">\(\lambda, \beta\)</span> 可以利用自己似然函數的方法分別對其中一個求導數獲得 MLE，然後用 Fisher information matrix 計算各自的標準誤，從而計算 95% 信賴區間。這裏的 <span class="math inline">\(\beta\)</span> 回歸系數，可以做是否爲零 (等價於比較 <span class="math inline">\(e^\beta = 1\)</span>) 的 Wald 檢驗:</p>
<p><span class="math display">\[
\frac{\hat\beta}{SE(\hat\beta)} \sim N(0,1)
\]</span></p>

<div class="example">
<span id="exm:11-Survival-analysis-3" class="example"><strong>Example 73.1  </strong></span><strong>推導<span class="math inline">\(\lambda,\beta\)</span>的MLE:</strong>
</div>

<p><span class="math display">\[
\begin{aligned}
L &amp; = \prod_{i = 1}^n\{\lambda e^{\beta x} \exp({-\lambda t^{\beta x}}) \}^{\delta_i}\{ \exp(-\lambda t^{\beta x})\}^{1-\delta_i} \\
  &amp; = \prod_{i = 1}^n\{\lambda e^{\beta x}\}^{\delta_i}\exp(-\lambda t^{\beta x}) \\
\Rightarrow \ell &amp; = \log(\lambda)\sum_{i=1}^n \delta_i + \beta \sum_{i = 1}^n(x_i\delta_i) - \lambda\sum_{i = 1}^n t_ie^{\beta x_i} \\
\text{Let} &amp; \sum_{i = 1}^n = n_1 \text{(numer of events)}; \\
&amp;\sum_{i=1}^n(x_i\delta_i) = n_{11} \text{(number of events in } x=1); \\
&amp;\sum_{x_i=1}^n t_i = T_1 \text{(sum of survival/censors T in } x=1);\\
&amp;\sum_{x_i=0}^n t_i = T_0 \text{(sum of survival/censors T in } x=0);\\
\Rightarrow \ell &amp; =n_1 \log(\lambda) + n_{11}\beta - \lambda(T_0 + T_1e^\beta)
\end{aligned}
\]</span></p>
<p>接下來求 MLE 就等同於解下面的聯立方程組:</p>
<p><span class="math display">\[
\left\{\begin{array}{l}
\frac{\text{d}\ell}{\text{d}\lambda} = \frac{n_1}{\lambda} - (T_0 +T_1e^\beta) =0 \\
\frac{\text{d}\ell}{\text{d}\beta} = n_{11} = T_1\lambda e^\beta = 0
\end{array}
\right. \\
\hat\lambda = \frac{n_1 - n_{11}}{T_0} \\
\hat\beta = \log\frac{T_0n_{11}}{T_1(n_1 - n_{11})}
\]</span></p>
</div>
<div id="weibull-分布-1" class="section level2">
<h2><span class="header-section-number">73.4</span> Weibull 分布</h2>
<p>指數分布的模型只能用於擬合數據滿足事件發生率恆定不變這一十分強的假設的前提下。Weibull 分布放鬆了這個假設前提，不再要求時間發生率恆定不變，但是它的前提條件是時間發生率隨着時間的變化是單調的 (遞增或者遞減，二者只能選一)。且 Weibull 分布是指數分布的一般化形式，或者說指數分布是 Weibull 分布的特殊形式。</p>
<p><strong>Weibull 分布的風險度方程:</strong></p>
<p><span class="math display">\[
h(t) = \kappa \lambda t^{\kappa - 1}
\]</span></p>
<p><strong>生存概率方程</strong></p>
<p><span class="math display">\[
S(t;x) = \exp\{ -\lambda t^\kappa \}
\]</span></p>
<p><strong>概率密度方程</strong></p>
<p><span class="math display">\[
f(t) = \kappa \lambda t^{\kappa - 1}  \exp\{ -\lambda t^\kappa \}
\]</span></p>
<p>那麼加入了一個二分類解釋變量 <span class="math inline">\(x\)</span> 的 Weibull 比例風險度方程就是:</p>
<p><span class="math display">\[
h(t;x) =  \kappa \lambda t^{\kappa - 1}e^{\beta x}
\]</span></p>
<p>其生存概率方程就是:</p>
<p><span class="math display">\[
S(t;x) = \exp\{ -\lambda t^\kappa e^{\beta x}\}
\]</span></p>
<p>概率密度方程是二者的乘積，那麼所有的生存數據的似然方程就是:</p>
<p><span class="math display">\[
L = \prod_{i=1}^n \{\kappa \lambda t^{\kappa - 1}e^{\beta x}\exp\{ -\lambda t^\kappa e^{\beta x}\} \}^{\delta_i}\{ \exp\{ -\lambda t^\kappa e^{\beta x}\}\}^{1-\delta_i}
\]</span></p>
<p>但是，比較悲劇的是，在 Weibull 分布的生存模型中，沒有辦法簡單的獲得參數 <span class="math inline">\(\kappa, \lambda. \beta\)</span> 的MLE。只能使用迭代法 (iterative numerical methods are required)。</p>
</div>
<div id="weibull-和-指數模型的比較" class="section level2">
<h2><span class="header-section-number">73.5</span> Weibull 和 指數模型的比較</h2>
<div id="繪圖法" class="section level3">
<h3><span class="header-section-number">73.5.1</span> 繪圖法</h3>
<p>在指數分布模型中，累積風險度 cumulative hazard 是和時間呈正比的:
<span class="math display">\[
H(t;x) = -\log S(t;x) = \lambda t e^{\beta x}
\]</span></p>
<p>在 Weibull 分布模型中，累積風險度 cumulative hazard，取了對數以後:</p>
<p><span class="math display">\[
\log H(t;x) = \log\{ -\log S(t;x) \} = \log \lambda + \kappa \log t + \beta x
\]</span></p>
<p>所以，累積風險度如果取了對數，那麼這個值和時間的對數 <span class="math inline">\(\log t\)</span> 是呈線性關系的，且當這個直線的坡度爲 1 的話 <span class="math inline">\(\kappa = 1\)</span>，就說明數據符合指數模型。如果，<span class="math inline">\(x\)</span> 只是一個二分類解釋變量的話，你會看到對數累積風險度和對數時間呈現爲<strong>兩條平行線</strong>。</p>
</div>
<div id="統計檢驗法" class="section level3">
<h3><span class="header-section-number">73.5.2</span> 統計檢驗法</h3>
<p>很簡單， Wald test:</p>
<p><span class="math display">\[
\frac{\log \hat\kappa}{SE(\log \hat\kappa)} \sim N(0,1)
\]</span></p>
<p>當然你也可以使用似然比檢驗 likelihood ratio test，因爲指數分布模型是 Weibull 分布模型在 <span class="math inline">\(\kappa = 1\)</span> 時的特殊形態，二者擬合的統計模型也會是嵌套式模型:</p>
<p><span class="math display">\[
-2(\ell_{\text{exponential}} - \ell_{\text{Weibull}}) \sim \chi_1^2
\]</span></p>
<p>服從的卡方分布的自由度是兩個模型的參數數量的差。</p>
</div>
</div>
<div id="多於-1-個解釋變量的參數模型" class="section level2">
<h2><span class="header-section-number">73.6</span> 多於 1 個解釋變量的參數模型</h2>
<p>當然可以在生存分析參數模型中加入多於一個變量，而且可以是分類型，連續型變量:</p>
<p><span class="math display">\[
h(t;x) = h_0 (t)e^{\beta^Tx}
\]</span></p>
<ul>
<li><span class="math inline">\(h_0(t)\)</span> 是基線組的風險度 (baseline hazard);</li>
<li><span class="math inline">\(\mathbf{\beta} = (\beta_1, \beta_2, \cdots, \beta_p)^T\)</span> 是一組解釋變量的回歸系數;</li>
<li><span class="math inline">\(\beta_k\)</span> 是當保持所有其他變量不變時，解釋變量 <span class="math inline">\(X_k\)</span> 在增加/減少一個單位對應的對數風險度比 (log-hazard ratio)。</li>
</ul>
</div>
<div id="practical-survival-03" class="section level2">
<h2><span class="header-section-number">73.7</span> Practical Survival 03</h2>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1067-1" title="1">whitehall &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/whitehall.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1067-2" title="2">whitehall &lt;-<span class="st"> </span>whitehall <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1067-3" title="3"><span class="st">                </span><span class="kw">mutate</span>(<span class="dt">timein =</span> <span class="kw">as.numeric</span>(timein),</a>
<a class="sourceLine" id="cb1067-4" title="4">                       <span class="dt">timeout =</span> <span class="kw">as.numeric</span>(timeout),</a>
<a class="sourceLine" id="cb1067-5" title="5">                       <span class="dt">timebth =</span> <span class="kw">as.numeric</span>(timebth)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1067-6" title="6"><span class="st">                </span><span class="kw">mutate</span>(<span class="dt">time =</span> (timeout <span class="op">-</span><span class="st"> </span>timein)<span class="op">/</span><span class="fl">365.25</span>)</a>
<a class="sourceLine" id="cb1067-7" title="7"></a>
<a class="sourceLine" id="cb1067-8" title="8"><span class="kw">with</span>(whitehall, <span class="kw">tabpct</span>(grade, chd, <span class="dt">graph =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<pre><code>## 
## Original table 
##        chd
## grade       0     1  Total
##   1      1104    90   1194
##   2       419    64    483
##   Total  1523   154   1677
## 
## Row percent 
##      chd
## grade       0       1  Total
##     1    1104      90   1194
##        (92.5)   (7.5)  (100)
##     2     419      64    483
##        (86.7)  (13.3)  (100)
## 
## Column percent 
##        chd
## grade       0       %    1       %
##   1      1104  (72.5)   90  (58.4)
##   2       419  (27.5)   64  (41.6)
##   Total  1523   (100)  154   (100)</code></pre>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1069-1" title="1"><span class="co">#### median time</span></a>
<a class="sourceLine" id="cb1069-2" title="2">Median_t &lt;-<span class="st"> </span><span class="kw">ddply</span>(whitehall,<span class="kw">c</span>(<span class="st">&quot;grade&quot;</span>,<span class="st">&quot;chd&quot;</span>),summarise,<span class="dt">Median=</span><span class="kw">median</span>(time))</a>
<a class="sourceLine" id="cb1069-3" title="3">Median_t</a></code></pre></div>
<pre><code>##   grade chd     Median
## 1     1   0 18.1779175
## 2     1   1 11.9110102
## 3     2   0 17.8726806
## 4     2   1  8.7679441</code></pre>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1071-1" title="1">whl.km &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(<span class="dt">time =</span> time, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade), <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1071-2" title="2"><span class="kw">plot</span>(whl.km, <span class="dt">conf.int =</span> T, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">mark.time =</span> F, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.8</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1071-3" title="3"><span class="kw">legend</span>(<span class="dv">1</span>, <span class="fl">0.85</span>, <span class="kw">c</span>(<span class="st">&quot;Grade 1&quot;</span>, <span class="st">&quot;Grade 2&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">lty =</span> <span class="dv">1</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-03-02"></span>
<img src="bookdown_files/figure-html/Surv-prac-03-02-1.png" alt="Rplots of the Kaplan-Meier survivor functions" width="70%" />
<p class="caption">
圖 73.1: Rplots of the Kaplan-Meier survivor functions
</p>
</div>
<p>“Grade 1” 患者的生存概率明顯好於 “Grade 2”。而且，95% 信賴區間沒有重疊，提示這兩組之間的生存概率曲線應該有統計學上的顯著不同。</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1072-1" title="1"><span class="co"># How many individuals survived 5, 10, 15 years of follow-up in each job grade?</span></a>
<a class="sourceLine" id="cb1072-2" title="2"><span class="kw">summary</span>(whl.km, <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>))</a></code></pre></div>
<pre><code>## Call: survfit(formula = Surv(time = time, event = chd) ~ as.factor(grade), 
##     data = whitehall)
## 
##                 as.factor(grade)=1 
##  time n.risk n.event survival  std.err lower 95% CI upper 95% CI
##     5   1169      10   0.9916 0.002648       0.9864       0.9968
##    10   1114      24   0.9709 0.004913       0.9613       0.9806
##    15   1045      30   0.9443 0.006772       0.9311       0.9577
## 
##                 as.factor(grade)=2 
##  time n.risk n.event survival  std.err lower 95% CI upper 95% CI
##     5    445      17   0.9642 0.008521       0.9477       0.9811
##    10    383      22   0.9144 0.013135       0.8890       0.9405
##    15    334      16   0.8747 0.015876       0.8442       0.9064</code></pre>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1074-1" title="1"><span class="co"># Log rank test to compare the estimated survivor functions in the two job grades</span></a>
<a class="sourceLine" id="cb1074-2" title="2"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(<span class="dt">time=</span>time, <span class="dt">event =</span> chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade), <span class="dt">data =</span> whitehall)</a></code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(time = time, event = chd) ~ as.factor(grade), 
##     data = whitehall)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## as.factor(grade)=1 1194       90   114.19     5.123     19.85
## as.factor(grade)=2  483       64    39.81    14.692     19.85
## 
##  Chisq= 19.8  on 1 degrees of freedom, p= 8.4e-06</code></pre>
<div class="sourceCode" id="cb1076"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1076-1" title="1"><span class="co"># Fit an exponential model</span></a>
<a class="sourceLine" id="cb1076-2" title="2">whl.exp &lt;-<span class="st"> </span><span class="kw">survreg</span>(<span class="kw">Surv</span>(time, chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade), <span class="dt">dist =</span> <span class="st">&quot;exponential&quot;</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1076-3" title="3"><span class="kw">summary</span>(whl.exp)</a></code></pre></div>
<pre><code>## 
## Call:
## survreg(formula = Surv(time, chd) ~ as.factor(grade), data = whitehall, 
##     dist = &quot;exponential&quot;)
##                     Value Std. Error      z         p
## (Intercept)        5.4205     0.1054 51.424   &lt; 2e-16
## as.factor(grade)2 -0.6885     0.1635 -4.211 0.0000255
## 
## Scale fixed at 1 
## 
## Exponential distribution
## Loglik(model)= -944.7   Loglik(intercept only)= -953.1
##  Chisq= 16.76 on 1 degrees of freedom, p= 0.000042 
## Number of Newton-Raphson Iterations: 6 
## n= 1677</code></pre>
<p>這裏 R 的輸出結果和 STATA 的結果略有不同:</p>
<pre><code>. streg i.grade, d(exp) nohr

         failure _d:  chd
   analysis time _t:  (timeout-origin)/365.25
             origin:  time timein

Iteration 0:   log likelihood = -627.95275
Iteration 1:   log likelihood = -620.09818
Iteration 2:   log likelihood = -619.57374
Iteration 3:   log likelihood = -619.57209
Iteration 4:   log likelihood = -619.57209

Exponential PH regression

No. of subjects =        1,677                  Number of obs    =       1,677
No. of failures =          154
Time at risk    =  27605.37066
                                                LR chi2(1)       =       16.76
Log likelihood  =   -619.57209                  Prob &gt; chi2      =      0.0000

------------------------------------------------------------------------------
          _t |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     2.grade |   .6885037   .1635118     4.21   0.000     .3680264    1.008981
       _cons |  -5.420525   .1054093   -51.42   0.000    -5.627123   -5.213926
------------------------------------------------------------------------------</code></pre>
<p>在 R 裏面，指數分布模型的回歸系數中，常數項 <code>(Intercept)</code> 等同於 STATA 裏的 <code>_cons</code>，但是，它在 R 裏估計的是 <span class="math inline">\(-\log \lambda\)</span>。<code>grade</code> 的回歸系數 <span class="math inline">\(\beta\)</span> 也一樣，在 R 裏它估計的是 <span class="math inline">\(-\beta\)</span>。所以你會發現 R 的輸出結果和 STATA 的結果符號相反，但是殊途同歸。</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1079-1" title="1"><span class="co"># Change the time scale to age time and fit the models again</span></a>
<a class="sourceLine" id="cb1079-2" title="2"></a>
<a class="sourceLine" id="cb1079-3" title="3"><span class="co">#The survreg function does not allow delayed entry times, so we can&#39;t use it with age as the time scale and entry at &#39;timein&#39;</span></a>
<a class="sourceLine" id="cb1079-4" title="4"><span class="co">#But we can fit the same model using an alternative function called &#39;weibreg&#39; which is in the &#39;eha&#39; package. You will need to install this package.</span></a>
<a class="sourceLine" id="cb1079-5" title="5"><span class="co"># install.packages(&quot;eha&quot;) # install and loading this package by uncomment these two lines</span></a>
<a class="sourceLine" id="cb1079-6" title="6"><span class="co"># library(eha)</span></a>
<a class="sourceLine" id="cb1079-7" title="7"></a>
<a class="sourceLine" id="cb1079-8" title="8">whl.exp2&lt;-<span class="kw">weibreg</span>(<span class="kw">Surv</span>(timein<span class="op">/</span><span class="fl">365.25</span>, timeout<span class="op">/</span><span class="fl">365.25</span>,<span class="dt">event=</span>chd,<span class="dt">origin=</span>timebth<span class="op">/</span><span class="fl">365.25</span>)<span class="op">~</span><span class="kw">as.factor</span>(grade), <span class="dt">data =</span> whitehall,</a>
<a class="sourceLine" id="cb1079-9" title="9">                  <span class="dt">shape =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1079-10" title="10"><span class="kw">summary</span>(whl.exp2)</a></code></pre></div>
<pre><code>## Call:
## weibreg(formula = Surv(timein/365.25, timeout/365.25, event = chd, 
##     origin = timebth/365.25) ~ as.factor(grade), data = whitehall, 
##     shape = 1)
## 
## Covariate           Mean       Coef Exp(Coef)  se(Coef)    Wald p
## as.factor(grade) 
##                1    0.737     0         1           (reference)
##                2    0.263     0.689     1.991     0.164     0.000 
## 
## log(scale)                    5.421   225.998     0.105     0.000 
## 
##  Shape is fixed at  1 
## 
## Events                    154 
## Total time at risk         27605 
## Max. log. likelihood      -944.7 
## LR test statistic         16.76 
## Degrees of freedom        1 
## Overall p-value           0.0000423884</code></pre>
<div class="sourceCode" id="cb1081"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1081-1" title="1"><span class="co">#Another alternative is the flexsurv package</span></a>
<a class="sourceLine" id="cb1081-2" title="2"><span class="co"># install.packages(&quot;flexsurv&quot;) # install and loading this package by uncomment these two lines</span></a>
<a class="sourceLine" id="cb1081-3" title="3"><span class="co"># library(flexsurv)</span></a>
<a class="sourceLine" id="cb1081-4" title="4">whl.exp3&lt;-<span class="kw">flexsurvreg</span>(<span class="kw">Surv</span>(timein<span class="op">/</span><span class="fl">365.25</span>, timeout<span class="op">/</span><span class="fl">365.25</span>,<span class="dt">event=</span>chd,<span class="dt">origin=</span>timebth<span class="op">/</span><span class="fl">365.25</span>)<span class="op">~</span><span class="kw">as.factor</span>(grade), <span class="dt">data =</span> whitehall,<span class="dt">dist =</span> <span class="st">&quot;exponential&quot;</span>,<span class="dt">inits =</span> <span class="kw">rep</span>(<span class="fl">0.1</span>,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## Warning in (function (q, rate = 1, lower.tail = TRUE, log.p = FALSE) : NaNs produced</code></pre>
<div class="sourceCode" id="cb1083"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1083-1" title="1">whl.exp3</a></code></pre></div>
<pre><code>## Call:
## flexsurvreg(formula = Surv(timein/365.25, timeout/365.25, event = chd, 
##     origin = timebth/365.25) ~ as.factor(grade), data = whitehall, 
##     dist = &quot;exponential&quot;, inits = rep(0.1, 2))
## 
## Estimates: 
##                    data mean  est       L95%      U95%      se        exp(est)  L95%      U95%    
## rate                     NA   0.004425  0.003599  0.005440  0.000466        NA        NA        NA
## as.factor(grade)2  0.288014   0.688359  0.367869  1.008848  0.163518  1.990446  1.444653  2.742439
## 
## N = 1677,  Events: 154,  Censored: 1523
## Total time at risk: 27605.371
## Log-likelihood = -944.69654, df = 2
## AIC = 1893.3931</code></pre>
<p>在指數分布模型下，我們默認事件發生率不會隨着時間變化，所以，改變了時間尺度，對生存分析估計的參數結果沒有影響。</p>
<div class="sourceCode" id="cb1085"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1085-1" title="1">whitehall &lt;-<span class="st"> </span>whitehall <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1085-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">agecat =</span> <span class="kw">cut</span>(agein, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">55</span>, <span class="dv">60</span>, <span class="dv">65</span>, <span class="dv">70</span>),<span class="dt">right =</span> F, <span class="dt">labels =</span> F))</a>
<a class="sourceLine" id="cb1085-3" title="3">whl.exp &lt;-<span class="st"> </span><span class="kw">survreg</span>(<span class="kw">Surv</span>(time, chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(agecat), <span class="dt">dist =</span> <span class="st">&quot;exponential&quot;</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1085-4" title="4"><span class="kw">summary</span>(whl.exp)</a></code></pre></div>
<pre><code>## 
## Call:
## survreg(formula = Surv(time, chd) ~ as.factor(grade) + as.factor(agecat), 
##     data = whitehall, dist = &quot;exponential&quot;)
##                      Value Std. Error      z        p
## (Intercept)         6.2076     0.1956 31.729  &lt; 2e-16
## as.factor(grade)2  -0.2681     0.1755 -1.527 0.126669
## as.factor(agecat)2 -0.9559     0.2582 -3.703 0.000213
## as.factor(agecat)3 -1.4462     0.2416 -5.985 2.16e-09
## as.factor(agecat)4 -1.4832     0.2707 -5.480 4.26e-08
## as.factor(agecat)5 -2.4060     0.3749 -6.418 1.38e-10
## 
## Scale fixed at 1 
## 
## Exponential distribution
## Loglik(model)= -914.1   Loglik(intercept only)= -953.1
##  Chisq= 78.01 on 5 degrees of freedom, p= 2.2e-15 
## Number of Newton-Raphson Iterations: 6 
## n= 1677</code></pre>
<div class="sourceCode" id="cb1087"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1087-1" title="1"><span class="co"># Fit the Weibull model in R, keep job grade and age category</span></a>
<a class="sourceLine" id="cb1087-2" title="2"></a>
<a class="sourceLine" id="cb1087-3" title="3">whl.weibull &lt;-<span class="st"> </span><span class="kw">survreg</span>(<span class="kw">Surv</span>(time, chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(agecat), <span class="dt">dist =</span> <span class="st">&quot;weibull&quot;</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1087-4" title="4"></a>
<a class="sourceLine" id="cb1087-5" title="5"><span class="kw">summary</span>(whl.weibull)</a></code></pre></div>
<pre><code>## 
## Call:
## survreg(formula = Surv(time, chd) ~ as.factor(grade) + as.factor(agecat), 
##     data = whitehall, dist = &quot;weibull&quot;)
##                       Value Std. Error      z        p
## (Intercept)         5.23905    0.22680 23.100  &lt; 2e-16
## as.factor(grade)2  -0.20191    0.12469 -1.619 0.105383
## as.factor(agecat)2 -0.68550    0.18946 -3.618 0.000297
## as.factor(agecat)3 -1.04268    0.18683 -5.581 2.39e-08
## as.factor(agecat)4 -1.07834    0.20598 -5.235 1.65e-07
## as.factor(agecat)5 -1.80110    0.28840 -6.245 4.23e-10
## Log(scale)         -0.34620    0.07678 -4.509 6.51e-06
## 
## Scale= 0.7074 
## 
## Weibull distribution
## Loglik(model)= -905.1   Loglik(intercept only)= -946.7
##  Chisq= 83.21 on 5 degrees of freedom, p= 1.8e-16 
## Number of Newton-Raphson Iterations: 10 
## n= 1677</code></pre>
<p>這個結果和 STATA 的結果也有些許不同:</p>
<pre><code>streg i.grade i.agecat, d(weib) nohr

         failure _d:  chd
   analysis time _t:  (timeout-origin)/365.25
             origin:  time timein

Fitting constant-only model:

Iteration 0:   log likelihood = -627.95275
Iteration 1:   log likelihood = -621.65709
Iteration 2:   log likelihood = -621.54148
Iteration 3:   log likelihood = -621.54144

Fitting full model:

Iteration 0:   log likelihood = -621.54144
Iteration 1:   log likelihood = -591.43979
Iteration 2:   log likelihood = -580.27283
Iteration 3:   log likelihood =  -579.9356
Iteration 4:   log likelihood = -579.93477
Iteration 5:   log likelihood = -579.93477

Weibull PH regression

No. of subjects =        1,677                  Number of obs    =       1,677
No. of failures =          154
Time at risk    =  27605.37066
                                                LR chi2(5)       =       83.21
Log likelihood  =   -579.93477                  Prob &gt; chi2      =      0.0000

------------------------------------------------------------------------------
          _t |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     2.grade |    .285431   .1753856     1.63   0.104    -.0583184    .6291805
             |
      agecat |
          2  |   .9690825   .2581668     3.75   0.000      .463085     1.47508
          3  |    1.47402   .2416534     6.10   0.000     1.000388    1.947652
          4  |   1.524436   .2707669     5.63   0.000     .9937422    2.055129
          5  |   2.546185   .3759036     6.77   0.000     1.809428    3.282943
             |
       _cons |  -7.406372   .3705694   -19.99   0.000    -8.132675   -6.680069
-------------+----------------------------------------------------------------
       /ln_p |   .3462011   .0767777     4.51   0.000     .1957195    .4966827
-------------+----------------------------------------------------------------
           p |   1.413687   .1085397                      1.216186    1.643261
         1/p |   .7073702   .0543103                      .6085461    .8222428
------------------------------------------------------------------------------</code></pre>
<ul>
<li>STATA裏的 <code>ln_p</code> (就是<span class="math inline">\(\kappa\)</span>形狀參數 shape parameter)，在 R 裏的名字是 <code>-log(scale)</code>。</li>
<li>STATA報告對數風險度比 <code>2.grade |.285431</code> ，R 裏面的回歸系數 <code>as.factor(grade)2  -0.2019</code> 其實是對數風險度比除以形狀參數之後變更符號，所以 <span class="math inline">\(-\frac{0.2854}{\exp(0.346)} = 0.202\)</span></li>
<li>所以在 R 中實際上輸出的結果是: <span class="math inline">\(-\log\kappa, -\frac{\beta}{\kappa}\)</span>。</li>
</ul>
<div class="sourceCode" id="cb1090"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1090-1" title="1">whl.km.agecat1 &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(<span class="dt">time=</span>time,<span class="dt">event=</span>chd)<span class="op">~</span>grade,<span class="dt">data=</span><span class="kw">subset</span>(whitehall,agecat<span class="op">==</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1090-2" title="2"><span class="kw">plot</span>(whl.km.agecat1,<span class="dt">conf.int=</span>T,<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;black&quot;</span>),<span class="dt">mark.time=</span>F,<span class="dt">xlab=</span><span class="st">&quot;log time&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;log(-log S(t))&quot;</span>,<span class="dt">fun=</span><span class="st">&quot;cloglog&quot;</span>)</a></code></pre></div>
<pre><code>## Warning in xy.coords(x, y, xlabel, ylabel, log): 1 x value &lt;= 0 omitted from logarithmic plot</code></pre>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-03-06"></span>
<img src="bookdown_files/figure-html/Surv-prac-03-06-1.png" alt="Non-paramatric plot to investigate whether the Weibull model fit the data appropriate" width="70%" />
<p class="caption">
圖 73.2: Non-paramatric plot to investigate whether the Weibull model fit the data appropriate
</p>
</div>
<p>用 Weibull 分布模型的結果，繪制兩個 job grade 在 5 個不同年齡層次的估計生存概率曲線:</p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1092-1" title="1">whl.weibull &lt;-<span class="st"> </span><span class="kw">survreg</span>(<span class="kw">Surv</span>(time, chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(agecat), <span class="dt">dist =</span> <span class="st">&quot;weibull&quot;</span>, <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1092-2" title="2"><span class="kw">plot</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">1</span>, <span class="dt">agecat =</span> <span class="dv">1</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>,</a>
<a class="sourceLine" id="cb1092-3" title="3">     <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Survivor function: S(t)&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1092-4" title="4"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">2</span>, <span class="dt">agecat =</span> <span class="dv">1</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1092-5" title="5"></a>
<a class="sourceLine" id="cb1092-6" title="6"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">1</span>, <span class="dt">agecat =</span> <span class="dv">2</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</a>
<a class="sourceLine" id="cb1092-7" title="7"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">2</span>, <span class="dt">agecat =</span> <span class="dv">2</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</a>
<a class="sourceLine" id="cb1092-8" title="8"></a>
<a class="sourceLine" id="cb1092-9" title="9"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">1</span>, <span class="dt">agecat =</span> <span class="dv">3</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb1092-10" title="10"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">2</span>, <span class="dt">agecat =</span> <span class="dv">3</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb1092-11" title="11"></a>
<a class="sourceLine" id="cb1092-12" title="12"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">1</span>, <span class="dt">agecat =</span> <span class="dv">4</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;orange&quot;</span>)</a>
<a class="sourceLine" id="cb1092-13" title="13"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">2</span>, <span class="dt">agecat =</span> <span class="dv">4</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;orange&quot;</span>)</a>
<a class="sourceLine" id="cb1092-14" title="14"></a>
<a class="sourceLine" id="cb1092-15" title="15"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">1</span>, <span class="dt">agecat =</span> <span class="dv">5</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb1092-16" title="16"><span class="kw">lines</span>(<span class="kw">predict</span>(whl.weibull, <span class="dt">newdata =</span> <span class="kw">list</span>(<span class="dt">grade =</span> <span class="dv">2</span>, <span class="dt">agecat =</span> <span class="dv">5</span>),  <span class="dt">type =</span> <span class="st">&quot;quantile&quot;</span>, <span class="dt">p =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)), <span class="kw">seq</span>(<span class="fl">0.99</span>, <span class="fl">0.01</span>, <span class="dt">by =</span> <span class="fl">-0.01</span>), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Surv-prac-03-07"></span>
<img src="bookdown_files/figure-html/Surv-prac-03-07-1.png" alt="The estimated survivor curves from the Weibull model in each job and age-at-entry category" width="70%" />
<p class="caption">
圖 73.3: The estimated survivor curves from the Weibull model in each job and age-at-entry category
</p>
</div>
<p>下面把隨訪時間按照 5 到 20 年每間隔五年的方法把所有患者的追蹤時間截斷成4個部分。然後用指數分布回歸模型擬合數據，這也是一種放鬆<strong>恆定事件發生率</strong>這一前提條件的方法:</p>
<div class="sourceCode" id="cb1093"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1093-1" title="1">whl.split &lt;-<span class="st"> </span><span class="kw">survSplit</span>(<span class="kw">Surv</span>(time, chd) <span class="op">~</span><span class="st"> </span>., whitehall, <span class="dt">cut =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>), <span class="dt">start =</span> <span class="st">&quot;time0&quot;</span>, <span class="dt">episode =</span> <span class="st">&quot;fuband&quot;</span>)</a>
<a class="sourceLine" id="cb1093-2" title="2"></a>
<a class="sourceLine" id="cb1093-3" title="3"><span class="kw">with</span>(whitehall, whitehall[id <span class="op">==</span><span class="st"> </span><span class="dv">5038</span>,])</a></code></pre></div>
<pre><code>## # A tibble: 1 x 16
##      id   all   chd   sbp  chol grade4  smok agein grade cholgrp sbpgrp timein timeout timebth  time
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1  5038     0     0   147   295      2     3  51.4     1       4      3  -840.   6239. -19630.  19.4
## # ... with 1 more variable: agecat &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb1095"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1095-1" title="1"><span class="kw">with</span>(whl.split, whl.split[id <span class="op">==</span><span class="st"> </span><span class="dv">5038</span>,])</a></code></pre></div>
<pre><code>##      id all sbp chol grade4 smok     agein grade cholgrp sbpgrp     timein   timeout    timebth
## 9  5038   0 147  295      2    3 51.444218     1       4      3 -840.01318 6238.9795 -19630.013
## 10 5038   0 147  295      2    3 51.444218     1       4      3 -840.01318 6238.9795 -19630.013
## 11 5038   0 147  295      2    3 51.444218     1       4      3 -840.01318 6238.9795 -19630.013
## 12 5038   0 147  295      2    3 51.444218     1       4      3 -840.01318 6238.9795 -19630.013
##    agecat time0      time chd fuband
## 9       2     0  5.000000   0      2
## 10      2     5 10.000000   0      3
## 11      2    10 15.000000   0      4
## 12      2    15 19.381226   0      5</code></pre>
<div class="sourceCode" id="cb1097"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1097-1" title="1">whl.split.exp &lt;-<span class="st"> </span><span class="kw">flexsurvreg</span>(<span class="kw">Surv</span>(time0, time, chd) <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(agecat) <span class="op">+</span></a>
<a class="sourceLine" id="cb1097-2" title="2"><span class="st">                               </span><span class="kw">as.factor</span>(fuband), <span class="dt">dist =</span> <span class="st">&quot;exponential&quot;</span>, <span class="dt">data =</span> whl.split)</a>
<a class="sourceLine" id="cb1097-3" title="3"></a>
<a class="sourceLine" id="cb1097-4" title="4">whl.split.exp</a></code></pre></div>
<pre><code>## Call:
## flexsurvreg(formula = Surv(time0, time, chd) ~ as.factor(grade) + 
##     as.factor(agecat) + as.factor(fuband), data = whl.split, 
##     dist = &quot;exponential&quot;)
## 
## Estimates: 
##                     data mean  est        L95%       U95%       se         exp(est)   L95%     
## rate                       NA   0.001059   0.000627   0.001788   0.000283         NA         NA
## as.factor(grade)2    0.266742   0.286099  -0.057633   0.629832   0.175377   1.331225   0.943996
## as.factor(agecat)2   0.218258   0.970919   0.464910   1.476929   0.258173   2.640371   1.591871
## as.factor(agecat)3   0.194422   1.477681   1.003971   1.951391   0.241693   4.382770   2.729097
## as.factor(agecat)4   0.114967   1.529719   0.998873   2.060564   0.270845   4.616879   2.715221
## as.factor(agecat)5   0.016053   2.562203   1.824200   3.300206   0.376539  12.964346   6.197836
## as.factor(fuband)3   0.261716   0.628789   0.153466   1.104112   0.242516   1.875338   1.165868
## as.factor(fuband)4   0.242744   0.783803   0.307212   1.260394   0.243163   2.189785   1.359630
## as.factor(fuband)5   0.223610   1.074270   0.569018   1.579521   0.257786   2.927854   1.766532
##                     U95%     
## rate                       NA
## as.factor(grade)2    1.877295
## as.factor(agecat)2   4.379475
## as.factor(agecat)3   7.038471
## as.factor(agecat)4   7.850399
## as.factor(agecat)5  27.118216
## as.factor(fuband)3   3.016545
## as.factor(fuband)4   3.526812
## as.factor(fuband)5   4.852630
## 
## N = 6167,  Events: 154,  Censored: 6013
## Total time at risk: 27605.371
## Log-likelihood = -904.07753, df = 9
## AIC = 1826.1551</code></pre>
<p>我們用指數分布回歸擬合的生存時間模型，其實還可以用泊鬆回歸模型來做，結果也是一樣的:</p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1099-1" title="1">whl.poi &lt;-<span class="st"> </span><span class="kw">glm</span>(chd <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(grade), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">offset =</span> <span class="kw">log</span>(time), <span class="dt">data =</span> whitehall)</a>
<a class="sourceLine" id="cb1099-2" title="2"><span class="kw">summary</span>(whl.poi)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = chd ~ as.factor(grade), family = poisson(link = log), 
##     data = whitehall, offset = log(time))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.58433  -0.41268  -0.40212  -0.39440   3.55361  
## 
## Coefficients:
##                   Estimate Std. Error  z value   Pr(&gt;|z|)    
## (Intercept)       -5.42052    0.10541 -51.4238  &lt; 2.2e-16 ***
## as.factor(grade)2  0.68850    0.16351   4.2108 0.00002545 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 947.906  on 1676  degrees of freedom
## Residual deviance: 931.144  on 1675  degrees of freedom
## AIC: 1243.14
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>你可以回頭去和指數分布回歸的模型結果做個比較，他們的回歸系數估計和標準誤完全是一樣的。</p>
</div>
</div>
<div id="cox-比例風險模型" class="section level1">
<h1><span class="header-section-number">第 74 章</span> Cox 比例風險模型</h1>
<p><span class="math display">\[
h(t|x) = h_0(t)e^{\beta^Tx}
\]</span></p>
<p>其中，<span class="math inline">\(h_0(t)\)</span> 是被比較的基線組成員(baseline individual)的風險度 (hazard)，在 Weibull 模型或者指數模型中，這個基線風險 (baseline hazard) 是需要被模型根據數據來進行參數估計的 (parameterized)。但是，1972年，神一樣的人物 Cox <span class="citation">(Cox <a href="#ref-Cox1972b" role="doc-biblioref">1972</a>)</span> 提出，其實我們不需要對這個基線風險進行“無謂”的估計，可以無視它在模型中的存在。正因為如此，這個模型被冠以發明者的名字 Cox proportional hazards model。因為此模型不對基線風險進行任何估計，但是對預測變量對於風險的效果 (effect of the explanatory variable) 用模型中的 <span class="math inline">\(\beta\)</span> 進行參數估計，所以，它又是一種典型的半參數化模型 (semi-parametric model)。</p>
<p>Cox 比例風險模型下的似然：</p>
<p><span class="math display">\[
L= \prod_{i=1}^n\{ h_0(t)e^{\beta^Tx_i}\exp(-\int_0^{t_i} h_0(u)e^{\beta^Tx_i}du) \}^{\delta_i}\{ \exp(-\int_0^{t_i} h_0(u)e^{\beta^Tx_i}du) \}^{1-\delta_i}
\]</span></p>
<p>是無法估計的，此時要用到偏似然 (partial likelihood)，</p>
<p>思考這樣一個問題，在一組用 <span class="math inline">\(R_j\)</span> 標記的患者集合中，當我們已知它們同時都存活到了時間點 <span class="math inline">\(t_j\)</span>，且沒有發生刪失，那麼這組患者中的某個 <span class="math inline">\(i_j\)</span>，他/她有一個解釋變量 <span class="math inline">\(x_i\)</span>，他在這個時間點恰好發生事件的條件概率該怎麼計算：</p>
<p><span class="math display">\[
\frac{h_0(t_j)\exp(\beta^Tx_{i_j})}{\sum_{k\in R_j}h_0(t_j)\exp(\beta^Tx_k)} = \frac{\exp(\beta^Tx_{i_j})}{\sum_{k\in R_j}\exp(\beta^Tx_k)}
\]</span></p>
<p>是的，你沒有看錯，基線風險被完美的消除掉了，這就是它不需要被參數估計的原因。此時，我們用偏似然來計算這樣的模型似然：</p>
<p><span class="math display">\[
L_p = \prod_j \frac{\exp(\beta^Tx_{i_j})}{\sum_{k\in R_j}\exp(\beta^Tx_k)}
\]</span></p>
<p>模型的假設：</p>
<p><span class="math display">\[
h(t|x) = h_0(t)e^{\beta^Tx}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Proportional hazards assumption - explanatory variables act <strong>multiplicatively</strong> on the hazard and their effect on the hazard does not change over time;</li>
<li>We have correctly specified the form for how continuous explanatory variables act on the hazard;</li>
<li>We have included all relevant explanatory variables including possbile interactions;</li>
<li>Uninformative censoring;</li>
<li>Individuals are independent.</li>
</ol>
<div id="該用半參數模型還是用全參數模型" class="section level2">
<h2><span class="header-section-number">74.1</span> 該用半參數模型還是用全參數模型</h2>
<ul>
<li>如果說指數模型或者 Weibull 模型是合理的，通常此時用 Cox 半參數模型也是合理的；</li>
<li>如果指數模型或者 Weibull 模型都是合理的，那麼 Cox 半參數模型給出的估計，其實不會和指數模型或者 Weibull 模型相差甚遠。指數模型或者 Weibull 模型可能給出的估計會相對更精確 (更小的標準誤)，但是實際應用中這種更加精確的程度其實十分有限；</li>
<li>另外，使用指數模型或者 Weibull 模型，重要的基線風險是否被模型擬合正確將會是關鍵 (baseline hazard mis-specified?)，但是使用 Cox 模型，就可以避免這個假設，忽略掉基線風險；</li>
<li>2002 年，<span class="citation">(Royston and Parmar <a href="#ref-Royston2002" role="doc-biblioref">2002</a>)</span> 提出第三種生存數據模型，“flexible parametric survival models”，結合了參數和半參數模型的長處，正在變得流行起來。在這個新型靈活參數生存模型中，使用了三次方程平滑曲線 (cubic splines modelled smoothly) 擬合對數基線累積風險 (log cumulative baseline hazard)。</li>
</ul>
</div>
</div>
<div id="分析策略和模型檢查-model-checking-survival-analysis" class="section level1">
<h1><span class="header-section-number">第 75 章</span> 分析策略和模型檢查 Model checking-survival analysis</h1>
<div id="生存分析策略" class="section level2">
<h2><span class="header-section-number">75.1</span> 生存分析策略</h2>
</div>
<div id="針對臨床實驗" class="section level2">
<h2><span class="header-section-number">75.2</span> 針對臨床實驗</h2>
</div>
<div id="針對觀察性研究" class="section level2">
<h2><span class="header-section-number">75.3</span> 針對觀察性研究</h2>
</div>
<div id="模型檢查的要點" class="section level2">
<h2><span class="header-section-number">75.4</span> 模型檢查的要點</h2>
<ol style="list-style-type: decimal">
<li>總體模型對數據的擬合情況是否合理？</li>
<li>是否有極端數據，影響了模型的擬合結果？</li>
<li>解釋變量，特別是連續型變量是否以正確的形式進入了模型？</li>
</ol>
</div>
<div id="比例風險假設的檢查-check-the-proportional-hazard-assumtion" class="section level2">
<h2><span class="header-section-number">75.5</span> 比例風險假設的檢查 check the proportional hazard assumtion</h2>
<p>主要有三板斧：</p>
<ol style="list-style-type: decimal">
<li>用非參數法繪製簡單的生存曲線圖；</li>
<li>用統計檢驗，判斷一個解釋變量對風險的影響是否和時間產生了交互作用；</li>
<li>殘差繪圖法。</li>
</ol>
<p>非參數法繪製生存曲線圖詳見第 @ref{nonparametric} 章節部分。</p>
<div id="比例風險檢查的統計檢驗法" class="section level3">
<h3><span class="header-section-number">75.5.1</span> 比例風險檢查的統計檢驗法</h3>
<p>在滿足比例風險前提下，某個解釋變量估計的風險比 (hazard ratio) 不會隨著時間變化而變化，根據這個特點，我們可以認為，如果某些解釋變量在追踪開始時對風險影響很強，在之後的追踪中，和風險之間的關係變弱的話，(或者反過來)，那麼風險比的這一變化就違背了比例風險這一前提。最簡單的，我們可以在模型中加入該變量和時間的相乘項 (交互作用項)：</p>
<p><span class="math display">\[
h(t|x) = h_0(t)\exp\{ \beta x + \gamma (x\times t)\}
\]</span></p>
<p>聰明的你一下子就明白了，接下來只要檢驗 <span class="math inline">\(H_0: \gamma = 0\)</span>:</p>
<p><span class="math display">\[
\frac{\hat\gamma}{SE(\hat\gamma)} \sim N(0,1)
\]</span></p>
</div>
<div id="用-schoenfeld-殘差繪圖" class="section level3">
<h3><span class="header-section-number">75.5.2</span> 用 Schoenfeld 殘差繪圖</h3>
<p>另外一種視覺化檢查比例風險假設的方法是使用 <strong>Schoenfeld 殘差</strong>：</p>
<p>The residual compares the observed values of the explanatory variable for the case at a given envent time with the weighted average of the explanatory variable in the risk set. The residuals should not show any dependence on time – this would indicate that the proportional hazards assumptions is not met.</p>
<p>It is actually more convenient to use the “scaled Schoenfeld residuals”. <strong>The Scaled Schoenfeld residuals have a mean which is the true log hazard ratio</strong> under the proportional hazards assumption, and the average values of the scaled Schoenfeld residuals over time can be interpreted as the time-varying log-hazard ratio. A plot of the scaled Schoenfeld residuals over time is therefore directly informative about how the log hazard ratio changes overtime. It is useful to show a smoothed average curve on these plots.</p>
</div>
</div>
<div id="評價模型擬合的其他有趣方法" class="section level2">
<h2><span class="header-section-number">75.6</span> 評價模型擬合的其他有趣方法</h2>
<div id="martingale-殘差-assessing-the-functional-form-of-continuous-variables" class="section level3">
<h3><span class="header-section-number">75.6.1</span> Martingale 殘差-assessing the functional form of continuous variables</h3>
<p>Martingale (馬丁哥?) 殘差圖可以用來檢驗，比較連續型變量在模型中是否被正確擬合，因為有時候連續型變量需要增加該連續型變量的二次項或者多次項，也可能要用對數項之類的變形之後，才能完全把其與生存數據之間的關係完全解釋清楚。</p>
<p>A Martingale is a residual for an event process – it is the difference between what happened to a person (whether they had the event or not) and what is predicted to happen to a person under the model that has been fitted. The Martingale residual for individual i is:</p>
<p><span class="math display">\[
r_{M_i} = \delta_i - \hat H_0(t_i)\exp(\hat\beta x_i)
\]</span></p>
<p>Where, <span class="math inline">\(\delta_i\)</span> is the indicator of whether the individual <span class="math inline">\(i\)</span> had the event (1) or was censored (0), <span class="math inline">\(t_i\)</span> is the event or censoring time, <span class="math inline">\(x_i\)</span> denotes the explanatory variable (or more generally a vector of explanatory variables), and <span class="math inline">\(\hat H_0(t_i)\)</span> is the estimated baseline cumulative hazard at time <span class="math inline">\(t_i\)</span>. If the model is correct then the Martingale residuals should sum to 0.</p>
</div>
<div id="deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit" class="section level3">
<h3><span class="header-section-number">75.6.2</span> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</h3>
<p>偏差殘差是馬丁哥殘差的轉換值，它的定義是:</p>
<p><span class="math display">\[
r_{D_i} = \text{sign}(r_{M_i})[-2\{r_{M_i} + \delta_i\log(\delta_i - r_{M_i})\}]^{\frac{1}{2}}
\]</span></p>
<p>偏差殘差通過上面的公式，把模型給出的馬丁哥殘差轉換成為一組理論上應該是平均分佈在零兩側的數據。如果某個個體的偏差殘差過大，偏離0太遠的話，提示該模型對該個體數據擬合不佳。具體來說，如果偏差殘差遠大於零，提示的是該個體遠在模型預測他/她/它會發生事件的時間之前就已經發生了事件；相反如果偏差殘差遠小於零，則提示該個體在模型預測發生事件的時間點之後很晚才真的發生事件。</p>
<p>把偏差殘差作 Y 軸，危險度評分 (risk score <span class="math inline">\(=\beta^Tx\)</span>)，作 x 軸繪圖可以用於分析模型是否針對某些危險度高的人給出較高的偏差殘差，從而可以判斷模型是否合理。當判斷某些人可能偏差殘差過大，或者過小，之後要做的決定才是殘忍的，你要從數據中刪除這些個體？還是分析這些個體到底有哪些與眾不同的特質？或者是要重新對模型的各項解釋變量的形式進行修正？</p>
<p><strong>在進行生存分析的時候，請一定要一邊構建模型，一邊用這些殘差來綜合分析模型的合理性。</strong></p>
</div>
</div>
</div>
<div id="競爭風險模型-competing-risk" class="section level1">
<h1><span class="header-section-number">第 76 章</span> 競爭風險模型 competing risk</h1>
<p>當我們在做風險模型研究的時候，除了重要的比例風險假設，另外一個 (經常被忘記的) 假設是我們認為<strong>刪失值只是一堆無效信息 (non-informative censoring)</strong>。這個假設通常來說都是合理的，但是如果某些刪失值是由於他們身上發生了別的事件，導致無法追踪或者無法再發生我們關心的事件。這樣的現象被叫做競爭風險 (competing risk)。最明顯的例子是我們關心某些疾病(心血管疾病，癌症)的發生，但是患者可能提前因為別的原因 (事故或者別的原因) 死亡而離開研究。這些離開研究的人，假如沒有死亡，繼續留在研究中，他們還是有可能會發生研究關心的事件的。那麼此時，我們說死亡事件，是一個疾病發生的競爭風險。</p>
<div id="cause-specific-hazard" class="section level2">
<h2><span class="header-section-number">76.1</span> Cause-specific hazard</h2>
<p>如果，我們認為研究中存在 <span class="math inline">\(k\)</span> 種“事件(event/failure)”，我們可以定義這樣的因素別風險方程 (cause-specific hazard function):</p>
<p><span class="math display">\[
h_k(t) = \lim_{\delta t \rightarrow 0} \frac{1}{\delta t}\text{Pr}\{ t\leqslant T &lt; t + \delta t, D = k | T\geqslant t  \}
\]</span></p>
<p>這可以被定義為在時間點 <span class="math inline">\(t\)</span>，該對象發生事件 <span class="math inline">\(k\)</span> 的瞬間風險。(This can be interpreted as the instantaneous risk of dying from cause <span class="math inline">\(k\)</span> given the individual is alive at time <span class="math inline">\(t\)</span>. i.e. they have not died of any cause before time <span class="math inline">\(t\)</span>)</p>
<p>(Cumulative cause-specific hazard)累積因素別風險方程則可以被定義為：</p>
<p><span class="math display">\[
H_k(t) = \int_0^t h_k(s)ds
\]</span></p>
<p>相應地，生存方程：</p>
<p><span class="math display">\[
S_k(t) = \exp(-H_k(t))
\]</span></p>
<p>Overall hazard is the sum of all cause-specific hazards:</p>
<p><span class="math display">\[
\begin{aligned}
h(t) &amp; = \sum_{e=1}^K \lim_{\delta t\rightarrow 0} \frac{1}{\delta t}\text{Pr}\{ t\leqslant T &lt; t + \delta t, D = e | T\geqslant t  \} \\
     &amp; = \lim_{\delta t \rightarrow 0} \frac{1}{\delta t}\text{Pr}\{ t\leqslant T &lt; t + \delta t | T \geqslant t  \}
\end{aligned}
\]</span></p>
<p>It follows that the overall survival can be written as useful application of this cause-specific survivor function:</p>
<p><span class="math display">\[
S(t) = \exp[-\sum_{e=1}^KH_e(t)] = \prod_{e = 1}^K \exp(-H_e(t))
\]</span></p>
<div id="cause-specific-hazards-models" class="section level3">
<h3><span class="header-section-number">76.1.1</span> Cause-specific hazards models</h3>
<p><span class="math display">\[
h_k(t|x) = h_{k, 0} (t)e^{\beta_k x}
\]</span></p>
<ul>
<li>People are censored at the time of any event that is not the event of interest</li>
<li>We fit a separate Cox model for each event type</li>
<li><span class="math inline">\(\beta_k\)</span> represents the impact of <span class="math inline">\(x\)</span> on the hazard for event type k,** among those at risk of event type k**</li>
</ul>
</div>
</div>
<div id="cumulative-incidence-function" class="section level2">
<h2><span class="header-section-number">76.2</span> Cumulative incidence function</h2>
<p>Other names: absolute cause-specific risk/Crude Probabilty of event</p>
<p><span class="math display">\[
I_k(t) = \int_0^t h_k(s)S(s)ds
\]</span></p>
</div>
<div id="subdistribution-hazard---fine-and-gray-model" class="section level2">
<h2><span class="header-section-number">76.3</span> Subdistribution hazard - Fine and Gray model</h2>
<p>The approach uses an alternative definition of the hazard, called the subdistribution hazard, which represents the instantaneous risk of dying from cause k given that an individual has not already died from cause k, that is:</p>
<p><span class="math display">\[
h^s_k(t) = \lim_{\delta t \rightarrow 0} \frac{1}{\delta t} \{ \text{Pr}(t \leqslant T &lt; t + \delta t, K = k | T &gt; t \text{ or } (T \leqslant t, K \neq k)) \}
\]</span></p>
<p>This differs from the cause-specific hazard in its risk set; here individuals are not removed from the risk set if they die from another competing cause of death than cause k.</p>
<div id="subdistribution-hazard-model" class="section level3">
<h3><span class="header-section-number">76.3.1</span> Subdistribution hazard model</h3>
<p><span class="math display">\[
h_k^s(t) = -\frac{d}{dt} \log(1 - I_k(t))
\]</span></p>
<p><span class="math display">\[
h_k^s(t|x)  = h_{0,k}(t)e^{\beta^T_k x}
\]</span></p>
<p>The relationsship between the CIFs in the two treatment groups is given by:</p>
<p><span class="math display">\[
1 - I_k(t|1) = [1 - I_k(t|0)]^{\exp(\beta_kx)}
\]</span></p>
</div>
</div>
<div id="multi-state-models" class="section level2">
<h2><span class="header-section-number">76.4</span> Multi-state models</h2>
<div id="the-markov-model" class="section level3">
<h3><span class="header-section-number">76.4.1</span> The Markov model</h3>
<p>A common assumption for multi-state mode is that upon entering a particular state i, individuals are subject to common trasition rate for movement to state j, irrespective of their history. In other words, we assume that the transition rate does not differ according to the previous states an individual has been in. This is called the Markov assumption, and is often quite a strong assumption to make.</p>
</div>
<div id="cox-proportional-hazards-model-for-transition-intensities" class="section level3">
<h3><span class="header-section-number">76.4.2</span> Cox proportional hazards model for transition intensities</h3>
<p>The transition intensities for transition i to j is given by:</p>
<p><span class="math display">\[
h_{ij} (t | x) = h_{ij,0} (t)\exp(\beta_{ij}^Tx)　
\]</span></p>
</div>
</div>
</div>
<div id="生存分析的其他手段" class="section level1">
<h1><span class="header-section-number">第 77 章</span> 生存分析的其他手段</h1>
<div id="分層cox生存分析-stratified-cox-proportional-hazards-model" class="section level2">
<h2><span class="header-section-number">77.1</span> 分層Cox生存分析 stratified Cox proportional hazards model</h2>
<p>Under the Cox proportional hazards model, the effect of each explanatory variable on the hazard is assumed to be such that the ratio of hazards is constant accross the time scale (the proportional hazards assumption). In applications with several explanatory variabls, the effect of some of these variables may not be proportional. When the aim of the analysis is not focussed on these particular variables, for example if they are just being used as adjustment variables and are not the main exposures of interest, then the proportionality assumption can be relaxed just for those variables by fitting a stratified Cox proportional hazards model.</p>
<p>In the stratified Cox proportional hazards model, instead of assuming that the proportional hazards model holds overall, we assume that the proportional hazards assumption holds within groups (or strata) of individuals.</p>
<p><span class="math display">\[
h(t|x,s) = h_{0s} (t)e^{\beta^T x}
\]</span></p>
<p>Each stratum, s, has a separate baseline hazard <span class="math inline">\(h_{0s}(t)\)</span>. However, the other explanatory variables x are assumed to act in the same way on the baseline hazard in each stratum, i.e. the <span class="math inline">\(\beta\)</span> are the same accross strata.</p>
</div>
<div id="加速失效模型-accelerated-failure-time-aft-model" class="section level2">
<h2><span class="header-section-number">77.2</span> 加速失效模型 Accelerated failure time (AFT) model</h2>
<p>加速失效模型，AFT 模型的特點是不管所謂的風險概念，而是對每個患者真正的生存時間進行模型化處理，其實個人更加喜歡這個模型，因為它很直觀地告訴你某類人的生存時間就是比另一類人短，而不是告訴你一個抽象的一組的風險低於或者高於另一組，因為很多人無法理解什麼是風險 (hazard)，正如很多人無法理解什麼是比值 (odds) 一樣。同樣還因為風險比例模型還要考慮是否對基線風險進行參數估計的取捨問題。</p>
<p>所以，風險比例模型：</p>
<p><span class="math display">\[
h_1(t) = \psi_{PH}h_0(t)
\]</span></p>
<p>AFT 模型：</p>
<p><span class="math display">\[
T_1 = \psi_{AFT}T_0
\]</span></p>
<p>在 AFT 模型中，<span class="math inline">\(\psi_{AFT}\)</span> 就是加速指數，它的直接涵義就是，治療組患者的死亡時間被“加速”或者“減緩”了。也就是它可以回答，治療組的患者是不是更快的痊癒？或者更快的死亡？這樣明了的問題。</p>
<p>通常情況下，這個加速指數用 <span class="math inline">\(e^{-\beta_{AFT}}\)</span> 進行參數化分析：</p>
<p><span class="math display">\[
T_1 = T_0 e^{-\beta_{AFT}}
\]</span></p>
<p>寫下此時的生存方程，和基線組生存方程的關係：</p>
<p><span class="math display">\[
\begin{aligned}
S_1(t) &amp; = \text{Pr}(T_1 &gt; t) \\
       &amp; = \text{Pr}(e^{-\beta_{AFT}}T_0 &gt; t) \\
       &amp; = \text{Pr}(T_0 &gt; te^{\beta_{AFT}}) \\
       &amp; = S_0(e^{\beta_{AFT}}t)
\end{aligned}
\]</span></p>
<div id="weibull-模型也是一種-aft-模型" class="section level3">
<h3><span class="header-section-number">77.2.1</span> Weibull 模型也是一種 AFT 模型</h3>
<p>一個 Weibull 模型在風險比例前提下的生存方程是：</p>
<p><span class="math display">\[
S(t|x) = \exp\{-\lambda e^{\beta_{PH}x} t^\kappa \}
\]</span></p>
<p>一個 Weibull 模型在 AFT 模型下的生存方程是：</p>
<p><span class="math display">\[
S(t|x) = \exp \{ -\lambda e^{\kappa \beta_{AFT}x} t^\kappa \}
\]</span></p>
<p>所以當你用 Weibull 模型時，其實可以自由在兩種類型 (PH or AFT) 之間自由切換：</p>
<p><span class="math display">\[
\exp(\beta^T_{PH}) = \exp(\kappa\beta^T_{AFT})
\]</span></p>
<p>所以，Weibull 模型和其特殊形態–指數模型，為唯二的兩個，可以在 PH 模型和 AFT 模型之間自由切換的模型。</p>
</div>
</div>
</div>
<div id="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model" class="section level1">
<h1><span class="header-section-number">第 78 章</span> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</h1>
<div id="時間依存變量指的是什麼" class="section level2">
<h2><span class="header-section-number">78.1</span> 時間依存變量指的是什麼</h2>
<p>生存分析的模型中，我們常常會使用一些實際上會經過時間變化而變化的預測變量。這些變量被稱爲時間依存型變量<em>(time-dependent variables)</em>。有些教科書會把這種類型的變量命名爲自更新變量(time-updated)或者時變變量(time-varying)。實際的例子有：</p>
<ul>
<li><p>某觀察型研究使用患者病例數據庫分析患有囊性肺纖維化(cystic fibrosis)的病人的生存情況。在病人數據庫隨訪收集數據的過程中，有些患者接受了肺部臟器的移植，有些患者沒有。那麼有沒有肺部臟器移植手術就是影響患者死亡率，或者說生存概率的重要指標之一。那麼這樣的模型中，是否接受過移植手術這一變量就是一個時間依存型變量。它的特徵除了是一個二分類變量以外，患者只能從 0（未接受移植）變成 1（接受過移植），而不能反過來。</p></li>
<li><p>某觀察型隊列研究的課題是分析研究對象的血壓水平和心臟疾病之間的關係。在隊列研究的隨訪中，研究對象的血壓可能在每次隨訪時都有相應的測量數據。在這樣的實驗情形下，每次隨訪獲得的血壓數據就是一個時間依存型的連續變量。</p></li>
</ul>
<p>時間依存型變量除了有二分類的，連續型的等等不同之外，它還有另外一個更加重要的性質需要考慮並且加以區分。這就是看我們想要討論的時間依存型變量的時間依存性質的來源，是內在性的(internal)還是外源性(external)的。</p>
<p>內在性的時間依存變量是指這個變量的隨時間的變化的特性是只能在觀察對象未發生我們所關心的事件（比如死亡事件）之前測量獲取的。而且這種內在性還體現在如果不與實驗對象取得聯繫的話，更新之後的數據研究者是無法得到的。比方說需要從仍然存活的患者身上提取血液樣本測量一些生物指標，比如是否接受過臟器移植，或者是最近的血壓值是多少等等。</p>
<p>外源性的時間依存變量是指這樣的變量雖然隨着時間變化，但是不需要通過聯繫患者或者實驗對象也能夠獲取想要的數據。年齡是最典型的一個例子，你只要知道患者在起始時的年齡，也就知道了在隨訪過程中患者的年齡。另外的常見外源性時間依存變量的例子還有如一些臨牀試驗中隨着患者病程的變化而按照事先準備或者計劃好的劑量調整治療方案。再比如研究空氣污染水平和患者哮喘之間關係的空氣污染水平數據，可以通過外來的如氣象局提供的歷史數據來查詢獲得。</p>
<p>這兩種類型的時間依存變量在進行數據分析的時候，常常不需要加以刻意的區分，但是在結果的解讀和解釋的時候就需要考慮這兩種不同類型的時間依存性質給分析結果帶來的影響。</p>
<p>在正式進入時間依存變量的數學模型之前，我們需要引入時間依存變量的數學標記方法。一般地，<span class="math inline">\(x\)</span>被用於表示預測變量，它可以是一個單一的變量，也可以是一個由許多預測變量組成的向量。在處理時間依存型變量的時候，我們通常使用 <span class="math inline">\(x(t)\)</span> 來表示。其含義就是在時間點 <span class="math inline">\(t\)</span> 時預測變量的值。如果 <span class="math inline">\(x(t)\)</span> 是一個向量，它可以同時表示時間依存型變量和其他的不隨時間變化而變化的變量。如果用 <span class="math inline">\(x(t)\)</span> 表示一個非時間依存型變量的話，它就表示無論時間 <span class="math inline">\(t\)</span> 是多少，<span class="math inline">\(x\)</span> 值的大小都始終保持不變。</p>
</div>
<div id="extended-cox-model-把cox模型擴展開去" class="section level2">
<h2><span class="header-section-number">78.2</span> Extended Cox model 把Cox模型擴展開去</h2>
<p>Cox比例風險模型是很容易被擴展，用來加入時間依存型預測變量。當Cox比例風險模型中加入了時間依存型變量，它的數學模型被寫作：</p>
<p><span class="math display">\[
h(t|x(t)) = h_0(t) e^{\beta^Tx(t)}
\]</span></p>
<p>這一數學模型其實是在說我們對該預測變量感興趣的是在時間點 <span class="math inline">\(t\)</span> 時的測量值是否和發生相關事件的風險(hazard)有關係。也就是在這個模型裏，時間依存變量的最新值，是我們關心的最主要預測變量。這裏的基線風險(baseline hazard, <span class="math inline">\(h_0(t)\)</span>)應該被解釋爲是一個所有的預測變量從起始直至所有追蹤結束時均爲零的觀察對象。[This formulation is assumed that we are interested in the explanatory variable at the time of the event of interest. In other words, it means that only the current value of the covariates (i.e. at time t) affects the hazard. Here, the baseline hazard function is interpreted as the hazard function for an individual for whom all the variables are zero (from the time origin and during all the follow-up).]</p>
<p>那麼這個模型的對數風險度比(log hazard ratios)又該怎麼理解呢？爲了便於解釋，先考慮只有一個時間依存型變量的模型 <span class="math inline">\(x_1(t)\)</span>。那麼對象編號爲 <span class="math inline">\(r\)</span> 和對象編號爲 <span class="math inline">\(s\)</span> 的兩人，他們之間的風險度比 (hazard ratio)：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{h(t|x_{1r}(t))}{h(t|x_{1s}(t))} &amp; = \frac{h_0e^{\beta_1x_{1r}(t)}}{h_0e^{\beta_1x_{1s}(t)}} \\
&amp; = \exp(\beta_1(x_{1r}(t) - x_{1s}(t)))
\end{aligned}
\]</span></p>
<p>所以，簡單地解釋就是，<span class="math inline">\(\beta_1\)</span> 比較的是<span class="math inline">\(r,s\)</span>兩個觀察對象的預測變量 <span class="math inline">\(x_1\)</span> 在任意一個時間點時相差一個單位時的風險度。值得指出的是，這裏回歸係數的解釋暗示了 <strong>時間依存變量<span class="math inline">\(x_1\)</span>在任意一個時間點時，改變一個單位的風險度比是固定不變的。</strong>但是，由於 <span class="math inline">\(x_{1r}(t) - x_{1s}(t)\)</span> 是會隨時間 <span class="math inline">\(t\)</span> 變化的（也就是風險度比不再是成固定比例的，而是允許它隨時間變化而發生改變）。這個Cox風險模型就不能再被叫做<strong>“比例”</strong>風險模型，它被叫做<strong>Cox擴展模型(extended Cox Model)</strong>。</p>
<div id="練習題-exercise-8.1" class="section level3">
<h3><span class="header-section-number">78.2.1</span> 練習題 exercise 8.1</h3>
<p>假設我們使用下面這樣的Cox擴展模型來研究關於肺部臟器移植與否的時間依存變量和死亡之間的關係：</p>
<p><span class="math display">\[
h(t|x) = h_0(t)\text{exp}(\beta x(t))
\]</span></p>
<p>如果患者<span class="math inline">\(r\)</span>在時間點5時進行了肺部的臟器移植，患者<span class="math inline">\(s\)</span>則整個隨訪中都沒有接受臟器移植。請試着計算下列時間點時兩名患者之間的死亡風險度比：</p>
<ol style="list-style-type: decimal">
<li>時間點4；</li>
<li>時間點6。</li>
</ol>
<p>（我們假設兩名患者在這兩個時間點時都依然還是存活着的）</p>
</div>
<div id="解答" class="section level3">
<h3><span class="header-section-number">78.2.2</span> 解答</h3>
<ol style="list-style-type: decimal">
<li>在時間點4時，兩名患者都沒有接受臟器移植，此時，他們的死亡風險度都是基線風險：<span class="math inline">\(h(t|x) = h_0(t)\)</span>，故在時間點4時，他們的死亡風險度比是 1。</li>
<li>在時間點6時，患者<span class="math inline">\(r\)</span>的風險度是：<span class="math inline">\(h(t|x) = h_0(t)\text{exp}(\beta)\)</span>。患者 <span class="math inline">\(s\)</span> 的風險度是：<span class="math inline">\(h(t|x) = h_0(t)\)</span>。所以，在時間點6時，患者<span class="math inline">\(r,s\)</span>之間的死亡風險度比就是 <span class="math inline">\(\text{exp}(\beta)\)</span>。</li>
</ol>
<hr />
<p>在Cox擴展模型下，加入了時間依存變量之後，模型所使用的偏似然(partial likelihood)是：</p>
<p><span class="math display">\[
L_p = \prod_j\frac{\text{exp}\beta^Tx_{i_j}(t_j)}{\sum_{k\in R_j}\text{exp}\beta^Tx_k(t_j)}
\]</span></p>
<p>在這個偏似然中，我們實際比較了在時間點 <span class="math inline">\(t_j\)</span> 時，實際觀察到的有發生事件的對象的預測變量 <span class="math inline">\(x_{i_j}(t_j)\)</span> 的風險度，和在時間點 <span class="math inline">\(t_j\)</span> 時仍然存在在觀察數據集合(the risk set at time <span class="math inline">\(t_j\)</span>)中的個體(假設人數爲 <span class="math inline">\(R_j\)</span>)的預測變量 <span class="math inline">\(x_k(t_j)\)</span>的風險度。這裏需要特別指出的是，當使用這個偏似然作爲估計的工具時，我們需要知道所有觀察對象，當他/她/它仍然處在觀察數據集合中的時候，每當有新的事件發生被觀察到，那每個新時間發生的時間點，模型中所有預測變量的最新值（包括時間依存變量本身）。這個假設對於二分類（是否接受移植臟器）時間依存變量來說不難，但是當時間依存變量是連續型變量的時候，要知道每一次事件發生時所有存在在觀察數據集合中每一名觀察對象的觀察值（例如血壓），是無法辦到的。這是因爲血壓值其實是時時刻刻都處在變化中的，但是我們實際對患者隨訪測量血壓時，都只能獲得患者在某個時間點上的血壓值。因此，這個Cox擴展模型中如果存在連續性的時間依存變量，那麼模型的另一個隱含的前提條件是，假設患者或者實驗對象的連續性時間依存變量在前後兩次測量值獲得的間隔期內是保持不變的（assuming that it stays constant from the last time it has been observed）。</p>
</div>
</div>
<div id="時間依存變量數據的結構" class="section level2">
<h2><span class="header-section-number">78.3</span> 時間依存變量數據的結構</h2>
<p>假設有一個隨時間變化而變化的二分類型解釋變量 <span class="math inline">\(x(t)\)</span>，假設有三名從時間點 0 開始參與其中的實驗對象：</p>
<ul>
<li>實驗對象1，她/他的 <span class="math inline">\(x(t)\)</span> 隨着時間沒有發生變化，在整個隨訪過程中都是 <span class="math inline">\(x(t) = 0\)</span>的狀態，在時間點10時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象2，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 5 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點20時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象3，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 15 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點25時該患者死亡 (event = 1)。</li>
</ul>
<p>用表格來說明這三人在追蹤隨訪過程中的狀態如下：</p>
<p>其中的實驗對象：</p>
<ul>
<li>實驗對象1，她/他的 <span class="math inline">\(x(t)\)</span> 隨着時間沒有發生變化，在整個隨訪過程中都是 <span class="math inline">\(x(t) = 0\)</span>的狀態，在時間點10時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象2，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 5 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點20時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象3，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 15 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點25時該患者死亡 (event = 1)。</li>
</ul>
<p>用表格來說明這三人在追蹤隨訪過程中的狀態如下：</p>
<p>其中的實驗對象：</p>
<ul>
<li>實驗對象1，她/他的 <span class="math inline">\(x(t)\)</span> 隨着時間沒有發生變化，在整個隨訪過程中都是 <span class="math inline">\(x(t) = 0\)</span>的狀態，在時間點10時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象2，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 5 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點20時該患者失去聯繫（刪失值，censor）。</li>
<li>實驗對象3，她/他的 <span class="math inline">\(x(t)\)</span> 在隨訪時間 15 之前均爲 <span class="math inline">\(x(t) = 0\)</span>，在該時間點之後 <span class="math inline">\(x(t) = 1\)</span>，在時間點25時該患者死亡 (event = 1)。</li>
</ul>
<p>用表格來說明這三人在追蹤隨訪過程中的狀態如下：</p>
<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:700px; ">
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:08-surv8-1">表 78.1: </span>Example data for individuals with time-dependent explanatory variable x(t). Each individual has a line of data for each time period over which the explanatory variables takes a different value. The status refers to whether the individual has the event (1) or not (0) at the end of the interval.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Individual
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Time.origin
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Start.time
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Stop.time
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
x.t.
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
status
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
</tbody>
</table>
</div>
<p>表格 <a href="#tab:08-surv8-1">78.1</a> 中時間區間其實是左開右閉的。所以2號實驗對象在時間段 <span class="math inline">\((0, 5]\)</span> 的 <span class="math inline">\(x(t) = 0\)</span>，但是在時間段 <span class="math inline">\((5, 20]\)</span> 時 <span class="math inline">\(x(t) = 1\)</span>。</p>
<p>實際研究數據的例子：</p>
<pre><code>## 
## 
## . use &quot;backupfiles/stanford.d. list in 1/10
## 
##      +-----------------------------------------------------------------+
##      | id   sex         dob      datein      datetr     dateout   dead |
##      |-----------------------------------------------------------------|
##   1. |  1     0   10jan1937   15nov1967           .   03jan1968      1 |
##   2. |  2     0   02mar1916   02jan1968           .   07jan1968      1 |
##   3. |  3     0   19sep1913   06jan1968   06jan1968   21jan1906      1 |
##   4. |  4     0   23dec1927   28mar1968   02may1968   05may1968      1 |
##   5. |  5     0   28jul1947   10may1968           .   27may1968      1 |
##      |-----------------------------------------------------------------|
##   6. |  6     0   08nov1913   13jun1968           .   15jun1968      1 |
##   7. |  7     0   29aug1917   12jul1968   31aug1968   17may1970      1 |
##   8. |  8     0   27mar1923   01aug1968           .   09sep1968      1 |
##   9. |  9     0   11jun1921   09aug1968           .   01nov1968      1 |
##  10. | 10     1   31jan1939   22feb1974   31mar1974   01apr1974      0 |
##      +-----------------------------------------------------------------+</code></pre>
<p>其中</p>
<ul>
<li><code>datein</code> 是該名患者加入實驗的日期；</li>
<li><code>datetr</code> 是該名患者接受心臟移植手術的日期（如果沒有接受手術則爲缺失值）；</li>
<li><code>dateout</code> 是患者離開實驗追蹤的日期（因爲死亡或者刪失）；</li>
<li><code>dead</code> 是實驗追蹤截止時患者的生存狀態（死亡１，刪失0）。</li>
</ul>
<p>爲了讓這個數據能夠進行 Cox 比例風險模型的擬合，在 Stata 中需要使用到 <code>stsplot</code> 命令，當患者在隨訪中曾經接受過心臟移植手術，那麼他/她的數據將被分成兩行，前一行是移植手術前，後一行則是移植手術後的數據。患者如果沒有接受心臟移植手術，她/他的數據就只有一行。</p>
<pre><code>## 
## 
## . use &quot;backupfiles/stanford.d. replace datetr = mdy(01, 01, 2001) if datetr == .
## (34 real changes made)
## 
## . 
## . stset dateout, id(id) origin(datein) scale(365.25) f(dead)
## 
##                 id:  id
##      failure event:  dead != 0 &amp; dead &lt; .
## obs. time interval:  (dateout[_n-1], dateout]
##  exit on or before:  failure
##     t for analysis:  (time-origin)/365.25
##             origin:  time datein
## 
## ------------------------------------------------------------------------------
##         103  total observations
##           3  multiple records at same instant                   PROBABLE ERROR
##              (dateout[_n-1]==dateout)
##           2  observations end on or before enter()
##           1  observation begins on or after (first) failure
## ------------------------------------------------------------------------------
##          97  observations remaining, representing
##          97  subjects
##          72  failures in single-failure-per-subject data
##      86.793  total analysis time at risk and under observation
##                                                 at risk from t =         0
##                                      earliest observed entry t =         0
##                                           last observed exit t =  4.925394
## 
## . 
## . stsplit post = datetr, at(0)
## (64 observations (episodes) created)
## 
## . 
## . replace post = post+1
## (161 real changes made)
## 
## . 
## . list in 1/20
## 
##      +-----------------------------------------------------------------------+
##   1. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  1 |   0 | 10jan1937 | 15nov1967 | 01jan2001 | 03jan1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      2875    |   .13415469    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   2. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  2 |   0 | 02mar1916 | 02jan1968 | 01jan2001 | 07jan1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      2923    |   .01368925    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   3. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  4 |   0 | 23dec1927 | 28mar1968 | 02may1968 | 02may1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3009    |   .09582478    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   4. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  4 |   0 | 23dec1927 | 28mar1968 | 02may1968 | 05may1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3009    |   .10403833    |   .09582478    |       1    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   5. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  5 |   0 | 28jul1947 | 10may1968 | 01jan2001 | 27may1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3052    |   .04654346    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   6. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  6 |   0 | 08nov1913 | 13jun1968 | 01jan2001 | 15jun1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3086    |    .0054757    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   7. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  7 |   0 | 29aug1917 | 12jul1968 | 31aug1968 | 31aug1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3115    |   .13689254    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   8. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  7 |   0 | 29aug1917 | 12jul1968 | 31aug1968 | 17may1970 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3115    |   1.8453114    |   .13689254    |       1    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##   9. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  8 |   0 | 27mar1923 | 01aug1968 | 01jan2001 | 09sep1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3135    |   .10677618    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  10. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      |  9 |   0 | 11jun1921 | 09aug1968 | 01jan2001 | 01nov1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3143    |   .22997947    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  11. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 10 |   0 | 20may1928 | 13sep1967 | 01jan2001 | 18sep1967 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      2812    |   .01368925    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  12. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 11 |   0 | 22aug1920 | 15aug1968 | 09sep1968 | 09sep1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3149    |   .06844627    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  13. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 11 |   0 | 22aug1920 | 15aug1968 | 09sep1968 | 14jan1969 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3149    |   .41615332    |   .06844627    |       1    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  14. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 12 |   0 | 09jul1915 | 17sep1968 | 01jan2001 | 24sep1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3182    |   .01916496    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  15. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 13 |   0 | 22feb1914 | 19sep1968 | 05oct1968 | 05oct1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3184    |   .04380561    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  16. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 13 |   0 | 22feb1914 | 19sep1968 | 05oct1968 | 08dec1968 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3184    |   .21902806    |   .04380561    |       1    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  17. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 14 |   0 | 16sep1914 | 20sep1968 | 26oct1968 | 26oct1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3185    |   .09856263    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  18. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 14 |   0 | 16sep1914 | 20sep1968 | 26oct1968 | 07jul1972 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3185    |   3.7946612    |   .09856263    |       1    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  19. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 16 |   0 | 16may1919 | 26oct1968 | 22nov1968 | 22nov1968 |    . |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    0    |      3221    |   .07392197    |           0    |       0    |
##      +-----------------------------------------------------------------------+
## 
##      +-----------------------------------------------------------------------+
##  20. | id | sex |       dob |    datein |    datetr |   dateout | dead | _st |
##      | 16 |   0 | 16may1919 | 26oct1968 | 22nov1968 | 29aug1969 |    1 |   1 |
##      |----------------------------------------------------------+------------|
##      |   _d    |   _origin    |          _t    |         _t0    |    post    |
##      |    1    |      3221    |   .84052019    |   .07392197    |       1    |
##      +-----------------------------------------------------------------------+
## 
## . 
## . stcox post
## 
##          failure _d:  dead
##    analysis time _t:  (dateout-origin)/365.25
##              origin:  time datein
##                  id:  id
## 
## Iteration 0:   log likelihood = -283.80782
## Iteration 1:   log likelihood = -283.79628
## Iteration 2:   log likelihood = -283.79628
## Refining estimates:
## Iteration 0:   log likelihood = -283.79628
## 
## Cox regression -- Breslow method for ties
## 
## No. of subjects =           97                  Number of obs    =         161
## No. of failures =           72
## Time at risk    =   86.7926078
##                                                 LR chi2(1)       =        0.02
## Log likelihood  =   -283.79628                  Prob &gt; chi2      =      0.8792
## 
## ------------------------------------------------------------------------------
##           _t | Haz. Ratio   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##         post |   .9550011   .2889517    -0.15   0.879     .5277868    1.728022
## ------------------------------------------------------------------------------</code></pre>
<p>請問，經過Stata調整過後的數據中，<code>_t0, t, post, _d</code> 分別是什麼意義的數字？</p>
<ul>
<li><code>_t0</code> 是追蹤的時間起點，對於有接受心臟移植的患者來說，第二行的 <code>_t0</code> 是接受完移植手術後的時間起點；</li>
<li><code>t</code> 是生存時間，或者刪失值發生之前的時間；</li>
<li><code>_d</code> 是事件指示變量(event indicator)，對於有接受心臟移植的患者來說，她/他有兩行數據，第一行是手術前，第二行是手術後。當患者死亡(event = 1)，那麼那一行的 <code>_d = 1</code>，之前的每一行都是<code>0</code>。每名患者最多只有一行發生死亡事件；</li>
<li><code>post</code> 則是指示該行患者數據是處於心臟移植手術之前(<code>post = 0</code>)，還是之後(<code>post = 1</code>)。例如，第7名患者進入實驗的起點時間是1968年7月12日，她/他在1968年8月31日 (即0.13698245年之後)這天接受了心臟移植手術。所以在這兩個時間點之內是該患者的第一行數據，被記錄爲手術前 (<code>post = 0</code>)，這之後該患者又被持續追蹤到1970年5月17日，在這段時間內的數據是患者的第二行數據，被記錄爲手術後 (<code>post = 1</code>)；</li>
<li><code>stcox post</code> 的結果 <code>Haz. Ratio = 0.96, 95%CI: 0.528, 1.728</code>的涵義是，接受心臟手術之後，患者的死亡風險相比不接受心臟移植手術平均要低 4%，但是這個風險比 (HR)的 95%信賴區間是 (0.53, 1.73)，包含了零假設時的 1，所以數據分析的結果是心臟手術降低的死亡風險不能達到顯著性效果，沒有統計學意義。</li>
</ul>
<div id="值得注意的點" class="section level3">
<h3><span class="header-section-number">78.3.1</span> 值得注意的點</h3>
<ul>
<li>如果說我們感興趣的時間依存變量是外源性的 (external time-dependent variable)，那麼經典的條件風險 (conditional hazard) 和條件生存概率 (conditional survival)的關係仍然是有意義的：</li>
</ul>
<p><span class="math display">\[
S(t | x(u), u\leqslant t) = \text{exp}(-\int_0^t h_0(u)\text{exp}(\beta^Tx(u))du)
\]</span></p>
<ul>
<li><p>如果說時間依存變量本身是內源性的（internal time-dependent variable），那麼上面這個經典的條件風險和條件生存概率之間的關係就是沒有意義的了。因爲內源性的變量必須在患者生存的時候才能測量得到，如果你測量到了患者的時間依存變量就意味着該患者的生存概率是1。</p></li>
<li><p>另一個需要注意的點是在包括了時間依存變量的Cox比例風險模型中，當你加入了在暴露和結果的因果關係通路上的變量作爲共變量時，模型會變得不可解釋。舉例來說，如果治療心肌梗死的藥物是通過降低血壓來達到降低心肌梗死發生的概率的話，假設模型中調整的是跟隨時間發生變化的血壓作爲共變量，那麼這個模型中上升或者下降的血壓就會把治療效果給抵消掉(cancel out the treatment effect)。在這樣的場景設定中，血壓的變化本身是作爲主要暴露因素（治療與否）和主要結果因素（心肌梗死的發生概率）之間的媒介 (mediator)。</p></li>
</ul>
</div>
</div>
<div id="frailty-models-脆弱模型" class="section level2">
<h2><span class="header-section-number">78.4</span> Frailty Models (脆弱模型?)</h2>
<p>脆弱模型是時間事件數據的隨機效應模型。</p>
<p>Frailty models are random effects models for time-to-event data.</p>
<div id="individual-frailty-model" class="section level3">
<h3><span class="header-section-number">78.4.1</span> Individual frailty model</h3>
<p><span class="math display">\[
h_i(t|x_i) = \alpha_ih(t|x_i) = \alpha_i h_0(t)\exp(\beta^Tx_i)
\]</span></p>
</div>
<div id="application-to-a-weibull-model" class="section level3">
<h3><span class="header-section-number">78.4.2</span> Application to a Weibull model</h3>
<p><span class="math display">\[
h(t|x_i,\alpha_i) = \alpha_i \kappa \lambda t^{\kappa - 1}e^{\beta^Tx}
\]</span></p>
</div>
<div id="shared-frailty-model" class="section level3">
<h3><span class="header-section-number">78.4.3</span> Shared frailty model</h3>
<p><span class="math display">\[
h(t|x_{ij}, \alpha_i) = \alpha_j h_0(t)e^{\beta^Tx_{ij}}
\]</span></p>
</div>
</div>
</div>
<div id="時間事件數據的高級分析法" class="section level1">
<h1><span class="header-section-number">第 79 章</span> 時間事件數據的高級分析法</h1>

</div>



<div id="爲什麼我們要用貝葉斯統計學方法" class="section level1">
<h1><span class="header-section-number">第 80 章</span> 爲什麼我們要用貝葉斯統計學方法？</h1>
<blockquote>
<p>Everybody is a Bayesian. It’s just that some know it, and some don’t.</p>
<p>– Trivellore Raghunathan</p>
</blockquote>
<p>統計學模型 (理論)，結合現實的數據 (實踐)，才能讓我們深刻地理解這個世界，既能檢驗我們的理論，又能從中找出規律性，爲一些現象做出總結和結論。如果說這個理論和實踐相結合的過程有類別之分，那麼最大的兩個類別區分就是: 概率論，和貝葉斯理論。</p>
<p>試從一個醫生的角度來思考他推斷一個患者疾病的過程: 門診中，有個患者因爲身患多種症狀前來就醫，他/她自己可能<strong>認爲自己</strong>患了某種疾病。你作爲接診的醫生，在思考和推斷患者是否患有他/她所認爲的那種疾病時，你的思考會建立在如下的前提 (prior view) 之上: 你觀察到的患者症狀，患者的家族病史，會帶來相同症狀的不同疾病的鑑別診斷。接下來，你可能讓該患者去做一些具體的生理生化，影像或者病理學檢查 (收集相應的數據)。接下來，你收到了該患者的生理生化檢查結果，影像報告和病理學報告，在看了這些報告 (分析獲得的數據) 過後，你重新再對患者到底是否患上該種疾病進行評估，獲得你心中認可的，他/她患有該疾病的概率 (updates their prior in light of the data to get a posterior view on whether the patient has the disease)。當然，更加常見的情況是，你看了這些初步報告之後，可能又讓該患者進一步做一些確診性質的檢查，用於輔助診斷。<strong>可能你還沒意識到，這個思考過程，就是一個十分典型的貝葉斯方式的推理。</strong></p>
<p>在上面的醫生給患者做診斷的例子中，醫生診斷的過程，其實就是在評估該特定患者患有某種疾病的概率。很顯然不同的醫生可能會給出不同的概率 (=不同的診斷)，這個概率，其實是一個主觀概率 (subjectively)。每個醫生給出的概率大小，其實是他/她自己對於給定了相應的數據 (患者主訴，檢查報告) 之後對於該患者患有該疾病的可能性的度量。(The size of the probability represents the physician’s degree of belief about the occurence of an event, i.e. their own personal assessment of how likely an event is, based on the evidence available to them.) 這樣的主觀概率，你是否也認爲它比起概率論者常說的概率更加接近我們平時常說的 “概率” 的概念呢？ (概率論者的“概率”: 一個事件發生的概率，等於在無數次相同的實驗中，該事件發生次數所佔的比例)。所以這個貝葉斯方式的主觀概率，其實是因人而異的 (其屬性在於人)，而非所謂的客觀現象 (not the phenomenon of interest)。所以，主觀概率是貝葉斯統計學的最基礎思維方式。</p>
<p>下面我們用兩個例子，來闡述貝葉斯和概率論兩種統計學思維所展示的不同。第一個來自論文 <span class="citation">(Johnson et al. <a href="#ref-johnson2009shifting" role="doc-biblioref">2009</a>)</span>，該論文中，作者使用了貝葉斯統計方法重新分析了使用概率論方法分析過的一個臨牀隨機試驗的結果。第二個例子來自於 <span class="citation">(Spiegelhalter, Abrams, and Myles <a href="#ref-spiegelhalter2004bayesian" role="doc-biblioref">2004</a>)</span>，叫做 GREAT 的隨機臨牀試驗。</p>
<div id="氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效" class="section level2">
<h2><span class="header-section-number">80.1</span> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</h2>
<div id="背景資料-ssc-trial" class="section level3">
<h3><span class="header-section-number">80.1.1</span> 背景資料-SSc trial</h3>
<p>該臨牀試驗 (RCT) 的設定是這樣的，兩組患者，一組是新療法 (氨甲喋呤)，一組是安慰劑 (或者標準療法)。在一個傳統的概率論者的框架底下，分析這樣一個RCT試驗數據的人最有可能進行的分析步驟如下:</p>
<ol style="list-style-type: decimal">
<li>建立一個所謂的零假設 (歸零假設), null hypothesis: 氨甲喋呤對於系統性硬皮病的治療是無效的。</li>
<li>確定一個和零假設互補的替代假設。</li>
<li>設定 0.05 (或者 5%) 作爲假陽性出現概率，也就是 type I error。</li>
<li>通過模型計算，報告 p 值。</li>
</ol>
<p>那麼，當報告中的 p 值 <span class="math inline">\(&gt; 0.05\)</span> 時，大多數蠢蠢欲動的醫生和研究者可能就會下結論說: “我們沒有找到足夠的證據來拒絕零假設”。事實真的是這樣子嗎？更糟糕的是，許多這樣的臨牀試驗可能會被打上 “negative (消極結果)” 的標籤，然後經過很多年以後大家都認爲這個RCT就被總結成了類似 “氨甲喋呤無效”，或者 “氨甲喋呤不能治療系統性硬皮病”等結論在醫學界被傳播。要知道，類似系統性硬皮病這樣的稀少疾病，其實是很難找到足夠的患者數量進行臨牀試驗的。這些稀少疾病的臨牀試驗中，p 值 <span class="math inline">\(&gt; 0.05\)</span> 很可能只是反映了獲得數據的統計效能不足 (lack of power)，並不一定就說明了藥物或者療法是無效的。</p>
<p>系統性硬皮病是一種患病率極低的罕見疾病。目前沒有特效藥物治療該疾病，從而導致患者長期忍受疾病的折磨，生活品質因爲身體機能的下降而長期處在十分低下的水平。過去有兩個小型試驗報告了氨甲喋呤 (MTX) 可能在系統性硬皮病的治療中起到積極的效果，於是就有研究者組織了一個爲時一年的隨機雙盲臨牀試驗，對象是那些系統性硬皮病的早期患者。35名患者被隨機分配接受 MTX 治療，另外36名患者被分配至了安慰劑對照組。期間有一些患者中途退出了試驗，多數退出的患者的理由是，治療缺乏有效性。</p>
<p>MTX對系統性硬皮病的治療效果評價，使用了三個指標:</p>
<ol style="list-style-type: decimal">
<li>modified Rodnan skin score (MRSS) - 得分範圍: 0-78;</li>
<li>University of California Los Angeles (UCLA) skin score - 得分範圍 0-30;</li>
<li>Physician global assessment of overall disease activity (ODA) - 使用視覺模擬指標，評分範圍從 0 (無疾病) 至 10 (極爲嚴重疾病) 不等。</li>
</ol>
</div>
<div id="概率論者分析結果" class="section level3">
<h3><span class="header-section-number">80.1.2</span> 概率論者分析結果</h3>
<p>下圖 <a href="#fig:MTX">80.1</a>，是從論文 <span class="citation">(Johnson et al. <a href="#ref-johnson2009shifting" role="doc-biblioref">2009</a>)</span> 中節選出來的，該表格展示了典型的概率論者分析該臨牀試驗數據的結果，當時的分析中，只對最終完成試驗的患者的數據進行了分析。</p>
<div class="figure" style="text-align: center"><span id="fig:MTX"></span>
<img src="img/Selection_030.png" alt="Methotrexate in Seleroderma: results of a frequentist analysis" width="80%" />
<p class="caption">
圖 80.1: Methotrexate in Seleroderma: results of a frequentist analysis
</p>
</div>
<p>根據這個分析結果，概率論者報告了下面三個 p 值:</p>
<ol style="list-style-type: decimal">
<li>MRSS - 效果不顯著 (<span class="math inline">\(p \geqslant 0.05\)</span>);</li>
<li>UCLA - 效果不顯著 (<span class="math inline">\(p \geqslant 0.05\)</span>);</li>
<li>ODA - 有統計學意義的顯著效果 (<span class="math inline">\(p = 0.04\)</span>)。</li>
</ol>
<p>要知道，這個臨牀試驗，在設計的時候是計劃能夠通過它尋找 35% 或者以上的療效差異的。所以，任何小於 35% 的療效 (儘管在臨牀上很可能是有意義的) 在概率論的理論框架下都是無法被檢驗，或者沒有足夠的統計效能來檢驗的。於是概率論持有的研究者就此結果下了結論: 我們沒有找到足夠的證據來拒絕 “氨甲喋呤在治療系統性硬皮病上是無效的” 這一零假設。如此，過了一些時日，這個試驗的結論在醫學界漸漸就變成了 “氨甲喋呤不能治療系統性硬皮病”。</p>
<p>其實，概率論持有者下的結論，其真實的含義是: 如果，零假設 (“氨甲喋呤在治療系統性硬皮病上是無效的”) 是正確的，假如可以重複無數次相同的臨牀試驗 (每次都找來不同的各自獨立的系統性硬皮病早期患者)，那麼我們能觀察到和該次RCT試驗得到的試驗療效相同，甚至療效更加顯著的試驗出現的概率是大於 0.05 的。你爲這樣的結論，真的正面回答了你想知道的問題了嗎？</p>
<p>我認爲，更加能夠回答大衆或患者們所關心的關於這個試驗的醫學問題應該是，“當我們獲得且分析了試驗數據以後，氨甲喋呤對於系統性硬皮病治療有效的概率是多少 (what is the probability that the intervention is effective given the data?)”。貝葉斯統計學其實可以讓我們正式地，在數學模型上把已知的對於某個事件的知識包括進試驗獲得的數據及其模型當中去，從而計算這個新的治療方法在考慮了已知的醫學背景，及現有的試驗數據之後，它對於疾病的治療是有效的概率到底是多少。這才應是每一個臨牀試驗真正想要回答的最關鍵的問題。</p>
</div>
<div id="貝葉斯統計分析結果" class="section level3">
<h3><span class="header-section-number">80.1.3</span> 貝葉斯統計分析結果</h3>
<p>使用貝葉斯統計理論分析相同臨牀試驗數據的結果，我們從論文<span class="citation">(Johnson et al. <a href="#ref-johnson2009shifting" role="doc-biblioref">2009</a>)</span>截取來放在圖 <a href="#fig:MTXbayes">80.2</a> 中。在該圖中，可以看見作者除了對完成試驗的患者的數據進行分析，同時使用補全法補過缺失值後的數據分析結果也展示在 “imputing missing data” 這一列中。</p>
<div class="figure" style="text-align: center"><span id="fig:MTXbayes"></span>
<img src="img/Selection_031.png" alt="Methotrexate in Seleroderma: results of a Bayesian analysis" width="80%" />
<p class="caption">
圖 80.2: Methotrexate in Seleroderma: results of a Bayesian analysis
</p>
</div>
<p>貝葉斯統計分析的結果，直接且正面的回答了我們想知道的問題，那就是 MTX 到底對於治療系統性硬皮病這一疾病來說是不是有效的。從圖 <a href="#fig:MTXbayes">80.2</a> 中的表格，以及該論文中作者用貝葉斯多元模型分析的結果可以看到，貝葉斯模型推算的是 MTX 在使用三種不同指標進行療效評估時，MTX可以<strong>被認定爲有療效的概率</strong>。<span class="citation">(Johnson et al. <a href="#ref-johnson2009shifting" role="doc-biblioref">2009</a>)</span>報告說，有96%的可能性，在使用三種療效評估方法中的兩種或者以上來評估時，我們講看到 MTX 其實是可以改善系統性硬皮病的病情的 (也就是有效的)。</p>
<p>圖 <a href="#fig:MTXbayes">80.2</a> 中表格用的先驗概率是不明確的，沒有太多信息的先驗概率 (vague/flat prior)，其含義是:</p>
<ol style="list-style-type: decimal">
<li>所有可能的治療效果，不論大小，都被認爲有相似的先驗概率 (prior)。(every possible size of treatment effect considered equally likely a priori)</li>
<li>沒有太多信息的先驗概率意味着不提供太多的背景知識給模型。(no external information to current trial incorporated in analysis)</li>
</ol>
<p>但是，其實我們是有背景知識的，在做這個臨牀試驗之前，已經有兩個小型試驗告訴人們， MTX很有可能可以治療系統性硬皮病，這才導致研究者組織了這一次臨牀試驗。這兩個小型試驗的結果，被 <span class="citation">(Johnson et al. <a href="#ref-johnson2009shifting" role="doc-biblioref">2009</a>)</span> 轉換成爲含有信息的先驗概率 (informative prior)。</p>
<p>圖 <a href="#fig:MTXpriors">80.3</a> 展示的是，使用兩種先驗概率所計算的不同的後驗概率的結果之比較。左邊使用的是沒有信息的先驗概率 (flat, wide black prior distribution)，右邊則使用的是有信息的先驗概率。兩個圖中，黑色線均爲先驗概率，綠色線是似然 (來自本次實驗的數據)，紅色線是後驗概率。紅色的面積表示 MTX 在MRSS療效指標中支持其有效的概率，95%CrI是各自的可信區間。可見，當只使用來自本次試驗的數據的時候 (無信息的先驗概率，左邊圖)，療效的點估計，和可信區間，是十分接近概率論者計算的點估計和信賴區間的。與之相對的是，當我們給模型中加入了有信息的先驗概率分佈時，後驗概率分佈給出的點估計和可信區間發生了變化:</p>
<ul>
<li>後驗概率分佈向右邊 (治療無效) 發生了位移 (shift towards no treatment effect)，也就是療效的點估計從 -5.3 下降至 -3.4;</li>
<li>95%可信區間的範圍變得比左邊使用無信息先驗概率的結果狹窄了 (估計變得精確了)，從之前的 (-11.8, 1.3) 變窄至 (-7.3, 0.4)。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:MTXpriors"></span>
<img src="img/Selection_032.png" alt="Methotrexate in Seleroderma: comparison of priors" width="90%" />
<p class="caption">
圖 80.3: Methotrexate in Seleroderma: comparison of priors
</p>
</div>
<p>紅色面積 (也就是支持 MTX 治療有效的概率)，因爲分佈的位移，以及可信區間變窄的原因，從 94% 略增加到了 96%。</p>
<p>在這個實驗中先驗概率分佈和該次試驗計算的似然給模型提供了相似的信息量。在更多的情況下，歷史數據，背景知識只能給出有限的信息量。所以，一個使用貝葉斯方法計算的統計報告，你會看見統計學家使用多個不同的先驗概率分佈，加上該次試驗的似然，來計算多個不同先驗概率下給出的後驗概率分佈結果，從而展示他/她給出的結論對於不同先驗概率的敏感程度。</p>
<p>這個實例給我們展示了貝葉斯統計學能做到，而概率論統計學不能做到的幾個要點:</p>
<ol style="list-style-type: decimal">
<li>貝葉斯分析結果可以告訴我們，藥物有效的概率是多少，簡單直接了當。</li>
<li>背景知識，除了你可以洋洋灑灑地寫在論文中之外，竟然還可以被當做一種先驗概率分佈，有效地和實驗數據獲得的似然相結合，妙哉妙哉。</li>
<li>三種評估手段，可以通過貝葉斯統計學模型整合到一起，同時給出後驗概率的分佈，這在傳統的概率論統計學模型中是很難，甚至是不可能做到的。貝葉斯方法同時還允許我們建立十分複雜的模型，且不必擔心模型擬合計算量對電腦的要求。</li>
<li>中途退出試驗的患者數據可以使用貝葉斯方法簡單地歸納進統計模型中來，概率論統計學所使用的缺失值的補全法其實相比貝葉斯法來說顯得不完整，且可靠程度較低。</li>
<li>醫生從貝葉斯統計方法計算的結果中獲得了更加多的信息，和結論。你可以計算超過某個療效差異的概率大小。在貝葉斯統計學方法中，整個事後概率的密度分佈圖都可以給出，而不僅僅是一個點和信賴區間的估計。</li>
</ol>
</div>
</div>
<div id="example-the-great-trial" class="section level2">
<h2><span class="header-section-number">80.2</span> Example: The GREAT trial</h2>
<p>接下來我們一起一步一步利用GREAT臨牀試驗數據，看看下面不同的分析方法會帶給我們什麼樣子的結果：</p>
<ol style="list-style-type: decimal">
<li>經典統計學方法;</li>
<li>貝葉斯統計學方法（通過兩種不同的先驗概率分布）</li>
</ol>
<div id="background-great-trial" class="section level3">
<h3><span class="header-section-number">80.2.1</span> Background (GREAT trial)</h3>
<p>GREAT 臨牀試驗是一項隨機雙盲對照試驗(RCT)，試驗藥物是阿尼普酶(anistreplase，復合纖維溶解酶)，具有溶解血栓的效果。該試驗比較的是傳統的心肌梗塞(myocardial infarction, MI)被確診之後的治療方法，和家庭醫生對患者確診心肌梗塞之後在家中就立即服用阿尼普酶的療效是否有差異。</p>
<ul>
<li>主要結果：30天死亡率</li>
<li>之前有過研究(GISSI trial)，結果表明，當患者在醫院時，阿尼普酶如果在確認患者發生心肌梗塞之後一小時內服用，能夠有效降低患者因心肌梗塞導致的一年死亡率 (從19%降低至12%)。但是當投藥發生在患者心肌梗塞確診６小時以上時，死亡率則沒有變化。</li>
<li>本次試驗的方法是：家庭醫生給予患者阿尼普酶 (治療組) 或者安慰劑 (對照組)；當患者被送至醫院後，院內給予安慰劑(治療組)，或者阿尼普酶 (對照組)。[注意二者投藥順序正好相反]。</li>
</ul>
</div>
<div id="試驗結果" class="section level3">
<h3><span class="header-section-number">80.2.2</span> 試驗結果</h3>
<p>治療組（在家中先服用阿尼普酶後院內服用安慰劑）163例，死亡病例13例；對照組 (家中服用安慰劑後院內服用阿尼普酶) 148例，死亡23例。</p>
</div>
<div id="經典統計學分析方法" class="section level3">
<h3><span class="header-section-number">80.2.3</span> 經典統計學分析方法</h3>
<p>觀察數據給出的比值比的點估計可以計算爲: <span class="math inline">\(\text{OR} = \frac{13/(163-13)}{23/(148-23)} = 0.47\)</span>; 根據比值比的對數服從正態分布，且標準誤爲: <span class="math inline">\(\text{SE}_{\log(\text{OR})} = \sqrt{\frac{1}{13} + \frac{1}{163-13} + \frac{1}{23} + \frac{1}{148-23}} = -0.7528664\)</span>，那麼 <span class="math inline">\(\log{\text{OR}}\)</span> 的95%CI 可以計算爲<span class="math inline">\(\log{0.47} \pm 1.96*(-0.7528664) = (-1.47, -0.03)\)</span>，再反過來計算<span class="math inline">\(\text{OR}\)</span>的95%CI，可以獲得比值比的信賴區間是：<span class="math inline">\((0.23, 0.97)\)</span>。</p>
<p>至此，傳統的統計學方法的計算過程結束，獲得點估計: <span class="math inline">\(\text{OR} = 0.47; 95\%\text{CI:} (0.23, 0.97), p = 0.04\)</span>。</p>
</div>
<div id="貝葉斯統計學分析方法" class="section level3">
<h3><span class="header-section-number">80.2.4</span> 貝葉斯統計學分析方法</h3>
<ol style="list-style-type: decimal">
<li>先驗概率使用專家意見: expert prior</li>
</ol>
<ul>
<li>專家的意見來自之前已經進行過的三個較小的臨牀試驗：
<ul>
<li>阿尼普酶可能可以降低一些死亡率，但是不多 (15-25%);</li>
<li>阿尼普酶不太可能降低死亡率達到40%或者以上</li>
</ul></li>
<li>這個專家意見被貝葉斯統計學家用統計學語言翻譯成: 在比值比尺度上(OR)，治療組(家中立即服用阿尼普酶)相對對照組的比值比的95%信賴區間應該在 <span class="math inline">\((0.6, 1)\)</span> 範圍內，包括1。</li>
<li>我們還需要把這句話再進行對數轉換以便於做邏輯回歸計算 (log-odds ratio)
<ul>
<li><span class="math inline">\(\log(\text{OR})\)</span> 的95%信賴區間的範圍需要落在<span class="math inline">\((-0.51, 0)\)</span>之內;</li>
<li>這相當於就是一個均值爲 <span class="math inline">\(\log(0.6)/2 = -0.26\)</span>, 方差是 <span class="math inline">\((\frac{0-\log(0.6)}{2} = 0.13)^2\)</span> ，的正態分布:</li>
</ul></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:GREAT-expert"></span>
<img src="bookdown_files/figure-html/GREAT-expert-1.png" alt="Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely." width="90%" />
<p class="caption">
圖 80.4: Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely.
</p>
</div>
<ul>
<li>試驗數據告訴我們，<span class="math inline">\(\text{OR} = 0.47; 95\%\text{CI:} (0.23, 0.97), p = 0.04\)</span>，它的分布是數據支持的似然函數分布：</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:GREAT-expert-likelihood"></span>
<img src="bookdown_files/figure-html/GREAT-expert-likelihood-1.png" alt="Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely, adding likelihood (blue) from the GREAT trial." width="90%" />
<p class="caption">
圖 80.5: Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely, adding likelihood (blue) from the GREAT trial.
</p>
</div>
<ul>
<li>當我們使用貝葉斯方法把專家給出的先驗概率，以及本次實驗給出的似然合並之後，獲得的事後概率認爲，心肌梗塞患者在家中立刻服藥沒有幫助或者甚至有害的概率是0.5%：</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:GREAT-expert-posterior"></span>
<img src="bookdown_files/figure-html/GREAT-expert-posterior-1.png" alt="Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely, adding likelihood (blue) from the GREAT trial, and posterior distribution (red)." width="90%" />
<p class="caption">
圖 80.6: Expert Prior probablity density: small reductions in mortality likely, no or large benefit unlikely, adding likelihood (blue) from the GREAT trial, and posterior distribution (red).
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>先驗概率使用懷疑觀點的概率分布: scetptical prior</li>
</ol>
<ul>
<li>假定我們不相信專家意見，懷疑地認爲阿尼普酶對降低心肌梗塞患者死亡率本身應該沒有什麼效果的話，可以認爲比值比爲1，也就是 <span class="math inline">\(\log(\text{OR}) = 0\)</span>。同時還認爲有顯著療效是小概率事件。此時，先驗概率的分布可以表示爲：</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:GREAT-sceptical"></span>
<img src="bookdown_files/figure-html/GREAT-sceptical-1.png" alt="Sceptical Prior probablity density, no benifit or large treatment effect unlikely" width="90%" />
<p class="caption">
圖 80.7: Sceptical Prior probablity density, no benifit or large treatment effect unlikely
</p>
</div>
<ul>
<li>即便如此，實驗數據給出的似然函數分布依然把這個持懷疑觀點的先驗概率分布向治療有效的方向拉動了，此時給出的心肌梗塞患者在家中立刻服藥沒有幫助或者甚至有害的概率是8%：</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:GREAT-sceptical-posterior"></span>
<img src="bookdown_files/figure-html/GREAT-sceptical-posterior-1.png" alt="Sceptical Prior probablity density, adding likelihood (blue) from the GREAT trial, and posterior distribution (red)." width="90%" />
<p class="caption">
圖 80.8: Sceptical Prior probablity density, adding likelihood (blue) from the GREAT trial, and posterior distribution (red).
</p>
</div>
<p>專家的觀點十分樂觀，但是它仍然起到了把實驗數據給出的似然概率向更現實的方向（不那麼樂觀的方向）拉動了一點點，使用專家意見給出的事後比值比均值是0.73，值得關注的是，採用懷疑論觀點的先驗概率分布，也能給出相似的事後比值比均值 0.70，只是懷疑觀點的先驗概率分布使得事後概率分布中藥物可能無效甚至有害的概率變大了。這個分析展示了，一個對該藥物療效持懷疑觀點的人，和持樂觀觀點的人二者分析相同數據時很可能作出不同的結論，但是有一點是相同的，那就是傳統概率論統計學計算獲得的比值比，<span class="math inline">\(\text{OR} = 0.47; 95\%\text{CI:} (0.23, 0.97), p = 0.04\)</span>不論與專家意見相比，還是和懷疑論者相比，都<strong>過於樂觀了</strong> (0.48 is too good to be true)。</p>
</div>
</div>
</div>
<div id="MC-estimation" class="section level1">
<h1><span class="header-section-number">第 81 章</span> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</h1>
<div id="起源" class="section level2">
<h2><span class="header-section-number">81.1</span> 起源</h2>
<div class="figure" style="text-align: center"><span id="fig:Bayes-problem"></span>
<img src="img/BayesProblem.png" alt="Reproduction of part of the original printed Bayes paper." width="80%" />
<p class="caption">
圖 81.1: Reproduction of part of the original printed Bayes paper.
</p>
</div>
<p>一切都開始於1763年，英國東南地區叫做唐橋井 (Tunbridge Wells) 的地方有個叫做託馬斯貝葉斯的牧師死後，他的朋友將他遺留下的手稿發表於世。圖 <a href="#fig:Bayes-problem">81.1</a> 是他遺作論文的節選。這段話使用的當時的英文有點令人摸不着頭腦，但其實翻譯成現代文的意思是（這裏請在大腦中想象我們最長使用的投擲一枚可能有偏的硬幣的場景）：我們一共投擲硬幣 <span class="math inline">\(n\)</span> 次，這其中有 <span class="math inline">\(y\)</span> 次硬幣是正面朝上的（事件發生）。假定 <span class="math inline">\(y\)</span> 服從參數爲 <span class="math inline">\(\theta\)</span> 的二項分布：<span class="math inline">\(y \sim \text{Binomial}(\theta, n)\)</span>，那麼<span class="math inline">\(\theta\)</span>就是硬幣正面朝上的概率。</p>
<p>貝葉斯牧師感興趣的是，參數<span class="math inline">\(\theta\)</span>，落在某個範圍內 <span class="math inline">\(\text{Pr}(\theta_1 &lt; \theta &lt; \theta_2 | y, n)\)</span>的<strong>可能性(chance)</strong>。這句話，在當年那個概率論持有者爲主流的社會中是極爲危險而且激進的 (radical) ，因爲貝葉斯牧師使用<strong>可能性 (chance)</strong>來描述一個參數的不確定性(uncertainty)。本質上說，貝葉斯牧師打算對一個無法直接觀測的參數用一個簡單直接的數學表達式來描述它的不確定性。這句話對於概率論觀點持有者佔主流的統計學領域來說，是一種明顯的異端邪說。因爲在概率論觀點持有者的語境下，概率是在無數次可重復實驗中事件發生的平均次數 (probability is interpreted in terms of a long run sequence of events)，這個無法觀測到的參數，是不會改變的 (the key idea is that the unknown parameter is considered to be a random variable under Bayesian theory, rather than fixed but unknown)。</p>
<p>我們在第一章也看到了，貝葉斯牧師提出的理論有助於我們直接，正面地回答研究中我們想知道的問題。圖 <a href="#fig:Bayes-tinmouth">81.2</a> 提供了一個很好的例子，它節選自論文<span class="citation">(Tinmouth et al. <a href="#ref-tinmouth2004low" role="doc-biblioref">2004</a>)</span>中，該文的作者是這樣描述的：“There is an 89% probability that the absolute increase in major bleeds is less than 10 percent with low-dose PLT transfusions. (使用低劑量PLT輸血時，患者大出血的出血量增加的絕對值小於10%的可能性是89%。)”</p>
<div class="figure" style="text-align: center"><span id="fig:Bayes-tinmouth"></span>
<img src="img/tinmouthBayes.png" alt="Example of a direct expression about an unknown parameter." width="50%" />
<p class="caption">
圖 81.2: Example of a direct expression about an unknown parameter.
</p>
</div>
<p>像圖 <a href="#fig:Bayes-tinmouth">81.2</a> 這樣使用一個概率分布來描述我們想知道的參數有什麼好處呢？</p>
<ul>
<li><p>最重要的好處是，用概率分布描述這個未知參數可以直觀地告訴我們這個參數它本身可能分布的範圍，和在各自分布點時的可能性。</p></li>
<li><p>沒有 p 值，因爲我們要計算整個參數可能分布的範圍，這是概率密度分布的面積。</p></li>
<li><p>沒有(難以令人理解的)信賴區間的概念(confidence interval)，相反地，我們需要盡可能詳細地描述參數可能的分布，它的中位數，它的均值，它可能取值的範圍，它中間包含了95%可信範圍的參數(credible interval)</p></li>
<li><p>方便地直接應用於預測。</p></li>
<li><p>自然地適用於決策分析 (decision analysis)，經濟學的成本效益分析 (cost-effective analysis)等。</p></li>
<li><p>貝葉斯理論讓我們從數學上把經驗（已經發表的實驗結果，以及已有的專家意見）納入到參數的估計上來，這是一個自我學習進化的過程。</p>
<pre><code>                         ## 百分比的統計學推斷 inference on proportions</code></pre></li>
</ul>
<p>我們先用一個新藥的臨牀試驗來作爲例子。</p>
<pre><code>                        ### Example: New Drug</code></pre>
<p>有一種新研發的被用於治療慢性疼痛的藥物。爲了對其有效性進行科學客觀的評價，研究者需要組織一項評價其效用的小規模臨牀試驗。在實施這項臨牀試驗之前，我們自己心裏就會提出一個問題，這個新藥物用於治療慢性疼痛時有療效的百分比有可能會是多少（期望值，expectation）？</p>
<p>假如經驗告訴我們，相似成分的藥物可能達到的有療效百分比是在0.2-0.6之間。那麼我們可以把這個經驗翻譯成爲，有效率的期望可能服從某個分布，其均值是0.4，標準差是 0.1，下一步就是用一個能夠具有這樣的均值和標準差特徵的分布來表達這個經驗。我們在數學的寶庫中發現了 Beta 分布這個可以用於描述百分比的分布。</p>
<pre><code>                        ### Beta 分布</code></pre>
<p>Beta 分布的特徵是取值範圍嚴格限定在0, 1之間，這就滿足了百分比數值的取值範圍條件。它由兩個參數來決定分布的特徵。</p>
<p>我們用 <span class="math inline">\(\theta \sim \text{Beta}(a, b)\)</span> 標記 Beta 分布。它的特徵值有：　</p>
<p><span class="math display">\[
\begin{aligned}
p(\theta|a, b) &amp; = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}\theta^{a-1}(1-\theta)^{b-1}; \theta \in (0,1) \\
\text{E}(\theta|a, b) &amp; = \frac{a}{a+b} \\
\text{V}(\theta|a, b) &amp; = \frac{ab}{(a+b)^2(a + b + 1)}
\end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\Gamma(a) = (a-1)!\)</span> 是一個伽瑪方程。</p>
<p>正如我們在貝葉斯入門的章節<a href="#beta-distribution-intro">41.2.1</a>也介紹過的那樣，Beta分布的一些形狀特徵總結如下：</p>
<div class="figure" style="text-align: center"><span id="fig:beta-distr-bayes"></span>
<img src="bookdown_files/figure-html/beta-distr-bayes-1.png" alt="Shape of some Beta distribution functions for various values of a, b" width="90%" />
<p class="caption">
圖 81.3: Shape of some Beta distribution functions for various values of a, b
</p>
</div>
<p>回到新藥試驗的話題上來看，我們的經驗被翻譯成了均值爲0.4, 標準差0.1，那麼把它們帶入Beta分布的均值方差的特徵值公式中去，就可以求得相對應的Beta分布：<span class="math inline">\(\text{Beta}(9.2, 13.8)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; \sim \text{Beta}(9.2, 13.8) \\ 
\text{E}(\theta) &amp; = \frac{9.2}{9.2 + 13.8} = 0.4 \\
\text{V}(\theta) &amp; = \frac{9.2\times13.8}{(9.2 + 13.8)^2(9.2+13.8+1)} = 0.01 = 0.1^2
\end{aligned}
\]</span></p>
<p>這個本來只是一句話的經驗，就被我們成功用Beta分布翻譯成了數學模型可以使用的分布方程，它的概率密度曲線如下，使用這個Beta分布的含義就是，經驗告訴我們相似成分的藥物可能達到的有療效百分比是在0.2-0.6之間：</p>
<div class="figure" style="text-align: center"><span id="fig:beta-distr-drug"></span>
<img src="bookdown_files/figure-html/beta-distr-drug-1.png" alt="Prior distribution for Drug Example" width="90%" />
<p class="caption">
圖 81.4: Prior distribution for Drug Example
</p>
</div>
<div id="作出預測" class="section level3">
<h3><span class="header-section-number">81.1.1</span> 作出預測</h3>
<p>在臨牀試驗觀測到有療效人數 <span class="math inline">\(y\)</span> 之前，我們可以通過把未知參數積分消除(intergrate out)的方法給出預測分布：</p>
<p><span class="math display">\[
p(y) = \int p(y|\theta)p(\theta)d\theta
\]</span></p>
<p>預測在很多領域都可以得到廣泛的應用，比如做天氣預報，經濟學上的成本效益分析，進行實驗設計，以及用於檢驗觀測數據是否和期望值相匹配，等等。</p>
</div>
<div id="example-新藥表現預測" class="section level3">
<h3><span class="header-section-number">81.1.2</span> Example: 新藥表現預測</h3>
<p>我們再回到新藥治療慢性疼痛的臨牀試驗上來，假設我們設計接納20名患者進入這個臨牀試驗。那麼我們可能想根據已有的經驗，來預測一下這進來的20名患者中藥物有效的人數。</p>
<p>我們已經知道用 Beta 分布來描述經驗（也就是先驗概率 prior distribution），此時，我們再加入用 <span class="math inline">\(y\)</span> 標記20名患者中有效人數的隨機變量。那麼很自然地，我們會使用二項分布作爲 <span class="math inline">\(y\)</span> 的理想模型：</p>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; \sim \text{Beta} (a,b) \\
y &amp; \sim \text{Binomial}(\theta, n)
\end{aligned}
\]</span></p>
<p>這個模型的預測模型能夠被計算得到（甚至不需要用到計算機），且它有個自己的專有名字 <strong>Beta-Binomial</strong>，它的概率方程是：</p>
<p><span class="math display">\[
\begin{aligned}
p(y) &amp; = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\binom{n}{y}\frac{\Gamma(a + y)\Gamma(b + n - y)}{\Gamma(a + b + n)} \\
     &amp; = \binom{n}{y}\frac{B(a + y, b + n -y)}{B(a,b)}
\end{aligned}
\]</span>
其中，<span class="math inline">\(B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\)</span>；</p>
<p>均值是：</p>
<p><span class="math display">\[
\text{E}(Y) = n\frac{a}{a + b}
\]</span></p>
<p>那麼我們在進行這項試驗時我們可以預測，20名患者中有療效人數出現的概率，我們將它的預測概率分布圖和先驗概率分布放在一起：</p>
<div class="figure" style="text-align: center"><span id="fig:Beta-binomial-def"></span>
<img src="bookdown_files/figure-html/Beta-binomial-def-1.png" alt="Prior and predictive distribution for the drug example." width="90%" />
<p class="caption">
圖 81.5: Prior and predictive distribution for the drug example.
</p>
</div>
<p>我們根據這個預測概率分布，或者預測概率方程，可以計算“20名患者中有15名或者更多的患者的症狀得到改善”這一事件出現的概率會是：</p>
<p><span class="math display">\[
P(y \geqslant 15) = \sum_{15}^{20}p(y) = 0.015
\]</span></p>
</div>
</div>
<div id="蒙特卡羅估計" class="section level2">
<h2><span class="header-section-number">81.2</span> 蒙特卡羅估計</h2>
<p>但是在一般的情況下，像這個新藥臨牀試驗這樣能夠獲得一個閉環式 (closed-form) 概率預測概率方程的情況少之又少，有時候幾乎是不太可能完成的任務。假設我們本來也無法順利計算出上面的 Beta-Binomial概率公式，我們是否有其他的手段來獲得我們想要的預測概率結果呢？答案是，有的。人類發明的計算機，可以通過模擬試驗的方式(computer simulation)幫我們計算這個結果，它有個很酷的名字，叫做蒙特卡羅積分 (Monte Carlo integration)。</p>
<div id="用蒙特卡羅法估計概率分佈尾側累積概率面積" class="section level3">
<h3><span class="header-section-number">81.2.1</span> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</h3>
<p>假設要求一個很簡單的問題，一枚完美的硬幣，投擲10次中8次甚至更多次正面朝上的概率是多少？</p>
<p>在概率數學上，我們會用正式的方法來求:</p>
<p><span class="math display">\[
\begin{aligned}
y &amp; \sim \text{Binomial}(0.5, 10), \text{Pr}(y \geqslant 8)? \\ 
\text{Pr}(y\geqslant 8 \text{ heads}) &amp; = \sum_{y = 8}^{10}p(y | \theta = 0.5, n = 10) \\ 
&amp; = \binom{10}{8}(0.5)^8(0.5)^2 + \binom{10}{9}(0.5)^9(0.5)^1 + \binom{10}{10}(0.5)^{10}(0.5^0) \\
&amp; = 0.0547
\end{aligned}
\]</span></p>
<p>但是，如果有人很懶，他可以不這樣計算，而是真的拿那個硬幣過來不停的進行很多很多次投擲試驗，然後計算其中8次正面朝上出現的試驗的比例，那麼從長遠來說，就能夠無線接近理論計算的概率數值。</p>
<p>那麼，計算機進行模擬試驗的過程 (simulation)，其實就是讓計算機代替我們進行投擲硬幣試驗的過程。圖 <a href="#fig:coin-tosses">81.6</a> 展示的是計算機模擬投擲硬幣(a) 100次 (b) 10,000 次時正面朝上次數的概率分佈，以及 (c) 真實的概率分佈。</p>
<div class="figure" style="text-align: center"><span id="fig:coin-tosses"></span>
<img src="img/tosses10heads.png" alt="Proportion of simulations with 8 or more &quot;heads&quot; in 10 tosses." width="80%" />
<p class="caption">
圖 81.6: Proportion of simulations with 8 or more “heads” in 10 tosses.
</p>
</div>
<p>從中可以計算每種情況下硬幣正面朝上10次中出現8次或者更多的事件出現的概率分別是:</p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>100次模擬試驗: 0.08</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>10000次模擬試驗: 0.0562</li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-alpha">
<li>真實的二項分佈累積概率: 0.0547</li>
</ol></li>
</ul>
<p>可見，當模擬試驗的次數增加，計算想要的事件出現的比例，就越來越接近理論計算的真實值。蒙特卡羅積分法，用的也是類似計算機模擬試驗的方法來計算預測概率分佈的。</p>
</div>
<div id="用蒙特卡羅法計算預測概率分佈" class="section level3">
<h3><span class="header-section-number">81.2.2</span> 用蒙特卡羅法計算預測概率分佈</h3>
<p>如果用蒙特卡羅法，也就是計算機模擬試驗的方法來計算預測概率分佈的話，那麼我們就不需要再通過 Beta-binomial 概率分佈的公式來進行計算了。取而代之的就是，蒙特卡羅積分法:</p>
<ol style="list-style-type: decimal">
<li>從先驗概率分佈中隨機選取一個值 <span class="math inline">\(\theta = \theta_1\)</span></li>
<li>把從先驗概率分佈中隨機選取的 <span class="math inline">\(\theta_1\)</span> 作爲已知量放到二項分佈中再隨機選取一個服從 <span class="math inline">\(n = 20, \theta = \theta_1\)</span> 二項分佈數據中的 <span class="math inline">\(y\)</span>。</li>
</ol>
<p>重複上面步驟1，2成千上萬次之後，獲得的新的概率分佈，就是 <span class="math inline">\(y\)</span> 的預測分佈的一個樣本。這樣獲得的樣本，我們就可以想進各種方法來描述它，可以是取均值，取方差，取四分位，等任何你可以用來描述的特徵值來作爲對預測概率分佈的描述。</p>
</div>
</div>
<div id="蒙特卡羅法分析軟件-openbugs" class="section level2">
<h2><span class="header-section-number">81.3</span> 蒙特卡羅法分析軟件 OpenBUGS</h2>
<p>本書中我們用 <a href="http://www.openbugs.net/w/FrontPage">OpenBUGS</a> 這一軟件進行全部的貝葉斯分析。</p>
<div id="用-openbugs-分析投擲硬幣數據" class="section level3">
<h3><span class="header-section-number">81.3.1</span> 用 OpenBUGS 分析投擲硬幣數據</h3>
<p>,
回到投擲硬幣的簡單模型上來，我們的隨機變量 <span class="math inline">\(y\)</span> 服從的是二項分佈，<span class="math inline">\(y \sim \text{Binomial}(0.5, 10)\)</span>，我們想要計算的是“8次或者更多次正面朝上”事件出現的概率: <span class="math inline">\(P(y\geqslant 8)\)</span>。這一模型在 BUGS 語言下被描述爲:</p>
<pre><code>model{
    y ~ dbin(0.5, 10)
    P8 &lt;- step(y - 7.5)
}</code></pre>
<p>其中<code>step</code>是一個能夠產生邏輯結果(True or False)的指示方程(indicator function)。<code>P8 &lt;- step(y - 7.5)</code>這段BUGS語句的含義是，當<code>y - 7.5</code>的結果<span class="math inline">\(\geqslant0\)</span>，<code>P8</code>將會取 1 (True)，反之將返回結果 0 (False)。意思就是使得當隨機選取的二項分布樣本 <span class="math inline">\(y\geqslant8\)</span> 時，<code>P8</code>會取值1，否則取0。</p>
<p>將這一段計算機模擬拋擲硬幣的語句重復一萬次以上(iterations)，然後對獲得的所有10000個<code>P8</code>取均值，獲得的就會是 <span class="math inline">\(y\geqslant8\)</span> 這一事件將會出現的概率。</p>
</div>
<div id="用-openbugs-對藥物臨牀試驗的結果做預測" class="section level3">
<h3><span class="header-section-number">81.3.2</span> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</h3>
<p>還記得我們在藥物對慢性疼痛治療療效評價的這一臨牀試驗中使用的先驗概率是 <span class="math inline">\(\theta \sim \text{Beta}(9.2, 13.8)\)</span>。我們再來思考一次，我們收集到20位志願者參加這個臨牀試驗，那麼“這20位患者中，有15名或者更多的患者症狀得到改善（治療有效）”這件事發生的概率是多少？</p>
<p>這時候，模型的先驗概率和似然，以及我們想要知道的問題，被數學語言寫成了下面的三句話：</p>
<p><span class="math display">\[
\begin{split}
\theta &amp; \sim \text{Beta}(9.2, 13.8) &amp; \text{ Prior distribution} \\
y      &amp; \sim \text{Binomial}(\theta, 20) &amp; \text{ Sampling distribution}  \\
P_{crit} &amp; = P(y \geqslant 15)           &amp; \text{ Probability of exceeding critical threshold}
\end{split}
\]</span></p>
<p>如果要把這三句話翻譯成爲BUGS語言，可以這樣表達：</p>
<pre><code>model{
  theta ~ dbeta(9.2, 13.8) # Prior distribution
  y ~ dbin(theta, 20)      # Sampling distribution
  P.crit &lt;- step(y - 14.5) # = 1 if y &gt;= 15, 0 otherwise
}</code></pre>
<p>計算機模擬試驗10000次以後獲得的結果可能是下面這樣子的</p>
<pre><code>Node statistics
          mean   sd        MC_error  val2.5pc    median  val97.5pc  start   sample
P.crit  0.015    0.1216    0.00121   0.0         0.0       0.0        1       10000
theta   0.4008   0.09903     9.683E-4    0.2159    0.3982    0.5993     1       10000
y       8.034    2.919   0.02578     3.0         8.0       14.0       1     10000</code></pre>
<p>第一行我們可以看見顯示的是列的名稱，接下來每一行都是OpenBUGS的軟件在進行計算機模擬試驗過程中監測的(monitor)變量的結果，以及它們的數據描述。值得注意的是其中<code>P.crit</code>這一行，除了第一列的均值<code>mean = 0.015</code>有實際意義意外，其餘的數值是沒有什麼含義的，可以忽略。這個<code>P.crit</code>均值的含義即是我們關心的問題【“這20位患者中，有15名或者更多的患者症狀得到改善（治療有效）”這件事發生的概率】的答案，</p>
<p>我們可以把蒙特卡羅算法給出的計算機模擬試驗的結果，和精確統計學計算法獲得的結果相比較：</p>
<ul>
<li><span class="math inline">\(\theta:\)</span> 均值0.4，標準差0.1；</li>
<li><span class="math inline">\(y:\)</span> 均值8, 標準差2.93。</li>
<li>20人中15人及以上治療有效的概率是0.015。</li>
</ul>
<p>由於這些樣本是互相獨立的，輸出結果中的 <code>MC_error</code> <span class="math inline">\(=\frac{\text{SD}}{\sqrt{\text{n of iterations}}}\)</span>。如果你願意，完全可以爲了提高精確度再增加計算機模擬試驗的次數。</p>
<p>OpenBUGS 同時可以輸出計算機模擬計算過後的圖片：</p>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSfigs"></span>
<img src="img/OpenBUGS01.png" alt="Example OpenBUGS plots from the drug example" width="70%" />
<p class="caption">
圖 81.7: Example OpenBUGS plots from the drug example
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSfigs"></span>
<img src="img/OpenBUGS02.png" alt="Example OpenBUGS plots from the drug example" width="70%" />
<p class="caption">
圖 81.7: Example OpenBUGS plots from the drug example
</p>
</div>
</div>
<div id="用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation" class="section level3">
<h3><span class="header-section-number">81.3.3</span> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</h3>
<p>假設有一個臨牀試驗是這樣設計的，計劃在治療組和對照組各徵集 <span class="math inline">\(n\)</span> 名患者，治療陽性反應率的標準差爲<span class="math inline">\(\sigma = 1\)</span>。設計上希望達到一類錯誤 5%，和80%的效能。治療組和對照組的療效差異希望能達到 <span class="math inline">\(\theta = 0.5\)</span>。計算樣本量爲<span class="math inline">\(n\)</span>，療效差爲<span class="math inline">\(\theta\)</span>的試驗的統計效能的數學公式已知爲：</p>
<p><span class="math display">\[
\text{Power} = \Phi(\sqrt{\frac{n\theta^2}{2\sigma^2}} - 1.96)
\]</span></p>
<p>再假設我們希望對<span class="math inline">\(\theta,\sigma\)</span>同時描述其不確定性：</p>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; \sim \text{Uniform}(0.3, 0.7) \\ 
\sigma &amp; \sim \text{Uniform}(0.5, 1.5) \\
\end{aligned}
\]</span></p>
<p>接下來，我們可以利用這個公式和給出的先驗概率對統計效能的不確定性進行估計。</p>
<ol style="list-style-type: decimal">
<li>模擬從<span class="math inline">\(\theta, \sigma\)</span>的先驗概率中各自選取相應的值；</li>
<li>把每次模擬試驗獲得的 <span class="math inline">\(\theta, \sigma\)</span> 代入上面計算效能的公式中計算每次可以獲得的統計效能；</li>
<li>重復步驟１，２許多次，獲取這個過程中計算得到的統計效能的預測分布(predictive distribution)。</li>
</ol>
<p>如果說每組患者人數是63人，那麼這個模型寫成BUGS語言就是：</p>
<pre><code>model{
  sigma ~ dunif(0.5, 1.5) 
  theta ~ dunif(0.3, 0.7)
  power &lt;- phi(sqrt(63/2)*theta/sigma - 1.96)
  prob70 &lt;- step(power - 0.7) # is power &gt;= 0.7
}</code></pre>
<p>該模型的輸出結果如下，預測的效能分布圖爲圖<a href="#fig:PowerBUGS">81.8</a>：</p>
<pre><code>Node statistics
         mean     sd       MC_error   val2.5pc   median   val97.5pc   start   sample
power    0.7508   0.2249   0.00216    0.2846     0.8031   1.0         1       10000
prob70   0.6265   0.4837   0.004626   0.0        1.0      1.0         1       10000</code></pre>
<p>當治療組對照組每組各只有６３人時，你會發現統計效能在電腦模擬１００００次試驗過後的中位數才勉強達到了80%，而且這麼寬的效能預測分布也提示我們６３人實在太少了，效能遠遠不能達到設計的要求。</p>
<div class="figure" style="text-align: center"><span id="fig:PowerBUGS"></span>
<img src="img/PowerBUGS.png" alt="Predictive Distribution of Power" width="70%" />
<p class="caption">
圖 81.8: Predictive Distribution of Power
</p>
</div>
</div>
</div>
<div id="practical-bayesian-statistics-02" class="section level2">
<h2><span class="header-section-number">81.4</span> Practical Bayesian Statistics 02</h2>
<ol style="list-style-type: decimal">
<li>拋擲硬幣試驗</li>
</ol>
<p>用BUGS語言描述拋擲硬幣的模型，把寫有下列模型代碼的文件保存爲<code>coinmodel.txt</code>:</p>
<pre><code>model{
  y ~ dbin(0.5, 10) 
  P8 &lt;- step(y - 7.5) # = 1 if Y is 8 or more
} </code></pre>
<p>下面的代碼展示了如何在R裏連接OpenBUGS進行蒙特卡羅運算和調出其結果的過程：</p>
<div class="sourceCode" id="cb1112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1112-1" title="1"><span class="kw">library</span>(BRugs)</a>
<a class="sourceLine" id="cb1112-2" title="2"></a>
<a class="sourceLine" id="cb1112-3" title="3"><span class="co"># bugpath &lt;- &quot;C:/Users/Chao/Documents/LSHTMlearningnote/&quot; # in letsnote win10</span></a>
<a class="sourceLine" id="cb1112-4" title="4">bugpath &lt;-<span class="st"> &quot;C:/Users/AMU-phealth/Documents/LSHTMlearningnote/&quot;</span> <span class="co"># in epson win10</span></a>
<a class="sourceLine" id="cb1112-5" title="5"></a>
<a class="sourceLine" id="cb1112-6" title="6"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1112-7" title="7"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/coinmodel.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))</a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1114-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1114-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1116-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1116-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1116-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1116-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1116-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1118-1" title="1"><span class="co"># Set monitors on nodes of interest</span></a>
<a class="sourceLine" id="cb1118-2" title="2"><span class="kw">samplesSet</span>(<span class="kw">c</span>(<span class="st">&quot;P8&quot;</span>, <span class="st">&quot;y&quot;</span>))</a></code></pre></div>
<pre><code>## monitor set for variable &#39;P8&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<div class="sourceCode" id="cb1121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1121-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1121-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1123-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1123-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1123-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##     mean    sd MC_error val2.5pc median val97.5pc start sample
## P8 0.054 0.226 0.007945        0      0         1     1   1000
## y  4.980 1.588 0.051630        2      5         8     1   1000</code></pre>
<div class="sourceCode" id="cb1125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1125-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1125-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">P8 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P8&quot;</span>),</a>
<a class="sourceLine" id="cb1125-3" title="3">                    <span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>))</a>
<a class="sourceLine" id="cb1125-4" title="4"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">ask=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS00"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS00-1.png" alt="History of the iterations." width="80%" />
<p class="caption">
圖 81.9: History of the iterations.
</p>
</div>
<p>對模型進行修改，嘗試計算相同設計的試驗，在徵集了30名患者，新藥的有效率爲0.7時，15名或者以內的患者有顯著療效的事件發生的概率是多少？</p>
<pre><code>model{
  y ~ dbin(0.7, 30) 
  P15 &lt;- step(15.5 - y) # = 1 if Y is 15 or fewer
} </code></pre>
<div class="sourceCode" id="cb1127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1127-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1127-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/coinmodel30.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1129-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1129-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1131-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1131-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1131-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1131-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1131-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1133-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1133-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P15&quot;</span>, <span class="st">&quot;y&quot;</span>)</a>
<a class="sourceLine" id="cb1133-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;P15&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<div class="sourceCode" id="cb1136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1136-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1136-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1138-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1138-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1138-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##        mean     sd MC_error val2.5pc median val97.5pc start sample
## P15  0.0165 0.1274  0.00125        0      0         0     1  10000
## y   21.0200 2.5120  0.02466       16     21        26     1  10000</code></pre>
<div class="sourceCode" id="cb1140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1140-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1140-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">P15 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P15&quot;</span>),</a>
<a class="sourceLine" id="cb1140-3" title="3">                    <span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>))</a>
<a class="sourceLine" id="cb1140-4" title="4"><span class="co">#### PLOT THE HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1140-5" title="5"><span class="co">## samplesDensity(&quot;*&quot;, 1,  mfrow = c(2,2), ask=NULL)</span></a>
<a class="sourceLine" id="cb1140-6" title="6"></a>
<a class="sourceLine" id="cb1140-7" title="7"><span class="cf">for</span>(p_ <span class="cf">in</span> parameters)</a>
<a class="sourceLine" id="cb1140-8" title="8">  {</a>
<a class="sourceLine" id="cb1140-9" title="9">    <span class="kw">hist</span>(chain[[p_]], <span class="dt">main=</span>p_,</a>
<a class="sourceLine" id="cb1140-10" title="10">         <span class="dt">ylab=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="ot">NA</span>, <span class="co">#prob = TRUE,</span></a>
<a class="sourceLine" id="cb1140-11" title="11">         <span class="dt">nclas=</span><span class="dv">50</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1140-12" title="12">  }</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS011"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS01-1.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.10: Predictive distribution of the nodes of interest.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS012"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS01-2.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.11: Predictive distribution of the nodes of interest.
</p>
</div>
<p>所以此時少於或等於１５人得到症狀改善的事件發生的概率被推測爲1.6%。</p>
<ol start="2" style="list-style-type: decimal">
<li>藥物治療臨牀試驗</li>
</ol>
<p>藥物臨牀試驗的例子中，我們建立的模型如下：</p>
<pre><code>#  Monte Carlo predictions for Drug example

model{
    theta   ~ dbeta(9.2,13.8)          # prior distribution
    y         ~ dbin(theta,20)         # sampling distribution
    P.crit   &lt;- step(y-14.5)           # =1 if y &gt;= 15, 0 otherwise
}</code></pre>
<p>把這個模型存儲成<code>drug-MC.txt</code>文件之後，可以使用OpenBUGS完成這個模型的蒙特卡羅模擬試驗計算：</p>
<div class="sourceCode" id="cb1142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1142-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1142-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/drug-MC.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1144-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1144-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1146-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1146-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1146-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1146-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1146-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1148-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1148-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;P.crit&quot;</span>)</a>
<a class="sourceLine" id="cb1148-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;theta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<pre><code>## monitor set for variable &#39;P.crit&#39;</code></pre>
<div class="sourceCode" id="cb1152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1152-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1152-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1154-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1154-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1154-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##          mean      sd  MC_error val2.5pc median val97.5pc start sample
## P.crit 0.0150 0.12160 0.0012100   0.0000 0.0000    0.0000     1  10000
## theta  0.4008 0.09903 0.0009683   0.2159 0.3982    0.5993     1  10000
## y      8.0340 2.91900 0.0257800   3.0000 8.0000   14.0000     1  10000</code></pre>
<div class="sourceCode" id="cb1156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1156-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1156-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">theta =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta&quot;</span>),</a>
<a class="sourceLine" id="cb1156-3" title="3">                    <span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>),</a>
<a class="sourceLine" id="cb1156-4" title="4">                    <span class="dt">P.crit =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.crit&quot;</span>))</a>
<a class="sourceLine" id="cb1156-5" title="5"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1156-6" title="6"><span class="co">##1. samplesDensity(&quot;*&quot;, 1,  mfrow = c(2,2), ask=NULL)</span></a>
<a class="sourceLine" id="cb1156-7" title="7"><span class="co"># or 2. by looping </span></a>
<a class="sourceLine" id="cb1156-8" title="8"><span class="co"># for(p_ in parameters)</span></a>
<a class="sourceLine" id="cb1156-9" title="9"><span class="co">#   {</span></a>
<a class="sourceLine" id="cb1156-10" title="10"><span class="co">#     hist(chain[[p_]], main=p_,</span></a>
<a class="sourceLine" id="cb1156-11" title="11"><span class="co">#          ylab=NA, xlab=NA, #prob = TRUE,</span></a>
<a class="sourceLine" id="cb1156-12" title="12"><span class="co">#          nclas=50, col=&quot;red&quot;)</span></a>
<a class="sourceLine" id="cb1156-13" title="13"><span class="co">#   }</span></a>
<a class="sourceLine" id="cb1156-14" title="14"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1156-15" title="15"></a>
<a class="sourceLine" id="cb1156-16" title="16"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>theta), <span class="dt">main =</span> <span class="st">&quot;theta sample 10000&quot;</span>, </a>
<a class="sourceLine" id="cb1156-17" title="17">     <span class="dt">ylab =</span> <span class="st">&quot;P(theta)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;theta&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1156-18" title="18"><span class="kw">hist</span>(chain<span class="op">$</span>y, <span class="dt">main =</span> <span class="st">&quot;y sample 10000&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;P(Y)&quot;</span>, </a>
<a class="sourceLine" id="cb1156-19" title="19">     <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:12-Bayesian-stats-3"></span>
<img src="bookdown_files/figure-html/12-Bayesian-stats-3-1.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.12: Predictive distribution of the nodes of interest.
</p>
</div>
<p>如果把藥物治療的臨牀試驗例子的先驗概率分布修改一下，修改成爲一個沒有信息的均一分布 <span class="math inline">\(\text{Uniform}(0, 1)\)</span>，模型的結果會有怎樣的變化呢？嘗試繪制成功次數的預測概率分布，此時“20名患者中大於或者等於15名患者有療效”這一事件發生的概率是多少？</p>
<pre><code>#  Monte Carlo predictions for Drug example
#  with a uniform prior

model{
#   theta   ~ dbeta(9.2,13.8)          # prior distribution
  theta   ~ dunif(0,1)               # prior distribution
    y         ~ dbin(theta,20)         # sampling distribution
    P.crit   &lt;- step(y-14.5)           # =1 if y &gt;= 15, 0 otherwise
}</code></pre>
<div class="sourceCode" id="cb1158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1158-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1158-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/drug-MCuniform.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1160"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1160-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1160-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1162"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1162-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1162-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1162-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1162-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1162-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1164-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1164-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;P.crit&quot;</span>)</a>
<a class="sourceLine" id="cb1164-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;theta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<pre><code>## monitor set for variable &#39;P.crit&#39;</code></pre>
<div class="sourceCode" id="cb1168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1168-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1168-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1170-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1170-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1170-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##          mean     sd MC_error val2.5pc  median val97.5pc start sample
## P.crit 0.2805 0.4492 0.004402  0.00000  0.0000    1.0000     1  10000
## theta  0.4975 0.2883 0.002962  0.02472  0.4977    0.9731     1  10000
## y      9.9450 6.0590 0.063150  0.00000 10.0000   20.0000     1  10000</code></pre>
<div class="sourceCode" id="cb1172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1172-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1172-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">theta =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta&quot;</span>),</a>
<a class="sourceLine" id="cb1172-3" title="3">                    <span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>),</a>
<a class="sourceLine" id="cb1172-4" title="4">                    <span class="dt">P.crit =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.crit&quot;</span>))</a>
<a class="sourceLine" id="cb1172-5" title="5"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1172-6" title="6"></a>
<a class="sourceLine" id="cb1172-7" title="7"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1172-8" title="8"></a>
<a class="sourceLine" id="cb1172-9" title="9"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>theta), <span class="dt">main =</span> <span class="st">&quot;theta sample 10000&quot;</span>, </a>
<a class="sourceLine" id="cb1172-10" title="10">     <span class="dt">ylab =</span> <span class="st">&quot;P(theta)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;theta&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1172-11" title="11"><span class="kw">hist</span>(chain<span class="op">$</span>y, <span class="dt">main =</span> <span class="st">&quot;y sample 10000&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;P(Y)&quot;</span>, </a>
<a class="sourceLine" id="cb1172-12" title="12">     <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:12-Bayesian-stats-4"></span>
<img src="bookdown_files/figure-html/12-Bayesian-stats-4-1.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.13: Predictive distribution of the nodes of interest.
</p>
</div>
<p>這個條件下，“20名患者中大於或者等於15名患者有療效”這一事件發生的概率爲28.05%。</p>
<ol start="3" style="list-style-type: decimal">
<li>嘗試自己來寫一個模型。</li>
</ol>
<p>打開一個空白文檔，試着寫一個模型，它的先驗概率是一個標準正態分布，(OpenBUGS code: <code>x ~ dnorm(0,1)</code>)。值得注意的是，在OpenBUGS的環境下，標準正態分布的描述方式和平時概率論統計學有些不一樣：概率論的標準差或者方差，在貝葉斯統計學中被冠以另一種新的概念–精確度(precision, = 1/variance)。試着嘗試用蒙特卡羅模擬試驗的方法計算標準正態分布中取值低於-1.96，和-2.326的事件發生的概率各自是多少。（已知二者的理論值分別是0.025, 0.01）。</p>
<pre><code>#  Monte Carlo predictions
#  with a standard normal distribution prior

model{
  x        ~ dnorm(0, 1)             # prior distribution
    p.1     &lt;- step(-1.96 - x)         # = 1 if x &lt;= -1.96, 0 otherwise
    p.2     &lt;- step(-2.32 - x)         # = 1 if x &lt;= -2.32, 0 otherwise
}</code></pre>
<p>分別對這個模型嘗試蒙特卡羅模擬試驗100, 1000, 和100000次，比較蒙特卡羅模擬試驗給出的概率估計和理論值的差異。</p>
<div class="sourceCode" id="cb1174"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1174-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1174-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/standardnormalMC.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1176-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1176-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1178-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1178-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1178-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1178-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1178-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1180-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1180-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;p.1&quot;</span>, <span class="st">&quot;p.2&quot;</span>, <span class="st">&quot;x&quot;</span>)</a>
<a class="sourceLine" id="cb1180-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;p.1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;p.2&#39;</code></pre>
<pre><code>## monitor set for variable &#39;x&#39;</code></pre>
<div class="sourceCode" id="cb1184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1184-1" title="1"><span class="co"># Generate 100 iterations</span></a>
<a class="sourceLine" id="cb1184-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">100</span>)</a></code></pre></div>
<pre><code>## 100 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1186-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1186-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1186-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##       mean     sd  MC_error val2.5pc  median val97.5pc start sample
## p.1 0.0000 0.0000 1.000e-11    0.000 0.00000     0.000     1    100
## p.2 0.0000 0.0000 1.000e-11    0.000 0.00000     0.000     1    100
## x   0.0606 0.9453 8.951e-02   -1.559 0.05174     2.003     1    100</code></pre>
<div class="sourceCode" id="cb1188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1188-1" title="1"><span class="co"># Generate 900 iterations</span></a>
<a class="sourceLine" id="cb1188-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">900</span>)</a></code></pre></div>
<pre><code>## 900 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1190-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1190-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1190-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##       mean     sd MC_error val2.5pc    median val97.5pc start sample
## p.1 0.0240 0.1530 0.005491    0.000  0.000000     0.000     1   1000
## p.2 0.0110 0.1043 0.003899    0.000  0.000000     0.000     1   1000
## x   0.0261 1.0090 0.036770   -1.928 -0.007392     2.032     1   1000</code></pre>
<div class="sourceCode" id="cb1192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1192-1" title="1"><span class="co"># Generate 100000 iterations</span></a>
<a class="sourceLine" id="cb1192-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">99000</span>)</a></code></pre></div>
<pre><code>## 99000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1194"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1194-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1194-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1194-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##          mean     sd  MC_error val2.5pc   median val97.5pc start sample
## p.1  0.025160 0.1566 0.0004711    0.000  0.00000     1.000     1 100000
## p.2  0.010180 0.1004 0.0002970    0.000  0.00000     0.000     1 100000
## x   -0.003323 1.0020 0.0031550   -1.962 -0.00278     1.967     1 100000</code></pre>
<p>我們知道理論上 <span class="math inline">\(x\sim N(0,1^2)\)</span>，它的均值爲0，標準差爲1。我們也能看見蒙特卡羅模擬試驗的結果，隨着我們增加其重復取樣次數二越來越接近理論值。當取樣達到十萬次以上之後，可以看到蒙特卡羅的結果已經十分之接近真實值。在一開始剛剛重復100次蒙特卡羅時，我們可以看到<code>p.1, p.2</code>的估計還很不準確，但是類似的，當蒙特卡羅採樣次數達到十萬次以上時，這兩個概率估計也已經十分接近真實值。另外值得注意的一點是，隨着蒙特卡羅樣本量增加，<code>MC_error</code>也在變得越來越小（越來越精確）。事實上，這個<code>MC_error</code>本身約等於<span class="math inline">\(\frac{\text{sd}}{\sqrt{\text{sample size}}}\)</span>。所以對<span class="math inline">\(x\)</span>來說，經過1000次蒙特卡羅計算，<span class="math inline">\(\text{sd}(x) = 1.009\)</span>，那麼此時的<code>MC_error</code><span class="math inline">\(=\frac{1.009}{\sqrt{1000}} \approx 0.0319\)</span>，十分接近計算機給出的<code>MC_error = 0.03677</code>。<code>MC_error</code>本身可以作爲這個<span class="math inline">\(x\)</span>均值的估計精確度來理解，我們同時相信，真實的理論值會落在蒙特卡羅樣本均值<span class="math inline">\(\pm 2\times\)</span> <code>MC_error</code>範圍內。</p>
<p>下面我們來探索一下 t分布。嘗試寫下一個BUGS模型，它的先驗概率分布是一個自由度爲4的t分布，<code>y ~ dt(0,1,4)</code>。然後進行10000次蒙特卡羅採樣計算，並給出概率密度分布圖。</p>
<pre><code>#  Monte Carlo predictions
#  with a t distribution prior with degree of freedom = 4

model{
  y ~ dt(0, 1, 4)
}</code></pre>
<div class="sourceCode" id="cb1197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1197-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1197-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/MCt.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1199-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1199-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1201-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1201-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1201-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1201-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1201-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1203-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1203-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;y&quot;</span>)</a>
<a class="sourceLine" id="cb1203-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<div class="sourceCode" id="cb1205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1205-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1205-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1207-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1207-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1207-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##       mean   sd MC_error val2.5pc    median val97.5pc start sample
## y -0.02244 1.43  0.01534   -2.857 -0.001755     2.725     1  10000</code></pre>
<div class="sourceCode" id="cb1209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1209-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1209-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>))</a>
<a class="sourceLine" id="cb1209-3" title="3"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1209-4" title="4"></a>
<a class="sourceLine" id="cb1209-5" title="5"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>y), <span class="dt">main =</span> <span class="st">&quot;y sample 10000&quot;</span>, </a>
<a class="sourceLine" id="cb1209-6" title="6">     <span class="dt">ylab =</span> <span class="st">&quot;P(y)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:12-Bayesian-stats-6"></span>
<img src="bookdown_files/figure-html/12-Bayesian-stats-6-1.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.14: Predictive distribution of the nodes of interest.
</p>
</div>
<p>下面再嘗試計算一個來自均值爲1，標準差爲2的正態分布的隨機變量，它的三次方的期望值是多少。已知標準差<span class="math inline">\(SD = 2\)</span>，那麼方差爲<span class="math inline">\(Var = 4\)</span>，那麼翻譯成BUGS語言就是精確度爲 <span class="math inline">\(\frac{1}{4} = 0.25\)</span>。</p>
<pre><code>#  Monte Carlo predictions

model{
  y ~ dnorm(1, 0.25) 
  ycubed &lt;- pow(y, 3) # note how to write power in BUGS
}</code></pre>
<div class="sourceCode" id="cb1211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1211-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1211-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/MCcube.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1213-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1213-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1215-1" title="1"><span class="co"># There is no need to provide initial values as this is </span></a>
<a class="sourceLine" id="cb1215-2" title="2"><span class="co"># a Monte Carlo forward sampling from a known distribution</span></a>
<a class="sourceLine" id="cb1215-3" title="3"><span class="co"># but the program still requires initial values to begin</span></a>
<a class="sourceLine" id="cb1215-4" title="4"><span class="co"># generate a random value.</span></a>
<a class="sourceLine" id="cb1215-5" title="5"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1217-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1217-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;ycubed&quot;</span>)</a>
<a class="sourceLine" id="cb1217-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;y&#39;</code></pre>
<pre><code>## monitor set for variable &#39;ycubed&#39;</code></pre>
<div class="sourceCode" id="cb1220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1220-1" title="1"><span class="co"># Generate 100 iterations</span></a>
<a class="sourceLine" id="cb1220-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">100000</span>)</a></code></pre></div>
<pre><code>## 100000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1222-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1222-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1222-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##           mean     sd MC_error val2.5pc median val97.5pc start sample
## y       0.9934  2.004  0.00631   -2.925 0.9944     4.933     1 100000
## ycubed 12.9700 39.720  0.12930  -25.020 0.9834   120.100     1 100000</code></pre>
<div class="sourceCode" id="cb1224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1224-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1224-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y&quot;</span>), </a>
<a class="sourceLine" id="cb1224-3" title="3">                    <span class="dt">ycubed =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;ycubed&quot;</span>))</a>
<a class="sourceLine" id="cb1224-4" title="4"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1224-5" title="5"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1224-6" title="6"></a>
<a class="sourceLine" id="cb1224-7" title="7"></a>
<a class="sourceLine" id="cb1224-8" title="8"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>y), <span class="dt">main =</span> <span class="st">&quot;y sample 100000&quot;</span>, </a>
<a class="sourceLine" id="cb1224-9" title="9">     <span class="dt">ylab =</span> <span class="st">&quot;P(y)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1224-10" title="10"></a>
<a class="sourceLine" id="cb1224-11" title="11"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>ycubed), <span class="dt">main =</span> <span class="st">&quot;ycubed sample 100000&quot;</span>, </a>
<a class="sourceLine" id="cb1224-12" title="12">     <span class="dt">ylab =</span> <span class="st">&quot;P(ycubed)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;ycubed&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:12-Bayesian-stats-7"></span>
<img src="bookdown_files/figure-html/12-Bayesian-stats-7-1.png" alt="Predictive distribution of the nodes of interest." width="80%" />
<p class="caption">
圖 81.15: Predictive distribution of the nodes of interest.
</p>
</div>
<p>所以，一個隨機變量如果它來自一個均值爲1，標準差爲2的正態分布，那麼它的三次方的期望值是13，注意<code>ycubed</code>右側的尾巴很長。</p>
</div>
</div>
<div id="共軛先驗概率-conjugate-priors" class="section level1">
<h1><span class="header-section-number">第 82 章</span> 共軛先驗概率 Conjugate priors</h1>
<p>本章節我們重溫一下最早在貝葉斯統計學入門部分(Chapter <a href="#intro-Bayes">40</a>)介紹過的一些基本原則。特別是關於共軛先驗概率的概念，並提供一些使用BUGS模型的例子來展示如何運算這些模型。</p>
<div id="貝葉斯推斷的基礎" class="section level2">
<h2><span class="header-section-number">82.1</span> 貝葉斯推斷的基礎</h2>
<p>在一個臨牀試驗中，作爲一名貝葉斯統計學者，必須清晰明瞭地闡述如下幾個問題:</p>
<ol style="list-style-type: decimal">
<li>合理地描述目前爲止，在瞭解本次試驗數據的結果之前，類似研究曾經給出過的療效差異的報告結果，可能的取值範圍 (the <strong>prior distribution</strong>)；</li>
<li>本次試驗數據得到的結果，支持怎樣的療效差異 (the <strong>likelihood</strong>)；<br>
之後需要將上述兩個資源通過合理的數學模型結合在一起，用於產生</li>
<li>最終療效是否存在的意見和建議，證據的總結 (the <strong>posterior distribution</strong>)。</li>
</ol>
<p>最後第三步將先驗概率和似然相結合的過程，用到的是貝葉斯定理(Bayes Theorem)。通過貝葉斯定理把目前位置的經驗作爲先驗概率統合現階段試驗數據給出的似然的過程，其實是一個自我學習不斷更新知識的過程。經過貝葉斯推斷，給出事後概率分布之時，我們可以拿它來做什麼呢？</p>
<ul>
<li>估計和評價治療效果，治療差異。</li>
<li>估計和評價模型中參數的不確定性。</li>
<li>計算你感興趣的那個變量（可以是療效差異，可以是模型中的參數）達到或者超過某個特定目標值的概率。</li>
<li>預測你感興趣的那個變量可能存在的範圍。</li>
<li>作爲未來要進行的試驗設計階段的先驗概率分布。</li>
<li>給決策者提供證據。</li>
</ul>
<p>你是否還記得貝葉斯定理的公式:
如果<span class="math inline">\(A, B\)</span>分別標記兩個事件，那麼有</p>
<p><span class="math display">\[
p(A|B) = \frac{p(B|A)p(A)}{p(B)}
\]</span></p>
<p>如果<span class="math inline">\(A_i\)</span>是一系列互斥不相交事件，也就是<span class="math inline">\(p(\cup_iA_i) = \sum_ip(A_i) = 1\)</span>，貝葉斯定理可以被改寫成爲：</p>
<p><span class="math display">\[
p(A_i|B) = \frac{p(B|A_i)p(A_i)}{\sum_jp(B|A_j)p(A_j)}
\]</span></p>
<p>貝葉斯統計學推斷從根本上的特點在於嚴格區分：</p>
<ol style="list-style-type: decimal">
<li>觀測數據 <span class="math inline">\(y\)</span>，也就是試驗獲得的數據。</li>
<li>未知參數 <span class="math inline">\(\theta\)</span>，這裏，<span class="math inline">\(\theta\)</span>可以用統計學工具來描述，它可以是統計學參數，可以是缺失值，可以是測量誤差數據等等。</li>
</ol>
<ul>
<li>這裏貝葉斯統計學把未知參數當做一個可以變化的隨機變量(parameters are treated as random variables)；</li>
<li>在貝葉斯統計學框架下，我們對參數的不確定性進行描述(we make probability statements about model parameters)。</li>
<li>在概率論統計學框架下，統計學參數是未知，但是確實不變的。使用概率論統計學進行推斷時，我們只對數據進行不確定性的描述(<strong>parameters are fixed non-random quantities</strong> and the probability statements concern the data.)</li>
</ul>
<p>貝葉斯統計學推斷中，我們仍然需要建立模型用來描述 <span class="math inline">\(p(y|\theta)\)</span>，這個也就是概率論統計學中常見的<strong>似然(likelihood)</strong>。似然是把各個變量關聯起來的完整的<strong>概率模型(full probability model)</strong>。</p>
<p>從貝葉斯統計學推斷的觀點出發，</p>
<ul>
<li>在實施試驗，收集數據之前，參數(<span class="math inline">\(\theta\)</span>)是未知的，所以它需要由一個<strong>概率分布(probability distribution)</strong>來反應它的不確定性，也就是說，我們需要先對參數可能來自的分布進行描述，指定一個<strong>先驗概率(prior distribution)</strong><span class="math inline">\(p(\theta)\)</span>；</li>
<li>試驗進行完了，數據整理分析之時，我們知道了<span class="math inline">\(y\)</span>，這就是我們來和先驗概率結合的似然，使用貝葉斯定理，從而獲得給定了觀測數據之後(conditional on)，服從先驗概率的參數現在服從的概率分布，這被叫做<strong>事後概率分布(posterior distribution)</strong>。</li>
</ul>
<p><span class="math display">\[
p(\theta|y) = \frac{p(\theta)p(y|\theta)}{\int p(\theta)p(y|\theta)d\theta} \propto p(\theta)p(y|\theta)
\]</span></p>
<p>總結一下就是，</p>
<ol style="list-style-type: decimal">
<li>先驗概率(prior distribution)，<span class="math inline">\(p(\theta)\)</span>描述的是在<strong>收集數據之前</strong>參數的不確定性。</li>
<li>事後概率(posterior distribution)，<span class="math inline">\(p(\theta | y)\)</span> 描述的是在<strong>收集數據之後</strong>參數的不確定性。</li>
</ol>
</div>
<div id="二項分布似然數據的共軛先驗概率" class="section level2">
<h2><span class="header-section-number">82.2</span> 二項分布(似然)數據的共軛先驗概率</h2>
<p>沿用前一個章節新藥試驗的例子。我們在實施試驗之前對藥物的認知是，我們認爲它的藥效概率可能在 0.2-0.6 之間。我們把這個試驗前對藥物療效的估計認知翻譯成一個服從均值爲0.4，標準差爲0.1的Beta分布。這個Beta分布使用的參數(參數的參數被叫做<strong>超參數, hyperparameter</strong>)，是9.2, 13.8，寫作<span class="math inline">\(\text{Beta}(9.2, 13.8)\)</span>。那麼現在我們假設試驗結束，收集的20名患者中15名療效顯著。接下來貝葉斯統計學家要回答的問題是，這個試驗結果對先驗概率分布產生了多大的影響(How should this trial change our opinion about the positive response rate)？</p>
<p>在這個例子中，我們現在來詳細給出先驗概率和似然。</p>
<ul>
<li>似然 likelihood (distribution of the data)：<br>如果患者可以被認爲是相互獨立的，他們來自一個相同的總體，在這個總體中有一個未知的對藥物療效有效反應(positive response)的概率 <span class="math inline">\(\theta\)</span>，這樣的數據可以用一個二項分布似然來描述 binomial likelihood:</li>
</ul>
<p><span class="math display">\[
p(y | n, \theta) = \binom{n}{y}\theta^y(1-\theta)^{n-y} \propto \theta^y(1-\theta)^{n-y}
\]</span></p>
<ul>
<li>描述試驗前我們對<span class="math inline">\(\theta\)</span>的認知的先驗概率 prior distribution，這是一個連續型先驗概率分布。<br>對於百分比，我們用Beta分布來描述：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; \sim   \text{Beta}(a,b) \\ 
p(\theta) &amp; = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1}\\
\end{aligned}
\]</span></p>
<p>根據貝葉斯定理，我們來把先驗概率分布和似然相結合（相乘），來獲取事後概率分布：</p>
<p><span class="math display">\[
\begin{aligned}
p(\theta | y, n) &amp; \propto p(y|\theta, n)p(\theta) \\
                 &amp; \propto \theta^y(1-\theta)^{n-y}\theta^{a-1}(1-\theta)^{b-1} \\
                 &amp; = \theta^{y + a -1}(1-\theta)^{n - y + b -1}
\end{aligned}
\]</span>
眼尖的人立刻能看出來，這個事後概率分布本身也是一個Beta分布的概率方程，只是它的超參數和先驗概率相比發生了變化(更新)：</p>
<p><span class="math display">\[
p(\theta | y,n) = \text{Beta}(a + y, b + n -y)
\]</span></p>
<p>像這樣，先驗概率和事後概率兩個概率分布都來自相同家族的情況，先驗概率又被叫做和似然成共軛關系的先驗概率(共軛先驗概率, conjugate prior)。</p>
<div class="sourceCode" id="cb1225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1225-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1225-2" title="2"><span class="co"># Plot exact prior probability density </span></a>
<a class="sourceLine" id="cb1225-3" title="3"><span class="co"># values of the hyperparameters</span></a>
<a class="sourceLine" id="cb1225-4" title="4">a &lt;-<span class="st"> </span><span class="fl">9.2</span> </a>
<a class="sourceLine" id="cb1225-5" title="5">b &lt;-<span class="st"> </span><span class="fl">13.8</span></a>
<a class="sourceLine" id="cb1225-6" title="6"></a>
<a class="sourceLine" id="cb1225-7" title="7"><span class="co"># prior function</span></a>
<a class="sourceLine" id="cb1225-8" title="8">prior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a, b))</a>
<a class="sourceLine" id="cb1225-9" title="9"><span class="co"># Plot </span></a>
<a class="sourceLine" id="cb1225-10" title="10"><span class="kw">curve</span>(prior, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Prior for &quot;</span><span class="op">~</span>theta, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">4.5</span>), <span class="dt">frame =</span> F,</a>
<a class="sourceLine" id="cb1225-11" title="11">      <span class="dt">xlab =</span> <span class="st">&quot;Probability of positive response&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex.axis =</span> <span class="fl">1.5</span>, <span class="dt">cex.lab =</span> <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb1225-12" title="12"></a>
<a class="sourceLine" id="cb1225-13" title="13"><span class="co"># binomial likelihood function (likelihood)</span></a>
<a class="sourceLine" id="cb1225-14" title="14"></a>
<a class="sourceLine" id="cb1225-15" title="15">Likelihood &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbinom</span>(<span class="dv">15</span>, <span class="dv">20</span>, theta))</a>
<a class="sourceLine" id="cb1225-16" title="16"></a>
<a class="sourceLine" id="cb1225-17" title="17"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb1225-18" title="18"><span class="kw">curve</span>(Likelihood, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Likelihood for the data&quot;</span>, </a>
<a class="sourceLine" id="cb1225-19" title="19">      <span class="dt">frame =</span> <span class="ot">FALSE</span>, <span class="dt">xlab =</span> <span class="st">&quot;Probability of positive response&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>, </a>
<a class="sourceLine" id="cb1225-20" title="20">      <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex.axis =</span>  <span class="fl">1.5</span>, <span class="dt">cex.lab =</span> <span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb1225-21" title="21"><span class="co"># n &lt;- 0; r &lt;- 0; a &lt;- 9.2; b &lt;- 13.8; np &lt;- 20</span></a>
<a class="sourceLine" id="cb1225-22" title="22"><span class="co"># plot(0:20, BetaBinom(0:20), type = &quot;b&quot;, xlab = &quot;r*&quot;, ylab = &quot;P(R = r*)&quot;, </span></a>
<a class="sourceLine" id="cb1225-23" title="23"><span class="co">#      main = &quot;Prior predictive: a = 9.2, b = 13.8&quot;)</span></a>
<a class="sourceLine" id="cb1225-24" title="24"></a>
<a class="sourceLine" id="cb1225-25" title="25"><span class="co"># Posterior function </span></a>
<a class="sourceLine" id="cb1225-26" title="26"></a>
<a class="sourceLine" id="cb1225-27" title="27">posterior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a<span class="op">+</span><span class="dv">15</span>, b<span class="op">+</span><span class="dv">20-15</span>))</a>
<a class="sourceLine" id="cb1225-28" title="28"></a>
<a class="sourceLine" id="cb1225-29" title="29"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb1225-30" title="30"></a>
<a class="sourceLine" id="cb1225-31" title="31"><span class="kw">curve</span>(posterior, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Posterior for &quot;</span><span class="op">~</span>theta, </a>
<a class="sourceLine" id="cb1225-32" title="32">      <span class="dt">frame =</span> <span class="ot">FALSE</span>, <span class="dt">xlab =</span> <span class="st">&quot;Probability of positive response&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>, </a>
<a class="sourceLine" id="cb1225-33" title="33">      <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex.axis =</span> <span class="fl">1.5</span>, <span class="dt">cex.lab =</span> <span class="fl">1.5</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS07"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS07-1.png" alt="Prior, likelihood, and posterior for Drug example" width="80%" />
<p class="caption">
圖 82.1: Prior, likelihood, and posterior for Drug example
</p>
</div>
<p>本次試驗的模型，它的三個部分（先驗概率，似然，事後概率），分別從上到下繪制在圖 <a href="#fig:R-OpenBUGS07">82.1</a> 中。由於我們使用了共軛先驗概率，所以我們也可以通過數學的計算（甚至不需要計算機的輔助）也能算出事後概率分布。可是，並不是所有的模型都有共軛先驗概率分布供我們選擇，這時候，蒙特卡羅模擬試驗的算法就提供了強有力的工具。在BUGS語言中，我們可以用蒙特卡羅算法，忽視掉那些無法在數學上推導出事後概率分布方程的模型。BUGS本身很厲害，它可以自動識別出我們給它的先驗概率分布是否和似然之間是共軛的，如果是，那麼它會計算出共軛的事後概率分布方程，然後從事後概率分布方程中選取蒙特卡羅樣本。這個新藥試驗的BUGS模型可以寫作：</p>
<pre><code>#  Monte Carlo model for Drug example

model{
    theta   ~ dbeta(9.2,13.8)          # prior distribution
    y       ~ dbin(theta,20)           # sampling distribution (likelihood)
    y       &lt;- 15                      # data
}</code></pre>
<p>你可以看到這個模型和我們在前一章做預測的模型只有第三行指令發生了變化。當時我們是打算要來做試驗結果的預測。此時，我們試驗完畢，觀察到15名患者的疼痛症狀得到了改善，所以試驗數據是15。BUGS本身會自動識別出我們是否給似然增加了觀察數據。當它識別到我們不是用這個模型做結果預測時，它會自動明白我們現在要來做事後概率分布的計算了。這個在似然裏面的數據，是它要拿來放到模型中做條件的(observed values, i.e. data needs to be conditioned on)。</p>
<div id="事後概率分布預測" class="section level3">
<h3><span class="header-section-number">82.2.1</span> 事後概率分布預測</h3>
<p>假如這個新藥的效果仍然無法讓人覺得信服，我們考慮再做一次試驗徵集更多的患者，如果在這個試驗中，40名患者中有25名或者更多的患者症狀得到緩解，可以考慮把該藥物加入下一次發展計劃當中。這時候，又一次回到了預測概率的問題上來，我們想知道，“再做40人的試驗時，有25名或者更多的患者的症狀可以得到緩解”這件事可能發生的概率。這時候的模型可以被擴展如下：</p>
<p><span class="math display">\[
\begin{split}
\theta &amp; \sim \text{Beta}(a,b) &amp; \text{ Prior distribution} \\
y      &amp; \sim \text{Binomial}(\theta, n) &amp; \text{ Sampling distribution} \\
y_{\text{pred}} &amp; \sim \text{Binomial}(\theta, m) &amp; \text{ Predictive distribution} \\
P_{\text{crit}} &amp; \sim P(y_{\text{pred}} \geqslant m_{\text{crit}}) &amp; \text{ Probability of exceeding critical threshold}
\end{split}
\]</span></p>
<p>這段模型翻譯成BUGS語言可以描述爲：</p>
<pre><code>model{
  theta     ~ dbeta(a, b)                  # prior distribution
  y         ~ dbin(theta, n)               # sampling distribution
  y.pred    ~ dbin(theta, m)               # predictive distribution
  P.crit   &lt;- step(y.pred - mcrit + 0.5)   # = 1 if y.pred &gt;= mcrit, 0 otherwise
}</code></pre>
<p>我們可以把數據寫在另一個txt文件裏面：</p>
<pre><code>list(a = 9.2,             # parameters of prior distribution 
     b = 13.8, 
     y = 15,              # number of successes in completed trial
     n = 20,              # number of patients in completed trial
     m = 40,              # number of patients in future trial 
     mcrit = 25)          # critical value of future successes</code></pre>
<p>當然這是一個很簡單的例子，你完全可以把數據和模型寫在一起：</p>
<pre><code>model{
  theta     ~ dbeta(9.2, 13.8)                  # prior distribution
  y         ~ dbin(theta, 20)                   # sampling distribution
  y.pred    ~ dbin(theta, 40)                   # predictive distribution
  P.crit   &lt;- step(y.pred - 24.5)               # = 1 if y.pred &gt;= mcrit, 0 otherwise
  y        &lt;- 15
}</code></pre>
<p>```{r　R-OpenBUGS08, cache=TRUE, fig.width=7, fig.height=3, fig.cap=‘Posterior and predictive distributions for Drug example’, fig.align=‘center’, out.width=‘80%’, message=TRUE, warning=FALSE}</p>
</div>
</div>
</div>
<div id="step-1-check-model" class="section level1">
<h1><span class="header-section-number">第 83 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/MCdrugP29.txt”, sep = "“))
# there is no data so just compile the model
modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(”P.crit“,”theta“,”y.pred")
samplesSet(parameters)
# Generate 50000 iterations
modelUpdate(50000)</p>
<div id="show-posterior-statistics" class="section level4">
<h4><span class="header-section-number">83.0.0.1</span> SHOW POSTERIOR STATISTICS</h4>
<p>sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
</div>
<div id="put-the-sampled-values-in-one-r-data-frame" class="section level4">
<h4><span class="header-section-number">83.0.0.2</span> PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</h4>
<p>chain.3 &lt;- data.frame(P.crit = samplesSample(“P.crit”),
theta = samplesSample(“theta”),
y.pred = samplesSample(“y.pred”))
#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES
par(mfrow=c(1,2))</p>
<p>plot(density(chain.3$theta), main = “theta sample 50000”, xlim = c(0,1),
ylab = “P(theta)”, xlab = “Probability of response”, col = “red”)</p>
<p>hist(chain.3$y.pred, main = “y.pred sample 50000”, prob = TRUE,xlim = c(0, 40),
ylab = “P(y.pred)”, xlab = “Number of success”, col = “red”)</p>
<pre><code>
圖\@ref(fig:R-OpenBUGS08)左邊的圖，是前一次試驗結果的事後概率分布，20名患者中觀察到15名患者症狀改善。右邊的圖則是對下一次40人的試驗的結果做的預測，平均22.5名患者可能會有症狀改善，這個均值的標準差是4.3。



```r
# Step 1 check model
modelCheck(paste(bugpath, &quot;backupfiles/MCdrugP29.txt&quot;, sep = &quot;&quot;)) </code></pre>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1232-1" title="1"><span class="co"># there is no data so just compile the model</span></a>
<a class="sourceLine" id="cb1232-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1234-1" title="1"><span class="co"># There is no need to provide initial values as </span></a>
<a class="sourceLine" id="cb1234-2" title="2"><span class="co"># they are aleady provided in the model specification</span></a>
<a class="sourceLine" id="cb1234-3" title="3"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1236-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1236-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P.crit&quot;</span>, <span class="st">&quot;theta&quot;</span>, <span class="st">&quot;y.pred&quot;</span>)</a>
<a class="sourceLine" id="cb1236-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;P.crit&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y.pred&#39;</code></pre>
<div class="sourceCode" id="cb1240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1240-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1240-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">50000</span>)</a></code></pre></div>
<pre><code>## 50000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1242-1" title="1"><span class="co">#### SHOW POSTERIOR STATISTICS</span></a>
<a class="sourceLine" id="cb1242-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1242-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##           mean      sd  MC_error val2.5pc median val97.5pc start sample
## P.crit  0.3316 0.47080 0.0020680   0.0000  0.000    1.0000     1  50000
## theta   0.5632 0.07483 0.0003351   0.4153  0.564    0.7068     1  50000
## y.pred 22.5500 4.30900 0.0190200  14.0000 23.000   31.0000     1  50000</code></pre>
<div class="sourceCode" id="cb1244"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1244-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1244-2" title="2">chain<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">P.crit =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.crit&quot;</span>), </a>
<a class="sourceLine" id="cb1244-3" title="3">                    <span class="dt">theta =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta&quot;</span>), </a>
<a class="sourceLine" id="cb1244-4" title="4">                    <span class="dt">y.pred =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y.pred&quot;</span>))</a>
<a class="sourceLine" id="cb1244-5" title="5"></a>
<a class="sourceLine" id="cb1244-6" title="6"><span class="kw">plot</span>(chain<span class="fl">.3</span><span class="op">$</span>theta, <span class="dt">main=</span><span class="st">&quot;&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;theta&quot;</span>, </a>
<a class="sourceLine" id="cb1244-7" title="7">     <span class="dt">xlab=</span><span class="st">&quot;iteration&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.2</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:MCMC00"></span>
<img src="bookdown_files/figure-html/MCMC00-1.png" alt="Plot of the MCMC chain of the parameter, Drug example." width="80%" />
<p class="caption">
圖 83.1: Plot of the MCMC chain of the parameter, Drug example.
</p>
</div>
<p>爲了比較，我們可以把精確計算獲得的答案和蒙特卡羅算法給出的預測做個比較：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta:\)</span>均值爲0.563，標準差是0.075；</li>
<li><span class="math inline">\(y_{\text{pred}}:\)</span>均值22.51，標準差是4.31；</li>
<li>至少25名患者得到症狀改善的精確概率是 0.329。</li>
</ol>
</div>
<div id="正態分布似然數據的共軛先驗概率" class="section level2">
<h2><span class="header-section-number">83.1</span> 正態分布(似然)數據的共軛先驗概率</h2>
<p>例子：英國各地自來水公司依照法律規定，需要定期監測自己公司生產的自來水中三氯甲烷(trihalomethane, THM)的濃度。一年之中，每個公司都會在各個時期，不同的供水區域進行水樣的採集。假設現在我們需要來估計某個供水區域的自來水中三氯甲烷的濃度。</p>
<p>已知已經進行了兩次取樣，監測到三氯甲烷濃度分別是 <span class="math inline">\(y_1 = 128\mu g/l, y_2 = 132 \mu g/l\)</span>。兩次監測的均值爲 <span class="math inline">\(130 \mu g/l\)</span>。如果，這一片固定供水區域監測三氯甲烷濃度時檢測值的標準差是已知的 <span class="math inline">\(\sigma = 5\mu g/l\)</span>，那麼問題是，在這片固定供水區域的三氯甲烷濃度的估計值<span class="math inline">\((\theta)\)</span>能否計算？</p>
<p>一個只有概率論知識的統計專家是這樣計算的：</p>
<ol style="list-style-type: decimal">
<li>樣本均值 <span class="math inline">\(\bar y = 130 \mu g/l\)</span>是總體均值 <span class="math inline">\(\theta\)</span> 的一次估計；</li>
<li>它的標準誤是 <span class="math inline">\(\frac{\sigma}{\sqrt{n}} = 5/\sqrt{2} = 3.5 \mu g/l\)</span>。</li>
<li>然後這兩次測量的結果告訴我們總體均值的點估計和95%信賴區間是: <span class="math inline">\(\bar y \pm 1.96 \times \sigma/\sqrt{n} = 130 \pm 1.96\times3.5 = (123.1, 136.9) \mu g /l\)</span></li>
</ol>
<p>但是一個擁有了貝葉斯統計學知識的統計專家則會是這樣思考的：</p>
<p>這個模型中，我們知道<strong>似然(likelihood)</strong>是一個正態分布：<span class="math inline">\(y_i \sim N(\theta, \sigma^2) (i = 1, \dots, n)\)</span>，且這裏的標準差是已知的 <span class="math inline">\(\sigma = 5\mu g/l\)</span>。那麼我們給均值這個參數 <span class="math inline">\(\theta\)</span> 一個怎樣的先驗概率分布呢？</p>
<p><span class="math display">\[
\theta \sim N(\mu, \omega^2)
\]</span></p>
<ul>
<li>先驗概率分布的方差 <span class="math inline">\(\omega^2\)</span> 常可以用數據的方差來表達：<span class="math inline">\(\omega^2 = \sigma^2/n_0\)</span>。</li>
<li>這裏的 <span class="math inline">\(n_0\)</span>，可以被解釋爲隱藏的先驗概率樣本量(implicit prior sample size)。</li>
</ul>
<p>在 BUGS 標記法中，正態分布的代碼是 <code>y ~ dnorm(theta, tau)</code>，其中 <code>tau</code> 是方差的倒數(又叫做精確度)。</p>
<p>這時候我們需要一些過去同一家供水廠監測三氯甲烷時濃度的數據來給這個先驗概率分布一些提示。例如翻閱記錄我們發現來自<strong>同一家自來水公司，在其他供水區域的</strong>三氯甲烷濃度均值是 <span class="math inline">\(120 \mu g/l\)</span>，標準差是 <span class="math inline">\(10 \mu g/l\)</span>。這就提供了 <span class="math inline">\(N(120, 10^2)\)</span> 作爲 <span class="math inline">\(\theta\)</span> 的先驗概率分布。這時我們把先驗概率分布的標準差用觀測區域的標準差來表達: <span class="math inline">\(\omega^2 = \sigma^2/n_0\)</span>，此時 <span class="math inline">\(n_0 = \sigma^2/\omega^2 = 5^2/10^2 = 0.25\)</span>。那麼先驗概率分布可以被表達成 <span class="math inline">\(\theta \sim N(120, \sigma^2/0.25)\)</span>。如果 <span class="math inline">\(n_0\)</span> 靠近 <span class="math inline">\(0\)</span>，那麼根據這個方程我們知道先驗概率分布的方差就會變大，意味着先驗概率給出的信息越不精確，分布越“平坦(flatter)”。</p>
<p>此時貝葉斯統計專家把似然和先驗概率分布結合起來，計算事後概率分布：</p>
<p><span class="math display">\[
\begin{aligned}
\theta | \mathbf{y}  &amp; \sim  N(\frac{n_0 + n\bar y}{n_0 + n}, \frac{\sigma^2}{n_0 + n})\\  
                     &amp; \sim N(\frac{0.25\times 120 + 2 \times 130}{0.25 + 2}, \frac{5^2}{0.25 + 2}) \\ 
                     &amp; = N(128.9, 3.33^2 )
\end{aligned}
\]</span></p>
<p>貝葉斯算法給出的事後概率分布的95%可信區間則是 <span class="math inline">\((122.4, 135.4) \mu g/l\)</span>。</p>
<ul>
<li><p>事後概率分布的均值<span class="math inline">\(\frac{n_0 + n\bar y}{n_0 + n}\)</span>其實是先驗概率均值，和觀測數據均值之間加權之後的綜合值，它們加的權重，分別是各自的精確度(相對樣本量 relative sample size)。這其實告訴我們，觀測數據和先驗概率二者結合之時，需要各自妥協。(a compromise between the likelihood and the prior)</p></li>
<li><p>事後概率分布的方差也是和先前提到的先驗概率樣本量有密切關系。它是觀測數據的方差除以觀測樣本量和先驗概率樣本量之和。</p></li>
<li><p>當然，當你的觀測數據樣本量趨向於無窮大時 <span class="math inline">\(n \rightarrow \infty\)</span>，事後概率分布本身就接近與觀測數據的似然 <span class="math inline">\(p(\theta | \mathbf{y}) \rightarrow N(\bar y, \sigma^2/n)\)</span>。也就是說觀測數據的信息量佔絕對主導，先驗概率分布，不再能提供太多有價值的信息，可以忽略不計了。</p></li>
</ul>
<div class="sourceCode" id="cb1245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1245-1" title="1"><span class="co"># prior function</span></a>
<a class="sourceLine" id="cb1245-2" title="2">xseq&lt;-<span class="kw">seq</span>(<span class="dv">80</span>,<span class="dv">180</span>,.<span class="dv">01</span>)</a>
<a class="sourceLine" id="cb1245-3" title="3">densities&lt;-<span class="kw">dnorm</span>(xseq, <span class="dv">120</span>,<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb1245-4" title="4"></a>
<a class="sourceLine" id="cb1245-5" title="5"><span class="co"># Plot </span></a>
<a class="sourceLine" id="cb1245-6" title="6"><span class="kw">plot</span>(xseq, densities, <span class="dt">col=</span><span class="st">&quot;darkgreen&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;mean THM concentration, ug/l (theta)&quot;</span>, </a>
<a class="sourceLine" id="cb1245-7" title="7">     <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">cex=</span><span class="dv">2</span>, </a>
<a class="sourceLine" id="cb1245-8" title="8">     <span class="co"># main=&quot;PDF of Prior, likelihood, and posterior for THM example.&quot;, </span></a>
<a class="sourceLine" id="cb1245-9" title="9">     <span class="dt">cex.axis=</span><span class="fl">0.9</span>, <span class="dt">cex.lab =</span> <span class="dv">1</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.12</span>))</a>
<a class="sourceLine" id="cb1245-10" title="10"></a>
<a class="sourceLine" id="cb1245-11" title="11"><span class="co"># normal likelihood function (likelihood)</span></a>
<a class="sourceLine" id="cb1245-12" title="12"></a>
<a class="sourceLine" id="cb1245-13" title="13">Likelihood &lt;-<span class="st"> </span><span class="kw">dnorm</span>(xseq, <span class="dv">130</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1245-14" title="14"></a>
<a class="sourceLine" id="cb1245-15" title="15"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb1245-16" title="16"><span class="kw">points</span>(xseq, Likelihood, <span class="dt">col=</span><span class="st">&quot;darkred&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1245-17" title="17"></a>
<a class="sourceLine" id="cb1245-18" title="18"></a>
<a class="sourceLine" id="cb1245-19" title="19"><span class="co"># Posterior function </span></a>
<a class="sourceLine" id="cb1245-20" title="20"></a>
<a class="sourceLine" id="cb1245-21" title="21">posterior &lt;-<span class="st">  </span><span class="kw">dnorm</span>(xseq, <span class="fl">128.9</span>, <span class="fl">3.33</span>)</a>
<a class="sourceLine" id="cb1245-22" title="22"></a>
<a class="sourceLine" id="cb1245-23" title="23"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb1245-24" title="24"></a>
<a class="sourceLine" id="cb1245-25" title="25"><span class="kw">points</span>(xseq, posterior, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1245-26" title="26"></a>
<a class="sourceLine" id="cb1245-27" title="27"><span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;Prior&quot;</span>, <span class="st">&quot;Likelihood&quot;</span>, <span class="st">&quot;Posterior&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb1245-28" title="28">       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;black&quot;</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:normalconjugate"></span>
<img src="bookdown_files/figure-html/normalconjugate-1.png" alt="PDF of Prior, likelihood and posterior for THM example." width="80%" />
<p class="caption">
圖 83.2: PDF of Prior, likelihood and posterior for THM example.
</p>
</div>
</div>
<div id="泊淞分布似然數據的共軛先驗概率" class="section level2">
<h2><span class="header-section-number">83.2</span> 泊淞分布(似然)數據的共軛先驗概率</h2>
<p>接下來，我們把注意力轉到計數型數據的模型，泊淞分布上來。如果一組數據是計數型數據，<span class="math inline">\(y_1, y_2, \dots. , y_n\)</span>，它們可以被認爲是服從泊淞分布的話，它們的總體均值是<span class="math inline">\(\mu\)</span>，其似然(likelihood)方程可以寫作：</p>
<p><span class="math display">\[
p(\mathbf{y} | \mu) = \prod_i\frac{\mu^{y_i}e^{-\mu}}{y_i!}
\]</span></p>
<p>那麼，經過前輩探索，我們知道，泊淞分布的似然它也有一個共軛先驗概率分布，是伽馬分布(Gamma distribution)：</p>
<p><span class="math display">\[
p(\mu) = \text{Gamma}(a,b) = \frac{b^a}{\Gamma(a)}\mu^{a-1}e^{-b\mu}
\]</span></p>
<p>伽馬分布是一個十分靈活的分布，適用於要求數據嚴格爲正的模型(positive quantities)。如果 <span class="math inline">\(\mu \sim \text{Gamma}(a,b)\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
p(\mu | a,b) &amp; = \frac{b^a}{\Gamma(a)}\mu^{a-1}e^{-b\mu}, \mu \in (0,\infty) \\ 
\text{E}(\mu |a,b) &amp; = \frac{a}{b} \\ 
\text{V}(\mu |a,b) &amp; = \frac{a}{b^2}
\end{aligned}
\]</span></p>
<p>它的模型在BUGS語言可以用 <code>mu ~ dgamma(a,b)</code> 來表述。伽馬分布還有如下的一些有趣的特徵：</p>
<ul>
<li><span class="math inline">\(\text{Gamma}(1,b)\)</span> 是均值爲 <span class="math inline">\(\frac{1}{b}\)</span> 的指數分布。</li>
<li><span class="math inline">\(\text{Gamma}(\frac{v}{2},\frac{1}{2})\)</span>，其實是自由度爲 <span class="math inline">\(v\)</span> 的卡方分布 <span class="math inline">\(\chi_v^2\)</span>。</li>
<li><span class="math inline">\(\mu \sim \text{Gamma}(0,0)\)</span> 其實等價於 <span class="math inline">\(p(\mu) \propto \frac{1}{\mu}\)</span>，或者 <span class="math inline">\(\log \mu \sim \text{Uniform}\)</span>。</li>
<li>伽馬分布同時也是正態分布數據（似然）的精確度（方差的倒數，inverse variance or precision）共軛先驗概率。</li>
<li>伽馬分布也可以用於正向非對稱性分布(skewed positive valued quantities)的樣本分布。</li>
</ul>
<p>下圖展示了一些常見伽馬分布的形狀：</p>
<div class="figure" style="text-align: center"><span id="fig:gammadistri"></span>
<img src="bookdown_files/figure-html/gammadistri-1.png" alt="Shape of some Gamma distribution functions for various values of a, b" width="90%" />
<p class="caption">
圖 83.3: Shape of some Gamma distribution functions for various values of a, b
</p>
</div>
<p>將伽馬分布的概率方程和泊淞分布似然方程相結合，貝葉斯定理告訴我們，它會變成另外一個更新過後的伽馬分布：</p>
<p><span class="math display">\[
\begin{aligned}
p(\mu | \mathbf{y}) &amp; \propto p(\mu) p(\mathbf{y} | \mu) \\ 
                    &amp; = \frac{b^a}{\Gamma(a)}\mu^{a-1}e^{-b\mu} \prod_{i=1}^ne^{-\mu}\frac{\mu^{y_i}}{y_i!} \\
                    &amp; \propto \mu^{a + n\bar y -1} e^{-(b+n)\mu} \\ 
                    &amp; = \text{Gamma}(a + n\bar y, b+n)
\end{aligned}
\]</span></p>
<p>這個新的伽馬分布的期望值是：</p>
<p><span class="math display">\[
E(\mu | \mathbf{y}) = \frac{a + n\bar y}{b + n} = \bar y (\frac{n}{n + b}) + \frac{a}{b}(1 - \frac{n}{n + b})
\]</span></p>
<p>也就是說事後概率分布的伽馬分布，它的均值（期望）是先驗概率分布的均值 <span class="math inline">\(\frac{a}{b}\)</span> 和數據樣本均值 <span class="math inline">\(\bar y\)</span> 相互妥協的結果。泊淞－伽馬分布的模型常常可以用於估計發病率(rate)，或者相對危險度(relative risk)，反而較少用於估計率數據的均值(mean of possion data)。</p>
</div>
<div id="共軛先驗概率分布的總結" class="section level2">
<h2><span class="header-section-number">83.3</span> 共軛先驗概率分布的總結</h2>
<p>從這些共軛概率分布的結果和他們的特徵值的推導來看，我們發現：</p>
<ol style="list-style-type: decimal">
<li>事後概率分布的均值，總是將先驗概率分布均值和觀察數據的樣本均值相結合並且互相妥協之後的結果。</li>
<li>事後概率分布的標準差（方差），總是小於先驗概率分布的方差和觀察數據的樣本標準差的任何一個。</li>
</ol>
<p>而且，當樣本數據的樣本量很大， <span class="math inline">\(n \rightarrow \infty\)</span>：</p>
<ol style="list-style-type: decimal">
<li>事後概率分布的均值都會無限接近觀察數據的樣本均值。<span class="math inline">\(\text{The posterior mean } \rightarrow \text{ the sample mean}\)</span>；</li>
<li>事後概率分布的標準差會無限接近觀察數據的樣本標準誤。<span class="math inline">\(\text{The posterior standard deviation } \rightarrow \text{ the standard error}\)</span>；</li>
<li>事後概率分布就不再依賴先驗概率分布了。</li>
</ol>
<p>當事後概率分布，和先驗概率分布恰好都來自相同分布家族時，我們稱這樣的分布具有<strong>共軛性質(conjugacy)</strong>。此時，先驗概率分布的參數常常可以被解讀成爲<strong>先驗概率樣本(prior sample)</strong>。</p>
<p>這樣的分布我們總結一下常見的例子：</p>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Conjugate">表 83.1: </span>Examples of conjugate distributions and likelihood.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Likelihood
</th>
<th style="text-align:center;">
Parameter
</th>
<th style="text-align:center;">
Prior
</th>
<th style="text-align:center;">
Posterior
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Normal
</td>
<td style="text-align:center;">
mean
</td>
<td style="text-align:center;">
Normal
</td>
<td style="text-align:center;">
Normal
</td>
</tr>
<tr>
<td style="text-align:center;">
Normal
</td>
<td style="text-align:center;">
precision
</td>
<td style="text-align:center;">
Gamma
</td>
<td style="text-align:center;">
Gamma
</td>
</tr>
<tr>
<td style="text-align:center;">
Binomial
</td>
<td style="text-align:center;">
success prob.
</td>
<td style="text-align:center;">
Beta
</td>
<td style="text-align:center;">
Beta
</td>
</tr>
<tr>
<td style="text-align:center;">
Poisson
</td>
<td style="text-align:center;">
rate or mean
</td>
<td style="text-align:center;">
Gamma
</td>
<td style="text-align:center;">
Gamma
</td>
</tr>
</tbody>
</table>
<p>共軛先驗概率分布在數學上是十分便利的，但是並不是所有的似然都能找到它的共軛概率分布做先驗概率。這時候我們就需要求助於計算機模擬試驗的威力，下一章我們會接觸到怎樣使用 Markov Chain Monte Carlo (MCMC)來克服我們找不到共軛先驗概率的似然時，後驗概率分布的計算。它的中文名被翻譯成馬爾可夫鏈蒙特卡羅。</p>
</div>
<div id="BayesPrac03" class="section level2">
<h2><span class="header-section-number">83.4</span> Practical Bayesian Statistics 03</h2>
<p>A. 新藥試驗模型</p>
<p>新藥臨牀試驗的BUGS模型可以寫作:</p>
<pre><code># Drug example - model code

model{
   theta    ~ dbeta(a,b)               # prior distribution
   y        ~ dbin(theta,n)            # sampling distribution
   y.pred   ~ dbin(theta,m)            # predictive distribution
   P.crit   &lt;- step(y.pred-ncrit+0.5)  # =1 if y.pred &gt;= ncrit, 0 otherwise
}</code></pre>
<p>這個模型中 <code>theta</code> 是藥物的陽性反應率(有效率, response rate)；<code>y.pred</code>是40名未來患者中可能出現陽性反應的人數(number of positive response in 40 future patients)。<code>P.crit</code> 是用來表示患者中有25名或者更多的人有陽性反應時的指示變量(indicator variable)。</p>
<p>新藥試驗的數據則可以寫爲:</p>
<pre><code># Drug example - data
# values for a, b, m, n, ncrit could alternatively have been given in model description

list(
a = 9.2,    # parameters of prior distribution
b = 13.8,
y = 15,     # number of successes
n = 20,     # number of trials
m = 40,     # future number of trials
ncrit = 25) # critical value of future successes</code></pre>
<p>把這裏的模型保存稱爲 <code>drug-model.txt</code>文件，把數據保存成 <code>drug-data.txt</code>文件，我們來試着用OpenBUGS跑這個模型:</p>
<p>```{r　R-OpenBUGS09 12-Bayesian-stats-9, cache=TRUE, message=TRUE, warning=FALSE}</p>
</div>
</div>
<div id="step-1-check-model-1" class="section level1">
<h1><span class="header-section-number">第 84 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/drug-model.txt”, sep = "“))
# Load the data
modelData(paste(bugpath,”backupfiles/drug-data.txt“, sep =”“))<br />
# compile the model
modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(”P.crit“,”theta“,”y.pred")
samplesSet(parameters)</p>
</div>
<div id="generate-10000-iterations" class="section level1">
<h1><span class="header-section-number">第 85 章</span> Generate 10000 iterations</h1>
<p>modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
<pre><code>
此時我們獲得我們關心的各個事後概率分佈描述，其中陽性反應率的點估計是0.5626，其95%可信區間是(0.414, 0.706)。40名患者中25人或者以上出現有療效反應的概率是32.96%。

請繪製`theta`的事後概率分佈的密度曲線，以及`y.pred`的預測概率分佈:



```r
# Step 1 check model
modelCheck(paste(bugpath, &quot;backupfiles/drug-model.txt&quot;, sep = &quot;&quot;)) </code></pre>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1250-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1250-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/drug-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1252-1" title="1"><span class="co"># compile the model</span></a>
<a class="sourceLine" id="cb1252-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1254-1" title="1"><span class="co"># There is no need to provide initial values as </span></a>
<a class="sourceLine" id="cb1254-2" title="2"><span class="co"># they are aleady provided in the model specification</span></a>
<a class="sourceLine" id="cb1254-3" title="3"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1256-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1256-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P.crit&quot;</span>, <span class="st">&quot;theta&quot;</span>, <span class="st">&quot;y.pred&quot;</span>)</a>
<a class="sourceLine" id="cb1256-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;P.crit&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;y.pred&#39;</code></pre>
<div class="sourceCode" id="cb1260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1260-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1260-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1262-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1262-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">P.crit =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.crit&quot;</span>), </a>
<a class="sourceLine" id="cb1262-3" title="3">                    <span class="dt">theta =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta&quot;</span>), </a>
<a class="sourceLine" id="cb1262-4" title="4">                    <span class="dt">y.pred =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;y.pred&quot;</span>))</a>
<a class="sourceLine" id="cb1262-5" title="5"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1262-6" title="6"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1262-7" title="7"></a>
<a class="sourceLine" id="cb1262-8" title="8"></a>
<a class="sourceLine" id="cb1262-9" title="9"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>theta), <span class="dt">main =</span> <span class="st">&quot;theta sample 10000&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),</a>
<a class="sourceLine" id="cb1262-10" title="10">     <span class="dt">ylab =</span> <span class="st">&quot;P(theta)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Probability of response&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb1262-11" title="11"></a>
<a class="sourceLine" id="cb1262-12" title="12"><span class="kw">hist</span>(chain<span class="op">$</span>y.pred, <span class="dt">main =</span> <span class="st">&quot;y.pred sample 10000&quot;</span>, <span class="dt">prob =</span> <span class="ot">TRUE</span>,<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">40</span>),</a>
<a class="sourceLine" id="cb1262-13" title="13">     <span class="dt">ylab =</span> <span class="st">&quot;P(y.pred)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Number of success&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center">
<img src="bookdown_files/figure-html/%20R-OpenBUGS10-1.png" alt="Posterior and predictive distributions for Drug example" width="80%" />
<p class="caption">
(#fig: R-OpenBUGS10)Posterior and predictive distributions for Drug example
</p>
</div>
<p>比較一下這裏的模型和我們前一章的練習中的模型，</p>
<ul>
<li>Model from Practical 2</li>
</ul>
<pre><code>#  Monte Carlo predictions for Drug example

model{
    theta   ~ dbeta(9.2,13.8)          # prior distribution
    y         ~ dbin(theta,20)         # sampling distribution
    P.crit   &lt;- step(y-14.5)           # =1 if y &gt;= 15, 0 otherwise
}</code></pre>
<ul>
<li>Model from Practical 3</li>
</ul>
<pre><code># Drug example - model code

model{
   theta    ~ dbeta(a,b)               # prior distribution
   y        ~ dbin(theta,n)            # sampling distribution
   y.pred   ~ dbin(theta,m)            # predictive distribution
   P.crit   &lt;- step(y.pred-ncrit+0.5)  # =1 if y.pred &gt;= ncrit, 0 otherwise
# data
y &lt;- 15
}</code></pre>
<p>這兩個模型的構成基本上是相同的，最重要的不同點在於，Practical 2中的 MC分析中沒有關於該次試驗的觀測數據 <code>y</code>，也就是20名患者中陽性反應，療效顯著的患者人數。所以，該模型不能從試驗數據中“學習”，導致 OpenBUGS其實在進行 MC 模擬試驗時僅僅是從先驗概率分佈 <span class="math inline">\(\text{Beta}(9.2, 13.8)\)</span> 中隨機採樣對結果做出預測。在 Practical 3的模型裏，我們把試驗數據加入到了模型裏面 <code>y &lt;- 15</code>，所以OpenBUGS此時識別了本次試驗數據是20人中15人有效，接下來它就知道需要做事後概率分佈的計算而不是一個結果的預測。獲得事後概率分佈之後，OpenBUGS也就開始從事後概率分佈當中獲取隨機樣本。然後我們需要在模型中加入新的變量來預測下一次如果做40人的研究時，可能出現的事後概率分佈。</p>
<p>如果把模型中陽性反應率<code>theta</code>的先驗概率分佈改成一個沒有太多信息的，連續型均勻分佈(uniform distribution)，例如 <span class="math inline">\(\text{Uniform}(0,1)\)</span>，或者是 <span class="math inline">\(\text{Beta}(1,1)\)</span>。MC結果會變成怎樣呢？</p>
<p>先驗概率爲連續型均勻分佈的BUGS模型和數據可以寫成是:</p>
<pre><code># Drug example - model code

model{
   theta    ~ dunif(0,1)               # prior distribution uniform distribution
   y        ~ dbin(theta,n)            # sampling distribution for n observed patients
   y.pred   ~ dbin(theta,m)            # predictive distribution for m new patients
   P.crit   &lt;- step(y.pred-ncrit+0.5)  # =1 if y.pred &gt;= ncrit, 0 otherwise
}</code></pre>
<pre><code>list(
y = 15,                                # number of successes
n = 20,                                # number of trials 
m = 40,                                # future number of trials 
ncrit = 25                             # critical value of future successes
)</code></pre>
<p>```{r　R-OpenBUGS11 12-Bayesian-stats-10, cache=TRUE, message=TRUE, warning=FALSE}</p>
</div>
<div id="step-1-check-model-2" class="section level1">
<h1><span class="header-section-number">第 86 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/drug-modeluniform.txt”, sep = "“))
# Load the data
modelData(paste(bugpath,”backupfiles/drug-datauniform.txt“, sep =”“))<br />
# compile the model
modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(”P.crit“,”theta“,”y.pred")
samplesSet(parameters)</p>
</div>
<div id="generate-10000-iterations-1" class="section level1">
<h1><span class="header-section-number">第 87 章</span> Generate 10000 iterations</h1>
<p>modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
<pre><code>
這個結果則提示，如果使用連續型均勻分佈的先驗概率，新藥試驗的陽性反應率是0.73，95%可信區間是(0.53, 0.89)。根據這個試驗結果對下次40人的試驗做預測時，認爲40人中大於或者等於25人有顯著療效(陽性反應)的概率會有0.84。

B. THM 三氯甲烷濃度實例

在飲用水檢測三氯甲烷濃度這個試驗中，我們已知濃度的方差，希望通過貝葉斯方法推斷其均值。

以下是我們需要思考的問題:
1. 在這個供水區域內，三氯甲烷的濃度均值是多少？
2. 兩次測量濃度的數據，它的似然是怎樣的？ 如果可以假定三氯甲烷濃度服從正態分佈，那麼似然就是正態分佈似然: `y[i] ~ N(theta, sigma^2)`。
3. 在上面提到的正態分佈似然中，有哪些參數，哪個是已知的哪個是未知的？ `theta` 區域濃度的均值未知，`sigma`區域濃度的方差是給定的(已知的)。
4. 哪個參數需要在模型中給出先驗概率分佈？該怎樣指定這個先驗概率分佈才合理？`theta`，區域濃度均值需要給它指定一個先驗概率分佈，正態分佈數據均值的先驗概率分佈可以使用正態分佈。


</code></pre>
</div>
<div id="thm-model" class="section level1">
<h1><span class="header-section-number">第 88 章</span> THM model:</h1>
<p>model {
# data
y[1] &lt;- 128
y[2] &lt;- 132
tau &lt;- 1/pow(5, 2)</p>
<p>for(i in 1:2) {
y[i] ~ dnorm(theta, tau)
}</p>
</div>
<div id="informative-prior" class="section level1">
<h1><span class="header-section-number">第 89 章</span> informative prior</h1>
<p>theta ~ dnorm(120, prec)
prec &lt;- 1/100</p>
</div>
<div id="vague-prior" class="section level1">
<h1><span class="header-section-number">第 90 章</span> vague prior</h1>
</div>
<div id="theta-dnorm0-0.000001" class="section level1">
<h1><span class="header-section-number">第 91 章</span> theta ~ dnorm(0, 0.000001)</h1>
</div>
<div id="or" class="section level1">
<h1><span class="header-section-number">第 92 章</span> OR</h1>
</div>
<div id="theta-dunif-10000-10000" class="section level1">
<h1><span class="header-section-number">第 93 章</span> theta ~ dunif(-10000, 10000)</h1>
<p>}</p>
<pre><code>
在BUGS語言中，正態分佈用 `dnorm(theta, tau)`，其中 `theta` 爲均值，`tau` 是精確度(precision = 1/variance)，它是方差的倒數。

```{r　R-OpenBUGS12 12-Bayesian-stats-11, cache=TRUE, message=TRUE, warning=FALSE}


# Step 1 check model
modelCheck(paste(bugpath, &quot;backupfiles/thm-model.txt&quot;, sep = &quot;&quot;)) 
  
# compile the model
modelCompile(numChains = 1) 
# There is no need to provide initial values as 
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(&quot;theta&quot;)
samplesSet(parameters)

# Generate 10000 iterations
modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats(&quot;*&quot;)
print(sample.statistics)</code></pre>
<p>所以這個區域三氯甲烷的事後均值和95%可信區間分別是 128.9 (122.4, 135.5)。和我們之前用精確計算法給出的結果相同。</p>
<p>如果在這個模型中，我們嘗試沒有信息的先驗概率分佈，結果會怎樣呢？</p>
<p>```{r　R-OpenBUGS13 12-Bayesian-stats-12, cache=TRUE, message=TRUE, warning=FALSE}</p>
</div>
<div id="step-1-check-model-3" class="section level1">
<h1><span class="header-section-number">第 94 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/THM-vaguemodel.txt”, sep = ""))</p>
</div>
<div id="compile-the-model" class="section level1">
<h1><span class="header-section-number">第 95 章</span> compile the model</h1>
<p>modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(“theta”)
samplesSet(parameters)</p>
</div>
<div id="generate-10000-iterations-2" class="section level1">
<h1><span class="header-section-number">第 96 章</span> Generate 10000 iterations</h1>
<p>modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
<pre><code>
MC試驗10000次給出的事後均值是130.0，它和樣本均值相同，因爲此時我們給模型一個幾乎不含有效信息的先驗概率分佈時，意味着我們讓試驗獲得的數據做完全主導作用，&quot;data speak for themselves&quot;。

C. Disease risk in a small area

下面的BUGS模型代碼可以用來進行泊淞－伽馬分布似然的MC計算。在這個例子中，在某個區域我們觀察到５例白血病新病例，已知該區域的年齡性別標準化發病期望病例數是$E = 2.8$。注意看我們在代碼中加入了兩種不同類型的先驗概率分布，一個是沒有太多信息的(vague prior distribution)`dgamma(0.1, 0.1)`，一個則是有一定信息的(informative prior, stribution) `dgamma(48, 40)`。我們把兩個先驗概率分布同時加在一個模型裏，這是十分便於進行兩種先驗概率對結果的影響的比較的手段。你當然可以把它寫成兩個不同的模型。注意模型代碼是如何表示事後概率分布和計算相對危險度比(relative risk)大於1的概率的。
</code></pre>
<p>model {</p>
<p>lambda[1] ~ dgamma(0.1, 0.1) # vague prior distribution
lambda[2] ~ dgamma(48, 40) # informative prior distribution</p>
<p>y[1] ~ dpois(mu[1]) # sampling distribution
mu[1] &lt;- lambda[1] * 2.8</p>
<p># repeat for second model
y[2] ~ dpois(mu[2]) # sampling distribution
mu[2] &lt;- lambda[2] * 2.8</p>
</div>
<div id="is-relative-risk-1" class="section level1">
<h1><span class="header-section-number">第 97 章</span> Is relative risk &gt; 1</h1>
<p>P.excess[1] &lt;- step(lambda[1] - 1)
P.excess[2] &lt;- step(lambda[2] - 1)</p>
<p># data
y[1] &lt;- 5
y[2] &lt;- 5 # replicate data to fit both models together</p>
<p>}</p>
<pre><code>
```{r　R-OpenBUGS14 12-Bayesian-stats-13, cache=TRUE, message=TRUE, warning=FALSE}


# Step 1 check model
modelCheck(paste(bugpath, &quot;backupfiles/disease-model.txt&quot;, sep = &quot;&quot;)) 

# compile the model
modelCompile(numChains = 1) 
# There is no need to provide initial values as 
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(&quot;P.excess[1]&quot;, &quot;P.excess[2]&quot;, &quot;lambda[1]&quot;, &quot;lambda[2]&quot;)
samplesSet(parameters)

# Generate 10000 iterations
modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats(&quot;*&quot;)
print(sample.statistics)</code></pre>
<p>在沒有信息的先驗概率(<code>dgamma(0.1, 0.1)</code>)分布條件下，該地區可能有較高白血病發病率的概率是85%，但是在有參考價值信息的先驗概率分布(<code>dgamma(48, 40)</code>)條件下，該地區可能有較高白血病發病率的概率是93%。所以，盡管相對危險度(relative risk)的事後均值在沒有信息的先驗概率分布條件下比較高(<code>lambda[1] = 1.766 &gt; lambda[2] = 1.239</code>)，但是沒有信息的先驗概率分布條件下，這個相對危險度大於1的概率(85%)要比有信息的先驗概率分布條件下相對危險度大於1的概率要低(93%)。這是因爲在沒有信息的先驗概率分布條件下，相對危險度估計本身有太多的不確定性(uncertainty，圖<a href="#fig:R-OpenBUGS15">97.1</a>)。</p>
<div class="sourceCode" id="cb1271"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1271-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1271-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/disease-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1273-1" title="1"><span class="co"># compile the model</span></a>
<a class="sourceLine" id="cb1273-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1275"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1275-1" title="1"><span class="co"># There is no need to provide initial values as </span></a>
<a class="sourceLine" id="cb1275-2" title="2"><span class="co"># they are aleady provided in the model specification</span></a>
<a class="sourceLine" id="cb1275-3" title="3"><span class="kw">modelGenInits</span>() <span class="co">#</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1277-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1277-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;P.excess[1]&quot;</span>, <span class="st">&quot;P.excess[2]&quot;</span>, <span class="st">&quot;lambda[1]&quot;</span>, <span class="st">&quot;lambda[2]&quot;</span>)</a>
<a class="sourceLine" id="cb1277-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;P.excess[1]&#39;</code></pre>
<pre><code>## monitor set for variable &#39;P.excess[2]&#39;</code></pre>
<pre><code>## monitor set for variable &#39;lambda[1]&#39;</code></pre>
<pre><code>## monitor set for variable &#39;lambda[2]&#39;</code></pre>
<div class="sourceCode" id="cb1282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1282-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1282-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1284-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1284-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">P.excess1 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.excess[1]&quot;</span>), </a>
<a class="sourceLine" id="cb1284-3" title="3">                    <span class="dt">P.excess2 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P.excess[2]&quot;</span>), </a>
<a class="sourceLine" id="cb1284-4" title="4">                    <span class="dt">lambda1 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;lambda[1]&quot;</span>), </a>
<a class="sourceLine" id="cb1284-5" title="5">                    <span class="dt">lambda2 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;lambda[2]&quot;</span>))</a>
<a class="sourceLine" id="cb1284-6" title="6"></a>
<a class="sourceLine" id="cb1284-7" title="7"><span class="kw">boxplot</span>(chain<span class="op">$</span>lambda1,chain<span class="op">$</span>lambda2, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;lambda&quot;</span>, </a>
<a class="sourceLine" id="cb1284-8" title="8">        <span class="dt">outline=</span><span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;boxplot: lambda&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">4</span>), </a>
<a class="sourceLine" id="cb1284-9" title="9">        <span class="dt">names =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;2&quot;</span>)) </a>
<a class="sourceLine" id="cb1284-10" title="10"><span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">1.5</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS15"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS15-1.png" alt="Box plots of relative risk (lambda) of leukaemia under different priors (vague = 1, informative = 2)." width="80%" />
<p class="caption">
圖 97.1: Box plots of relative risk (lambda) of leukaemia under different priors (vague = 1, informative = 2).
</p>
</div>
<p>圖 <a href="#fig:R-OpenBUGS15">97.1</a>的箱式圖也告訴我們，相對危險度的事後概率分布在有信息的先驗概率分布條件下要精確得多，其標準差<code>sd[2] = 0.17</code>也要小得多 <code>sd[1] = 0.78</code>。所以，此時，先驗概率分布對我們的事後概率分布推斷產生了較大的影響，有信息的先驗概率分布把相對危險度的估計值更加拉近了1的同時(more realistic)，也使得相對危險度的事後概率估計變得更加精確。</p>
<p>接下來，假設我們在該區域進行了更長時間的觀察，收集到100個新的白血病病例，同時在這段時間內病例的期望值只有56例。據此，重新改寫這個模型，在兩種先驗概率分布條件下，此時由於觀察數據信息量的增加，相對危險度的事後估計有怎樣的變化？</p>
<pre><code>model {

    lambda[1]  ~ dgamma(0.1, 0.1)   # vague prior distribution
    lambda[2]  ~ dgamma(48, 40)     # informative prior distribution

    y[1]  ~ dpois(mu[1])             # sampling distribution
    mu[1] &lt;- lambda[1] * 56          # the expectation changed from 2.8 to 56

    # repeat for second model
    y[2] ~ dpois(mu[2])             # sampling distribution
    mu[2] &lt;- lambda[2] * 56         # the expectation changed from 2.8 to 56
  
  # Is relative risk &gt; 1
  P.excess[1] &lt;- step(lambda[1] - 1) 
  P.excess[2] &lt;- step(lambda[2] - 1)
 
    # data
    y[1] &lt;- 100             # the observed new cases changed from 5 to 100
    y[2] &lt;- 100             # replicate data to fit both models together

}</code></pre>
<p>```{r　R-OpenBUGS16 12-Bayesian-stats-14, cache=TRUE, message=TRUE, warning=FALSE}</p>
</div>
<div id="step-1-check-model-4" class="section level1">
<h1><span class="header-section-number">第 98 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/disease-modelupdated.txt”, sep = ""))</p>
</div>
<div id="compile-the-model-1" class="section level1">
<h1><span class="header-section-number">第 99 章</span> compile the model</h1>
<p>modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(“P.excess[1]”, “P.excess[2]”, “lambda[1]”, “lambda[2]”)
samplesSet(parameters)</p>
</div>
<div id="generate-10000-iterations-3" class="section level1">
<h1><span class="header-section-number">第 100 章</span> Generate 10000 iterations</h1>
<p>modelUpdate(10000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
<pre><code>
有了更多的觀察數據的模型，我們看到，相對危險度的事後估計`lambda[1], lambda[2]`都變得更加精確了，有了更小的標準差。這和我們的預期相同，因爲觀察數據增加自然會提高相對危險度估計的精確度。可是，我們發現在沒有信息的先驗概率分布條件下，相對危險度的事後估計幾乎沒有太大的變化(1.786 v.s. 1.766)。相反地，有信息的先驗概率分布條件下，相對危險度的事後估計比之前增加了不少(1.541 v.s. 1.239)。這主要是因爲，現在我們得到更多的觀察數據，這些數據得到的信息被給予了更多的權重，且觀察數據提示相對危險度應該要比較大(100/56 = 1.786)。

盡管觀察數據確實給模型提供了較多的有價值的信息，你會發現，我們使用的第二個先驗概率分布（也就是有信息的先驗概率分布）仍然對相對危險度的事後估計起到了相當的影響(the prior variance is 0.03, giving prior sd of 0.17)。這也是因爲這個先驗概率分布給出的信息量，幾乎相當於觀察數據給出的信息量（二者的標準差很接近）。另外一種理解此現象的方法是看事後概率分布推導出的新的伽馬分布的計算式：

$$
\begin{aligned}
p(\lambda | y, E) &amp; \propto p(\lambda) p (y | \lambda, E) \\ 
                  &amp; \propto \frac{b^a}{\Gamma(a)}\lambda^{a-1}e^{-b\lambda} \frac{(\lambda E)^ye^{-\lambda E}}{y!} \\ 
                  &amp; \propto \lambda^{a + y -1}e^{-(b+E)\lambda} \\ 
                  &amp; = \text{Gamma}(a + y, b + E)
\end{aligned}
$$

由於事後伽馬分布的方差（標準差）主要由第二個參數$(b + E)$決定，從上面的公式推導我們可以看見，事後伽馬分布的第二個參數$(b + E)$，分別是先驗概率分布的第二個參數$(b = 40)$，和觀察數據的期望值$(E = 56)$。由於這兩個數值大小接近，所以我們也可以理解此時先驗概率提供的信息和我們觀察數據提供的信息旗鼓相當。另外，在這個新的觀察數據條件下，我們無論使用哪個先驗概率分布做條件，都獲得了100%的結果也就是這個特定區域的白血病發病率大於期望值的概率是100%。也就是我們此時有100%的把握認爲這個特定區域的白血病發病率較高。



```r
#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;- data.frame(P.excess1 = samplesSample(&quot;P.excess[1]&quot;), 
                    P.excess2 = samplesSample(&quot;P.excess[2]&quot;), 
                    lambda1 = samplesSample(&quot;lambda[1]&quot;), 
                    lambda2 = samplesSample(&quot;lambda[2]&quot;))

boxplot(chain$lambda1,chain$lambda2, col = &quot;green&quot;, ylab = &quot;lambda&quot;, 
        outline=FALSE, main = &quot;boxplot: lambda&quot;, ylim = c(0,4), 
        names = c(&quot;1&quot;, &quot;2&quot;)) 
abline(h = 1.66)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGS17"></span>
<img src="bookdown_files/figure-html/R-OpenBUGS17-1.png" alt="Box plots of relative risk (lambda) of leukaemia under different priors (vague = 1, informative = 2) with more observations." width="80%" />
<p class="caption">
圖 100.1: Box plots of relative risk (lambda) of leukaemia under different priors (vague = 1, informative = 2) with more observations.
</p>
</div>
<p>D. James Bond Example.</p>
<p>007邦德喝了16杯馬丁尼酒，每飲一杯，都被問道那杯馬丁尼酒是被調酒師用搖的(shaken)還是用攪拌的(stired)調制的。結果在這邦德喝過的16杯馬丁尼酒中，他居然答對了13杯。（007就是流弊）</p>
<ol style="list-style-type: decimal">
<li><p>嘗試修改新藥試驗的模型代碼，用均一分布作爲參數<span class="math inline">\(\theta\)</span>的先驗概率分布，你是否能進行一個貝葉斯分析來回答這個問題：“邦德能夠正確區分一杯馬丁尼酒的調制方法的概率是多少？”</p></li>
<li><p>那如果把這個問題稍微改變一下，“邦德能夠區分馬丁尼酒的調制方法的概率是多少？(what is the probability that James Bond has at least some ability to tell the difference between shaken and stirred martinis?i.e. better than guessing)”你能回答嗎？</p></li>
<li><p>假定這樣一個場景，你和另外三個朋友在酒吧遇見了邦德，你們每個人都說要和邦德玩品酒的遊戲，如果邦德能準確分辨出馬丁尼酒的調制方法，你們就付那一杯酒錢，如果邦德答錯了，那他要把酒錢付給你們。在這樣的場景下，已知邦德能分辨16杯馬丁尼酒中的13杯，你們４人有多大的概率能把酒錢都賺回來？</p></li>
</ol>
<pre><code># Bond example - model code

model{
   theta    ~ dunif(0, 1)               # prior distribution
   y        ~ dbin(theta,16)            # sampling distribution
   
   P.ability &lt;- step(theta - 0.5)       # = 1 if theta &gt; 0.5 (i.e. if better than guessing)
   
   y.pred   ~ dbin(theta,4)             # predictive distribution for 4 new taste tests
   
   P.Moneyback   &lt;- step(0.5 - y.pred)  # =1 if y.pred &lt;= 0.5, 0 otherwise
  #P.Moneyback   &lt;- equals(y.pred, 0)   # alternative way of calculating predictive prob of 0 correct taste tests
# data 
  y &lt;- 13                               # observed number of correct taste tests in original experiment
  
}</code></pre>
<p>```{r　R-OpenBUGS18 12-Bayesian-stats-15, cache=TRUE, message=TRUE, warning=FALSE}</p>
</div>
<div id="step-1-check-model-5" class="section level1">
<h1><span class="header-section-number">第 101 章</span> Step 1 check model</h1>
<p>modelCheck(paste(bugpath, “backupfiles/bondmodel.txt”, sep = ""))</p>
</div>
<div id="compile-the-model-2" class="section level1">
<h1><span class="header-section-number">第 102 章</span> compile the model</h1>
<p>modelCompile(numChains = 1)
# There is no need to provide initial values as
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(“P.ability”, “P.Moneyback”, “theta”, “y.pred”)
samplesSet(parameters)</p>
</div>
<div id="generate-100000-iterations" class="section level1">
<h1><span class="header-section-number">第 103 章</span> Generate 100000 iterations</h1>
<p>modelUpdate(100000)
#### SHOW POSTERIOR STATISTICS
sample.statistics &lt;- samplesStats("*")
print(sample.statistics)</p>
<pre><code>
1. 第一個問題，可以用 `theta` 的事後概率分布來回答，十萬次MC計算的結果顯示，邦德能夠準確分辨馬丁尼酒的調制方法的概率是0.78，且這個事後概率分布的95%可信區間是(0.5653, 0.9317)。

2. 第二個問題，邦德擁有能準確分辨馬丁尼酒調制方法的能力(不是猜的)的概率是 `P.ability = 0.9935`。如果邦德只是瞎猜，那麼 `theta` 就只能等於或者十分接近0.5。所以我們相信邦德有這樣一種分辨能力的概率是99.4%。

3. 你和４名好友在酒吧能從邦德身上把4被馬丁尼酒錢賺回來的概率，也就等價於邦德在這四次猜酒的結果上都給出了錯誤的答案，四次全錯的概率，就是 `P.Moneyback = 0.0057`。模型代碼中 `y.pred` 用來預測邦德在接下來４次猜酒遊戲中給出的答案是 0還是 1(四次都對的話和爲4)。結果顯示 `y.pred` 的均值達到了3.116，４次全錯的概率是驚人的0.006。

# 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言 {#MCMC-methods}

## Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法

### 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？

貝葉斯統計推斷是圍繞着事後概率分佈進行的: 

$$
p(\mathbf{\theta}|x) \propto p(x|\mathbf{\theta})\times p(\mathbf{\theta})
$$

其中，$\mathbf{\theta}$ 常常是一個很長的參數向量(vector of parameters) $\mathbf{\theta} = \{ \theta_1, \theta_2, \dots, \theta_k \}$，其中似然$p(x|\mathbf{\theta})$和先驗概率分佈$p(\mathbf{\theta})$一般都能找到相應的計算式，或者叫做**閉合解形式(closed form)**。可惜事後概率分佈 $p(\mathbf{\theta}|x)$就沒有這麼幸運，你會常常碰見**無法在數學上獲得解析解的情況(analytically untractable)**。

此時，我們又希望能夠獲得

- 某個或者某些參數的事後概率分布 $p(\theta_i | x) = \int\int\dots\int p(\mathbf{\theta}|x)d\mathbf{\theta_{(-i)}}$ (where $\mathbf{\theta_{(-i)}}$ denotes the vector of $\theta$s excluding $\theta_i$)。
- 計算某個或者某些參數的事後概率分布的數學性質，特徵值如均值 $= \int\theta_i p(\theta_i | x)d\theta_i$，或者尾部的概率面積(tail areas) $=\int_T^\infty p(\theta_i |x)d\theta_i$等等。

我們無法獲得解析解 (analytical solution/closed solution) 的情況下，可以求助於數學上的數值解 (numerical solution/intergration)。

第二章 (\@ref(MC-estimation)) 我們已經見識過了蒙特卡羅模擬法可以用來從先驗概率分布，或者從**閉合解形式(closed form)**的事後概率分布中採樣計算的過程。如果我們可以把人類不可能完成的任務，也交給計算機來對無法獲取閉合解的事後概率分布做蒙特卡羅樣本採集的話，那麼貝葉斯統計學推斷就可以被推廣到幾乎任何一種模型，任何一種試驗設計中。

所以，我們的目的是希望從無法獲得閉合解形式的多維(多變量)事後概率分布$p(\mathbf{\theta}|x)$中採集樣本做計算機模擬實驗(simulation)。但是，現實中從這樣的事後概率分布中採集**相互獨立(independent)**的樣本，是不容易的一件事。反其道行之，科學家發現，從事後概率分布**有依賴性的馬爾可夫鏈式樣本採集(dependent sampling from a Markov chain)**，作爲一種穩態分布(stationary/equilibrium distribution)卻相對容易。

一連串的隨機變量 $\theta^{(0)},\theta^{(1)},\theta^{(2)},\cdots$ 形成的[馬爾可夫鏈](https://en.wikipedia.org/wiki/Markov_chain)，其重點在於 $\theta^{(i + 1)} \sim p(\theta|\theta^{(i)}$，也就是在 $\theta^{(i)}$ 的條件下 $\theta^{(i+1)}$ 和它之前的樣本 $\theta^{(i - 1)},\cdots,\theta^{(0)}$是獨立的。這樣的馬爾科夫鏈式採樣，需要特殊的方法來進行。[美特羅波利斯-海斯廷斯(Metroplis-Hastings)算法(algorithm)](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)是其中的一種。而[吉布斯(Gibbs)採樣法](https://en.wikipedia.org/wiki/Gibbs_sampling)是 Metropolis-Hastings 算法的一種特殊形態。吉布斯採樣法是從**全條件分布(full conditional distributions)**中產生一串馬爾科夫鏈的算法。我們下面來看看吉布斯採樣法的特徵和使用方法，其詳細的算法我們過後再來討論。

### 吉布斯採樣 {#Gibbs-sampling}

假設，現在我們在給定了數據 $x$ 之後，我們需要在關於它的一個未知參數的向量中$\mathbf{\theta} = (\theta_1, \theta_2, \dots,\theta_k)$採集事後概率分布樣本。那麼吉布斯採樣法的具體過程描述如下：

1. 把未知參數向量分成不同的成分，最簡單的就是每個元素爲一個部分 $\mathbf{\theta} = (\theta_1, \theta_2, \dots,\theta_k)$；
2. 給每個部分/參數選取一個起始值(starting/initial values) $\theta_1^{(0)},\theta_2^{(0)},\dots,\theta_k^{(0)}$；
3. 然後:&lt;br&gt;從$p(\theta_1|\theta_2^{(0)},\theta_3^{(0)},\dots,\theta_k^{(0)},x)$中採集 $\theta_1^{(1)}$&lt;br&gt;從$p(\theta_2|\theta_1^{(1)},\theta_3^{(0)},\dots,\theta_k^{(0)},x)$中採集$\theta_2^{(1)}$&lt;br&gt;$\vdots$&lt;br&gt;從$p(\theta_k|\theta_1^{(1)},\theta_2^{(1)},\dots,\theta_{k-1}^{(0)},x)$中採集$\theta_k^{(1)}$
4. 重復第3步 $N$ 次，我們就可以獲得一串參數的事後分布樣本 $\mathbf{\theta}^{(0)},\mathbf{\theta}^{(1)},\dots,\mathbf{\theta}^{(N)}$。當 $N\rightarrow\infty$ 我們就獲得了多維事後概率分布的一個樣本 $p(\mathbf{\theta}|x)$。

用只有兩個位置參數的向量來解釋就是：$k = 2, \text{ i.e. } \mathbf{\theta} = (\theta_1, \theta_2)$。下圖 \@ref(fig:gibbssampling) 展示了對兩個未知參數進行吉布斯採樣的一個過程：當我們先設定一組起始值 $\mathbf{\theta}^{(0)}$，之後從$p(\theta_1|\theta_2^{(0)}, x)$中採集$\theta_1^{(1)}$，然後再從 $p(\theta_2|\theta_1^{(1)}, x)$中採集$\theta_2^{(1)}$，這樣就獲得了樣本 $\mathbf{\theta}^{(1)}$。然後再重復相同搞得過程採集接下來的參數樣本。

&lt;div class=&quot;figure&quot; style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;img/gibbs_sampling.png&quot; alt=&quot;Gibbs sampling with k = 2.&quot; width=&quot;80%&quot; /&gt;
&lt;p class=&quot;caption&quot;&gt;(\#fig:gibbssampling)Gibbs sampling with k = 2.&lt;/p&gt;
&lt;/div&gt;

利用馬爾科夫鏈的性質，可以被證明的是當採樣達到無窮大 $N\rightarrow\infty$，無論起始樣本 $(\theta_1^{(0)},\theta_2^{(0)},\dots,\theta_k^{(0)})$ 如何採樣，最終產生的事後概率樣本 $\mathbf{\theta}^{(0)},\mathbf{\theta}^{(1)},\dots,\mathbf{\theta}^{(N)}$ 將會收斂成爲真實的事後概率分布 $p(\mathbf{\theta}|y)$，所以確保了重復這個過程的次數是無窮大時，起初的一部分采样，$N_0$可作爲初始樣本，並且因爲通常一開始的採樣過程是不穩定的，而把他們從總體事後概率分布樣本中刨除，這個過程被叫做 burn in。最終可獲得樣本量爲 $N-N_0$ 的事後概率分布樣本。

我们需要指出的是，這一採集事後概率分布樣本的方法之所以有用，是因爲條件事後概率分布(conditional posterior sampling)的採集，要比全事後概率分布(full posterior sampling)的採集要容易得多。否則，我們爲啥不直接從全事後概率分布中採樣呢。

簡單地說，比如我們需要同時對正態分布數據似然的均值，和方差兩個未知參數進行事後概率分布樣本的採集，兩個未知參數的事後概率分布需要用到復雜的微積分推導過程，但是我們知道已知均值時方差的事後概率分布，或者是已知方差時均值的事後概率分布，它們都比兩個未知參數時的計算和推導要簡單明了得多。

接下來我們來討論一下使用MCMC在貝葉斯統計學推斷中的實際應用和一些技巧。

### 初始值 initial values

MCMC過程需要對所有的未知參數先給出起始值(initial/starting values)。我們在使用BUGS進行貝葉斯統計學推斷時，可以利用先驗概率分布對各個未知參數隨機產生各自的起始值，但是這要建立在先驗概率分布是含有有價值的信息的前提下(informative priors)，如果我們只有一些聊勝於無的先驗概率分布(vague priors)，隨機從這樣的分布中產生起始值的話，很可能導致計算機選取很不恰當的起始值使得模型需要花很長的時間才能收斂，有些時候甚至導致計算機崩潰。這時候，統計學家的經驗是我們最好人爲地給模型中的未知參數設定幾個&quot;合理&quot;的起始值(separate reasonable initial values lists)，以防止不收斂或者計算機崩潰的情況出現。同時，我們也發現用戶如果給模型提供合理的起始值，也有助於鑑別模型收斂(convergence checking)。

在 BUGS 語言中，起始值可以直接寫在模型中，也可以寫在另外一個獨立的文件裏。需要明確指出的是，這些起始值是用來輔助 MCMC 採樣的，**起始值並不是先验概率(initial values are not priors)**。

## 使用 MCMC 時需要考慮的一些問題

在使用 MCMC 時有兩個主要的問題需要我們思考：

1. 收斂時間：MCMC採集的樣本 $\{\mathbf{\theta}^{(t)}\}$，需要多久時間能夠到達或者接近事後概率分布 $p(\mathbf{\theta}|x)$。
2. 效率：從採集的樣本 $\mathbf{\theta}^{(t)}$ 中估計的參數是否在事後概率分布 $p(\mathbf{\theta}|x)$ 中真的有效 (how well are functionals of $p(\mathbf{\theta}|x)$ estimated from $\{\mathbf{\theta}^{(t)}\}$)。

### 收斂時間

收斂時間，是我們關心的最主要的問題之一，我們在進行 MCMC 時要花多長時間才能使採集的樣本達到或者接近(數學上叫做收斂)真是的事後概率分布呢？換句話說，我們需要從採集的樣本中刨除掉多少一開始採集的不穩定的樣本呢(how do we know the number of &quot;burn-in&quot; iterations)？可以說沒有人能準確地給出一個答案。所以在檢查MCMC採樣是否收斂時，我們需要格外的小心。很多時候，沒有人能夠給出100%確定的答案說一條MCMC鏈達到了收斂，但是幸運地是，我們能準確地判斷沒有成功收斂的 MCMC 鏈。

檢查MCMC是否收斂，最常用的方法是視覺檢查，作出MCMC鏈式圖來輔助我們診斷。我們建議，使用多個不同的起始值，產生多個不同的 MCMC 樣本鏈來輔助診斷。當然，除了視覺診斷，另外還存在一些比較鏈內(within)和鏈間(between)方差的方法來進行收斂診斷的手段。但是，沒有哪種方法是萬無一失的。在 R 裏面，有一個很強大的包 [`coda`](https://cran.r-project.org/doc/Rnews/Rnews_2006-1.pdf#page=7)，它被設計來把OpenBUGS的輸出結果 (output) 轉變成爲輸入對象 (input object)，利用R來便利地進行模型分析和診斷。許多對模型收斂程度的診斷，都會認爲未知參數的起始值是相對事後概率分布來說過度離散的。所以，建議在提供起始值的時候，每一個未知參數的起始值，都盡量爲每一個MCMC鏈給出幾個**&quot;合理&quot;但差異較大(plausible but widely differing initial values)**的起始值。


評估MCMC的收斂與否，一個比較實用的手段是雙保險的方法: 就是既從圖形視覺上來診斷產生的MCMC樣本鏈的收斂程度，也通過統計檢驗方法對收斂作收斂與否的統計學分析。當某些模型含有衆多的未知的參數的時候，你想對每一個未知參數的事後概率分佈的MCMC採樣是否收斂進行分析和檢驗可能是不太實際的，此時的常見手段是隨機選取衆多未知參數中幾個來分析其MCMC採樣結果的收斂與否。

我們的選擇包括：

- 把MCMC事後概率分布採樣過程的整個歷史(history)痕跡(trace)全部繪制出來-不同起始值的同一個未知參數的MCMC鏈是否都給出了相對穩定的歷史痕跡？他們是否有合理的相互重疊(overlapping)？
- 檢查自我相關程度(autocorrelation)-過高的自相關暗示收斂過程較慢。(high autocorrelation is a symtom of slow convergence)。
- 看Gelman-Rubin收斂統計量-它通過比較MCMC鏈內方差(within variability)和鏈間方差(between variability)來評估MCMC鏈是否達到收斂。

#### 視覺檢驗方法

視覺檢驗方法是一種十分有效的輔助鑑別MCMC樣本鏈是否收斂的手段。常用的方法是使用幾個不同，且合理的起始值進行MCMC採樣運算，看他們是否最終都收斂到相同的位置。通常我們會把採集的 $\theta^{(i)}$ 樣本和 $i$ (也就是採樣次數) 做圖，如果順利達到收斂，圖形應該顯示爲隨機出現在一條直線上下附近的散點圖。

在BUGS軟件裏，通常有兩種方法可以供用戶查看未知參數的MCMC樣本鏈的歷史痕跡(history trace)：


1. 實時觀察MCMC樣本採集的歷史痕跡。 (只能在windows下進行，需要用到OpenBUGS的窗口)
2. MCMC樣本採集結束以後把採集的未知參數事後樣本的歷史痕跡一次性全部繪制出來。

繪制歷史痕跡時用不同顏色來表示不同起始值的MCMC鏈會更加有助於我們在圖形上識別出MCMC鏈是否分別都達到了令人滿意的模型收斂，互相的重疊程度也能一目了然。

至於(Brooks-)Gelman-Rubin (BGR)診斷收斂統計量，它的使用前提是必須使用合理且差異較大的不同起始值（至少兩個）。

### 模型效率 efficiency of MCMC

一旦你認爲MCMC採集的樣本鏈已經達到收斂於事後概率分布。接下來要做的是繼續MCMC樣本採集，採集的事後概率分布樣本越多，事後概率推斷就越精確。通常一個表現良好的事後概率分布，我們的經驗是4000個左右的獨立樣本產生的95%可信區間能夠給出94%-96%實際的事後概率分布(actual posterior probability) [@Raftery92howmany]。但是實際上MCMC採集的樣本鏈是高度自相關的(autocorrelated)，因此實際有效的樣本量會少於真實的樣本量。(effective sample size &lt; actual sample size)

計算事後概率分布對未知參數的估計的精確度的方法之一，是給每一個未知參數計算蒙特卡羅標準誤(Monte Carlo standard error)。它是對MCMC樣本參數均值和真實事後均值之間差的估計(estimate of the difference between the mean of the sampled values, which we are using as our estimate of the posterior mean for each parameter, and the true posterior mean.)。

MCSE (Monte Carlo Standard Error) 等於未知參數的事後樣本均值的標準誤。此時，事後樣本均值被當做是事後期望值的理論取值的一個估計 (an estimate of the theoretical posterior expectation) $E(\theta|y)$。

如果採集的樣本是相互獨立的，那麼$\text{MCSE}^{ind} = \frac{s}{\sqrt{N}}$ 其中，$s = \text{posterior SD}$ 參數$\theta$的事後樣本標準差，$N$ 是採集的事後樣本的樣本量。但是我們真正能採集到的樣本是自相關樣本(autocorrelated samples)，自相關樣本的$\text{MCSE}^{ac} &gt; \text{MCSE}^{ind}$。

一個有自相關的MCMC鏈的**有效樣本量 (effective sample size)**$N^*$可以這樣估計：

$$
N^* = (\frac{s}{\text{MCSE}^{ac}})^2
$$

所以，如果：

- $\text{MCSE}^{ac} \approx 0.05s \Rightarrow N^* \approx 1/0.05^2 = 400$;
- $\text{MCSE}^{ac} \approx 0.015s \Rightarrow N^* \approx 1/0.015^2 = 4444$;
- $\text{MCSE}^{ac} \approx 0.01s \Rightarrow N^* \approx 1/0.01^2 = 10000$;

由事後樣本的標準差和蒙特卡羅標準誤之間的關系可見，基本上MCMC鏈達到收斂以後，你需要重復MCMC採樣的次數，也就是採集的事後分布樣本量的大小要使得蒙特卡羅標準誤小於事後樣本標準差的1/100才能基本滿足要求。未知參數的事後估計和總結也就是要建立在有效樣本量至少爲10000或更多的基礎之上。


## BUGS 軟件

你完全可以另闢蹊徑在STATA或者R裏面寫下吉布斯採樣的算法，但是這並不簡單。幸好，許多軟件已經能夠幫助我們規避掉寫吉布斯採樣算法這一複雜的過程。

BUGS全稱是 **B**ayesian inference **U**sing **G**ibbs **S**ampling。它是用來描述貝葉斯統計學模型的計算機語言。有三種流行的統計學軟件都使用BUGS語言來描述貝葉斯統計學模型，他們分別是 WinBUGS，OpenBUGS，和 JAGS。他們的語法十分接近R的語法，甚至可以直接在R的環境下運行(正如我這本書中在R裏連接OpenBUGS運算貝葉斯統計推斷一樣)。

WinBUGS 1.4.3是一個穩定的貝葉斯統計學軟件，但是它已經不再更新，也沒有再跟進開發。也正如其名字暗示的那樣，它能且只能運行在瘟倒死(windows)機器上。你可以從它的網站上下載並免費使用之: [https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/](https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/)。

OpenBUGS是開源的，且能夠在Linux機器上無縫運行。它也有自己的GUI(只有在瘟倒死上才有的功能)，讓你實現用鼠標點擊也能完成貝葉斯統計學分析。它的主要網站是[http://www.openbugs.net/w/Downloads](http://www.openbugs.net/w/Downloads)。

JAGS的全稱是 **J**ust **A**nother **G**ibbs **S**ampler，開發者是 [Martyn Plummer](https://martynplummer.wordpress.com/jags/)。它沒有任何GUI，只能通過命令行來執行運算。

其他著名的軟件還有 [Stan](http://mc-stan.org/)。它也是開源的自由軟件。


## 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)

在統計學模型中我們常常默認指定一些隨機變量之間的邏輯關系，這樣的邏輯關系可以用圖形來表示：

- **節點 nodes**：用來表示變量(variables)；
- **連接線 links**：用來表示變量之間的邏輯依賴關系(dependence association)。

**帶方向的連接線 (directed links)**被用來表示邏輯依賴關系的方向(natural ordering of the dependence association)。
其實這連接線所帶的方向本身就是回歸模型中表示預測變量和結果變量之間的依賴關系。貝葉斯統計學中常用的有向無環圖 (directed acyclic graphs, DAGs)，是我們常用的輔助建立貝葉斯模型的示意圖。

例如一個描述吸煙，肥胖和心髒病發病可能的關系的的有向無環圖如下圖 \@ref(fig:DAGS-bayesian)。途中帶方向的連線（箭頭）表示預測變量和結果變量之間的依賴關系。


&lt;div class=&quot;figure&quot; style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;img/heartDAG.png&quot; alt=&quot;DAG for heart disease example&quot; width=&quot;60%&quot; /&gt;
&lt;p class=&quot;caption&quot;&gt;(\#fig:DAGS-bayesian)DAG for heart disease example&lt;/p&gt;
&lt;/div&gt;

### 條件獨立的概念 conditional independence concept

在概率論入門(Chapter \@ref(intro))中學習過獨立的概念：

$$
p(Y,X) = p(Y)p(X)
$$

我們說 $X,Y$ 以條件 $Z$ 獨立如果他們滿足：

$$
p(X,Y|Z) = p(Y|Z)p(X|Z)
$$

條件獨立的關系可以用下面的有向無環圖 \@ref(fig:DAGS-condind) 來表示：


&lt;div class=&quot;figure&quot; style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;img/conditionalindependence.png&quot; alt=&quot;DAG for conditional independence&quot; width=&quot;60%&quot; /&gt;
&lt;p class=&quot;caption&quot;&gt;(\#fig:DAGS-condind)DAG for conditional independence&lt;/p&gt;
&lt;/div&gt;


**基因型例子 genotype example:**如果 $X,Y$ 分別是同一個家庭中的兩個孩子的基因型，$Z$是其父母的基因型。那麼兩個孩子之間的基因型就是以父母的基因型爲條件獨立的關系: $p(X,Y|Z) = p(Y|Z)p(X|Z)$。如果沒有父母親基因型的條件，兩個孩子的基因型就不互相獨立，而是相關的（很顯然因爲他們是親兄弟/妹）。

在有向無環圖的術語中，一個變量的Parent(父/母)指的是有向連線指向該變量的最近的那個變量，反過來這個被指向的變量就被叫做Child(子)。所以如果從變量 $\alpha$ 存在指向 $\beta$ 的箭頭連線，那麼 $\alpha$ 被叫做 $\beta$ 的父/母(parent)，$\beta$ 被叫做 $\alpha$ 的子(child)。

**硬幣例子 coin example:**如果一枚硬幣正面朝上或者反面朝上的概率分別是 $p(H), p(T)$，那麼令 $p(H) = \theta = 1 - p(T)$，如果兩次投擲硬幣試驗的結果分別是 $X, Y$，那麼 $X,Y$ 就是以 $\theta$ 爲條件的獨立事件: $p(X,Y|\theta) = p(Y|\theta)p(X|\theta)$。這裏的 $\theta$ 在貝葉斯統計學的環境下不是固定不變的，而是一個隨機的未知參數。


條件獨立是一個十分重要的概念，因爲它爲$X,Y,Z$三個未知參數的聯合分布(joint distribution)提供了十分有用的因式分解理論依據：

$$
p(X,Y,Z)  = p(Y|Z)p(X|Z)p(Z)
$$


因爲，即使使用計算機進行模擬實驗 (simulation)，從條件分布$p(Y|Z), p(X|Z)$中採集事後概率分布樣本，也比從 $p(X,Y,Z)$ 中直接採集樣本要容易進行得多。

一般地，一個含有許多個變量節點(nodes)的向量的聯合分布可以寫作：

$$
p(V) = \prod_{v\in V} p(v|\text{parents}[v])
$$

下圖\@ref(fig:DAGS-complex)給出的一個較爲復雜的 DAG 模型，其實它沒有看起來那麼復雜，有了條件獨立的概念，我們可以方便地把它的聯合分布進行因式分解：

$$
p(V) = p(A)p(F)p(B|A)p(C|A)p(E|A,F)p(D|B,C)
$$

&lt;div class=&quot;figure&quot; style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;img/complexDAG.png&quot; alt=&quot;More complex DAG for conditional independence&quot; width=&quot;80%&quot; /&gt;
&lt;p class=&quot;caption&quot;&gt;(\#fig:DAGS-complex)More complex DAG for conditional independence&lt;/p&gt;
&lt;/div&gt;

BUGS軟件也是利用這一概念來進行復雜的事後概率分布模型的計算，例如上述的模型中，

$$
p(E|A,B,C,D,F) = p(E|A,F)
$$


## BUGS language 

在 BUGS 軟件提供的手冊裏有對 BUGS 語言更加詳盡的介紹，這裏我們只是對其精要部分做簡單概括的介紹。

### 節點的種類 types of nodes

在 BUGS 環境下，每個變量或者參數都被叫做一個節點。它主要被分爲兩類：

- **隨機節點 (stochastic nodes)：**需要我們給出它們分布的描述。一個波浪線 `~` 被用來幫助我們描述這些隨機節點的分布，例如 ` r ~ dunif(a, b)` 的含義就是，在區間 $[a,b]$ 內，$r$服從均一分布。
- **邏輯節點 (logical nodes)：**則表示的是對節點和節點之間關系的定義，它常常是一個方程，用 `&lt;-` 來輔助定義。例如，`m &lt;- alpha + beta*x` 定義的是 $m$ 和 $alpha, beta, x$ 節點之間的數學關系。

### 分布的標記法

BUGS語言中常用的分布和其對應的標記法歸納如下:

| Expression    | Distribution  |        Usage          |
|:----------:   |:------------: |:------------------:   |
|    `dbin`     |   binomial    |    ` r ~ dbin(p,n)`       |
|    `dnorm`    |    normal     | `x ~ dnorm(mu, tau)`  |
|    `dpois`    |    Poisson    |   ` r ~ dpois(lambda)`    |
|    `dunif`    |    uniform    |   `x ~ dunif(a, b)`   |
|   `dgamma`    |     gamma     |  `x ~ dgamma(a, b)`   |

要注意的是，這裏的正態分布的參數是均值 `mu`，和精確度 precision `tau`: 

$$
\text{precision} = \frac{1}{\text{variance}} = \frac{1}{sd^2}
$$

另外，在 BUGS 語言中，我們無法在指定分布時給參數使用方程，這種時候必須做的是分步驟來寫模型：
</code></pre>
<p>y ~ dnorm(mu, tau); mu &lt;- a + b*x</p>
<pre><code>
不能被寫作：
</code></pre>
<p>y ~ dnorm(a+b*x, tau)</p>
<pre><code>
### Arrays and loops 

當有些模型需要有重復執行的步驟的時候，可以使用排列 (arrays) 或者循環 (loops) 的方式來寫你的BUGS模型。例如下面的代碼用來表示在長度或者人數爲 $m$ 的數據中循環相同的步驟，其中`n, p, r`都是具有相同長度的向量：
</code></pre>
<p>for (i in 1:m){ # loop over m individuals
r[i] ~ dbin(p[i], n[i])
p[i] ~ dunif(0, 1)
}</p>
<pre><code>
所有被包括在大括號 `{}` 裏面的命令都跟着變量 `i` 被從 `1` 開始重復相同的步驟直至第 `m` 個對象。

### 常用的方程

BUGS 建立貝葉斯模型你會常用到的方程有：

1. `p &lt;- step(x - 0.7)`: 當 $x\geqslant0.7$時$=1$，反之 $=0$；類似這樣的方程可以拿來監測 `p` 這個節點，如果取它的均值，我們就得到 $x\geqslant0.7$ 的概率。
2. `p &lt;- equals(x, 0.7)`: 當 $x = 0.7$時$=1$，反之 $=0$。
3. `tau &lt;- 1/pow(s, 2)`: 這是用來給變量節點 `s` 加指數方程的命令等價於 $\tau = \frac{1}{s^2}$。
4. `s &lt;- 1/sqrt(tau)`: 等價於 $s = \frac{1}{\sqrt{\tau}}$。

在BUGS手冊的 &quot;Model Specification/Logical nodes&quot; 章節有更多對不同方程命令的描述。

一般地，方程的定義要出現在 `&lt;-` 的右邊，例如 `totalx &lt;- sum(x[])`，但是並不是全部都必須如此的，例如在廣義線性回歸模型(GLM)中，鏈接方程 (link function) 是允許出現在箭頭的左邊的：
</code></pre>
<p>logit(p[i]) &lt;- a +b<em>x[i]
log(m[i]) &lt;- c + d</em>y[i]</p>
<pre><code>
`mean(p[])`的含義是對 `p` 的所有成分取均值，如果是 `mean(p[m:n])`，則是對數列 `p` 中成分排序在 `m,n` 之間取均值，忽略掉其前後的元素。相似的概念也適用於 `sum(p[])` 命令。

## 爲BUGS model模型準備格式正確的數據

OpenBUGS 只能接受格式爲 R/S-plus 的，或者是整理成形狀爲長方形的文字格式數據。例如，名叫GREAT的臨牀試驗數據中，

- 在家中接受治療的患者人數是163，其中13例死亡；
- 在醫院內接受治療的患者人數是148，其中23例死亡。

這個模型可以用循環寫作：
</code></pre>
<p>for(i in 1:2){ # loop through the arms
deaths[i] ~ dbin(p[i], n[i]) # likelihood for each arm
p[i] ~ dbeta(alpha, beta) # same prior for each arm
}</p>
<pre><code>
這個模型的標記中， `deaths[i]` 表示第 $i$ 組對象中死亡人數，`n[i]` 則表示第 $i$ 組實驗對象中的總人數。而 `p[i]` 則代表了第 $i$ 組對象中實驗對象死亡的概率。

那麼這個數據應該用怎樣的語言來描述才合理呢？

如果用長方形格式數據，要寫作：
</code></pre>
<p>n[] deaths[]
163 13
148 23
END</p>
<pre><code>
這種格式中，第一行需要給出變量名稱，每一列是變量相對應的數據，變量名稱也必須和模型中的變量名稱相匹配。在數據最後一行則需要用`END`來結束，並且接着要有一個空行。（所以在這樣的數據格式中最後一行必須是空行）


R/S-plus格式的數據，我們已經很熟悉了，可以寫作：
</code></pre>
<p>list(n = c(163, 148),
deaths = c(13, 23))</p>
<pre><code>
OpenBUGS同時還允許你給模型加載多個數據文件，你如果願意的話，可以把不同格式的數據混合使用，一起加載在模型裏運算。

## Practical Bayesian Statistics 04

這一次練習題的主要目的是，通過使用OpenBUGS來思考，它是如何從非共軛模型的事後概率分布中採集MCMC樣本的。這個過程和從共軛模型的事後概率分布中採樣有哪些不同。

思考前一次，第三章的課後練習題裏的(Chapter \@ref(BayesPrac03))新藥試驗的例子。還是用這個場景，但是我們這次實施8個不同的試驗，$i = 1,\dots,8$，其中第$i$次試驗有 $n_i$ 名患者，其中 $y_i$ 名患者的治療被認爲有顯著療效。每次試驗中的 $n_i$ 名患者都給予相同劑量$x_i$，但是不同於其他次試驗時的使用劑量的藥物。此時我們把注意力轉到，評估治療有效百分比 $\theta_i$，和劑量$x_i$之間的關系上來。

一種方法是，我們可以對這個數據擬合一個邏輯回歸模型，在貝葉斯統計學中，邏輯回歸模型的擬合方式如下：

$$
\begin{aligned}
y_i &amp; \sim \text{Binomial}(\theta_i, n_i) \\ 
\text{logit}(\theta_i) &amp; = \beta_0 +  \beta_1 x_i
\end{aligned}
$$

其中 $\text{logit}$ 轉換是方便地把 $0\sim1$ 之間的百分比變量轉化成爲 $-\infty, +\infty$ 變量的鏈接方程。另外，貝葉斯統計學模型中，我們需要給所有模型中出現的未知參數，提供一個先驗概率分布。在上面這個模型中，我們給有效百分比 $\theta_i$ 定義了一個回歸方程式，因此，我們需要給這個回歸方程式的回歸系數(regression coefficients)指定先驗概率分布。我們先使用模糊的，沒有太多信息的先驗概率分布，例如均一分布：

$$
\begin{aligned}
\beta_0 &amp; \sim \text{Uniform}(-100, 100)\\
\beta_1 &amp; \sim \text{Uniform}(-100, 100)
\end{aligned}
$$


1.首先，用第三章練習題中的新藥試驗模型，使用 $\text{beta}(1, 1)$ 作爲 $\theta$的先驗概率分布（已知$\text{beta}(1, 1)$其實等價於一個均一分布）。設定監測未知參數 `theta`，執行1000次MCMC運算之後，繪制 `theta` 的歷史痕跡。

</code></pre>
</div>
<div id="original-conjugate-drug-model-with-uniform-beta01-prior-on-theta" class="section level1">
<h1><span class="header-section-number">第 104 章</span> original conjugate drug model with uniform beta(0,1) prior on theta</h1>
<p>model{
theta ~ dbeta(1,1) # prior distribution
y ~ dbin(theta, 20)# sampling distribution for 20 observed patients
y &lt;- 15
}</p>
<pre><code>
```{r　OpenBUGSPractical0400 12-Bayesian-stats-16, cache=TRUE, fig.width=7, fig.height=3, fig.cap=&#39;History plot showing 1000 samples of theta&#39;, fig.align=&#39;center&#39;, out.width=&#39;80%&#39;, message=TRUE, warning=FALSE}


# Step 1 check model
modelCheck(paste(bugpath, &quot;backupfiles/MCdrugPractical04.txt&quot;, sep = &quot;&quot;)) 

# compile the model
modelCompile(numChains = 1) 
# There is no need to provide initial values as 
# they are aleady provided in the model specification
modelGenInits() #
# Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:
parameters &lt;- c(&quot;theta&quot;)
samplesSet(parameters)

# Generate 1000 iterations
modelUpdate(1000)
#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;- data.frame(theta = samplesSample(&quot;theta&quot;))

#### PLOT THE MCMC CHAINS:
plot(chain$theta, main=~theta, type=&quot;l&quot;, ylim = c(0.2, 1.2),
         ylab=&quot;theta&quot;, xlab=&quot;iteration&quot;, col=&quot;red&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>下面我們來看題幹中的邏輯回歸模型的BUGS版本：</li>
</ol>
<pre><code>model {
       for( i in 1 : N ) { # loop thorugh experiments
            y[i] ~ dbin(theta[i],n[i])
           logit(theta[i]) &lt;- beta0 + beta1 * x[i]    
       }
       # priors
       beta0 ~ dunif(-100, 100)
       beta1 ~ dunif(-100, 100)
}</code></pre>
<p>試驗獲得觀察數據如下：</p>
<pre><code>list(y = c(1, 3, 6, 8, 11, 15, 17, 19), 
     n = c(20, 20, 20, 20, 20, 20, 20, 20), 
     x = c(30, 32, 34, 36, 38, 40, 42, 44), 
     N = 8 )</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>嘗試使用OpenBUGS來跑這個模型。記得你需要把數據加載到軟件裏面去。</li>
</ol>
<div class="sourceCode" id="cb1299"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1299-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1299-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1301"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1301-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1301-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1303"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1303-1" title="1"><span class="co"># compile the model</span></a>
<a class="sourceLine" id="cb1303-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1305"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1305-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1305-2" title="2"><span class="kw">modelGenInits</span>() </a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>對未知參數，也就是邏輯回歸的回歸系數 <code>beta0, beta1</code>，和第六次試驗的治療成功百分比 <code>theta[6]</code> 設定監測追蹤其採樣軌跡。試着執行1000次MCMC採樣，把這三個跟蹤的未知參數的採樣歷史軌跡繪制下來。</li>
</ol>
<div class="sourceCode" id="cb1307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1307-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1307-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)</a>
<a class="sourceLine" id="cb1307-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode" id="cb1311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1311-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1311-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1313-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1313-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),</a>
<a class="sourceLine" id="cb1313-3" title="3">                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),</a>
<a class="sourceLine" id="cb1313-4" title="4">                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))</a>
<a class="sourceLine" id="cb1313-5" title="5"></a>
<a class="sourceLine" id="cb1313-6" title="6"><span class="co">#### PLOT THE MCMC CHAINS:</span></a>
<a class="sourceLine" id="cb1313-7" title="7"><span class="kw">plot</span>(chain<span class="op">$</span>beta0[<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>], <span class="dt">main=</span><span class="st">&quot;beta0&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">180</span>),</a>
<a class="sourceLine" id="cb1313-8" title="8">         <span class="dt">ylab=</span><span class="st">&quot;beta0&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;iteration&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0402"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0402-1.png" alt="History plot showing 1000 samples of beta0" width="80%" />
<p class="caption">
圖 104.1: History plot showing 1000 samples of beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0403"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0403-1.png" alt="History plot showing 1000 samples of beta1" width="80%" />
<p class="caption">
圖 104.2: History plot showing 1000 samples of beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0404"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0404-1.png" alt="History plot showing 1000 samples of theta[6]" width="80%" />
<p class="caption">
圖 104.3: History plot showing 1000 samples of theta[6]
</p>
</div>
<p>對這三個位置變量的採樣歷史繪制痕跡圖之後，你發現每個參數期初的一些採樣是十分不穩定的，有很大的變動(variability)。</p>
<ol start="5" style="list-style-type: decimal">
<li>接下來，我們給上面同一個邏輯回歸模型增加另一條MCMC採樣鏈，重復跑相同的模型1000次，繪制同樣是這三個未知參數的事後分布MCMC採樣歷史痕跡圖。</li>
</ol>
<div class="sourceCode" id="cb1314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1314-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1314-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1314-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1314-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1314-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1314-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1314-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1314-8" title="8"><span class="kw">modelGenInits</span>() </a>
<a class="sourceLine" id="cb1314-9" title="9"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1314-10" title="10">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)</a>
<a class="sourceLine" id="cb1314-11" title="11"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1314-12" title="12"></a>
<a class="sourceLine" id="cb1314-13" title="13"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1314-14" title="14"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1314-15" title="15"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1314-16" title="16">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),</a>
<a class="sourceLine" id="cb1314-17" title="17">                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),</a>
<a class="sourceLine" id="cb1314-18" title="18">                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))</a>
<a class="sourceLine" id="cb1314-19" title="19"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0405"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0405-1.png" alt="History plot showing 1000 samples of beta0, beta1, and theta[6]" width="80%" />
<p class="caption">
圖 104.4: History plot showing 1000 samples of beta0, beta1, and theta[6]
</p>
</div>
<p>使用兩個不同的起始值作爲MCMC的採樣起點時，每個未知參數分別獲得兩條不同顏色的歷史痕跡圖。和之前只有一條MCMC採樣鏈時一樣，採樣的起始部分(大約100次左右)都有一些不穩定的值。等到100次採樣過後，我們發現每個參數的採樣結果都趨向於比較穩定，也就是方差，變化小了很多。但是藍色鏈，紅色鏈一直到200-300次採樣之後才逐漸互相交叉重疊。下面的圖把起初的500次採樣刨除了之後重新對每個未知參數的MCMC採樣繪制歷史痕跡。</p>
<div class="sourceCode" id="cb1315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1315-1" title="1"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>), <span class="dt">beg =</span> <span class="dv">501</span>, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0407"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0407-1.png" alt="History plot showing 1000 samples of beta0, beta1, and theta[6], iteration between 501-1000" width="80%" />
<p class="caption">
圖 104.5: History plot showing 1000 samples of beta0, beta1, and theta[6], iteration between 501-1000
</p>
</div>
<p>500-1000次之間的隨機採樣被放大了觀察之後，我們發現 <code>beta0, beta1</code> 的兩條MCMC鏈條的重疊程度並不理想，不像<code>theta[6]</code>那樣呈現令人滿意地重疊，兩條採樣鏈上下扭動，且在一些地方差異較大。</p>
<p>繪制每個參數的MCMC鏈的自相關圖 (autocorrelation)，下面的圖中只繪制了500-1000次範圍內採樣的自相關圖。</p>
<div class="sourceCode" id="cb1316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1316-1" title="1"><span class="kw">samplesAutoC</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">1</span>, <span class="dt">beg =</span> <span class="dv">501</span>,</a>
<a class="sourceLine" id="cb1316-2" title="2">             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">lag.max =</span> <span class="dv">100</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0408081"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical040808-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.6: Autocorrelation plot for beta0
</p>
</div>
<div class="sourceCode" id="cb1317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1317-1" title="1"><span class="kw">samplesAutoC</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dt">beg =</span> <span class="dv">501</span>, </a>
<a class="sourceLine" id="cb1317-2" title="2">             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">lag.max =</span> <span class="dv">100</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0408082"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical040808-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.7: Autocorrelation plot for beta0
</p>
</div>
<div class="sourceCode" id="cb1318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1318-1" title="1"><span class="co"># acf(chain$beta0, main=&quot;beta0&quot;,lwd=4,col=&quot;red&quot;, lag.max = 50)</span></a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04091"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0409-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.8: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04092"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0409-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.9: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04101"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0410-1.png" alt="Autocorrelation plot for theta[6]" width="80%" />
<p class="caption">
圖 104.10: Autocorrelation plot for theta[6]
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04102"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0410-2.png" alt="Autocorrelation plot for theta[6]" width="80%" />
<p class="caption">
圖 104.11: Autocorrelation plot for theta[6]
</p>
</div>
<p>其中 <code>theta[6]</code> 可以在視覺上認爲這些樣本基本沒有自相關。但是 <code>beta0, beta1</code> 的自相關圖提示相隔50次以上的採樣之間仍然有較強的，不能被忽視的自相關。這一點在 <code>beta0, beta1</code>各自的歷史痕跡圖中也能看出來因爲他們各自的痕跡圖提示採樣時的跳躍並不顯著，相對照的， <code>theta[6]</code>的採樣的跳躍就比較顯著，反映了這個未知參數事後概率分布採樣時的連續互相獨立性較好(near-independence of the values being sampled at consecutive iterations.)。</p>
<ol start="6" style="list-style-type: decimal">
<li>重新在OpenBUGS裏跑這個邏輯回歸模型，這一次，嘗試自己給 <code>beta0, beta1</code> 設置起始值。然後更新模型，採集MCMC鏈樣本10000次。這次嘗試同時使用繪制歷史痕跡圖（視覺檢查），和計算Brooks-Gelman-Rubin診斷參數及其圖示來判斷事後概率分布採樣是否達到收斂。你能判斷這個模型需要拋出掉多少一開始採集的樣本嗎(burn-in)？</li>
</ol>
<div class="sourceCode" id="cb1319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1319-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1319-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1321-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1321-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1323"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1323-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1323-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1325"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1325-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1325-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1325-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)</a>
<a class="sourceLine" id="cb1325-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1328-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)</a>
<a class="sourceLine" id="cb1328-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1331"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1331-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1331-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)</a>
<a class="sourceLine" id="cb1331-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode" id="cb1335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1335-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1335-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1337-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1337-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),</a>
<a class="sourceLine" id="cb1337-3" title="3">                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),</a>
<a class="sourceLine" id="cb1337-4" title="4">                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))</a>
<a class="sourceLine" id="cb1337-5" title="5"></a>
<a class="sourceLine" id="cb1337-6" title="6"><span class="co">#### PLOT the chain history of beta0, beta1</span></a>
<a class="sourceLine" id="cb1337-7" title="7"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04111"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0411-1.png" alt="History plots based on first 10000 iterations." width="80%" />
<p class="caption">
圖 104.12: History plots based on first 10000 iterations.
</p>
</div>
<div class="sourceCode" id="cb1338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1338-1" title="1"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta1&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04112"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0411-2.png" alt="History plots based on first 10000 iterations." width="80%" />
<p class="caption">
圖 104.13: History plots based on first 10000 iterations.
</p>
</div>
<div class="sourceCode" id="cb1339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1339-1" title="1"><span class="co"># Let&#39;s use R2OpenBUGS to run the model again</span></a>
<a class="sourceLine" id="cb1339-2" title="2"><span class="co"># Call OpenBUGS to run model</span></a>
<a class="sourceLine" id="cb1339-3" title="3"><span class="co">#/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote/</span></a>
<a class="sourceLine" id="cb1339-4" title="4"><span class="co"># output.dir &lt;- &quot;backupfiles/bugsoutput/&quot;</span></a>
<a class="sourceLine" id="cb1339-5" title="5"><span class="co"># drug.odir &lt;- paste(output.dir, &quot;drug-logistic-model/&quot;, sep = &quot;&quot;)</span></a>
<a class="sourceLine" id="cb1339-6" title="6"><span class="co">#  pars &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;)</span></a>
<a class="sourceLine" id="cb1339-7" title="7"><span class="co"># drug.data &lt;- list(y = c(1, 3, 6, 8, 11, 15, 17, 19), </span></a>
<a class="sourceLine" id="cb1339-8" title="8"><span class="co">#      n = c(20, 20, 20, 20, 20, 20, 20, 20), </span></a>
<a class="sourceLine" id="cb1339-9" title="9"><span class="co">#      x = c(30, 32, 34, 36, 38, 40, 42, 44), </span></a>
<a class="sourceLine" id="cb1339-10" title="10"><span class="co">#      N = 8 )</span></a>
<a class="sourceLine" id="cb1339-11" title="11"><span class="co"># </span></a>
<a class="sourceLine" id="cb1339-12" title="12"><span class="co"># </span></a>
<a class="sourceLine" id="cb1339-13" title="13"><span class="co"># drug.log.sim &lt;- bugs(data = drug.data, parameters.to.save = pars,</span></a>
<a class="sourceLine" id="cb1339-14" title="14"><span class="co">#                      model.file = &quot;/backupfiles/logistic-reg-model.txt&quot;, inits = list(initlist, initlist1),</span></a>
<a class="sourceLine" id="cb1339-15" title="15"><span class="co">#                      n.chains = 2, n.iter = 10000,</span></a>
<a class="sourceLine" id="cb1339-16" title="16"><span class="co">#                      n.burnin = 0, DIC = T, working.directory = drug.odir,</span></a>
<a class="sourceLine" id="cb1339-17" title="17"><span class="co">#                      codaPkg = TRUE)</span></a>
<a class="sourceLine" id="cb1339-18" title="18"><span class="co"># drug.log.sim</span></a>
<a class="sourceLine" id="cb1339-19" title="19"><span class="co"># </span></a>
<a class="sourceLine" id="cb1339-20" title="20"><span class="co"># postsamples &lt;- read.bugs(drug.log.sim)</span></a>
<a class="sourceLine" id="cb1339-21" title="21">postsamples &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1339-22" title="22"><span class="kw">gelman.diag</span>(postsamples)</a></code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##          Point est. Upper C.I.
## beta0             1          1
## beta1             1          1
## theta[6]          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="sourceCode" id="cb1341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1341-1" title="1"><span class="kw">gelman.plot</span>(postsamples)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0412"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0412-1.png" alt="Brooks-Gelman-Rubin diagnostic graph" width="80%" />
<p class="caption">
圖 104.14: Brooks-Gelman-Rubin diagnostic graph
</p>
</div>
<p>從Gelman.plot的圖形可以看出，在2000次及以上的採集樣本過後，基本上可以認爲採集的樣本收斂於事後概率分布。</p>
<ol start="7" style="list-style-type: decimal">
<li>確認了你想要刨除的初始樣本量(burn-in)，繼續再進行MCMC採樣直到獲得100,000個事後概率分布樣本。此時你對獲得的事後概率分布樣本量提供的參數估計精確度滿意否？(MC_error is about 1% of the posterior SD?)嘗試報告此時獲得的參數們的事後均值，及其95%可信區間。</li>
</ol>
<div class="sourceCode" id="cb1342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1342-1" title="1"><span class="co"># Generate another 1000000 iterations</span></a>
<a class="sourceLine" id="cb1342-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">42000</span>) </a></code></pre></div>
<pre><code>## 42000 updates took 1 s</code></pre>
<div class="sourceCode" id="cb1344"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1344-1" title="1">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">2001</span>)</a>
<a class="sourceLine" id="cb1344-2" title="2"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##              mean      sd MC_error val2.5pc   median val97.5pc start sample
## beta0    -13.8600 2.17800 0.077560 -18.3500 -13.8300   -9.7840  2001 100000
## beta1      0.3746 0.05858 0.002087   0.2650   0.3738    0.4957  2001 100000
## theta[6]   0.7514 0.04910 0.001077   0.6503   0.7532    0.8423  2001 100000</code></pre>
<p>由於 <code>beta0, beta1</code> 事後MCMC採樣的高度自相關性，我們不得不採取獲得十萬以上的事後樣本量的手段來獲取較爲精確的事後參數的均值估計。此時，<code>beta0</code>的<code>MC_error</code> 仍然也只達到事後樣本標準差的3.6% (0.077560/2.17800)。其對應的有效樣本量(effective sample size)大約是 1/(0.036^2) = 772。即使我們再繼續進行MCMC採樣達到一百萬的事後樣本量，我們也只能勉強讓MC_error達到事後標準差的1.4%(=0.02742/2.09200)，對應的有效樣本量是 1/(0.014^2) = 5102。</p>
<div class="sourceCode" id="cb1346"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1346-1" title="1"><span class="co"># Generate another 900000 iterations</span></a>
<a class="sourceLine" id="cb1346-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">480000</span>) </a></code></pre></div>
<pre><code>## 480000 updates took 17 s</code></pre>
<div class="sourceCode" id="cb1348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1348-1" title="1">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">2001</span>)</a>
<a class="sourceLine" id="cb1348-2" title="2"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##              mean      sd  MC_error val2.5pc   median val97.5pc start  sample
## beta0    -13.8500 2.09200 0.0274200 -18.1800 -13.7900   -9.9170  2001 1060000
## beta1      0.3743 0.05627 0.0007373   0.2685   0.3726    0.4907  2001 1060000
## theta[6]   0.7514 0.04845 0.0003782   0.6517   0.7532    0.8407  2001 1060000</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>繪制此時<code>beta0,beta1</code>的自相關圖。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04151"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0415-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.15: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04152"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0415-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.16: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04161"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0416-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.17: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04162"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0416-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.18: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0417"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0417-1.png" alt="The joint posterior distribution, scatter plot of beta0 and beta1." width="80%" />
<p class="caption">
圖 104.19: The joint posterior distribution, scatter plot of beta0 and beta1.
</p>
</div>
<p>此圖<a href="#fig:OpenBUGSPractical0417">104.19</a>提示我們該邏輯回歸模型的截距(intercept)<code>beta0</code>，和斜率(slope)<code>beta1</code>其實是高度相關的。這導致了未知參數(兩個回歸系數)的事後概率分布樣本高度內部相關(high autocorrealtion within the samples of each individual parameter)。這是他們效率低下，需要大量的採集樣本仍然無法滿足或者達到理想的收斂的主要原因。</p>
<ol start="9" style="list-style-type: decimal">
<li>給邏輯回歸的回歸系數中心化之後的模型：我們來把兩個回歸系數的樣本中心化(centre the covariate <span class="math inline">\(x\)</span>)。在BUGS語言中可以使用<code>x[i] - mean(x[])</code>的命令來把未知參數的事後概率分布MCMC採樣過程中心化。然後我們重復一下上面的計算過程，看結果有怎樣的變化。與前者的分析比較一下收斂所需要的時間和未知參數事後估計的效率差別。</li>
</ol>
<pre><code># logistic regression model with centred covariate
model{
  for(i in 1:N){# loop through experiments
              y[i] ~ dbin(theta[i], n[i])
   logit(theta[i]) &lt;- beta0 + beta1 * (x[i] - mean(x[]))
  }
  # priors 
  beta0 ~ dunif(-100, 100)
  beta1 ~ dunif(-100, 100)
}</code></pre>
<div class="sourceCode" id="cb1351"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1351-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1351-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-model-centred.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1353-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1353-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1355"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1355-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1355-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1357-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1357-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1357-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)</a>
<a class="sourceLine" id="cb1357-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1360-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)</a>
<a class="sourceLine" id="cb1360-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1363-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1363-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)</a>
<a class="sourceLine" id="cb1363-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode" id="cb1367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1367-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1367-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</a></code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1369-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1369-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),</a>
<a class="sourceLine" id="cb1369-3" title="3">                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),</a>
<a class="sourceLine" id="cb1369-4" title="4">                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))</a>
<a class="sourceLine" id="cb1369-5" title="5"></a>
<a class="sourceLine" id="cb1369-6" title="6"><span class="co">#### PLOT the chain history of beta0, beta1</span></a>
<a class="sourceLine" id="cb1369-7" title="7"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04181"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0418-1.png" alt="History plots based on first 10000 iterations with centred covariates." width="80%" />
<p class="caption">
圖 104.20: History plots based on first 10000 iterations with centred covariates.
</p>
</div>
<div class="sourceCode" id="cb1370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1370-1" title="1"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta1&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04182"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0418-2.png" alt="History plots based on first 10000 iterations with centred covariates." width="80%" />
<p class="caption">
圖 104.21: History plots based on first 10000 iterations with centred covariates.
</p>
</div>
<p>用中心化之後的模型我們發現需要更多的起始樣本來達到事後概率分布的收斂(7500左右)。BGR診斷圖 <a href="#fig:OpenBUGSPractical0419">104.22</a> 也提示我們大概在7500次之後的重復採樣才能達到收斂。所以我們決定要刨除起始7500次採集的樣本。(burn-in = 7500)</p>
<div class="sourceCode" id="cb1371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1371-1" title="1"><span class="co"># Let&#39;s use R2OpenBUGS to run the model again</span></a>
<a class="sourceLine" id="cb1371-2" title="2"><span class="co"># Call OpenBUGS to run model</span></a>
<a class="sourceLine" id="cb1371-3" title="3"><span class="co"># output.dir &lt;- &quot;backupfiles/bugsoutput/&quot;</span></a>
<a class="sourceLine" id="cb1371-4" title="4"><span class="co"># drug.odir &lt;- paste(output.dir, &quot;drug-logistic-model/&quot;, sep = &quot;&quot;)</span></a>
<a class="sourceLine" id="cb1371-5" title="5"><span class="co">#  pars &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;)</span></a>
<a class="sourceLine" id="cb1371-6" title="6"><span class="co"># drug.log.sim &lt;- bugs(data = &quot;/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote/backupfiles/logistic-reg-data.txt&quot;, parameters.to.save = pars,</span></a>
<a class="sourceLine" id="cb1371-7" title="7"><span class="co">#                      model.file = &quot;/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote/backupfiles/logistic-reg-model-centred.txt&quot;, inits = list(initlist, initlist1),</span></a>
<a class="sourceLine" id="cb1371-8" title="8"><span class="co">#                      n.chains = 2, n.iter = 20000,</span></a>
<a class="sourceLine" id="cb1371-9" title="9"><span class="co">#                      n.burnin = 0, DIC = T, working.directory = drug.odir,</span></a>
<a class="sourceLine" id="cb1371-10" title="10"><span class="co">#                      codaPkg = TRUE)</span></a>
<a class="sourceLine" id="cb1371-11" title="11"><span class="co"># drug.log.sim</span></a>
<a class="sourceLine" id="cb1371-12" title="12"><span class="co"># </span></a>
<a class="sourceLine" id="cb1371-13" title="13"><span class="co"># postsamples &lt;- read.bugs(drug.log.sim)</span></a>
<a class="sourceLine" id="cb1371-14" title="14"><span class="kw">modelUpdate</span>(<span class="dv">20000</span>)</a></code></pre></div>
<pre><code>## 20000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1373-1" title="1">postsamples &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1373-2" title="2"></a>
<a class="sourceLine" id="cb1373-3" title="3"><span class="kw">gelman.diag</span>(postsamples)</a></code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##          Point est. Upper C.I.
## beta0             1          1
## beta1             1          1
## theta[6]          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="sourceCode" id="cb1375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1375-1" title="1"><span class="kw">gelman.plot</span>(postsamples)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0419"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0419-1.png" alt="Brooks-Gelman-Rubin diagnostic graph" width="80%" />
<p class="caption">
圖 104.22: Brooks-Gelman-Rubin diagnostic graph
</p>
</div>
<p>刨除了起始7500次採集的樣本之後，剩餘的25000個MCMC樣本的自相關也基本都降至0，說明這時候採集的事後概率分布樣本基本上都可以認爲是相互獨立的樣本，散點圖 (Fig. <a href="#fig:OpenBUGSPractical0423">104.27</a>)同樣支持了這一觀點。此時有效樣本量基本上約等於採集到的樣本量。</p>
<pre><code>##               mean      sd  MC_error val2.5pc    median val97.5pc start sample
## beta0    -0.002141 0.20210 0.0011980  -0.3978 -0.002367    0.3942  7501  25000
## beta1     0.374600 0.05598 0.0003554   0.2706  0.372700    0.4887  7501  25000
## theta[6]  0.751100 0.04810 0.0003154   0.6513  0.752600    0.8400  7501  25000</code></pre>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04211"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0421-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.23: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04212"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0421-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 104.24: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04221"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0422-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.25: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04222"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0422-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 104.26: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0423"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0423-1.png" alt="The joint posterior distribution, scatter plot of beta0 and beta1 with centred covariates." width="80%" />
<p class="caption">
圖 104.27: The joint posterior distribution, scatter plot of beta0 and beta1 with centred covariates.
</p>
</div>
<ol start="10" style="list-style-type: decimal">
<li><p>這時候我們獲得的回歸系數的事後估計的均值 <code>beta1 = 0.3746</code>，和它的95%可信區間，<code>0.2706, 0.4887</code>。它其實是藥物劑量每增加1mg，隨之增加的藥物有效百分比的對數比值比 (log-odds-ratio of a positive response per 1 mg increase in dose.)，你有沒有發現其實我們很難解釋這個變量的實際含義呢？有沒有什麼辦法可以來改善這個結果，讓它更加容易讓人明白呢？</p></li>
<li><p>想辦法在未知參數被中心的話邏輯回歸模型中增加新的語句，生成一些新的容易讓人解釋的變量，改善模型的易解釋程度。也許你可以把對數比值比轉換成比值比，你也許可以自己算一下在哪種劑量條件下可以讓95%的患者都有治療療效(ED95)：</p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{logit}0.95 &amp; = \beta_0 + \beta_1(ED95 - \bar x) \\ 
\Rightarrow ED95 &amp; = (\text{logit}0.95 - \beta_0)/\beta_1 + \bar x
\end{aligned}
\]</span></p>
<pre><code># logistic regression model with centred covariate 
# and added statements
model{
  for(i in 1:N){# loop through experiments
              y[i] ~ dbin(theta[i], n[i])
   logit(theta[i]) &lt;- beta0 + beta1 * (x[i] - mean(x[]))
  }
  # priors 
  beta0 ~ dunif(-100, 100)
  beta1 ~ dunif(-100, 100)
  OR &lt;- exp(beta1) # odds ratio of positive response per 1 mg increase in dose
  ED95 &lt;- (logit(0.95) - beta0)/beta1 + mean(x[]) # dose that gives 95% of maximal response
  logit(P35) &lt;- beta0 + beta1 * (35 - mean(x[]))
}</code></pre>
<div class="sourceCode" id="cb1378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1378-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1378-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-model-centred-stat.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1380-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1380-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1382"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1382-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1382-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1384-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1384-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1384-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)</a>
<a class="sourceLine" id="cb1384-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1387"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1387-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)</a>
<a class="sourceLine" id="cb1387-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1390"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1390-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1390-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ED95&quot;</span>, <span class="st">&quot;OR&quot;</span>, <span class="st">&quot;P35&quot;</span>, <span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>)</a>
<a class="sourceLine" id="cb1390-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;ED95&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR&#39;</code></pre>
<pre><code>## monitor set for variable &#39;P35&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<div class="sourceCode" id="cb1396"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1396-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1396-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">20000</span>)</a></code></pre></div>
<pre><code>## 20000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1398"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1398-1" title="1"><span class="co">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:</span></a>
<a class="sourceLine" id="cb1398-2" title="2">chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">ED95   =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;ED95&quot;</span>),</a>
<a class="sourceLine" id="cb1398-3" title="3">                    <span class="dt">OR     =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;OR&quot;</span>),</a>
<a class="sourceLine" id="cb1398-4" title="4">                    <span class="dt">P35    =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P35&quot;</span>),</a>
<a class="sourceLine" id="cb1398-5" title="5">                    <span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),</a>
<a class="sourceLine" id="cb1398-6" title="6">                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>))</a>
<a class="sourceLine" id="cb1398-7" title="7">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">7501</span>)</a>
<a class="sourceLine" id="cb1398-8" title="8"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##            mean      sd  MC_error val2.5pc    median val97.5pc start sample
## ED95  45.050000 1.36800 0.0091440  42.7800 44.910000   48.1100  7501  25000
## OR     1.457000 0.08205 0.0005216   1.3110  1.452000    1.6300  7501  25000
## P35    0.322600 0.04981 0.0002789   0.2284  0.321300    0.4223  7501  25000
## beta0 -0.002141 0.20210 0.0011980  -0.3978 -0.002367    0.3942  7501  25000
## beta1  0.374600 0.05598 0.0003554   0.2706  0.372700    0.4887  7501  25000</code></pre>
<p>所以，藥物每增加劑量1mg，有療效的比值比是OR = 1.46 (95%CrI: 1.31, 1.63)。能夠達到95%患者都有療效的劑量是 45.05 mg (95% CrI: 42.8, 48.1 mg)。如果給予患者藥物劑量爲 35 mg，患者的疼痛能夠得到緩解(有療效)的概率是 32.3% (95% CrI: 22.8%, 42.2%)。跟着看到這裏的你是不是也覺得貝葉斯的結果和過程能夠更加豐富地回答我們想知道的問題呢？</p>
<div class="sourceCode" id="cb1400"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1400-1" title="1"><span class="co">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES</span></a>
<a class="sourceLine" id="cb1400-2" title="2"></a>
<a class="sourceLine" id="cb1400-3" title="3"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>ED95[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;ED95 sample 25000&quot;</span>, </a>
<a class="sourceLine" id="cb1400-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;P(ED95)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04251"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-1.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 104.28: Posterior density plots of ED95, OR, and P35.
</p>
</div>
<div class="sourceCode" id="cb1401"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1401-1" title="1"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>OR[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;OR sample 25000&quot;</span>, </a>
<a class="sourceLine" id="cb1401-2" title="2">     <span class="dt">ylab =</span> <span class="st">&quot;P(OR)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04252"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-2.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 104.29: Posterior density plots of ED95, OR, and P35.
</p>
</div>
<div class="sourceCode" id="cb1402"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1402-1" title="1"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>P35[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;OR sample 25000&quot;</span>, </a>
<a class="sourceLine" id="cb1402-2" title="2">     <span class="dt">ylab =</span> <span class="st">&quot;P(OR)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04253"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-3.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 104.30: Posterior density plots of ED95, OR, and P35.
</p>
</div>
</div>
<div id="建模和模型的檢查" class="section level1">
<h1><span class="header-section-number">第 105 章</span> 建模和模型的檢查</h1>
<p>對所有想要嘗試貝葉斯統計學的人來說，這個過程需要你有能力建立一個可以被用於MCMC採樣的貝葉斯模型，並且懂得怎樣獲取收斂合理，樣本量大小合適的事後概率分布樣本。下圖 <a href="#fig:BayesianChapter0501">105.1</a> 中總結了建立貝葉斯統計模型並運行MCMC計算的大致過程：</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0501"></span>
<img src="img/MCMC_procedure.png" alt="Input files, steps for generating a posterior sample and checks required for successfully running a Bayesian analysis using BUGS." width="80%" />
<p class="caption">
圖 105.1: Input files, steps for generating a posterior sample and checks required for successfully running a Bayesian analysis using BUGS.
</p>
</div>
<p>虛線最上端，意爲我們需要準備三種最重要的文件：</p>
<ol style="list-style-type: decimal">
<li>BUGS語言描述下的貝葉斯統計學模型；</li>
<li>包含模型中使用到的觀察變量的數據文件（可以是一個，也可是多個組合）；</li>
<li>每個未知參數的MCMC採樣鏈的起始值 (initial values, 1 set for each chain)。</li>
</ol>
<p>兩條虛線的中間部分是產生事後概率分布的重要步驟及其先後順序。虛線最下面則是三個重要的模型檢查，你需要在運行貝葉斯模型MCMC採集樣本的過程中反復使用這三個檢查模型的方案以確保過程的準確，以獲得合理的結果。</p>
<p>下面我們通過使用貝葉斯統計學框架來進行一個簡單線性回歸模型的計算和MCMC採集樣本的過程，詳細地解釋圖<a href="#fig:BayesianChapter0501">105.1</a>中的每一個步驟及其含義。</p>
<p>先思考，一個只有概率論知識的統計學者，他/她是如何進行簡單線性回歸模型的擬合過程的？</p>
<ol style="list-style-type: decimal">
<li>確認觀察數據的概率分布(似然/likelihood)；</li>
<li>確認結果變量和預測變量之間的合適表達式(線性回歸方程)。</li>
</ol>
<p>這兩個步驟在貝葉斯統計學中也是不可缺少的，此外，貝葉斯統計學模型的建立和MCMC採樣還需要統計師給出回歸系數的先驗概率分布(prior distributions for the regression coefficients)，以及其他未知（可能是令人感到麻煩的 nuisance）參數的先驗概率分布。</p>
<div id="BayesianLM" class="section level2">
<h2><span class="header-section-number">105.1</span> 簡單線性回歸模型</h2>
<p>如果簡單線性回歸模型的結果變量是一個服從正態分布的單一變量 <span class="math inline">\(y_i\)</span>，我們想要拿來預測這個結果變量的預測變量是從每個試驗個體 <span class="math inline">\(i, i = 1, \dots, n\)</span> 上收集到的一系列共變量 (covariates) 的向量 <span class="math inline">\(x_{1i}, \dots, x_{pi}\)</span>。概率論統計學者會把這樣的模型用數學表達式寫成：</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp; = \beta_0 + \sum_{k = 1}^p\beta_k x_{ki} + \epsilon_i \\ 
\epsilon_i &amp; \sim \text{Normal}(0, \sigma^2)
\end{aligned}
\]</span></p>
<p>或者也有人習慣於把誤差項拿掉，用結果變量的期望值（也就是均值） <span class="math inline">\(E(y_i) = \mu_i\)</span> 來寫這個模型：</p>
<p><span class="math display">\[
\begin{aligned}
y_i    &amp; \sim \text{Normal}(\mu_i, \sigma^2) \\ 
\mu_i  &amp; = \beta_0 +  \sum_{k = 1}^p\beta_k x_{ki}
\end{aligned}
\]</span></p>
<p>在貝葉斯框架下，這個模型的參數<span class="math inline">\((\beta_0, \beta_1, \dots, \beta_p, \sigma^2)\)</span>，還需要給出它們各自的先驗概率分布。所以貝葉斯框架下的簡單線性回歸模型的標記法是：</p>
<p><span class="math display">\[
\begin{aligned}
y_i   &amp; \sim \text{Normal}(\mu_i, \sigma^2) \\ 
\mu_i &amp; = \beta_0+  \sum_{k = 1}^p\beta_k x_{ki} \\
(\beta_0, \beta_1, \dots, \beta_p, \sigma^2) &amp; \sim \text{ Prior Distributions}
\end{aligned}
\]</span></p>
<p>如果想要獲得和概率論的簡單線性回歸模型的算法(OLS, ordinary least squares / MLE, maximum likelihood estimates)獲得的結果接近的參數估計，那麼先驗概率分布可以指定爲：</p>
<p><span class="math display">\[
\begin{aligned}
\beta_k &amp; \sim \text{Uniform}(-\infty, +\infty), k = 0, \dots, p \\
\log\sigma^2 &amp; \sim \text{Uniform}(-\infty, +\infty)
\end{aligned}
\]</span></p>
<p>我們以後還會仔細再討論先驗概率分布的選擇問題。</p>
</div>
<div id="children-in-the-gambia" class="section level2">
<h2><span class="header-section-number">105.2</span> Children in the Gambia</h2>
<p>這個數據實例我們在簡單線性回歸的課程中(Chapter <a href="#growgam">26.6</a>)也用過，它收集的是岡比亞農村兒童的身高體重年齡等信息。你可以有空和當時的模型擬合過程進行一個對比。這裏用到的變量是190名兒童的體重，年齡，和性別。圖 <a href="#fig:BayesianChapter0502">105.2</a>示意的是這些兒童的體重和年齡及性別的關系。</p>
<pre><code>## # A tibble: 6 x 4
##          sex   age    wt   len
##    &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 2 [female]    23  8.40  73.2
## 2 2 [female]    22 10.9   84.4
## 3 2 [female]     6  7.20  68.7
## 4 1 [male]      24 10.3   83.7
## 5 1 [male]      14 10.5   79.2
## 6 2 [female]    18  9.60  75.8</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0502"></span>
<img src="bookdown_files/figure-html/BayesianChapter0502-1.png" alt="Children in the Gambian cross-sectional survey" width="90%" />
<p class="caption">
圖 105.2: Children in the Gambian cross-sectional survey
</p>
</div>
<p>在這項橫斷面研究中，我們關心的主要是：</p>
<ol style="list-style-type: decimal">
<li>年齡每增加一個月，體重的變化是多少 kg？</li>
<li>男孩女孩之間的體重差別是多少 kg？</li>
</ol>
<div id="岡比亞兒童數據模型" class="section level3">
<h3><span class="header-section-number">105.2.1</span> 岡比亞兒童數據模型</h3>
<p>我們給出的模型是：</p>
<ul>
<li>結果變量 (outcome/response)：體重(kg), weight in kg；</li>
<li>預測變量 (predictors)：年齡(age in months)，性別(1=男孩，2=女孩)。</li>
</ul>
<p>一開始，我們的假設是，體重和年齡之間有線性關系(linear relationship)，且誤差項服從正態分布。這一句話用貝葉斯統計學標記來表達就是：</p>
<p><span class="math display" id="eq:gambiamodel">\[
\begin{aligned}
\text{wt}_i &amp; \sim \text{Normal}(\mu_i, \sigma^2) \;\; i = 1, \dots, 190 \\
\mu_i       &amp; = \alpha + \beta \times \text{age}_i + \gamma \times \text{sex}_i \\
\log\sigma^2 &amp; \sim \text{Uniform}(-100, 100) \\ 
\alpha       &amp; \sim \text{Uniform}(-1000, 1000) \\
\beta        &amp; \sim \text{Uniform}(-1000, 1000) \\ 
\gamma       &amp; \sim \text{Uniform}(-1000, 1000) \\ 
\end{aligned}
\tag{105.1}
\]</span></p>
<p>如果想用有向無環圖(DAG)來表示這個模型的話，可以用圖 <a href="#fig:BayesianChapter0503">105.3</a> 來表示這個線性回歸模型。圖中每一個元素都用圓形或者方形來表示，各個成分之間的關系則用帶方向箭頭的直線或虛線來連接。大的方形標注着 Child <span class="math inline">\(i\)</span> 的部分把該模型中被循環重復的部分。這個方形又被叫做盤(plates)，盤內標記的名稱和下標表示每一個被循環重復的最小個體單位。在這個岡比亞兒童數據中，兩個共變量/預測變量(<span class="math inline">\(age_i, sex_i\)</span>)，和一個結果變量(<span class="math inline">\(wt_i\)</span>)是從每一名兒童身上測量獲得的，所以每一名兒童是模型循環重復的最小單位。未知參數 <span class="math inline">\(\alpha, \beta, \gamma, \sigma^2\)</span> 都放在了盤以外的位置表示這些變量並不會隨着循環重復而改變。</p>
<p>值得注意的是，這個DAG圖 <a href="#fig:BayesianChapter0503">105.3</a> 中有兩種不同類型的直線。如果在你寫下的模型<a href="#eq:gambiamodel">(105.1)</a>中兩個變量之間使用的是 <span class="math inline">\(\sim\)</span> 連接的，那麼它們之間的連線就是實線，如果變量之間的關系使用的是等號 <span class="math inline">\(=\)</span> 建立的關系，那麼它們之間的連線是虛線。因爲 <span class="math inline">\(\sim\)</span> 表示的是隨機的不確定的關系(如服從某個先驗概率分布, stochastic links to a probability relationship)，而等號 <span class="math inline">\(=\)</span> 代表的關系是確定的 (deteministic relationships)。習慣上，圓形變量表示未知參數/隨機變量(random variables)，方形變量表示觀測到的值(fully observed covariates)。盡管結果變量 <span class="math inline">\((wt_i)\)</span> 是我們觀測收集的數據之一，但是在模型中它是隨機變量，因此在DAG繪圖法中也用圓形來標記。</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0503"></span>
<img src="img/DAGgambia.png" alt="DAG for Gambia Regression Model" width="45%" />
<p class="caption">
圖 105.3: DAG for Gambia Regression Model
</p>
</div>
</div>
<div id="bugs-model-for-gambia-example" class="section level3">
<h3><span class="header-section-number">105.2.2</span> BUGS model for Gambia example</h3>
<p>模型的數學標記(表達式 <a href="#eq:gambiamodel">(105.1)</a>)確定了以後，把它翻譯成BUGS語言就是下一步的工作了。本例中，我們並不想給模型加入任何有意義的先驗概率分布信息，所以給每個未知參數的先驗概率分布都是沒有信息的扁平的分布 (flat priors)。翻譯成BUGS語言以後的模型寫作：</p>
<pre><code>model{
    for(i in 1:190){ # loop through the 190 children
    wt[i] ~ dnorm(mu[i], tau)
    mu[i] &lt;- alpha + beta*age[i] + gamma*sex[i]
    }
  # priors
  alpha ~ dunif(-1000, 1000)
  beta  ~ dunif(-1000, 1000)
  gamma ~ dunif(-1000, 1000)
  logsigma2 ~ dunif(-100, 100)
  sigma2 &lt;- exp(logsigma2)
  tau    &lt;- 1/sigma2
}</code></pre>
</div>
<div id="data-file-for-the-gambia-example" class="section level3">
<h3><span class="header-section-number">105.2.3</span> Data file for the Gambia example</h3>
<p>準備數據時，有兩種格式是適用的：</p>
<div id="方形數據格式-rectangular-format" class="section level4">
<h4><span class="header-section-number">105.2.3.1</span> 方形數據格式 rectangular format</h4>
<pre><code>sex[] age[] wt[]
2    23  8.40  
2    22 10.9   
2     6  7.20  
1    24 10.3   
1    14 10.5   
2    18  9.60  
...
1    30 12.1 
END
</code></pre>
</div>
<div id="rs-plus-格式數據" class="section level4">
<h4><span class="header-section-number">105.2.3.2</span> R/S-plus 格式數據</h4>
<p>這種格式的數據較爲靈活，你可以在其中放入長度不一樣的向量，假如我們在模型的第一行不給出兒童的人數 <span class="math inline">\(190\)</span> 而是寫作：</p>
<pre><code>    for(i in 1:N){ # loop through the 190 children</code></pre>
<p>的話，那麼在數據文件中我們需要給出這個 <code>N</code> 的大小：　</p>
<pre><code>list(
  N = 190, 
 wt = c(8.4, 10.9, , 7.2, 10.3, 10.5, ..., 12.1), 
age = c(23, 22, 6, 24, 14, 18, ... , 30), 
sex = c(2, 2, 2, 1, 1, 2, 2, ..., 1)
)</code></pre>
</div>
</div>
<div id="初始值文件-initial-value-files" class="section level3">
<h3><span class="header-section-number">105.2.4</span> 初始值文件 initial value files</h3>
<p>前一章節我們探討過如何確認事後概率分布的MCMC採樣達到收斂，其中一個要點是使用兩個或更多的起始值，前提是你給模型的未知參數起始值需要是在合理範圍內，且差異較大的起始值。同樣使用 <code>list</code> 命令。</p>
<p>MCMC採樣鏈1的起始值：</p>
<pre><code>list(alpha = 0, beta = 1, gamma = 5, logsigma2 = 1)</code></pre>
<p>MCMC採樣鏈2的起始值：</p>
<pre><code>list(alpha = 10, beta = 0, gamma = -5, logsigma2 = 5)</code></pre>
</div>
<div id="給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1" class="section level3">
<h3><span class="header-section-number">105.2.5</span> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</h3>
<p>一開始我們先採集1000個事後概率分布樣本。模型中的四個未知參數<span class="math inline">\(\alpha, \beta, \gamma, \sigma^2\)</span>的1000次事後MCMC採樣的歷史痕跡圖繪制如圖 <a href="#fig:BayesianChapter0505">105.4</a>。我們可以看到模型收斂的速度很快。刨除前50次採樣的圖 (Fig. <a href="#fig:BayesianChapter0506">105.5</a>)，可以對採樣過程看得更加清楚。像圖 <a href="#fig:BayesianChapter0506">105.5</a> 這樣粗粗的有點像毛毛蟲一樣的歷史痕跡圖通常象徵已經達到理想的收斂。</p>
<div class="sourceCode" id="cb1410"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1410-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1410-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1412"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1412-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1412-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1414"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1414-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1414-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1416"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1416-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1416-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1416-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">0</span>, <span class="dt">beta =</span> <span class="dv">1</span>, <span class="dt">gamma =</span> <span class="dv">5</span>, <span class="dt">logsigma2 =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1416-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1419"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1419-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">10</span>, <span class="dt">beta =</span> <span class="dv">0</span>, <span class="dt">gamma =</span> <span class="dv">-5</span>, <span class="dt">logsigma2 =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1419-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1422"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1422-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1422-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;gamma&quot;</span>, <span class="st">&quot;sigma2&quot;</span>)</a>
<a class="sourceLine" id="cb1422-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;alpha&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;gamma&#39;</code></pre>
<pre><code>## monitor set for variable &#39;sigma2&#39;</code></pre>
<div class="sourceCode" id="cb1427"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1427-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1427-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 1 s</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0505"></span>
<img src="bookdown_files/figure-html/BayesianChapter0505-1.png" alt="History plots for iterations 1-1000 for the Gambia example." width="80%" />
<p class="caption">
圖 105.4: History plots for iterations 1-1000 for the Gambia example.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0506"></span>
<img src="bookdown_files/figure-html/BayesianChapter0506-1.png" alt="History plots for iterations 51-1000 for the Gambia example." width="80%" />
<p class="caption">
圖 105.5: History plots for iterations 51-1000 for the Gambia example.
</p>
</div>
<p>再看這1000次MCMC抽樣獲得的 Gelman-Rubin 統計量，差不多鏈內鏈間差異的比值在1000次左右可以認爲等於1，所以我們把這前1000次MCMC採樣作爲 burn-in 從事後樣本中刨除。確定了 burn-in 之後我們再對每一條MCMC鏈重復採樣25000次。</p>
<pre><code>## Potential scale reduction factors:
## 
##        Point est. Upper C.I.
## alpha        1.01       1.04
## beta         1.01       1.05
## gamma        1.00       1.00
## sigma2       1.00       1.00
## 
## Multivariate psrf
## 
## 1.01</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0507"></span>
<img src="bookdown_files/figure-html/BayesianChapter0507-1.png" alt="Gelman-Rubin convergence statistic for the Gambia example." width="80%" />
<p class="caption">
圖 105.6: Gelman-Rubin convergence statistic for the Gambia example.
</p>
</div>
</div>
<div id="岡比亞兒童體重數據的貝葉斯統計學推斷結果" class="section level3">
<h3><span class="header-section-number">105.2.6</span> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</h3>
<div class="sourceCode" id="cb1430"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1430-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1430-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1432"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1432-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1432-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1434"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1434-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1434-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1436"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1436-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1436-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1436-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">0</span>, <span class="dt">beta =</span> <span class="dv">1</span>, <span class="dt">gamma =</span> <span class="dv">5</span>, <span class="dt">logsigma2 =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1436-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1439"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1439-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">10</span>, <span class="dt">beta =</span> <span class="dv">0</span>, <span class="dt">gamma =</span> <span class="dv">-5</span>, <span class="dt">logsigma2 =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1439-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1442"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1442-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1442-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;gamma&quot;</span>, <span class="st">&quot;sigma2&quot;</span>)</a>
<a class="sourceLine" id="cb1442-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;alpha&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;gamma&#39;</code></pre>
<pre><code>## monitor set for variable &#39;sigma2&#39;</code></pre>
<div class="sourceCode" id="cb1447"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1447-1" title="1"><span class="co"># Generate 52000 iterations</span></a>
<a class="sourceLine" id="cb1447-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a></code></pre></div>
<pre><code>## 26000 updates took 25 s</code></pre>
<div class="sourceCode" id="cb1449"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1449-1" title="1">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1449-2" title="2"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##           mean      sd  MC_error val2.5pc  median val97.5pc start sample
## alpha   7.1490 0.23490 0.0034690   6.6900  7.1500    7.6120  1001  50000
## beta    0.1642 0.01093 0.0001514   0.1428  0.1642    0.1855  1001  50000
## gamma  -0.5199 0.18460 0.0017070  -0.8812 -0.5199   -0.1570  1001  50000
## sigma2  1.5810 0.16570 0.0007710   1.2880  1.5700    1.9340  1001  50000</code></pre>
<p>由於我們給每個未知參數的先驗概率分布都是沒有實際信息的，因此，預期貝葉斯模型給出的結果將會十分接近概率論模型給出的分析結果，事實也證明的確是如此：</p>
<div class="sourceCode" id="cb1451"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1451-1" title="1">Gambia.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(wt <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(sex), <span class="dt">data =</span> growgam1)</a>
<a class="sourceLine" id="cb1451-2" title="2"><span class="kw">summary</span>(Gambia.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age + factor(sex), data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -4.19236 -0.76268 -0.00696  0.75675  3.79163 
## 
## Coefficients:
##               Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)   7.152414   0.234254 30.5327 &lt; 2.2e-16 ***
## age           0.163998   0.010919 15.0189 &lt; 2.2e-16 ***
## factor(sex)2 -0.518854   0.183053 -2.8344  0.005095 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.2503 on 187 degrees of freedom
## Multiple R-squared:  0.5597, Adjusted R-squared:  0.55499 
## F-statistic: 118.85 on 2 and 187 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb1453"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1453-1" title="1"><span class="kw">regress.display</span>(Gambia.lm)</a></code></pre></div>
<pre><code>##  
##                    Coeff  lower095ci  upper095ci        Pr&gt;|t|
## (Intercept)   7.15241353  6.69029297  7.61453409 1.4039052e-74
## age           0.16399839  0.14245724  0.18553954 5.7949167e-34
## factor(sex)2 -0.51885399 -0.87996857 -0.15773941 5.0951539e-03</code></pre>
<p>即使用 Stata 獲得的也是一樣的結果，差異十分微小。</p>
<pre><code>## 
## 
## . use &quot;backupfiles/growgam1.d. regress wt age i.sex
## 
##       Source |       SS           df       MS      Number of obs   =       190
## -------------+----------------------------------   F(2, 187)       =    118.85
##        Model |  371.623281         2   185.81164   Prob &gt; F        =    0.0000
##     Residual |  292.346478       187  1.56335015   R-squared       =    0.5597
## -------------+----------------------------------   Adj R-squared   =    0.5550
##        Total |  663.969759       189  3.51306751   Root MSE        =    1.2503
## 
## ------------------------------------------------------------------------------
##           wt |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          age |   .1639984   .0109195    15.02   0.000     .1424572    .1855395
##              |
##          sex |
##      female  |   -.518854   .1830531    -2.83   0.005    -.8799686   -.1577394
##        _cons |   7.152414   .2342542    30.53   0.000     6.690293    7.614534
## ------------------------------------------------------------------------------</code></pre>
</div>
<div id="檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2" class="section level3">
<h3><span class="header-section-number">105.2.7</span> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</h3>
<p>盡管我們獲取了50000個事後MCMC樣本，但是關於 <span class="math inline">\(\text{MC_error} \approx 2 \text{ orders of magnitude smaller than the posterior SD}\)</span> 的經驗法則 (rule of thumb)，其實並沒有得到滿足。實際用於估計事後 <span class="math inline">\(\alpha, \beta\)</span> 的有效樣本量是小於 10000的。繪制每個參數的自回歸 (autocorrelation) 圖也證實了這些事後樣本有許多有強的自相關：</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0510"></span>
<img src="bookdown_files/figure-html/BayesianChapter0510-1.png" alt="Autocorrelation plot for the Gambia example (uncentered model, chain 1)" width="80%" />
<p class="caption">
圖 105.7: Autocorrelation plot for the Gambia example (uncentered model, chain 1)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0511"></span>
<img src="bookdown_files/figure-html/BayesianChapter0511-1.png" alt="Autocorrelation plot for the Gambia example (uncentered model, chain 2)" width="80%" />
<p class="caption">
圖 105.8: Autocorrelation plot for the Gambia example (uncentered model, chain 2)
</p>
</div>
<p>這些 MCMC 樣本的自相關程度之所以如此之高，其最主要的原因是我們沒有把連續變量年齡給中心化。解決這個問題的辦法是把原先模型中的線性回歸模型的年齡中心化：</p>
<pre><code>mu[i] &lt;- alpha + beta*(age[i] - mean(age[])) + gamma*sex[i]</code></pre>
<p>這一次我們獲得的50000個MCMC事後樣本的參數估計結果如下：</p>
<div class="sourceCode" id="cb1457"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1457-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1457-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-model-agecen.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1459"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1459-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1459-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/gambia-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1461"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1461-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1461-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1463"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1463-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1463-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1463-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">0</span>, <span class="dt">beta =</span> <span class="dv">1</span>, <span class="dt">gamma =</span> <span class="dv">5</span>, <span class="dt">logsigma2 =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1463-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1466"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1466-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">10</span>, <span class="dt">beta =</span> <span class="dv">0</span>, <span class="dt">gamma =</span> <span class="dv">-5</span>, <span class="dt">logsigma2 =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1466-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1469"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1469-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1469-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;gamma&quot;</span>, <span class="st">&quot;sigma2&quot;</span>)</a>
<a class="sourceLine" id="cb1469-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;alpha&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;gamma&#39;</code></pre>
<pre><code>## monitor set for variable &#39;sigma2&#39;</code></pre>
<div class="sourceCode" id="cb1474"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1474-1" title="1"><span class="co"># Generate 51000 iterations</span></a>
<a class="sourceLine" id="cb1474-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a></code></pre></div>
<pre><code>## 26000 updates took 30 s</code></pre>
<div class="sourceCode" id="cb1476"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1476-1" title="1">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1476-2" title="2"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##           mean     sd   MC_error val2.5pc  median val97.5pc start sample
## alpha   9.9360 0.1376 0.00111200   9.6660  9.9360   10.2000  1001  50000
## beta    0.1640 0.0110 0.00005164   0.1424  0.1640    0.1855  1001  50000
## gamma  -0.5178 0.1845 0.00151300  -0.8788 -0.5178   -0.1564  1001  50000
## sigma2  1.5800 0.1661 0.00076440   1.2910  1.5690    1.9360  1001  50000</code></pre>
<p>注意到這時候事後參數估計給出的 <code>alpha</code> 結果發生了微妙的變化，然而其他的幾個變量的事後估計結果幾乎沒有改變。且此時 <code>MC_error</code> 也變得小了很多，達到了我們的經驗法則所要求的。這時候的事後MCMC採樣鏈的自相關圖也提供較爲了理想的結果：</p>
<div class="sourceCode" id="cb1478"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1478-1" title="1"><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1478-2" title="2"><span class="kw">samplesAutoC</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">chain =</span> <span class="dv">1</span>, <span class="dt">beg =</span> <span class="dv">1001</span>,</a>
<a class="sourceLine" id="cb1478-3" title="3">             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">lag.max =</span> <span class="dv">50</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0513"></span>
<img src="bookdown_files/figure-html/BayesianChapter0513-1.png" alt="Autocorrelation plot for the Gambia example (centered model, chain 1)" width="80%" />
<p class="caption">
圖 105.9: Autocorrelation plot for the Gambia example (centered model, chain 1)
</p>
</div>
<div class="sourceCode" id="cb1479"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1479-1" title="1"><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb1479-2" title="2"><span class="kw">samplesAutoC</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">chain =</span> <span class="dv">2</span>, <span class="dt">beg =</span> <span class="dv">1001</span>,</a>
<a class="sourceLine" id="cb1479-3" title="3">             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">lag.max =</span> <span class="dv">50</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0514"></span>
<img src="bookdown_files/figure-html/BayesianChapter0514-1.png" alt="Autocorrelation plot for the Gambia example (centered model, chain 2)" width="80%" />
<p class="caption">
圖 105.10: Autocorrelation plot for the Gambia example (centered model, chain 2)
</p>
</div>
<p>共變量年齡，和性別的回歸系數的事後概率分布圖繪制如下：</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0515"></span>
<img src="bookdown_files/figure-html/BayesianChapter0515-1.png" alt="Change in weight per month increase in age (posterior mean: 0.164 kg, 95% credible interval (0.142, 0.185)" width="80%" />
<p class="caption">
圖 105.11: Change in weight per month increase in age (posterior mean: 0.164 kg, 95% credible interval (0.142, 0.185)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0516"></span>
<img src="bookdown_files/figure-html/BayesianChapter0516-1.png" alt="Change in weight for girls compared to boys (posterior mean: -0.516 kg, 95% credible interval (-0.877, -0.156)" width="80%" />
<p class="caption">
圖 105.12: Change in weight for girls compared to boys (posterior mean: -0.516 kg, 95% credible interval (-0.877, -0.156)
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0517"></span>
<img src="img/fitted_regression_line.png" alt="Fitted regression line versus covariate (age)" width="80%" />
<p class="caption">
圖 105.13: Fitted regression line versus covariate (age)
</p>
</div>
<p>BUGS軟件也能提供類似圖 <a href="#fig:BayesianChapter0517">105.13</a> 這樣的擬合值和共變量年齡之間的關系的圖。其中紅色線代表體重的擬合值，藍色線代表95%可信區間的範圍。</p>
<p>經過這些步驟的分析，相信你也意識到，給貝葉斯模型中的共變量中心化(centering covariates)，是提高模型分析採樣效率的好方法。它把事後未知參數的位置中心化，同時減少事後MCMC採樣的自相關。之前沒有把年齡中心化的模型結果也提示我們如果共變量未被中心化，其事後概率分布的MCMC樣本的有效樣本量是會被打了折扣的，採樣的收斂速度也較長。</p>
</div>
<div id="檢查模型擬合程度-checking-model-fit-for-the-gambia-example" class="section level3">
<h3><span class="header-section-number">105.2.8</span> 檢查模型擬合程度 checking model fit for the Gambia example</h3>
<p>目前爲止我們完成了貝葉斯簡單線性回歸模型的建立，及其事後概率樣本的 MCMC 採集。下一步應該做的是對模型的擬合度進行檢查。模型檢查包括我們在簡單先行回顧章節學習過的一些標準(standard)檢查要點：</p>
<ul>
<li><strong>殘差 residuals：</strong>把殘差和各個共變量做散點圖，檢查每個未知參數的自相關；</li>
<li><strong>預測 prediction：</strong>把創建的模型拿到其他的新數據中驗證其外部有效程度 (external validation/cross validation)。</li>
</ul>
<p>除此之外，我們仍然要補充做的包括：</p>
<ul>
<li>檢查先驗概率分布和實際觀察數據之間是否有衝突 check for conflict between prior and data；</li>
<li>檢查貝葉斯模型是否會對不同的先驗概率分布較爲敏感 check for unintended sensitivity to the prior。</li>
</ul>
<p>標準化殘差 (standardised residuals) 的計算公式是 <span class="math inline">\(r = \frac{y - \mu}{\sigma}\)</span>，其中 <span class="math inline">\(\mu = E[y], \sigma^2 = V[y]\)</span>。在貝葉斯模型中獲得的殘差也是隨機變量 (random quantities)，有自己的分布。如果你願意，你可以把殘差的事後概率分布密度圖給繪制出來，或者選擇檢驗分布的形狀參數 (testing distributional shape)等等方法來檢驗殘差，但是如果你只要給每個對象提取一個模型殘差值，你的選擇可以有：</p>
<ul>
<li>標準化殘差的事後概率分布均值 posterior mean of the standardised residuals <span class="math inline">\(E(r)\)</span>；</li>
<li>(plug-in posterior mean) 或者把參數的事後均值<span class="math inline">\(\mu\)</span>及其標準差<span class="math inline">\(\sigma\)</span>的均值放到計算式裏面: <span class="math inline">\(r = \frac{y - E(\mu)}{E(\sigma)}\)</span>。</li>
</ul>
<p>使用MCMC計算機模擬試驗的算法優勢，我們擁有了重復計算大量參數的能力。所以對於每一個觀察對象(岡比亞兒童)，我們可以用這個線性回歸模型計算他/她的體重的事後預測分布(predictive distribution) <span class="math inline">\(y_i^{pred}\)</span>，然後把他/她的體重觀察值<span class="math inline">\((y_i^{obs})\)</span>和他/她的體重事後概率分布做比較。利用 <code>step</code> 命令來計算每個孩子身上用模型計算的預測體重分布中，小於觀察的體重數據的面積 <span class="math inline">\(p(y_i^{pred} &lt; y_i^{obs})\)</span>。如果有許多觀測值，位於它各自事後概率分布的兩極（即預測體重遠小於，或者遠大於觀測體重），那麼可以認爲該模型擬合度較差。</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0518"></span>
<img src="img/predictive-check.png" alt="Predictive check" width="70%" />
<p class="caption">
圖 105.14: Predictive check
</p>
</div>
<p>用岡比亞兒童體重的貝葉斯模型來說，我們利用MCMC強大的事後樣本採集能力，在模型中增加並監測三個新的變量 <code>res, wt.pred, p.pred</code>：</p>
<pre><code>model{
    for(i in 1:190){ # loop through the 190 children
    wt[i] ~ dnorm(mu[i], tau)
    mu[i] &lt;- alpha + beta*(age[i] - mean(age[])) + gamma*sex[i]
    
    # standardised residuals 
    res[i] &lt;- (wt[i] - mu[i]) / sqrt(sigma2)
    
    # predictions 
    wt.pred[i] ~ dnorm(mu[i], tau) # repredict for each child
    p.pred[i] &lt;- step(wt[i] - wt.pred[i])
    }
  # priors
  alpha ~ dunif(-1000, 1000)
  beta  ~ dunif(-1000, 1000)
  gamma ~ dunif(-1000, 1000)
  logsigma2 ~ dunif(-100, 100)
  sigma2 &lt;- exp(logsigma2)
  tau    &lt;- 1/sigma2
}</code></pre>
<p>所以我們只要增加對新增的三個變量 <code>res, wt.pred, p.pred</code> 的事後樣本採集的監控就可以了。圖 <a href="#fig:BayesianChapter0519">105.15</a> 展示了BUGS軟件提供的殘差分析圖(caterpillar/毛蟲 plot)。它其實十分接近箱式圖 (box-plot)，唯一的區別是不顯示四分位數間距 (inter-quartile range)。毛蟲圖的最大優點在於，便於比較有很多事後概率分布的情況，像本例中190名兒童的體重都有各自的事後概率分布，他們每人的殘差也有各自的分布。圖 <a href="#fig:BayesianChapter0520">105.16</a> 則是BUGS軟件繪制的岡比亞兒童體重的95%預測區間，後面的黑色散點圖是觀察值。</p>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0519"></span>
<img src="img/caterpillarplot.png" alt="Caterpillar plot of the posterior distribution of standardised residuals vs. child ID" width="70%" />
<p class="caption">
圖 105.15: Caterpillar plot of the posterior distribution of standardised residuals vs. child ID
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianChapter0520"></span>
<img src="img/PredictionbandsGambia.png" alt="Prediction bands for replicate data." width="70%" />
<p class="caption">
圖 105.16: Prediction bands for replicate data.
</p>
</div>
</div>
<div id="tdreplacegaussian" class="section level3">
<h3><span class="header-section-number">105.2.9</span> 其他的替代模型 alternative model with t-errors</h3>
<p>檢查一個模型意爲着我們可能需要替代模型。例如，我們可以使模型中的體重不是服從正態分布，而是服從 t 分布，因爲 t 分布將會給模型提供更高的穩健性。（t分布的兩端面積比起正態分布要大一些，也就是允許模型考慮更多的離羣值outliers）：</p>
<pre><code>model{
    for(i in 1:190){ # loop through the 190 children
    wt[i] ~ dt(mu[i], tau, 4) # robust likelihood t distribution on 4 df
    mu[i] &lt;- alpha + beta*(age[i] - mean(age[])) + gamma*sex[i]
}
  # priors
  alpha ~ dunif(-1000, 1000)
  beta  ~ dunif(-1000, 1000)
  gamma ~ dunif(-1000, 1000)
  logsigma2 ~ dunif(-100, 100)
  sigma2 &lt;- exp(logsigma2)
  tau    &lt;- 1/sigma2
}</code></pre>
</div>
</div>
<div id="貝葉斯統計模型的比較-bayesian-model-comparison" class="section level2">
<h2><span class="header-section-number">105.3</span> 貝葉斯統計模型的比較 Bayesian model comparison</h2>
<p>在使用統計學模型時，我們自然而然地想用模型對數據的擬合度來輔助進行模型的篩選及比較。常用的指標有 Akaike Information Criterion (AIC)：</p>
<p><span class="math display">\[
\text{AIC} = -2\log p(y | \hat \theta) + 2k
\]</span>
其中， <span class="math inline">\(p(y|\hat\theta)\)</span> 就是模型的似然(likelihood)用來代表模型對數據的擬合度，<span class="math inline">\(k\)</span> 是模型中的未知參數個數，用來表示模型的復雜程度。</p>
<div id="deviance-information-criterion-dic" class="section level3">
<h3><span class="header-section-number">105.3.1</span> Deviance Information Criterion (DIC)</h3>
<p><span class="citation">(Spiegelhalter et al. <a href="#ref-Spiegelhalter2002" role="doc-biblioref">2002</a>)</span>提出用 DIC 來比較貝葉斯模型。它也是利用和 AIC 類似的思想，使用DIC來綜合表示模型的擬合度，及模型的復雜程度：</p>
<p><span class="math display">\[
\text{DIC} = \text{goodness of fit} + \text{complexity}
\]</span></p>
<p>其中模型的擬合程度部分用的是模型偏差值：<span class="math inline">\(D(\theta) = -2\log L(data | \theta)\)</span>；</p>
<p>模型復雜程度使用的則是，模型中有效的未知參數的個數：</p>
<p><span class="math display">\[
\begin{aligned}
p_D &amp; = E_{\theta | y}[D] - D(E_{\theta | y}[\theta]) \\ 
    &amp; = \bar D - D(\bar\theta)
\end{aligned}
\]</span></p>
<p>i.e. the posterior mean deviance minus the deviance evaluated at the posterior mean of the parameters.</p>
<p>然後 DIC 的定義也模仿 AIC：</p>
<p><span class="math display">\[
\begin{aligned}
\text{DIC} &amp; = D(\bar\theta) + 2 p_D \\ 
           &amp; = \bar D + p_D
\end{aligned}
\]</span></p>
<p>比較的方法是DIC越小的模型，越優，數據越支持。</p>
<ul>
<li>如果兩個模型的 DIC 相差大於 10，說明DIC較小的模型更好；</li>
<li>如果兩個模型的 DIC 相差小於 5，說明兩個模型無太大差別。</li>
</ul>
<p>在BUGS軟件中你需要像追蹤監測其他隨機變量一樣監測模型的DIC，特別是要在確定模型已經達到收斂之後，採集收斂之後的 DIC 數值用於比較。</p>
</div>
<div id="岡比亞兒童體重數據模型比較" class="section level3">
<h3><span class="header-section-number">105.3.2</span> 岡比亞兒童體重數據模型比較</h3>
<p>當設定體重服從正態分布時，我們獲得模型的 DIC 是</p>
<pre><code>       Dbar  Dhat   DIC    pD
wt    625.1 621.1 629.1 3.983
total 625.1 621.1 629.1 3.983</code></pre>
<p>當設定體重服從自由度爲4的t分布時，我們獲得模型的 DIC 是</p>
<pre><code>       Dbar Dhat   DIC    pD
wt    622.1  618 626.2 4.114
total 622.1  618 626.2 4.114</code></pre>
<p>兩個模型的DIC差別在3左右，也就是說用正態分布，或者t分布，對結果影響不大。</p>
<p>這兩個模型給出的我們的問題的答案也不會有本質上的差別：</p>
<ul>
<li>年齡每增加1個月，體重的變化：
<ul>
<li>正態分布：<span class="math inline">\(\beta\)</span> 的事後均值爲 0.164 kg，95% 可信區間 (0.142, 0.185)；</li>
<li>t 分布：<span class="math inline">\(\beta\)</span> 的事後均值爲 0.167 kg, 95% 可信區間 (0.146, 0.187)。</li>
</ul></li>
<li>男孩和女孩的體重差別：
<ul>
<li>正態分布：<span class="math inline">\(\gamma\)</span> 的事後均值爲 -0.519 kg，95% 可信區間 (-0.877, -0.156)；</li>
<li>t 分布：<span class="math inline">\(\gamma\)</span> 的事後均值爲 -0.574 kg，95% 可信區間 (-0.915, -0.232)。</li>
</ul></li>
</ul>
</div>
</div>
<div id="practical-bayesian-statistics-05" class="section level2">
<h2><span class="header-section-number">105.4</span> Practical Bayesian Statistics 05</h2>
<p>本次練習我們來比較多個貝葉斯線性回歸模型。看看在模型中增加其他的變量是否能改善模型的擬合度，最終你會選哪個線性回歸模型來回答一開始我們提出的問題。</p>
<p>除了本章實例中使用的線性回歸模型，另外可以拿來比較的模型分別是：</p>
<ol style="list-style-type: decimal">
<li>增加年齡的二次方項 <span class="math inline">\(age^2\)</span>；</li>
<li>增加年齡和性別的交互作用項 <span class="math inline">\(age \times sex\)</span>。</li>
</ol>
<p>在思考貝葉斯模型怎樣增加上面兩個變量的語法的同時，請思考這樣幾個問題：</p>
<ol style="list-style-type: decimal">
<li>要怎樣修改模型的BUGS代碼才能正確表達想要增加的模型變量？特別是模型應該怎麼寫才能把年齡的平方中心化？</li>
<li>如何寫MCMC鏈的起始值？</li>
<li>跑完模型以後，給模型的擬合實施常規的檢查。</li>
<li>簡單線性迴歸模型中增加了這些部分後的結果，要如何回答我們一開始提出的問題？（年齡每增加一個月，體重的變化是多少kg？男孩和女孩之間的體重差別是多少kg？）</li>
</ol>
<div id="增加年齡二次方項-adding-age-squared" class="section level3">
<h3><span class="header-section-number">105.4.1</span> 增加年齡二次方項 adding age squared</h3>
<pre><code>model{
    for(i in 1:190){ # loop through the 190 children
    wt[i] ~ dnorm(mu[i], tau)
    mu[i] &lt;- alpha + beta*cage[i] + gamma*sex[i] + delta*cagesq[i]
    cage[i] &lt;- age[i] - mean(age[]) # centered age
    agesq[i] &lt;- pow(age[i], 2)
    cagesq[i] &lt;- agesq[i] - mean(agesq[]) # centered age squared
    
    # standardised residuals 
    res[i] &lt;- (wt[i] - mu[i]) / sqrt(sigma2)
    
    # predictions 
    wt.pred[i] ~ dnorm(mu[i], tau) # repredict for each child
    p.pred[i] &lt;- step(wt[i] - wt.pred[i])
    }
  # priors
  alpha ~ dunif(-1000, 1000)
  beta  ~ dunif(-1000, 1000)
  gamma ~ dunif(-1000, 1000)
  delta ~ dunif(-1000, 1000)
  logsigma2 ~ dunif(-100, 100)
  sigma2 &lt;- exp(logsigma2)
  tau    &lt;- 1/sigma2
}</code></pre>
<p>使用的兩個MCMC鏈的起始值分別是：</p>
<pre><code>initlist &lt;- list(alpha = 0, beta = 1, gamma = 5, delta = -1, logsigma2 = 1)
initlist1 &lt;- list(alpha = 10, beta = 0, gamma = -5, delta = 1, logsigma2 = 5)</code></pre>
<p>獲得的50000個事後概率分佈樣本的統計描述是：</p>
<pre><code>            mean       sd  MC_error  val2.5pc    median  val97.5pc start sample
alpha   9.945000 0.136100 1.166e-03  9.677000  9.945000 10.2100000  1001  50000
beta    0.256600 0.053360 1.452e-03  0.151600  0.256500  0.3621000  1001  50000
delta  -0.002429 0.001372 3.731e-05 -0.005133 -0.002422  0.0002715  1001  50000
gamma  -0.535000 0.181100 1.526e-03 -0.887300 -0.534900 -0.1815000  1001  50000
sigma2  1.563000 0.164300 8.325e-04  1.275000  1.551000  1.9190000  1001  50000</code></pre>
<p>模型的 DIC 是：</p>
<pre><code>      Dbar Dhat DIC    pD
wt     623  618 628 5.008
total  623  618 628 5.008</code></pre>
<p>和之前沒有增加年齡平方的模型相比較DIC減少了大概只有1。因此，基本沒有差別的情況下，我們選擇沒有年齡平方的一開始的模型。從 <code>delta</code> 的事後概率分佈結果也知道它的95%可信區間是包括0的。也說明了增加年齡平方項的部分無太多意義。</p>
</div>
<div id="增加年齡和性別的交互作用項-adding-an-interaction-term" class="section level3">
<h3><span class="header-section-number">105.4.2</span> 增加年齡和性別的交互作用項 adding an interaction term</h3>
<pre><code>model{
    for(i in 1:190){ # loop through the 190 children
    wt[i] ~ dnorm(mu[i], tau)
    mu[i] &lt;- alpha + beta*cage[i] + gamma*sex[i] + delta*cage[i]*sex[i]
    cage[i] &lt;- age[i] - mean(age[]) # centered age

    # standardised residuals 
    res[i] &lt;- (wt[i] - mu[i]) / sqrt(sigma2)
    
    # predictions 
    wt.pred[i] ~ dnorm(mu[i], tau) # repredict for each child
    p.pred[i] &lt;- step(wt[i] - wt.pred[i])
    }
  # priors
  alpha ~ dunif(-1000, 1000)
  beta  ~ dunif(-1000, 1000)
  gamma ~ dunif(-1000, 1000)
  delta ~ dunif(-1000, 1000)
  logsigma2 ~ dunif(-100, 100)
  sigma2 &lt;- exp(logsigma2)
  tau    &lt;- 1/sigma2
}</code></pre>
<p>使用的起始值分別是：</p>
<pre><code>initlist &lt;- list(alpha = 0, beta = 1, gamma = 5, delta = -5, logsigma2 = 1)
initlist1 &lt;- list(alpha = 10, beta = 0, gamma = -5, delta = 5, logsigma2 = 5)</code></pre>
<p>事後概率分佈樣本的統計學描述是：</p>
<pre><code>            mean      sd  MC_error val2.5pc    median val97.5pc start sample
alpha   9.937000 0.13730 0.0011460  9.66900  9.936000  10.21000  1001  50000
beta    0.165500 0.01609 0.0001244  0.13380  0.165500   0.19710  1001  50000
delta  -0.002979 0.02223 0.0001703 -0.04668 -0.003053   0.04065  1001  50000
gamma  -0.519900 0.18380 0.0015730 -0.88040 -0.518800  -0.16250  1001  50000
sigma2  1.590000 0.16700 0.0007803  1.29800  1.578000   1.94800  1001  50000</code></pre>
<p>DIC是：</p>
<pre><code>       Dbar  Dhat   DIC    pD
wt    626.1 621.1 631.1 5.003
total 626.1 621.1 631.1 5.003</code></pre>
<p>增加了性別年齡交互項的模型給出的DIC比原先的模型大了2個單位左右，所以，我們還是會選擇沒有交互作用項的一開始的簡單線性迴歸模型。</p>
</div>
</div>
</div>
<div id="不同實驗研究設計時適用的貝葉斯模型" class="section level1">
<h1><span class="header-section-number">第 106 章</span> 不同實驗/研究設計時適用的貝葉斯模型</h1>
<p>本章節我們將要學習和探索如何給不同的實驗設計方法寫相對應的 BUGS 貝葉斯模型，用於比較不同組之間的差異。根據不同的試驗設計，模型也會跟着發生變化。例如病例對照研究的數據和模型結構，一定和隊列研究，或者是簡單的橫斷面研究的模型和數據結構差別甚遠。</p>
<p>爲不同的實驗設計寫下正確的貝葉斯模型的關鍵是，要深刻理解不同實驗設計時的樣本採集過程：實驗對象的哪些特徵，哪些變量是確定的，哪些被認爲是隨機變量。我們要爲那些被認爲是隨機變量的部分採集事後概率分佈樣本。</p>
<p>貫穿本章節，我們默認：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Y\)</span> 是要研究的疾病，<span class="math inline">\(X\)</span> 是要研究的暴露因素；</li>
<li>給概率 (probabilities)，和患病率 (prevalences)提供均一先驗概率分佈 (uniform priors)。給作用效果的評價指標例如危險度比 (risk ratios, RR)，危險度差 (risk difference, RD)，或者是比值比 (odds ratios, OR)提供中性的，圍繞着無效爲中心的先驗概率分佈 (“neutral” priors centred on no effect)。</li>
</ol>
<div id="隊列研究設計時的貝葉斯模型" class="section level2">
<h2><span class="header-section-number">106.1</span> 隊列研究設計時的貝葉斯模型</h2>
<p>假如我們徵集兩組觀察對象，一組爲2000名非吸菸者，另一組爲1000名吸菸者。他們年齡均爲30歲，之後我們隨訪這兩組研究對象20年，觀察到非吸菸者癌症發病人數爲100人，吸菸者癌症發病人數爲150人。這個實驗設計的目的是比較兩組觀察對象的20年癌症發病危險度。在這個實驗設計條件下，癌症發病是隨機變量，但是暴露組（吸菸）和非暴露組（非吸菸）的人數，是一開始已經定下來不會改變的數值。</p>
<p>需要強調的是，BUGS語言十分靈活，同一個模型，不同的人寫可能會給出完全不同，結果卻十分相近的代碼。給模型中的未知參數指定先驗概率分布時的方法也不盡相同。本隊列研究的實例中，比較癌症發病危險度 (risk) 的模型之一，可以寫作：</p>
<pre><code>model{
    Y0 ~ dbin(r0, X0) # Data model for unexposed
    Y1 ~ dbin(r1, X1) # Data model for exposed
    
    # Priors for risks of exposed and unexposed
    r0 ~ dbeta(a.unexp, b.unexp)
    r1 ~ dbeta(a.exp, b.exp)
    
    # Computation of comparison statistics
    rd &lt;-  r1 - r0   # for Risk Difference 
    rr &lt;- r1 / r0    # for Risk Ratio
}</code></pre>
<p>數據文件可以寫作：</p>
<div class="sourceCode" id="cb1493"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1493-1" title="1"><span class="kw">list</span>(<span class="dt">X0 =</span> <span class="dv">2000</span>, </a>
<a class="sourceLine" id="cb1493-2" title="2">     <span class="dt">X1 =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb1493-3" title="3">     <span class="dt">Y0 =</span> <span class="dv">100</span>, </a>
<a class="sourceLine" id="cb1493-4" title="4">     <span class="dt">Y1 =</span> <span class="dv">150</span>, </a>
<a class="sourceLine" id="cb1493-5" title="5">     <span class="dt">a.unexp =</span> <span class="dv">1</span>, <span class="dt">b.unexp =</span> <span class="dv">1</span>, </a>
<a class="sourceLine" id="cb1493-6" title="6">     <span class="dt">a.exp   =</span> <span class="dv">1</span>, <span class="dt">b.exp   =</span> <span class="dv">1</span>)</a></code></pre></div>
<p>在上面的BUGS模型代碼中，我們需要給暴露組和非暴露組的發病危險度 (risks) 指定先驗概率分布。但是更常見的是直接給出危險度差，或者危險度比本身的先驗概率分布。這時候你可以把上面的 BUGS 模型加以修改：</p>
<pre><code>model{
    Y0 ~ dbin(r0, X0) # Data model for unexposed
    Y1 ~ dbin(r1, X1) # Data model for exposed
    
    # define r1 as the unexposed risk plus an effect &quot;rd&quot;
    r1 &lt;- r0 + rd
    
    # Priors for risks of exposed and unexposed
    r0 ~ dbeta(a.unexp, b.unexp)
    rd ~ dunif(min.rd, max.rd)
    
    # Computation of comparison statistics
    rr &lt;- r1 / r0    # for Risk Ratio
}</code></pre>
<p>對於這個模型代碼來說，你需要給出的數據文件中，對於 <code>r1</code> 的部分可以省去，但是需要給出 <code>rd</code> 的先驗概率分布中均一分布的兩個超參數 (hyper parameters)：</p>
<div class="sourceCode" id="cb1495"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1495-1" title="1"><span class="kw">list</span>(<span class="dt">X0 =</span> <span class="dv">2000</span>, </a>
<a class="sourceLine" id="cb1495-2" title="2">     <span class="dt">X1 =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb1495-3" title="3">     <span class="dt">Y0 =</span> <span class="dv">100</span>, </a>
<a class="sourceLine" id="cb1495-4" title="4">     <span class="dt">Y1 =</span> <span class="dv">150</span>, </a>
<a class="sourceLine" id="cb1495-5" title="5">     <span class="dt">a.unexp =</span> <span class="dv">1</span>, <span class="dt">b.unexp =</span> <span class="dv">1</span>, </a>
<a class="sourceLine" id="cb1495-6" title="6">     <span class="dt">min.rd =</span> <span class="dv">-30</span>, <span class="dt">max.rd =</span> <span class="dv">30</span>)</a></code></pre></div>
<p>如果你又改變主意，對相對危險度比 (risk ratio, RR) 的模型更加感興趣，建議你使用 <code>logit</code> 來把百分比放入模型中，因爲 <span class="math inline">\(\log \text{OR}\)</span> 通常更加符合正態分布，便於給出先驗概率分布。這時候模型又可以變形成爲：　</p>
<pre><code>model{
    Y0 ~ dbin(r0, X0)   # Data model for unexposed
    logit(r0) &lt;- lr0    # define the logit of r0
    Y1 ~ dbin(r1, X1)   # Data model for exposed
    logit(r1) &lt;- lr1    # define the logit of r1
    
    # define lr1 as the unexposed logit(risk) plus log(OR):
    lr1 &lt;- lr0 + lor
    
    # priors for the logit of risk of unexposed and of log(OR): 
    lr0 ~ dnorm(mean.lr0, pr.lr0) 
    lor ~ dnorm(mean.lor, pr.lor)
    
    # computations of comparison statistics: 
    rd &lt;- r1 - r0      # For risk difference
    rr &lt;- r1 / r0      # For risk ratio
}</code></pre>
<p>這個模型中要給 <code>r0</code> 一個均一分布的先驗概率，又希望給 <code>or</code> 指定一個95%可信區間在 (1/30, 30) 範圍內的先驗概率。那麼合適的數據文件可以寫作：</p>
<div class="sourceCode" id="cb1497"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1497-1" title="1"><span class="kw">list</span>(<span class="dt">X0 =</span> <span class="dv">2000</span>, </a>
<a class="sourceLine" id="cb1497-2" title="2">     <span class="dt">X1 =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb1497-3" title="3">     <span class="dt">Y0 =</span> <span class="dv">100</span>, </a>
<a class="sourceLine" id="cb1497-4" title="4">     <span class="dt">Y1 =</span> <span class="dv">150</span>, </a>
<a class="sourceLine" id="cb1497-5" title="5">     <span class="dt">mean.lr0 =</span> <span class="dv">0</span>, <span class="dt">pr.lr0 =</span> <span class="fl">0.3</span>, </a>
<a class="sourceLine" id="cb1497-6" title="6">     <span class="dt">mean.lor =</span> <span class="dv">0</span>, <span class="dt">pr.lor =</span> <span class="fl">0.33</span>)</a></code></pre></div>
</div>
<div id="病例對照研究設計時的貝葉斯模型" class="section level2">
<h2><span class="header-section-number">106.2</span> 病例對照研究設計時的貝葉斯模型</h2>
<p>假設試驗設計改成了病例對照研究，我們找到了1000名癌症患者，2000名無癌症的研究對象作爲對照。之後我們讓這兩羣研究對象回憶自己過去20年的吸煙史。假設數據收集到的是，在癌症患者組，有100名是吸煙者，在無癌症的對照組中吸煙人數有800人。在這個實驗設計的條件下，隨機會發生變化的就再也不是癌症的發病概率，或者危險度，而是吸煙於非吸煙的暴露，非暴露的變量 (smokers, non-smokers)。這時候我們來把模型中的變量用 <code>logit</code> 刻度(scale)來表示就是：</p>
<pre><code>model{
    X0 ~ dbin(p0, Y0) # data model for CONTROLS 
    logit(p0) &lt;- lp0  # define the logit of p0
    X1 ~ dbin(p1, Y1) # data model for CASES
    logit(p1) &lt;- lp1  # define the logit of p1
    
    # define lp1 as the unexposed logit(exposure) plus log(OR)
    lp1 &lt;- lp0 + lor
    
    # Priors for logit of exposure and of log(OR)
    lp0 ~ dnorm(mean.lp0, pr.lp0)
    lor ~ dnorm(mean.lor, pr.lor)
    
    # Computation of comparison statistics
    or &lt;- exp(lor)    # For Odds Ratio
}</code></pre>
<p>這時候合適的數據文件，及先驗概率分布的超參數的指定可以寫作：</p>
<div class="sourceCode" id="cb1499"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1499-1" title="1"><span class="kw">list</span>(<span class="dt">Y0 =</span> <span class="dv">2000</span>, </a>
<a class="sourceLine" id="cb1499-2" title="2">     <span class="dt">Y1 =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb1499-3" title="3">     <span class="dt">X0 =</span> <span class="dv">800</span>, </a>
<a class="sourceLine" id="cb1499-4" title="4">     <span class="dt">X1 =</span> <span class="dv">600</span>, </a>
<a class="sourceLine" id="cb1499-5" title="5">     <span class="dt">mean.lp0 =</span> <span class="dv">0</span>, <span class="dt">pr.lp0 =</span> <span class="fl">0.3</span>, </a>
<a class="sourceLine" id="cb1499-6" title="6">     <span class="dt">mean.lor =</span> <span class="dv">0</span>, <span class="dt">pr.lor =</span> <span class="fl">0.33</span>)</a></code></pre></div>
<p>從這裏的代碼也可以看出，此時我們能獲得的評價指標只能是比值比 OR，它直接從對數比值比<span class="math inline">\(\log \text{OR}\)</span>獲得。在病例對照研究的實驗設計下，我們無法計算危險度差(risk difference)，或者危險度比(risk ratio)，因爲我們獲得的只有在病例組，和對照組中暴露和非暴露的百分比 (we only have probabilities of exposure in disease categories)。</p>
</div>
<div id="橫斷面研究設計時的貝葉斯模型" class="section level2">
<h2><span class="header-section-number">106.3</span> 橫斷面研究設計時的貝葉斯模型</h2>
<p>思考橫斷面研究時，我們的數據是怎樣構成的？</p>
<p>此時我們採集400名實驗對象作爲橫斷面研究的樣本，然後在這個樣本中我們觀察他們的癌症患病與否，及吸煙習慣。假設數據是這樣的：</p>
<ul>
<li>25名吸煙者患有癌症；</li>
<li>15名非吸煙者患有癌症；</li>
<li>150名吸煙者無癌症；</li>
<li>剩餘210名非吸煙者無癌症。</li>
</ul>
<p>此時，這四個數據全部都是隨機變量。唯一一個固定不變的數字是總的樣本量 400 名研究對象。我們用 <span class="math inline">\(N_{ij}\)</span> 來標記疾病狀態爲 <span class="math inline">\(i\)</span>，吸煙習慣爲 <span class="math inline">\(j\)</span> 的實驗對象人數。其中 <span class="math inline">\(i, j = 0 \text{(absent) or } 1\text{(present)}\)</span>，那麼此時我們的數據就是 <span class="math inline">\(N=[N_{11}, N_{10}, N_{01}, N_{00}] = [25, 15, 150, 210]\)</span>。</p>
<p>這四個數字是隨機，但不獨立的，因爲它們的總和400是已知的。這時可以想象這四個數字是按照一定的比例，從總體爲 1 的樣本中抽取，其參數分別是 <span class="math inline">\(\theta_{ij}, i, j = 0, 1\)</span>，且滿足 <span class="math inline">\(\sum_{ij}\theta_{ij} = 1\)</span>。滿足這樣實驗設計的數學模型叫做多項式分布 (multinomial distribution)：</p>
<p><span class="math display">\[
N \sim \text{Multinomial}([\theta_{11}, \theta_{10}, \theta_{01}, \theta_{00}], 400)
\]</span></p>
<p>這樣的多項式分布中，我們感興趣的是其多個參數組成的一個互相有關系的向量 <span class="math inline">\(\mathbf{\theta}\)</span>。由於這個向量中的參數之間並非相互獨立，所以我們無法分別一一給予先驗概率分布。（這很容易理解，因爲當某些參數很高時，其餘參數取值就必須是低的）這時候我們需要給整個向量 <span class="math inline">\(\mathbf{\theta}\)</span> 提供一個綜合的先驗概率分布。</p>
<p>能給一個元素都是百分比的向量提供合適先驗概率的合理分布叫做<a href="https://en.wikipedia.org/wiki/Dirichlet_distribution"><strong>狄利克雷 (Dirichlet) 分布</strong></a>。狄利克雷分布可以被認爲是 Beta 分布的多維擴展分布(multi-dimensional generalization of the beta distribution)。它是易於參數化(parameterize)的一個很靈活的分布，其組成元素就是一個由正數組成的向量 (a positive numbers)：</p>
<p><span class="math display">\[
\mathbf{\theta} \sim \text{Dirichlet}(\alpha_1, \alpha_2, \dots. \alpha_k) \text{ where } \alpha_i &gt;0, \text{ and we denote } \sum_{i = 1}^k \alpha_i = \alpha
\]</span></p>
<p>一個滿足狄利克雷分布的向量，它有如下的特徵：</p>
<ol style="list-style-type: decimal">
<li>狄利克雷分布中的任意一個分類的(category)邊際先驗概率分布(marginal prior distribution)是一個Beta分布：<span class="math inline">\(\theta_i \sim \text{Beta}(\alpha_i, \alpha - \alpha_i)\)</span>；</li>
<li>狄利克雷分布中的任意一個分類的參數 <span class="math inline">\(\theta_i\)</span> 的均值（期望）是：<span class="math inline">\(E(\theta_i) = \frac{\alpha_i}{\alpha}\)</span>；</li>
<li>狄利克雷分布中的任意一個分類的參數 <span class="math inline">\(\theta_i\)</span> 的方差是：<span class="math inline">\(V(\theta_i) = \frac{E(\theta_i)(1-E(\theta_i))}{\alpha + 1}\)</span></li>
</ol>
<p>另外有意思的一個特點是，當一個狄利克雷分布的所有元素 <span class="math inline">\(\alpha_i\)</span> 同時乘以一個正數 <span class="math inline">\(w\)</span> (positive number)，產生的新的狄利克雷分布中的每個元素的參數均值（期望）與之前的狄利克雷分布均值相同，但是方差約等於之前狄利克雷分布元素的參數方差除以 <span class="math inline">\(w\)</span>。利用這個性質，我們可以認爲 <span class="math inline">\(\alpha\)</span> 相當於樣本量大小：</p>
<ul>
<li>狄利克雷分布<span class="math inline">\(\text{Dirichlet}(1,2,1)\)</span>，其實是樣本量爲<span class="math inline">\(\alpha = 4\)</span>，均值是 <span class="math inline">\(\text{Means}[0.25, 0.5, 0.25]\)</span>的分布；</li>
<li>狄利克雷分布<span class="math inline">\(\text{Dirichlet}(1,2,1)\)</span>，其實是樣本量爲<span class="math inline">\(\alpha = 40\)</span>，均值也是<span class="math inline">\(\text{Means}[0.25, 0.5, 0.25]\)</span>的分布。</li>
</ul>
<p>利用狄利克雷分布作爲橫斷面研究設計的先驗概率分布，我們把本節的實驗設計用BUGS語言總結出它的合適的模型：</p>
<pre><code>model{
    N[1:4] ~ dmulti(p[], S)  # data model for sample
    p[1:4] ~ ddirch(alpha[]) # Dirichlet prior for vector of probabilities
    
    # Computation of comparison statistics: 
    px0 &lt;- p[2] + p[4]       # proportion of non-exposed
    px1 &lt;- 1 - px0           # proportion of exposed 
    r0 &lt;- p[2] / px0         # risk in the non-exposed
    r1 &lt;- p[1] / px1         # risk in the exposed
    rr &lt;- r1 / r0            # risk ratio, RR
    rd &lt;- r1 - r0            # risk difference, RD
    or &lt;- (p[1]*p[4]) / (p[2]*p[3])   # odds ratio, OR
    p.crit &lt;- step(or - 1)   # =1 if or &gt;= 1, 0 otherwise
    
    # calculate the total sample size
    S &lt;- sum(N[])
}</code></pre>
<p>這個模型的數據文件則應該寫作：</p>
<div class="sourceCode" id="cb1501"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1501-1" title="1"><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">15</span>, <span class="dv">150</span>, <span class="dv">210</span>), </a>
<a class="sourceLine" id="cb1501-2" title="2">     <span class="dt">alpha =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)) <span class="co"># uniform prior for p_ij</span></a></code></pre></div>
<p>模型的最後一行我們定義了總樣本量，且我們在橫斷面研究的實驗設計下，可以同時計算危險度差，危險度比，以及比值比等指標。另外我們還利用方便的<code>step</code>命令計算比值比大於1的概率。和其他任何一個貝葉斯模型一樣，我們需要給模型中的未知參數 <code>p[1:4]</code> 合理且分散的起始值 (initial values)。</p>
<p>這個模型的結果展示如下：</p>
<pre><code>Iterations = 1001:26000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 25000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean       SD  Naive SE Time-series SE
deviance 18.81623 2.453005 1.097e-02      1.105e-02
or        2.43862 0.861082 3.851e-03      3.886e-03
p[1]      0.06436 0.012207 5.459e-05      5.459e-05
p[2]      0.03959 0.009694 4.335e-05      4.335e-05
p[3]      0.37378 0.024005 1.074e-04      1.078e-04
p[4]      0.52227 0.024829 1.110e-04      1.110e-04
p.crit    0.99372 0.078998 3.533e-04      3.630e-04
r0        0.07046 0.016980 7.594e-05      7.593e-05
r1        0.14689 0.026570 1.188e-04      1.188e-04
rd        0.07643 0.031454 1.407e-04      1.407e-04
rr        2.21362 0.703480 3.146e-03      3.172e-03

2. Quantiles for each variable:

             2.5%      25%      50%      75%    97.5%
deviance 16.04000 17.02000 18.19000 19.92000 25.11000
or        1.18700  1.83300  2.29700  2.88600  4.52103
p[1]      0.04272  0.05571  0.06368  0.07215  0.09039
p[2]      0.02285  0.03268  0.03880  0.04563  0.06050
p[3]      0.32720  0.35750  0.37360  0.38980  0.42150
p[4]      0.47350  0.50560  0.52240  0.53890  0.57060
p.crit    1.00000  1.00000  1.00000  1.00000  1.00000
r0        0.04094  0.05839  0.06914  0.08114  0.10730
r1        0.09882  0.12820  0.14570  0.16410  0.20270
rd        0.01569  0.05514  0.07586  0.09718  0.13970
rr        1.16700  1.71900  2.10500  2.58700  3.90200</code></pre>
<p>可以看到，所有的監測指標的95%可信區間的下限都超過了零假設值 (null value)。且 OR 大於1的概率超過99%，由於我們使用的是無實際信息的先驗概率分布，所以這個分析結果是十分接近概率論模型的結果的。</p>
<p>假如我們現在有充分的理由相信，在本次研究對象中無癌症的對象中的吸煙者的百分比是被嚴重低估的，且我們有充足的理由認爲，這些人中有大約60%其實是吸煙者，但是對於癌症患者中吸煙者的百分比我們沒有太多的概念。那麼這樣的知識可以被翻譯到先驗概率分布的超參數裏面去：<code>alpha = c(1,1,600,400)</code></p>
<p>這時候結果變成了下面這樣：</p>
<pre><code>Iterations = 1001:26000
Thinning interval = 1 
Number of chains = 2 
Sample size per chain = 25000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean       SD Naive SE Time-series SE
deviance 86.75869 10.43878 4.67e-02       4.67e-02
or        1.41233  0.48014 2.15e-03       2.15e-03
p[1]      0.01854  0.00361 1.61e-05       1.61e-05
p[2]      0.01141  0.00283 1.27e-05       1.28e-05
p[3]      0.53491  0.01330 5.95e-05       5.92e-05
p[4]      0.43514  0.01325 5.93e-05       5.96e-05
p.crit    0.81588  0.38759 1.73e-03       1.74e-03
r0        0.02554  0.00630 2.82e-05       2.86e-05
r1        0.03350  0.00646 2.89e-05       2.89e-05
rd        0.00796  0.00901 4.03e-05       4.03e-05
rr        1.39672  0.46134 2.06e-03       2.06e-03

2. Quantiles for each variable:

             2.5%      25%      50%     75%    97.5%
deviance 67.64000 79.50000 86.26000 93.5700 108.5000
or        0.70919  1.07600  1.33600  1.6600   2.5680
p[1]      0.01216  0.01598  0.01833  0.0208   0.0262
p[2]      0.00654  0.00940  0.01118  0.0132   0.0176
p[3]      0.50880  0.52600  0.53480  0.5439   0.5611
p[4]      0.40930  0.42620  0.43510  0.4440   0.4613
p.crit    0.00000  1.00000  1.00000  1.0000   1.0000
r0        0.01473  0.02106  0.02504  0.0294   0.0393
r1        0.02205  0.02894  0.03313  0.0376   0.0472
rd       -0.01009  0.00205  0.00804  0.0140   0.0255
rr        0.71649  1.07400  1.32400  1.6360   2.5040</code></pre>
<p>這時候我們通過先驗概率分布給模型中加入和較大的信息量，事實上，我們加入的先驗概率代表的“樣本量”：<code>alpha = c(1,1,600,400)</code>，甚至比本次試驗本身的數據樣本量還要大。這時候各項指標 OR, RD, RR 的95%可信區間下限都包含了零假設值 (Null value)。甚至於此時OR大於1的概率已經降到了只有82%左右。</p>
</div>
<div id="把不同實驗設計的數據用貝葉斯模型連接起來" class="section level2">
<h2><span class="header-section-number">106.4</span> 把不同實驗設計的數據用貝葉斯模型連接起來</h2>
<p>通過使用不同的先驗概率分布，我們可以有效地利用實驗數據收集之前已經有的關於相似，或者相同實驗的重要結果（而不是僅僅做相互比較和討論）。比方說，我們計算獲得的某個模型某次實驗數據之後獲得的參數的事後概率分佈可以用作下一次類似研究時需要使用的先驗概率分佈信息。另外一種提高數據利用率的方法是，我們通過兩個試驗(可以是設計相同也可以是設計不同，但是討論相同研究問題的試驗)的共同參數把兩次甚至多次試驗的模型連接起來，如此既能提高事後概率分佈估計的精確度，也提高了數據的合理利用率。</p>
<div id="linking-sub-models-throug-common-parameters" class="section level3">
<h3><span class="header-section-number">106.4.1</span> Linking sub-models throug common parameters</h3>
<p>在本章節的語境下，我們假設對一個相同的疾病結果<span class="math inline">\((Y)\)</span>，和相同的暴露因素<span class="math inline">\((X)\)</span>之間的關係做了兩次不同的研究。數據分別收集自一個隊列研究，和一個病例對照研究。</p>
<p>對於隊列研究來說，我們用 <span class="math inline">\(X0c, X1c\)</span> 分別標記非暴露組，及暴露組的總觀察人數；用 <span class="math inline">\(Y0c, Y1c\)</span> 分別標記非暴露組和暴露組的新發病例人數。那麼和這個隊列研究數據分析相匹配的貝葉斯模型的 BUGS 代碼是：</p>
<pre><code>model{
    # Data model for unexposed group 
    Y0c ~ dbin(r0, X0c) 
    logit(r0) &lt;- lr0 
    
    # Data model for exposed group 
    Y1c ~ dbin(r1, X1c)
    logit(r1) &lt;- lr1 
    
    # lor is log(OR)
    lr1 &lt;- lr0 + lor
    
    # Prior for logit of unexposed risk 
    lr0 ~ dnorm(0, 0.3) 
    # Prior for log(OR) 
    lor ~ dnorm(0, 0.33)
}</code></pre>
<p>該模型也可以用 DAG 有向無環圖 (<a href="#fig:DAG0601">106.1</a>) 來表示：</p>
<div class="figure" style="text-align: center"><span id="fig:DAG0601"></span>
<img src="img/DAG6-1.png" alt="DAG for model for data from the cohort study" width="80%" />
<p class="caption">
圖 106.1: DAG for model for data from the cohort study
</p>
</div>
<p>至於病例對照設計的研究數據，用 <span class="math inline">\(Y0cc\)</span> 來標記收集到的病例組人數，<span class="math inline">\(Y1cc\)</span> 來標記收集到的對照組人數。用 <span class="math inline">\(X0cc, X1cc\)</span> 分別標記對照組和病例組中有暴露的人數。那麼此時，該病例對照研究的實驗設計對應的BUGS語言描述的貝葉斯統計學模型可以寫作：</p>
<pre><code>model{
    # Data model for controls 
    X0cc ~ dbin(p0, Y0cc)
    logit(p0) &lt;- lp0 
    
    # Data model for cases 
    X1cc ~ dbin(p1, Y1cc)
    logit(p1) &lt;- lp1 
    
    # lor is log(OR)
    lp1 &lt;- lp0 + lor
    
    # Prior for logit of probability of exposure for controls 
    lp0 ~ dnorm(0, 0.3)
    # Prior for log(OR)
    lor ~ dnorm(0, 0.33)
}</code></pre>
<p>這個病例對照模型的 DAG 圖可以表示爲：</p>
<div class="figure" style="text-align: center"><span id="fig:DAG0602"></span>
<img src="img/DAG0602.png" alt="DAG for model for data from the case-control study" width="80%" />
<p class="caption">
圖 106.2: DAG for model for data from the case-control study
</p>
</div>
<p>從這兩個DAG圖我們也能一眼看出，這兩個模型裏面有一個共同的未知參數 <code>lor</code>。就是這個共同的參數可以讓我們把兩個模型連在一起，提高數據的利用效率。現在，我們把這兩個模型通過共同參數連起來的模型的DAG圖繪製出來：</p>
<div class="figure" style="text-align: center"><span id="fig:DAG0603"></span>
<img src="img/DAG0603.png" alt="DAG for JOINT model for data from the cohort study and the case-control study combined through log(OR)" width="80%" />
<p class="caption">
圖 106.3: DAG for JOINT model for data from the cohort study and the case-control study combined through log(OR)
</p>
</div>
<p>此時，對應 DAG 圖 <a href="#fig:DAG0603">106.3</a> 的合併模型的聯合模型，其BUGS語言描述的貝葉斯模型如下：</p>
<pre><code>model{
# Cohort sub-model
   # Data model for unexposed group 
    Y0c ~ dbin(r0, X0c) 
    logit(r0) &lt;- lr0 
    
    # Data model for exposed group 
    Y1c ~ dbin(r1, X1c)
    logit(r1) &lt;- lr1 
    
    # lor is log(OR)
    lr1 &lt;- lr0 + lor
    
    # Prior for logit of unexposed risk 
    lr0 ~ dnorm(0, 0.3) 
# Case-control sub-model     
   # Data model for controls 
    X0cc ~ dbin(p0, Y0cc)
    logit(p0) &lt;- lp0 
    
    # Data model for cases 
    X1cc ~ dbin(p1, Y1cc)
    logit(p1) &lt;- lp1 
    
    # lor is log(OR)
    lp1 &lt;- lp0 + lor
    
    # Prior for logit of probability of exposure for controls 
    lp0 ~ dnorm(0, 0.3)
    
# Prior for common log(OR)
    lor ~ dnorm(0, 0.33)
}</code></pre>
<p>其實，通過類似的辦法，你可以把無數多個研究，無論它們是相似的或者不同的實驗設計，只要你能找到它們有共同的未知參數，就可以通過貝葉斯模型連接起來，成爲一個首尾相接，數據聯通的大模型。這真是一件在概率論模型下永遠也無法做到的神奇的事情！</p>
</div>
</div>
<div id="practical-bayesian-statistics-06" class="section level2">
<h2><span class="header-section-number">106.5</span> Practical Bayesian Statistics 06</h2>
<div id="the-great-trial" class="section level3">
<h3><span class="header-section-number">106.5.1</span> The GREAT Trial</h3>
<p>在第一個章節，貝葉斯入門和回顧基礎知識的時候，我們介紹過GREAT臨牀試驗，這是一個雙盲對照試驗。比較阿尼普酶，一種血栓溶解藥物的兩種治療方案：</p>
<ul>
<li>治療組：當患者被家庭醫生 (General Practitioners) 發現心肌梗塞時(myocardial infarctin, MI)，在家中立刻給予阿尼普酶藥物，等到患者被救護車帶到醫院以後給患者服用安慰劑。</li>
<li>對照組：同樣情況下，家庭醫生在家中發現患者有心肌梗塞時先不給予藥物治療，而是先讓患者服用安慰劑，等救護車帶患者抵達醫院之後再讓患者服用真正的阿尼普酶藥物。</li>
</ul>
<p>這項試驗的主要觀察結果 (primary outcome) 是30天死亡率。</p>
<p>該項試驗獲得的觀察數據如下：</p>
<ul>
<li>治療組163人，13例死亡；</li>
<li>對照組148人，23例死亡。</li>
</ul>
<p>利用這個簡單的臨牀試驗設定，我們來實際的體驗一下，不同的先驗概率分佈對貝葉斯分析結果的影響。</p>
<p>我們用BUGS語言先描述一下這個模型的設定：</p>
<pre><code>model {
    for (i in 1:2) {
        deaths[i] ~ dbin(p[i],n[i])
        logit(p[i]) &lt;- alpha + beta*treat[i]
    }
    alpha ~ dunif(-100,100)
    beta ~ dunif(-100,100)
    OR &lt;- exp(beta)
}</code></pre>
<p>其中，</p>
<pre><code>treat[i] 是一個指示变量 (indicator variable)，i = 1 時表示對照組，i = 0 時表示治療組；
death[i] 是第 i 組對象的死亡病例數；
n[i]     是第 i 組對象的總人數；
p[i]     是第 i 組試驗組患者死亡的概率。</code></pre>
<ul>
<li>解釋上面模型語句中 <code>alpha, beta</code> 的含義是什麼。</li>
</ul>
<p><code>alpha</code> 是治療組的對數比值 (log odds for the treatment arm) <br>
<code>beta</code> 是對照組和治療組相比較的死亡比值比 (log odds ratio of death in the control arm compared to the treatment arm)，當 <code>beta</code> 大於1時，說明對照組死亡比值高，結果對治療組有利。</p>
<ul>
<li>用兩組起始值文件來跑這個貝葉斯模型。</li>
</ul>
<div class="sourceCode" id="cb1509"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1509-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1509-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model1.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1509-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1509-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1509-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1509-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1509-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1509-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1509-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">beta =</span> <span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb1509-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1509-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">-1</span>, <span class="dt">beta =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1509-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1509-13" title="13"></a>
<a class="sourceLine" id="cb1509-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1509-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1509-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1509-17" title="17"></a>
<a class="sourceLine" id="cb1509-18" title="18"></a>
<a class="sourceLine" id="cb1509-19" title="19"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1509-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1509-21" title="21"></a>
<a class="sourceLine" id="cb1509-22" title="22"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1509-23" title="23"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0601"></span>
<img src="bookdown_files/figure-html/BayesianPractical0601-1.png" alt="History plots for iterations 1-1000 for the GREAT trial." width="80%" />
<p class="caption">
圖 106.4: History plots for iterations 1-1000 for the GREAT trial.
</p>
</div>
<div class="sourceCode" id="cb1510"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1510-1" title="1">postsamples &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(<span class="st">&quot;*&quot;</span>)</a>
<a class="sourceLine" id="cb1510-2" title="2"><span class="kw">gelman.diag</span>(postsamples)</a></code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##       Point est. Upper C.I.
## OR          1.01       1.03
## alpha       1.01       1.06
## beta        1.01       1.04
## p[1]        1.02       1.08
## p[2]        1.00       1.00
## 
## Multivariate psrf
## 
## 1.01</code></pre>
<div class="sourceCode" id="cb1512"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1512-1" title="1"><span class="kw">gelman.plot</span>(postsamples)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0603"></span>
<img src="bookdown_files/figure-html/BayesianPractical0603-1.png" alt="Gelman-Rubin convergence statistic for the GREAT trial." width="80%" />
<p class="caption">
圖 106.5: Gelman-Rubin convergence statistic for the GREAT trial.
</p>
</div>
<p>你會發現這個模型很快就能達到收斂，所以，我們選擇刨除前1000次採樣能夠滿足要求，我們另外再進行每條 MCMC 鏈各 25000 次樣本採集：</p>
<ul>
<li>記錄這時候我們獲得的比值比 OR，迴歸係數，及兩組實驗組的事後死亡概率。</li>
</ul>
<div class="sourceCode" id="cb1513"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1513-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1513-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1515"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1515-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1515-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1515-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##           mean      sd  MC_error val2.5pc   median val97.5pc start sample
## OR     2.31600 0.92180 0.0089740  1.06100  2.14400    4.5740  1001  50000
## alpha -2.48000 0.29400 0.0028080 -3.09800 -2.46500   -1.9410  1001  50000
## beta   0.76930 0.37200 0.0035940  0.05961  0.76250    1.5200  1001  50000
## p[1]   0.07982 0.02104 0.0001969  0.04321  0.07837    0.1255  1001  50000
## p[2]   0.15540 0.02958 0.0001403  0.10200  0.15370    0.2182  1001  50000</code></pre>
<ul>
<li>現在我們把先驗概率分佈修改成：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\alpha &amp; \sim \text{Logistic}(0,1) \\
\beta  &amp; \sim \text{Normal}(0, 0.33)\; 0.33 \text{ is the precision}\\ 
\end{aligned}
\]</span></p>
<p>其中，邏輯分佈方程的BUGS語言是 <code>dlogis</code>；這個先驗概率給予 <code>beta</code> 的指定信息是基於想要給它一個沒有太多信息量的先驗概率分佈，其中對數比值比(log odds ratio)服從均值爲 0, 精確度(precision)爲 0.33 的正態分佈時，其對應的比值比 (odds ratio) 的95%則分佈在 1/30 至 30 之間。<span class="math inline">\((\text{sd} = \frac{\log30 - \log(1/30)}{2*1.96}) = 1.735 \rightarrow \tau^2 = (1/1.735)^2 \approx 0.33\)</span>。</p>
<p>用相似的過程試着跑完這個貝葉斯模型：</p>
<div class="sourceCode" id="cb1517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1517-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1517-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model1_alt.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1519"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1519-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1519-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1521-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1521-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1523"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1523-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1523-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1523-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">beta =</span> <span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb1523-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1526"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1526-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">-1</span>, <span class="dt">beta =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1526-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1529"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1529-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1529-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1529-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR&#39;</code></pre>
<pre><code>## monitor set for variable &#39;alpha&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta&#39;</code></pre>
<pre><code>## monitor set for variable &#39;p&#39;</code></pre>
<div class="sourceCode" id="cb1534"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1534-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1534-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0606"></span>
<img src="bookdown_files/figure-html/BayesianPractical0606-1.png" alt="History plots for iterations 1-1000 for the GREAT trial with alternative priors for alpha and beta." width="80%" />
<p class="caption">
圖 106.6: History plots for iterations 1-1000 for the GREAT trial with alternative priors for alpha and beta.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##       Point est. Upper C.I.
## OR         1.002      1.005
## alpha      1.005      1.008
## beta       1.000      1.003
## p[1]       1.016      1.023
## p[2]       0.999      0.999
## 
## Multivariate psrf
## 
## 1.01</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0607"></span>
<img src="bookdown_files/figure-html/BayesianPractical0607-1.png" alt="Gelman-Rubin convergence statistic for the GREAT trial with alternative priors for alpha and beta." width="80%" />
<p class="caption">
圖 106.7: Gelman-Rubin convergence statistic for the GREAT trial with alternative priors for alpha and beta.
</p>
</div>
<div class="sourceCode" id="cb1537"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1537-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1537-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1539"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1539-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1539-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1539-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##          mean      sd  MC_error val2.5pc   median val97.5pc start sample
## OR     2.0710 0.77560 0.0102800  0.97510  1.93600    3.9790  1001  50000
## alpha -2.3860 0.27890 0.0043500 -2.96700 -2.37600   -1.8720  1001  50000
## beta   0.6639 0.35670 0.0047540 -0.02521  0.66040    1.3810  1001  50000
## p[1]   0.0867 0.02167 0.0003371  0.04892  0.08504    0.1333  1001  50000
## p[2]   0.1539 0.02925 0.0001229  0.10130  0.15250    0.2151  1001  50000</code></pre>
<ul>
<li>對改變了先驗概率前後的貝葉斯分析結果，你有什麼看法？</li>
</ul>
<p>我們發現改變先驗概率前的模型得到的事後比值比的結果有更大的均值，及更不穩定的估計(較高的事後樣本標準差，及較寬的事後樣本95%可信區間)。</p>
<ul>
<li>爲了分析改變先驗概率分佈前後到底哪種給予了模型更多的信息，我們可以把兩個模型改寫成不含數據，只有預測模型的語句，從而可以看到只有先驗概率分佈時的結果是怎樣的。這時候我們把數據加載這一步省略掉，然後對 <code>alpha, beta, p</code> 進行軌跡檢測，繪製他們的預測分佈密度曲線。</li>
</ul>
<div class="sourceCode" id="cb1541"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1541-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1541-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model1_forward.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1541-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1541-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-forward.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1541-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1541-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1541-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1541-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1541-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">beta =</span> <span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb1541-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1541-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">-1</span>, <span class="dt">beta =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1541-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1541-13" title="13"></a>
<a class="sourceLine" id="cb1541-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1541-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1541-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1541-17" title="17"></a>
<a class="sourceLine" id="cb1541-18" title="18"></a>
<a class="sourceLine" id="cb1541-19" title="19"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1541-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a>
<a class="sourceLine" id="cb1541-21" title="21"></a>
<a class="sourceLine" id="cb1541-22" title="22"></a>
<a class="sourceLine" id="cb1541-23" title="23"><span class="co"># Density plot </span></a>
<a class="sourceLine" id="cb1541-24" title="24"><span class="kw">samplesDensity</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0609"></span>
<img src="bookdown_files/figure-html/BayesianPractical0609-1.png" alt="Density plots for parameters prediction in GREAT trial first prior." width="80%" />
<p class="caption">
圖 106.8: Density plots for parameters prediction in GREAT trial first prior.
</p>
</div>
<p>對於這個模型來說，儘管我們給兩個邏輯迴歸的參數 <code>alpha, beta</code> 兩個“沒有信息”的均一分佈 (uniform distribution) 作爲先驗概率分佈，但是事實上，從 <code>p[1], p[2]</code> 的預測概率密度分佈圖來看，其實我們不經意竟然告訴模型另外的信息：就是我們認爲這兩組患者中死亡率要麼很高，接近1，要麼很低很低，接近於0。所以，我們自認爲給了模型無信息的先驗概率分佈，但是事實上卻給了模型大量的信息。</p>
<div class="sourceCode" id="cb1542"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1542-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1542-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model1_altforward.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1542-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1542-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-forward.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1542-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1542-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1542-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1542-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1542-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">beta =</span> <span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb1542-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1542-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">-1</span>, <span class="dt">beta =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1542-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1542-13" title="13"></a>
<a class="sourceLine" id="cb1542-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1542-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1542-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1542-17" title="17"></a>
<a class="sourceLine" id="cb1542-18" title="18"></a>
<a class="sourceLine" id="cb1542-19" title="19"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1542-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a>
<a class="sourceLine" id="cb1542-21" title="21"></a>
<a class="sourceLine" id="cb1542-22" title="22"></a>
<a class="sourceLine" id="cb1542-23" title="23"><span class="co"># Density plot </span></a>
<a class="sourceLine" id="cb1542-24" title="24"><span class="kw">samplesDensity</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0610"></span>
<img src="bookdown_files/figure-html/BayesianPractical0610-1.png" alt="Density plots for parameters prediction in GREAT trial second prior." width="80%" />
<p class="caption">
圖 106.9: Density plots for parameters prediction in GREAT trial second prior.
</p>
</div>
<p>第二次修改過後的先驗概率明顯就安全得多了。因爲我們看到兩組的死亡概率基本可以認爲不再像前一個模型那樣含有太多不實際的信息。</p>
<ol start="2" style="list-style-type: decimal">
<li>作爲替代方案，我們可以把上述模型重新用對數比值比(Log odds ratio, LOR)作爲未知參數來重新建模：</li>
</ol>
<p><span class="math display">\[
LOR = \log(\frac{p[1]/(1 - p[1])}{p[2]/(1 - p[2])}) = \text{logit}(p[1]) - \text{logit}(p[2]) 
\]</span></p>
<p>這時候我們需要給 <code>p[2], LOR</code> 賦予先驗概率分布：</p>
<pre><code>model {
    for (i in 1:2) {
        deaths[i] ~ dbin(p[i],n[i])     
    }
    logit(p[1]) &lt;- logit(p[2]) + LOR
    p[2] ~ dbeta(1,1) 
    LOR ~ dnorm(0,0.33) 
    OR &lt;- exp(LOR)
}</code></pre>
<ul>
<li>再看一遍上面寫好的模型，確定你能夠理解其含義，請確認先驗概率分布的實際意義。</li>
</ul>
<p>注意我們用beta 分布來描述 <code>p[2]</code> 的先驗概率分布。</p>
<div class="sourceCode" id="cb1544"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1544-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1544-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model2.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1546-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1546-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-data-alt.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1548-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1548-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1550"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1550-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1550-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1550-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">LOR =</span> <span class="fl">0.5</span>, <span class="dt">p =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.2</span>))</a>
<a class="sourceLine" id="cb1550-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1553"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1553-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">LOR =</span> <span class="dv">5</span>, <span class="dt">p =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.8</span>))</a>
<a class="sourceLine" id="cb1553-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1556-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1556-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1556-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR&#39;</code></pre>
<pre><code>## monitor set for variable &#39;p&#39;</code></pre>
<div class="sourceCode" id="cb1559"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1559-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1559-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a></code></pre></div>
<pre><code>## 26000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1561"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1561-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1561-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1561-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##        mean      sd  MC_error val2.5pc  median val97.5pc start sample
## OR   2.0790 0.77960 0.0073820  0.97320 1.94300    3.9890  1001  50000
## p[1] 0.1539 0.02947 0.0001353  0.10060 0.15230    0.2162  1001  50000
## p[2] 0.0864 0.02153 0.0001985  0.04896 0.08474    0.1331  1001  50000</code></pre>
<ul>
<li>修改模型的代碼使之用於向前採集樣本用於預測：</li>
</ul>
<pre><code>model {
#   for (i in 1:2) {
#       deaths[i] ~ dbin(p[i],n[i])     
#   }
    logit(p[1]) &lt;- logit(p[2]) + LOR
    p[2] ~ dbeta(1,1) 
    LOR ~ dnorm(0,0.33) 
    OR &lt;- exp(LOR)
}</code></pre>
<div class="sourceCode" id="cb1564"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1564-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1564-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/great-model2_forward.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1566-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1566-2" title="2"><span class="co"># modelData(paste(bugpath, &quot;backupfiles/great-forward.txt&quot;, sep = &quot;&quot;))     </span></a>
<a class="sourceLine" id="cb1566-3" title="3"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1566-4" title="4"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1568-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1568-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1568-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">LOR =</span> <span class="fl">0.5</span>, <span class="dt">p =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.2</span>))</a>
<a class="sourceLine" id="cb1568-4" title="4"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1571"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1571-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">LOR =</span> <span class="dv">5</span>, <span class="dt">p =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.8</span>))</a>
<a class="sourceLine" id="cb1571-2" title="2"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1574-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1574-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb1574-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR&#39;</code></pre>
<pre><code>## monitor set for variable &#39;p&#39;</code></pre>
<div class="sourceCode" id="cb1577"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1577-1" title="1"><span class="co"># Generate 10000 iterations</span></a>
<a class="sourceLine" id="cb1577-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">26000</span>)</a></code></pre></div>
<pre><code>## 26000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1579"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1579-1" title="1"><span class="co"># Density plot the first 1000 run </span></a>
<a class="sourceLine" id="cb1579-2" title="2"><span class="kw">samplesDensity</span>(<span class="st">&quot;p&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0612"></span>
<img src="bookdown_files/figure-html/BayesianPractical0612-1.png" alt="Density plots for parameters prediction in GREAT trial second prior." width="80%" />
<p class="caption">
圖 106.10: Density plots for parameters prediction in GREAT trial second prior.
</p>
</div>
<p>這時候先驗概率分布給出的兩組死亡率的密度分布和之前提出的第二個模型沒有什麼兩樣。</p>
</div>
<div id="吸煙與癌症" class="section level3">
<h3><span class="header-section-number">106.5.2</span> 吸煙與癌症</h3>
<p>在這道題中，你將練習自己使用和描述一個隊列研究設計，及一個病例對照研究設計的貝葉斯模型，同時學習如何把兩個試驗的數據和模型通過共同的未知參數連接起來。在整道題目中，癌症作爲發病結果 (disease of interest)，吸煙作爲暴露因素 (exposure of interest)。</p>
<div id="隊列研究設計" class="section level4">
<h4><span class="header-section-number">106.5.2.1</span> 隊列研究設計</h4>
<p>在一個隊列研究中，2000名非吸煙者，和1000名吸煙者被跟蹤隨訪20年。在非吸煙者中和非吸煙者中分別觀察到100例，及150例新發生的癌症患者。我們關心的是和非吸煙者相比，吸煙者患癌症的比值比是多少。這個實驗的貝葉斯模型可以寫作：</p>
<pre><code>model{ 
    # Data model for non-smokers   
    Y0c ~ dbin(r0, X0c) 
    logit(r0) &lt;- lr0
            
     # Data model for smokers
     Y1c ~ dbin(r1, X1c) 
     logit(r1) &lt;- lr1  
            
    lr1 &lt;- lr0 + lor   # lor is log(OR)
    OR &lt;- exp(lor)  # comparison statistic
            
    # Priors
    lr0 ~ dnorm(0, 0.3)  # priors for logit of non-smokers  
    lor ~ dnorm(0, 0.33)  # prior for log(OR)
}


# Y0c number of non-smokers developed cancer  
# X0c number of nonpsmokers 
# Y1c number of smokers developed cancer 
# X1c number of smokers </code></pre>
<p>數據文件可以寫作：</p>
<pre><code>list(X0c = 2000, 
     Y0c = 100,
     X1c = 1000, 
     Y1c = 150) </code></pre>
<p>未知參數 <code>lor, lr0</code> 的起始值可以選定爲：</p>
<pre><code>list(lr0 = -1, lor = 0)
list(lr0 = -5, lor = 5)</code></pre>
<p>對這麼模型進行50000次事後樣本採集，獲取比值比 OR 的事後概率分布描述：</p>
<div class="sourceCode" id="cb1583"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1583-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1583-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/cohort-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1583-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1583-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/dataforcohort.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1583-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1583-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1583-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1583-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1583-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lr0 =</span> <span class="dv">-1</span>, <span class="dt">lor =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1583-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1583-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lr0 =</span> <span class="dv">-5</span>, <span class="dt">lor =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1583-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1583-13" title="13"></a>
<a class="sourceLine" id="cb1583-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1583-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;lor&quot;</span>)</a>
<a class="sourceLine" id="cb1583-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1583-17" title="17"></a>
<a class="sourceLine" id="cb1583-18" title="18"></a>
<a class="sourceLine" id="cb1583-19" title="19"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1583-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1583-21" title="21"></a>
<a class="sourceLine" id="cb1583-22" title="22"></a>
<a class="sourceLine" id="cb1583-23" title="23"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1583-24" title="24"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0613"></span>
<img src="bookdown_files/figure-html/BayesianPractical0613-1.png" alt="Density plots for parameters prediction in smoking and cancer cohort study." width="80%" />
<p class="caption">
圖 106.11: Density plots for parameters prediction in smoking and cancer cohort study.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##     Point est. Upper C.I.
## OR       0.999      0.999
## lor      0.999      0.999
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0614"></span>
<img src="bookdown_files/figure-html/BayesianPractical0614-1.png" alt="Gelman-Rubin convergence statistic for smoking and cancer cohort study." width="80%" />
<p class="caption">
圖 106.12: Gelman-Rubin convergence statistic for smoking and cancer cohort study.
</p>
</div>
<div class="sourceCode" id="cb1585"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1585-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1585-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1587"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1587-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1587-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1587-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##      mean     sd MC_error val2.5pc median val97.5pc start sample
## OR  3.335 0.4513 0.003901   2.5360  3.304     4.302  1001  50000
## lor 1.195 0.1347 0.001163   0.9306  1.195     1.459  1001  50000</code></pre>
</div>
<div id="病例對照研究設計下的模型" class="section level4">
<h4><span class="header-section-number">106.5.2.2</span> 病例對照研究設計下的模型</h4>
<p>在病例對照研究設計下，研究者收集了1000名癌症患者(病例組)，和2000名對照組志願者。研究者對這兩組研究對象分別調查了他們各自過去20年的吸煙史，發現：</p>
<ul>
<li>病例組中600人過去20年中有過吸煙史；</li>
<li>對照組中800人過去20年中有過吸煙史。</li>
</ul>
<p>同樣地，我們關心的是兩組之間吸煙習慣的比值比 (Odds ratio)。這個實驗設計的模型可以用BUGS語言寫作(保存爲<code>case-control-model.txt</code>)：</p>
<pre><code>model{ 
    # Data model for non-cancer controls   
    X0cc ~ dbin(p0, Y0cc) 
    logit(p0) &lt;- lp0
            
    # Data model for cancer cases   
     X1cc ~ dbin(p1, Y1cc) 
    logit(p1) &lt;- lp1  
    
    lp1 &lt;- lp0 + lor # lor is log(OR)
    OR &lt;- exp(lor)  # comparison statistic
            
     # Priors
     lp0 ~ dnorm(0, 0.3)  # prior for logit of probability of exposure for controls                 
     lor ~ dnorm(0, 0.33) # prior for log(OR)
    }
    
    
    # X0cc indicates number of smokers among controls (without cancer)
    # Y0cc indicates number of controls 
    # X1cc is the number of smokers among cancer cases 
    # Y1cc is the number of cancer cases </code></pre>
<p>其中，</p>
<ul>
<li><code>X0cc</code> 表示對照組中有吸煙史的人數；</li>
<li><code>Y0cc</code> 表示對照組的總人數；</li>
<li><code>X1cc</code> 表示癌症患者組中有吸煙史的人數；</li>
<li><code>Y1cc</code> 表示癌症患者組的總人數。</li>
</ul>
<p>數據文件可以描述爲（保存爲<code>dataforcasecontrol.txt</code>）：</p>
<pre><code>list(X0cc = 800, 
     Y0cc = 2000, 
     X1cc = 600, 
     Y1cc = 1000)</code></pre>
<p>模型擬合過程和結果分別羅列如下：</p>
<div class="sourceCode" id="cb1591"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1591-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1591-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/case-control-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1591-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1591-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/dataforcasecontrol.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1591-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1591-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1591-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1591-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1591-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lp0 =</span> <span class="dv">-2</span>, <span class="dt">lor =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1591-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1591-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lp0 =</span> <span class="dv">2</span>, <span class="dt">lor =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1591-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1591-13" title="13"></a>
<a class="sourceLine" id="cb1591-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1591-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;lor&quot;</span>)</a>
<a class="sourceLine" id="cb1591-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1591-17" title="17"></a>
<a class="sourceLine" id="cb1591-18" title="18"></a>
<a class="sourceLine" id="cb1591-19" title="19"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1591-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1591-21" title="21"></a>
<a class="sourceLine" id="cb1591-22" title="22"></a>
<a class="sourceLine" id="cb1591-23" title="23"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1591-24" title="24"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0616"></span>
<img src="bookdown_files/figure-html/BayesianPractical0616-1.png" alt="Density plots for parameters prediction in smoking and cancer case-control study." width="80%" />
<p class="caption">
圖 106.13: Density plots for parameters prediction in smoking and cancer case-control study.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##     Point est. Upper C.I.
## OR           1          1
## lor          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0617"></span>
<img src="bookdown_files/figure-html/BayesianPractical0617-1.png" alt="Gelman-Rubin convergence statistic for smoking and cancer cohort study." width="80%" />
<p class="caption">
圖 106.14: Gelman-Rubin convergence statistic for smoking and cancer cohort study.
</p>
</div>
<div class="sourceCode" id="cb1593"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1593-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1593-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1595"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1595-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1595-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1595-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##       mean      sd  MC_error val2.5pc median val97.5pc start sample
## OR  2.2530 0.17780 0.0011660   1.9260 2.2450    2.6210  1001  50000
## lor 0.8092 0.07875 0.0005161   0.6555 0.8088    0.9636  1001  50000</code></pre>
</div>
<div id="聯合模型-joint-model" class="section level4">
<h4><span class="header-section-number">106.5.2.3</span> 聯合模型 joint model</h4>
<p>把兩個甚至多個不同的研究獲得的數據聯合起來的方法主要有兩種，一是使用其中一個或者多個的研究結果作爲有信息的先驗概率分布，放到之後的研究模型中去，二是把多個不同的研究用共同的位置變量聯通起來 (link sub-models for different data sources through common parameter(s))。在這個吸煙和癌症的研究話題中，我們發現隊列研究，和病例對照研究兩者之間有共同的未知變量-比值比 (OR)，如果這個比值比有這相同的含義，那麼我們可以通過它把兩個獨立的研究連接起來。</p>
<p>我們提供一個聯合模型的例子如下（保存爲<code>jointmodel.txt</code>）：</p>
<pre><code># Joint model

model{
        # cohort sub-model
        Y0c ~ dbin(r0, X0c) # data model for non-smokers
        logit(r0) &lt;- lr0 
        Y1c ~ dbin(r1, X1c) # data model for smokers 
        logit(r1) &lt;- lr1 
        lr1 &lt;- lr0 + lor # lor is log(OR)
        # prior for cohort sub-model
        lr0 ~ dnorm(0, 0.3) # prior for logOdds of nonsmokers 
        
        # case-control sub-model 
        X0cc ~ dbin(p0, Y0cc) # data model for non-cancer controls
        logit(p0) &lt;- lp0
        X1cc ~ dbin(p1, Y1cc) # data model for cancer cases 
        logit(p1) &lt;- lp1
        lp1 &lt;- lp0 + lor # lor is log(OR)
        # prior for case-control sub-model 
        lp0 ~ dnorm(0, 0.3) # prior for logOdds of exposure for controls 
        
        # Common code 
        lor ~ dnorm(0, 0.33) # prior for common log(OR)
        OR &lt;- exp(lor) # comparison statistic
}</code></pre>
<p>把兩個獨立研究的數據合並成爲一個（保存成爲<code>dataforjoint.txt</code>）：</p>
<pre><code>list(X0c  = 2000, 
         Y0c  = 100, 
         X1c  = 1000, 
         Y1c  = 150,
         X0cc = 800, 
         Y0cc = 2000, 
         X1cc = 600,
         Y1cc = 1000
)</code></pre>
<p>接下來是對聯合模型的擬合及對OR值事後樣本的採集過程：</p>
<div class="sourceCode" id="cb1599"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1599-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1599-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/jointmodel.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a>
<a class="sourceLine" id="cb1599-3" title="3"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1599-4" title="4"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/dataforjoint.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a>
<a class="sourceLine" id="cb1599-5" title="5"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1599-6" title="6"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb1599-7" title="7"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1599-8" title="8"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1599-9" title="9">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lr0 =</span> <span class="dv">-1</span>, <span class="dt">lp0 =</span> <span class="dv">-2</span>, <span class="dt">lor =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1599-10" title="10"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a>
<a class="sourceLine" id="cb1599-11" title="11">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">lr0 =</span> <span class="dv">-5</span>, <span class="dt">lp0 =</span> <span class="dv">2</span>, <span class="dt">lor =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1599-12" title="12"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a>
<a class="sourceLine" id="cb1599-13" title="13"></a>
<a class="sourceLine" id="cb1599-14" title="14"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1599-15" title="15">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR&quot;</span>, <span class="st">&quot;lor&quot;</span>)</a>
<a class="sourceLine" id="cb1599-16" title="16"><span class="kw">samplesSet</span>(parameters)</a>
<a class="sourceLine" id="cb1599-17" title="17"></a>
<a class="sourceLine" id="cb1599-18" title="18"></a>
<a class="sourceLine" id="cb1599-19" title="19"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1599-20" title="20"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1599-21" title="21"></a>
<a class="sourceLine" id="cb1599-22" title="22"></a>
<a class="sourceLine" id="cb1599-23" title="23"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1599-24" title="24"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0619"></span>
<img src="bookdown_files/figure-html/BayesianPractical0619-1.png" alt="Density plots for parameters prediction in smoking and cancer joint model." width="80%" />
<p class="caption">
圖 106.15: Density plots for parameters prediction in smoking and cancer joint model.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##     Point est. Upper C.I.
## OR           1          1
## lor          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0620"></span>
<img src="bookdown_files/figure-html/BayesianPractical0620-1.png" alt="Gelman-Rubin convergence statistic for smoking and cancer cohort study." width="80%" />
<p class="caption">
圖 106.16: Gelman-Rubin convergence statistic for smoking and cancer cohort study.
</p>
</div>
<div class="sourceCode" id="cb1601"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1601-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1601-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1603"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1603-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1603-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1603-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##       mean      sd  MC_error val2.5pc median val97.5pc start sample
## OR  2.4930 0.17070 0.0009080   2.1760 2.4870     2.844  1001  50000
## lor 0.9111 0.06842 0.0003648   0.7777 0.9111     1.045  1001  50000</code></pre>
<p>可以看到，聯合模型給出的事後OR均值(2.493)是位於兩個獨立研究給出的OR均值(3.335, 2.253)的中間。但是它明顯更加靠近病例對照研究的結果，暗示我們兩個研究中病例對照研究給出的信息量相對權重較大。另外，事後OR分布的標準差本身比兩個獨立研究估計的事後OR分布標準差都要小，說明充分利用兩個研究的數據時，事後估計的精確度得到了提升。精確度提升的原因很容易理解，因爲聯合模型把二者獲得的數據都包含了進來，信息量比兩個獨立研究都要大。</p>
</div>
<div id="你是否能證明兩個研究的比值比是相同的" class="section level4">
<h4><span class="header-section-number">106.5.2.4</span> 你是否能證明兩個研究的比值比是相同的？</h4>
<p>對於隊列研究來說，我們估計其比值比所用的表格可以寫作：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Cancer</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>Y</td>
<td>N</td>
<td></td>
</tr>
<tr class="even">
<td>Smoking</td>
<td>Y</td>
<td></td>
<td></td>
<td>S</td>
</tr>
<tr class="odd">
<td></td>
<td>N</td>
<td></td>
<td></td>
<td>NS</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>C</td>
<td>NC</td>
<td></td>
</tr>
</tbody>
</table>
<p>那麼這個研究中的比值比計算式就是：</p>
<p><span class="math display">\[
\text{OR}_{\text{cohort}} = \frac{\text{Pr}(C|S)\times\text{Pr}(NC|NS)}{\text{Pr}(C|NS)\times\text{Pr}(NC|S)}
\]</span></p>
<p>對於病例對照研究來說，其比值比估計時使用的表格是：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Smoking</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>Y</td>
<td>N</td>
<td></td>
</tr>
<tr class="even">
<td>Cancer</td>
<td>Y</td>
<td></td>
<td></td>
<td>C</td>
</tr>
<tr class="odd">
<td></td>
<td>N</td>
<td></td>
<td></td>
<td>NC</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>S</td>
<td>NS</td>
<td></td>
</tr>
</tbody>
</table>
<p>其比值比的計算式可以寫作：</p>
<p><span class="math display">\[
\text{OR}_{\text{case-control}} = \frac{\text{Pr}(S|C)\times\text{Pr}(NS|NC)}{\text{Pr}(S|NC)\times\text{Pr}(NS|C)}
\]</span></p>
<p>可以證明兩者相同（反復使用貝葉斯定理）：</p>
<p><span class="math display">\[
\begin{aligned}
\text{OR}_{\text{cohort}} &amp; = \frac{\text{Pr}(C|S)\times\text{Pr}(NC|NS)}{\text{Pr}(C|NS)\times\text{Pr}(NC|S)} \\ 
                          &amp; = \frac{\frac{\text{Pr}(S|C)\text{Pr}(C)}{\text{Pr}(S)}\times\frac{\text{Pr}(NS|NC)\text{Pr}(NC)}{\text{Pr}(NS)}}{\frac{\text{Pr}(NS|C)\text{Pr}(C)}{\text{Pr}(NS)}\times\frac{\text{Pr}(S|NC)\text{Pr}(NC)}{\text{Pr}(S)}} \\
                          &amp; = \frac{\text{Pr}(S|C)\times\text{Pr}(NS|NC)}{\text{Pr}(S|NC)\times\text{Pr}(NS|C)} \\
                          &amp; = \text{OR}_{\text{case-control}} 
\end{aligned}
\]</span></p>
</div>
</div>
</div>
</div>
<div id="貝葉斯廣義線性回歸" class="section level1">
<h1><span class="header-section-number">第 107 章</span> 貝葉斯廣義線性回歸</h1>
<p>第五章(Chapter <a href="#BayesianLM">105.1</a>)中我們已經展示過如何在貝葉斯統計學語境下如何描述和運算簡單線性回歸模型的過程：</p>
<ul>
<li>描述預測變量和結果變量之間應有的關係；</li>
<li>描述結果變量的概率分佈假設 (probability assumptions)：也就是在前一步指定的方程式描述的預測變量和相應的參數的條件下，結果變量的分佈。</li>
<li>給每個回歸係數，以及其他未知的參數提供先驗概率分佈的信息。</li>
</ul>
<p>對於一個結果變量 <span class="math inline">\(y_i\)</span> 來說，如果有一個預測變量的向量 <span class="math inline">\(x_1, \dots, x_p\)</span>，來描述它 <span class="math inline">\(i = 1,\dots, n\)</span> 個個體的話，標準的貝葉斯版本的線性回歸模型要寫作：</p>
<p><span class="math display" id="eq:Bayesianchapter7eq01">\[
\begin{aligned}
y_i &amp; \sim N(\mu_i, \sigma^2) \\ 
\mu_i &amp; = \beta_0 +  \sum_{i = 1}^p\beta_jx_{ji} \\ 
(\beta_0, \beta_1, \dots, \beta_p) &amp; \sim \text{ Prior distributions } \\
\end{aligned}
\tag{107.1}
\]</span></p>
<p>用貝葉斯方法建立回歸模型的優點有很多。首先，你可以方便地對未知的回歸係數等參數加入相關的先驗概率分佈用來表達已有的知識，或者對回歸係數加以合理的限制。其次，你可以從容地對回歸模型的擬合效果，預測能力做出統計學推斷。再加上，使用貝葉斯方法也很容易讓我們把模型擴展到非線性回歸模型，處理並分析缺失值，以及分析共變量的測量誤差等等。</p>
<p>更重要的是，MCMC方法讓我們人類也可以很容易地進行穩健的統計推斷 (robust inference)。例如上面的線性回歸模型中，如果有理由認為誤差服從的是自由度為4的 t 分佈，那就可以把第一行模型似然改寫成為：</p>
<p><span class="math display">\[
y_i \sim t_4(\mu_i, \sigma^2)
\]</span></p>
<p>使用t分佈作為模型似然的話，相比高斯模型(正態分佈)可以調低(downweight)離群值(outliers)的權重。(詳見 Chapter <a href="#tdreplacegaussian">105.2.9</a>)</p>
<p>實際上，貝葉斯廣義線性回歸模型(Bayesian GLM)直觀地可以被認為是貝葉斯線性回歸模型的擴展模型。記得在基礎的廣義線性回歸模型章節，我們學習過如何用一個<strong>鏈接方程(link function)</strong>把結果變量(outcome)，和解釋變量用數學表達式連接起來。廣義線性回歸模型中最常見的莫過於邏輯回歸模型，接下來我們就來看看如何在貝葉斯統計學框架下擬合我們想要的邏輯回歸模型。在這之前，我們先要學習如何在BUGS語言下描述一個分類型變量(categorical variable)。</p>
<div id="如何在bugs語言中描述分類型變量" class="section level2">
<h2><span class="header-section-number">107.1</span> 如何在BUGS語言中描述分類型變量</h2>
<p>雖然 BUGS 語言風格和 R 語言十分接近，但是二者並不完全通用。BUGS並無像R語言一樣有Factor因子型變量的概念來表述分類型數據。相似的概念在BUGS語言中可以有兩種方法來表達：</p>
<ul>
<li>人工把分類型變量編輯成為啞變量的方式，然後把啞變量輸入數據框中；</li>
<li>利用BUGS語言方便的索引功能 (indexing facilities)。</li>
</ul>
<p>下面我們用簡單線性回歸模型來解釋這兩種方法的異同，其中一個分類型解釋變量 <span class="math inline">\(x_i\)</span>，它有 <span class="math inline">\(A,B,C\)</span> 三種分型(例如ABO血型只有三種分類時的情況)，其中 A 是三個分類中的參照組(reference group)。</p>
<div id="啞變量的數據矩陣" class="section level3">
<h3><span class="header-section-number">107.1.1</span> 啞變量的數據矩陣</h3>
<p>用啞變量矩陣的方式表達分類型變量是常用的手段，為一個有三個分類的變量生成啞變量我們需要給出兩個指示變量(indicator variable)，其中 <span class="math inline">\(x2=1\)</span> 時表示 <span class="math inline">\(x_i = B\)</span>，<span class="math inline">\(x2=0\)</span>時表示 <span class="math inline">\(x_i\neq B\)</span>，<span class="math inline">\(x3=1\)</span> 時表示<span class="math inline">\(x_i = C\)</span>，<span class="math inline">\(x3=0\)</span> 時表示 <span class="math inline">\(x_i\neq C\)</span>：</p>
<pre><code>y[]    x2[]    x3[]
32     0       0        # x_i=A
21     0       0
...
6      0       0
15     1       0        # x_i=B
24     1       0     
...
12     1       0
7      0       1        # x_i=C
26     0       1
...
19     0       1
END
</code></pre>
<p>此時，這個模型的BUGS表達式可以寫作：</p>
<pre><code>for (i in 1:n) {
      y[i]  ~ dnorm(mu[i], tau) 
      mu[i] &lt;- alpha + beta2*x2[i] + beta3*x3[i]
}

alpha ~ dunif(-1000, 1000)
beta2 ~ dunif(-1000, 1000)
beta3 ~ dunif(-1000, 1000)
tau   ~ dgamma(0.001, 0.001)</code></pre>
<p>其中，</p>
<ul>
<li><code>alpha</code> 是參照組 <span class="math inline">\(x_i = A\)</span> 的結果變量的均值；</li>
<li><code>beta2</code> 是和參照組相比，<span class="math inline">\(x_i = B\)</span> 的結果變量的均值和參照組之間結果變量均值的差；</li>
<li><code>beta3</code> 是和參照組相比，<span class="math inline">\(x_i = C\)</span> 的結果變量的均值和參照組之間結果變量均值的差。</li>
</ul>
</div>
<div id="雙重索引bugs語言標記法" class="section level3">
<h3><span class="header-section-number">107.1.2</span> 雙重索引BUGS語言標記法</h3>
<p>與前面的啞變量矩陣描述相異的，我們可以利用BUGS語言中便捷的索引方法來描述一個分類型變量，例如用 <span class="math inline">\(x = 1\)</span> 表示 <span class="math inline">\(x_i = A\)</span>，用 <span class="math inline">\(x = 2\)</span> 表示 <span class="math inline">\(x_i = B\)</span>，用 <span class="math inline">\(x = 3\)</span> 表示 <span class="math inline">\(x_i = C\)</span>：</p>
<pre><code>y[]      x[]
32       1               # x = A
21       1 
... 
6        1
15       2               # x = B
24       2 
...
12       2
7        3               # x = C
26       3
...
19       3
END
</code></pre>
<p>此時，相同的模型則需要被表達成爲：</p>
<pre><code>for(i in 1:n) {
    y[i] ~ dnorm(m[i], tau)
    mu[i] &lt;- alpha + beta[x[i]]
}
alpha ~ dunif(-1000, 1000)
beta[1] &lt;- 0   # fixed as baseline class
beta[2] ~ dunif(-1000, 1000)
beta[3] ~ dunif(-1000, 1000)
tau ~ dgamma(0.001, 0.001)</code></pre>
<p>可以注意到我們在這個模型中把參考組的回歸系數篤定在了 0。這時候，我們給起始值數據時，就不需要給 <code>beta[1]</code> 指定起始值了：</p>
<pre><code>list(alpha = 10, beta = c(NA, -2, 4), tau = 1)</code></pre>
</div>
</div>
<div id="邏輯回歸-bayesian-logistic-regression" class="section level2">
<h2><span class="header-section-number">107.2</span> 邏輯回歸 Bayesian Logistic Regression</h2>
<p>對於一個二分類的結果變量 (binary outcome variable) 來說，最自然的模型是使用邏輯回歸模型。</p>
<p>假如每個個體都有一個二分類結果變量 <span class="math inline">\(y_i = 0 \text{ or } 1\)</span>。那麼每個個體 <span class="math inline">\(i\)</span> 的結果 <span class="math inline">\(y_i\)</span> 可以用伯努利分布 (Chapter <a href="#bernoulli">4</a>) 來描述它：</p>
<p><span class="math display">\[
y_i \sim Bern(p_i)
\]</span></p>
<p>其中，<span class="math inline">\(p_i\)</span>是第<span class="math inline">\(i\)</span>個個體的結果變量取1時<span class="math inline">\((y_i = 1)\)</span>的概率。此時 <span class="math inline">\(P(p_i = 1)\)</span> 是我們想要知道的需要用貝葉斯模型來擬合的未知參數。邏輯回歸模型中我們使用的鏈接方程是 <span class="math inline">\(\mathbf{logit}\)</span>：</p>
<p><span class="math display">\[
\theta_i = \text{logit}(p_i) = \log(\frac{p_i}{1-p_i})
\]</span></p>
<p><span class="math inline">\(\mathbf{logit}\)</span>鏈接方程允許我們把一個只能在 <span class="math inline">\((0,1)\)</span> 之間取值的概率數據，映射到可以在 <span class="math inline">\((-\infty, +\infty)\)</span> 之間取值的變量，之後我們再把這個變量和預測變量使用線性方程連接起來：</p>
<p><span class="math display" id="eq:GLMbayesian01">\[
\text{logit}(p_i)  = \alpha + \sum_k\beta_kx_{ki}
\tag{107.2}
\]</span></p>
<p>這個模型的似然方程，它的事後概率分布是無法獲得閉合解的 (closed form)，但是但是，MCMC強大的計算機模擬過程幫我們解決了這個棘手的問題。</p>
<p>###　邏輯回歸模型中回歸系數的含義</p>
<p>在表達式 <a href="#eq:GLMbayesian01">(107.2)</a> 中我們可以對每個回歸系數做出如下的定義：</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是當所有的預測變量取值同時爲零時的結果變量的對數比值 (log odds)：</li>
</ul>
<p><span class="math display">\[
\Rightarrow \text{logit}^{-1}(\alpha) = \frac{e^\alpha}{(1+e^\alpha)} = \text{ probability of the outcome when all covariates are set to zero}
\]</span></p>
<ul>
<li><span class="math inline">\(\beta_k\)</span> 則是預測變量 <span class="math inline">\(x_k\)</span> 發生一個單位變化時，引起的結果變量的變化的對數比值比 (log odds ratio)：</li>
</ul>
<p><span class="math display">\[
\Rightarrow e^{\beta_k} = \text{ odds ratio of outcome per unit change in } x_k
\]</span></p>
<div id="低出生體重數據-1" class="section level3">
<h3><span class="header-section-number">107.2.1</span> 低出生體重數據</h3>
<p>本例子中，我們關心的研究問題是，三氯甲烷 (trihalomethane, THM)濃度和生下的新生兒爲低出生體重之間是否相關。THM已知是使用氟化氫(chlorine)對飲用水消毒時可能產生副產品，被認爲可能對人類生殖系統造成一定的傷害。數據收集到931名新生兒體重數據，該數據包含的變量有：</p>
<ul>
<li><code>lbw</code> 是該新生兒出生時體重是否爲低體重的二分類變量。</li>
<li><code>thm</code> 是一個指示變量，當它爲0時表示暴露的THM爲低水平，當它爲1時表示暴露的THM爲高水平。</li>
<li><code>age</code> 是一個關於母親們年齡的分類型變量 (1 = $$25歲，2 = 25-29歲，3 = 30-34 歲，4 = <span class="math inline">\(\geqslant\)</span> 35歲)。</li>
<li><code>male</code> 表示新生兒的性別 (0 是女孩，1 是男孩)。</li>
<li><code>car</code> 是一個表示貧困程度的指數。</li>
<li><code>smoke</code> 是表示母親在懷孕期間是否有吸煙習慣的變量 (0 = 無吸煙習慣，1 = 有吸煙習慣)。</li>
</ul>
<p>要回答我們關心的研究問題，那麼這個數據中，</p>
<ul>
<li><code>lbw</code> 是結果變量；</li>
<li><code>thm</code> 是暴露變量；</li>
<li><code>age, male, car, smoke</code> 是可能影響暴露變量和結果之間關係的混雜因子 (confounders)。</li>
</ul>
<p>這時候，本例中的貝葉斯模型的數學表達式可以寫作：</p>
<p><span class="math display">\[
\begin{aligned}
lbw_i &amp; \sim Bernoulli(p_i) \;\; [\text{equivalent to } Binomial(p_i, 1)] \\ 
\text{logit}(p_i) &amp;  = \alpha + \beta_{thm}thm_i + \beta^T_C\mathbf{C}_i \\
\alpha, \beta_{thm}, \dots &amp; \sim \text{Normal}(0, 10000^2) \\
e^{\beta_{thm}}&amp; = \text{odds ratio of low birth weight for high v low thm exposure}
\end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\mathbf{C}\)</span> 是混雜因子組成的向量。也就是母親的年齡，新生兒的性別，貧困指數，以及母親孕期吸煙史。</p>
<p>利用OpenBUGS的雙重索引功能來標記分類型變量的話，這個低體重數據可以被整理為：</p>
<pre><code>lbw[] thm[] age[] male[] car[] smoke[]
0     0     1     1      0.156   1
0     0     3     0     -2.165   1
0     1     1     0     -1.391   1
1     1     4     0      0.156   1
......
0     1     3     1      0.930   0
END
</code></pre>
<p>其對應的BUGS模型代碼為：</p>
<pre><code>model{
    ### MODEL ###
    for (i in 1:931) { # loop through 931 individuals
       y[i] ~ dbern(p[i])
       logit(p[i]) &lt;-  alpha+beta.thm*thm[i]+beta.age[age[i]]+beta.male*male[i]+
       beta.car*car[i]+beta.smoke*smoke[i]
    }
    ### PRIORS ###
    alpha ~ dnorm(0,0.00000001)
    beta.thm ~ dnorm(0,0.00000001)
    beta.age[1] ~ dnorm(0,0.00000001)
    beta.age[2] &lt;- 0 # alias second level of maternal age beta
    beta.age[3] ~ dnorm(0,0.00000001)
    beta.age[4] ~ dnorm(0,0.00000001)
    beta.male ~ dnorm(0,0.00000001)
    beta.car ~ dnorm(0,0.00000001)
    beta.smoke ~ dnorm(0,0.00000001)
    ### CALCULATE THE ODDS RATIOS ###
    OR.thm &lt;- exp(beta.thm)
    OR.age1 &lt;- exp(beta.age[1])
}</code></pre>
<p>OpenBUGS中刨除前5000次樣本採集之後，獲取30000個位置參數的事後樣本，我們獲得了如下的結果：</p>
<pre><code>         mean   sd     MC_error val2.5pc median val97.5pc
beta.thm 0.7587 0.4181 0.008799 -0.02731 0.7453 1.631
OR.thm   2.337  1.074  0.02403  0.9731   2.107  5.107</code></pre>
<p>所以，我們獲得事後比值比2.337的含義就是，孕期暴露高劑量THM和低劑量的THM相比，新生兒出生體重為低出生體重的比值是2.3 (95% 可信區間 credible intervals: 0.97, 5.11)。</p>
<p>值得注意的是，我們上面獲得的事後<code>beta.thm</code>均值，並不等於<code>OR.thm</code>均值取對數：<span class="math inline">\(0.7587 \neq log(2.337)\)</span>。</p>
</div>
</div>
<div id="貝葉斯泊鬆回歸-bayesian-poisson-regression" class="section level2">
<h2><span class="header-section-number">107.3</span> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</h2>
<p>泊鬆回歸用於對計數型數據做回歸模型，例如死亡人數，住院人數，發病人數等。對計數型結果變量使用泊鬆模型時，我們對發生事件的次數的均值的對數加以數學模型：<span class="math inline">\(\mu_i = E(y_i)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp; \sim Poi(\mu_i) \\
\log (\mu_i) &amp; = \alpha + \sum_k\beta_kx_{ki}
\end{aligned}
\]</span></p>
<p>泊鬆模型的數學公式同時也暗示我們默認結果事件發生次數的均值，取對數以後和解釋變量之間呈線性關系。同樣地，高斯先驗概率分布(正態分布)長用於這樣廣義線性回歸模型中的未知參數。</p>
</div>
<div id="glm-in-a-bayesian-way" class="section level2">
<h2><span class="header-section-number">107.4</span> GLM in a Bayesian way</h2>
<ul>
<li>各種你學過的廣義線性回歸模型均可以使用貝葉斯統計學的方法來描述並分析，通過MCMC獲得模型中每個未知參數的事後概率分布描述。</li>
<li>各種你學過的廣義線性回歸模型使用的標準鏈接方程，都可以照搬過來用在貝葉斯廣義線性會回歸模型中。</li>
<li>因爲我們用 MCMC 方法對各個未知參數的事後概率分布進行樣本採集，我們有極其靈活的先驗概率分布描述手段。回歸系數的先驗概率分布通常可以使用高斯分布(正態分布)，一般來說會設定均值爲0，方差合適的正態分布作爲先驗概率分布。</li>
<li>使用貝葉斯統計學框架，廣義線性回歸模型的右邊，可以被擴展至任何非線性回歸模型。強大的計算機模擬過程幫我們解決了無法獲得閉合解這一大難題。</li>
</ul>
</div>
<div id="Bayesian-practical07" class="section level2">
<h2><span class="header-section-number">107.5</span> Practical Bayesian Statistics 07</h2>
<p>要點：</p>
<ul>
<li>學會用OpenBUGS跑貝葉斯邏輯回歸模型；</li>
<li>懂得如何解讀，解釋貝葉斯廣義線性回歸模型結果中的參數估計；</li>
<li>使用DIC比較不同的貝葉斯模型。</li>
</ul>
<p>數據來自研究 <span class="citation">(Diggle et al. <a href="#ref-diggle2002childhood" role="doc-biblioref">2002</a>)</span>，該研究設計是爲了評價 National Impregnated Bednet Programme 是否能減少岡比亞兒童瘧疾發病率，及由於瘧疾導致的死亡。當時研究者從2035名岡比亞兒童身上採集了血樣，用於化驗是否有瘧原蟲感染。同時收集的變量包括，兒童的年齡，兒童是否有規律地使用蚊帳，以及使用的蚊帳是否是經過 (permethrin insecticide) 殺蟲。另外還收集的兩個村莊水平 (village level) 的變量分別是，兒童生活的村莊是否受 Primary Health Care System 管轄，以及村莊環境中的植被情況 (greenness of the village environment)。</p>
<p>該試驗數據除了對使用蚊帳和罹患瘧疾之間的關係進行評估之外，還希望能通過收集到的數據分析是否存在超二項變異 (extra-binomial variation)的證據。這裏，超二項變異的含義是，在調整了已測量的全部觀察變量以後，仍然存在其他未知或者是未測量的潛在因子，導致殘留的差異(residual differences)無法被解釋。</p>
<p>原始數據是個人級別的 (1 record per child)。這裏爲了練習的需要，我們對數據進行了整理彙總，這樣的數據其實使用 MCMC 採集事後樣本效率也比較高。且我們的練習題用的數據只是研究地區西部25個村莊構成的局部數據。這樣，經過處理後的數據庫保存有805名兒童的數據，他們的彙總後的數據有149個二項變量 (binomial categories)。</p>
<p>數據保存在 <code>malaria-data.txt</code> 文件中，使用的是方形格式 (rectangular format)，它有如下的幾個變量:</p>
<pre><code>POP[] MALARIA[] AGE[] BEDNET[] GREEN[] PHC[] VILLAGE[] 
3     2         2     1        40.85   1      1
1     1         3     1        40.85   1      1
2     2         4     1        40.85   1      1
7     3         1     2        40.85   1      1
5     1         2     2        40.85   1      1
6     3         3     2        40.85   1      1
... 
END
</code></pre>
<ul>
<li><code>POP</code> 是所有變量組合下兒童的人數；</li>
<li><code>MALARIA</code> 是所有變量組合下兒童感染虐原蟲兒童的人數；</li>
<li><code>AGE</code> 表示年齡分組 (1 = 0-2 歲，2 = 2-3 歲，3 = 3-4 歲，4 = 4-5 歲)；</li>
<li><code>BEDNET</code> 表示使用蚊帳的情況分類 (1 = 不使用蚊帳，2 = 使用未經殺蟲劑處理過的蚊帳，3 = 使用經過殺蟲劑處理過的蚊帳)；</li>
<li><code>GREEN</code> 是表示村莊植被環境的一個連續型指標；</li>
<li><code>PHC</code> 是一個二分類數據，1/0 = 該村莊是/不是受到 Primary Health Care System 管轄。</li>
<li><code>VILLAGE</code> 是村莊的代碼。</li>
</ul>
<ol style="list-style-type: decimal">
<li>使用貝葉斯邏輯迴歸模型估計使用蚊帳與否和虐原蟲感染之間的關係。嘗試寫下這個貝葉斯模型的BUGS表達文件，並且注意計算:</li>
</ol>
<ul>
<li>參照組(也就是未使用蚊帳組)兒童的瘧疾感染率 (百分比)</li>
<li>每一個可能的共變量的比值比</li>
<li>使用蚊帳和不使用蚊帳相比，能夠降低兒童患瘧疾的比值(odds)的概率；<br> 使用殺蟲劑處理過的蚊帳和使用未處理過的蚊帳相比，能夠降低兒童患瘧疾的比值的概率； <br></li>
</ul>
<p>模型可以寫作:</p>
<pre><code># Logistic regression model for malaria data
    
model {
   for(i in 1:149) {
      MALARIA[i] ~ dbin(p[i], POP[i])
      logit(p[i]) &lt;- alpha + beta.age[AGE[i]] + beta.bednet[BEDNET[i]] +
                                   beta.green*(GREEN[i] - mean(GREEN[])) + beta.phc*PHC[i]  
   }
  
   # vague priors on regression coefficients
   alpha ~ dnorm(0, 0.00001)
   beta.age[1] &lt;- 0          # set coefficient for baseline age group to zero (corner point constraint)
   beta.age[2] ~ dnorm(0, 0.00001)     
   beta.age[3] ~ dnorm(0, 0.00001)     
   beta.age[4] ~ dnorm(0, 0.00001)     
   beta.bednet[1] &lt;- 0     # set coefficient for baseline bednet group to zero (corner point constraint)
   beta.bednet[2] ~ dnorm(0, 0.00001)     
   beta.bednet[3] ~ dnorm(0, 0.00001)     
   beta.green ~ dnorm(0, 0.00001)     
   beta.phc ~ dnorm(0, 0.00001)     
 
   # calculate odds ratios of interest
   OR.age[2] &lt;- exp(beta.age[2]) # OR of malaria for age group 2 vs. age group 1
   OR.age[3] &lt;- exp(beta.age[3]) # OR of malaria for age group 3 vs. age group 1
   OR.age[4] &lt;- exp(beta.age[4]) # OR of malaria for age group 4 vs. age group 1
   
   OR.bednet[2] &lt;- exp(beta.bednet[2]) # OR of malaria for children using untreated bednets vs. not using bednets
   OR.bednet[3] &lt;- exp(beta.bednet[3]) # OR of malaria for children using treated bednets vs. not using bednets
   OR.bednet[4] &lt;- exp(beta.bednet[3] - beta.bednet[2]) # OR of malaria for children using treated bednets vs. using untreated bednets 
   OR.green &lt;- exp(beta.green)  # OR of malaria per unit increase in greenness index of village
   OR.phc &lt;- exp(beta.phc)      # OR of malaria sfor children living in villages belonging to the primary health care system versus children living in villages not in the health care system 
   logit(baseline.prev) &lt;- alpha # baseline prevalence of malaria in baseline group (i.e. child in age group 1, sleeps without bednet, and lives in a village with average greenness index and not in the health care system) 
   
   PP.untreated &lt;- step(1 - OR.bednet[2]) # probability that using untreated bed net vs. no bed net reduces odds of malaria
   PP.treated &lt;- step(1- OR.bednet[4]) # probability that using treated vs. untreated bednet reduces odds of malaria
}</code></pre>
<div class="sourceCode" id="cb1615"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1615-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1615-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-model-editted.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1617-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1617-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded (variables not in the model: VILLAGE)</code></pre>
<div class="sourceCode" id="cb1619"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1619-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1619-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1621"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1621-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1621-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1621-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">-0.51</span>, </a>
<a class="sourceLine" id="cb1621-4" title="4">                 <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.83</span>,  <span class="fl">0.28</span>, <span class="fl">-1.68</span>), </a>
<a class="sourceLine" id="cb1621-5" title="5">                 <span class="dt">beta.bednet =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">-2.41</span>,  <span class="fl">0.68</span>), </a>
<a class="sourceLine" id="cb1621-6" title="6">                 <span class="dt">beta.green =</span> <span class="fl">-0.23</span>, </a>
<a class="sourceLine" id="cb1621-7" title="7">                 <span class="dt">beta.phc =</span> <span class="fl">1.82</span>)</a>
<a class="sourceLine" id="cb1621-8" title="8"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1624"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1624-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">1.29</span>, </a>
<a class="sourceLine" id="cb1624-2" title="2">                  <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.49</span>, <span class="fl">-0.38</span>, <span class="fl">-0.04</span>),  </a>
<a class="sourceLine" id="cb1624-3" title="3">                  <span class="dt">beta.bednet =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">6.85</span>,  <span class="fl">0.09</span>), </a>
<a class="sourceLine" id="cb1624-4" title="4">                  <span class="dt">beta.green =</span> <span class="fl">2.66</span>, </a>
<a class="sourceLine" id="cb1624-5" title="5">                  <span class="dt">beta.phc =</span> <span class="fl">-0.31</span>)</a>
<a class="sourceLine" id="cb1624-6" title="6"></a>
<a class="sourceLine" id="cb1624-7" title="7"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1627"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1627-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1627-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR.age&quot;</span>, <span class="st">&quot;OR.bednet&quot;</span>, <span class="st">&quot;OR.green&quot;</span>, <span class="st">&quot;OR.phc&quot;</span>, <span class="st">&quot;PP.treated&quot;</span>, <span class="st">&quot;PP.untreated&quot;</span>, <span class="st">&quot;baseline.prev&quot;</span>)</a>
<a class="sourceLine" id="cb1627-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR.age&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.bednet&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.green&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.phc&#39;</code></pre>
<pre><code>## monitor set for variable &#39;PP.treated&#39;</code></pre>
<pre><code>## monitor set for variable &#39;PP.untreated&#39;</code></pre>
<pre><code>## monitor set for variable &#39;baseline.prev&#39;</code></pre>
<div class="sourceCode" id="cb1635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1635-1" title="1"><span class="co"># monitor the DIC as well</span></a>
<a class="sourceLine" id="cb1635-2" title="2"><span class="kw">dicSet</span>()</a></code></pre></div>
<pre><code>## deviance set</code></pre>
<div class="sourceCode" id="cb1637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1637-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1637-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 1 s</code></pre>
<div class="sourceCode" id="cb1639"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1639-1" title="1"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1639-2" title="2"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">11</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0701"></span>
<img src="bookdown_files/figure-html/BayesianPractical0701-1.png" alt="Density plots for parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 107.1: Density plots for parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##               Point est. Upper C.I.
## OR.age[2]           1.01       1.05
## OR.age[3]           1.01       1.03
## OR.age[4]           1.01       1.03
## OR.bednet[2]        1.00       1.02
## OR.bednet[3]        1.00       1.00
## OR.bednet[4]        1.00       1.01
## OR.green            1.00       1.01
## OR.phc              1.00       1.00
## PP.treated          1.00       1.01
## PP.untreated        1.01       1.02
## baseline.prev       1.00       1.02
## 
## Multivariate psrf
## 
## 1.01</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical07021"></span>
<img src="bookdown_files/figure-html/BayesianPractical0702-1.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 107.2: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical07022"></span>
<img src="bookdown_files/figure-html/BayesianPractical0702-2.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 107.3: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<p>基本可以認爲刨除前1000次取樣 (burn-in) 可以達到收斂。</p>
<div class="sourceCode" id="cb1641"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1641-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1641-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 25 s</code></pre>
<div class="sourceCode" id="cb1643"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1643-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1643-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1643-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##                 mean      sd  MC_error val2.5pc median val97.5pc start sample
## OR.age[2]     1.7340 0.39890 0.0023940   1.0870 1.6910    2.6500  1001  50000
## OR.age[3]     2.0040 0.44410 0.0027200   1.2760 1.9580    3.0050  1001  50000
## OR.age[4]     2.3180 0.52370 0.0030520   1.4650 2.2620    3.5110  1001  50000
## OR.bednet[2]  0.8790 0.16270 0.0008858   0.6040 0.8642    1.2410  1001  50000
## OR.bednet[3]  0.6952 0.16770 0.0009744   0.4216 0.6758    1.0730  1001  50000
## OR.bednet[4]  0.8003 0.17520 0.0009782   0.5098 0.7822    1.1940  1001  50000
## OR.green      0.9753 0.02345 0.0001299   0.9298 0.9751    1.0220  1001  50000
## OR.phc        0.7112 0.13000 0.0007594   0.4873 0.7001    0.9967  1001  50000
## PP.treated    0.8737 0.33210 0.0017350   0.0000 1.0000    1.0000  1001  50000
## PP.untreated  0.7860 0.41010 0.0022380   0.0000 1.0000    1.0000  1001  50000
## baseline.prev 0.2880 0.04313 0.0002683   0.2073 0.2863    0.3766  1001  50000</code></pre>
<div class="sourceCode" id="cb1645"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1645-1" title="1"><span class="kw">dicStats</span>()</a></code></pre></div>
<pre><code>##          Dbar Dhat   DIC    pD
## MALARIA 461.1  453 469.3 8.127
## total   461.1  453 469.3 8.127</code></pre>
<p>參照組 (年齡小於2歲，不使用蚊帳，生活的村莊植被水平爲全部的平均值，且不在 PHC 管轄範圍內) 患瘧疾的百分比估計在 28.8% 左右 (<code>baseline.prev</code>)。極強的證據表明隨着年齡的增加，患瘧疾的危險度（比值）也升高。使用蚊帳可能可以降低一些些換瘧疾的危險度（比值），(<code>OR.bednet[2] = 0.88</code>) 但是其95%可信區間範圍是包括了1的 (0.604, 1.241)。使用未經殺蟲劑處理的蚊帳，也有79%的概率能夠降低兒童患瘧疾。和使用未經殺蟲劑處理的蚊帳相比，經過殺蟲劑處理的蚊帳也可能(有87.4%的概率)可以進一步降低兒童患瘧疾的危險 (<code>OR.bednet[4]</code> = 0.8003, 95% 可信區間 0.51, 1.19)。和不在PHC管轄內的村莊相比，在PHC管轄的村莊可能可以降低兒童患瘧疾的危險 (<code>OR.phc</code> = 0.7112，95% 可信區間 0.49, 0.99)。</p>
<p>把模型中發現和兒童發生瘧疾無太大關係的變量從貝葉斯邏輯迴歸模型中拿掉以後重新跑新的模型，和之前包含了全部變量的而模型相比較，你覺得哪個模型更合適？</p>
<p>由於植被指標變量和是否使用蚊帳的變量和是否發生瘧疾似乎關係不太大，我們把這兩個變量從模型中拿掉，再跑這個貝葉斯模型:</p>
<pre><code># Logistic regression model for malaria data
    
model {
   for(i in 1:149) {
      MALARIA[i] ~ dbin(p[i], POP[i])
      logit(p[i]) &lt;- alpha + beta.age[AGE[i]] + beta.phc*PHC[i]  
   }
  
   # vague priors on regression coefficients
   alpha ~ dnorm(0, 0.00001)
   beta.age[1] &lt;- 0          # set coefficient for baseline age group to zero (corner point constraint)
   beta.age[2] ~ dnorm(0, 0.00001)     
   beta.age[3] ~ dnorm(0, 0.00001)     
   beta.age[4] ~ dnorm(0, 0.00001)     
   beta.phc ~ dnorm(0, 0.00001)     
 
   # calculate odds ratios of interest
   OR.age[2] &lt;- exp(beta.age[2]) # OR of malaria for age group 2 vs. age group 1
   OR.age[3] &lt;- exp(beta.age[3]) # OR of malaria for age group 3 vs. age group 1
   OR.age[4] &lt;- exp(beta.age[4]) # OR of malaria for age group 4 vs. age group 1
   
   OR.phc &lt;- exp(beta.phc)      # OR of malaria sfor children living in villages belonging to the primary health care system versus children living in villages not in the health care system 
   logit(baseline.prev) &lt;- alpha # baseline prevalence of malaria in baseline group (i.e. child in age group 1, sleeps without bednet, and lives in a village with average greenness index and not in the health care system) 
}</code></pre>
<div class="sourceCode" id="cb1648"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1648-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1648-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-model-dropped.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1650"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1650-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1650-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded (variables not in the model: BEDNET, GREEN, VILLAGE)</code></pre>
<div class="sourceCode" id="cb1652"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1652-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1652-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1654"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1654-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1654-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1654-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">-0.51</span>, </a>
<a class="sourceLine" id="cb1654-4" title="4">                 <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.83</span>,  <span class="fl">0.28</span>, <span class="fl">-1.68</span>), </a>
<a class="sourceLine" id="cb1654-5" title="5">               <span class="co">#  beta.bednet = c(NA, -2.41,  0.68), </span></a>
<a class="sourceLine" id="cb1654-6" title="6">              <span class="co">#   beta.green = -0.23, </span></a>
<a class="sourceLine" id="cb1654-7" title="7">                 <span class="dt">beta.phc =</span> <span class="fl">1.82</span>)</a>
<a class="sourceLine" id="cb1654-8" title="8"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1657"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1657-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">1.29</span>, </a>
<a class="sourceLine" id="cb1657-2" title="2">                  <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.49</span>, <span class="fl">-0.38</span>, <span class="fl">-0.04</span>),  </a>
<a class="sourceLine" id="cb1657-3" title="3">               <span class="co">#   beta.bednet = c(NA, 6.85,  0.09), </span></a>
<a class="sourceLine" id="cb1657-4" title="4">              <span class="co">#    beta.green = 2.66, </span></a>
<a class="sourceLine" id="cb1657-5" title="5">                  <span class="dt">beta.phc =</span> <span class="fl">-0.31</span>)</a>
<a class="sourceLine" id="cb1657-6" title="6"></a>
<a class="sourceLine" id="cb1657-7" title="7"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode" id="cb1660"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1660-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1660-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR.age&quot;</span>, <span class="st">&quot;OR.phc&quot;</span>, <span class="st">&quot;baseline.prev&quot;</span>)</a>
<a class="sourceLine" id="cb1660-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR.age&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.phc&#39;</code></pre>
<pre><code>## monitor set for variable &#39;baseline.prev&#39;</code></pre>
<div class="sourceCode" id="cb1664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1664-1" title="1"><span class="co"># monitor the DIC as well</span></a>
<a class="sourceLine" id="cb1664-2" title="2"><span class="kw">dicSet</span>()</a></code></pre></div>
<pre><code>## deviance set</code></pre>
<div class="sourceCode" id="cb1666"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1666-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1666-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="sourceCode" id="cb1668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1668-1" title="1"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1668-2" title="2"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0704"></span>
<img src="bookdown_files/figure-html/BayesianPractical0704-1.png" alt="Density plots for parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 107.4: Density plots for parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##               Point est. Upper C.I.
## OR.age[2]           1.01       1.01
## OR.age[3]           1.00       1.01
## OR.age[4]           1.00       1.00
## OR.phc              1.01       1.03
## baseline.prev       1.01       1.03
## 
## Multivariate psrf
## 
## 1.01</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0705"></span>
<img src="bookdown_files/figure-html/BayesianPractical0705-1.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 107.5: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="sourceCode" id="cb1670"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1670-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1670-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 13 s</code></pre>
<div class="sourceCode" id="cb1672"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1672-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1672-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1672-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##                 mean     sd  MC_error val2.5pc median val97.5pc start sample
## OR.age[2]     1.6760 0.3787 0.0019230   1.0550 1.6350    2.5240  1001  50000
## OR.age[3]     1.9590 0.4333 0.0023000   1.2480 1.9140    2.9280  1001  50000
## OR.age[4]     2.3110 0.5209 0.0028120   1.4640 2.2550    3.4920  1001  50000
## OR.phc        0.6506 0.1057 0.0005506   0.4684 0.6425    0.8806  1001  50000
## baseline.prev 0.2701 0.0362 0.0001863   0.2022 0.2691    0.3443  1001  50000</code></pre>
<div class="sourceCode" id="cb1674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1674-1" title="1"><span class="kw">dicStats</span>()</a></code></pre></div>
<pre><code>##          Dbar  Dhat   DIC    pD
## MALARIA 461.5 456.5 466.5 5.023
## total   461.5 456.5 466.5 5.023</code></pre>
<p>這個新模型的DIC和之間包含全部變量的模型相比降低了大概3左右，也就是去掉三個共變量對模型的影響。DIC的變化爲3時可認爲幾乎模型的擬合效果沒有太大的變化。處於簡約的考慮，我們選擇這個新的變量較少的模型。</p>
</div>
</div>
<div id="貝葉斯等級回歸模型" class="section level1">
<h1><span class="header-section-number">第 108 章</span> 貝葉斯等級回歸模型</h1>
<div id="關於等級迴歸模型" class="section level2">
<h2><span class="header-section-number">108.1</span> 關於等級迴歸模型</h2>
<p>等級迴歸模型，指的是是一大類模型的設定，它也有很多不同的名字，例如多層模型(multilevel models)，隨機效應模型(random effect models)，隨機係數模型(random coefficient models)，方差成分模型(variance-component models)，混合效應模型(mixed effect models)。等級迴歸模型的最主要特點在於，這一類模型爲我們提供了一種正式的統計學框架，允許我們對複雜結構的數據進行恰當的統計分析，做出合理推斷。</p>
<p>等級迴歸模型最常見的情形可以是:</p>
<ol style="list-style-type: decimal">
<li>社會屬性上的：屬於相同家庭環境下的個人，成長於相似年代背景的一代人等各種社會網絡屬性；</li>
<li>地理屬性上的：在同一社區生活的人，同一城市，甚至是同一個國家生活的個體；</li>
<li>組織結構上的：如在同一個學校上學的學生，屬於同一個教育機構的工作人員等；</li>
<li>實驗設計上的：多中心，多地區合作的聯合臨牀實驗設計(mult-centre clinical trial)；</li>
<li>時間序列上的：相同個體在不同時間點接受相同指標的測量獲得的一系列隨着時間變化而變化的數據。</li>
</ol>
<p>另外，等級迴歸模型有幾個重要的概念需要澄清：</p>
<ol style="list-style-type: decimal">
<li><p>等級迴歸模型有助於考慮數據中的複雜結構 (modelling data with a complex structure) <br> 數據的各種各樣的嵌套式結構可以通過等級迴歸模型體現出來，例如從屬於不同學校的學生，或者是在不同街道的家庭。</p></li>
<li><p>等級迴歸模型有助於考慮數據的異質性 (heterogeneity) <br> 等級迴歸模型不僅可以告訴我們常見的一般均值信息 (averages, i.e. provides the general relationships)，等級迴歸模型還可以告訴我們不同等級之間的方差的異同 (variances)，例如有些街道和另一些街道相比房價的差異變化更大，或者更小。</p></li>
<li><p>等級迴歸模型又有助於考慮數據之間可能存在的非獨立性（依賴性，dependency）<br> 許多數據它們本質上都不是相互獨立的，這種內在的依存性(也許是時間上，空間上，或者是周圍的環境相關的)可以通過等級迴歸模型來克服。例如，相同街區內的房屋價格，有理由認爲應該是有內在相關性的，它們更傾向於接近彼此的報價。</p></li>
<li><p>等級迴歸模型可以幫助我們更加深刻的理解數據的內在的，微觀上的(micro)關係和外在結構上的，或者說宏觀 (macro) 層面上的關係。<br> 例如，每個房屋的價格它的決定因素既有內在的影響因子，如房屋本身的性質，特徵，年份，主人等等；另外，決定它價格的可能還有它所在的街區，街道，小區，甚至是城市的特徵決定了它的價格。</p></li>
</ol>
<p>正因爲我們所認知的數據本身，幾乎都可以有其內在的結構屬性，因此我們有理由使用理論和分析方法上更家貼近這種多層結構的統計學模型來瞭解這個世界。例如從國家層面上來說，可能有些國家的平均脂肪消費水平很高，有研究者發現這些國家比起另外脂肪消費量較低的國家來說，女性的乳腺癌發病率較高。但是，另外有些研究者可能發現，在一個國家內部，從個體與個體之間的脂肪攝入量上來觀察的話，又無法認可脂肪攝入量和乳腺癌發病呈現任何有意義的關係。</p>
<p>許多標準的統計學模型，都需要默認數據與數據之間，觀察對象與<strong>觀察對象之間有獨立性 (independent observation)</strong>。然而現實之中這一點經常是無法做到的。許多實際數據中你會發現默認對象之間的獨立性本身，是不合理的。因爲觀察對象之間可能存在的內在相關性，決定了一些觀察對象可能比起另外一些觀察對象更加傾向於有同質性。</p>
<p>那麼多層迴歸模型就是這樣一類能夠幫助我們理解數據結構的模型。它的靈活性體現在，</p>
<ol style="list-style-type: decimal">
<li>多層迴歸模型提供我們把相關性或者異質性部分的數據結構用模塊化的方法 (modular) 放入統計學模型中；</li>
<li>多層迴歸模型也會允許我們把數據中的缺失值，甚至是測量誤差給考慮進來，提供更加強有力（但是複雜的）統計學模型。</li>
</ol>
</div>
<div id="多層數據在模型中可能要用到的前提條件" class="section level2">
<h2><span class="header-section-number">108.2</span> 多層數據在模型中可能要用到的前提條件</h2>
<p>在多層模型擬合多層數據時，有一個基本的問題就是如何正確地理解模型中各種各樣的回歸系數（參數, parameters）：例如 <span class="math inline">\(J\)</span> 個單位（可能是：個人，個體，子集 subset，區域，時間點，實驗組，等）的回歸參數 <span class="math inline">\(\theta_1, \dots, \theta_J\)</span>。對這些回歸系數的正確理解，是要建立在對我們研究的問題，研究的數據的結構的理解之上的。</p>
<p>舉幾個簡單的例子來說，<span class="math inline">\(\theta_j\)</span> 有可能有這樣的意義：</p>
<ol style="list-style-type: decimal">
<li>不同類型的患者（可以是不同的年齡組，疾病的分級，或者治療條件等）的治療效果；</li>
<li>在meta分析中則可以體現不同研究的研究效應(study effect)；</li>
<li>某疾病在不同地區，年齡組，時間段的相對危險度；</li>
<li>在某些生長曲線模型 (growth curves models) 中的個體效應 (subject effect)。</li>
</ol>
<p>綜上所述，我們可以發現，雖然多層回歸模型可能可以克服個體之間存在依賴性的問題，但是模型中的參數符合的前提條件可以有三種類別之分：</p>
<ul>
<li>參數是相同的 (identical parameters)；</li>
<li>參數是獨立的 (independent parameters)；</li>
<li>參數是可交換的 (exchangeable parameters)。</li>
</ul>
<p>下圖 <a href="#fig:Bayesian0801">108.1</a> 展示了個體從屬於家庭醫生，家庭醫生又接着從屬於 Primary Care Trusts (PCTs) 的數據結構示意圖。</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0801"></span>
<img src="img/Fig8_1P78Bayesian.png" alt="GP example of multi-level structure: individuals within GPs within PCTs" width="80%" />
<p class="caption">
圖 108.1: GP example of multi-level structure: individuals within GPs within PCTs
</p>
</div>
<div id="參數是相同的-identical-parameters" class="section level3">
<h3><span class="header-section-number">108.2.1</span> 參數是相同的 (identical parameters)</h3>
<p>如果說參數相同的前提被認爲可以接受，那麼什麼 GP 什麼 PCT 的數據結構都可以被忽略，也就是每個個體都可以被視爲相互獨立的：</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0802"></span>
<img src="img/Fig8_2P78Bayesian.png" alt="GP example assuming identical parameters" width="80%" />
<p class="caption">
圖 108.2: GP example assuming identical parameters
</p>
</div>
<p>但是，這意味着</p>
<ul>
<li>一個參數可以產生全部的觀察對象 (one parameter generates all the observations)；</li>
<li>參數<span class="math inline">\(\theta\)</span>的估計會很容易，因爲全部觀察對象都被用來估計一個未知參數；</li>
<li>不能體現實際數據的層級結構情況 (it does not take into account differences in the PCT, GPs, etc.)</li>
</ul>
</div>
<div id="參數是獨立的-independent-parameters" class="section level3">
<h3><span class="header-section-number">108.2.2</span> 參數是獨立的 (independent parameters)</h3>
<p>每一個參數如果要被認爲是全部沒有關聯（獨立）的話，如示意圖 <a href="#fig:Bayesian0803">108.3</a> 所展現的那樣，每個GP都被單獨對待，即使同處在一個 PCT 的 GP 之間也被認爲是沒有任何相關聯信息的。</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0803"></span>
<img src="img/Fig8_3P79Bayesian.png" alt="GP example assuming independent parameters" width="80%" />
<p class="caption">
圖 108.3: GP example assuming independent parameters
</p>
</div>
</div>
<div id="參數是可交換的-exchangeable-parameters" class="section level3">
<h3><span class="header-section-number">108.2.3</span> 參數是可交換的 (exchangeable parameters)</h3>
<p>如果認爲參數是可置換的，那麼如圖 <a href="#fig:Bayesian0804">108.4</a> 所示，這樣需要我們</p>
<ul>
<li>對不同層級進行相應的分析；</li>
<li>認爲從屬於一個 PCT 的 GP 們更加彼此相似/接近，且他們的參數 <span class="math inline">\(\theta\)</span> 通過共同的 <span class="math inline">\(\mu\)</span> 來產生；</li>
<li>允許不同層級之間的參數信息可以相互交換，因爲他們通過數據結構互相鏈接。</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0804"></span>
<img src="img/Fig8_4P79Bayesian.png" alt="GP example assuming exchangeable parameters" width="80%" />
<p class="caption">
圖 108.4: GP example assuming exchangeable parameters
</p>
</div>
<p>在較爲廣義的條件下(broad conditions)，參數的可交換定義在數學上等價於認爲 <span class="math inline">\(\theta_1, \dots, \theta_J\)</span> 來自於一個共同的先驗概率分佈 (common prior distribution)，只是它的參數是<strong>未知的</strong> (with <strong>unkown</strong> parameters)。</p>
<p>多層迴歸模型允許未知參數之間相互借鑑，取長補短 (borrowing of strength across units)。<span class="math inline">\(\theta_i\)</span>的事後概率分佈事實上從全部的未知參數構成的似然中借取能量 (borrows stength from the likelihood function contributions for all the units, via their joint influence on the posterior estimates of the unknown hyper-parameters)。通過 MCMC 計算機模擬試驗的方法，加上多層迴歸模型對真實世界的模擬，統計估計的效率被大大提升了。別忘了, MCMC的靈活性同時讓我們可以放鬆對隨機效應要服從正態分佈這一前提條件。</p>
<p>可見，這第三種情形，參數的可交換性是進行多層模型分析的基石，而不是認爲未知參數是相互獨立或者完全相同。</p>
<p>構建多層迴歸模型本身提供了廣闊的視野，讓我們通過統計學工具一窺真實世界數據的複雜結構：</p>
<ul>
<li>我們可以在模型中加入2層甚至更多層的數據結構；</li>
<li>允許加入非嵌套變量，交叉變量 (non-nested/cross-classified)，例如不同GP的病人，他們參加治療的醫院或許各不相同。</li>
<li>同一對象的重複觀察值 (repeated observations)，可以出現在一部分未知參數，或者全部未知參數中，然後我們通過線性或者非線性（廣義線性）隨機效應模型來表達其關係。</li>
<li>數據中的時間前後關係，甚至於是空間上的關係也可以通過多層迴歸模型來表達。</li>
<li>當然，你也可以在不同層級水平上增加需要考慮的共變量。</li>
</ul>
<p>當我們在學習和建立複雜數據結構的模型時，貝葉斯統計學提供的強有力工具再一次印證了其高效且強大的分析效能。這裏我們僅有機會使用一個簡單的例子來展示如何在貝葉斯框架下構建擬合縱向研究數據的多層迴歸模型。</p>
</div>
</div>
<div id="抗抑鬱臨牀試驗實例" class="section level2">
<h2><span class="header-section-number">108.3</span> 抗抑鬱臨牀試驗實例</h2>
<div id="縱向數據" class="section level3">
<h3><span class="header-section-number">108.3.1</span> 縱向數據</h3>
<p>縱向數據常見於對同一(單元的)樣本個體經過不同的時間點重複多次收集獲得的數據。一般來說，從同一個體收集的觀察數據相互之間存在依存關係。分析縱向數據可以有很多方法，但是不論哪種方法，都必須考慮到這個存在依存關係的數據結構。其中兩種最常見的手段分別是隨機效應線性迴歸模型 (random effects/hierarchical linear model) 和自迴歸模型 (autoregressive model)。這裏的實例我們使用隨機效應模型。</p>
</div>
<div id="hamd-example" class="section level3">
<h3><span class="header-section-number">108.3.2</span> HAMD example</h3>
<p>抗抑鬱臨牀試驗是一個有6個不同試驗中心，367名患者被隨機分配到3種治療方案。每名參加試驗的患者每週都會被使用 Hamilton depression score (HAMD) 評估打分，持續5周時間。其中 HAMD 分數範圍是 0-50 之間，分數越高，抑鬱症狀越嚴重。5周連續的HAMD打分過程是這樣的，第一次評分 (Week 0) 是在治療前，之後的4次打分是在治療開始之後 (Week 1-4)。這個數據之前曾經發表於文獻 <span class="citation">(Diggle and Kenward <a href="#ref-diggle1994informative" role="doc-biblioref">1994</a>)</span> 中。</p>
<p>實際上該試驗中從第二週開始就有患者退出治療 (dropout)。我們在這裏暫且忽略掉有患者中途退出這件事，先分析246名從頭至尾都完成了試驗的患者的數據。圖 <a href="#fig:Bayesian0805">108.5</a> 展示的是完成全部試驗評分的患者中隨機選取50人的5次評分結果，按照時間的先後順序繪製的不同治療方案下每個人的分數變化軌跡，和每組治療方案的患者平均治療成績的軌跡。</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0805"></span>
<img src="img/HAMD.png" alt="HAMD data for complete cases" width="80%" />
<p class="caption">
圖 108.5: HAMD data for complete cases
</p>
</div>
<p>這個實驗中，我們關心的問題是<strong>三種治療方案對抑鬱症患者 HAMD 分數的變化的影響是否存在不同？</strong></p>
<p>此時數據中的變量有：</p>
<ul>
<li><span class="math inline">\(y\)</span> HAMD 分數</li>
<li><span class="math inline">\(t\)</span> 治療組</li>
<li><span class="math inline">\(w\)</span> 治療周</li>
</ul>
<p>這裏我們先暫且忽略掉試驗中心可能造成的不同療效，且假設HAMD評分隨着時間呈線性變化。那麼我們來思考或許可行的三個模型：</p>
<ul>
<li>標準的簡單線性迴歸，非多層迴歸模型 (standard linear regression)；</li>
<li>多層線性迴歸模型，且允許有隨機截距 (hierarchical model with random intercepts)；</li>
<li>多層線性迴歸模型，且允許同時有隨機截距和隨機斜率兩種模型 (hierarchical mdoel with random intercepts and random slopes)。</li>
</ul>
</div>
<div id="貝葉斯簡單線性迴歸模型" class="section level3">
<h3><span class="header-section-number">108.3.3</span> 貝葉斯簡單線性迴歸模型</h3>
<p>爲此 HAMD 數據設定簡單線性迴歸模型如下：</p>
<ul>
<li>患者的評分服從的概率分佈: <span class="math inline">\(y_{iw} \sim \text{Normal}(\mu_{iw}, \sigma^2)\)</span>，其中，<span class="math inline">\(y_{iw}\)</span> 是第 <span class="math inline">\(i\)</span> 名患者
在第 <span class="math inline">\(w, w \in \{0, 1, 2, 3, 4\}\)</span> 周時的 HAMD 評分。</li>
<li>線性預測變量: <span class="math inline">\(\mu_{iw} = \alpha + \beta_{\text{treat}(i)}w\)</span>，其中，<span class="math inline">\(\text{treat}(i)\)</span> 是第 <span class="math inline">\(i\)</span> 名患者的治療組編號，可以取值 <span class="math inline">\(1,2,3\)</span>，<span class="math inline">\(w\)</span> 則是周數，治療前爲第 <span class="math inline">\(w = 0\)</span> 周，治療開始之後取 <span class="math inline">\(w = 1,2,3,4\)</span> 周。</li>
</ul>
<p>在簡單線性迴歸模型中，重複測量數據嵌套於 (nested) 每個患者個體這一事實被忽略了，我們爲每個未知參數加以無信息的先驗概率分佈：</p>
<p><span class="math display">\[
\begin{aligned}
\alpha, \beta_1, \beta_2, \beta_2 &amp; \sim \text{Normal}(0, 10000)  \\
\frac{1}{\sigma^2} &amp; \sim \text{Gamma}(0.001, 0.001)
\end{aligned}
\]</span></p>
<p>這個簡單線性迴歸模型對應的 BUGS 模型可以寫作：</p>
<pre><code>for (i in 1:N){ # N individuals 
    for (w in 1:W) { # W weeks
        hamd[i, w] ~ dnorm(mu[i, w], tau)
        mu[i, w] &lt;- alpha + beta[treat[i]]*(w-1)
    }
# specification of priors
  alpha ~ dnorm(0, 0.00001) 
  for (i in 1:T){ # T treatments
    beta[t]~dnorm(0, 0.00001)
  }
  tau ~ dgamma(0.001, 0.001)
  sigma.sq&lt;-1/tau # normal errors
}</code></pre>
</div>
<div id="貝葉斯等級線性回歸隨機截距模型" class="section level3">
<h3><span class="header-section-number">108.3.4</span> 貝葉斯等級線性回歸–隨機截距模型</h3>
<p>對簡單線性回歸模型進行適當修改之後就能直接把它引申爲隨機截距模型。其中，每一名患者都有自己的截距:</p>
<p><span class="math display">\[
\begin{aligned}
y_{iw}   &amp; \sim \text{Normal}(\mu_{iw}, \sigma^2) \\
\mu_{iw} &amp; = \alpha_i + \beta_{treat(i)}w
\end{aligned}
\]</span></p>
<p>此時模型中的前提是，以每名患者自己的截距 <span class="math inline">\(\alpha_i\)</span> 爲條件時 (conditional on)，患者的HAMD測試結果 <span class="math inline">\(\{y_{iw}, w = 0, \dots, 4\}\)</span> 會相互獨立。同時，我們還假設所有的隨機截距 <span class="math inline">\(\alpha_i\)</span> 服從<strong>相同的（共同的）</strong>先驗概率分佈。</p>
<p><span class="math display">\[
\alpha_i \sim \text{Normal}(\mu_\alpha, \sigma^2_\alpha) \;\; i = 1, \dots, 246
\]</span></p>
<p>這裏我們又假定了每個人的均值（截距）是來自相同分佈（可以互換的，exchangeability）。</p>
<p>再接下來，對於人羣的截距這一數據設定非常模糊的先驗概率超參數 (hyperparameters):</p>
<p><span class="math display">\[
\begin{aligned}
\mu_\alpha    &amp; \sim \text{Normal}(0, 10000) \\ 
\sigma_\alpha &amp; \sim \text{Uniform}(0, 100) 
\end{aligned}
\]</span></p>
<p>這是一個典型的多層線性回歸模型 (Hierarchical LM or Linear Mixed Model, LMM)，或者又叫做隨機截距模型(Random Intercepts model)。</p>
<p>這個模型可以使用BUGS語言描述如下：</p>
<pre><code>for (i in 1:N) { # N individuals 
    for (w in 1:W) { # W weeks 
        hamd[i, w] ~ dnorm(mu[i,w], tau)
        mu[i,w] &lt;- alpha[i] + beta[treat[i]]*(w-1)
    }
    alpha[i] ~ dnorm(alpha.mu, alpha.tau) # random intercepts
}
   # Specification of priors
alpha ~ dnorm(0, 0.00001)
alpha.mu ~ dnorm(0, 0.00001)
alpha.sigma ~ dunif(0, 100)
alpha.sigma.sq &lt;- pow(alpha.sigma, 2)
alpha.tau &lt;- 1/alpha.sigma.sq

for (t in 1:T){ # T treatments
    beta[t] ~ dnorm(0, 0.00001)
}
tau ~ dgamma(0.001, 0.001)
sigma.sq &lt;- 1/tau  # Normal errors</code></pre>
<p>無隨機截距的簡單線性回歸模型，和包括了隨機截距模型的多層線性回歸模型之間的差別，用 DAG 圖來表示可以直觀的展示如下：</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0806"></span>
<img src="img/DAGsHAMD.png" alt="DAGs for models for the HAMD example" width="80%" />
<p class="caption">
圖 108.6: DAGs for models for the HAMD example
</p>
</div>
</div>
<div id="貝葉斯等級線性回歸模型隨機截距和隨機斜率模型" class="section level3">
<h3><span class="header-section-number">108.3.5</span> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</h3>
<p>與隨機截距模型相類似地，我們可以把該模型從隨機截距的基礎上再擴展到隨機斜率模型，也就是可以認爲每名患者的HAMD分數變化的直線的斜率可以因人而異。</p>
<p><span class="math display">\[
\begin{aligned}
y_{iw}   &amp; \sim \text{Normal}(\mu_{iw}, \sigma^2) \\ 
\mu_{iw} &amp; =    \alpha_i + \beta_{treat(i), i}w
\end{aligned}
\]</span></p>
<p>模型中的隨機截距<span class="math inline">\(\{\beta_{(1,i)}\}, \{\beta_{(2,i)}\}, \{\beta_{(3,i)}\}\)</span>, 同隨機截距 <span class="math inline">\(\{\alpha_i\}\)</span> 一樣我們都賦予其相同的且模糊的無有效信息的先驗概率分佈：</p>
<p>這個隨機效應模型的BUGS模型代碼寫作如下：</p>
<pre><code>for (i in 1:N) { # N individuals
    for (w in 1:W) { # W weeks 
        hamd[i, w] ~ dnorm(mu[i, w], tau)
        mu[i, w] &lt;- alpha[i] + beta[treat[i], i] * (w - 1)
    }
    alpha[i] ~ dnorm(alpha.mu, alpha.tau)
    for(t in 1:T) {beta[t, i] ~ dnorm(beta.mu[t], beta.tau[t])}
}

# Priors
for (t in 1:T) { # T treatments
    beta.mu[t] ~ dnorm(0, 0.0001)
    beta.sigma[t] ~ dunif(0, 100)
    beta.sigma.sq[t] &lt;- pow(beta.sigma[t], 2)
    beta.tau[t] &lt;- 1/beta.sigma.sq[t]
}

# specification of other priors as before in the random intercept model
alpha ~ dnorm(0, 0.00001)
alpha.mu ~ dnorm(0, 0.00001)
alpha.sigma ~ dunif(0, 100)
alpha.sigma.sq &lt;- pow(alpha.sigma, 2)
alpha.tau &lt;- 1/alpha.sigma.sq

for (t in 1:T){ # T treatments
    beta[t] ~ dnorm(0, 0.00001)
}
tau ~ dgamma(0.001, 0.001)
sigma.sq &lt;- 1/tau  # Normal errors</code></pre>
</div>
<div id="hamd-數據不同模型結果的比較" class="section level3">
<h3><span class="header-section-number">108.3.6</span> HAMD 數據不同模型結果的比較</h3>
<ul>
<li>在非隨機效應模型（即簡單線性回歸模型）中，
<ul>
<li>一共有3條回歸直線被統計模型擬合，其中每個治療方案爲一條回歸直線；</li>
<li>每個治療方案獲得的回歸直線本身，具有相同的截距；</li>
<li>每個治療方案的回歸直線具有不同的斜率。</li>
</ul></li>
<li>在隨機截距模型中，
<ul>
<li>每名參加實驗的患者有自己的回歸直線；</li>
<li>每名患者的回歸直線只有自己的隨機截距，也就是HAMD的起始值被允許取不同的值。</li>
</ul></li>
<li>再隨機截距隨機斜率模型中，
<ul>
<li>每名患者的回歸直線被允許擁有不同的斜率，和不同的截距。</li>
</ul></li>
</ul>
<p>下圖(表) <a href="#fig:Bayesian0807">108.7</a> 提供了三種不同模型分析 HAMD 數
據結果的報告。可以注意到當模型中增加隨機效應時，明顯地，殘差方差
(residual variance) <span class="math inline">\(\sigma^2\)</span> 大幅下降。因爲這些使用簡單線性回歸模型
時只能被歸類到一個隨機殘差當中去的方差，分別被歸類到了隨機截距的方差，
和隨機斜率的方差中去了。三個模型的 DIC 指標也提示我們，該數據更加支持
隨機效應模型，且兩個隨機效應模型相比，隨機截距和隨機斜率都有的隨機效應
模型更加貼合收集來的觀測數據。同時表格的最下面也列出了每個不同模型中實
際使用到的有效變量個數 (effective number of parameters, <span class="math inline">\(p_D\)</span>)，而且這
個有效變量個數隨着隨機效應的增加而顯著增加。</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0807"></span>
<img src="img/DAGsHAMDhierresults.png" alt="Posterior mean (95% credible intervals) for the non-hierarchical and hierarchical models fitted to the HAMD data." width="80%" />
<p class="caption">
圖 108.7: Posterior mean (95% credible intervals) for the non-hierarchical and hierarchical models fitted to the HAMD data.
</p>
</div>
</div>
<div id="hamd-數據實例結果的解釋" class="section level3">
<h3><span class="header-section-number">108.3.7</span> HAMD 數據實例結果的解釋</h3>
<p>值得注意的是，在 HAMD 數據中，我們關心的實驗問題其實是，“三種不同治療方案，對於HAMD分析得分的<strong>變化（也就是回歸線的斜率）</strong>，是否起到不同的作用。(whether there are any difference in the effects of the 3 treatments on the change in HAMD score over time)”。也就是說我們特別對斜率的不同感興趣。</p>
<ul>
<li><span class="math inline">\(\beta_1 - \beta_2, \beta_1 - \beta_3, \beta_2 - \beta_3\)</span>；</li>
<li>以及隨機斜率模型中的：<span class="math inline">\(\mu_{\beta_1} - \mu_{\beta_2}, \mu_{\beta_1} - \mu_{\beta_3}, \mu_{\beta_2} - \mu_{\beta_3}\)</span></li>
</ul>
<p>這些斜率差值其實可以通過 BUGS 代碼簡單方便的計算出來，便於我們進行樣本採集和統計推斷：</p>
<pre><code># calculate contrasts
contrasts[1] &lt;- beta[1] - beta[2]
contrasts[2] &lt;- beta[1] - beta[3]
contrasts[3] &lt;- beta[2] - beta[3]</code></pre>
<p>或者寫成：</p>
<pre><code>contrasts[1] &lt;- beta.mu[1] - beta.mu[2]
...</code></pre>
<p>三個不同模型的斜率比較結果總結如下圖（表）<a href="#fig:Bayesian0808">108.8</a>，其中隨機即截距隨機斜率模型的三個斜率比較的事後概率分佈圖繪製如圖<a href="#fig:Bayesian0809">108.9</a>。由於 HAMD 得分越低表示抑鬱症症狀越輕，所以表格中的斜率差如果是負的，表示斜率比較中前者的療效更好（下降效果更顯著），如果斜率差是正的，那麼就是反過來證明斜率比較中後者的療效更好。所以很顯然，療法2比起療法1對於 HAMD 分數的下降更加有顯著效果。這個結果和之前對數據的粗略均值繪製圖<a href="#fig:Bayesian0805">108.5</a>提示的結果相一致。當然一個更加完整的貝葉斯統計學分析還要包括對模型進行擬合診斷，以及對模型進行更加仔細的推敲（例如對線性變量中心化，或者增加實驗設施這個層級的隨機效應，或者允許增加非線性的結果）。另外值得注意的是，我們之前介紹過的所有對於非多層回歸模型的擬合檢查在混合效應模型中都會變得更加複雜。還有值得提醒的一點在於，DIC在大部分模型擬合中都可以用於比較不同的模型，但是有時候也會出現 BUGS 軟件無法計算 DIC 的情況。先驗概率分佈的選擇也是混合效應模型擬合時需要慎重考慮的一點，這些內容這裏由於篇幅限制無法一一詳細介紹。</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0808"></span>
<img src="img/DAGsHAMDhiercontrast.png" alt="Posterior mean (95% credible interval) for the contrasts (treatment comparisons) from models fitted to the HAMD data" width="80%" />
<p class="caption">
圖 108.8: Posterior mean (95% credible interval) for the contrasts (treatment comparisons) from models fitted to the HAMD data
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0809"></span>
<img src="img/DAGsHAMDhierfig.png" alt="Density plots for the hierarchical model with random intercepts and random slopes." width="80%" />
<p class="caption">
圖 108.9: Density plots for the hierarchical model with random intercepts and random slopes.
</p>
</div>
</div>
</div>
<div id="practical-bayesian-statistics-08" class="section level2">
<h2><span class="header-section-number">108.4</span> Practical Bayesian Statistics 08</h2>
<p>本章練習題會延續使用前一個章節 (Chapter <a href="#Bayesian-practical07">107.5</a>) 中使用的練習題數據，岡比亞兒童使用蚊帳睡眠是否能夠降低或者減輕瘧疾。</p>
<ol style="list-style-type: decimal">
<li>把前章練習中的貝葉斯邏輯回歸模型改造成爲一個包含村莊級別隨機效應的多層邏輯回歸模型。</li>
</ol>
<pre><code># Logistic regression model for malaria data
    
model {
   for(i in 1:149) {
      MALARIA[i] ~ dbin(p[i], POP[i])
      logit(p[i]) &lt;- alpha + beta.age[AGE[i]] +
                            beta.bednet[BEDNET[i]] + 
                            beta.green*(GREEN[i] - mean(GREEN[])) +
                            beta.phc*PHC[i] + 
                            theta[VILLAGE[i]]
   }
   # village-level randome effect 
   for (j in 1:25) {
       theta[j] ~ dnorm(0, tau)
       OR.village[j]  &lt;- exp(theta[j])
       # Odds ratio of malaria in village j relative to the average
   }
  
  
   # vague priors on regression coefficients
   alpha ~ dnorm(0, 0.00001)
   sigma ~ dunif(0, 100)
   tau &lt;- 1/pow(sigma, 2)
   beta.age[1] &lt;- 0        
       # set coefficient for baseline age group to zero (corner point constraint)
   beta.age[2] ~ dnorm(0, 0.00001)     
   beta.age[3] ~ dnorm(0, 0.00001)     
   beta.age[4] ~ dnorm(0, 0.00001)     
   beta.bednet[1] &lt;- 0    
       # set coefficient for baseline bednet group to zero (corner point constraint)
   beta.bednet[2] ~ dnorm(0, 0.00001)     
   beta.bednet[3] ~ dnorm(0, 0.00001)     
   beta.green ~ dnorm(0, 0.00001)     
   beta.phc ~ dnorm(0, 0.00001)     
 
   # calculate odds ratios of interest
   OR.age[2] &lt;- exp(beta.age[2]) # OR of malaria for age group 2 vs. age group 1
   OR.age[3] &lt;- exp(beta.age[3]) # OR of malaria for age group 3 vs. age group 1
   OR.age[4] &lt;- exp(beta.age[4]) # OR of malaria for age group 4 vs. age group 1
   
   OR.bednet[2] &lt;- exp(beta.bednet[2]) # OR of malaria for children using untreated bednets vs. not using bednets
   OR.bednet[3] &lt;- exp(beta.bednet[3]) # OR of malaria for children using treated bednets vs. not using bednets
   OR.bednet[4] &lt;- exp(beta.bednet[3] - beta.bednet[2]) # OR of malaria for children using treated bednets vs. using untreated bednets 
   OR.green &lt;- exp(beta.green)  # OR of malaria per unit increase in greenness index of village
   OR.phc &lt;- exp(beta.phc)      # OR of malaria sfor children living in villages belonging to the primary health care system versus children living in villages not in the health care system 
   logit(baseline.prev) &lt;- alpha # baseline prevalence of malaria in baseline group (i.e. child in age group 1, sleeps without bednet, and lives in a village with average greenness index and not in the health care system) 
   
   PP.untreated &lt;- step(1 - OR.bednet[2]) # probability that using untreated bed net vs. no bed net reduces odds of malaria
   PP.treated &lt;- step(1- OR.bednet[4]) # probability that using treated vs. untreated bednet reduces odds of malaria
}</code></pre>
<div class="sourceCode" id="cb1682"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1682-1" title="1"><span class="co"># Step 1 check model</span></a>
<a class="sourceLine" id="cb1682-2" title="2"><span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-model-hierarchical.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </a></code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode" id="cb1684"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1684-1" title="1"><span class="co"># Load the data </span></a>
<a class="sourceLine" id="cb1684-2" title="2"><span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;backupfiles/malaria-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </a></code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode" id="cb1686"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1686-1" title="1"><span class="co"># compile the model with two separate chains</span></a>
<a class="sourceLine" id="cb1686-2" title="2"><span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </a></code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode" id="cb1688"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1688-1" title="1"><span class="co"># generate initial values </span></a>
<a class="sourceLine" id="cb1688-2" title="2"><span class="co"># the choice is arbitrary</span></a>
<a class="sourceLine" id="cb1688-3" title="3">initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">-0.51</span>, </a>
<a class="sourceLine" id="cb1688-4" title="4">                 <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.83</span>,  <span class="fl">0.28</span>, <span class="fl">-1.68</span>), </a>
<a class="sourceLine" id="cb1688-5" title="5">                 <span class="dt">beta.bednet =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">-2.41</span>,  <span class="fl">0.68</span>), </a>
<a class="sourceLine" id="cb1688-6" title="6">                 <span class="dt">beta.green =</span> <span class="fl">-0.23</span>, </a>
<a class="sourceLine" id="cb1688-7" title="7">                 <span class="dt">beta.phc =</span> <span class="fl">1.82</span>,</a>
<a class="sourceLine" id="cb1688-8" title="8">                 <span class="dt">sigma =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb1688-9" title="9"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</a></code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded but chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1691"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1691-1" title="1">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">1.29</span>, </a>
<a class="sourceLine" id="cb1691-2" title="2">                  <span class="dt">beta.age =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">0.49</span>, <span class="fl">-0.38</span>, <span class="fl">-0.04</span>),  </a>
<a class="sourceLine" id="cb1691-3" title="3">                  <span class="dt">beta.bednet =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="fl">6.85</span>,  <span class="fl">0.09</span>), </a>
<a class="sourceLine" id="cb1691-4" title="4">                  <span class="dt">beta.green =</span> <span class="fl">2.66</span>, </a>
<a class="sourceLine" id="cb1691-5" title="5">                  <span class="dt">beta.phc =</span> <span class="fl">-0.31</span>,</a>
<a class="sourceLine" id="cb1691-6" title="6">                  <span class="dt">sigma =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1691-7" title="7"></a>
<a class="sourceLine" id="cb1691-8" title="8"><span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</a></code></pre></div>
<pre><code>## Initializing chain 2: 
## initial values loaded but chain contain uninitialized variables</code></pre>
<div class="sourceCode" id="cb1693"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1693-1" title="1"><span class="kw">modelGenInits</span>()  <span class="co"># same with click on the gen inits to generate initial values (for the random effects (theta))</span></a></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode" id="cb1695"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1695-1" title="1"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span></a>
<a class="sourceLine" id="cb1695-2" title="2">parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;OR.age&quot;</span>, <span class="st">&quot;OR.bednet&quot;</span>, <span class="st">&quot;OR.green&quot;</span>, <span class="st">&quot;OR.phc&quot;</span>, <span class="st">&quot;PP.treated&quot;</span>, <span class="st">&quot;PP.untreated&quot;</span>, <span class="st">&quot;baseline.prev&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;OR.village&quot;</span>)</a>
<a class="sourceLine" id="cb1695-3" title="3"><span class="kw">samplesSet</span>(parameters)</a></code></pre></div>
<pre><code>## monitor set for variable &#39;OR.age&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.bednet&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.green&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.phc&#39;</code></pre>
<pre><code>## monitor set for variable &#39;PP.treated&#39;</code></pre>
<pre><code>## monitor set for variable &#39;PP.untreated&#39;</code></pre>
<pre><code>## monitor set for variable &#39;baseline.prev&#39;</code></pre>
<pre><code>## monitor set for variable &#39;sigma&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR.village&#39;</code></pre>
<div class="sourceCode" id="cb1705"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1705-1" title="1"><span class="co"># monitor the DIC as well</span></a>
<a class="sourceLine" id="cb1705-2" title="2"><span class="kw">dicSet</span>()</a></code></pre></div>
<pre><code>## deviance set</code></pre>
<div class="sourceCode" id="cb1707"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1707-1" title="1"><span class="co"># Generate 1000 iterations</span></a>
<a class="sourceLine" id="cb1707-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## 1000 updates took 1 s</code></pre>
<div class="sourceCode" id="cb1709"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1709-1" title="1"><span class="co"># Check trace history for the first 1000 run </span></a>
<a class="sourceLine" id="cb1709-2" title="2"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">38</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical0801"></span>
<img src="bookdown_files/figure-html/BayesianPractical0801-1.png" alt="Density plots for parameters for hierarchical GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.10: Density plots for parameters for hierarchical GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<pre><code>## Potential scale reduction factors:
## 
##                Point est. Upper C.I.
## OR.age[2]           1.000       1.00
## OR.age[3]           0.999       1.00
## OR.age[4]           1.000       1.00
## OR.bednet[2]        1.079       1.29
## OR.bednet[3]        1.003       1.01
## OR.bednet[4]        1.024       1.08
## OR.green            1.014       1.04
## OR.phc              1.038       1.17
## OR.village[1]       1.008       1.04
## OR.village[2]       1.002       1.01
## OR.village[3]       0.999       1.00
## OR.village[4]       1.015       1.07
## OR.village[5]       1.000       1.00
## OR.village[6]       1.004       1.02
## OR.village[7]       1.000       1.00
## OR.village[8]       1.026       1.10
## OR.village[9]       1.075       1.25
## OR.village[10]      1.002       1.01
## OR.village[11]      1.012       1.01
## OR.village[12]      1.029       1.10
## OR.village[13]      1.012       1.01
## OR.village[14]      1.001       1.01
## OR.village[15]      1.009       1.01
## OR.village[16]      1.001       1.01
## OR.village[17]      1.013       1.01
## OR.village[18]      1.000       1.00
## OR.village[19]      1.007       1.03
## OR.village[20]      1.001       1.00
## OR.village[21]      1.020       1.10
## OR.village[22]      1.010       1.05
## OR.village[23]      1.004       1.01
## OR.village[24]      1.001       1.01
## OR.village[25]      1.056       1.19
## PP.treated          1.000       1.00
## PP.untreated        1.102       1.30
## baseline.prev       1.058       1.24
## sigma               1.017       1.07
## 
## Multivariate psrf
## 
## 1.11</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical08021"></span>
<img src="bookdown_files/figure-html/BayesianPractical0802-1.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.11: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical08022"></span>
<img src="bookdown_files/figure-html/BayesianPractical0802-2.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.12: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical08023"></span>
<img src="bookdown_files/figure-html/BayesianPractical0802-3.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.13: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical08024"></span>
<img src="bookdown_files/figure-html/BayesianPractical0802-4.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.14: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BayesianPractical08025"></span>
<img src="bookdown_files/figure-html/BayesianPractical0802-5.png" alt="Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children." width="80%" />
<p class="caption">
圖 108.15: Gelman-Rubin convergence statistic of parameters for GLM about the odds of malaria regarding netbeds use in Gambia children.
</p>
</div>
<p>基本可以認爲刨除前1000次取樣 (burn-in) 可以達到收斂。</p>
<div class="sourceCode" id="cb1711"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1711-1" title="1"><span class="co"># Generate 50000 iterations</span></a>
<a class="sourceLine" id="cb1711-2" title="2"><span class="kw">modelUpdate</span>(<span class="dv">25000</span>)</a></code></pre></div>
<pre><code>## 25000 updates took 43 s</code></pre>
<div class="sourceCode" id="cb1713"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1713-1" title="1"><span class="co"># Summary Statistics</span></a>
<a class="sourceLine" id="cb1713-2" title="2">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">1001</span>)</a>
<a class="sourceLine" id="cb1713-3" title="3"><span class="kw">print</span>(sample.statistics)</a></code></pre></div>
<pre><code>##                  mean      sd  MC_error val2.5pc median val97.5pc start sample
## OR.age[2]      1.7920 0.43740 0.0023580  1.09300 1.7390    2.7900  1001  50000
## OR.age[3]      2.2810 0.54760 0.0031840  1.39800 2.2180    3.5320  1001  50000
## OR.age[4]      2.3520 0.56790 0.0032130  1.43500 2.2860    3.6420  1001  50000
## OR.bednet[2]   0.7323 0.20980 0.0020190  0.40520 0.7046    1.2160  1001  50000
## OR.bednet[3]   0.6442 0.24880 0.0023530  0.28980 0.6017    1.2450  1001  50000
## OR.bednet[4]   0.9136 0.35070 0.0034810  0.41700 0.8543    1.7670  1001  50000
## OR.green       0.9518 0.06135 0.0009845  0.83160 0.9513    1.0740  1001  50000
## OR.phc         0.7004 0.33980 0.0053690  0.25770 0.6360    1.5300  1001  50000
## OR.village[1]  2.7390 1.29800 0.0159400  1.07300 2.4710    6.0350  1001  50000
## OR.village[2]  1.2560 0.50340 0.0064470  0.55060 1.1650    2.4940  1001  50000
## OR.village[3]  1.3780 0.77670 0.0073130  0.43210 1.2040    3.3300  1001  50000
## OR.village[4]  0.7853 0.40550 0.0041650  0.25950 0.7020    1.8030  1001  50000
## OR.village[5]  1.3340 0.68630 0.0076610  0.46850 1.1900    3.0360  1001  50000
## OR.village[6]  1.0980 0.60200 0.0057480  0.34970 0.9671    2.5820  1001  50000
## OR.village[7]  3.3230 1.62700 0.0201700  1.26800 2.9780    7.4070  1001  50000
## OR.village[8]  0.4820 0.22640 0.0025300  0.17390 0.4393    1.0420  1001  50000
## OR.village[9]  0.2384 0.11800 0.0012410  0.07823 0.2159    0.5266  1001  50000
## OR.village[10] 1.0880 0.55770 0.0058250  0.37350 0.9712    2.4880  1001  50000
## OR.village[11] 0.7239 0.44150 0.0051660  0.19610 0.6225    1.8340  1001  50000
## OR.village[12] 2.0300 0.95950 0.0105800  0.76080 1.8340    4.4360  1001  50000
## OR.village[13] 1.7740 1.57700 0.0245200  0.31740 1.3760    5.5590  1001  50000
## OR.village[14] 0.7315 0.40040 0.0036680  0.22400 0.6454    1.7320  1001  50000
## OR.village[15] 0.3391 0.20680 0.0025810  0.08944 0.2929    0.8554  1001  50000
## OR.village[16] 0.6627 0.34430 0.0029900  0.20710 0.5924    1.5190  1001  50000
## OR.village[17] 1.3130 0.67130 0.0069450  0.45190 1.1710    3.0110  1001  50000
## OR.village[18] 4.3990 2.63200 0.0271600  1.45000 3.7630   11.1700  1001  50000
## OR.village[19] 0.9124 0.47030 0.0046900  0.30700 0.8149    2.0880  1001  50000
## OR.village[20] 1.3460 0.67480 0.0076280  0.49080 1.2050    3.0260  1001  50000
## OR.village[21] 2.7370 1.34100 0.0159800  1.04100 2.4530    6.1000  1001  50000
## OR.village[22] 1.0970 0.54730 0.0057850  0.39480 0.9828    2.4400  1001  50000
## OR.village[23] 1.1760 0.57610 0.0064560  0.43040 1.0580    2.5930  1001  50000
## OR.village[24] 0.3970 0.30360 0.0028640  0.07161 0.3203    1.1620  1001  50000
## OR.village[25] 2.5440 1.46200 0.0144900  0.82750 2.2020    6.2320  1001  50000
## PP.treated     0.6695 0.47040 0.0039280  0.00000 1.0000    1.0000  1001  50000
## PP.untreated   0.8944 0.30740 0.0022230  0.00000 1.0000    1.0000  1001  50000
## baseline.prev  0.3209 0.08472 0.0011590  0.17090 0.3148    0.5034  1001  50000
## sigma          0.9168 0.19010 0.0018350  0.60980 0.8945    1.3530  1001  50000</code></pre>
<div class="sourceCode" id="cb1715"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1715-1" title="1"><span class="kw">dicStats</span>()</a></code></pre></div>
<pre><code>##          Dbar  Dhat   DIC    pD
## MALARIA 367.6 341.7 393.6 25.94
## total   367.6 341.7 393.6 25.94</code></pre>
<p>從多層邏輯回歸分析的結果來看，每個變量的事後概率分佈的標準差都比無考慮村莊這一隨機效應時要大一些。這主要時因爲，多層回歸模型考慮了數據中村莊這個層面的過度離散效應(overdispersion)。但是整體的來說，每個比值比的含義並沒有發生太多改變。另外，村莊層級的隨機效應，其方差的事後均值爲 <code>0.9168</code>，這是相對高的過度離散效應的表現。DIC結果也比無隨機效應的邏輯回歸模型提升顯著 <code>469.3-&gt;393.6</code>。這也是村莊層級隨機效應十分顯著的證據之一。</p>
</div>
</div>
<div id="再訪-mcmc" class="section level1">
<h1><span class="header-section-number">第 109 章</span> 再訪 MCMC</h1>
<p>和我們之前在介紹MCMC(Markov Chain Monte Carlo)時 (Chapter <a href="#MCMC-methods"><strong>??</strong></a>)介紹過的那樣，大部分的統計模型其事後概率分佈的直接樣本 <span class="math inline">\(p(\theta|x)\)</span> 採集是十分困難的。但是我們可以使用間接的算法實施採樣過程。吉布斯樣本採集 (Chapter <a href="#Gibbs-sampling"><strong>??</strong></a>) 是<a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">美特羅波利斯-海斯廷斯(Metroplis-Hastings)算法(algorithm)</a>的特殊形態。本章我們來深入探討Metropolis-Hastings算法具體的實施過程是怎樣進行的。</p>
<div id="metropolis-hastings-algorithm" class="section level2">
<h2><span class="header-section-number">109.1</span> Metropolis-Hastings algorithm</h2>
<p>美特羅波利斯-海斯廷斯算法在歷史上爲統計學打開了一扇嶄新的大門。因爲它的發明，我們現在可以繞過複雜的微積分計算過程，對幾乎任何一種分佈實施樣本採集。這一種要算法的發明，不僅僅對於貝葉斯統計學來說是一個重大突破，同時也爲傳統的概率論統計學提供了強有力的算法。</p>
<p>具體的算法過程較爲複雜，我們可以不用完全掌握其所有細節，但是我們應該明白它的大致採集樣本的原理。理解了它的採樣原理，有助於我們實際操作時選取合適的參數(parameters)，從目標分佈中獲取品質優良的隨機樣本。它的基本原理框架是這樣的：</p>
<ol style="list-style-type: decimal">
<li>先從變量可能的取值樣本中，爲<span class="math inline">\(X_0\)</span>選取一個起始值 (starting value)，我們稱之爲“現在值 current” <span class="math inline">\((X_{t-1} = X_0)\)</span>；</li>
<li>以第一步選取的預測變量現在值爲條件 <span class="math inline">\(g(Y|X_{t-1})\)</span>，隨機設定一個候選變量(candidate <span class="math inline">\(Y_t\)</span>)的<strong>分佈</strong>，例如可以是典型的高斯（正態）分佈：<span class="math inline">\(Y_t \sim N(X_{t-1}, \sigma)\)</span>；</li>
<li>隨機從第二步設定的分佈中選取 <span class="math inline">\(Y_t\)</span> 作爲樣本 <span class="math inline">\((X_t)\)</span> 的第二個元素，同時滿足下面的概率關係：
<span class="math display">\[
P(X_t = Y_t) = min(1, \frac{P(Y_t|data)/g(Y_t|X_{t-1})}{P(X_{t-1}|data)/g(X_{t-1}|Y_t)}) 
\]</span></li>
<li>假設你沒有選擇 <span class="math inline">\(Y_t\)</span> 那麼 <span class="math inline">\(X_{t-1}\)</span> 會被重複選取作爲樣本的元素，<span class="math inline">\(X_t = X_{t-1}\)</span>；</li>
<li>回到第二步，然後進行下一個樣本(increase <span class="math inline">\(t\)</span> by 1)的採集。</li>
</ol>
<p>在上面的公式中， <span class="math inline">\(P(Y_t|data)\)</span>是利用指定（的先驗概率）分佈的概率密度方程(probability density function, pdf)中隨機選取的 <span class="math inline">\(Y_t\)</span> 計算獲得的概率。這個方程包含了一個很大概率我們人類無法計算的積分分母：<span class="math inline">\(\int P(data|\theta)P(\theta)\)</span>。(however, the method also works if we substitute any function proportional to the posterior because the proportionality constant will cancel out)但是在計算過程中如果我們用與該事後概率密度分佈成比例的方程將之替代掉，那麼這部分複雜的積分方程會由於成比例性最終同時在分子分母中被抹去。例如常用的是事後概率分佈密度方程的分子部分： <span class="math inline">\(f(Y_t) = P(data|Y_t)\times P(Y_t) \propto P(Y_t|data)\)</span>。另外，如果用於採集樣本的分佈 <span class="math inline">\(g\)</span> 是左右對稱的：<span class="math inline">\(g(Y_t|X_{t-1}) = g(X_{t-1}|Y_t)\)</span>，算法會簡化成爲 <strong>Metropolis</strong> 算法：</p>
<p><span class="math display">\[
P(X_t = Y_t) = min(1, \frac{f(Y_t)}{f(X_{t-1})})
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian0901"></span>
<img src="img/Metropolis-hastings.png" alt="Sampling with the Metropolis-Hastings algorithm" width="80%" />
<p class="caption">
圖 109.1: Sampling with the Metropolis-Hastings algorithm
</p>
</div>
</div>
<div id="適應階段-adaptive-phase" class="section level2">
<h2><span class="header-section-number">109.2</span> 適應階段 adaptive phase</h2>
</div>
</div>
<div id="貝葉斯和概率論的比較" class="section level1">
<h1><span class="header-section-number">第 110 章</span> 貝葉斯和概率論的比較</h1>
<blockquote>
<p>Bayesianisom provides advice about how you should change your degree of belief as you acquire new evidence.</p>
</blockquote>
<div id="兩種方法的不同點總覽" class="section level2">
<h2><span class="header-section-number">110.1</span> 兩種方法的不同點總覽</h2>
<p>嚴格來說，每個研究問題，都可以通過兩種統計學方法，要麼概率論手段，要麼貝葉斯思想，來描述及進行推斷。它們之間的不同，通過前面幾個章節的描述應該能夠切身體會得到：</p>
<ol style="list-style-type: decimal">
<li>貝葉斯思想利用的是事後概率分佈 <span class="math inline">\(p(\theta|y) \propto p(y|\theta)p(\theta)\)</span>；而傳統概率論統計學只需要使用其中的似然(likelihood)部分。</li>
<li>貝葉斯思想需要使用者把進行實驗之前，已經有的知識和背景總結成爲先驗概率分佈 (prior distribution, <span class="math inline">\(p(\theta)\)</span>)；而傳統概率論並無數學或者統計學的方案來考慮這些實驗進行之前已經有的背景知識，有的只是做完實驗之後，事後的討論，及對實驗結果的解讀，演繹時進行的描述。</li>
<li>貝葉斯思想一般是對噪音參數 (nuisance parameters) 進行取均值的做法；而傳統概率論是把這些參數也極大化 (maximise)。</li>
<li>貝葉斯統計學方法相對來說對計算能力要求較高，但是 MCMC 計算機模擬採樣過程使得現實中特別複雜的統計學模型也能變得直觀且易於獲得結果。</li>
</ol>
<p>下面我們來討論一下上面提到的這些不同點在常見的臨牀實驗，以及流行病學研究的統計學案例中如何啓示分析者作出選擇。</p>
</div>
<div id="亞組分析-subgroup-analysis" class="section level2">
<h2><span class="header-section-number">110.2</span> 亞組分析 subgroup analysis</h2>
<p>很常見的一種現象是，一些藥物的治療效果，在總體中被發現具有顯著性的療效，但是當分析人員把研究對象根據一些特徵進行分層分析之後，卻發現這種顯著療效只存在與一部分亞組對象中，（如男性中有療效，但是女性中沒有療效等類似的現象）。同時，交互作用分析的結果又提示說分層變量和療效之間並沒有有意義的交互作用 (while an interaction analysis reveals that the effect is not significantly different for men and women)。</p>
<p>例如，我們看這樣一個實際的例子，有一個臨牀實驗比較的是 sinvastatin 和安慰劑對患者血清膽固醇水平下降能力上的異同。實驗對象有男性也有女性，它們的共同點是(曾經)患有心絞痛，或者心肌梗塞。實驗組和對照組的五年死亡人數等數據總結如下：</p>
<div class="figure" style="text-align: center"><span id="fig:Bayesian1001"></span>
<img src="img/table10-1.png" alt="Five-year mortality for simvastatin vs. placebo trial." width="80%" />
<p class="caption">
圖 110.1: Five-year mortality for simvastatin vs. placebo trial.
</p>
</div>
<p>根據這個結果，就有人會提出尖銳的問題，到底女性患者是否應該使用該藥物來降低膽固醇？</p>
<ul>
<li>是。理由是總體（男女共同的）治療是有效果的，且交互作用並無提示療效有男女差異。</li>
<li>否。理由是分層分析結果現實女性中療效是無顯著意義的，並且還甚至可能有害 (RR &gt; 1)。</li>
</ul>
<p>如果使用貝葉斯思想來進行接下來的分析的話，貝葉斯統計學會要求給療效<span class="math inline">\(\times\)</span>性別這一代表交互作用的變量的回歸係數加上有信息的先驗概率分佈 (informative prior)，但是給其他的回歸係數以不含信息的先驗概率分佈 (non-informative priors on all the other parameters.)。這樣的一種方法，可以從男性結果中借來 (borrowing information from men) 一些療效信息，因爲顯然上面這個實驗中女性患者的數量很少，只有男性患者的不到三分之一人數。同時把模型中男性相對女性患者的信息量比重下調 (down-weighting information from men compared with information from women)。</p>
</div>
<div id="多重比較問題-multiple-comparisons" class="section level2">
<h2><span class="header-section-number">110.3</span> 多重比較問題 multiple comparisons</h2>
<p>臨牀實驗和流行病學研究同時都面對多重比較的問題。貝葉斯統計學方法提供了</p>

</div>
</div>



<div id="causal-languages-因果推斷的語法" class="section level1">
<h1><span class="header-section-number">第 111 章</span> Causal Languages 因果推斷的語法</h1>
<blockquote>
<p>All models are wrong, but some are useful.</p>
<p>— George E. P. Box</p>
</blockquote>
<div id="當我們在談論因果推斷的時候我們在談論什麼" class="section level2">
<h2><span class="header-section-number">111.1</span> 當我們在談論因果推斷的時候，我們在談論什麼？</h2>
<p>衆多的醫學研究，科研工作者們苦苦收集數據，都是爲了能夠給觀察到的現象作出<strong>因果關系的結論</strong>。研究者帶着的研究問題通常是:</p>
<ul>
<li>這個治療方案有沒有效果？</li>
<li>暴露在某種可能有害的因素中到底有沒有危險？</li>
<li>提出的新的衛生政策到底能不能解決實際的醫療問題？</li>
</ul>
<p>這些都是內在爲因果關系的設問。隨機對照實驗，之所以要隨機設計，且對其<strong>隨機性</strong>要求精準且苛刻，就是爲了一個能夠清晰可靠地作出因果關系的結論。在很多流行病學研究中，隨機設計可能因爲倫理因素不能使用。但每一個精心設計的實驗或者觀察性研究，其終極目的都是爲了解答暴露和結果之間到底有沒有因果關系這一設問。</p>
<p>這裏我們用 “因果推斷” 來命名一類 “專門以探尋因果關系爲目的的” 統計學方法。其與傳統的統計學方法最大的不同點在於因果推斷用一套<strong>正式的科學語言</strong>，來解釋現象中到底有沒有因果關系。</p>
<p>之所以發明這一套因果推斷專用的科學語言，有這樣幾個目的:</p>
<ol style="list-style-type: decimal">
<li>更清晰地描述，我們到底要估計的 (estimate) 是什麼。</li>
<li>更徹底地強調，因果推斷結論背後的統計學前提和假設。</li>
<li>建立在前兩條前提的基礎上，我們可以使用專門爲統計推斷設計的新的統計學技巧，達到爲因果推斷提供證據的目的。</li>
</ol>
<p>因果推斷包括三個部分:</p>
<ol style="list-style-type: decimal">
<li>清晰描述因果關系概念的正式科學語言 (causal language)。</li>
<li>因果關系示意圖 (causal diagram) – 清晰地展示研究者對變量之間存在的所有可能因果關系的假設，在實驗設計，和數據分析兩個階段都需要用到。</li>
<li>因果關系統計學方法 (causal inference methods) – 從獲得的數據中，用和傳統方法不同的假設，作出因果關系的推斷。</li>
</ol>
</div>
<div id="傳統的統計學方法" class="section level2">
<h2><span class="header-section-number">111.2</span> 傳統的統計學方法</h2>
<p>用一個簡單實例來理解傳統統計學方法實際上做的是什麼:</p>

<div class="example">
<span id="exm:16-ASM-Causal-infer-1" class="example"><strong>Example 111.1  </strong></span>臨牀上認爲，給有貧血的患者靜脈內補充鐵劑是進行髖關節置換手術 (hip replacement operation) 之前建議的手段。研究者收集了某個醫院 2009 年至 2014 年間接受髖關節置換手術且有貧血的患者數據。在這個研究中，暴露變量 (exposure) 是患者是否在術前接受了靜脈內鐵劑補充，結果變量是髖關節置換手術之後，患者是否存活時間達到 90 天及以上。其他同時收集的數據有: 年齡，性別，伴隨疾病 (心血管疾病，糖尿病，腎病)，手術過程中是否接受了外來血源的輸血，以及住院時間。
</div>

<div id="初步分析" class="section level3">
<h3><span class="header-section-number">111.2.1</span> 初步分析</h3>
<p>很多人第一步想到的，一定是先制作 2×2 的暴露 (FeIV) 和結果 (Death90) 的表格:</p>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="2">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Death90
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
0
</th>
<th style="text-align:center;">
1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="2">
FeIV
</td>
<td style="text-align:center;font-weight: bold;">
0
</td>
<td style="text-align:center;">
9206
</td>
<td style="text-align:center;">
376
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
1
</td>
<td style="text-align:center;">
7365
</td>
<td style="text-align:center;">
312
</td>
</tr>
</tbody>
</table>
<p>從這個四格表我們計算的初步對數比值比是: 0.04 (95% CI: -0.12, 0.19)。</p>
<p>請問在這個對數比值比的計算過程中，我們估計的到底是什麼？ 這裏的被估計量 (estimand) 是:</p>
<p><span class="math display">\[
\log \text{OR}_{Y|X} = \log\{\frac{\text{Pr}(Y=1 | X = 1)}{1- \text{Pr}(Y = 1|X = 1)}\} - \log\{\frac{\text{Pr}(Y=1 | X = 0)}{1- \text{Pr}(Y = 1|X = 0)}\}
\]</span></p>

<div class="definition">
<span id="def:estimand" class="definition"><strong>Definition 111.1  </strong></span><br>
1. Estimand (被估計量): 我們想要知道的到底是什麼，例如，英國人口中收縮期血壓的平均值，這是一個無法知道，但是肯定存在確定量的量 (unknown fixed quantity)。<br>
2. Estimator (估計量): 數據用來計算被估計量的某種<strong>方程</strong>，例如，隨機從街上找來100個人，測量他們的血壓，求出來的平均值，這是一個隨機變量 (random variable)，會隨着隨機挑選的樣本而變化。<br>
3. Estimate (估計): 給定數據下，計算獲得的具體的量，例如，我做了隨機抽取100名英國人血壓測量的實驗，獲得 130.4 mmHg 這個平均收縮期血壓的測量值，這是一個可以計算成爲已知的確定量 (known fixed quantity)。
</div>

</div>
<div id="混雜" class="section level3">
<h3><span class="header-section-number">111.2.2</span> 混雜</h3>
<p>我們知道，單純這樣簡單初步計算獲得的對數比值比，我們是無法對其作出因果關系的解釋的，因爲通常這樣的分析都忽略掉了潛在的混雜。在目前爲止我們學習過的傳統統計學方法中，混雜被我們粗略地定義成: “和暴露，結果兩個變量同時且獨立地相關，但是確定不存在在暴露和結果的因果通路上的變量 (associated with the exposure and independently associated with the outcome, without being on the causal pathway from exposure to outcome)”，下一章我們會看到，這其實是一個不能令人滿意的定義。</p>
<p>例如，可能之所以有些病人在髖關節置換術之前會被提供靜脈鐵劑支持，其原因不僅是貧血，還可能他們本身體質虛弱，年紀較大，或者是貧血得太嚴重，或者還有許多其他的並發症，那麼表面看起來靜脈鐵劑支持，和術後90天生存率沒有關系的對數比值比就成了一個表面現象。這些因素會混淆，甚至是掩蓋靜脈鐵劑可能對貧血患者的潛在保護作用。此時我們說初步分析的對數比值比被混雜偏倚所影響 (suffer from confounding bias)。(關於偏倚在統計推斷中的概念，滾回章節 <a href="#bias">10.2.1</a>。)</p>
<p>當我們說，初步分析的對數比值比被混雜偏倚影響，那麼其實是在說，我們心裏想要的那個被估計量 (estimand)，和實際計算中使用的被估計量是兩個不同的概念。我們心裏想要的那個–沒有被偏倚影響的–被估計量，是可以有因果關系的推論的。所以偏倚，就是一種漸進偏倚 (an asymptotic bias)，它是我們心裏想要的那個被估計量，和實際被用到的被估計量之間的差。</p>
</div>
<div id="以共變量爲條件-conditioning-on-covariates" class="section level3">
<h3><span class="header-section-number">111.2.3</span> 以共變量爲條件 conditioning on covariates</h3>
<p>對於混雜偏倚，常見的做法是要麼進行分層分析，或者直接丟到回歸模型中去做調整，這樣的做法，其實是把我們使用的被估計量從一個初步對數比值比，改成了一個條件對數比值比:</p>
<p><span class="math display">\[
\log\text{OR}_{Y|X\cdot C} = \log\{\frac{\text{Pr}(Y=1 | X = 1, \mathbf{C})}{1- \text{Pr}(Y = 1|X = 1, \mathbf{C})}\} - \log\{\frac{\text{Pr}(Y=1 | X = 0, \mathbf{C})}{1- \text{Pr}(Y = 1|X = 0, \mathbf{C})}\}
\]</span></p>
<p>其中，<span class="math inline">\(\mathbf{C}\)</span> 就是被調整的變量組成的向量。</p>
<p><strong>應該調整哪些變量？</strong></p>
<p>從簡單的理解來看，輸血與否，和住院時間長短，應該是處在暴露和結果兩個變量的因果通路之上的，所以不應該調整這兩個變量。所以，隨着這個思路，我們雖然不能調整輸血與否，和住院時間長短兩個變量，但是可以調整諸如年齡，性別，心血管疾病，糖尿病，腎病，貧血嚴重程度，和手術的種類等。</p>
<p>調整了上述變量之後，我們獲得的條件對數比值比 (conditional log-odds ratio) 是 -0.24 (95%CI -0.41, -0.07)。</p>
<p><strong>可以給予這個條件對數比值比以因果關系的解釋嗎？</strong></p>
<p>顯然，由於還有其他我們不知道的因素，可能混淆這裏的暴露和結果變量 (我們沒有收集)，所以此時漸進偏倚定義是上面的這個條件對數比值比和我們心裏那個真實想要測量的因果被估計量 (causal estimand) 之間的差:</p>
<p><span class="math display">\[
\log\text{OR}_{Y|X\cdot C} - \{ \text{True value of some causally -interpretable estimand} \}
\]</span></p>
<p>在哪些前提條件下，這個漸進偏倚可以被認爲等於零？此時我們需要因果推斷的科學定義和語言來幫助我們理解。</p>
</div>
</div>
<div id="更加正規的方法" class="section level2">
<h2><span class="header-section-number">111.3</span> 更加正規的方法</h2>
<div id="因果推斷使用的語言" class="section level3">
<h3><span class="header-section-number">111.3.1</span> 因果推斷使用的語言</h3>
<p><strong>概率與統計學</strong></p>
<p>概率論和統計學中使用的詞匯和語言，允許我們估計，描述很多觀察變量之間的聯合分布 (joint distribution)，例如均值，方差，協方差，四分位，回歸系數，相關系數等。</p>
<p>但是這一標準的統計學語言，卻無法描述這些聯合分布在受到外在影響或者幹預 (external intervention) 之後，會發生怎樣的變化。用這裏使用的例子來說就是，當所有患者都被提供了靜脈內鐵劑支持，(注意到這是和現實情況不一樣的)
患者的生存概率會是多少？</p>
<p>因果關系的思考，其實是在追問這樣一個問題: 當暴露變量 <span class="math inline">\(X\)</span>，可以改變，並且<strong>以與我們觀察到的相反的形式出現</strong>，那麼結果變量 <span class="math inline">\(Y\)</span> 會發生怎樣的變化？本書，我們使用 <span class="citation">(Neyman <a href="#ref-Neyman1923" role="doc-biblioref">1923</a>)</span> 當年創立，後來被 <span class="citation">(Rubin <a href="#ref-Rubin1974" role="doc-biblioref">1974</a>)</span> 發展的概念: 潛在結果框架 (potential outcome framework)。</p>

<div class="definition">
<span id="def:16-ASM-Causal-infer-3" class="definition"><strong>Definition 111.2  </strong></span><strong>潛在結果 Potential outcome</strong>: 定義 <span class="math inline">\(Y(x)\)</span> 爲當暴露變量 <span class="math inline">\(X\)</span> 取假設的值 (x) 時，結果變量的取值。
</div>

<p>對於一個而二分類暴露變量 <span class="math inline">\(X\)</span>，每個個體/研究對象，我們賦予它一個潛在的可能取值結果的概念: <span class="math inline">\(Y(0)\)</span> 和 <span class="math inline">\(Y(1)\)</span>。<span class="math inline">\(Y(0)\)</span> 的意思是當暴露變量是 <span class="math inline">\(0\)</span> 的時候該對象可能的取值，<span class="math inline">\(Y(1)\)</span> 的意思是當暴露變量是 <span class="math inline">\(1\)</span> 的時候，該對象可能的取值。但是，在現實情況下，我們只能觀察到二者中的一種結果。在我們的例題中，當一個患者真的接受了靜脈鐵劑補充，那麼他/她的觀察結果 <span class="math inline">\(Y = Y(1)\)</span>，也就是此時觀察結果等於暴露爲 <span class="math inline">\((1)\)</span> 時的潛在結果 <span class="math inline">\(Y(1)\)</span>。對與這個患者來說，他/她在沒有接受經脈鐵劑補充的情況下的另一種潛在結果 <span class="math inline">\(Y(0)\)</span> 是沒有被觀測到的。但是，這個患者的潛在結果 <span class="math inline">\(Y(0)\)</span>，表示的是他/她如果接受沒有接受靜脈鐵劑補充的話，他/她在90天時死亡/存活的<strong>潛在結果</strong>。</p>

<div class="definition">
<span id="def:16-ASM-Causal-infer-4" class="definition"><strong>Definition 111.3  </strong></span><strong>用潛在結果表示邊緣和條件因果對比 marginal and conditional causal contrast:</strong> <br>
邊緣對比: <span class="math display">\[E\{Y(1)\} - E\{ Y(0) \}\]</span>
條件對比: <span class="math display">\[E\{ Y(1) | \mathbf{V=v} \} - E\{ Y(0) | \mathbf{V=v} \}\]</span>
</div>

<p>這種潛在結果的統計框架，曾經被 <span class="citation">(Dawid <a href="#ref-Dawid2000" role="doc-biblioref">2000</a>)</span> 批判爲一種不恰當的方法。以爲潛在結果框架建議說存在另一個完全不存在的平行宇宙，使得觀察對象在一個空間裏做一件事，在另一個空間裏做一件相反的事情，看會發生怎樣的結果，這實際是在說存在這種潛在的完美聯合分布。另外，我們會在第四章中看見的，在潛在結果的框架下，我們可能問的問題是，當所有人都接受了暴露變量時，暴露和結果之間的因果效應的平均值:</p>
<p><span class="math display">\[
E\{ Y(1) - Y(0) | X = 1 \}
\]</span></p>
<p>潛在結果框架不是完美的。但是它非常實用:</p>
<ol style="list-style-type: decimal">
<li>使不確定性變得明確而清晰;</li>
<li>把研究的問題變得更加容易理解;</li>
<li>能夠保證研究者明確做因果推斷時的前提條件;</li>
<li>改善實驗設計;</li>
<li>有助於設計更能回答研究問題的統計分析方案;</li>
<li>可以給結果恰當的因果關系解釋。</li>
</ol>
<p>但是我們需要注意的是:</p>
<ol style="list-style-type: decimal">
<li>不要過度相信你做的因果推斷的前提假設是正確的 (over confidence in assumptions);</li>
<li>不要錯誤的解讀你的分析結果。</li>
</ol>
</div>
<div id="因果推斷的被估計量-causal-estimands" class="section level3">
<h3><span class="header-section-number">111.3.2</span> 因果推斷的被估計量 causal estimands</h3>
<p>於是，現在用這些重新定義過的名詞和語言，我們來描述 (二分類結果變量在) 因果推斷中的被估計量:</p>
<p>邊緣被估計量 (marginal estimands):</p>
<p><span class="math display">\[
\begin{aligned}
\text{Potential risk difference: } &amp; \text{Pr}\{Y(1) = 1| \mathbf{V=v}\} - \text{Pr}\{Y(0) = 1| \mathbf{V=v}\} \\
\text{Potential risk ratio: } &amp; \frac{\text{Pr}\{ Y(1) = 1 | \mathbf{V=v}\}}{\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\} } \\
\text{Potential log odds ratio: } &amp; \\
                \log[\frac{ \text{Pr}\{Y(1) = 1| \mathbf{V=v}\}}{1- \text{Pr}\{Y(1) = 1| \mathbf{V=v}\}}] &amp; - \log[\frac{\text{Pr}\{Y(0) = 1| \mathbf{V=v} \}}{1-\text{Pr}\{Y(0) = 1| \mathbf{V=v} \}}]
\end{aligned}
\]</span></p>
<p>條件被估計量:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Potential risk difference: } &amp; \text{Pr}\{Y(1) = 1\} - \text{Pr}\{Y(0) = 1\} \\
\text{Potential risk ratio: } &amp; \frac{\text{Pr}\{ Y(1) = 1 \}}{\text{Pr\{Y(0) = 1 \}}} \\
\text{Potential log odds ratio: } &amp; \\
                \log[\frac{ \text{Pr}\{Y(1) = 1\}}{1- \text{Pr}\{Y(1) = 1\}}] &amp; - \log[\frac{\text{Pr\{Y(0) = 1 \}}}{1-\text{Pr\{Y(0) = 1 \}}}]
\end{aligned}
\]</span></p>
</div>
<div id="鑑定因果推斷時的前提假設-assumptions-for-identification" class="section level3">
<h3><span class="header-section-number">111.3.3</span> 鑑定因果推斷時的前提假設 assumptions for identification</h3>
<ul>
<li><strong>無相互幹擾 no interference</strong></li>
</ul>
<p><span class="math inline">\(Y_i(x)\)</span> 表示的是，如果第 <span class="math inline">\(i\)</span> 個個體的暴露變量被設定爲 <span class="math inline">\(x\)</span> 時，結果變量的值。所以是 <span class="math inline">\(X_i\)</span> 被設定成爲 <span class="math inline">\(x (i = 1, \cdots, n)\)</span> 時， <span class="math inline">\(Y_i\)</span> 的潛在結果。此時，我們已經有了一個前提假設，那就是，潛在結果 <span class="math inline">\(Y_i\)</span>，和另一個個體的潛在暴露 <span class="math inline">\(X_j (j\neq i)\)</span> 是相互獨立的。這個前提被稱爲無相互幹擾前提。這個前提，在暴露變量是某些特殊情況 (如注射疫苗) 的情況下，是無法成立的。因爲人羣中如果有些人注射了疫苗，同樣也能保護那些沒有注射疫苗的人。</p>
<ul>
<li><strong>一致性 consistency</strong></li>
</ul>
<p><span class="math display">\[
X_i = x \Rightarrow Y_i = Y_i(x)
\]</span></p>
<p>一致性的含義是，對於某個觀察對象來說，他/她的暴露變量是 <span class="math inline">\(x\)</span> 時，觀測到的結果變量的觀測值 <span class="math inline">\(Y_i\)</span>，和在<strong>虛擬世界中</strong>，該觀察對象接受潛在 <span class="math inline">\((x)\)</span> 暴露變量時獲得的潛在結果 <span class="math inline">\(Y_i(x)\)</span>，是一樣的。更具體地說:</p>
<ol style="list-style-type: decimal">
<li>暴露變量的定義，要清晰明確。</li>
<li>爲了保持一致性，也就是在實際實驗中，如果暴露變量是 <span class="math inline">\(x\)</span>，那麼你觀察到的結果 <span class="math inline">\(Y\)</span>，必須和理論討論的虛擬世界中我們預想的那樣潛在變量 <span class="math inline">\((x)\)</span> 導致的潛在結果 <span class="math inline">\(Y(x)\)</span> 是相同的。</li>
</ol>
<p>在臨牀試驗的設定下，用本文一開始的靜脈鐵劑補充例子來說明就是，我們構築的潛在世界框架下的幹預手段 (靜脈鐵劑補充)，對患者起到的不論是積極的還是負面的作用，它的理論效果，和我們在實際現實世界中觀察到的對患者進行靜脈鐵劑補充起到的效果，是相同的。</p>
<p>在非臨牀試驗的設定下，一致性有許多值得探討的地方。假如，潛在暴露變量是體質指數 (BMI)，這時候的一致性前提就十分微妙。因爲能夠改變 BMI (運動，飲食，服藥，接受抽脂手術，吸煙，吸毒，甚至是截肢)，以及BMI變化導致的結果 (如心血管疾病) 途徑非常多。所以，當我們在這種觀察實驗的設定下，寫下某個潛在暴露量 X (BMI = 20) 時的潛在結果 Y 時，就必須把暴露變量達到 20 的特定條件指明才可以 (need to be clear under what sort of intervention we imagine that BMI is set to 20)。所以，在非臨牀試驗的觀察性研究中，如果探討的是類似 BMI 這樣的暴露變量，那麼在我們想象的平行世界中對BMI造成影響的因素將會和現實世界一樣是非常復雜的，單一的想象幹預，如抽脂手術，不可能滿足<strong>一致性</strong>的前提假設。所以，觀察對象的 BMI 達到 20 的條件，更加合理的是多種方法的組合 (it is more likely that the individuals in our observational study achieved their different BMI level through a combination of different ways.)，那麼在一致性的前提下，在那個我們想象出來的平行世界裏，潛在暴露 BMI 獲得的幹預，就是各種和 BMI 有關的所有變量。</p>
<ul>
<li><strong>條件可置換性 conditional exchangeability</strong></li>
</ul>
<p>第三個前提假設是條件可置換性:</p>
<p><span class="math display">\[
Y(x) \perp\perp X |\mathbf{C}, \forall x
\]</span></p>
<p><span class="math inline">\(\perp\perp\)</span> 表示條件獨立 (conditional independence)，所以 <span class="math inline">\(A\perp\perp B|C\)</span> 的正確讀法是: “在C的條件下，A條件獨立於B”。<span class="math inline">\(A\perp\perp B\)</span> 的意思就是， A 和 B 之間互爲 (邊際 marginally) 獨立。</p>
<p>在條件向量 <span class="math inline">\(\mathbf{C}\)</span> 的條件下，觀測對象的實際暴露狀況 <span class="math inline">\(X\)</span> 和他/她/它的所有潛在結果之間相互獨立。</p>
<p>我們可以把第三個前提條件設想爲: 潛在結果 <span class="math inline">\(Y(x)\)</span> 已經能夠把對象身上所有的和結果 <span class="math inline">\(Y\)</span> 相關的特點都包含進來，唯一不包含的是他/她/它在現實世界中的觀測暴露變量。也就是，如果我們知道潛在結果 <span class="math inline">\(Y(0), Y(1)\)</span>，且我們知道 <span class="math inline">\(X\)</span>，那麼我們就可以知道 Y，因爲 <span class="math inline">\(Y = XY(1) + (1-X) Y(0)\)</span>。</p>

<div class="example">
<span id="exm:16-ASM-Causal-infer-5" class="example"><strong>Example 111.2  </strong></span>還是靜脈鐵劑補充的例子，如果我們手裏拿到的數據如下表。一共只有24名患者，假定只有一個條件變量 C (貧血嚴重與否)，表格中羅列的是觀察變量 <span class="math inline">\(X,Y,C\)</span>，同時還羅列了兩個平行世界的潛在結果變量 <span class="math inline">\(Y(1), Y(0)\)</span>。這裏我們爲了解釋條件可置換性，我們先假裝真的可以獲得所有的潛在結果，實際情況下是不可能的。
</div>

<div style="border: 1px solid #ddd; padding: 0px; margin-left: auto; margin-right: auto;overflow-y: scroll; height:500px; overflow-x: scroll; width:400px; ">
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Patient ID
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
X
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Y
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
C
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Y(0)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
Y(1)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
17
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
0
</td>
</tr>
</tbody>
</table>
</div>
<p>在這個表格的數據中，我們注意到一致性的前提得到滿足，因爲對於每個 <span class="math inline">\(X=1\)</span> 的研究對象 <span class="math inline">\(Y = Y(1)\)</span>，對於每個 <span class="math inline">\(X=0\)</span> 的研究對象 <span class="math inline">\(Y=Y(0)\)</span>。</p>
<ul>
<li>邊際概率 marginal probability:</li>
</ul>
<p>接下來，第一步，假設我們的數據中沒有條件變量 C，我們來看看數據是否能滿足可置換性 (<span class="math inline">\(Y(0), Y(1)\)</span> 和 <span class="math inline">\(X\)</span> 互相獨立)。</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}\{ Y(0)=1|X=1 \} &amp;= \frac{2}{3}, \;\; \text{Pr}\{ Y(0)=1|X=0 \} = \frac{7}{12} \\
\text{Pr}\{ Y(1)=1|X=1 \} &amp;= \frac{5}{12}, \;\; \text{Pr}\{ Y(1)=1|X=0 \} = \frac{1}{3}
\end{aligned}
\]</span></p>
<p>這裏條件概率計算的結果告訴我們，邊際概率此時不具有可置換性，因爲潛在結果變量 <span class="math inline">\(Y(0) = 1\)</span> 的概率取決與 觀測暴露變量 <span class="math inline">\(X\)</span>。</p>
<ul>
<li>條件概率 conditional probability:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}\{ Y(0) = 1 | X=1, C=0\} &amp; = \frac{1}{2} \;\; \text{Pr}\{Y(0) = 1 | X=0, C=0 \} = \frac{1}{2}\\ 
\text{Pr}\{ Y(1) = 1 | X=1, C=0\} &amp; = \frac{1}{4} \;\; \text{Pr}\{ Y(1) = 1 | X=0, C=0\}  = \frac{1}{4} \\
\text{Pr}\{ Y(0) = 1 | X=1, C=1\} &amp; = \frac{3}{4} \;\; \text{Pr}\{ Y(0) = 1 | X=0, C=1\}  = \frac{3}{4} \\
\text{Pr}\{ Y(1) = 1 | X=1, C=1\} &amp; = \frac{1}{2} \;\; \text{Pr}\{ Y(1) = 1 | X=0, C=1\}  = \frac{1}{2} 
\end{aligned}
\]</span></p>
<p>在 C 條件下，我們發現這個時候 <span class="math inline">\(Y(0) = 1\)</span> 和 <span class="math inline">\(X\)</span> 之間相互獨立，<span class="math inline">\(Y(1) = 1\)</span> 也和 <span class="math inline">\(X\)</span> 之間相互獨立了。這就是條件可置換性的最直觀展示。</p>
</div>
<div id="鑑定-identification" class="section level3">
<h3><span class="header-section-number">111.3.4</span> 鑑定 identification</h3>
<p>假設 <span class="math inline">\(X,Y\)</span> 兩個變量都是二分類變量。我們關心他們二者之間的邊際因果危險度差:</p>
<p><span class="math display">\[
\text{Pr}\{ Y(1) = 1 \} - \text{Pr}\{ Y(0) = 1 \}
\]</span></p>
<p>假定，<strong>互相無幹擾前提成立</strong>，用 <span class="math inline">\(\mathbf{C}\)</span> 標記要被控制的混雜變量向量。用概率論的全概率法則，</p>
<p><span class="math display">\[
\text{Pr}\{ Y(x) = 1 \} = \sum_c \text{Pr}\{ Y(x) = 1|C=c \} \text{Pr}(C=c)
\]</span></p>
<p>假定，<strong>條件可置換的前提成立</strong>，那麼上面的式子可以變成</p>
<p><span class="math display">\[
\sum_c\text{Pr}\{ Y(x) =1 | X=x, C=c \}\text{Pr}(C = c)
\]</span></p>
<p>這是因爲條件可置換性告訴我們，在 C 的條件下，潛在結果 <span class="math inline">\(Y(x)\)</span> 和實際觀測的暴露變量值之間相互獨立，所以可以在上面條件概率公式的右半邊可以加入 <span class="math inline">\(X=x\)</span>。</p>
<p>假定，<strong>一致性的前提成立</strong>，那麼上面的式子有可以繼續變成</p>
<p><span class="math display">\[
\sum_c \text{Pr}\{ Y = 1 | X = x, C=c \}\text{Pr}(C=c)
\]</span></p>
<p>這是因爲一致性告訴我們，現實條件下 <span class="math inline">\(X=x\)</span> 時導致的結果變量 <span class="math inline">\(Y\)</span>， 和平行世界中的潛在暴露變量 <span class="math inline">\((x)\)</span> 導致導致的潛在結果 <span class="math inline">\(Y(x)\)</span> 相同。那麼，接下來就可以把編輯因果危險度差的式子推導成爲:</p>
<p><span class="math display" id="eq:Causal-infe-1-1">\[
\begin{aligned}
\text{Pr}\{ &amp; Y(1) = 1 \}  - \text{Pr}\{ Y(0) = 1 \} \\ 
                         &amp; = \sum_c\text{Pr}(Y=1 | X=1,C = c)\text{Pr}(C=c)  \\
                         &amp; \;\;\;\; -\sum_c\text{Pr}(Y=0 | X=1,C = c)\text{Pr}(C=c)
\end{aligned}
\tag{111.1}
\]</span></p>

<div class="definition">
<p><span id="def:16-ASM-Causal-infer-6" class="definition"><strong>Definition 111.4  </strong></span><strong>標準化和 g computation 公式</strong>:
<span class="math display">\[\text{Pr}\{ Y(x) = 1 \} = \sum_c\text{Pr}(Y=1|X=x,C=c)\text{Pr}(C=c)\]</span>
是我們在因果推斷中說的 g computation 公式的簡單例子。這個過程在流行病學中，被命名爲標準化 standardisation。所以，條件因果效應 (conditional causal effect):</p>
<p><span class="math display">\[\text{Pr}(Y=1 | X=1, C=c) - \text{Pr}(Y=1 | X=1, C=c)\]</span></p>
在這個 g computation 的過程中，被根據條件變量 C 在人羣衆的分布給標準化了。就是在這個根據條件變量的分布標準化 (或者叫邊際化 marginalisation) 的過程中，條件效應的含義華麗轉身變成了邊際因果效應 (marginal causal risk difference)。
</div>


<div class="definition">
<p><span id="def:16-ASM-Causal-infer-7" class="definition"><strong>Definition 111.5  </strong></span><strong>鑑定和估計 identification vs. estimation:</strong> 在因果推斷的語境中，鑑定過程和估計過程被嚴格區分。</p>
<p>鑑定 identification 指的是，因果被估計量利用因果推斷的假設把無法觀察的概率分布用可以觀察的數據的分布推導計算的過程。</p>
<p>估計 estimation 指的是，當我們對因果關系鑑定完畢之後，接下來進行的用實際觀察數據來估計被估計量的過程。這個過程通常不需要再進行公式推導，會使用統計模型，這些統計模型自己又自帶另外的一些前提假設。</p>
<p>所以，鑑定過程的前提假設是因果推斷的命根，最最底層的前提。接下來的數據計算或者模型擬合帶來的別的假設和鑑定過程的假設有本質的區別。區分這兩個過程的另一目的還包括鑑定過程的前提假設基本上是無法找到統計學方法進行檢驗的 (untestable structual assumptions) 結構性假設。</p>
<strong>對機器學習的一點點暗示:</strong>
在因果推斷中新興的一個重要話題 – 機器學習 (machine learning，或者叫做 data-adaptive estimation techniques 數據適應性估計技巧) 在當今大數據時代顯得特別突出。常有人認爲，數據適應性估計技巧可以用於預測，但是不能用於因果推斷。這其實只能是說對了一部分。機器學習本身，其實是在給定了 (一大堆) 變量之後，尋找某個變量的最佳預測量。但是從我們目前爲止在因果推斷中的推導來看，相信你也能看出來，因果推斷本身也包括了預測的過程。因果推斷的第一個部分 – 鑑定過程是處理的是因果之間的前提假設，以及判斷因果推斷中用到的參數怎樣和已觀察到的數據在這裏因果條件下連接起來 – 這個部分是不能放到機器中去的。但是因果推斷的第二部分 – 估計 – 就是純粹的預測過程啦。這裏想強調的是機器學習的方法，可以被用在因果推斷的第二部分，而不是第一部分。第一部分還是要由人來完成。<span class="citation">(Laan and Rose <a href="#ref-Laan2017" role="doc-biblioref">2017</a>)</span>
</div>


<div class="example">
<p><span id="exm:16-ASM-Causal-infer-8" class="example"><strong>Example 111.3  </strong></span>用前面的靜脈內鐵劑補充的24名患者數據來看，由於我們不切實際地假定了我們可以知道每個對象的所有潛在結果。所以，我們可以直接先用這個結果計算因果危險度差 (causal risk difference):</p>
<p><span class="math display">\[\text{Pr}\{Y(1) = 1\} - \text{Pr}\{ Y(0) =1 \} = \frac{9}{24} - \frac{15}{24} = -\frac{1}{4}\]</span></p>
<p>如果我們忽略掉患者貧血嚴重程度 C 的混雜效果，從觀察數據 X, Y, 計算獲得的粗危險度差 (crude risk difference) 就是</p>
<p><span class="math display">\[\text{Pr}(Y=1 | X=1) - \text{Pr}(Y=1|X=0) = \frac{5}{12} - \frac{7}{12} = -\frac{1}{6}\]</span></p>
<p>可見在這個例子中，忽略了貧血嚴重程度時，粗危險度差是往無效的方向偏倚的。但是其實那些被給予了靜脈內鐵劑補充支持的患者本身體質就弱，貧血就嚴重，粗危險度差的結果掩蓋掉了補充鐵劑對患者實際存在的保護作用。</p>
<p>當考慮了貧血嚴重程度時，我們知道，在前提條件條件可置換性和一致性成立時，我們可以用<a href="#eq:Causal-infe-1-1">(111.1)</a> 來進行因果危險度差的計算:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}\{ Y(1) = 1 \} &amp; - \text{Pr}\{ Y(0) = 1 \} \\
&amp; = \sum_{c=0}^1\text{Pr}(Y=1|X=1,C=c)\text{Pr}(C=c) \\ 
&amp; \;\;\; - \sum_{c=0}^1\text{Pr}(Y=1|X=0,C=c)\text{Pr}(C=c) \\
&amp; = \text{Pr}(Y=1|X=1,C=0)\text{Pr}(C=0) \\
&amp; \;\;\; + \text{Pr}(Y=1|X=1,C=1)\text{Pr}(C=1) \\ 
&amp; \;\;\; -  \text{Pr}(Y=1|X=0,C=0)\text{Pr}(C=0) \\
&amp; \;\;\; - \text{Pr}(Y=1|X=0,C=1)\text{Pr}(C=1) \\
&amp; = \frac{1}{4}\times\frac{1}{2} + \frac{1}{2}\times\frac{1}{2} - \frac{1}{2}\times\frac{1}{2} - \frac{3}{4}\times\frac{1}{2} \\
&amp; = -\frac{1}{4} \\
\end{aligned}
\]</span></p>
和前面計算的相吻合。
</div>

<p>當 C 是連續型變量時，<span class="math inline">\(\text{Pr}(C=c)\)</span> 變成關於 <span class="math inline">\(c\)</span> 的概率密度方程，加號就變成了積分符號:</p>
<p><span class="math display">\[
\text{Pr}\{ Y(x) = 1 \} = \int_c \text{Pr}\{ Y(x) = 1 | \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
\]</span></p>
<p>Where <span class="math inline">\(p_\mathbf{C}(\cdot)\)</span> is the joint probability density/mass function for <span class="math inline">\(\mathbf{C}\)</span>, <span class="math inline">\(\mu_\mathbf{C}(\mathbf{c})\)</span> is a dominating measure (Lebesque for continuous components of <span class="math inline">\(\mathbf{C}\)</span> and counting measure otherwise).</p>
<p>By conditional exchangeability, this can be rewritten as:</p>
<p><span class="math display">\[
\int_c \text{Pr}\{ Y(x) = 1 | X=x, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
\]</span></p>
<p>By consistency, this is</p>
<p><span class="math display">\[
\int_c \text{Pr}\{ Y = 1 | X=x, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
\]</span></p>
<p>Thus we have</p>
<p><span class="math display">\[
\text{Pr}\{ Y(x) = 1 \} - \text{Pr}\{ Y(0) = 1 \} \\
= \int_c \text{Pr}\{ Y = 1 | X=1, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) - \\
 \int_c \text{Pr}\{ Y = 1 | X=0, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
\]</span></p>
</div>
</div>
</div>
<div id="graphical-models-因果推斷的圖形模型" class="section level1">
<h1><span class="header-section-number">第 112 章</span> Graphical Models 因果推斷的圖形模型</h1>
<p>條件可置換性 (conditional exchangeability) 是因果推斷中最重要的前提假設。</p>
<p><span class="math display">\[
Y(x) \perp\perp X|\mathbf{C}, \forall x 
\]</span></p>
<p>當你的變量太多的時候，用圖形來表示變量之間的條件關系顯得十分直觀。有向無環圖 (Directed acyclic graphs, DAG) 就是能夠幫助我們理解變量之間條件獨立性關系的好工具。</p>
<div id="統計學中的有向無環圖" class="section level2">
<h2><span class="header-section-number">112.1</span> 統計學中的有向無環圖</h2>

<div class="definition">
<span id="def:16-ASM-Causal-infer-9" class="definition"><strong>Definition 112.1  </strong></span><strong>DAG</strong>, 是一種包括了多個節點 (nodes)，並且用箭頭直線連接這些節點的一種示意圖，值得注意的是，我們用的 DAG 示意圖中，沒有閉環 (也就是沒有哪個節點會隨着箭頭回到該節點本身成爲一個閉環，所以叫做有向無環圖)。且，DAG示意圖中也沒有雙向箭頭鏈接任何兩個節點。
</div>

<p>統計學中，DAG 用來表示一系列變量的聯合分布 (joint distribution)，它的箭頭指向表示了不同變量之間的向量關系。(DAGs are used to represent the factorisation of a joint distribution.) 如果一組變量組成向量 <span class="math inline">\(\mathbf{V}=(V_1, V_2, V_3, V_4, V_5, V_6)\)</span>，且這些變量之間的聯合分布關系是這樣子:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;p_\mathbf{V}(\mathbf{v}) = \\
&amp;\;p_{V_1}(v_1)p_{V_2}(v_2)p_{V_3|V_1,V_2}(v_3|v_1,v_2)p_{V_4|V_1,V_3}(v_4|v_1,v_3)p_{V_5|V_1,V_2}(v_5|v_1, v_2)p_{V_6|V_5}(v_6|v_5)
\end{aligned}
\]</span></p>
<p>那麼這些變量之間關系對應的 DAG 圖就是這樣子:</p>
<div class="sourceCode" id="cb1717"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1717-1" title="1">g &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&#39;dag {</span></a>
<a class="sourceLine" id="cb1717-2" title="2"><span class="st">    V6 [pos=&quot;2,0&quot;]</span></a>
<a class="sourceLine" id="cb1717-3" title="3"><span class="st">    V4 [pos=&quot;1,-1&quot;]</span></a>
<a class="sourceLine" id="cb1717-4" title="4"><span class="st">    V5 [pos=&quot;1,1&quot;]</span></a>
<a class="sourceLine" id="cb1717-5" title="5"><span class="st">    V2 [pos=&quot;-1,-1&quot;]</span></a>
<a class="sourceLine" id="cb1717-6" title="6"><span class="st">    V3 [pos=&quot;-1,1&quot;]   </span></a>
<a class="sourceLine" id="cb1717-7" title="7"><span class="st">    V1 [pos=&quot;-2,0&quot;]   </span></a>
<a class="sourceLine" id="cb1717-8" title="8"></a>
<a class="sourceLine" id="cb1717-9" title="9"><span class="st">   V1 -&gt; V4</span></a>
<a class="sourceLine" id="cb1717-10" title="10"><span class="st">   V1 -&gt; V5 -&gt; V6 </span></a>
<a class="sourceLine" id="cb1717-11" title="11"><span class="st">   V1 -&gt; V3 -&gt; V4 </span></a>
<a class="sourceLine" id="cb1717-12" title="12"><span class="st">   V2 -&gt; V3 -&gt; V4 </span></a>
<a class="sourceLine" id="cb1717-13" title="13"><span class="st">   V2 -&gt; V5 -&gt; V6</span></a>
<a class="sourceLine" id="cb1717-14" title="14"><span class="st">}&#39;</span>)</a>
<a class="sourceLine" id="cb1717-15" title="15"><span class="kw">plot</span>(g)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:DAG01"></span>
<img src="bookdown_files/figure-html/DAG01-1.png" alt="Example of a DAG" width="50%" />
<p class="caption">
圖 112.1: Example of a DAG
</p>
</div>
<p>上面長長的因子化 (factorisation) 公式可以簡略爲:</p>
<p><span class="math display">\[
p_{\mathbf{V}}(\mathbf{v}) = \prod_jp_{V_j|S_j}(v_j|s_j)
\]</span></p>
<p>其中 <span class="math inline">\(S_j\)</span> 是 <span class="math inline">\(V_j\)</span> 的子集，在DAG圖中，我們可以添加從 <span class="math inline">\(V_k\)</span> 到 <span class="math inline">\(V_j\)</span> 箭頭的充分且必要條件是 <span class="math inline">\(V_k \in \mathbf{S}_j\)</span>。</p>
<div id="dag-和條件獨立性-conditional-independence" class="section level3">
<h3><span class="header-section-number">112.1.1</span> DAG 和條件獨立性 conditional independence</h3>
<p>DAG 圖包含了變量之間的條件獨立性關系。如果 <span class="math inline">\(V_k\)</span> 到 <span class="math inline">\(V_j\)</span> 沒有箭頭，意味着這兩個變量在所有其他有指向 <span class="math inline">\(V_j\)</span> 箭頭的變量的條件下，互相獨立:</p>
<p><span class="math display">\[
V_4 \perp\perp V_2 | V_1, V_3
\]</span></p>
</div>
<div id="dag-圖的術語" class="section level3">
<h3><span class="header-section-number">112.1.2</span> DAG 圖的術語</h3>

<div class="definition">
<span id="def:16-ASM-Causal-infer-10" class="definition"><strong>Definition 112.2  </strong></span><strong>父與子 parent and child</strong>: <span class="math inline">\(V_i\rightarrow V_j\)</span>，那麼 <span class="math inline">\(V_i\)</span> 是 <span class="math inline">\(V_j\)</span> 的父，<span class="math inline">\(V_j\)</span> 是 <span class="math inline">\(V_i\)</span> 的子。圖<a href="#fig:DAG01">112.1</a>中 <span class="math inline">\(V_2\)</span> 是 <span class="math inline">\(V_5\)</span> 的父，<span class="math inline">\(V_5\)</span> 是 <span class="math inline">\(V_2\)</span> 的子。
</div>


<div class="definition">
<span id="def:16-ASM-Causal-infer-11" class="definition"><strong>Definition 112.3  </strong></span><strong>通路 path</strong>: 從節點 <span class="math inline">\(V_i\)</span> 到另一個節點 <span class="math inline">\(V_j\)</span> 如果可以用 DAG 箭頭 (方向可左可右) 從頭到尾連接起來，成爲一個通路。<span class="math inline">\(V_i, V_{k_1}, \cdots ,V_{k_n}, V_j\)</span> 之間如果有通路，那麼這個通路上的每兩個變量之間都有一個箭頭連接 (無論哪個方向)。圖 <a href="#fig:DAG01">112.1</a> 中 <span class="math inline">\(V_1\rightarrow V_3 \leftarrow V_2 \rightarrow V_5\)</span> 是一條從 <span class="math inline">\(V_1\)</span> 到 <span class="math inline">\(V_5\)</span> 的通路。
</div>


<div class="definition">
<span id="def:16-ASM-Causal-infer-12" class="definition"><strong>Definition 112.4  </strong></span><strong>有向通路 directed path</strong>: 從節點 <span class="math inline">\(V_i\)</span> 到節點 <span class="math inline">\(V_j\)</span> 之間如果有通路，且箭頭的方向只有從左往右，那麼這個通路被叫做有向通路。圖 <a href="#fig:DAG01">112.1</a> 中 <span class="math inline">\(V_1\rightarrow V_5 \rightarrow V_6\)</span> 是一條從 <span class="math inline">\(V_1\)</span> 到 <span class="math inline">\(V_6\)</span> 的有向通路。
</div>


<div class="definition">
<span id="def:16-ASM-Causal-infer-13" class="definition"><strong>Definition 112.5  </strong></span><strong>祖先與後代 ancestor and descendant</strong>: 如果 <span class="math inline">\(V_i\)</span> 和 <span class="math inline">\(V_j\)</span> 之間有一條有向通路，那麼我們說 <span class="math inline">\(V_i\)</span> 是 <span class="math inline">\(V_j\)</span> 的祖先，<span class="math inline">\(V_j\)</span> 是 <span class="math inline">\(V_i\)</span> 的後代。圖 <a href="#fig:DAG01">112.1</a> 中 <span class="math inline">\(V_2\)</span> 是 <span class="math inline">\(V_6/V_5\)</span> 的祖先，<span class="math inline">\(V_6/V_5\)</span> 是 <span class="math inline">\(V_2\)</span> 的後代。
</div>


<div class="definition">
<span id="def:16-ASM-Causal-infer-14" class="definition"><strong>Definition 112.6  </strong></span><strong>對撞因子 collider</strong>: 如果一條通路上的某個變量 <span class="math inline">\(V_{K_i}\)</span> 有左右兩個箭頭同時指向它本身，那麼<span class="math inline">\(V_{K_i}\)</span> 被叫做對撞因子。圖 <a href="#fig:DAG01">112.1</a> 中 <span class="math inline">\(V_1\rightarrow V_3 \leftarrow V_2\)</span>，的通路上 <span class="math inline">\(V_3\)</span> 是一個對撞因子。
</div>

</div>
<div id="阻斷通路-blocking-paths" class="section level3">
<h3><span class="header-section-number">112.1.3</span> 阻斷通路 blocking paths</h3>

<div class="definition">
<span id="def:16-ASM-Causal-infer-15" class="definition"><strong>Definition 112.7  </strong></span>當 <span class="math inline">\(\mathbf{Z}\in\mathbf{V}\)</span> 時，如果一條通路 <span class="math inline">\(p\)</span> 上存在一個節點 <span class="math inline">\(W\)</span> 滿足這兩個條件中的一個: (1) <span class="math inline">\(W\)</span> 是通路 <span class="math inline">\(p\)</span> 上的一個對撞因子，且 <span class="math inline">\(W\)</span> 和它的任何後代都 <span class="math inline">\(\notin \mathbf{Z}\)</span>。(2) <span class="math inline">\(W\)</span> 不是通路 <span class="math inline">\(p\)</span> 上的對撞因子，且 <span class="math inline">\(W\in\mathbf{Z}\)</span>。我們說 <span class="math inline">\(\mathbf{Z}\)</span> 阻斷了通路 <span class="math inline">\(p\)</span>。
</div>

</div>
<div id="以對撞因子爲條件-conditioning-on-a-collider" class="section level3">
<h3><span class="header-section-number">112.1.4</span> 以對撞因子爲條件 conditioning on a collider</h3>
<p>如下圖 <a href="#fig:DAG02">112.2</a> 所示，<span class="math inline">\(V_3\)</span> 取決於 <span class="math inline">\(V_1, V_2\)</span>，且 <span class="math inline">\(V_1, V_2\)</span> 互相獨立。那麼給定了 <span class="math inline">\(V_3\)</span> 之後 <span class="math inline">\(V_1, V_2\)</span> 其實就變成了條件依賴的關系 (conditionally dependent)。盡管 <span class="math inline">\(V_1, V_2\)</span> 這兩個變量之間是邊際獨立 (marginally independent) 的關系。</p>
<div class="figure" style="text-align: center"><span id="fig:DAG02"></span>
<img src="bookdown_files/figure-html/DAG02-1.png" alt="Conditioning on a collider" width="50%" />
<p class="caption">
圖 112.2: Conditioning on a collider
</p>
</div>
</div>
</div>
<div id="以非對撞銀子爲條件-conditioning-on-a-non-collider" class="section level2">
<h2><span class="header-section-number">112.2</span> 以非對撞銀子爲條件 conditioning on a non-collider</h2>
<p>如果 <span class="math inline">\(V_1,V_2\)</span> 同時取決於 <span class="math inline">\(V_3\)</span>:</p>
<div class="figure" style="text-align: center"><span id="fig:DAG03"></span>
<img src="bookdown_files/figure-html/DAG03-1.png" alt="Conditioning on a non-collider (1)" width="50%" />
<p class="caption">
圖 112.3: Conditioning on a non-collider (1)
</p>
</div>
<p>那麼此時 <span class="math inline">\(V_1,V_2\)</span> 的關系是邊際依賴 (marginally dependent)，但是以 <span class="math inline">\(V_3\)</span> 爲條件獨立 (conditionally independent)。</p>
<p>假設三個變量之間的關系又變成: <span class="math inline">\(V_3\)</span> 取決於 <span class="math inline">\(V_1\)</span>，<span class="math inline">\(V_2\)</span> 取決於 <span class="math inline">\(V_3\)</span>:</p>
<div class="figure" style="text-align: center"><span id="fig:DAG04"></span>
<img src="bookdown_files/figure-html/DAG04-1.png" alt="Conditioning on a non-collider (2)" width="50%" />
<p class="caption">
圖 112.4: Conditioning on a non-collider (2)
</p>
</div>
<p>類似地，此種情形底下， <span class="math inline">\(V_1,V_2\)</span> 的關系也是邊際依賴 (conditionally dependent)，但是以 <span class="math inline">\(V_3\)</span> 爲條件獨立 (conditionally independent)。</p>
<div id="條件的總結" class="section level3">
<h3><span class="header-section-number">112.2.1</span> 條件的總結</h3>
<ul>
<li>以 <span class="math inline">\(V_3\)</span> 爲條件會殺死 圖 <a href="#fig:DAG03">112.3</a> 和 <a href="#fig:DAG04">112.4</a> 中 <span class="math inline">\(V_1, V_2\)</span> 之間的關系;</li>
<li>以 <span class="math inline">\(V_3\)</span> 爲條件會創建 圖 <a href="#fig:DAG02">112.2</a> 中 <span class="math inline">\(V_1, V_2\)</span> 之間的關系;</li>
<li>以 <span class="math inline">\(V_3\)</span> 爲條件會阻斷 圖 <a href="#fig:DAG03">112.3</a> 和 <a href="#fig:DAG04">112.4</a> 中 <span class="math inline">\(V_1, V_2\)</span> 之間的關系;</li>
<li>以 <span class="math inline">\(V_3\)</span> 爲條件會解鎖 圖 <a href="#fig:DAG02">112.2</a> 中 <span class="math inline">\(V_1, V_2\)</span> 之間的關系。</li>
</ul>
</div>
<div id="d-分離-d-separation" class="section level3">
<h3><span class="header-section-number">112.2.2</span> D 分離 d-separation</h3>

<div class="definition">
<span id="def:16-ASM-Causal-infer-16" class="definition"><strong>Definition 112.8  </strong></span>一組變量組成的向量 <span class="math inline">\(\mathbf{V}\)</span>，如果它的三個沒有交集的子集向量 <span class="math inline">\(\mathbf{X,Y,Z}\)</span> 之間中的一個 <span class="math inline">\(\mathbf{Z}\)</span> 把 <span class="math inline">\(\mathbf{X}\)</span> 到 <span class="math inline">\(\mathbf{Y}\)</span> 的通路<strong>全部阻斷</strong> (block)，我們說 <span class="math inline">\(\mathbf{Z}\)</span> 把 <span class="math inline">\(\mathbf{X}\)</span> 中的任何一個節點到 <span class="math inline">\(\mathbf{Y}\)</span> 中任何一個節點 d 分離了 (d-seperate)。
</div>


<div class="example">
<p><span id="exm:16-ASM-Causal-infer-17" class="example"><strong>Example 112.1  </strong></span>圖 <a href="#fig:DAG04">112.4</a> 中，<span class="math inline">\(V_2\)</span> 是否阻斷了 <span class="math inline">\(V_3\)</span> 到 <span class="math inline">\(V_6\)</span> 的通路呢？</p>
<p>從 <span class="math inline">\(V_3\)</span> 到 <span class="math inline">\(V_6\)</span> 的通路一共有如下幾條:</p>
<p><span class="math display">\[
\begin{aligned}
1.&amp; V_3 \leftarrow V_1 \rightarrow V_5 \rightarrow V_6 \\
2.&amp; V_3 \leftarrow V_2 \rightarrow V_5 \rightarrow V_6 \\
3.&amp; V_3 \rightarrow V_4 \leftarrow V_1 \rightarrow V_5 \rightarrow V_6
\end{aligned}
\]</span></p>
其中，第 2,3 條通路，是被 <span class="math inline">\(V_2\)</span> 阻斷了的，但是第 1 條沒有被 <span class="math inline">\(V_2\)</span> 阻斷。
因此，我不能說 <span class="math inline">\(V_2\)</span> 把 <span class="math inline">\(V_3\)</span> 到 <span class="math inline">\(V_6\)</span> 之間的全部通路阻斷 (d-分離，d-separation)。
</div>

<div class="figure" style="text-align: center"><span id="fig:DAG05"></span>
<img src="bookdown_files/figure-html/DAG05-1.png" alt="Example of a DAG" width="50%" />
<p class="caption">
圖 112.5: Example of a DAG
</p>
</div>

<div class="theorem">
<p><span id="thm:16-ASM-Causal-infer-18" class="theorem"><strong>Theorem 112.1  </strong></span><strong>D分離和條件獨立性</strong>: 如果 <span class="math inline">\(\mathbf{X, Y, Z}\)</span> 之間互無交集，且 <span class="math inline">\(\mathbf{Z}\)</span> d 分離了從 <span class="math inline">\(\mathbf{X}\)</span> 到 <span class="math inline">\(\mathbf{Y}\)</span> 之間的所有通路那麼有:</p>
<span class="math display">\[\mathbf{X}\perp\perp\mathbf{Y|Z}\]</span>
</div>

<p>根據 D 分離的定義來看，通過 DAG 圖，可以直觀地分析一組變量和另一組變量在已第三組變量爲條件的基礎上通路的變化和變量之間的獨立性。以某組變量爲條件之後，很可能阻斷了某些通路的同時，又解鎖了某些通路，當殺死一些通路的同時，可能建立起其他變量之間的聯系。這是一個有內在邏輯聯系的關系網絡。</p>
<p>變量之間通路的打開，阻斷，d 分離過程，用手繪制當然可行，但是變量如果很多，這個過程就顯得太過於繁瑣，幸好我們已經有了完美的解決方案，可以使用<a href="www.dagitty.net">在線DAG工具: www.dagitty.net</a>。</p>
</div>
</div>
</div>
<div id="regression-methods-with-continuous-outcomes-結果變量爲連續型變量" class="section level1">
<h1><span class="header-section-number">第 113 章</span> Regression Methods with continuous outcomes 結果變量爲連續型變量</h1>
<div id="用於對連續型結果變量做因果推斷的被估計量" class="section level2">
<h2><span class="header-section-number">113.1</span> 用於對連續型結果變量做因果推斷的被估計量</h2>
<p>邊際潛在結果的差 marginal potential outcomes:</p>
<p><span class="math display">\[
E\{ Y(1) - Y(0) \}
\]</span></p>
<p>或者是條件下潛在結果的差 conditional potential outcomes:</p>
<p><span class="math display">\[
E\{ Y(1) - Y(2) | \mathbf{V = v} \}
\]</span></p>
<p>邊際潛在結果的差，有專門的名字: the <em>Average Causal Effect (ACE) 平均因果效應</em> 或者叫 <em>Average Treatment Effect 平均治療效應</em>。這裏的 “treatment” 其實不是特指治療，而是泛指所有我們想要比較的暴露。</p>
</div>
<div id="鑑定-identification---revision" class="section level2">
<h2><span class="header-section-number">113.2</span> 鑑定 identification - revision</h2>
<div id="條件因果均差-conditional-causal-mean-difference" class="section level3">
<h3><span class="header-section-number">113.2.1</span> 條件因果均差 conditional causal mean difference</h3>
<p><span class="math display">\[
\begin{aligned}
E\{ Y(1) - Y(0) | \mathbf{C = c} \} &amp; =  E\{ Y(1) | \mathbf{C=c} \} - E\{ Y(0) | \mathbf{C=c} \} \\
 \text{(By} &amp; \text{ conditional exchangeability given } \mathbf{C}:) \\
&amp;= E\{  Y(1) | X = 1, \mathbf{C=c} \} - E\{  Y(0) | X = 0, \mathbf{C=c} \}  \\
 \text{(By} &amp; \text{ consistency:)} \\ 
&amp; =   E\{  Y | X = 1, \mathbf{C=c} \} - E\{  Y | X = 0, \mathbf{C=c} \}  \\
\end{aligned}
\]</span></p>
</div>
<div id="簡單分類型條件變量-c-的-ace" class="section level3">
<h3><span class="header-section-number">113.2.2</span> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</h3>
<p><span class="math display" id="eq:causalinfer3-2">\[
\begin{aligned}
E\{ Y(1) - Y(0)\}  &amp; = \sum_cE\{ Y(1) | C=c \}\text{Pr}(C = c) - \sum_c E\{ Y(0) | C=c \}\text{Pr}(C=c) \\
 \text{(By} &amp; \text{ the law of total probability }\uparrow) \\ 
&amp; =  \sum_cE\{  Y(1) | X = 1, \mathbf{C=c} \}\text{Pr}(C=c) \\
&amp; \;\;\;\;\;\;\;\;\;- \sum_cE\{  Y(0) | X = 0, \mathbf{C=c} \} \text{Pr}(C = c) \\
 \text{(By} &amp; \text{ conditional exchangeability }\uparrow) \\
&amp; = \sum_cE\{  Y | X = 1, \mathbf{C=c} \}\text{Pr}(C=c) \\ 
&amp; \;\;\;\;\;\;\;\;\;- \sum_cE\{  Y | X = 0, \mathbf{C=c} \} \text{Pr}(C = c) \\
 \text{(By} &amp; \text{ consistency }\uparrow) \\ 
&amp; = \sum_c\{ E(Y|X = 1, C=c) -E(Y|X=0, C=c) \}\text{Pr}(C=c)
\end{aligned}
\tag{113.1}
\]</span></p>
</div>
<div id="簡單連續型條件變量-c-的ace" class="section level3">
<h3><span class="header-section-number">113.2.3</span> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</h3>
<p><span class="math display" id="eq:causalinfer3-3">\[
\begin{aligned}
E\{ Y(1) - Y(0)\}  &amp; = \int_cE\{ Y(1) | C=c \}f_C(c)\text{d}c - \int_c E\{ Y(0) | C=c \}f_C(c)\text{d}c \\
&amp; =  \int_cE\{  Y(1) | X = 1, \mathbf{C=c} \}f_C(c)\text{d}c \\ 
 &amp; \;\;\;\;\;\;\;\;\;- \int_cE\{  Y(0) | X = 0, \mathbf{C=c} \} f_C(c)\text{d}c \\
&amp; = \int_cE\{  Y | X = 1, \mathbf{C=c} \}f_C(c)\text{d}c \\
&amp; \;\;\;\;\;\;\;\;\;- \int_cE\{  Y | X = 0, \mathbf{C=c} \} f_C(c)\text{d}c \\
&amp; = \int_c\{ E(Y|X = 1, C=c) -E(Y|X=0, C=c) \}f_C(c)\text{d}c
\end{aligned}
\tag{113.2}
\]</span></p>
</div>
</div>
<div id="通過線性回歸模型來估計-ace" class="section level2">
<h2><span class="header-section-number">113.3</span> 通過線性回歸模型來估計 ACE</h2>
<div id="條件因果均值差" class="section level3">
<h3><span class="header-section-number">113.3.1</span> 條件因果均值差</h3>
<p>假設<span class="math inline">\(Y,X\)</span>分別表示結果變量和暴露變量，有三個變量需要調整 (做爲條件變量): <span class="math inline">\(C_1\)</span> 連續型，<span class="math inline">\(C_2\)</span> 二分類型(0/1)，<span class="math inline">\(C_3\)</span> 分類型(0/1/2/3)，然後我們擬合的線性回歸模型如下:</p>
<p><span class="math display" id="eq:causalinfer3-4">\[
\begin{aligned}
E(Y|X = x, C_1 = c_1, C_2 = c_2, C_3 = c_3) &amp; = \alpha + \beta_Xx + \gamma_{C_1}c_1 + \gamma_{C_2}c_2 \\
 \;\;\; +\gamma_{C_{31}}I(c_3 =1)+&amp;\gamma_{C_{32}}I(c_3 =2)+\gamma_{C_{33}}I(c_3 =3)
\end{aligned}
\tag{113.3}
\]</span></p>
<p>如果，<strong>無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability</strong>三個最主要的前提條件得到滿足，加上，公式 <a href="#eq:causalinfer3-4">(113.3)</a> 中三個條件變量得到了正確的模型敘述 (specification of the model is correct)。那麼，這個模型估計的回歸系數 <span class="math inline">\(\beta_Xx\)</span> 就可以被賦予因果關系的解讀:</p>
<p><span class="math display">\[
E\{ Y(1) -Y(0) |\mathbf{C=c}\}
\]</span></p>

<div class="example">
<span id="exm:16-ASM-Causal-infer-19" class="example"><strong>Example 113.1  </strong></span><strong>孕期吸煙和嬰兒出生體重的關系</strong>: 數據來自<span class="citation">(Cattaneo <a href="#ref-Cattaneo2010d" role="doc-biblioref">2010</a>)</span>
結果變量是出生體重 <code>bweight</code>，暴露變量是孕期母親是否吸煙 <code>mbsmoke</code>。這裏先只考慮3個條件變量: 懷孕時的年齡 <code>mage</code>，嬰兒是否是該母親的第一個孩子 <code>fbaby</code>，三個懷孕階段中，該母親第一次訪問婦產科醫生的時間段 <code>prenatal</code>，那麼我們可以擬合的最簡單模型其實是這樣的:
</div>

<div class="sourceCode" id="cb1718"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1718-1" title="1">cattaneo2 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/cattaneo2.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1718-2" title="2">Cat_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke) <span class="op">+</span><span class="st"> </span>mage <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(fbaby) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(prenatal), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1718-3" title="3"><span class="kw">summary</span>(Cat_mod)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bweight ~ as.factor(mbsmoke) + mage + as.factor(fbaby) + 
##     as.factor(prenatal), data = cattaneo2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3062.28  -308.27    28.87   354.08  2000.92 
## 
## Coefficients:
##                       Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)          2735.8442    78.2260  34.9736 &lt; 2.2e-16 ***
## as.factor(mbsmoke)1  -252.2599    21.5677 -11.6962 &lt; 2.2e-16 ***
## mage                    5.2681     1.6146   3.2627 0.0011114 ** 
## as.factor(fbaby)1     -59.9184    17.7004  -3.3851 0.0007173 ***
## as.factor(prenatal)1  578.8464    68.5077   8.4494 &lt; 2.2e-16 ***
## as.factor(prenatal)2  534.2280    70.6032   7.5666 4.592e-14 ***
## as.factor(prenatal)3  458.5222    80.9992   5.6608 1.597e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 562.03 on 4635 degrees of freedom
## Multiple R-squared:  0.0584, Adjusted R-squared:  0.057181 
## F-statistic: 47.912 on 6 and 4635 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>在<strong>無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability，和該模型是正確模型</strong>的前提下，線性回歸的結果 <code>-252.26</code> 可以被賦予因果推斷的解釋: <strong>在懷孕年齡，嬰兒是否是第一胎，第一次訪問婦產科醫生的孕期時期都相同的條件下，如果比較一個懷孕母親全部都在吸煙，和另一個懷孕母親全部都沒有在吸煙的兩個潛在世界，孕期吸煙的世界的母親生的嬰兒平均出生體重比另一個全部都不吸煙的母親生的嬰兒的出生體重輕 252.3 克。且在我們擬合的模型中，認爲這個新生兒體重的差在其他條件變量取任何值時都保持不變。</strong></p>
<p><strong>模型是正確的</strong>這個前提其實是可以放寬的，因爲你可能會擬合這樣一個線性回歸模型:</p>
<div class="sourceCode" id="cb1720"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1720-1" title="1">Cat_mod2 &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke) <span class="op">+</span><span class="st"> </span>mage <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mage<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(fbaby)<span class="op">*</span><span class="kw">as.factor</span>(prenatal), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1720-2" title="2"><span class="kw">summary</span>(Cat_mod2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bweight ~ as.factor(mbsmoke) + mage + I(mage^2) + 
##     as.factor(fbaby) * as.factor(prenatal), data = cattaneo2)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3081.576  -307.339    31.472   350.836  2022.096 
## 
## Coefficients:
##                                          Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)                            2265.09914  174.11509  13.0092 &lt; 2.2e-16 ***
## as.factor(mbsmoke)1                    -251.54047   21.58407 -11.6540 &lt; 2.2e-16 ***
## mage                                     32.66383   11.70667   2.7902 0.0052893 ** 
## I(mage^2)                                -0.50575    0.21294  -2.3751 0.0175863 *  
## as.factor(fbaby)1                       409.55446  153.91082   2.6610 0.0078181 ** 
## as.factor(prenatal)1                    689.11361   79.41616   8.6772 &lt; 2.2e-16 ***
## as.factor(prenatal)2                    684.61449   82.81672   8.2666 &lt; 2.2e-16 ***
## as.factor(prenatal)3                    555.06907   95.65524   5.8028 6.956e-09 ***
## as.factor(fbaby)1:as.factor(prenatal)1 -460.27080  154.79291  -2.9735 0.0029598 ** 
## as.factor(fbaby)1:as.factor(prenatal)2 -538.85385  159.42416  -3.3800 0.0007308 ***
## as.factor(fbaby)1:as.factor(prenatal)3 -393.84997  180.50617  -2.1819 0.0291656 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 561.14 on 4631 degrees of freedom
## Multiple R-squared:  0.062187,   Adjusted R-squared:  0.060162 
## F-statistic: 30.709 on 10 and 4631 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>這個模型裏，我們給懷孕時年齡擬合了二次項，又允許 <code>fbaby</code> 和 <code>prenatal</code> 之間有交互作用，但是，這並不妨礙我們對我們最關心的因果關系 <code>mbsmke</code> 的回歸系數的解讀，因爲這兩個模型的結果基本沒有差別。</p>
<p>還有別人可能給出的模型是這樣的:</p>
<div class="sourceCode" id="cb1722"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1722-1" title="1">Cat_mod3 &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke)<span class="op">*</span><span class="kw">as.factor</span>(fbaby) <span class="op">+</span><span class="st"> </span>mage <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mage<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(prenatal), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1722-2" title="2"><span class="kw">summary</span>(Cat_mod3)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bweight ~ as.factor(mbsmoke) * as.factor(fbaby) + 
##     mage + I(mage^2) + as.factor(prenatal), data = cattaneo2)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3067.913  -309.329    23.246   349.241  2010.918 
## 
## Coefficients:
##                                         Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)                           2370.45016  167.13049  14.1832 &lt; 2.2e-16 ***
## as.factor(mbsmoke)1                   -304.70729   27.49473 -11.0824 &lt; 2.2e-16 ***
## as.factor(fbaby)1                      -77.54831   19.35568  -4.0065 6.260e-05 ***
## mage                                    35.28829   11.62801   3.0348  0.002421 ** 
## I(mage^2)                               -0.55192    0.21169  -2.6073  0.009156 ** 
## as.factor(prenatal)1                   559.64429   68.58918   8.1594 4.298e-16 ***
## as.factor(prenatal)2                   525.31989   70.55368   7.4457 1.144e-13 ***
## as.factor(prenatal)3                   455.26790   80.89765   5.6277 1.934e-08 ***
## as.factor(mbsmoke)1:as.factor(fbaby)1  132.78365   43.73770   3.0359  0.002411 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 561.23 on 4633 degrees of freedom
## Multiple R-squared:  0.061474,   Adjusted R-squared:  0.059853 
## F-statistic: 37.933 on 8 and 4633 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>模型 <code>Cat_mod3</code> 中，<code>mbsmoke</code> 和新生兒體重之間的因果關系的解釋發生了變化，因爲我們對 <code>mbsmoke</code> 和 <code>fbaby</code> 之間的交互作用進行了檢驗，是有意義的 <code>p = 0.0024*</code>。這時候，在<strong>無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability，和該模型是正確模型</strong>的前提下，且模型 <code>Cat_mod3</code> 是正確的話，數據中的因果關系解釋及就不止一個了: <code>-304.71</code> 的條件因果關系均差 (conditional causal mean difference) 是針對那些已經有過孩子媽媽來說的; <code>-304.71 + 132.784 = -171.9</code> 這一條件因果關系均差 (conditional causal mean difference) 是對那些第一次懷孕當媽媽的人來說的。吸煙這個本來應該十分有害的行爲，對新生兒體重的影響因果關系似乎在第一次當媽媽的人當中影響較小 (這個因果關系陳述以相同懷孕年齡，和有相同的第一次訪問產科醫生時期爲前提)。</p>
</div>
<div id="效應修正-effect-modification-和-交互作用-interaction" class="section level3">
<h3><span class="header-section-number">113.3.2</span> 效應修正 effect modification 和 交互作用 interaction</h3>
<p>在上文中模型 <code>Cat_mod3</code> 中，如果模型是正確的，且無互相幹擾，一致性，條件可置換性前提都得到滿足時，嬰兒是否是第一胎 <code>fbaby</code> 這一變量，對於我們研究的暴露變量 <code>mbsmoke</code> (孕期吸煙) 和結果變量 <code>bweight</code> (新生兒體重) 之間的關系起到了效應修正作用 (effect modification)。因爲我們看到該模型的結果是孕期吸煙對新生兒體重的影響因爲嬰兒是否是第一胎而發生了很大的變化。流行病學中把這個稱爲交互作用 (interaction)。但是，在因果推斷的研究領域中，傾向於把效應修正和交互作用加以區分。效應修正指對我們關心的關系造成效應修正的變量本身，並沒有因果關系的解釋 (effect modification is not causal with respect to the second variable)，<strong>對因果關系造成了效應修正的變量本身，沒有“無互相幹擾，一致性，條件可置換性”前提的要求</strong>。它只是衆多的條件變量之一。</p>
<p><strong>相反，因果推斷的研究中，把交互作用的專有名詞保留給兩個暴露變量之間，也就是發生了交互作用的兩個變量，都是要研究的暴露變量，都有和結果變量之間因果關系的討論，所以兩個發生了交互作用的暴露變量，都需要滿足“無互相幹擾，一致性，條件可置換性”前提。</strong></p>
<p>假如不光研究孕期吸煙，研究者還想一起研究孕期飲酒習慣 <span class="math inline">\((X_2)\)</span>，和吸煙習慣 <span class="math inline">\((X_1)\)</span> 共同對新生兒體重的因果關系影響:</p>
<p><span class="math display">\[
\{ X_1, X_2 \} \perp\perp Y(x_1, x_2) | \mathbf{C}, \forall x_1,x_2
\]</span></p>
<p>所以，只有當暴露變量有兩個時 (因爲要同時對飲酒習慣和吸煙習慣兩個暴露變量做潛在結果分析 potential outcome)，才會用到交互作用 (interaction)。</p>
</div>
<div id="分類型條件變量的平均因果效應-ace" class="section level3">
<h3><span class="header-section-number">113.3.3</span> 分類型條件變量的平均因果效應 (ACE)</h3>
<p>Average Causal Effect (ACE) 平均因果效應:</p>
<p><span class="math display">\[
E\{ Y(1) - Y(0) \}
\]</span></p>
<p>在只有一個分類型條件變量的情況下，我們推導過其 ACE (See equations: <a href="#eq:causalinfer3-2">(113.1)</a>):</p>
<p><span class="math display">\[
\sum_c\{ E(Y|X=1, C=c) - E(Y|X=0, C=c) \}\text{Pr}(C=c)
\]</span></p>
<p>假設分類條件變量 <span class="math inline">\(C\)</span> 有四個水平 <span class="math inline">\(0/1/2/3\)</span>，那麼我們可以針對 <span class="math inline">\(C\)</span> 的每一層水平擬合線性回歸模型:</p>
<p><span class="math display" id="eq:CI-3-5">\[
\begin{aligned}
E(Y|X=x, C=c) &amp; = \alpha + \beta_0 x + \gamma_1 I(c=1) + \gamma_2 I(c=2) + \gamma_3 I(c=3) \\
&amp; \;\;\; + \beta_1 xI(c = 1) + \beta_2 x I(c=2)  + \beta_3 x I (c=3)
\end{aligned}
\tag{113.4}
\]</span></p>
<p>模型 <a href="#eq:CI-3-5">(113.4)</a> 是一個飽和模型，因爲 X 和 C 之間一共只有四種分組組合，我們又擬合了一個含有 8 個參數的模型。也就是說，這個模型允許這 8 種 X 和 C 之間的分組，每組都有不同的結果。</p>
<p><span class="math display">\[
\begin{aligned}
          \beta_0 &amp; = E(Y|X=1,C=0) - E(Y|X=0, C=0) \\
\beta_0 + \beta_1 &amp; = E(Y|X=1,C=1) - E(Y|X=0, C=1) \\
\beta_0 + \beta_2 &amp; = E(Y|X=1,C=2) - E(Y|X=0, C=2) \\
\beta_0 + \beta_3 &amp; = E(Y|X=1,C=3) - E(Y|X=0, C=3) \\
\end{aligned}
\]</span></p>
<p>爲了簡便起見，給他們分別命名:</p>
<p><span class="math display">\[
\begin{aligned}
\beta_0 &amp; = \eta_0 \\
\beta_0 + \beta_1 &amp; = \eta_1 \\
\beta_0 + \beta_2 &amp; = \eta_2 \\
\beta_0 + \beta_3 &amp; = \eta_3
\end{aligned}
\]</span></p>
<p>在只有一個分類型條件變量時，當無相互幹擾，一致性，和條件可置換性的前提被滿足，我們可以把公式 <a href="#eq:causalinfer3-2">(113.1)</a> 中的 <span class="math inline">\(E(Y|X=1, C=c) - E(Y|X=0, c=c)\)</span> 全部替換成爲 <span class="math inline">\(\eta_c\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
E\{ Y(1) - Y(0) \} &amp; = \sum_c\{ E(Y|X=1, C=c) - E(Y|X=0, c=c)\}\text{Pr}(C = c) \\
&amp; = \sum_c \eta_c \text{Pr}(C=c)
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb1724"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1724-1" title="1">Cat_mod4 &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke)<span class="op">*</span><span class="kw">as.factor</span>(prenatal), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1724-2" title="2"><span class="kw">summary</span>(Cat_mod4)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bweight ~ as.factor(mbsmoke) * as.factor(prenatal), 
##     data = cattaneo2)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3095.789  -313.854    23.211   360.458  2064.211 
## 
## Coefficients:
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2864.605     85.970 33.3210 &lt; 2.2e-16 ***
## as.factor(mbsmoke)1                      -317.160    138.425 -2.2912    0.0220 *  
## as.factor(prenatal)1                      571.184     86.560  6.5987 4.612e-11 ***
## as.factor(prenatal)2                      478.303     89.535  5.3421 9.628e-08 ***
## as.factor(prenatal)3                      428.609    102.354  4.1875 2.873e-05 ***
## as.factor(mbsmoke)1:as.factor(prenatal)1   35.913    140.700  0.2552    0.7985    
## as.factor(mbsmoke)1:as.factor(prenatal)2  163.470    146.522  1.1157    0.2646    
## as.factor(mbsmoke)1:as.factor(prenatal)3   87.177    168.400  0.5177    0.6047    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 563.74 on 4634 degrees of freedom
## Multiple R-squared:  0.052846,   Adjusted R-squared:  0.051415 
## F-statistic: 36.936 on 7 and 4634 DF,  p-value: &lt; 2.22e-16</code></pre>
<p><span class="math display">\[
\begin{aligned}
\widehat{\eta_0} &amp; = -317.2 \\
\widehat{\eta_1} &amp; = -317.2 + 35.9 = -281.2 \\
\widehat{\eta_2} &amp; = -317.2 + 163.5 = -153.7\\
\widehat{\eta_3} &amp; = -317.2 + 87.2 = -230.0 \\
\end{aligned}
\]</span></p>
<p>爲了估計平均因果效應，我們還需要 <code>prenatal</code> 的分布概率:</p>
<div class="sourceCode" id="cb1726"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1726-1" title="1"><span class="kw">with</span>(cattaneo2, <span class="kw">tab1</span>(prenatal, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>## prenatal : 
##         Frequency Percent Cum. percent
## 0              70     1.5          1.5
## 1            3720    80.1         81.6
## 2             697    15.0         96.7
## 3             155     3.3        100.0
##   Total      4642   100.0        100.0</code></pre>
<p>所以:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{ACE} &amp; = \sum_c \widehat{\eta_c}\widehat{\text{Pr}}(C=c) \\
&amp; = -317.2 \times \frac{70}{4642} -281.2\times\frac{3720}{4642} -153.7\times\frac{697}{4642}-230.0\times\frac{155}{4642} \\
&amp; = -260.9
\end{aligned}
\]</span></p>
</div>
<div id="positivity-非零性" class="section level3">
<h3><span class="header-section-number">113.3.4</span> Positivity 非零性</h3>
<p>當我們用下面的飽和模型的時候，八個可能的分組中，每個格子裏都不能是零，這一前提條件被成爲非零性 (positivity)。</p>
<div class="sourceCode" id="cb1728"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1728-1" title="1">Cat_mod4 &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke)<span class="op">*</span><span class="kw">as.factor</span>(prenatal), <span class="dt">data =</span> cattaneo2)</a></code></pre></div>
<p>用概率來表達，就是，在所有可能的 <span class="math inline">\(c\)</span> 層中的對象，其中暴露變量爲 1 的概率必須在 0, 1 之間:</p>
<p><span class="math display">\[
\textbf{Positivity: } \text{if Pr}(C=c) &gt; 0 \text{ then: } 0&lt;\text{Pr}(X=1|C=c) &lt;1  
\]</span></p>
</div>
<div id="連續型變量的平均因果效應" class="section level3">
<h3><span class="header-section-number">113.3.5</span> 連續型變量的平均因果效應</h3>
<div class="sourceCode" id="cb1729"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1729-1" title="1">Cat_mod5 &lt;-<span class="st"> </span><span class="kw">lm</span>(bweight <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(mbsmoke) <span class="op">+</span><span class="st"> </span>mage<span class="op">*</span><span class="kw">factor</span>(mbsmoke) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mage<span class="op">^</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">factor</span>(mbsmoke), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1729-2" title="2"></a>
<a class="sourceLine" id="cb1729-3" title="3"><span class="kw">summary</span>(Cat_mod5)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bweight ~ factor(mbsmoke) + mage * factor(mbsmoke) + 
##     I(mage^2) * factor(mbsmoke), data = cattaneo2)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -3131.920  -309.155    31.845   351.130  2024.364 
## 
## Coefficients:
##                              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                2423.99611  164.87921 14.7016 &lt; 2.2e-16 ***
## factor(mbsmoke)1           1121.03497  414.78336  2.7027  0.006903 ** 
## mage                         64.23439   12.37207  5.1919 2.171e-07 ***
## I(mage^2)                    -0.97679    0.22658 -4.3110 1.659e-05 ***
## factor(mbsmoke)1:mage       -92.69003   32.06902 -2.8903  0.003866 ** 
## factor(mbsmoke)1:I(mage^2)    1.44359    0.60351  2.3920  0.016796 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 564.93 on 4636 degrees of freedom
## Multiple R-squared:  0.04846,    Adjusted R-squared:  0.047434 
## F-statistic:  47.22 on 5 and 4636 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode" id="cb1731"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1731-1" title="1"><span class="kw">with</span>(cattaneo2, <span class="kw">summ</span>(mage, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  4642 26.505 26      5.619  13     45</code></pre>
<div class="sourceCode" id="cb1733"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1733-1" title="1"><span class="kw">with</span>(cattaneo2, <span class="kw">summ</span>(mage<span class="op">^</span><span class="dv">2</span>, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>##  obs. mean    median  s.d.    min.   max.  
##  4642 734.056 676     305.224 169    2025</code></pre>
<div class="sourceCode" id="cb1735"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1735-1" title="1">Y &lt;-<span class="st"> </span>cattaneo2<span class="op">$</span>bweight</a>
<a class="sourceLine" id="cb1735-2" title="2"><span class="co"># X &lt;- with(cattaneo2, cbind(fbaby, mmarried, alcohol, fedu, mage))</span></a>
<a class="sourceLine" id="cb1735-3" title="3">X &lt;-<span class="st"> </span><span class="kw">with</span>(cattaneo2, <span class="kw">cbind</span>(mage, mage<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1735-4" title="4">treat &lt;-<span class="st"> </span>cattaneo2<span class="op">$</span>mbsmoke</a>
<a class="sourceLine" id="cb1735-5" title="5">fit1&lt;-<span class="kw">ATE</span>(Y,treat,X)</a>
<a class="sourceLine" id="cb1735-6" title="6"></a>
<a class="sourceLine" id="cb1735-7" title="7"><span class="kw">summary</span>(fit1)</a></code></pre></div>
<pre><code>## Call:
## ATE(Y = Y, Ti = treat, X = X)
## 
##          Estimate    StdErr 95%.Lower 95%.Upper  Z.value    p.value    
## E[Y(1)] 3133.7541   20.7403 3093.1038 3174.4044 151.0948 &lt; 2.22e-16 ***
## E[Y(0)] 3409.4859    9.2843 3391.2890 3427.6827 367.2313 &lt; 2.22e-16 ***
## ATE     -275.7317   22.7443 -320.3098 -231.1537 -12.1231 &lt; 2.22e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><span class="math display">\[
\begin{aligned}
\widehat{\beta_0} &amp; = 1121.035 \\
\widehat{\beta_1} &amp; = -92.690 \\ 
\widehat{\beta_2} &amp; = 1.444 \\
\Rightarrow \widehat{ACE} &amp; = 1121.035 - 92.690\times26.505 + 1.444\times734.056 \\ 
&amp; = -275.7
\end{aligned}
\]</span></p>
<p>和 STATA 的 <code>teffects ra</code> 結果做個對比:</p>
<pre><code>. teffects ra (bweight mage mage2) (mbsmoke)

Iteration 0:   EE criterion =  9.667e-23  
Iteration 1:   EE criterion =  7.554e-27  

Treatment-effects estimation                    Number of obs     =      4,642
Estimator      : regression adjustment
Outcome model  : linear
Treatment model: none
----------------------------------------------------------------------------------------
                       |               Robust
               bweight |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-----------------------+----------------------------------------------------------------
ATE                    |
               mbsmoke |
(smoker vs nonsmoker)  |  -275.9901   22.74918   -12.13   0.000    -320.5777   -231.4025
-----------------------+----------------------------------------------------------------
POmean                 |
               mbsmoke |
            nonsmoker  |   3409.482   9.284654   367.22   0.000     3391.284    3427.679
----------------------------------------------------------------------------------------</code></pre>
<p>小數點以後的略差異應該是四舍五入的差異。別的估計包括 Robust Std. Err. 都是十分接近的。</p>
</div>
</div>
<div id="practical03---causal-inference" class="section level2">
<h2><span class="header-section-number">113.4</span> Practical03 - causal inference</h2>
<p>注意: 這裏的練習使用的是STATA 因爲，我在 R 裏找不到像 STATA 的 <code>teffects</code> 這樣靈活且方便的命令，如果你知道，歡迎告訴我: <a href="mailto:abelardccwang@gmail.com" class="email">abelardccwang@gmail.com</a>。</p>
<p>數據還是吸煙和新生兒體重的關系的數據:</p>
<pre><code>## 
## 
## . use &quot;backupfiles/cattaneo2.d(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
## 
## . describe
## 
## Contains data from backupfiles/cattaneo2.dta
##   obs:         4,642                          Excerpt from Cattaneo (2010)
##                                                 Journal of Econometrics 155:
##                                                 138-154
##  vars:            23                          21 Feb 2013 14:43
##  size:       143,902                          
## -------------------------------------------------------------------------------
##               storage   display    value
## variable name   type    format     label      variable label
## -------------------------------------------------------------------------------
## bweight         int     %9.0g                 infant birth weight (grams)
## mmarried        byte    %10.0g     mmarried   1 if mother married
## mhisp           byte    %9.0g                 1 if mother hispanic
## fhisp           byte    %9.0g                 1 if father hispanic
## foreign         byte    %9.0g                 1 if mother born abroad
## alcohol         byte    %9.0g                 1 if alcohol consumed during
##                                                 pregnancy
## deadkids        byte    %9.0g                 previous births where newborn
##                                                 died
## mage            byte    %9.0g                 mother&#39;s age
## medu            byte    %9.0g                 mother&#39;s education attainment
## fage            byte    %9.0g                 father&#39;s age
## fedu            byte    %9.0g                 father&#39;s education attainment
## nprenatal       byte    %9.0g                 number of prenatal care visits
## monthslb        int     %9.0g                 months since last birth
## order           byte    %9.0g                 order of birth of the infant
## msmoke          byte    %27.0g     smoke      cigarettes smoked during
##                                                 pregnancy
## mbsmoke         byte    %9.0g      mbsmoke    1 if mother smoked
## mrace           byte    %9.0g                 1 if mother is white
## frace           byte    %9.0g                 1 if father is white
## prenatal        byte    %9.0g                 trimester of first prenatal care
##                                                 visit
## birthmonth      byte    %9.0g                 month of birth
## lbweight        byte    %9.0g                 1 if low birthweight baby
## fbaby           float   %9.0g      YesNo      1 if first baby
## prenatal1       float   %9.0g      YesNo      1 if first prenatal visit in 1
##                                                 trimester
## -------------------------------------------------------------------------------
## Sorted by: 
## 
## . tab mbsmoke
## 
## 1 if mother |
##      smoked |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##   nonsmoker |      3,778       81.39       81.39
##      smoker |        864       18.61      100.00
## ------------+-----------------------------------
##       Total |      4,642      100.00
## 
## . 
## . summ bweight, detail
## 
##                  infant birth weight (grams)
## -------------------------------------------------------------
##       Percentiles      Smallest
##  1%         1474            340
##  5%         2438            340
## 10%         2693            397       Obs               4,642
## 25%         3033            454       Sum of Wgt.       4,642
## 
## 50%         3390                      Mean            3361.68
##                         Largest       Std. Dev.      578.8196
## 75%         3726           5188
## 90%         4026           5216       Variance       335032.2
## 95%         4224           5387       Skewness       -.784952
## 99%         4621           5500       Kurtosis       5.788678
## 
## . 
## . *1. 用簡單線性回顧分析一下 `mbsmoke` 和 `bweight` 之間的關系: 
## . *a) 
## . regress bweight i.mbsmoke
## 
##       Source |       SS           df       MS      Number of obs   =     4,642
## -------------+----------------------------------   F(1, 4640)      =    164.62
##        Model |  53275939.9         1  53275939.9   Prob &gt; F        =    0.0000
##     Residual |  1.5016e+09     4,640  323622.478   R-squared       =    0.0343
## -------------+----------------------------------   Adj R-squared   =    0.0341
##        Total |  1.5549e+09     4,641  335032.156   Root MSE        =    568.88
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |
##      smoker  |  -275.2519    21.4528   -12.83   0.000    -317.3096   -233.1942
##        _cons |   3412.912   9.255254   368.75   0.000     3394.767    3431.056
## ------------------------------------------------------------------------------
## 
## . 
## . 
## . *b) 
## . 
## . regress bweight i.mbsmoke i.fbaby
## 
##       Source |       SS           df       MS      Number of obs   =     4,642
## -------------+----------------------------------   F(2, 4639)      =     91.56
##        Model |  59045489.8         2  29522744.9   Prob &gt; F        =    0.0000
##     Residual |  1.4958e+09     4,639  322448.533   R-squared       =    0.0380
## -------------+----------------------------------   Adj R-squared   =    0.0376
##        Total |  1.5549e+09     4,641  335032.156   Root MSE        =    567.85
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |
##      smoker  |  -281.0638   21.45789   -13.10   0.000    -323.1314   -238.9961
##              |
##        fbaby |
##         Yes  |  -71.20491    16.8333    -4.23   0.000    -104.2062   -38.20364
##        _cons |   3445.178   11.98063   287.56   0.000      3421.69    3468.666
## ------------------------------------------------------------------------------
## 
## . 
## . *2. 調整了 `fbaby` 之後，暴露和結果之間的關系發生了怎樣的變化？
## . //說明 `fbaby` 是什麼類型的混雜因子？
## . 
## . *看兩個結果的報告，吸煙的線性回歸系數從調整 `fbaby` 前的 `-275.25`，
## . // 絕對值變大爲 `-281.06`，這是一種負方向混雜 (negative confounding)。
## . // 這種混雜可以分析 `fbaby` 和 `mbsmoke` 以及 `bweight`
## . // 各自的關系看出，懷第一胎的母親比較少吸煙，且第一胎嬰兒的出生體重
## . // 均值比不是第一胎嬰兒的出生體重要低: 
## . 
## . tab fbaby mbsmoke, row
## 
## +----------------+
## | Key            |
## |----------------|
## |   frequency    |
## | row percentage |
## +----------------+
## 
## 1 if first |  1 if mother smoked
##       baby | nonsmoker     smoker |     Total
## -----------+----------------------+----------
##         No |     2,066        543 |     2,609 
##            |     79.19      20.81 |    100.00 
## -----------+----------------------+----------
##        Yes |     1,712        321 |     2,033 
##            |     84.21      15.79 |    100.00 
## -----------+----------------------+----------
##      Total |     3,778        864 |     4,642 
##            |     81.39      18.61 |    100.00 
## 
## 
## . 
## . tabstat bweight, by(fbaby)
## 
## Summary for variables: bweight
##      by categories of: fbaby (1 if first baby)
## 
##  fbaby |      mean
## -------+----------
##     No |  3386.681
##    Yes |  3329.595
## -------+----------
##  Total |   3361.68
## ------------------
## 
## . 
## . tabstat bweight, by(mbsmoke)
## 
## Summary for variables: bweight
##      by categories of: mbsmoke (1 if mother smoked)
## 
##   mbsmoke |      mean
## ----------+----------
## nonsmoker |  3412.912
##    smoker |   3137.66
## ----------+----------
##     Total |   3361.68
## ---------------------
## 
## . 
## . // 這裏需要重新強調的是，通過比較調整新變量前後的回歸系數的變化，
## . // 能且僅僅只能在線性回歸模型 (可壓縮模型) 時使用，邏輯回歸中不適用。
## . 
## . 
## . *3 在怎樣的假設條件下，這裏的線性回歸模型的回歸系數 `mbsmoke` 
## . // 可以被賦予因果關系？
## . 
## . // 1. 無相互幹擾 no interference: 一個懷孕母親吸煙與否，和另一個母親
## . //    生下的嬰兒的出生體重之間沒有關系。
## . // 2. 一致性 consistency: 實際觀察到的孕期吸煙母親的嬰兒出生體重，和
## . //    潛在條件下 (當一個懷孕母親被強制吸煙時) 的嬰兒出生體重 (潛在結果)
## . //    是相同的。同樣地，在另一種潛在條件下 (懷孕母親被禁止吸煙時) 的
## . //    嬰兒出生體重 (潛在結果)，和實際觀察到的不吸煙的母親生下的嬰兒體重
## . //    是相同的。
## . // 3. 條件可置換性 conditional exchangeability: 在 `fbaby` 的各個組別中，
## . //    兩種潛在暴露造成的潛在結果，調整了其它共變量之後，和她們真實的暴露情況
## . //    (母親是否吸煙)之間是相互獨立的。在這個模型裏，我們只調整了 `fbaby` 
## . //    一個共變量，所以如果要給它的回歸系數加上因果關系結論，還必須假設 (雖然
## . //    很可能不合理) 控制 `fbaby` 這個單一的變量，就完全調整了了母親孕期吸煙和
## . //    新生兒體重之間關系的全部混雜因素。
## . // 4. 模型被正確擬合 correct specification of the regression model: 這是指，
## . //    模型中加入的變量與變量之間的關系，被正確地擬合了，因爲目前只有兩個
## . //    分類型變量在模型中，且該模型沒有加入交互作用項，那麼這條前提假設的含義
## . //    就是，我們認爲 `fbaby` 對孕期吸煙和新生兒體重之間的關系沒有交互作用。
## . 
## . *4 在前面解釋過的因果關系的前提條件下，要給 `mbsmoke` 一個因果關系的解釋
## . // 的話，(b) 模型的回歸系數該怎麼解釋呢？用潛在結果的概念解釋。
## . 
## . //    在 3. 的前提條件下， `mbsmoke` 的回歸系數的因果關系解讀可以是: 
## . //    當條件變量 `fbaby` 嬰兒是否是第一胎的變量保持不變時，281.0638 是暴露
## . //    (孕期吸煙) 導致的新生兒體重下降的量，其95%信賴區間是 (238.9961, 323.131
## &gt; 4)。
## . //    這是一個潛在結果的差，所以假如所有的媽媽孕期都吸煙，和所有的媽媽孕期都
## . //    不吸煙相比(潛在暴露)，嬰兒的出生平均體重要輕 281.0638 克: 
## . //     E{Y(1) | C = c} - E{Y(0) | C = c} = 281.0638
## . 
## . *5 用 STATA 的 `teffects ra` 命令擬合相同的模型: 
## .   
## . teffects ra (bweight fbaby) (mbsmoke)
## 
## Iteration 0:   EE criterion =  2.764e-25  
## Iteration 1:   EE criterion =  3.079e-26  
## 
## Treatment-effects estimation                    Number of obs     =      4,642
## Estimator      : regression adjustment
## Outcome model  : linear
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##      bweight |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##      mbsmoke |
##     (smoker  |
##          vs  |
##  nonsmoker)  |  -273.1552   20.93503   -13.05   0.000    -314.1872   -232.1233
## -------------+----------------------------------------------------------------
## POmean       |
##      mbsmoke |
##   nonsmoker  |   3414.403   9.279263   367.96   0.000     3396.216     3432.59
## ------------------------------------------------------------------------------
## 
## . 
## . // 因果均差 (ACE) 的估計在 STATA 被叫做 `ATE`，但是估計的結果略低於
## . // 模型 (b) 的結果: -273.1552 vs. -281.0638。
## . 
## . *6 在線性回歸模型中加入 `i.mbsmoke##i.fbaby` 的交互作用項，試着計算
## . // `fbaby` 爲 0/1 時各自的 `mbsmoke` 回歸系數: 
## .   
## . regress bweight i.mbsmoke##i.fbaby
## 
##       Source |       SS           df       MS      Number of obs   =     4,642
## -------------+----------------------------------   F(3, 4638)      =     65.17
##        Model |  62890495.3         3  20963498.4   Prob &gt; F        =    0.0000
##     Residual |  1.4920e+09     4,638  321689.034   R-squared       =    0.0404
## -------------+----------------------------------   Adj R-squared   =    0.0398
##        Total |  1.5549e+09     4,641  335032.156   Root MSE        =    567.18
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |
##      smoker  |  -339.8145   27.35206   -12.42   0.000    -393.4375   -286.1914
##              |
##        fbaby |
##         Yes  |  -98.18832   18.53668    -5.30   0.000     -134.529   -61.84761
##              |
##      mbsmoke#|
##        fbaby |
##  smoker#Yes  |   152.2046   44.02482     3.46   0.001     65.89506    238.5142
##              |
##        _cons |   3457.406   12.47823   277.08   0.000     3432.942    3481.869
## ------------------------------------------------------------------------------
## 
## . est store a
## 
## . 
## . *to get the stratum specific effects: 
## . 
## . lincom 1.mbsmoke  // when baby is not first born 
## 
##  ( 1)  1.mbsmoke = 0
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          (1) |  -339.8145   27.35206   -12.42   0.000    -393.4375   -286.1914
## ------------------------------------------------------------------------------
## 
## . 
## . lincom 1.mbsmoke + 1.mbsmoke#1.fbaby // when baby is first born
## 
##  ( 1)  1.mbsmoke + 1.mbsmoke#1.fbaby = 0
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          (1) |  -187.6098   34.49709    -5.44   0.000    -255.2405   -119.9791
## ------------------------------------------------------------------------------
## 
## . 
## . *7 計算 `fbaby` 各組所佔的百分比: (爲了計算孕期吸煙導致的新生兒體重下降
## . // 的邊際效應 marginal effect)
## . 
## . tab fbaby
## 
##  1 if first |
##        baby |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##          No |      2,609       56.20       56.20
##         Yes |      2,033       43.80      100.00
## ------------+-----------------------------------
##       Total |      4,642      100.00
## 
## . 
## . *8 用 6, 7 的結果，手動計算一下 ACE 的估計量: 
## .   
## . 
## . *now restore model estimates
## . est restore a 
## (results a are active now)
## 
## . 
## . lincom 0.562*1.mbsmoke  + 0.438*(1.mbsmoke + 1.mbsmoke#1.fbaby)
## 
##  ( 1)  1.mbsmoke + .438*1.mbsmoke#1.fbaby = 0
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          (1) |  -273.1488   21.55453   -12.67   0.000     -315.406   -230.8917
## ------------------------------------------------------------------------------
## 
## . 
## . margins, dydx(mbsmoke) // 你也可以用這個 margins 的命令，很方便，但是它估計的
## &gt; 標準誤不使用穩健統計學方法，所以略有不同。
## 
## Average marginal effects                        Number of obs     =      4,642
## Model VCE    : OLS
## 
## Expression   : Linear prediction, predict()
## dy/dx w.r.t. : 1.mbsmoke
## 
## ------------------------------------------------------------------------------
##              |            Delta-method
##              |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |
##      smoker  |  -273.1552   21.55433   -12.67   0.000     -315.412   -230.8985
## ------------------------------------------------------------------------------
## Note: dy/dx for factor levels is the discrete change from the base level.
## 
## . 
## . *9 爲什麼沒有加交互作用項的模型 (b) 給出的回歸系數估計和 `teffects ra`
## . // 的結果相差很大？
## . 
## . //   這是因爲如果給模型 (b) 的回歸系數賦予因果關系的解釋的話，第四個前提假設
## . //   -- 模型選擇正確且變量在模型中的形式也是正確 -- 太過樂觀了。這個前提假設
## . //   認爲沒有交互作用，但是，如果你看加交互作用項的第三個模型中，交互作用項
## . //   的回顧系數其實是有意義的 (有證據顯示交互作用存在): 
## .   
## . // mbsmoke#|
## . //       fbaby |
## . // smoker#Yes  |   152.2046   44.02482     3.46   0.001     65.89506    238.5
## &gt; 142  
## . 
## . *10 現在給模型中加入更多的共變量，用兩種命令分別擬合，比較其結果:
## .   
## . regress bweight mbsmoke fbaby mmarried alcohol fedu mage
## 
##       Source |       SS           df       MS      Number of obs   =     4,642
## -------------+----------------------------------   F(6, 4635)      =     46.86
##        Model |  88933839.4         6  14822306.6   Prob &gt; F        =    0.0000
##     Residual |  1.4660e+09     4,635  316278.403   R-squared       =    0.0572
## -------------+----------------------------------   Adj R-squared   =    0.0560
##        Total |  1.5549e+09     4,641  335032.156   Root MSE        =    562.39
## 
## ------------------------------------------------------------------------------
##      bweight |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |  -221.2625   22.28894    -9.93   0.000    -264.9594   -177.5656
##        fbaby |  -49.45095   17.62184    -2.81   0.005    -83.99814   -14.90375
##     mmarried |   152.3058   21.86593     6.97   0.000     109.4382    195.1734
##      alcohol |  -64.26606   47.48732    -1.35   0.176    -157.3638    28.83168
##         fedu |   4.515101   2.573722     1.75   0.079    -.5306195    9.560821
##         mage |   1.282969   1.750586     0.73   0.464    -2.149013    4.714952
##        _cons |   3230.456   49.40366    65.39   0.000     3133.601    3327.311
## ------------------------------------------------------------------------------
## 
## . 
## . 
## . teffects ra (bweight fbaby mmarried alcohol fedu mage) (mbsmoke)
## 
## Iteration 0:   EE criterion =  4.396e-24  
## Iteration 1:   EE criterion =  7.758e-26  
## 
## Treatment-effects estimation                    Number of obs     =      4,642
## Estimator      : regression adjustment
## Outcome model  : linear
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##      bweight |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##      mbsmoke |
##     (smoker  |
##          vs  |
##  nonsmoker)  |  -231.1408   24.50303    -9.43   0.000    -279.1659   -183.1158
## -------------+----------------------------------------------------------------
## POmean       |
##      mbsmoke |
##   nonsmoker  |   3403.054   9.532216   357.01   0.000     3384.372    3421.737
## ------------------------------------------------------------------------------
## 
## . 
## . 
## . //   此時我們發現，簡單現行回歸估計的因果均值差(ATE)總是和考慮了更復雜關系的
## &gt; 模型相比
## . //   相差較多。
## . 
## . *11 你可以用下面的非 teffects 代碼還原上面的計算: 
## .   
## .  qui regress bweight mbsmoke fbaby mmarried alcohol fedu mage if mbsmoke==0
## 
## .  predict Y0
## (option xb assumed; fitted values)
## 
## .  
## .  qui regress bweight mbsmoke fbaby mmarried alcohol fedu mage if mbsmoke==1
## 
## .  predict Y1
## (option xb assumed; fitted values)
## 
## .  
## .  sum Y0
## 
##     Variable |        Obs        Mean    Std. Dev.       Min        Max
## -------------+---------------------------------------------------------
##           Y0 |      4,642    3403.054    101.6744   3163.591   3549.308
## 
## .  gen E0=r(mean) 
## 
## .  
## .  sum Y1
## 
##     Variable |        Obs        Mean    Std. Dev.       Min        Max
## -------------+---------------------------------------------------------
##           Y1 |      4,642    3171.914    67.17853   2839.728   3306.694
## 
## .  gen E1=r(mean)
## 
## .  
## .  gen ACE = E1-E0 
## 
## .  sum ACE 
## 
##     Variable |        Obs        Mean    Std. Dev.       Min        Max
## -------------+---------------------------------------------------------
##          ACE |      4,642   -231.1409           0  -231.1409  -231.1409
## 
## .  
## .  // 或者使用方便的 margins
## .  
## . qui regress bweight i.mbsmoke fbaby mmarried alcohol fedu mage ///
## &gt;                 i.mbsmoke#i.fbaby i.mbsmoke#i.mmarried i.mbsmoke#i.alcohol i.
## &gt; mbsmoke#c.fedu ///
## &gt;                 i.mbsmoke#c.mage
## 
## .                 
## . margins, dydx(mbsmoke)
## 
## Average marginal effects                        Number of obs     =      4,642
## Model VCE    : OLS
## 
## Expression   : Linear prediction, predict()
## dy/dx w.r.t. : 1.mbsmoke
## 
## ------------------------------------------------------------------------------
##              |            Delta-method
##              |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##      mbsmoke |
##      smoker  |  -231.1408   24.05129    -9.61   0.000    -278.2928   -183.9888
## ------------------------------------------------------------------------------
## Note: dy/dx for factor levels is the discrete change from the base level.
## 
## . 
## . // 值得注意的是，即使是使用 `teffects ra` 我們可能對模型形式的指定還是過於簡
## . // 單，例如上面的模型中加入了許多變量，但是 STATA 其實並沒有考慮有三個或者三
## . // 個以上變量之間發生交互作用的情況，而且， `fedu, mage` 被認爲和結果變量 
## . // `bweight` 呈簡單一次的線性關系。</code></pre>
</div>
</div>
<div id="regression-methods-with-binary-outcomes-結果變量爲二分類變量" class="section level1">
<h1><span class="header-section-number">第 114 章</span> Regression Methods with binary outcomes 結果變量爲二分類變量</h1>
<div id="二分類結果變量的因果被估計量-causal-estimand" class="section level2">
<h2><span class="header-section-number">114.1</span> 二分類結果變量的因果被估計量 (causal estimand):</h2>
<p>Average causal effect (因果邊際危險度差，marginal causal risk difference), ACE :</p>
<p><span class="math display">\[
\text{Pr}\{Y(1) = 1\} - \text{Pr}\{Y(0) = 1\}
\]</span></p>
<p>因果邊際危險度比 (marginal causal risk ratio):</p>
<p><span class="math display">\[
\frac{\text{Pr}\{Y(1) = 1\}}{\text{Pr}\{Y(0) = 1\}}
\]</span></p>
<p>或，因果邊際比值比 (marginal causal odds ratio):</p>
<p><span class="math display">\[
\frac{[\frac{\text{Pr}\{Y(1) = 1\}}{1-\text{Pr}\{Y(1) = 1\}}]}{[\frac{\text{Pr}\{Y(0) = 1\}}{1-\text{Pr}\{Y(0) = 1\}}]}
\]</span></p>
<p>或，因果邊際對數危險度比/比值比:</p>
<p><span class="math display">\[
\log\{\text{Pr}\{Y(1) = 1\}\} - \log\{\text{Pr}\{Y(0) = 1\} \}
\]</span></p>
<p><span class="math display">\[
\log[\frac{\text{Pr}\{Y(1) = 1\}}{1-\text{Pr}\{Y(1) = 1\}}] - \log[\frac{\text{Pr}\{Y(0) = 1\}}{1-\text{Pr}\{Y(0) = 1\}}]
\]</span></p>
<p>和上一章節一樣，我們可能實際上還會關心這些被估計量的調整後的條件平均因果效應 (conditinal ACE):</p>
<p><span class="math display">\[
\text{Pr}\{Y(1) = 1 | \mathbf{V=v} \} - \text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}\\ 
\log\{\text{Pr}\{Y(1) = 1| \mathbf{V=v}\}\} - \log\{\text{Pr}\{Y(0) = 1| \mathbf{V=v}\} \}\\
\log[\frac{\text{Pr}\{Y(1) = 1 | \mathbf{V=v}\}}{1-\text{Pr}\{Y(1) = 1 | \mathbf{V=v}\}}] - \log[\frac{\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}}{1-\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}}]
\]</span></p>
<div id="比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio" class="section level3">
<h3><span class="header-section-number">114.1.1</span> 比值比的不可壓縮性 non-collapsibility of the odds ratio</h3>
<p>即便是沒有效應修飾，在 GLM 章節我們也學到過，由於邏輯回歸模型的不可壓縮性質，一般地，選擇的條件變量不同的話，(對數)比值比的大小都會發生變化。所以沒辦法用回歸系數的變化來推斷是否有明顯的混雜效應。</p>
</div>
</div>
<div id="鑑定-identification---conditional-effects" class="section level2">
<h2><span class="header-section-number">114.2</span> 鑑定 identification - conditional effects</h2>
<p>如果我們對暴露 <span class="math inline">\(X\)</span> 和結果 <span class="math inline">\(Y\)</span> 之間的條件因果危險度差 (conditional causal risk difference):</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}\{ Y(1) = 1 &amp; | \mathbf{C=c}\}  - \text{Pr}\{ Y(0) = 1 | \mathbf{C=c}\} \\ 
 &amp; = \text{Pr}\{ Y(1) = 1 | X=1, \mathbf{C=c}\} - \text{Pr}\{ Y(0) = 1 | X=1, \mathbf{C=c}\} \\
 &amp; \text{By conditional exchangeability given }\mathbf{C} \uparrow \\
 &amp; = \text{Pr}\{ Y = 1 | X=1, \mathbf{C=c}\} - \text{Pr}\{ Y = 1 | X=1, \mathbf{C=c}\} \\
 &amp; \text{By consistency } \uparrow \\
\end{aligned}
\]</span></p>
<p>相似地，條件因果對數危險度比 (conditional causal log risk ratio):</p>
<p><span class="math display">\[
\begin{aligned}
\log[\text{Pr}\{ Y(1) = 1 &amp;| \mathbf{C=c} \}] - \log[\text{Pr}\{ Y(0) = 1 | \mathbf{C=c} \}] \\ 
 &amp; = \log\{\text{Pr}( Y = 1 | X=1, \mathbf{C=c})\} - \log\{\text{Pr}( Y = 1 | X=1, \mathbf{C=c})\} \\
\end{aligned}
\]</span></p>
<p>條件因果對數比值比 (conditioanl causal log odds ratio):</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \log[\frac{\text{Pr}\{Y(1) = 1 | \mathbf{C=c}\}}{1-\text{Pr}\{Y(1) = 1 | \mathbf{C=c}\}}] - \log[\frac{\text{Pr}\{Y(0) = 1 | \mathbf{C=c}\}}{1-\text{Pr}\{Y(0) = 1 | \mathbf{C=c}\}}] \\
&amp; =\log[\frac{\text{Pr}\{Y = 1 | X = 1, \mathbf{C=c}\}}{1-\text{Pr}\{Y = 1 |X = 1, \mathbf{C=c}\}}] - \log[\frac{\text{Pr}\{Y = 1 |X = 0,\mathbf{C=c}\}}{1-\text{Pr}\{Y = 1 |X = 0, \mathbf{C=c}\}}] \\
\end{aligned}
\]</span></p>
</div>
<div id="鑑定-identification---marginal-effects" class="section level2">
<h2><span class="header-section-number">114.3</span> 鑑定 identification - marginal effects</h2>
<div id="marginal-causal-risk-difference-ace" class="section level3">
<h3><span class="header-section-number">114.3.1</span> Marginal causal risk difference (ACE)</h3>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}\{ Y(1) =1 \} &amp;  - \text{Pr}\{ Y(0) =1 \}   \\
=  &amp; \sum_c\text{Pr}\{ Y(1)=1 |C = c \}\text{Pr}(C=c) \\
&amp; - \sum_c\text{Pr}\{ Y(0)=1 | C=c\}\text{Pr}(C=c) \\
&amp; (\text{by the law of total probability } \uparrow) \\
= &amp;\sum_c\text{Pr}\{ Y(1)=1|X=1, C=c \} \text{Pr}(C=c) \\ 
&amp; - \sum_c\text{Pr}\{ Y(0)=1|X=1, C=c \} \text{Pr}(C=c) \\ 
&amp; (\text{by conditional exchangeability } \uparrow) \\
= &amp;\sum_c\text{Pr}( Y=1|X=1, C=c ) \text{Pr}(C=c) \\ 
&amp; - \sum_c\text{Pr} (Y=1|X=1, C=c) \text{Pr}(C=c) \\ 
&amp; (\text{by consistency } \uparrow) \\
= &amp;  \sum_c\{ \text{Pr}( Y=1|X=1, C=c) - \\ 
&amp; \;\;\;\;\; \text{Pr}( Y=1|X=1, C=c) \}\text{Pr}(C=c)
\end{aligned}
\]</span></p>
</div>
<div id="marginal-causal-log-risk-ratio" class="section level3">
<h3><span class="header-section-number">114.3.2</span> Marginal causal log risk ratio</h3>
<p><span class="math display">\[
\begin{aligned}
&amp; \log[\text{Pr}\{ Y(1) = 1 \}] - \log[\text{Pr}\{ Y(0) =1 \}] \\
&amp; = \log[\sum_c\text{Pr}(Y = 1|X=1, C=c)\text{Pr}(C=c)] \\
&amp; \;\;\;\; - \log[\sum_c\text{Pr}(Y = 1|X=0, C=c)\text{Pr}(C=c)] \\
\end{aligned}
\]</span>
### Marginal causal log odds ratio (cannot be calculated)</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \log[\frac{\text{Pr}\{Y(1) = 1\}}{1-\text{Pr}\{Y(1) = 1\}}] - \log[\frac{\text{Pr}\{Y(0) = 1\}}{1-\text{Pr}\{Y(0) = 1\}}] \\
&amp; = \log\{ \frac{\sum_c\text{Pr}(Y = 1|X=1, C=c)\text{Pr}(C=c)}{1-\sum_c\text{Pr}(Y = 1|X=1, C=c)\text{Pr}(C=c)} \} \\
&amp; \;\;\;\; - \log\{ \frac{\sum_c\text{Pr}(Y = 1|X=0, C=c)\text{Pr}(C=c)}{1-\sum_c\text{Pr}(Y = 1|X=0, C=c)\text{Pr}(C=c)} \}
\end{aligned}
\]</span></p>
</div>
</div>
<div id="通過邏輯回歸估計這些被估計量" class="section level2">
<h2><span class="header-section-number">114.4</span> 通過邏輯回歸估計這些被估計量</h2>
<div class="sourceCode" id="cb1739"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1739-1" title="1">Log_lbw &lt;-<span class="st"> </span><span class="kw">glm</span>(lbweight <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(mbsmoke) <span class="op">+</span><span class="st"> </span>mage <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(fbaby) <span class="op">+</span><span class="st"> </span><span class="kw">as.factor</span>(prenatal), <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), <span class="dt">data =</span> cattaneo2)</a>
<a class="sourceLine" id="cb1739-2" title="2"><span class="kw">summary</span>(Log_lbw)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = lbweight ~ as.factor(mbsmoke) + mage + as.factor(fbaby) + 
##     as.factor(prenatal), family = binomial(link = &quot;logit&quot;), data = cattaneo2)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.15417  -0.33142  -0.30949  -0.29641   2.60453  
## 
## Coefficients:
##                       Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)          -0.470282   0.402678 -1.1679   0.24285    
## as.factor(mbsmoke)1   0.775782   0.137371  5.6474 1.629e-08 ***
## mage                 -0.021202   0.012607 -1.6817   0.09263 .  
## as.factor(fbaby)1    -0.088391   0.136386 -0.6481   0.51692    
## as.factor(prenatal)1 -1.950799   0.274350 -7.1106 1.155e-12 ***
## as.factor(prenatal)2 -1.912776   0.299804 -6.3801 1.770e-10 ***
## as.factor(prenatal)3 -2.101474   0.430343 -4.8833 1.043e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2115.30  on 4641  degrees of freedom
## Residual deviance: 2026.64  on 4635  degrees of freedom
## AIC: 2040.64
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>但是，在邏輯回歸的模型下，即使是滿足<strong>無互相幹擾，一致性和條件可置換性</strong>的前提，並且你就算是 100% 自信地認爲你的模型絕對正確，計算獲得的條件比值比 (conditional odds ratio) 總也無法被賦予因果關系的含義。這是由於邏輯回歸的不可壓縮性 (non-collapsiblity)，這也是越來越多的人傾向與不使用比值比作爲評價治療效果 (treatment effect) 的指標的原因之一。</p>
<p>也因此，STATA 裏的 <code>teffects ra</code> 中即使你用的結果模型中加入 <code>logit</code> 的選項，它計算的是因果平均危險度差 (Marginal causal <strong>risk difference</strong> (ACE))。</p>
<pre><code>## 
## 
## . use &quot;backupfiles/cattaneo2.d(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
## 
## . teffects ra (lbweight mage i.fbaby i.prenatal, logit) (mbsmoke)
## 
## Iteration 0:   EE criterion =  2.950e-26  
## Iteration 1:   EE criterion =  7.782e-35  
## 
## Treatment-effects estimation                    Number of obs     =      4,642
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##     lbweight |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##      mbsmoke |
##     (smoker  |
##          vs  |
##  nonsmoker)  |   .0583827   .0117242     4.98   0.000     .0354036    .0813617
## -------------+----------------------------------------------------------------
## POmean       |
##      mbsmoke |
##   nonsmoker  |   .0503207   .0036151    13.92   0.000     .0432353    .0574061
## ------------------------------------------------------------------------------</code></pre>
</div>
<div id="average-causaltreatment-effect-in-the-exposedtreated-atet" class="section level2">
<h2><span class="header-section-number">114.5</span> Average causal/treatment effect in the exposed/treated (ATET)</h2>
<p>這是爲了回答公共衛生學上一個抽象的政策性問題: 對那些真的接受了治療/暴露/衛生政策幹預的人來說，他們身上發生的治療效果是怎樣的？因爲有些情況下你無法讓“所有人”都接受治療或幹預。</p>
<p>It is often of public health interest to ask “what is the effect of this exposure on those who choose to take it?” rather than “what would be its effect on everyone?”</p>
<p><span class="math display">\[
E\{ Y(1) - Y(0) | X=1 \}
\]</span></p>
<p>此時，條件可置換性的前提發生了微妙變化:</p>
<p><span class="math display">\[
Y(0) \perp\perp X|\mathbf{C}
\]</span></p>
<p>對於一個簡單的分類型條件變量 <span class="math inline">\(C\)</span> 來說，它的 ATET 的鑑定過程如下:</p>
<p><span class="math display">\[
\begin{aligned}
E\{ Y(1)  -Y(0) |X =1  \}  = &amp; \sum_cE\{ Y(1) |X=1, C=c \}\text{Pr}(C=c|X=1) \\ 
&amp; -  \sum_cE\{ Y(0) |X=1, C=c \}\text{Pr}(C=c|X=1) \\ 
&amp; \text{(by the law of total probability  } \uparrow) \\
= &amp; \sum_cE\{ Y(1) |X=1, C=c \}\text{Pr}(C=c|X=1) \\ 
&amp; -  \sum_cE\{ Y(0) |X=0, C=c \}\text{Pr}(C=c|X=1) \\ 
&amp; \text{(by conditional exchangeability  } \uparrow) \\
= &amp;\sum_cE (Y |X=1, C=c)\text{Pr}(C=c|X=1) \\ 
&amp; -  \sum_cE(Y |X=0, C=c)\text{Pr}(C=c|X=1) \\ 
&amp; \text{(by consistency } \uparrow) \\
= &amp;  \sum_c\{ E (Y |X=1, C=c) \\
&amp; \;\;\;- E(Y |X=0, C=c) \}\text{Pr}(C=c|X=1)
\end{aligned}
\]</span></p>
<p>這時，我們只關心那些真正暴露的人 (predicted potential outcomes are predicted only for the exposed)。</p>
<p>在 STATA 的 <code>teffects ra</code> 後面加上 <code>atet</code> 的選項即可:</p>
<pre class="stata"><code>teffects ra (lbweight mage i.fbaby i.prenatal, logit) (mbsmoke), atet</code></pre>
<pre><code>## 
## 
## . use &quot;backupfiles/cattaneo2.d(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
## 
## . teffects ra (lbweight mage i.fbaby i.prenatal, logit) (mbsmoke), atet
## 
## Iteration 0:   EE criterion =  2.950e-26  
## Iteration 1:   EE criterion =  2.504e-35  
## 
## Treatment-effects estimation                    Number of obs     =      4,642
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##     lbweight |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##      mbsmoke |
##     (smoker  |
##          vs  |
##  nonsmoker)  |   .0537169   .0114307     4.70   0.000     .0313131    .0761206
## -------------+----------------------------------------------------------------
## POmean       |
##      mbsmoke |
##   nonsmoker  |   .0562368   .0045959    12.24   0.000      .047229    .0652447
## ------------------------------------------------------------------------------</code></pre>
<p>這裏你看到的是 ATET 和 ACE 很接近的數字，還有別的情況下，你會發現，某種治療方案對於接受治療的人來說是有好處的，但是對其他人是有害/沒有用的。</p>
</div>
<div id="practical04---causal-inference" class="section level2">
<h2><span class="header-section-number">114.6</span> Practical04 - causal inference</h2>
<p>注意: 這裏的練習使用的是 STATA 因爲，我在 R 裏找不到像 STATA 的 <code>teffects</code> 這樣靈活且方便的命令，如果你知道，歡迎告訴我: <a href="mailto:abelardccwang@gmail.com" class="email">abelardccwang@gmail.com</a>。</p>
<p>數據來自一個觀察性研究，樣本量是 3551 的一個肺癌患者數據庫，四家醫院的肺癌患者正準備選用 1) 常規手術 或者 2) 射頻消蝕 (radiofrequency ablation, RFA) 兩種方法取出肺部的轉移腫塊。該數據的變量如下:</p>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. describe
## 
## Contains data from backupfiles/RFA.dta
##   obs:         3,551                          
##  vars:            14                          5 Nov 2013 15:05
##  size:       198,856                          
## -------------------------------------------------------------------------------
##               storage   display    value
## variable name   type    format     label      variable label
## -------------------------------------------------------------------------------
## id              float   %9.0g                 Patient ID
## age             float   %9.0g                 
## gender          float   %9.0g      gender     
## smoke           float   %9.0g      smoke      Smoking status
## hospital        float   %9.0g                 Hospital ID
## nodules         float   %9.0g                 Number of nodules
## mets            float   %9.0g                 Number of other metastatic sites
## duration        float   %9.0g                 Duration of disease (in months)
## maxdia          float   %9.0g                 Diameter of largest nodule (in
##                                                 cm)
## primary         float   %22.0g     primary    Location of primary cancer
## position        float   %9.0g      position   Ease with which nodules can be
##                                                 reached
## coag            float   %9.0g      coag       Coagulopathy
## rfa             float   %23.0g     rfa        Treatment variable: RFA or
##                                                 standard surgery
## dodp            float   %9.0g      dodp       Outcome variable: death or
##                                                 disease progression within 36
##                                                 months
## -------------------------------------------------------------------------------
## Sorted by: id</code></pre>
<p>其中，主要的混雜因子是:</p>
<ol style="list-style-type: decimal">
<li><code>hospital</code>: 有些醫院可能本身更傾向於/不傾向於使用 RFA，或者有些醫院的患者整體症狀較輕/較重;</li>
<li><code>maxdia</code>: 如果腫塊太大，那就不適合使用 RFA，而且腫塊較大的患者，生存的概率一般來說比較低;</li>
<li><code>position</code>: 腫塊位置，相比較傳統常規手術摘除的方法，RFA 能夠治療那些手術難以摘除的腫塊的部位。</li>
</ol>
<p>這三個主要的變量被認爲非常重要，需要在分析中被調整。</p>
<p>其他的變量被認爲不太會是混雜因子，但是醫生認爲對患者的預後有很強的預測效果: <code>age, gender, smoke, nodules, mets, duration, primary</code>。</p>
<p>最後一點，對於有凝血障礙的患者 <code>coag</code> 來說，RFA 是不安全的。</p>
<div id="在stata裡打開數據初步分析和熟悉數據" class="section level3">
<h3><span class="header-section-number">114.6.1</span> 在STATA裡打開數據，初步分析和熟悉數據</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. 
## . summarize age
## 
##     Variable |        Obs        Mean    Std. Dev.       Min        Max
## -------------+---------------------------------------------------------
##          age |      3,551    51.99944    4.379916         33         84
## 
## . 
## . tab gender
## 
##      gender |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##        male |      2,124       59.81       59.81
##      female |      1,427       40.19      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## . 
## . tab hospital
## 
## Hospital ID |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##           1 |        570       16.05       16.05
##           2 |        631       17.77       33.82
##           3 |      1,395       39.28       73.11
##           4 |        955       26.89      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## . 
## . summarize maxdia
## 
##     Variable |        Obs        Mean    Std. Dev.       Min        Max
## -------------+---------------------------------------------------------
##       maxdia |      3,551    1.816981    .5713256         .7          4
## 
## . 
## . tab position
## 
##   Ease with |
##       which |
## nodules can |
##  be reached |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##        easy |        857       24.13       24.13
##    moderate |      1,820       51.25       75.39
##   difficult |        874       24.61      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## . 
## . tab dodp
## 
##     Outcome |
##   variable: |
##    death or |
##     disease |
## progression |
##   within 36 |
##      months |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##          no |      2,604       73.33       73.33
##         yes |        947       26.67      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00</code></pre>
</div>
<div id="用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係" class="section level3">
<h3><span class="header-section-number">114.6.2</span> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. 
## . *(a)
## . logit dodp rfa 
## 
## Iteration 0:   log likelihood = -2059.3462  
## Iteration 1:   log likelihood = -2030.2625  
## Iteration 2:   log likelihood =  -2030.123  
## Iteration 3:   log likelihood =  -2030.123  
## 
## Logistic regression                             Number of obs     =      3,551
##                                                 LR chi2(1)        =      58.45
##                                                 Prob &gt; chi2       =     0.0000
## Log likelihood =  -2030.123                     Pseudo R2         =     0.0142
## 
## ------------------------------------------------------------------------------
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          rfa |  -.5881255   .0777773    -7.56   0.000    -.7405661   -.4356849
##        _cons |  -.7496965   .0498312   -15.04   0.000    -.8473639    -.652029
## ------------------------------------------------------------------------------
## 
## . 
## . *(b)
## . logit dodp rfa i.hospital maxdia i.position
## 
## Iteration 0:   log likelihood = -2059.3462  
## Iteration 1:   log likelihood = -1782.1086  
## Iteration 2:   log likelihood = -1770.8713  
## Iteration 3:   log likelihood = -1770.8481  
## Iteration 4:   log likelihood = -1770.8481  
## 
## Logistic regression                             Number of obs     =      3,551
##                                                 LR chi2(7)        =     577.00
##                                                 Prob &gt; chi2       =     0.0000
## Log likelihood = -1770.8481                     Pseudo R2         =     0.1401
## 
## ------------------------------------------------------------------------------
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##          rfa |  -.0215334   .0976595    -0.22   0.825    -.2129425    .1698757
##              |
##     hospital |
##           2  |  -.1087261    .147873    -0.74   0.462    -.3985519    .1810998
##           3  |   .4063856   .1222275     3.32   0.001     .1668242     .645947
##           4  |  -.1398633   .1340884    -1.04   0.297    -.4026717    .1229451
##              |
##       maxdia |   1.426368   .0891745    16.00   0.000     1.251589    1.601147
##              |
##     position |
##    moderate  |    .072014   .1096704     0.66   0.511     -.142936     .286964
##   difficult  |   1.226249   .1191946    10.29   0.000     .9926321    1.459866
##              |
##        _cons |  -4.234223   .2365292   -17.90   0.000    -4.697812   -3.770634
## ------------------------------------------------------------------------------</code></pre>
</div>
<div id="比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的" class="section level3">
<h3><span class="header-section-number">114.6.3</span> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</h3>
<p>總體來說，混雜的模式 (pattern) 應該是正混雜 (positive confounding)。模型 (a)，不經過任何調整，RFA 似乎比標準手術療法好很多 (幾乎減少一半三年內死亡的對數比值 log-odds)。但是調整了其他混雜因素的模型 (b)，結果暗示兩者之間對於患者預後沒有太大的影響 (treatment effect reduced to suggest very little evidence to departure from no effect)。所以調整的這些變量對暴露和結果之間的關係的混雜是正向的(傾向於把關係改變成為接近另假設 tend to change the association to null)。</p>
</div>
<div id="在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋" class="section level3">
<h3><span class="header-section-number">114.6.4</span> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</h3>
<p>這些假設包括：</p>
<ol style="list-style-type: decimal">
<li>無相互幹擾 no interference：某個病人接受的療法，不影響另一個病人療法的結果。</li>
<li>一致性 consistency：對於真的接受了 RFA 療法的病人來說，他/她的療效，和潛在暴露 (potential exposure) 為接受 RFA 療法時的潛在療效 (potential outcome) 是一致的。接受標準手術療法的患者中也是需要一樣的假設。</li>
<li>條件可置換性 conditional exchangeability：對於同一所醫院，腫塊大小相同，腫塊位置相同的患者來說，他/她的兩種潛在治療結果 (potential outcome)，和該病人最終到底是接受了常規手術治療，還是接受 RFA 之間是相互獨立的。用更通俗的話說是，暴露變量 <code>rfa</code> 和結果變量 <code>dodp</code> 之間的所有可能的混雜，都被模型中加入的 <code>hospital, maxdia, position</code> 囊括進去了。</li>
<li>正確的模型結構 correct specification of the model：因為模型 (b) 中不包括任何交互作用的相乘項，要給這個模型擬合的回歸係數以因果關係的解釋，我們需要認為模型中的變量之間沒有任何較互作用，也就是說<code>rfa</code>的療效，不因為醫院，腫塊位置，和腫塊大小不同而不同。</li>
</ol>
</div>
<div id="在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋" class="section level3">
<h3><span class="header-section-number">114.6.5</span> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</h3>
<p>當四個前提假設都可以滿足，模型 (b) 的<code>rfa</code>的回歸係數 <code>-0.022</code> 是一個條件對數比值比 (conditional log-odds ratio)。該條件對數比值比調整了醫院，腫瘤大小，和腫瘤位置。患者在三年內死亡或者疾病加重的對數比值 (log odds) 被估計為 0.022 (95% CI: -0.17, 0.21)。這個對數比值比較的是，情形 A.所有患者都被實施 RFA 手術，和情形 B. 所有患者都被實施常規手術摘除腫塊，兩種潛在情形的潛在結果。用潛在結果的數學語言來解釋就是：</p>
<p><span class="math display">\[
\log\{ \frac{\text{Pr}[Y(1) = 1|\mathbf{C = c}]}{1-\text{Pr}[Y(1) = 1|\mathbf{C = c}]} \} - \log\{ \frac{\text{Pr}[Y(0) = 1|\mathbf{C = c}]}{1-\text{Pr}[Y(0) = 1|\mathbf{C = c}]} \}
\]</span></p>
<p>其中，<span class="math inline">\(\mathbf{C}=\)</span> {<code>hospital, maxdia, position</code>}</p>
</div>
<div id="用-stata-的-teffects-ra-擬合上面兩個模型" class="section level3">
<h3><span class="header-section-number">114.6.6</span> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. 
## . *(a)
## . teffects ra (dodp, logit) (rfa)
## 
## Iteration 0:   EE criterion =  5.296e-17  
## Iteration 1:   EE criterion =  6.380e-32  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   -.113019   .0146495    -7.71   0.000    -.1417316   -.0843064
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .3208874   .0108592    29.55   0.000     .2996039     .342171
## ------------------------------------------------------------------------------
## 
## . 
## . *(b)
## . teffects ra (dodp i.hospital maxdia i.position, logit) (rfa)
## 
## Iteration 0:   EE criterion =  6.343e-18  
## Iteration 1:   EE criterion =  9.537e-33  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   .0261149   .0164826     1.58   0.113    -.0061903    .0584201
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |    .290968   .0110295    26.38   0.000     .2693506    .3125854
## ------------------------------------------------------------------------------</code></pre>
</div>
<div id="在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋" class="section level3">
<h3><span class="header-section-number">114.6.7</span> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</h3>
<p>這些假設包括：</p>
<ol style="list-style-type: decimal">
<li>無相互幹擾 no interference，解釋同前。</li>
<li>一致性 consistency，解釋同前。</li>
<li>條件可置換性 conditional exchangeability，解釋同前。</li>
<li>正確的模型結構 correct specification of the mode：調整了醫院，腫塊大小，和腫塊位置以後，患者的死亡或者疾病加重的對數比值 (log odds of death or diseae progression) 和腫塊大小，醫院，腫塊位置不再有任何依賴性(independent)，但是接受 RFA 療法和常規手術療法之間的<strong>療效差</strong>，被允許在不同的醫院，腫塊大小，以及腫塊位置的不同而有所不同。</li>
</ol>
</div>
<div id="前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同" class="section level3">
<h3><span class="header-section-number">114.6.8</span> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</h3>
<p>用 STATA 的 <code>teffects ra</code> 命令的時候，我們允許了療效差在不同的醫院，不同腫塊的大小，和不同腫塊的位置之間有所不同。The effect of treatment is allowed to differ nby hospital, position of the nodule and its diameter. 這種不同在擬合簡單邏輯回歸模型時是被忽略掉的。</p>
</div>
<div id="用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果" class="section level3">
<h3><span class="header-section-number">114.6.9</span> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</h3>
<p>模型 (b) 擬合的結果是邊際因果危險度差 (marginal causal risk difference)。情形 A. 所有患者都被實施 RFA 療法，和情形 B. 所有患者都被實施常規手術療法相比，患者中三年內死亡或者病情加重的比例 (proportion) 被估計要高出 0.026 (95%CI: -0.01, 0.06):</p>
<p><span class="math display">\[
E\{ Y(1) \} - E\{ Y(0) \}
\]</span></p>
</div>
<div id="如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢" class="section level3">
<h3><span class="header-section-number">114.6.10</span> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. 
## . teffects ra (dodp age gender i.smoke i.hospital nodules mets duration ///
## &gt;     maxdia i.primary i.position, logit) (rfa)
## 
## Iteration 0:   EE criterion =  1.417e-06  
## Iteration 1:   EE criterion =  1.527e-07  
## Iteration 2:   EE criterion =  1.726e-08  
## Iteration 3:   EE criterion =  3.724e-09  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   .0378445   .0137717     2.75   0.006     .0108525    .0648366
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .2856634   .0100116    28.53   0.000      .266041    .3052858
## ------------------------------------------------------------------------------
## 
## .</code></pre>
<p>ACE 的估計結果沒有發生非常劇烈的變化，但是，它的標準誤被大大降低了，有效地提高了療效估計的精確度。而且此時的結果已經提示平均因果危險度差是有統計學意義的 (p = 0.006)。這時候，對於整體患者來說，如果全部實施了 RFA，那麼和全部實施標準手術療法相比較會有略差的結果，這個相差是有統計學意義的。</p>
</div>
<div id="如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀" class="section level3">
<h3><span class="header-section-number">114.6.11</span> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. teffects ra (dodp age gender i.smoke i.hospital nodules mets duration ///
## &gt;     maxdia i.primary i.position coag, logit) (rfa)
## 
## Iteration 0:   EE criterion =  1.414e-06  
## Iteration 1:   EE criterion =  1.516e-07  
## Iteration 2:   EE criterion =  1.711e-08  
## Iteration 3:   EE criterion =  3.634e-09  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   .0401436   .0151604     2.65   0.008     .0104297    .0698574
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .2815725   .0101806    27.66   0.000     .2616189    .3015261
## ------------------------------------------------------------------------------</code></pre>
<p>ACE 的估計量的標準誤因為調整了只和暴露變量相關的變量 <code>coag</code> 變得比之前大了一些。但是此時的結果依然提示全部實施 RFA 療法的話結果會比全部實施常規手術治療要差。這裡應該考慮的是，因為 <code>coag</code> 本身不是暴露和結果變量之間的混雜因子，我們本不該調整這個變量，一旦調整了只和暴露變量相關的變量，我們<strong>反而會降低療效估計的精確度</strong>，所以不是說模型中想加多少變量就加多少變量的。(Violation of positivity)</p>
<p><strong>另外，已經有證據證明模型中調整了和暴露相關，但是並不是混雜因子的變量會嚴重增加估計量的偏倚</strong> <span class="citation">(Pearl <a href="#ref-Pearl2011" role="doc-biblioref">2011</a>)</span>。</p>
</div>
<div id="使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論" class="section level3">
<h3><span class="header-section-number">114.6.12</span> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. 
## . 
## . teffects ra (dodp, logit) (rfa), atet
## 
## Iteration 0:   EE criterion =  5.296e-17  
## Iteration 1:   EE criterion =  2.524e-32  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   -.113019   .0146495    -7.71   0.000    -.1417316   -.0843064
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .3208874   .0108592    29.55   0.000     .2996039     .342171
## ------------------------------------------------------------------------------
## 
## . 
## . teffects ra (dodp i.hospital maxdia i.position, logit) (rfa), atet
## 
## Iteration 0:   EE criterion =  6.343e-18  
## Iteration 1:   EE criterion =  6.101e-33  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |  -.0506326   .0164035    -3.09   0.002    -.0827828   -.0184824
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .2585011   .0141292    18.30   0.000     .2308084    .2861938
## ------------------------------------------------------------------------------
## 
## . 
## . teffects ra (dodp age gender i.smoke i.hospital nodules mets duration ///
## &gt;     maxdia i.primary i.position, logit) (rfa), atet
## 
## Iteration 0:   EE criterion =  1.118e-06  
## Iteration 1:   EE criterion =  9.719e-08  
## Iteration 2:   EE criterion =  2.682e-09  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |  -.0396473   .0137245    -2.89   0.004    -.0665468   -.0127479
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .2475158   .0130394    18.98   0.000      .221959    .2730726
## ------------------------------------------------------------------------------
## 
## . 
## . 
## . 
## . teffects ra (dodp age gender i.smoke i.hospital nodules mets duration ///
## &gt;     maxdia i.primary i.position coag, logit) (rfa), atet
## 
## Iteration 0:   EE criterion =  1.108e-06  
## Iteration 1:   EE criterion =  9.419e-08  
## Iteration 2:   EE criterion =  3.077e-09  
## 
## Treatment-effects estimation                    Number of obs     =      3,551
## Estimator      : regression adjustment
## Outcome model  : logit
## Treatment model: none
## ------------------------------------------------------------------------------
##              |               Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   -.031106   .0143989    -2.16   0.031    -.0593273   -.0028847
## -------------+----------------------------------------------------------------
## POmean       |
##          rfa |
## standard ..  |   .2389745   .0137425    17.39   0.000     .2120396    .2659094
## ------------------------------------------------------------------------------</code></pre>
<p>模型的最後加了 <code>atet</code> 之後最大的不同是導致結果分析的<strong>結論完全改變了</strong>。這時候 RFA 的療效反而變得有利起來。每個模型都給出了小於零的<strong>治療組因果危險度差 (causal risk difference in the treated)</strong>。這主要是因為接受 RFA療法和常規手術治療的兩類患者本身有太大的不同 (strong effect heterogeneity)。因為患者如果腫塊尺寸小， RFA 可以給出很好的預後，如果腫塊的位置太難找無法使用標準療法的時候又只能選用RFA。這些都是決定醫生最終給患者使用哪種療法的重要參考因素。所以如果 ATT 是小於零的，意味著，在那些(被)選擇了 RFA療法的患者中，療效是良好的，可以有效的減少三年內死亡和病情加重的概率。</p>
<p>另外值得一提的是，這裡調整了 <code>coag</code> 對ATT 估計的影響較小。這主要是因為，如果一個患者有凝血功能障礙，他/她就不可能接受 RFA 療法:</p>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. tab coag rfa, col chi
## 
## +-------------------+
## | Key               |
## |-------------------|
## |     frequency     |
## | column percentage |
## +-------------------+
## 
##            |  Treatment variable:
##            |    RFA or standard
## Coagulopat |        surgery
##         hy | standard   radiofreq |     Total
## -----------+----------------------+----------
##         no |     1,466      1,701 |     3,167 
##            |     79.33      99.88 |     89.19 
## -----------+----------------------+----------
##        yes |       382          2 |       384 
##            |     20.67       0.12 |     10.81 
## -----------+----------------------+----------
##      Total |     1,848      1,703 |     3,551 
##            |    100.00     100.00 |    100.00 
## 
##           Pearson chi2(1) = 388.2057   Pr = 0.000</code></pre>
<p>但是一個患者如果沒有凝血功能障礙，那麼他/她接受哪種療法就變得不受 <code>coag</code> 的影響。而此時我們使用 <code>etat</code> 估算的是所有接受 RFA 療法的患者中的療效。這裡受到模型變量共線性影響就較小。</p>
</div>
</div>
</div>
<div id="prospensity-score-傾向性評分" class="section level1">
<h1><span class="header-section-number">第 115 章</span> Prospensity Score 傾向性評分</h1>

<div class="definition">
<p><span id="def:16-ASM-Causal-infer-20" class="definition"><strong>Definition 115.1  </strong></span><strong>傾向性評分 propensity score:</strong> 如果研究中結果變量為 <span class="math inline">\(Y\)</span>，二分類的暴露變量 <span class="math inline">\(X\)</span>，以及條件變量 <span class="math inline">\(\mathbf{C}\)</span>，那麼每個觀察對象的傾向性評分 <span class="math inline">\(p\mathbf{C}\)</span> 可以被定義為，一個觀察對象真實被觀察到暴露變量 <span class="math inline">\(X=1\)</span> 的條件概率(<span class="math inline">\(p\mathbf{C}\)</span> is defined as the conditional probability of being exposed given covariates)：</p>
<span class="math display">\[
p(\mathbf{C}) = \text{Pr}(X=1 | \mathbf{C})
\]</span>
</div>

<p>注意，傾向性評分 propensity score，本質上僅僅只是一個標量 scalar，而不是條件變量那樣的多維變量。</p>
<p>而且，條件可置換性這一重要的前提假設，被 <span class="citation">(Rosenbaum and Rubin <a href="#ref-Rosenbaum1983" role="doc-biblioref">1983</a>)</span> 證明是可以拓展到這個標量的:</p>

<div class="theorem">
<p><span id="thm:16-ASM-Causal-infer-21" class="theorem"><strong>Theorem 115.1  </strong></span><strong>傾向性評分的最重要性質:</strong></p>
<p><span class="math display">\[
Y(x) \perp\perp X|\mathbf{C}, x=0,1 \Rightarrow Y(x) \perp\perp X|p(\mathbf{C}, x=0, 1)
\]</span></p>
<span class="citation">(Rosenbaum and Rubin <a href="#ref-Rosenbaum1983" role="doc-biblioref">1983</a>)</span>
</div>

<p>這一重要的性質告訴我們，其實在考慮調整混雜因素的時候，我們可以專注考慮這一個標量作爲混雜因素。實際操作中，這個標量通常需要通過一個邏輯回歸模型來擬合計算。這個計算傾向性評分的邏輯回歸模型，用的是對象是否被暴露作爲結果變量，用其他的和這個暴露相關的混雜因素作爲預測變量 <span class="math inline">\(X|\mathbf{C}\)</span>。</p>
<div id="關於條件可置換性" class="section level3">
<h3><span class="header-section-number">115.0.1</span> 關於條件可置換性</h3>
<p>如果兩個觀察對象，經過計算，他們二人的傾向性評分相同，那麼從這些條件變量來看，這兩個對象是否被暴露，就是<strong>完全隨機的</strong>，他們有相同的概率屬於被暴露或非暴露人羣。這一點和RCT有些相似，如果，一個完美的隨機化試驗，那麼一個患者被分進治療組或者對照組的概率是完全相同的，他們是完全可以置換的 (exchangeable)。所以，在一個觀察性研究中，如果傾向性評分相同，在給定的觀察到的所有混雜因素的條件下，這兩個對象是否暴露的概率是相同的 (可以條件置換的 conditional exchangeability given the propensity score)。</p>
<p>當然和RCT相比，這兩個概念的本質區別在於，隨機化臨牀實驗是通過實驗設計手段，保證了研究對象的完全可置換。觀察性研究，則沒有這個優點，因爲他們的可置換性質是由觀察到的混雜因子決定的，許多觀察性研究的混雜因子都無法保證全部觀察得到。條件可置換性是<strong>一個非常強的假設</strong>，因爲它假定我們真的把所有的混雜都觀察到了。</p>

<div class="example">
<span id="exm:16-ASM-Causal-infer-22" class="example"><strong>Example 115.1  </strong></span>前一章的練習題中的例子是，3351 名肺癌患者，其中 1848 名患者接受了標準手術摘除腫塊療法，另外 1703 名患者接受了高頻消蝕法 (RFA) 治療。表面上看，這兩個療法的3年存活率是 RFA 較高 (79.2% vs. 67.9%)，但是潛在的混雜因素很明顯: 因爲 RFA 無法治療尺寸較大的腫塊，所以腫塊大的病人醫生就傾向於給予標準手術摘除法，所以，腫塊大小本身造成了療效差異的混雜。因爲那些接受 RFA 治療的癌症患者腫塊多較小，那麼他們的預後本身也就會比較好。
</div>

<p>這個例子中的混雜因子包括: 年齡，性別，醫院 (1/2/3/4)，吸煙 (non, ex, current)，腫塊數量，其他腫瘤轉移部位，患者已患癌症的時間，腫塊的大小，主要癌症的部位 (膀胱，乳腺，大腸，食道，腎，皮膚，胃，睾丸等)，還有一個腫塊是否容易被摘除的難易程度 (容易，中等，困難)。那麼，我們可以給患者擬合下面的模型做傾向性評分:</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}\{ \text{Pr(RFA}|\mathbf{C} \}  = &amp; \beta_0 + \beta_1\text{age} + \beta_2 \text{gender}+ \beta_3I(\text{hospital = 2}) \\
&amp; +\beta_4I(\text{hospital =3}) + \beta_5I(\text{hospital = 4}) + \beta_6I(\text{smoke = 2} )\\
&amp; + \beta_7I(\text{smoke = 3}) + \beta_8\text{nodules} + \beta_9\text{mets} + \beta_{10}\text{duration} \\
&amp; + \cdots + \beta_{20}I(\text{primary = 9}) + \beta_{21}I(\text{position = 2}) + \beta_{22}I(\text{position = 3})
\end{aligned}
\]</span></p>
<p>擬合了這個模型，計算每個參數 <span class="math inline">\(\beta_0 sim \beta_22\)</span> 的極大似然估計之後，就可以計算每個患者的傾向性評分:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{p}(\mathbf{C}_i) = &amp; \text{expit}\{ \hat\beta_0 + \hat\beta_1\text{age} + \hat\beta_2 \text{gender}+ \hat\beta_3I(\text{hospital = 2}) \\
&amp; +\hat\beta_4I(\text{hospital =3}) + \hat\beta_5I(\text{hospital = 4}) + \hat\beta_6I(\text{smoke = 2} )\\
&amp; + \hat\beta_7I(\text{smoke = 3}) + \hat\beta_8\text{nodules} + \hat\beta_9\text{mets} + \hat\beta_{10}\text{duration} \\
&amp; + \cdots + \hat\beta_{20}I(\text{primary = 9}) + \hat\beta_{21}I(\text{position = 2}) + \hat\beta_{22}I(\text{position = 3}) \}
\end{aligned}
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
\text{expit}(a) = \frac{\exp(a)}{1+\exp(a)}
\]</span></p>
<p>下面就是傾向性評分模型的輸出結果:</p>
<pre><code>## 
## Call:
## glm(formula = rfa ~ age + gender + smoke + hospital + nodules + 
##     mets + duration + maxdia + primary + position, family = binomial(link = logit), 
##     data = RFAcat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.53460  -0.86875  -0.30119   0.89717   2.64611  
## 
## Coefficients:
##                Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  2.95798757  0.61770661   4.7887 1.679e-06 ***
## age         -0.00044027  0.00992941  -0.0443   0.96463    
## gender1      0.10435375  0.15103436   0.6909   0.48961    
## smoke1       0.11861648  0.15106839   0.7852   0.43235    
## smoke2       0.09342271  0.10380671   0.9000   0.36814    
## hospital2   -0.23564078  0.14243617  -1.6544   0.09805 .  
## hospital3    0.30045787  0.13850888   2.1692   0.03007 *  
## hospital4   -0.11174925  0.19236619  -0.5809   0.56129    
## nodules     -0.02987712  0.01820608  -1.6411   0.10079    
## mets         0.06514394  0.04672394   1.3942   0.16325    
## duration     0.00260668  0.00488559   0.5335   0.59366    
## maxdia      -2.26045488  0.08773789 -25.7637 &lt; 2.2e-16 ***
## primary2     0.09927913  0.29102032   0.3411   0.73300    
## primary3     0.14593436  0.29460236   0.4954   0.62035    
## primary4    -0.00212669  0.38021005  -0.0056   0.99554    
## primary5    -0.22135219  0.37933124  -0.5835   0.55953    
## primary6     0.04504894  0.34609342   0.1302   0.89644    
## primary7     1.57439087  0.64792618   2.4299   0.01510 *  
## primary8     0.21261200  0.38272919   0.5555   0.57854    
## primary9     0.33223472  0.40566455   0.8190   0.41279    
## position2    0.94096446  0.10080061   9.3349 &lt; 2.2e-16 ***
## position3    1.22134526  0.11678128  10.4584 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 4916.81  on 3550  degrees of freedom
## Residual deviance: 3834.74  on 3529  degrees of freedom
## AIC: 3878.74
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>正如我們預料的那樣，醫院，腫塊尺寸，和腫塊的位置是患者接受 RFA 治療與否的重要預測指標。</p>
<div class="figure" style="text-align: center"><span id="fig:propscore00"></span>
<img src="bookdown_files/figure-html/propscore00-1.png" alt="Density and histogram of the estimated propensity score in the two exposure groups." width="80%" />
<p class="caption">
圖 115.1: Density and histogram of the estimated propensity score in the two exposure groups.
</p>
</div>
<p>從圖 <a href="#fig:propscore00">115.1</a> 可以看出評分在兩個暴露組中的分布交叉十分令人滿意。</p>
</div>
<div id="怎樣使用傾向性評分" class="section level2">
<h2><span class="header-section-number">115.1</span> 怎樣使用傾向性評分</h2>
<p>傾向性評分在實際操作中的運用:</p>
<ol style="list-style-type: decimal">
<li><strong>分層 stratification</strong>: 把觀察對象按照傾向性評分的高低分層成爲幾個組，進行組內的療效比較;</li>
<li><strong>配對 matching</strong>: 在真實的暴露組中的對象，爲他們每個人找一個非暴露的人，一兩個對象的傾向性評分盡可能接近爲配對的方法;</li>
<li><strong>在模型中調整 adjustment</strong>: 在回歸模型中調整這個傾向性評分，而不是調整那些計算評分時的那些條件變量;</li>
<li>給每個研究對象按照其評分得分，使用<strong>逆向加權法 (inverse weighting)</strong>。</li>
</ol>
<div id="分層法-stratification" class="section level3">
<h3><span class="header-section-number">115.1.1</span> 分層法 stratification</h3>
<p><img src="img/Selection_133.png" width="90%" style="display: block; margin: auto;" /></p>
<p><span class="math display">\[
\widehat{\text{ACE}}  = \frac{13.1 + 6.0 - 4.8 - 13.4}{4} = 0.2%
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{ATT}} &amp; = \frac{13.1\times100 + 6.0\times341 - 4.8\times544 - 13.4\times718}{100 + 341 + 544 + 718} \\
&amp; = -5.2%\\
\end{aligned}
\]</span></p>
<p>再次印證了之前一章練習中的計算結果，也就是 RFA 如果施加給整體患者，那麼甚至可能還稍微提高三年內死亡/病情加重的概率。但是如果只給適合 RFA 療法的人，那麼 RFA 能明顯地降低死亡/病情加重的概率。</p>
</div>
<div id="配對法-matching" class="section level3">
<h3><span class="header-section-number">115.1.2</span> 配對法 matching</h3>
<p>用肺癌數據的例子來解釋，就是</p>
<p>從選擇了 RFA 療法的患者出發，在標準療法的患者中尋找一名或者多名和 RFA 療法患者的評分接近的患者作對照，這樣計算的是 ATT (average treatment effect in the treated)。</p>
<p>從選擇了標準手術療法的患者出發，在 RFA 療法的患者中尋找一名或者多名和 RFA 療法患者的評分接近的患者作對照，這樣計算的是 非暴露組中的平均療效 (average treatment effect in the untreated/unexposed)。</p>
<p>此時，配對患者選用是可以重復出現的 (replacement is allowed)，所以，有的對照可能同時給好幾個病例做對照也有可能。所以當你的樣本可能不平衡，那麼從樣本量大的那一部分出發的時候，就會出現這種情況。</p>
<p>選擇配對的方法也有很多:</p>
<ul>
<li>nearest neighbour matching (wthin calipers defined by the PS)</li>
<li>Kernel matching (nearest neighbour matching chooses one match)</li>
<li>etc.</li>
</ul>
<p>如果數據不適合使用傾向性評分法，那麼只要一做配對，就能立刻發現數據的問題，因爲如果違反了 positivity，那麼樣本中的某一組患者可能就大量地找不到相同相似PS評分的配對。另外配對法，可以配合調整變量共同使用，以增加估計的效能和穩健性。從經驗上來看 1:1 配對常常造成的效果是統計效能較低，而且即使使用配對法，觀察性研究還是觀察性研究，殘差混雜 (residual confounding) 依然存在。而且配對法導致估計量的標準誤難以估計，即使用自助重抽 (bootstrapping) 也常常是沒有效果。還好牛人 <span class="citation">(Abadie and Imbens <a href="#ref-Abadie2016" role="doc-biblioref">2016</a>)</span> 發現並發表了配對評分時的有效方差估計法，這個方法也已經加入了 STATA。</p>
<p>在 STATA 裏使用 <code>teffects psmatch</code> 命令執行傾向性評分的配對法</p>
<pre><code>## 
## 
## . use &quot;backupfiles/RFA.dt. teffects psmatch (dodp) (rfa age gender i.smoke i.hospital nodules mets durat
## &gt; ion maxdia i.primary i.position, logit)
## 
## Treatment-effects estimation                   Number of obs      =      3,551
## Estimator      : propensity-score matching     Matches: requested =          1
## Outcome model  : matching                                     min =          1
## Treatment model: logit                                        max =          1
## ------------------------------------------------------------------------------
##              |              AI Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   .0154886   .0204308     0.76   0.448     -.024555    .0555322
## ------------------------------------------------------------------------------
## 
## . 
## . teffects psmatch (dodp) (rfa age gender i.smoke i.hospital nodules mets durat
## &gt; ion maxdia i.primary i.position, logit), atet
## 
## Treatment-effects estimation                   Number of obs      =      3,551
## Estimator      : propensity-score matching     Matches: requested =          1
## Outcome model  : matching                                     min =          1
## Treatment model: logit                                        max =          1
## ------------------------------------------------------------------------------
##              |              AI Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATET         |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |  -.0387551   .0199095    -1.95   0.052    -.0777771    .0002668
## ------------------------------------------------------------------------------</code></pre>
<p>可見，結果和目前爲止計算的結果是吻合的。值得注意的是，配對法在文獻中被發現是最常(濫)用的方法，這裏提評分的配對法，不是因爲我贊成使用這種方法，而是因爲它常見，所以你需要知道這種配對的背後到底在幹啥。顯而易見的是，傾向性評分有它更好的使用方法 (逆向權重)。</p>
</div>
<div id="回歸模型校正法-adjustment" class="section level3">
<h3><span class="header-section-number">115.1.3</span> 回歸模型校正法 adjustment</h3>
<p><span class="math display">\[
E\{Y|X,p(\mathbf{C}) \} = \alpha + \beta X + \gamma p(\mathbf{C})
\]</span></p>
<p>校正傾向性評分，可以一定程度上克服<strong>有限樣本造成的偏倚 (finite sample bias)</strong>。</p>
</div>
</div>
<div id="practical05---causal-inference" class="section level2">
<h2><span class="header-section-number">115.2</span> Practical05 - causal inference</h2>
<p>數據還是和前一章節一樣的數據。傾向性評分的 R 包有很多，下面用 R 來進行大多數的計算。</p>
<div id="初步熟悉數據內容" class="section level3">
<h3><span class="header-section-number">115.2.1</span> 初步熟悉數據內容</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFAcat.dt. describe
## 
## Contains data from backupfiles/RFAcat.dta
##   obs:         3,551                          
##  vars:            18                          5 Nov 2013 15:05
##  size:       255,672                          
## -------------------------------------------------------------------------------
##               storage   display    value
## variable name   type    format     label      variable label
## -------------------------------------------------------------------------------
## id              float   %9.0g                 Patient ID
## age             float   %9.0g                 
## gender          float   %9.0g      gender     
## smoke           float   %9.0g      smoke      Smoking status
## hospital        float   %9.0g                 Hospital ID
## nodules         float   %9.0g                 Number of nodules
## mets            float   %9.0g                 Number of other metastatic sites
## duration        float   %9.0g                 Duration of disease (in months)
## maxdia          float   %9.0g                 Diameter of largest nodule (in
##                                                 cm)
## primary         float   %22.0g     primary    Location of primary cancer
## position        float   %9.0g      position   Ease with which nodules can be
##                                                 reached
## coag            float   %9.0g      coag       Coagulopathy
## rfa             float   %23.0g     rfa        Treatment variable: RFA or
##                                                 standard surgery
## dodp            float   %9.0g      dodp       Outcome variable: death or
##                                                 disease progression within 36
##                                                 months
## agecat          float   %9.0g      agecat     Age in categories
## nodcat          float   %9.0g      nodcat     Number of nodules in categories
## durcat          float   %12.0g     durcat     Duration of disease in categories
## diacat          float   %9.0g      diacat     Diameter of largest nodule in
##                                                 categories
## -------------------------------------------------------------------------------
## Sorted by: id
## 
## . 
## . **********************
## . *  Explore the data  *
## . **********************
## . 
## . /*  Question 1  */
## . * Exposure and outcome
## . tab rfa
## 
## Treatment variable: RFA |
##     or standard surgery |      Freq.     Percent        Cum.
## ------------------------+-----------------------------------
##        standard surgery |      1,848       52.04       52.04
## radiofrequency ablation |      1,703       47.96      100.00
## ------------------------+-----------------------------------
##                   Total |      3,551      100.00
## 
## . tab dodp rfa, col
## 
## +-------------------+
## | Key               |
## |-------------------|
## |     frequency     |
## | column percentage |
## +-------------------+
## 
##    Outcome |
##  variable: |
##   death or |
##    disease |  Treatment variable:
## progressio |    RFA or standard
##   n within |        surgery
##  36 months | standard   radiofreq |     Total
## -----------+----------------------+----------
##         no |     1,255      1,349 |     2,604 
##            |     67.91      79.21 |     73.33 
## -----------+----------------------+----------
##        yes |       593        354 |       947 
##            |     32.09      20.79 |     26.67 
## -----------+----------------------+----------
##      Total |     1,848      1,703 |     3,551 
##            |    100.00     100.00 |    100.00 
## 
## 
## . 
## . * New (categorised) variables: 
## . tab1 agecat nodcat durcat diacat, m
## 
## -&gt; tabulation of agecat  
## 
##      Age in |
##  categories |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##         &lt;45 |         96        2.70        2.70
##       45-49 |        860       24.22       26.92
##       50-54 |      1,755       49.42       76.34
##       55-59 |        662       18.64       94.99
##       60-64 |        135        3.80       98.79
##         65+ |         43        1.21      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## -&gt; tabulation of nodcat  
## 
##   Number of |
##  nodules in |
##  categories |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##           1 |        997       28.08       28.08
##           2 |      1,350       38.02       66.09
##           3 |        635       17.88       83.98
##           4 |        204        5.74       89.72
##         5-9 |        304        8.56       98.28
##         10+ |         61        1.72      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## -&gt; tabulation of durcat  
## 
##  Duration of |
##   disease in |
##   categories |      Freq.     Percent        Cum.
## -------------+-----------------------------------
##   &lt;10 months |         53        1.49        1.49
## 10-19 months |      1,437       40.47       41.96
## 20-29 months |      1,528       43.03       84.99
## 30-39 months |        397       11.18       96.17
##   40+ months |        136        3.83      100.00
## -------------+-----------------------------------
##        Total |      3,551      100.00
## 
## -&gt; tabulation of diacat  
## 
## Diameter of |
##     largest |
##   nodule in |
##  categories |      Freq.     Percent        Cum.
## ------------+-----------------------------------
##     &lt;1.5 cm |        967       27.23       27.23
##   1.5-1.9cm |      1,147       32.30       59.53
##     2-2.4cm |        940       26.47       86.00
##   2.5-2.9cm |        403       11.35       97.35
##        3cm+ |         94        2.65      100.00
## ------------+-----------------------------------
##       Total |      3,551      100.00
## 
## .</code></pre>
</div>
<div id="把連續型變量以分類型數據的形式放入模型中" class="section level3">
<h3><span class="header-section-number">115.2.2</span> 把連續型變量以分類型數據的形式放入模型中:</h3>
<pre><code>***************************
*  Regression adjustment  *
***************************

/*  Question 2  */
// teffects ra (dodp   i.agecat gender i.smoke i.hospital i.nodcat ///
// i.mets i.durcat i.diacat i.primary i.position,   ///
// logit) (rfa)</code></pre>
<p>你會發現 STATA 停不下來，計算永遠都不會收斂。這是因爲我們在這個模型中結果部分加入了太多的分類型變量，但數據又沒辦法進行足夠的計算。</p>
</div>
<div id="用相同的模型結構估計每個人的傾向性評分" class="section level3">
<h3><span class="header-section-number">115.2.3</span> 用相同的模型結構估計每個人的傾向性評分</h3>
<div class="sourceCode" id="cb1756"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1756-1" title="1">RFAcat &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/RFAcat.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1756-2" title="2">RFAcat &lt;-<span class="st"> </span>RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1756-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">gender =</span> <span class="kw">factor</span>(gender, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;men&quot;</span>, <span class="st">&quot;women&quot;</span>)), </a>
<a class="sourceLine" id="cb1756-4" title="4">         <span class="dt">smoke =</span> <span class="kw">factor</span>(smoke, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;never&quot;</span>, <span class="st">&quot;ex&quot;</span>, <span class="st">&quot;current&quot;</span>)),</a>
<a class="sourceLine" id="cb1756-5" title="5">         <span class="dt">hospital =</span> <span class="kw">as.factor</span>(hospital),</a>
<a class="sourceLine" id="cb1756-6" title="6">         <span class="dt">primary =</span> <span class="kw">factor</span>(primary, <span class="dt">labels =</span>  <span class="kw">c</span>(<span class="st">&quot;bladder&quot;</span>, </a>
<a class="sourceLine" id="cb1756-7" title="7">                                     <span class="st">&quot;breast&quot;</span>, </a>
<a class="sourceLine" id="cb1756-8" title="8">                                     <span class="st">&quot;colorectal&quot;</span>,</a>
<a class="sourceLine" id="cb1756-9" title="9">                                     <span class="st">&quot;gullet&quot;</span>, </a>
<a class="sourceLine" id="cb1756-10" title="10">                                     <span class="st">&quot;kidney&quot;</span>,</a>
<a class="sourceLine" id="cb1756-11" title="11">                                     <span class="st">&quot;prostate&quot;</span>,</a>
<a class="sourceLine" id="cb1756-12" title="12">                                     <span class="st">&quot;skin&quot;</span>,</a>
<a class="sourceLine" id="cb1756-13" title="13">                                     <span class="st">&quot;stomach&quot;</span>, </a>
<a class="sourceLine" id="cb1756-14" title="14">                                     <span class="st">&quot;testicular&quot;</span>)),</a>
<a class="sourceLine" id="cb1756-15" title="15">         <span class="dt">position =</span> <span class="kw">factor</span>(position, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;easy&quot;</span>, <span class="st">&quot;moderate&quot;</span>, <span class="st">&quot;difficult&quot;</span>)),</a>
<a class="sourceLine" id="cb1756-16" title="16">         <span class="dt">nodcat =</span> <span class="kw">factor</span>(nodcat, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>,<span class="st">&quot;2&quot;</span>,<span class="st">&quot;3&quot;</span>,<span class="st">&quot;4&quot;</span>,<span class="st">&quot;5-9&quot;</span>,<span class="st">&quot;10+&quot;</span>)),</a>
<a class="sourceLine" id="cb1756-17" title="17">         <span class="dt">mets =</span> <span class="kw">as.factor</span>(mets), </a>
<a class="sourceLine" id="cb1756-18" title="18">         <span class="dt">agecat =</span> <span class="kw">factor</span>(agecat, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;&lt; 45&quot;</span>, <span class="st">&quot;45-49&quot;</span>, <span class="st">&quot;50-54&quot;</span>, <span class="st">&quot;55-59&quot;</span>, <span class="st">&quot;60-64&quot;</span>,<span class="st">&quot;65+&quot;</span>)), </a>
<a class="sourceLine" id="cb1756-19" title="19">         <span class="dt">durcat =</span> <span class="kw">factor</span>(durcat, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;&lt; 10m&quot;</span>, <span class="st">&quot;10-19m&quot;</span>, <span class="st">&quot;20-29m&quot;</span>, <span class="st">&quot;30-39m&quot;</span>, <span class="st">&quot;40+m&quot;</span>)), </a>
<a class="sourceLine" id="cb1756-20" title="20">         <span class="dt">diacat =</span> <span class="kw">factor</span>(diacat, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;&lt;1.5cm&quot;</span>, <span class="st">&quot;1.5-1.9cm&quot;</span>, <span class="st">&quot;2-2.4cm&quot;</span>, <span class="st">&quot;2.5-2.9cm&quot;</span>, </a>
<a class="sourceLine" id="cb1756-21" title="21">                                            <span class="st">&quot;3cm+&quot;</span>)))</a>
<a class="sourceLine" id="cb1756-22" title="22">Pros_Score &lt;-<span class="st"> </span><span class="kw">glm</span>(rfa <span class="op">~</span><span class="st"> </span>agecat <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>hospital <span class="op">+</span><span class="st"> </span>nodcat <span class="op">+</span><span class="st"> </span>mets <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1756-23" title="23"><span class="st">                    </span>durcat <span class="op">+</span><span class="st"> </span>diacat <span class="op">+</span><span class="st"> </span>primary <span class="op">+</span><span class="st"> </span>position, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), </a>
<a class="sourceLine" id="cb1756-24" title="24">                  <span class="dt">data =</span> RFAcat)</a>
<a class="sourceLine" id="cb1756-25" title="25"><span class="kw">summary</span>(Pros_Score)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = rfa ~ agecat + gender + smoke + hospital + nodcat + 
##     mets + durcat + diacat + primary + position, family = binomial(link = logit), 
##     data = RFAcat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.45628  -0.90333  -0.26702   0.90927   2.67426  
## 
## Coefficients:
##                    Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)        0.243514   0.505730   0.4815  0.630154    
## agecat45-49        0.090044   0.261908   0.3438  0.730996    
## agecat50-54        0.107064   0.255438   0.4191  0.675115    
## agecat55-59       -0.040906   0.269042  -0.1520  0.879154    
## agecat60-64        0.074712   0.327138   0.2284  0.819351    
## agecat65+          0.398326   0.431966   0.9221  0.356464    
## genderwomen        0.083521   0.151596   0.5509  0.581673    
## smokeex            0.117319   0.150316   0.7805  0.435105    
## smokecurrent       0.144515   0.104757   1.3795  0.167732    
## hospital2         -0.190892   0.140877  -1.3550  0.175407    
## hospital3          0.345035   0.138004   2.5002  0.012413 *  
## hospital4         -0.094451   0.191935  -0.4921  0.622648    
## nodcat2           -0.085830   0.097834  -0.8773  0.380324    
## nodcat3           -0.012021   0.118491  -0.1014  0.919195    
## nodcat4            0.143596   0.182086   0.7886  0.430336    
## nodcat5-9         -0.482427   0.156551  -3.0816  0.002059 ** 
## nodcat10+          0.043502   0.299620   0.1452  0.884561    
## mets1              0.100543   0.099312   1.0124  0.311349    
## mets2              0.139866   0.105583   1.3247  0.185272    
## mets3             -0.091375   0.296308  -0.3084  0.757795    
## durcat10-19m       0.038115   0.342352   0.1113  0.911352    
## durcat20-29m      -0.009245   0.341993  -0.0270  0.978434    
## durcat30-39m       0.127019   0.356684   0.3561  0.721758    
## durcat40+m         0.159252   0.394089   0.4041  0.686138    
## diacat1.5-1.9cm   -1.053938   0.100734 -10.4626 &lt; 2.2e-16 ***
## diacat2-2.4cm     -2.223150   0.109874 -20.2337 &lt; 2.2e-16 ***
## diacat2.5-2.9cm   -3.781319   0.199920 -18.9142 &lt; 2.2e-16 ***
## diacat3cm+        -4.216794   0.470139  -8.9693 &lt; 2.2e-16 ***
## primarybreast      0.070017   0.288955   0.2423  0.808540    
## primarycolorectal  0.087730   0.292264   0.3002  0.764044    
## primarygullet     -0.091053   0.378701  -0.2404  0.809993    
## primarykidney     -0.269296   0.377865  -0.7127  0.476046    
## primaryprostate   -0.027718   0.344383  -0.0805  0.935850    
## primaryskin        1.557764   0.670168   2.3244  0.020102 *  
## primarystomach     0.134603   0.380885   0.3534  0.723792    
## primarytesticular  0.304981   0.403875   0.7551  0.450167    
## positionmoderate   0.891048   0.099587   8.9474 &lt; 2.2e-16 ***
## positiondifficult  1.178730   0.116364  10.1296 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 4916.81  on 3550  degrees of freedom
## Residual deviance: 3852.35  on 3513  degrees of freedom
## AIC: 3928.35
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb1758"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1758-1" title="1">RFAcat<span class="op">$</span>Score &lt;-<span class="st"> </span>Pros_Score<span class="op">$</span>fitted.values <span class="co"># extract the fitted scores</span></a>
<a class="sourceLine" id="cb1758-2" title="2"><span class="kw">ggthemr</span>(<span class="st">&#39;fresh&#39;</span>, <span class="dt">layout =</span> <span class="st">&#39;scientific&#39;</span>)</a>
<a class="sourceLine" id="cb1758-3" title="3">RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1758-4" title="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Score, <span class="dt">y=</span> ..density.., <span class="dt">fill =</span> <span class="kw">as.factor</span>(rfa))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1758-5" title="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">position =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1758-6" title="6"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1758-7" title="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>),</a>
<a class="sourceLine" id="cb1758-8" title="8">        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb1758-9" title="9">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1758-10" title="10">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb1758-11" title="11"><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>), </a>
<a class="sourceLine" id="cb1758-12" title="12">  <span class="dt">legend.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">19</span>),</a>
<a class="sourceLine" id="cb1758-13" title="13">  <span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, <span class="dt">legend.direction =</span> <span class="st">&quot;horizontal&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1758-14" title="14"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">fill =</span> <span class="st">&quot;Treatment Methods&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1758-15" title="15"><span class="st">  </span><span class="kw">scale_fill_discrete</span>(<span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Standard surgery&quot;</span>, <span class="st">&quot;RFA&quot;</span>)); <span class="kw">ggthemr_reset</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:CI-05-exe01"></span>
<img src="bookdown_files/figure-html/CI-05-exe01-1.png" alt="Density and histogram of the estimated propensity score in the two exposure groups, **with confounders and predictors of outcome included in the PS model.**" width="80%" />
<p class="caption">
圖 115.2: Density and histogram of the estimated propensity score in the two exposure groups, <strong>with confounders and predictors of outcome included in the PS model.</strong>
</p>
</div>
<p>概率密度分布圖和直方圖的內容告訴我們兩個暴露組患者的評分分布的交叉部分十分令人滿意，positivity 的前提假設可認爲得到滿足 (每個患者都有非零的概率接受 RFA 或者標準手術療法)。</p>
<p>一種比較組與組之間不同量的指標: standardized (mean) difference <span class="citation">(Austin <a href="#ref-Austin2011" role="doc-biblioref">2011</a>)</span>，可以用下面的方法來計算，使用 <code>tableone</code> 這個方便的 R 包:</p>
<div class="sourceCode" id="cb1759"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1759-1" title="1"><span class="co"># covariates</span></a>
<a class="sourceLine" id="cb1759-2" title="2">Cov &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;agecat&quot;</span>, <span class="st">&quot;gender&quot;</span>, <span class="st">&quot;smoke&quot;</span>, <span class="st">&quot;hospital&quot;</span>, <span class="st">&quot;nodcat&quot;</span>, <span class="st">&quot;mets&quot;</span>, <span class="st">&quot;durcat&quot;</span>, <span class="st">&quot;diacat&quot;</span>, </a>
<a class="sourceLine" id="cb1759-3" title="3">         <span class="st">&quot;primary&quot;</span>, <span class="st">&quot;position&quot;</span>)</a>
<a class="sourceLine" id="cb1759-4" title="4"><span class="co">## Construct a table</span></a>
<a class="sourceLine" id="cb1759-5" title="5">tabUnmatched &lt;-<span class="st"> </span><span class="kw">CreateTableOne</span>(<span class="dt">vars =</span> Cov, <span class="dt">strata =</span> <span class="st">&quot;rfa&quot;</span>, <span class="dt">data =</span> RFAcat, <span class="dt">test =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1759-6" title="6"><span class="co">## Show table with SMD</span></a>
<a class="sourceLine" id="cb1759-7" title="7"><span class="kw">print</span>(tabUnmatched, <span class="dt">smd =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##                     Stratified by rfa
##                      0            1            SMD   
##   n                  1848         1703               
##   agecat (%)                                    0.065
##      &lt; 45              51 ( 2.8)    45 ( 2.6)        
##      45-49            463 (25.1)   397 (23.3)        
##      50-54            891 (48.2)   864 (50.7)        
##      55-59            352 (19.0)   310 (18.2)        
##      60-64             72 ( 3.9)    63 ( 3.7)        
##      65+               19 ( 1.0)    24 ( 1.4)        
##   gender = women (%)  726 (39.3)   701 (41.2)   0.038
##   smoke (%)                                     0.031
##      never           1279 (69.2)  1157 (67.9)        
##      ex               135 ( 7.3)   136 ( 8.0)        
##      current          434 (23.5)   410 (24.1)        
##   hospital (%)                                  0.115
##      1                308 (16.7)   262 (15.4)        
##      2                349 (18.9)   282 (16.6)        
##      3                677 (36.6)   718 (42.2)        
##      4                514 (27.8)   441 (25.9)        
##   nodcat (%)                                    0.096
##      1                505 (27.3)   492 (28.9)        
##      2                703 (38.0)   647 (38.0)        
##      3                325 (17.6)   310 (18.2)        
##      4                104 ( 5.6)   100 ( 5.9)        
##      5-9              181 ( 9.8)   123 ( 7.2)        
##      10+               30 ( 1.6)    31 ( 1.8)        
##   mets (%)                                      0.061
##      0               1089 (58.9)   969 (56.9)        
##      1                393 (21.3)   375 (22.0)        
##      2                327 (17.7)   331 (19.4)        
##      3                 39 ( 2.1)    28 ( 1.6)        
##   durcat (%)                                    0.070
##      &lt; 10m             31 ( 1.7)    22 ( 1.3)        
##      10-19m           731 (39.6)   706 (41.5)        
##      20-29m           820 (44.4)   708 (41.6)        
##      30-39m           197 (10.7)   200 (11.7)        
##      40+m              69 ( 3.7)    67 ( 3.9)        
##   diacat (%)                                    1.086
##      &lt;1.5cm           222 (12.0)   745 (43.7)        
##      1.5-1.9cm        507 (27.4)   640 (37.6)        
##      2-2.4cm          661 (35.8)   279 (16.4)        
##      2.5-2.9cm        369 (20.0)    34 ( 2.0)        
##      3cm+              89 ( 4.8)     5 ( 0.3)        
##   primary (%)                                   0.126
##      bladder           46 ( 2.5)    35 ( 2.1)        
##      breast           423 (22.9)   401 (23.5)        
##      colorectal       694 (37.6)   671 (39.4)        
##      gullet            75 ( 4.1)    55 ( 3.2)        
##      kidney            66 ( 3.6)    47 ( 2.8)        
##      prostate         365 (19.8)   324 (19.0)        
##      skin               5 ( 0.3)    17 ( 1.0)        
##      stomach           86 ( 4.7)    67 ( 3.9)        
##      testicular        88 ( 4.8)    86 ( 5.0)        
##   position (%)                                  0.332
##      easy             565 (30.6)   292 (17.1)        
##      moderate         899 (48.6)   921 (54.1)        
##      difficult        384 (20.8)   490 (28.8)</code></pre>
<div class="sourceCode" id="cb1761"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1761-1" title="1"><span class="co">## Count covariates with important imbalance</span></a>
<a class="sourceLine" id="cb1761-2" title="2"><span class="kw">addmargins</span>(<span class="kw">table</span>(<span class="kw">ExtractSmd</span>(tabUnmatched) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.08</span>))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE   Sum 
##     5     5    10</code></pre>
<p>嚴重不平衡的變量有 5 個: <code>hospital, nodcat, diaact, primary, position</code>。</p>
</div>
<div id="用-ps-評分來把對象分層-stratification" class="section level3">
<h3><span class="header-section-number">115.2.4</span> 用 PS 評分來把對象分層 stratification</h3>
<div class="sourceCode" id="cb1763"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1763-1" title="1">RFAcat &lt;-<span class="st"> </span>RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1763-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">psblock =</span> <span class="kw">ntile</span>(Score, <span class="dv">4</span>))</a>
<a class="sourceLine" id="cb1763-3" title="3"></a>
<a class="sourceLine" id="cb1763-4" title="4">RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1763-5" title="5"><span class="st">  </span><span class="kw">group_by</span>(psblock) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1763-6" title="6"><span class="st">    </span><span class="kw">summarise</span>(<span class="kw">n</span>(), <span class="kw">min</span>(Score), <span class="kw">max</span>(Score))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 4
##   psblock `n()` `min(Score)` `max(Score)`
##     &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;        &lt;dbl&gt;
## 1       1   888       0.0167        0.280
## 2       2   888       0.281         0.508
## 3       3   888       0.508         0.695
## 4       4   887       0.696         0.951</code></pre>
<p>但是你看每層的傾向性評分其實範圍有點寬，提示使用分層的方法可能殘餘的混雜有點多。</p>
<p>看每層內數據的平衡:</p>
<div class="sourceCode" id="cb1765"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1765-1" title="1"><span class="co"># Cov &lt;- c(&quot;diacat&quot;, &quot;position&quot;)</span></a>
<a class="sourceLine" id="cb1765-2" title="2"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1765-3" title="3"><span class="co">#  in strata == 1                             #</span></a>
<a class="sourceLine" id="cb1765-4" title="4"><span class="co">#                                             #</span></a>
<a class="sourceLine" id="cb1765-5" title="5"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1765-6" title="6"><span class="co">## Construct a table</span></a>
<a class="sourceLine" id="cb1765-7" title="7">tabUnmatched &lt;-<span class="st"> </span><span class="kw">CreateTableOne</span>(<span class="dt">vars =</span> Cov, <span class="dt">strata =</span> <span class="st">&quot;rfa&quot;</span>, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,], <span class="dt">test =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1765-8" title="8"><span class="co">## Show table with SMD</span></a>
<a class="sourceLine" id="cb1765-9" title="9"><span class="kw">print</span>(tabUnmatched, <span class="dt">smd =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##                     Stratified by rfa
##                      0           1           SMD   
##   n                  777         111               
##   agecat (%)                                  0.321
##      &lt; 45             27 ( 3.5)    3 ( 2.7)        
##      45-49           211 (27.2)   25 (22.5)        
##      50-54           334 (43.0)   59 (53.2)        
##      55-59           162 (20.8)   23 (20.7)        
##      60-64            37 ( 4.8)    1 ( 0.9)        
##      65+               6 ( 0.8)    0 ( 0.0)        
##   gender = women (%) 304 (39.1)   45 (40.5)   0.029
##   smoke (%)                                   0.248
##      never           533 (68.6)   88 (79.3)        
##      ex               56 ( 7.2)    6 ( 5.4)        
##      current         188 (24.2)   17 (15.3)        
##   hospital (%)                                0.265
##      1               135 (17.4)   10 ( 9.0)        
##      2               152 (19.6)   27 (24.3)        
##      3               270 (34.7)   38 (34.2)        
##      4               220 (28.3)   36 (32.4)        
##   nodcat (%)                                  0.209
##      1               201 (25.9)   24 (21.6)        
##      2               293 (37.7)   47 (42.3)        
##      3               119 (15.3)   17 (15.3)        
##      4                41 ( 5.3)    7 ( 6.3)        
##      5-9             112 (14.4)   16 (14.4)        
##      10+              11 ( 1.4)    0 ( 0.0)        
##   mets (%)                                    0.141
##      0               463 (59.6)   70 (63.1)        
##      1               154 (19.8)   24 (21.6)        
##      2               138 (17.8)   15 (13.5)        
##      3                22 ( 2.8)    2 ( 1.8)        
##   durcat (%)                                  0.209
##      &lt; 10m            17 ( 2.2)    3 ( 2.7)        
##      10-19m          297 (38.2)   41 (36.9)        
##      20-29m          356 (45.8)   54 (48.6)        
##      30-39m           76 ( 9.8)   12 (10.8)        
##      40+m             31 ( 4.0)    1 ( 0.9)        
##   diacat (%)                                  0.515
##      &lt;1.5cm            0 ( 0.0)    0 ( 0.0)        
##      1.5-1.9cm         9 ( 1.2)    4 ( 3.6)        
##      2-2.4cm         310 (39.9)   68 (61.3)        
##      2.5-2.9cm       369 (47.5)   34 (30.6)        
##      3cm+             89 (11.5)    5 ( 4.5)        
##   primary (%)                                 0.279
##      bladder          23 ( 3.0)    1 ( 0.9)        
##      breast          180 (23.2)   25 (22.5)        
##      colorectal      273 (35.1)   43 (38.7)        
##      gullet           40 ( 5.1)    3 ( 2.7)        
##      kidney           34 ( 4.4)    7 ( 6.3)        
##      prostate        159 (20.5)   25 (22.5)        
##      skin              1 ( 0.1)    1 ( 0.9)        
##      stomach          32 ( 4.1)    3 ( 2.7)        
##      testicular       35 ( 4.5)    3 ( 2.7)        
##   position (%)                                0.181
##      easy            319 (41.1)   36 (32.4)        
##      moderate        342 (44.0)   55 (49.5)        
##      difficult       116 (14.9)   20 (18.0)</code></pre>
<div class="sourceCode" id="cb1767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1767-1" title="1"><span class="co">## Count covariates with important imbalance</span></a>
<a class="sourceLine" id="cb1767-2" title="2"><span class="kw">addmargins</span>(<span class="kw">table</span>(<span class="kw">ExtractSmd</span>(tabUnmatched) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.08</span>))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE   Sum 
##     1     9    10</code></pre>
<div class="sourceCode" id="cb1769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1769-1" title="1"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1769-2" title="2"><span class="co">#  in strata == 2                             #</span></a>
<a class="sourceLine" id="cb1769-3" title="3"><span class="co">#                                             #</span></a>
<a class="sourceLine" id="cb1769-4" title="4"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1769-5" title="5"><span class="co">## Construct a table</span></a>
<a class="sourceLine" id="cb1769-6" title="6">tabUnmatched &lt;-<span class="st"> </span><span class="kw">CreateTableOne</span>(<span class="dt">vars =</span> Cov, <span class="dt">strata =</span> <span class="st">&quot;rfa&quot;</span>, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">2</span>,], <span class="dt">test =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1769-7" title="7"><span class="co">## Show table with SMD</span></a>
<a class="sourceLine" id="cb1769-8" title="8"><span class="kw">print</span>(tabUnmatched, <span class="dt">smd =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##                     Stratified by rfa
##                      0           1           SMD   
##   n                  550         338               
##   agecat (%)                                  0.114
##      &lt; 45             12 ( 2.2)    5 ( 1.5)        
##      45-49           129 (23.5)   82 (24.3)        
##      50-54           294 (53.5)  173 (51.2)        
##      55-59            87 (15.8)   61 (18.0)        
##      60-64            21 ( 3.8)   10 ( 3.0)        
##      65+               7 ( 1.3)    7 ( 2.1)        
##   gender = women (%) 217 (39.5)  132 (39.1)   0.008
##   smoke (%)                                   0.091
##      never           384 (69.8)  222 (65.7)        
##      ex               39 ( 7.1)   29 ( 8.6)        
##      current         127 (23.1)   87 (25.7)        
##   hospital (%)                                0.101
##      1                91 (16.5)   48 (14.2)        
##      2                89 (16.2)   49 (14.5)        
##      3               226 (41.1)  154 (45.6)        
##      4               144 (26.2)   87 (25.7)        
##   nodcat (%)                                  0.139
##      1               150 (27.3)  102 (30.2)        
##      2               205 (37.3)  124 (36.7)        
##      3               117 (21.3)   61 (18.0)        
##      4                37 ( 6.7)   18 ( 5.3)        
##      5-9              30 ( 5.5)   26 ( 7.7)        
##      10+              11 ( 2.0)    7 ( 2.1)        
##   mets (%)                                    0.145
##      0               322 (58.5)  191 (56.5)        
##      1               127 (23.1)   72 (21.3)        
##      2                93 (16.9)   73 (21.6)        
##      3                 8 ( 1.5)    2 ( 0.6)        
##   durcat (%)                                  0.162
##      &lt; 10m             8 ( 1.5)    4 ( 1.2)        
##      10-19m          210 (38.2)  138 (40.8)        
##      20-29m          251 (45.6)  133 (39.3)        
##      30-39m           63 (11.5)   44 (13.0)        
##      40+m             18 ( 3.3)   19 ( 5.6)        
##   diacat (%)                                  0.057
##      &lt;1.5cm            4 ( 0.7)    4 ( 1.2)        
##      1.5-1.9cm       199 (36.2)  127 (37.6)        
##      2-2.4cm         347 (63.1)  207 (61.2)        
##      2.5-2.9cm         0 ( 0.0)    0 ( 0.0)        
##      3cm+              0 ( 0.0)    0 ( 0.0)        
##   primary (%)                                 0.099
##      bladder           9 ( 1.6)    8 ( 2.4)        
##      breast          124 (22.5)   79 (23.4)        
##      colorectal      221 (40.2)  126 (37.3)        
##      gullet           19 ( 3.5)   13 ( 3.8)        
##      kidney           14 ( 2.5)   12 ( 3.6)        
##      prostate        104 (18.9)   63 (18.6)        
##      skin              0 ( 0.0)    0 ( 0.0)        
##      stomach          33 ( 6.0)   19 ( 5.6)        
##      testicular       26 ( 4.7)   18 ( 5.3)        
##   position (%)                                0.041
##      easy            172 (31.3)  100 (29.6)        
##      moderate        242 (44.0)  155 (45.9)        
##      difficult       136 (24.7)   83 (24.6)</code></pre>
<div class="sourceCode" id="cb1771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1771-1" title="1"><span class="co">## Count covariates with important imbalance</span></a>
<a class="sourceLine" id="cb1771-2" title="2"><span class="kw">addmargins</span>(<span class="kw">table</span>(<span class="kw">ExtractSmd</span>(tabUnmatched) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.08</span>))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE   Sum 
##     3     7    10</code></pre>
<div class="sourceCode" id="cb1773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1773-1" title="1"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1773-2" title="2"><span class="co">#  in strata == 3                             #</span></a>
<a class="sourceLine" id="cb1773-3" title="3"><span class="co">#                                             #</span></a>
<a class="sourceLine" id="cb1773-4" title="4"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1773-5" title="5"><span class="co">## Construct a table</span></a>
<a class="sourceLine" id="cb1773-6" title="6">tabUnmatched &lt;-<span class="st"> </span><span class="kw">CreateTableOne</span>(<span class="dt">vars =</span> Cov, <span class="dt">strata =</span> <span class="st">&quot;rfa&quot;</span>, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">3</span>,], <span class="dt">test =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1773-7" title="7"><span class="co">## Show table with SMD</span></a>
<a class="sourceLine" id="cb1773-8" title="8"><span class="kw">print</span>(tabUnmatched, <span class="dt">smd =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##                     Stratified by rfa
##                      0           1           SMD   
##   n                  347         541               
##   agecat (%)                                  0.163
##      &lt; 45              6 ( 1.7)   13 ( 2.4)        
##      45-49            90 (25.9)  135 (25.0)        
##      50-54           171 (49.3)  261 (48.2)        
##      55-59            71 (20.5)  102 (18.9)        
##      60-64             8 ( 2.3)   25 ( 4.6)        
##      65+               1 ( 0.3)    5 ( 0.9)        
##   gender = women (%) 132 (38.0)  205 (37.9)   0.003
##   smoke (%)                                   0.049
##      never           245 (70.6)  372 (68.8)        
##      ex               22 ( 6.3)   40 ( 7.4)        
##      current          80 (23.1)  129 (23.8)        
##   hospital (%)                                0.125
##      1                59 (17.0)  107 (19.8)        
##      2                78 (22.5)  109 (20.1)        
##      3               101 (29.1)  176 (32.5)        
##      4               109 (31.4)  149 (27.5)        
##   nodcat (%)                                  0.087
##      1               101 (29.1)  161 (29.8)        
##      2               143 (41.2)  205 (37.9)        
##      3                59 (17.0)  101 (18.7)        
##      4                14 ( 4.0)   24 ( 4.4)        
##      5-9              22 ( 6.3)   40 ( 7.4)        
##      10+               8 ( 2.3)   10 ( 1.8)        
##   mets (%)                                    0.061
##      0               205 (59.1)  314 (58.0)        
##      1                78 (22.5)  122 (22.6)        
##      2                57 (16.4)   89 (16.5)        
##      3                 7 ( 2.0)   16 ( 3.0)        
##   durcat (%)                                  0.088
##      &lt; 10m             3 ( 0.9)    6 ( 1.1)        
##      10-19m          150 (43.2)  227 (42.0)        
##      20-29m          142 (40.9)  239 (44.2)        
##      30-39m           40 (11.5)   51 ( 9.4)        
##      40+m             12 ( 3.5)   18 ( 3.3)        
##   diacat (%)                                  0.142
##      &lt;1.5cm           68 (19.6)  135 (25.0)        
##      1.5-1.9cm       275 (79.3)  403 (74.5)        
##      2-2.4cm           4 ( 1.2)    3 ( 0.6)        
##      2.5-2.9cm         0 ( 0.0)    0 ( 0.0)        
##      3cm+              0 ( 0.0)    0 ( 0.0)        
##   primary (%)                                 0.121
##      bladder          12 ( 3.5)   18 ( 3.3)        
##      breast           73 (21.0)  124 (22.9)        
##      colorectal      131 (37.8)  198 (36.6)        
##      gullet           10 ( 2.9)   19 ( 3.5)        
##      kidney           13 ( 3.7)   16 ( 3.0)        
##      prostate         68 (19.6)  106 (19.6)        
##      skin              3 ( 0.9)    1 ( 0.2)        
##      stomach          17 ( 4.9)   25 ( 4.6)        
##      testicular       20 ( 5.8)   34 ( 6.3)        
##   position (%)                                0.162
##      easy             65 (18.7)  127 (23.5)        
##      moderate        216 (62.2)  294 (54.3)        
##      difficult        66 (19.0)  120 (22.2)</code></pre>
<div class="sourceCode" id="cb1775"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1775-1" title="1"><span class="co">## Count covariates with important imbalance</span></a>
<a class="sourceLine" id="cb1775-2" title="2"><span class="kw">addmargins</span>(<span class="kw">table</span>(<span class="kw">ExtractSmd</span>(tabUnmatched) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.08</span>))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE   Sum 
##     3     7    10</code></pre>
<div class="sourceCode" id="cb1777"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1777-1" title="1"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1777-2" title="2"><span class="co">#  in strata == 4                             #</span></a>
<a class="sourceLine" id="cb1777-3" title="3"><span class="co">#                                             #</span></a>
<a class="sourceLine" id="cb1777-4" title="4"><span class="co">#---------------------------------------------#</span></a>
<a class="sourceLine" id="cb1777-5" title="5"><span class="co">## Construct a table</span></a>
<a class="sourceLine" id="cb1777-6" title="6">tabUnmatched &lt;-<span class="st"> </span><span class="kw">CreateTableOne</span>(<span class="dt">vars =</span> Cov, <span class="dt">strata =</span> <span class="st">&quot;rfa&quot;</span>, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">4</span>,], <span class="dt">test =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1777-7" title="7"><span class="co">## Show table with SMD</span></a>
<a class="sourceLine" id="cb1777-8" title="8"><span class="kw">print</span>(tabUnmatched, <span class="dt">smd =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##                     Stratified by rfa
##                      0           1           SMD   
##   n                  174         713               
##   agecat (%)                                  0.105
##      &lt; 45              6 ( 3.4)   24 ( 3.4)        
##      45-49            33 (19.0)  155 (21.7)        
##      50-54            92 (52.9)  371 (52.0)        
##      55-59            32 (18.4)  124 (17.4)        
##      60-64             6 ( 3.4)   27 ( 3.8)        
##      65+               5 ( 2.9)   12 ( 1.7)        
##   gender = women (%)  73 (42.0)  319 (44.7)   0.056
##   smoke (%)                                   0.077
##      never           117 (67.2)  475 (66.6)        
##      ex               18 (10.3)   61 ( 8.6)        
##      current          39 (22.4)  177 (24.8)        
##   hospital (%)                                0.104
##      1                23 (13.2)   97 (13.6)        
##      2                30 (17.2)   97 (13.6)        
##      3                80 (46.0)  350 (49.1)        
##      4                41 (23.6)  169 (23.7)        
##   nodcat (%)                                  0.254
##      1                53 (30.5)  205 (28.8)        
##      2                62 (35.6)  271 (38.0)        
##      3                30 (17.2)  131 (18.4)        
##      4                12 ( 6.9)   51 ( 7.2)        
##      5-9              17 ( 9.8)   41 ( 5.8)        
##      10+               0 ( 0.0)   14 ( 2.0)        
##   mets (%)                                    0.061
##      0                99 (56.9)  394 (55.3)        
##      1                34 (19.5)  157 (22.0)        
##      2                39 (22.4)  154 (21.6)        
##      3                 2 ( 1.1)    8 ( 1.1)        
##   durcat (%)                                  0.094
##      &lt; 10m             3 ( 1.7)    9 ( 1.3)        
##      10-19m           74 (42.5)  300 (42.1)        
##      20-29m           71 (40.8)  282 (39.6)        
##      30-39m           18 (10.3)   93 (13.0)        
##      40+m              8 ( 4.6)   29 ( 4.1)        
##   diacat (%)                                  0.062
##      &lt;1.5cm          150 (86.2)  606 (85.0)        
##      1.5-1.9cm        24 (13.8)  106 (14.9)        
##      2-2.4cm           0 ( 0.0)    1 ( 0.1)        
##      2.5-2.9cm         0 ( 0.0)    0 ( 0.0)        
##      3cm+              0 ( 0.0)    0 ( 0.0)        
##   primary (%)                                 0.177
##      bladder           2 ( 1.1)    8 ( 1.1)        
##      breast           46 (26.4)  173 (24.3)        
##      colorectal       69 (39.7)  304 (42.6)        
##      gullet            6 ( 3.4)   20 ( 2.8)        
##      kidney            5 ( 2.9)   12 ( 1.7)        
##      prostate         34 (19.5)  130 (18.2)        
##      skin              1 ( 0.6)   15 ( 2.1)        
##      stomach           4 ( 2.3)   20 ( 2.8)        
##      testicular        7 ( 4.0)   31 ( 4.3)        
##   position (%)                                0.056
##      easy              9 ( 5.2)   29 ( 4.1)        
##      moderate         99 (56.9)  417 (58.5)        
##      difficult        66 (37.9)  267 (37.4)</code></pre>
<div class="sourceCode" id="cb1779"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1779-1" title="1"><span class="co">## Count covariates with important imbalance</span></a>
<a class="sourceLine" id="cb1779-2" title="2"><span class="kw">addmargins</span>(<span class="kw">table</span>(<span class="kw">ExtractSmd</span>(tabUnmatched) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.08</span>))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE   Sum 
##     5     5    10</code></pre>
<p>可以看出其實分層法中每層的數據依然還有很多的不平衡。分層法不是合理的利用傾向性評分的理想辦法。</p>
<div id="計算每層評分組內暴露和結果之間的關系" class="section level4">
<h4><span class="header-section-number">115.2.4.1</span> 計算每層評分組內，暴露和結果之間的關系</h4>
<div class="sourceCode" id="cb1781"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1781-1" title="1">(<span class="kw">lm</span>(dodp <span class="op">~</span><span class="st"> </span>rfa, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ]))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dodp ~ rfa, data = RFAcat[RFAcat$psblock == 1, ])
## 
## Coefficients:
## (Intercept)          rfa  
##     0.40927      0.11326</code></pre>
<div class="sourceCode" id="cb1783"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1783-1" title="1">(<span class="kw">lm</span>(dodp <span class="op">~</span><span class="st"> </span>rfa, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, ]))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dodp ~ rfa, data = RFAcat[RFAcat$psblock == 2, ])
## 
## Coefficients:
## (Intercept)          rfa  
##    0.285455     0.099161</code></pre>
<div class="sourceCode" id="cb1785"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1785-1" title="1">(<span class="kw">lm</span>(dodp <span class="op">~</span><span class="st"> </span>rfa, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">3</span>, ]))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dodp ~ rfa, data = RFAcat[RFAcat$psblock == 3, ])
## 
## Coefficients:
## (Intercept)          rfa  
##    0.198847    -0.041731</code></pre>
<div class="sourceCode" id="cb1787"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1787-1" title="1">(<span class="kw">lm</span>(dodp <span class="op">~</span><span class="st"> </span>rfa, <span class="dt">data =</span> RFAcat[RFAcat<span class="op">$</span>psblock <span class="op">==</span><span class="st"> </span><span class="dv">4</span>, ]))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dodp ~ rfa, data = RFAcat[RFAcat$psblock == 4, ])
## 
## Coefficients:
## (Intercept)          rfa  
##     0.28161     -0.16800</code></pre>
</div>
<div id="計算-ace" class="section level4">
<h4><span class="header-section-number">115.2.4.2</span> 計算 ACE</h4>
<div class="sourceCode" id="cb1789"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1789-1" title="1">(<span class="dv">888</span><span class="op">*</span><span class="fl">0.1132561</span> <span class="op">+</span><span class="st"> </span><span class="dv">888</span><span class="op">*</span><span class="fl">0.0991608</span> <span class="op">+</span><span class="st"> </span><span class="dv">888</span><span class="op">*</span>(<span class="op">-</span><span class="fl">0.0417308</span>) <span class="op">+</span><span class="st"> </span><span class="dv">887</span><span class="op">*</span>(<span class="op">-</span><span class="fl">0.1680047</span>))<span class="op">/</span><span class="dv">3551</span></a></code></pre></div>
<pre><code>## [1] 0.00071785072</code></pre>
</div>
</div>
<div id="用配對法計算-ace" class="section level3">
<h3><span class="header-section-number">115.2.5</span> 用配對法計算 ACE</h3>
<pre><code>## 
## 
## . use &quot;backupfiles/RFAcat.dt. /*  Question 10  */
## . teffects psmatch (dodp) (rfa i.agecat gender i.smoke i.hospital ///
## &gt;                         i.nodcat i.mets i.durcat i.diacat i.primary i.positio
## &gt; n, logit)
## 
## Treatment-effects estimation                   Number of obs      =      3,551
## Estimator      : propensity-score matching     Matches: requested =          1
## Outcome model  : matching                                     min =          1
## Treatment model: logit                                        max =          3
## ------------------------------------------------------------------------------
##              |              AI Robust
##         dodp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
## ATE          |
##          rfa |
## (radiofre..  |
##          vs  |
## standard..)  |   .0263775   .0187999     1.40   0.161    -.0104697    .0632248
## ------------------------------------------------------------------------------</code></pre>
</div>
<div id="模型校正-ps" class="section level3">
<h3><span class="header-section-number">115.2.6</span> 模型校正 PS</h3>
<div class="sourceCode" id="cb1792"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1792-1" title="1">RFAcat<span class="op">$</span>rfanew &lt;-<span class="st"> </span>RFAcat<span class="op">$</span>rfa</a>
<a class="sourceLine" id="cb1792-2" title="2">Log_ps &lt;-<span class="st"> </span><span class="kw">glm</span>(dodp <span class="op">~</span><span class="st"> </span><span class="kw">as.factor</span>(rfanew)<span class="op">*</span>Score, <span class="dt">data =</span> RFAcat, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb1792-3" title="3"><span class="kw">summary</span>(Log_ps)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = dodp ~ as.factor(rfanew) * Score, family = binomial(link = &quot;logit&quot;), 
##     data = RFAcat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.45859  -0.86831  -0.63218   1.29348   2.29729  
## 
## Coefficients:
##                          Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)              -0.28539    0.08742 -3.2646  0.001096 ** 
## as.factor(rfanew)1        1.04607    0.19586  5.3409 9.247e-08 ***
## Score                    -1.37952    0.22182 -6.2190 5.003e-10 ***
## as.factor(rfanew)1:Score -2.24706    0.37406 -6.0073 1.886e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 4118.69  on 3550  degrees of freedom
## Residual deviance: 3863.82  on 3547  degrees of freedom
## AIC: 3871.82
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb1794"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1794-1" title="1">RFAcat &lt;-<span class="st"> </span>RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1794-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rfanew =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1794-3" title="3">newdata &lt;-<span class="st"> </span><span class="kw">subset</span>(RFAcat, <span class="dt">select =</span> <span class="kw">c</span>(rfanew, Score))</a>
<a class="sourceLine" id="cb1794-4" title="4"></a>
<a class="sourceLine" id="cb1794-5" title="5">RFAcat<span class="op">$</span>Po1&lt;-<span class="st"> </span><span class="kw">predict</span>(Log_ps, newdata, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb1794-6" title="6"></a>
<a class="sourceLine" id="cb1794-7" title="7"></a>
<a class="sourceLine" id="cb1794-8" title="8">RFAcat &lt;-<span class="st"> </span>RFAcat <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1794-9" title="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rfanew =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1794-10" title="10">newdata1 &lt;-<span class="st"> </span><span class="kw">subset</span>(RFAcat, <span class="dt">select =</span> <span class="kw">c</span>(rfanew, Score))</a>
<a class="sourceLine" id="cb1794-11" title="11"></a>
<a class="sourceLine" id="cb1794-12" title="12">RFAcat<span class="op">$</span>Po0 &lt;-<span class="st"> </span><span class="kw">predict</span>(Log_ps, newdata1, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb1794-13" title="13"></a>
<a class="sourceLine" id="cb1794-14" title="14"></a>
<a class="sourceLine" id="cb1794-15" title="15"><span class="kw">with</span>(RFAcat, <span class="kw">summ</span>(Po1, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  3551 0.306  0.253   0.182  0.064  0.668</code></pre>
<div class="sourceCode" id="cb1796"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1796-1" title="1"><span class="kw">with</span>(RFAcat, <span class="kw">summ</span>(Po0, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  3551 0.285  0.272   0.072  0.168  0.423</code></pre>
<div class="sourceCode" id="cb1798"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1798-1" title="1"><span class="kw">with</span>(RFAcat, <span class="kw">summ</span>(Po1 <span class="op">-</span><span class="st"> </span>Po0, <span class="dt">graph =</span> F))</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  3551 0.021  -0.018  0.11   -0.105 0.245</code></pre>
</div>
</div>
</div>
<div id="inverse-probability-weighted-estimation-and-doubly-robust-methods" class="section level1">
<h1><span class="header-section-number">第 116 章</span> Inverse probability weighted estimation and doubly robust methods</h1>
</div>
<div id="causal-mediation-analysis" class="section level1">
<h1><span class="header-section-number">第 117 章</span> Causal mediation analysis</h1>

</div>



<div id="crude-and-stratified-rate-ratios" class="section level1">
<h1><span class="header-section-number">第 118 章</span> Crude and stratified rate ratios</h1>
<p>本章內容不討論任何理論的東西，着重強調用 R 進行實際數據的分析，並加強對輸出結果的理解。</p>
<p>此次實戰演練的目的是學會怎樣計算死亡率比 (Rate Ratios, RR)。學會用 Mantel-Haenszel 法總結 RR，並討論其意義。</p>
<div class="sourceCode" id="cb1800"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1800-1" title="1">whitehal &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/whitehal.dta&quot;</span>)</a>
<a class="sourceLine" id="cb1800-2" title="2">whitehal<span class="op">$</span>followupyrs &lt;-<span class="st"> </span>(whitehal<span class="op">$</span>timeout <span class="op">-</span><span class="st"> </span>whitehal<span class="op">$</span>timein)<span class="op">/</span><span class="fl">365.25</span></a>
<a class="sourceLine" id="cb1800-3" title="3"><span class="kw">max</span>(whitehal<span class="op">$</span>followupyrs<span class="op">*</span><span class="fl">365.25</span>) <span class="co"># time difference in days</span></a></code></pre></div>
<pre><code>## Time difference of 7078.9927 days</code></pre>
<div class="sourceCode" id="cb1802"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1802-1" title="1"><span class="kw">summary</span>(whitehal<span class="op">$</span>followupyrs &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(whitehal<span class="op">$</span>followupyrs)) <span class="co"># time difference in years</span></a></code></pre></div>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##  0.15063 17.16357 17.96020 16.46116 18.56262 19.38123</code></pre>
<div class="sourceCode" id="cb1804"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1804-1" title="1"><span class="co"># categorize agein into groups (40-44, 45-49, 50-54, ... , 65-69)</span></a>
<a class="sourceLine" id="cb1804-2" title="2">whitehal<span class="op">$</span>agecat &lt;-<span class="st"> </span><span class="kw">cut</span>(whitehal<span class="op">$</span>agein, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">40</span>, <span class="dv">70</span>, <span class="dv">5</span>), <span class="dt">right =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1804-3" title="3"><span class="kw">with</span>(whitehal, <span class="kw">table</span>(agecat))</a></code></pre></div>
<pre><code>## agecat
## [40,45) [45,50) [50,55) [55,60) [60,65) [65,70) 
##     277     445     362     340     215      38</code></pre>
<div class="sourceCode" id="cb1806"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1806-1" title="1"><span class="co"># examine how mortality rates change with age at entry</span></a>
<a class="sourceLine" id="cb1806-2" title="2"><span class="co"># </span></a>
<a class="sourceLine" id="cb1806-3" title="3"><span class="co"># with(whitehal %&gt;% group_by(agecat) %&gt;%</span></a>
<a class="sourceLine" id="cb1806-4" title="4"><span class="co">#   summarise(D = sum(all),</span></a>
<a class="sourceLine" id="cb1806-5" title="5"><span class="co">#             Y = sum(followupyrs)),</span></a>
<a class="sourceLine" id="cb1806-6" title="6"><span class="co">#   cbind(whitehal$agecat, pois.exact(x = D, pt = Y/1000)))</span></a>
<a class="sourceLine" id="cb1806-7" title="7"></a>
<a class="sourceLine" id="cb1806-8" title="8"></a>
<a class="sourceLine" id="cb1806-9" title="9"><span class="co">## rate ratios and 95% CIs for each age category compare with [40,44) age group</span></a>
<a class="sourceLine" id="cb1806-10" title="10">Model0 &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span>agecat <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(followupyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> whitehal); <span class="kw">ci.exp</span>(Model0)</a></code></pre></div>
<pre><code>##                   exp(Est.)          2.5%         97.5%
## (Intercept)    0.0048794197  0.0032705278  0.0072797841
## agecat[45,50)  1.1740971320  0.7154062934  1.9268827913
## agecat[50,55)  2.7732622719  1.7597191900  4.3705743919
## agecat[55,60)  4.5784055712  2.9519678778  7.1009572062
## agecat[60,65)  6.6882727538  4.2856745766 10.4377949444
## agecat[65,70) 17.1110624279 10.1140257533 28.9487553770</code></pre>
<div class="sourceCode" id="cb1808"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1808-1" title="1"><span class="co">## The rate ratios are increasing with age although there is no statistical evidence</span></a>
<a class="sourceLine" id="cb1808-2" title="2"><span class="co">## at 5% level that the rate among 45-49 year olds is different to the rate among men</span></a>
<a class="sourceLine" id="cb1808-3" title="3"><span class="co">## who are &lt;40 years</span></a>
<a class="sourceLine" id="cb1808-4" title="4"></a>
<a class="sourceLine" id="cb1808-5" title="5"></a>
<a class="sourceLine" id="cb1808-6" title="6"><span class="co"># with(whitehal %&gt;% group_by(grade) %&gt;%</span></a>
<a class="sourceLine" id="cb1808-7" title="7"><span class="co">#   summarise(D = sum(all),</span></a>
<a class="sourceLine" id="cb1808-8" title="8"><span class="co">#             Y = sum(followupyrs)),</span></a>
<a class="sourceLine" id="cb1808-9" title="9"><span class="co">#   cbind(whitehal$grade, pois.exact(x = D, pt = Y/1000)))</span></a>
<a class="sourceLine" id="cb1808-10" title="10"></a>
<a class="sourceLine" id="cb1808-11" title="11">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(grade) <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(followupyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> whitehal); <span class="kw">ci.exp</span>(Model1)</a></code></pre></div>
<pre><code>##                  exp(Est.)         2.5%       97.5%
## (Intercept)    0.010865404 0.0095233128 0.012396632
## factor(grade)2 2.305446287 1.8947528380 2.805158793</code></pre>
<div class="sourceCode" id="cb1810"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1810-1" title="1"><span class="co">## There is strong evidence that the all cause mortality rate differs between high</span></a>
<a class="sourceLine" id="cb1810-2" title="2"><span class="co">## and low grade workers.</span></a>
<a class="sourceLine" id="cb1810-3" title="3"></a>
<a class="sourceLine" id="cb1810-4" title="4"><span class="co">## To examine whether the estimated RR for grade is confounded by age at entry</span></a>
<a class="sourceLine" id="cb1810-5" title="5"><span class="co">## we compare the crude RR =2.31 (1.90, 2.81) with the Mantel-Haenszel summary</span></a>
<a class="sourceLine" id="cb1810-6" title="6"><span class="co">## estimate.</span></a>
<a class="sourceLine" id="cb1810-7" title="7"></a>
<a class="sourceLine" id="cb1810-8" title="8">whitehal_table &lt;-<span class="st"> </span><span class="kw">aggregate</span>(<span class="kw">cbind</span>(all, followupyrs) <span class="op">~</span><span class="st"> </span>grade <span class="op">+</span><span class="st"> </span>agecat, <span class="dt">data=</span>whitehal, sum)</a>
<a class="sourceLine" id="cb1810-9" title="9">stmh_array &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">20</span>,   <span class="fl">693.1284</span>,<span class="fl">4225.4893</span>,</a>
<a class="sourceLine" id="cb1810-10" title="10">                      <span class="dv">10</span>,<span class="dv">35</span>,   <span class="fl">1363.821</span>,<span class="fl">6491.072</span>,</a>
<a class="sourceLine" id="cb1810-11" title="11">                      <span class="dv">30</span>,<span class="dv">52</span>,  <span class="fl">1399.63</span>, <span class="fl">4660.12</span>,                                                        <span class="dv">51</span>,<span class="dv">67</span>,   <span class="fl">1832.169</span>,<span class="fl">3449.846</span>,</a>
<a class="sourceLine" id="cb1810-12" title="12">                      <span class="dv">59</span>,<span class="dv">42</span>,   <span class="fl">1660.597</span>,<span class="fl">1434.251</span>,</a>
<a class="sourceLine" id="cb1810-13" title="13">                      <span class="dv">28</span>,<span class="dv">5</span>,  <span class="fl">316.23840</span>, <span class="fl">79.00879</span>),</a>
<a class="sourceLine" id="cb1810-14" title="14">                      <span class="dt">dim=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">6</span>),</a>
<a class="sourceLine" id="cb1810-15" title="15">                      <span class="dt">dimnames =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb1810-16" title="16">                      <span class="dt">Grade=</span><span class="kw">c</span>(<span class="st">&quot;2&quot;</span>,<span class="st">&quot;1&quot;</span>),</a>
<a class="sourceLine" id="cb1810-17" title="17">                      <span class="kw">c</span>(<span class="st">&quot;death&quot;</span>, <span class="st">&quot;Person_years&quot;</span>),</a>
<a class="sourceLine" id="cb1810-18" title="18">                      <span class="dt">Agecat=</span><span class="kw">names</span>(<span class="kw">table</span>(whitehal<span class="op">$</span>agecat))</a>
<a class="sourceLine" id="cb1810-19" title="19">                    ))</a>
<a class="sourceLine" id="cb1810-20" title="20">stmh_array</a></code></pre></div>
<pre><code>## , , Agecat = [40,45)
## 
##      
## Grade death Person_years
##     2     4     693.1284
##     1    20    4225.4893
## 
## , , Agecat = [45,50)
## 
##      
## Grade death Person_years
##     2    10     1363.821
##     1    35     6491.072
## 
## , , Agecat = [50,55)
## 
##      
## Grade death Person_years
##     2    30      1399.63
##     1    52      4660.12
## 
## , , Agecat = [55,60)
## 
##      
## Grade death Person_years
##     2    51     1832.169
##     1    67     3449.846
## 
## , , Agecat = [60,65)
## 
##      
## Grade death Person_years
##     2    59     1660.597
##     1    42     1434.251
## 
## , , Agecat = [65,70)
## 
##      
## Grade death Person_years
##     2    28    316.23840
##     1     5     79.00879</code></pre>
<div class="sourceCode" id="cb1812"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1812-1" title="1">mhgrade_age &lt;-<span class="st"> </span><span class="kw">epi.2by2</span>(stmh_array, <span class="dt">method =</span> <span class="st">&quot;cohort.time&quot;</span>, <span class="dt">units =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb1812-2" title="2">mhgrade_age</a></code></pre></div>
<pre><code>##              Outcome +    Time at risk        Inc rate *
## Exposed +          182            7266              25.0
## Exposed -          221           20340              10.9
## Total              403           27605              14.6
## 
## Point estimates and 95% CIs:
## -------------------------------------------------------------------
## Inc rate ratio (crude)                       2.31 (1.88, 2.82)
## Inc rate ratio (M-H)                         1.43 (1.16, 1.76)
## Inc rate ratio (crude:M-H)                   1.61
## Attrib rate (crude) *                        14.18 (10.27, 18.10)
## Attrib rate (M-H) *                          6.28 (2.42, 10.15)
## Attrib rate (crude:M-H)                      2.26
## -------------------------------------------------------------------
##  Wald confidence limits
##  M-H: Mantel-Haenszel; CI: confidence interval
##  * Outcomes per 1000 units of population time at risk</code></pre>
<div class="sourceCode" id="cb1814"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1814-1" title="1"><span class="co">## Overall estimate and Wald 95% confidence intervals,</span></a>
<a class="sourceLine" id="cb1814-2" title="2"><span class="co">## controlling for agecate</span></a>
<a class="sourceLine" id="cb1814-3" title="3">mhgrade_age<span class="op">$</span>massoc<span class="op">$</span>IRR.mh.wald</a></code></pre></div>
<pre><code>##        est     lower     upper
## 1 1.429211 1.1598631 1.7611078</code></pre>
<div class="sourceCode" id="cb1816"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1816-1" title="1">mhgrade_age<span class="op">$</span>massoc<span class="op">$</span>chisq.mh <span class="co">## p-value for age-adjusted MH rate ratio</span></a></code></pre></div>
<pre><code>##   test.statistic df       p.value
## 1      11.132745  5 0.00084816981</code></pre>
<div class="sourceCode" id="cb1818"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1818-1" title="1"><span class="co">## The Mantel-Haenszel summary estimate RR = 1.43 (1.16, 1.76).</span></a>
<a class="sourceLine" id="cb1818-2" title="2"><span class="co">## The result shows that the crude estimate of the effect of grade was</span></a>
<a class="sourceLine" id="cb1818-3" title="3"><span class="co">## partly confounded by age at entry.</span></a>
<a class="sourceLine" id="cb1818-4" title="4"></a>
<a class="sourceLine" id="cb1818-5" title="5"><span class="co">## To assess whether there is effect modification betwee grade and</span></a>
<a class="sourceLine" id="cb1818-6" title="6"><span class="co">## agecat we examine the stratum specific estimates and assess</span></a>
<a class="sourceLine" id="cb1818-7" title="7"><span class="co">## whether there is evidence of important variation between them.</span></a>
<a class="sourceLine" id="cb1818-8" title="8">mhgrade_age<span class="op">$</span>massoc<span class="op">$</span>IRR.strata.wald</a></code></pre></div>
<pre><code>##         est      lower     upper
## 1 1.2192515 0.30302945 3.6397113
## 2 1.3598500 0.60057144 2.8059055
## 3 1.9208868 1.18309546 3.0676307
## 4 1.4332751 0.97576189 2.0941999
## 5 1.2132872 0.80308583 1.8474726
## 6 1.3991002 0.53338106 4.6404658</code></pre>
<div class="sourceCode" id="cb1820"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1820-1" title="1"><span class="co">## The result indicates that the data are compatible with the assumption</span></a>
<a class="sourceLine" id="cb1820-2" title="2"><span class="co">## of no interaction/effect modification (p=0.79)</span></a>
<a class="sourceLine" id="cb1820-3" title="3"></a>
<a class="sourceLine" id="cb1820-4" title="4"><span class="co">## test for unequal RRs (effect modification):</span></a>
<a class="sourceLine" id="cb1820-5" title="5">mhgrade_age<span class="op">$</span>res<span class="op">$</span>RR.homog</a></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb1822"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1822-1" title="1"><span class="co">## Hence, we do not need to present the stratum-specific estimates.</span></a></code></pre></div>

</div>
<div id="references" class="section level1 unnumbered">
<h1>&lt;U+53C2&gt;&lt;U+8003&gt;&lt;U+6587&gt;&lt;U+732E&gt;</h1>
<p>以下是我的 R 進程信息：</p>
<div class="sourceCode" id="cb1823"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1823-1" title="1"><span class="kw">sessionInfo</span>()</a></code></pre></div>
<pre><code>## R version 3.6.1 (2019-07-05)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] grid      splines   stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] factoextra_1.0.5     FactoMineR_1.42      R2OpenBUGS_3.2-3.2   coda_0.19-3         
##  [5] BRugs_0.9-0          TailRank_3.2.1       oompaBase_3.2.9      codetools_0.2-16    
##  [9] clubSandwich_0.3.5   HLMdiag_0.3.1        LogisticDx_0.2       PBSmodelling_2.68.8 
## [13] ROCR_1.0-7           gplots_3.0.1.1       Hmisc_4.2-0          Formula_1.2-3       
## [17] eha_2.7.6            stargazer_5.2.2      tableone_0.10.0      lmerTest_3.1-0      
## [21] ATE_0.2.0            dagitty_0.2-2        exact2x2_1.6.3.1     exactci_1.3-3       
## [25] ssanv_1.1            FSA_0.8.25           lmtest_0.9-37        zoo_1.8-6           
## [29] BSDA_1.2.0           lattice_0.20-38      ggthemr_1.1.0        binomTools_1.0-1    
## [33] limma_3.40.6         DescTools_0.99.30    ggsci_2.9            ggthemes_4.2.0      
## [37] car_3.0-3            carData_3.0-2        scatterplot3d_0.3-41 mvtnorm_1.0-11      
## [41] kableExtra_1.1.0     sandwich_2.5-1       nlme_3.1-140         lme4_1.1-21         
## [45] Matrix_1.2-17        psych_1.8.12         margins_0.3.23       epiDisplay_3.5.0.1  
## [49] nnet_7.3-12          MASS_7.3-51.4        foreign_0.8-71       rgl_0.100.30        
## [53] epiR_1.0-4           shiny_1.4.0          epitools_0.5-10      flexsurv_1.1.1      
## [57] mstate_0.2.11        cmprsk_2.2-9         gnm_1.1-0            KMsurv_0.1-5        
## [61] Epi_2.38             gridExtra_2.3        plotly_4.9.0         haven_2.1.1         
## [65] survminer_0.4.6      ggpubr_0.2.3         magrittr_1.5         ggfortify_0.4.7     
## [69] survival_2.44-1.1    forcats_0.4.0        stringr_1.4.0        dplyr_0.8.3         
## [73] purrr_0.3.3          readr_1.3.1          tidyr_1.0.0          tibble_2.1.3        
## [77] ggplot2_3.2.1        tidyverse_1.2.1      plyr_1.8.4           kfigr_1.2           
## [81] knitr_1.25          
## 
## loaded via a namespace (and not attached):
##   [1] SparseM_1.77            muhaz_1.2.6.1           oompaData_3.1.1        
##   [4] acepack_1.4.1           multcomp_1.4-10         data.table_1.12.6      
##   [7] rpart_4.1-15            generics_0.0.2          BiocGenerics_0.30.0    
##  [10] TH.data_1.0-10          polspline_1.1.16        RLRsim_3.1-3           
##  [13] webshot_0.5.1           xml2_1.2.2              lubridate_1.7.4        
##  [16] httpuv_1.5.2            assertthat_0.2.1        relimp_1.0-5           
##  [19] xfun_0.10               hms_0.5.1               evaluate_0.14          
##  [22] promises_1.1.0          fansi_0.4.0             caTools_1.17.1.2       
##  [25] readxl_1.3.1            km.ci_0.5-2             DBI_1.0.0              
##  [28] htmlwidgets_1.5.1       ellipsis_0.3.0          selectr_0.4-1          
##  [31] crosstalk_1.0.0         backports_1.1.5         V8_2.3                 
##  [34] bookdown_0.14           survey_3.36             aod_1.3.1              
##  [37] vctrs_0.2.0             Biobase_2.44.0          quantreg_5.51          
##  [40] abind_1.4-5             withr_2.1.2             packrat_0.5.0          
##  [43] checkmate_1.9.4         mnormt_1.5-5            cluster_2.1.0          
##  [46] lazyeval_0.2.2          crayon_1.3.4            labeling_0.3           
##  [49] pkgconfig_2.0.3         rlang_0.4.0             lifecycle_0.1.0        
##  [52] miniUI_0.1.1.1          MatrixModels_0.4-1      modelr_0.1.5           
##  [55] cellranger_1.1.0        tcltk_3.6.1             boot_1.3-22            
##  [58] base64enc_0.1-3         viridisLite_0.3.0       bitops_1.0-6           
##  [61] KernSmooth_2.23-15      pROC_1.15.3             speedglm_0.3-2         
##  [64] manipulateWidget_0.10.0 ggsignif_0.6.0          scales_1.0.0           
##  [67] leaps_3.0               gdata_2.18.0            compiler_3.6.1         
##  [70] RColorBrewer_1.1-2      cli_1.1.0               htmlTable_1.13.2       
##  [73] mgcv_1.8-28             tidyselect_0.2.5        stringi_1.4.3          
##  [76] highr_0.8               mitools_2.4             yaml_2.2.0             
##  [79] ggrepel_0.8.1           latticeExtra_0.6-28     survMisc_0.5.5         
##  [82] tools_3.6.1             parallel_3.6.1          rio_0.5.16             
##  [85] rstudioapi_0.10         digest_0.6.22           quadprog_1.5-7         
##  [88] Rcpp_1.0.2              broom_0.5.2             later_1.0.0            
##  [91] httr_1.4.1              qvcalc_1.0.1            colorspace_1.4-1       
##  [94] rvest_0.3.4             XML_3.98-1.20           statmod_1.4.32         
##  [97] expm_0.999-4            etm_1.0.5               xtable_1.8-4           
## [100] jsonlite_1.6            nloptr_1.2.1            flashClust_1.01-2      
## [103] zeallot_0.1.0           R6_2.4.0                pillar_1.4.2           
## [106] htmltools_0.4.0         mime_0.7                prediction_0.3.14      
## [109] glue_1.3.1              fastmap_1.0.1           minqa_1.2.4            
## [112] deSolve_1.24            class_7.3-15            utf8_1.1.4             
## [115] numDeriv_2016.8-1.1     curl_4.2                BiasedUrn_1.07         
## [118] gtools_3.8.1            zip_2.0.4               openxlsx_4.1.0.1       
## [121] rmarkdown_1.16          munsell_0.5.0           e1071_1.7-2            
## [124] labelled_2.2.1          reshape2_1.4.3          gtable_0.3.0           
## [127] rms_5.1-3.1</code></pre>

<div id="refs" class="references">
<div id="ref-Abadie2016">
<p>Abadie, Alberto, and Guido W Imbens. 2016. “Matching on the Estimated Propensity Score.” <em>Econometrica</em> 84 (2): 781–807.</p>
</div>
<div id="ref-Armitage2008">
<p>Armitage, Peter, Geoffrey Berry, and John Nigel Scott Matthews. 2008. <em>Statistical Methods in Medical Research</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-Austin2011">
<p>Austin, Peter C. 2011. “An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies.” <em>Multivariate Behavioral Research</em> 46 (3): 399–424.</p>
</div>
<div id="ref-van2004biostatistics">
<p>Belle, G. van, L. D. Fisher, P. J. Heagerty, and T. Lumley. 2004. <em>Biostatistics: A Methodology for the Health Sciences</em>. Wiley Series in Probability and Statistics. Wiley. <a href="https://books.google.co.uk/books?id=KSh8IOrLPzwC">https://books.google.co.uk/books?id=KSh8IOrLPzwC</a>.</p>
</div>
<div id="ref-Bland1986">
<p>Bland, J Martin, and DouglasG Altman. 1986. “Statistical Methods for Assessing Agreement Between Two Methods of Clinical Measurement.” <em>The Lancet</em> 327 (8476): 307–10.</p>
</div>
<div id="ref-Cattaneo2010d">
<p>Cattaneo, Matias D. 2010. “Efficient Semiparametric Estimation of Multi-Valued Treatment Effects Under Ignorability.” <em>Journal of Econometrics</em> 155 (2): 138–54.</p>
</div>
<div id="ref-Cox1972b">
<p>Cox, David R. 1972. “Models and Life-Tables Regression.” <em>JR Stat. Soc. Ser. B</em> 34: 187–220.</p>
</div>
<div id="ref-cox2006principles">
<p>Cox, D. R. 2006. <em>Principles of Statistical Inference</em>. Cambridge University Press. <a href="https://books.google.co.jp/books?id=nRgtGZXi2KkC">https://books.google.co.jp/books?id=nRgtGZXi2KkC</a>.</p>
</div>
<div id="ref-Cox1946">
<p>Cox, R. T. 1946. “Probability, Frequency and Reasonable Expectation.” <em>American Journal of Physics</em> 14 (1): 1–13. <a href="https://doi.org/10.1119/1.1990764">https://doi.org/10.1119/1.1990764</a>.</p>
</div>
<div id="ref-Dawid2000">
<p>Dawid, A Philip. 2000. “Causal Inference Without Counterfactuals.” <em>Journal of the American Statistical Association</em> 95 (450): 407–24.</p>
</div>
<div id="ref-DeFinetti1974">
<p>De Finetti, Bruno. 1974. <em>Theory of Probability: A Critical Introductory Treatment. Transl. By Antonio Machi and Adrian Smith</em>. J. Wiley.</p>
</div>
<div id="ref-diggle1994informative">
<p>Diggle, Peter, and Michael G Kenward. 1994. “Informative Drop-Out in Longitudinal Data Analysis.” <em>Applied Statistics</em>, 49–93.</p>
</div>
<div id="ref-diggle2002childhood">
<p>Diggle, Peter, Rana Moyeed, Barry Rowlingson, and Madeleine Thomson. 2002. “Childhood Malaria in the Gambia: A Case-Study in Model-Based Geostatistics.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 51 (4): 493–506.</p>
</div>
<div id="ref-Fisher1922">
<p>Fisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” <em>Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</em> 222: 309–68. <a href="http://www.jstor.org/stable/91208">http://www.jstor.org/stable/91208</a>.</p>
</div>
<div id="ref-gelman2013bayesian">
<p>Gelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. <em>Bayesian Data Analysis, Third Edition</em>. Chapman &amp; Hall/Crc Texts in Statistical Science. Taylor &amp; Francis. <a href="https://books.google.co.uk/books?id=ZXL6AQAAQBAJ">https://books.google.co.uk/books?id=ZXL6AQAAQBAJ</a>.</p>
</div>
<div id="ref-good2006permutation">
<p>Good, P. I. 2006. <em>Permutation, Parametric, and Bootstrap Tests of Hypotheses</em>. Springer Series in Statistics. Springer New York. <a href="https://books.google.co.uk/books?id=tQtedCBEgeAC">https://books.google.co.uk/books?id=tQtedCBEgeAC</a>.</p>
</div>
<div id="ref-Gower1971">
<p>Gower, John C. 1971. “A General Coefficient of Similarity and Some of Its Properties.” <em>Biometrics</em>, 857–71.</p>
</div>
<div id="ref-hosmer1980goodness">
<p>Hosmer, David W, and Stanley Lemesbow. 1980. “Goodness of Fit Tests for the Multiple Logistic Regression Model.” <em>Communications in Statistics-Theory and Methods</em> 9 (10): 1043–69.</p>
</div>
<div id="ref-johnson2009shifting">
<p>Johnson, Sindhu R, Brian M Feldman, Janet E Pope, and George A Tomlinson. 2009. “Shifting Our Thinking About Uncommon Disease Trials: The Case of Methotrexate in Scleroderma.” <em>The Journal of Rheumatology</em> 36 (2): 323–29.</p>
</div>
<div id="ref-Laan2017">
<p>Laan, Mark J van der, and Sherri Rose. 2017. “Targeted Learning in Data Science.” <em>New York, NY: Springer International Publishing. Doi</em> 10: 978–3.</p>
</div>
<div id="ref-lesaffre2012bayesian">
<p>Lesaffre, E., and A. B. Lawson. 2012. <em>Bayesian Biostatistics</em>. Statistics in Practice. Wiley. <a href="https://books.google.co.uk/books?id=WV7KVjEQnJMC">https://books.google.co.uk/books?id=WV7KVjEQnJMC</a>.</p>
</div>
<div id="ref-Mann2004">
<p>Mann, Vera, Bianca L De Stavola, and David A Leon. 2004. “Separating Within and Between Effects in Family Studies: An Application to the Study of Blood Pressure in Children.” <em>Statistics in Medicine</em> 23 (17): 2745–56.</p>
</div>
<div id="ref-Neyman1923">
<p>Neyman, JS. 1923. “On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.(Tlanslated and Edited by Dm Dabrowska and Tp Speed, Statistical Science (1990), 5, 465-480).” <em>Annals of Agricultural Sciences</em> 10: 1–51.</p>
</div>
<div id="ref-Pearl2011">
<p>Pearl, Judea. 2011. “Invited Commentary: Understanding Bias Amplification.” <em>American Journal of Epidemiology</em> 174 (11): 1223–7.</p>
</div>
<div id="ref-Pepe2007">
<p>Pepe, Margaret S, Ziding Feng, Ying Huang, Gary Longton, Ross Prentice, Ian M Thompson, and Yingye Zheng. 2007. “Integrating the Predictiveness of a Marker with Its Performance as a Classifier.” <em>American Journal of Epidemiology</em> 167 (3): 362–68.</p>
</div>
<div id="ref-Raudenbush2002">
<p>Raudenbush, Stephen W, and Anthony S Bryk. 2002. <em>Hierarchical Linear Models: Applications and Data Analysis Methods</em>. Vol. 1. Sage.</p>
</div>
<div id="ref-Robinson1991">
<p>Robinson, Laurence D, and Nicholas P Jewell. 1991. “Some Surprising Results About Covariate Adjustment in Logistic Regression Models.” <em>International Statistical Review</em>, 227–40.</p>
</div>
<div id="ref-Robinson1950">
<p>Robinson, W. S. 1950. “Ecological Correlations and the Behavior of Individuals.” <em>American Sociological Review</em> 15 (3): 351–57. <a href="http://www.jstor.org/stable/2087176">http://www.jstor.org/stable/2087176</a>.</p>
</div>
<div id="ref-Rosenbaum1983">
<p>Rosenbaum, Paul R, and Donald B Rubin. 1983. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” <em>Biometrika</em> 70 (1): 41–55.</p>
</div>
<div id="ref-Royston2002">
<p>Royston, Patrick, and Mahesh KB Parmar. 2002. “Flexible Parametric Proportional-Hazards and Proportional-Odds Models for Censored Survival Data, with Application to Prognostic Modelling and Estimation of Treatment Effects.” <em>Statistics in Medicine</em> 21 (15): 2175–97.</p>
</div>
<div id="ref-Rubin1974">
<p>Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” <em>Journal of Educational Psychology</em> 66 (5): 688.</p>
</div>
<div id="ref-Smith1995">
<p>Smith, Adrian. 1995. “A Conversation with Dennis Lindley.” <em>Statistical Science</em> 10 (3): 305–19.</p>
</div>
<div id="ref-Snijders1999">
<p>Snijders, Tom, and Roel Bosker. 1999. “Multilevel Analysis: An Introduction to Basic and Applied Multilevel Analysis.” London: Sage.</p>
</div>
<div id="ref-spiegelhalter2004bayesian">
<p>Spiegelhalter, David J, Keith R Abrams, and Jonathan P Myles. 2004. <em>Bayesian Approaches to Clinical Trials and Health-Care Evaluation</em>. Vol. 13. John Wiley &amp; Sons.</p>
</div>
<div id="ref-Spiegelhalter2002">
<p>Spiegelhalter, David J, Nicola G Best, Bradley P Carlin, and Angelika Van Der Linde. 2002. “Bayesian Measures of Model Complexity and Fit.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 64 (4): 583–639.</p>
</div>
<div id="ref-tinmouth2004low">
<p>Tinmouth, Alan, Ian F Tannock, Michael Crump, George Tomlinson, Joseph Brandwein, Mark Minden, and David Sutton. 2004. “Low-Dose Prophylactic Platelet Transfusions in Recipients of an Autologous Peripheral Blood Progenitor Cell Transplant and Patients with Acute Leukemia: A Randomized Controlled Trial with a Sequential Bayesian Design.” <em>Transfusion</em> 44 (12): 1711–9.</p>
</div>
<div id="ref-Verbeke1997">
<p>Verbeke, Geert. 1997. <em>Linear Mixed Models for Longitudinal Data</em>. Springer.</p>
</div>
<div id="ref-xie2015">
<p>Xie, Yihui. 2015. <em>Dynamic Documents with R and Knitr</em>. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. <a href="http://yihui.name/knitr/">http://yihui.name/knitr/</a>.</p>
</div>
<div id="ref-R-bookdown">
<p>———. 2018. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>區分與之前討論的對數似然比 (Section <a href="#llr">13</a>)，之前討論的對數似然比指的是<strong>所有的似然和極大似然</strong>之間的比，此處的似然比只是純粹在探討兩個假設之間的似然比，<strong>與極大似然無關</strong>。<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Rememer that <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> is a random variable: the data varies <strong>each time</strong> we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of <span class="math inline">\(\ell_{H_0}-\ell_{H_1}\)</span> which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="http://www.senns.demon.co.uk/wdict.html" class="uri">http://www.senns.demon.co.uk/wdict.html</a><a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Foreward for “Theory of probability, a critical introductory treatment” by B. de Finetti(Wiley, 1974)<span class="citation">(De Finetti <a href="#ref-DeFinetti1974" role="doc-biblioref">1974</a>)</span>; see also Smith (1995)<span class="citation">(Smith <a href="#ref-Smith1995" role="doc-biblioref">1995</a>)</span><a href="#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/%s",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
