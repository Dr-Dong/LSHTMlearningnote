<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 43 章 重要概念複習 | 醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="第 43 章 重要概念複習 | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 43 章 重要概念複習 | 醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2019-10-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="08-Intro-to-Bayes.html"/>
<link rel="next" href="10-Hierarchical-models.html"/>
<script src="assets/jquery/jquery.min.js"></script>
<link href="assets/gitbook/css/style.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/kePrint/kePrint.js"></script>
<script src="assets/htmlwidgets/htmlwidgets.js"></script>
<script src="assets/plotly-binding/plotly.js"></script>
<script src="assets/typedarray/typedarray.min.js"></script>
<link href="assets/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="assets/crosstalk/js/crosstalk.min.js"></script>
<link href="assets/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="assets/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="00-author.html"><a href="00-author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="01-Probability.html"><a href="01-Probability.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Probability.html"><a href="01-Probability.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="01-Probability.html"><a href="01-Probability.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="01-Probability.html"><a href="01-Probability.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="01-Probability.html"><a href="01-Probability.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="01-Probability.html"><a href="01-Probability.html#Bayes-Definition"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="01-Probability.html"><a href="01-Probability.html#期望-expectation-或均值-or-mean-和-方差-variance"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="01-Probability.html"><a href="01-Probability.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="01-Probability.html"><a href="01-Probability.html#bernoulli"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="01-Probability.html"><a href="01-Probability.html#binomial"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="01-Probability.html"><a href="01-Probability.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="01-Probability.html"><a href="01-Probability.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="01-Probability.html"><a href="01-Probability.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="01-Probability.html"><a href="01-Probability.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="01-Probability.html"><a href="01-Probability.html#poisson"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="01-Probability.html"><a href="01-Probability.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="01-Probability.html"><a href="01-Probability.html#正態分佈-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="01-Probability.html"><a href="01-Probability.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="01-Probability.html"><a href="01-Probability.html#CLT"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="01-Probability.html"><a href="01-Probability.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="01-Probability.html"><a href="01-Probability.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="01-Probability.html"><a href="01-Probability.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="01-Probability.html"><a href="01-Probability.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="01-Probability.html"><a href="01-Probability.html#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="01-Probability.html"><a href="01-Probability.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="01-Probability.html"><a href="01-Probability.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="01-Probability.html"><a href="01-Probability.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="01-Probability.html"><a href="01-Probability.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="01-Probability.html"><a href="01-Probability.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="02-Inference.html"><a href="02-Inference.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="02-Inference.html"><a href="02-Inference.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="02-Inference.html"><a href="02-Inference.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="02-Inference.html"><a href="02-Inference.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="02-Inference.html"><a href="02-Inference.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="02-Inference.html"><a href="02-Inference.html#估計和精確度-estimation-and-precision"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="02-Inference.html"><a href="02-Inference.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="02-Inference.html"><a href="02-Inference.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="02-Inference.html"><a href="02-Inference.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="02-Inference.html"><a href="02-Inference.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="02-Inference.html"><a href="02-Inference.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="02-Inference.html"><a href="02-Inference.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="02-Inference.html"><a href="02-Inference.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="02-Inference.html"><a href="02-Inference.html#chi-square-distribution"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="02-Inference.html"><a href="02-Inference.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="02-Inference.html"><a href="02-Inference.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="02-Inference.html"><a href="02-Inference.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-definition"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="02-Inference.html"><a href="02-Inference.html#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="02-Inference.html"><a href="02-Inference.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="02-Inference.html"><a href="02-Inference.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="02-Inference.html"><a href="02-Inference.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="02-Inference.html"><a href="02-Inference.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="02-Inference.html"><a href="02-Inference.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="02-Inference.html"><a href="02-Inference.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="02-Inference.html"><a href="02-Inference.html#llr"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="02-Inference.html"><a href="02-Inference.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="02-Inference.html"><a href="02-Inference.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="02-Inference.html"><a href="02-Inference.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="02-Inference.html"><a href="02-Inference.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="02-Inference.html"><a href="02-Inference.html#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="02-Inference.html"><a href="02-Inference.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="02-Inference.html"><a href="02-Inference.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="02-Inference.html"><a href="02-Inference.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="02-Inference.html"><a href="02-Inference.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="02-Inference.html"><a href="02-Inference.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="02-Inference.html"><a href="02-Inference.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="02-Inference.html"><a href="02-Inference.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="02-Inference.html"><a href="02-Inference.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的構建-construction-of-a-hypothesis-test"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="02-Inference.html"><a href="02-Inference.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="02-Inference.html"><a href="02-Inference.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="02-Inference.html"><a href="02-Inference.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="02-Inference.html"><a href="02-Inference.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="02-Inference.html"><a href="02-Inference.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="02-Inference.html"><a href="02-Inference.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="02-Inference.html"><a href="02-Inference.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="02-Inference.html"><a href="02-Inference.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="02-Inference.html"><a href="02-Inference.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="02-Inference.html"><a href="02-Inference.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="02-Inference.html"><a href="02-Inference.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="02-Inference.html"><a href="02-Inference.html#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗的近似方法"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="02-Inference.html"><a href="02-Inference.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="02-Inference.html"><a href="02-Inference.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="02-Inference.html"><a href="02-Inference.html#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="02-Inference.html"><a href="02-Inference.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="02-Inference.html"><a href="02-Inference.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="02-Inference.html"><a href="02-Inference.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="02-Inference.html"><a href="02-Inference.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="02-Inference.html"><a href="02-Inference.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="02-Inference.html"><a href="02-Inference.html#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="02-Inference.html"><a href="02-Inference.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="02-Inference.html"><a href="02-Inference.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="02-Inference.html"><a href="02-Inference.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="02-Inference.html"><a href="02-Inference.html#正態誤差模型-normal-error-models"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="02-Inference.html"><a href="02-Inference.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="02-Inference.html"><a href="02-Inference.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="02-Inference.html"><a href="02-Inference.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="02-Inference.html"><a href="02-Inference.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="02-Inference.html"><a href="02-Inference.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="02-Inference.html"><a href="02-Inference.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="02-Inference.html"><a href="02-Inference.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="02-Inference.html"><a href="02-Inference.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="02-Inference.html"><a href="02-Inference.html#多個參數時的統計推斷-inference-with-multiple-parameters-i"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="02-Inference.html"><a href="02-Inference.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="02-Inference.html"><a href="02-Inference.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="02-Inference.html"><a href="02-Inference.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="02-Inference.html"><a href="02-Inference.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="02-Inference.html"><a href="02-Inference.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="02-Inference.html"><a href="02-Inference.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="02-Inference.html"><a href="02-Inference.html#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="02-Inference.html"><a href="02-Inference.html#profile-log-likelihood"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="02-Inference.html"><a href="02-Inference.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="02-Inference.html"><a href="02-Inference.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="02-Inference.html"><a href="02-Inference.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="02-Inference.html"><a href="02-Inference.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="02-Inference.html"><a href="02-Inference.html#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path="02-Inference.html"><a href="02-Inference.html#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path="02-Inference.html"><a href="02-Inference.html#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path="02-Inference.html"><a href="02-Inference.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path="02-Inference.html"><a href="02-Inference.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間-confidence-intervals-1"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#假設檢驗"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關-association"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較-comparisons"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#前提和數據轉換-assumptions-and-transformations"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path="03-Analytic-Technique.html"><a href="03-Analytic-Technique.html#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#ANOVA"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析-multivariable-models"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元模型分析矩陣標記與其意義"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸的模型診斷"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path="04-Linear-Regression.html"><a href="04-Linear-Regression.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="05-clinical-trials.html"><a href="05-clinical-trials.html#baseline-adjustment-using-ancova"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法-permutation-procedures"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#自助重抽法-the-bootstrap"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="06-RobustStatistic.html"><a href="06-RobustStatistic.html#the-sandwich-estimator"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯定理的應用單一參數模型"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="08-Intro-to-Bayes.html"><a href="08-Intro-to-Bayes.html#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path="09-GLM.html"><a href="09-GLM.html"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path="09-GLM.html"><a href="09-GLM.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path="09-GLM.html"><a href="09-GLM.html#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path="09-GLM.html"><a href="09-GLM.html#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path="09-GLM.html"><a href="09-GLM.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path="09-GLM.html"><a href="09-GLM.html#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path="09-GLM.html"><a href="09-GLM.html#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path="09-GLM.html"><a href="09-GLM.html#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path="09-GLM.html"><a href="09-GLM.html#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path="09-GLM.html"><a href="09-GLM.html#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path="09-GLM.html"><a href="09-GLM.html#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path="09-GLM.html"><a href="09-GLM.html#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path="09-GLM.html"><a href="09-GLM.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="09-GLM.html"><a href="09-GLM.html#廣義線性迴歸入門"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path="09-GLM.html"><a href="09-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="09-GLM.html"><a href="09-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path="09-GLM.html"><a href="09-GLM.html#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path="09-GLM.html"><a href="09-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path="09-GLM.html"><a href="09-GLM.html#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path="09-GLM.html"><a href="09-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path="09-GLM.html"><a href="09-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path="09-GLM.html"><a href="09-GLM.html#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型-logistic-regression-model"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path="09-GLM.html"><a href="09-GLM.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path="09-GLM.html"><a href="09-GLM.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path="09-GLM.html"><a href="09-GLM.html#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path="09-GLM.html"><a href="09-GLM.html#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="09-GLM.html"><a href="09-GLM.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path="09-GLM.html"><a href="09-GLM.html#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path="09-GLM.html"><a href="09-GLM.html#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path="09-GLM.html"><a href="09-GLM.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path="09-GLM.html"><a href="09-GLM.html#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="09-GLM.html"><a href="09-GLM.html#模型比較和擬合優度"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path="09-GLM.html"><a href="09-GLM.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path="09-GLM.html"><a href="09-GLM.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path="09-GLM.html"><a href="09-GLM.html#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path="09-GLM.html"><a href="09-GLM.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path="09-GLM.html"><a href="09-GLM.html#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path="09-GLM.html"><a href="09-GLM.html#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path="09-GLM.html"><a href="09-GLM.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path="09-GLM.html"><a href="09-GLM.html#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="09-GLM.html"><a href="09-GLM.html#計數型因變量-poisson-regression"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path="09-GLM.html"><a href="09-GLM.html#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path="09-GLM.html"><a href="09-GLM.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path="09-GLM.html"><a href="09-GLM.html#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path="09-GLM.html"><a href="09-GLM.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="09-GLM.html"><a href="09-GLM.html#率的廣義線性迴歸-poisson-glm-for-rates"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path="09-GLM.html"><a href="09-GLM.html#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path="09-GLM.html"><a href="09-GLM.html#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path="09-GLM.html"><a href="09-GLM.html#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path="09-GLM.html"><a href="09-GLM.html#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path="09-GLM.html"><a href="09-GLM.html#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path="09-GLM.html"><a href="09-GLM.html#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path="09-GLM.html"><a href="09-GLM.html#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path="09-GLM.html"><a href="09-GLM.html#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="09-GLM.html"><a href="09-GLM.html#混雜的調整交互作用和模型的可壓縮性"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path="09-GLM.html"><a href="09-GLM.html#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path="09-GLM.html"><a href="09-GLM.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="09-GLM.html"><a href="09-GLM.html#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path="09-GLM.html"><a href="09-GLM.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path="09-GLM.html"><a href="09-GLM.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path="09-GLM.html"><a href="09-GLM.html#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="09-GLM.html"><a href="09-GLM.html#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="09-GLM.html"><a href="09-GLM.html#流行病學中的邏輯迴歸"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path="09-GLM.html"><a href="09-GLM.html#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path="09-GLM.html"><a href="09-GLM.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path="09-GLM.html"><a href="09-GLM.html#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="09-GLM.html"><a href="09-GLM.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path="09-GLM.html"><a href="09-GLM.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path="09-GLM.html"><a href="09-GLM.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path="09-GLM.html"><a href="09-GLM.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path="09-GLM.html"><a href="09-GLM.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="09-GLM.html"><a href="09-GLM.html#分析策略"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path="09-GLM.html"><a href="09-GLM.html#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path="09-GLM.html"><a href="09-GLM.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path="09-GLM.html"><a href="09-GLM.html#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path="09-GLM.html"><a href="09-GLM.html#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path="09-GLM.html"><a href="09-GLM.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="09-GLM.html"><a href="09-GLM.html#檢查你的模型-model-checking---glm"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path="09-GLM.html"><a href="09-GLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path="09-GLM.html"><a href="09-GLM.html#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path="09-GLM.html"><a href="09-GLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path="09-GLM.html"><a href="09-GLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="09-GLM.html"><a href="09-GLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path="09-GLM.html"><a href="09-GLM.html#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path="09-GLM.html"><a href="09-GLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path="09-GLM.html"><a href="09-GLM.html#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="09-GLM.html"><a href="09-GLM.html#評價模型的表現-assessing-model-performance"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path="09-GLM.html"><a href="09-GLM.html#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path="09-GLM.html"><a href="09-GLM.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path="09-GLM.html"><a href="09-GLM.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path="09-GLM.html"><a href="09-GLM.html#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗數據的分析法"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path="09-GLM.html"><a href="09-GLM.html#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path="09-GLM.html"><a href="09-GLM.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path="09-GLM.html"><a href="09-GLM.html#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="09-GLM.html"><a href="09-GLM.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path="09-GLM.html"><a href="09-GLM.html#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path="09-GLM.html"><a href="09-GLM.html#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="09-GLM.html"><a href="09-GLM.html#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path="09-GLM.html"><a href="09-GLM.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path="09-GLM.html"><a href="09-GLM.html#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path="09-GLM.html"><a href="09-GLM.html#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="09-GLM.html"><a href="09-GLM.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯迴歸-conditional-logistic-regression"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path="09-GLM.html"><a href="09-GLM.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path="09-GLM.html"><a href="09-GLM.html#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path="09-GLM.html"><a href="09-GLM.html#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path="09-GLM.html"><a href="09-GLM.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path="09-GLM.html"><a href="09-GLM.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path="09-GLM.html"><a href="09-GLM.html#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="09-GLM.html"><a href="09-GLM.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="09-GLM.html"><a href="09-GLM.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path="09-GLM.html"><a href="09-GLM.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型-random-intercept-model"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型中加入共變量-random-intercept-model-with-covariates"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數模型-random-coefficient-model"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.8" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.9" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.10" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.11" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-1"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-2"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#縱向研究數據-longitudinal-data-3"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#generalized-estimating-equation"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysisunsupervised-learning-聚類分析"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-1"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#principal-component-analysis-主成分分析"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#missing-data-2"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path="10-Hierarchical-models.html"><a href="10-Hierarchical-models.html#further-issues"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數分布"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#nonparametric"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據中的回歸模型"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-分布-1"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-比例風險模型"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分析策略和模型檢查-model-checking-survival-analysis"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#競爭風險模型-competing-risk"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#生存分析的其他手段"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#加速失效模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.1</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量-time-dependent-variables-和脆弱模型-frailty-model"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path="11-Survival-analysis.html"><a href="11-Survival-analysis.html#時間事件數據的高級分析法"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="80" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html"><i class="fa fa-check"></i><b>80</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="80.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>80.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="80.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>80.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="80.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#概率論者分析結果"><i class="fa fa-check"></i><b>80.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="80.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>80.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="80.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-the-great-trial"><i class="fa fa-check"></i><b>80.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="80.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#background-great-trial"><i class="fa fa-check"></i><b>80.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="80.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#試驗結果"><i class="fa fa-check"></i><b>80.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="80.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#經典統計學分析方法"><i class="fa fa-check"></i><b>80.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="80.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>80.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MC-estimation"><i class="fa fa-check"></i><b>81</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="81.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#起源"><i class="fa fa-check"></i><b>81.1</b> 起源</a><ul>
<li class="chapter" data-level="81.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#作出預測"><i class="fa fa-check"></i><b>81.1.1</b> 作出預測</a></li>
<li class="chapter" data-level="81.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#example-新藥表現預測"><i class="fa fa-check"></i><b>81.1.2</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>81.2</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="81.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>81.2.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="81.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>81.2.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="81.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#蒙特卡羅法分析軟件-openbugs"><i class="fa fa-check"></i><b>81.3</b> 蒙特卡羅法分析軟件 OpenBUGS</a><ul>
<li class="chapter" data-level="81.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>81.3.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="81.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>81.3.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="81.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>81.3.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>81.4</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="82" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率-conjugate-priors"><i class="fa fa-check"></i><b>82</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="82.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>82.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="82.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="82.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#事後概率分布預測"><i class="fa fa-check"></i><b>82.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="82.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>82.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="82.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>82.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="82.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesPrac03"><i class="fa fa-check"></i><b>82.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="83" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#MCMC-methods"><i class="fa fa-check"></i><b>83</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="83.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>83.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="83.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>83.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="83.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Gibbs-sampling"><i class="fa fa-check"></i><b>83.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="83.1.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值-initial-values"><i class="fa fa-check"></i><b>83.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="83.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>83.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="83.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#收斂時間"><i class="fa fa-check"></i><b>83.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="83.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>83.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="83.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-軟件"><i class="fa fa-check"></i><b>83.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="83.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>83.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="83.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>83.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="83.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-language"><i class="fa fa-check"></i><b>83.5</b> BUGS language</a><ul>
<li class="chapter" data-level="83.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>83.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="83.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#分布的標記法"><i class="fa fa-check"></i><b>83.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="83.5.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#arrays-and-loops"><i class="fa fa-check"></i><b>83.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="83.5.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#常用的方程"><i class="fa fa-check"></i><b>83.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="83.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>83.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="83.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>83.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#建模和模型的檢查"><i class="fa fa-check"></i><b>84</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="84.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#BayesianLM"><i class="fa fa-check"></i><b>84.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="84.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#children-in-the-gambia"><i class="fa fa-check"></i><b>84.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="84.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>84.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="84.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>84.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="84.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="84.2.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>84.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="84.2.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>84.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="84.2.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>84.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="84.2.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>84.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="84.2.8" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>84.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="84.2.9" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#tdreplacegaussian"><i class="fa fa-check"></i><b>84.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="84.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>84.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="84.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>84.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="84.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>84.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="84.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>84.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="84.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>84.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="84.4.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>84.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="85" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#不同實驗研究設計時適用的貝葉斯模型"><i class="fa fa-check"></i><b>85</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="85.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>85.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="85.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>85.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="85.4.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>85.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="85.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>85.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="85.5.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#the-great-trial"><i class="fa fa-check"></i><b>85.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="85.5.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#吸煙與癌症"><i class="fa fa-check"></i><b>85.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯廣義線性回歸"><i class="fa fa-check"></i><b>86</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="86.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>86.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="86.1.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>86.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="86.1.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>86.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="86.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>86.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="86.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#低出生體重數據-1"><i class="fa fa-check"></i><b>86.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="86.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>86.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="86.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>86.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="86.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#Bayesian-practical07"><i class="fa fa-check"></i><b>86.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="87" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級回歸模型"><i class="fa fa-check"></i><b>87</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="87.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>87.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="87.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>87.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="87.2.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>87.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="87.2.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>87.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="87.2.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>87.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="87.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>87.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="87.3.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#縱向數據"><i class="fa fa-check"></i><b>87.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="87.3.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-example"><i class="fa fa-check"></i><b>87.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="87.3.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>87.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="87.3.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>87.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="87.3.5" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>87.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="87.3.6" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>87.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="87.3.7" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>87.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="87.4" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>87.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#再訪-mcmc"><i class="fa fa-check"></i><b>88</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="88.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>88.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="88.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>88.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#貝葉斯和概率論的比較"><i class="fa fa-check"></i><b>89</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="89.1" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>89.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="89.2" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>89.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="89.3" data-path="12-Bayesian-stats.html"><a href="12-Bayesian-stats.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>89.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="90" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html"><i class="fa fa-check"></i><b>90</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="90.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>90.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="90.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>90.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="90.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步分析"><i class="fa fa-check"></i><b>90.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="90.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#混雜"><i class="fa fa-check"></i><b>90.2.2</b> 混雜</a></li>
<li class="chapter" data-level="90.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>90.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="90.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>90.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="90.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>90.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="90.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>90.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="90.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>90.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="90.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>90.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="91" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#graphical-models-因果推斷的圖形模型"><i class="fa fa-check"></i><b>91</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="91.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>91.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="91.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>91.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="91.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#dag-圖的術語"><i class="fa fa-check"></i><b>91.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="91.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>91.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="91.1.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>91.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="91.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#以非對撞銀子爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>91.2</b> 以非對撞銀子爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="91.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件的總結"><i class="fa fa-check"></i><b>91.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="91.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#d-分離-d-separation"><i class="fa fa-check"></i><b>91.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-continuous-outcomes-結果變量爲連續型變量"><i class="fa fa-check"></i><b>92</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="92.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>92.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="92.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>92.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="92.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>92.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="92.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>92.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="92.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>92.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="92.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>92.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="92.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#條件因果均值差"><i class="fa fa-check"></i><b>92.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="92.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>92.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="92.3.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>92.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="92.3.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#positivity-非零性"><i class="fa fa-check"></i><b>92.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="92.3.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>92.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical03---causal-inference"><i class="fa fa-check"></i><b>92.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="93" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#regression-methods-with-binary-outcomes-結果變量爲二分類變量"><i class="fa fa-check"></i><b>93</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="93.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>93.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="93.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>93.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>93.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="93.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>93.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="93.3.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>93.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="93.3.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>93.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="93.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>93.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="93.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>93.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="93.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical04---causal-inference"><i class="fa fa-check"></i><b>93.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="93.6.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>93.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="93.6.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>93.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="93.6.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>93.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="93.6.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>93.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="93.6.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>93.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="93.6.7" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>93.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="93.6.8" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>93.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="93.6.9" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>93.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="93.6.10" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>93.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="93.6.11" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>93.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="93.6.12" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>93.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="94" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#prospensity-score-傾向性評分"><i class="fa fa-check"></i><b>94</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="94.0.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#關於條件可置換性"><i class="fa fa-check"></i><b>94.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="94.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>94.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="94.1.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#分層法-stratification"><i class="fa fa-check"></i><b>94.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="94.1.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#配對法-matching"><i class="fa fa-check"></i><b>94.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="94.1.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>94.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#practical05---causal-inference"><i class="fa fa-check"></i><b>94.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="94.2.1" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>94.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="94.2.2" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>94.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="94.2.3" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>94.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="94.2.4" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>94.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="94.2.5" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#用配對法計算-ace"><i class="fa fa-check"></i><b>94.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="94.2.6" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#模型校正-ps"><i class="fa fa-check"></i><b>94.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#inverse-probability-weighted-estimation-and-doubly-robust-methods"><i class="fa fa-check"></i><b>95</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="96" data-path="16-ASM-Causal-infer.html"><a href="16-ASM-Causal-infer.html#causal-mediation-analysis"><i class="fa fa-check"></i><b>96</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="97" data-path="29SME.html"><a href="29SME.html"><i class="fa fa-check"></i><b>97</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="30-references.html"><a href="30-references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="重要概念複習" class="section level1">
<h1><span class="header-section-number">第 43 章</span> 重要概念複習</h1>
<blockquote>
<dl>
<dt>There are no routine statistical questions, only questionable statistical routines.</dt>
<dd>Sir David Cox
</dd>
</dl>
</blockquote>

<div class="rmdnote">
The Generalised Linear Regression lectures were orgainised and taught by Professor <a href="https://www.lshtm.ac.uk/aboutus/people/frost.chris">Chris Frost</a>.
</div>

<div id="概率論學派統計推斷要點複習" class="section level2">
<h2><span class="header-section-number">43.1</span> 概率論學派統計推斷要點複習</h2>
<p>下面我們一起用二項分佈的概念 (<span class="math inline">\(n\)</span> 個對象中 <span class="math inline">\(K\)</span> 個“事件”)，來複習概率論學派的統計推斷要點。</p>
<ol style="list-style-type: decimal">
<li>模型，the Model。一個統計模型，描述的不僅僅是我們研究的人羣的一些特徵，而且通常一個模型還可提供如何從人羣中收集該樣本的信息。<br> 用二項分佈的概念來解釋，人羣是衆多個體的集合，他們中的一部分佔比 <span class="math inline">\(\pi\)</span> 的人身上發生了某個事件。從這個人羣的集合中，我們隨機抽取 <span class="math inline">\(n\)</span> 個對象作爲<strong>研究樣本</strong>，該樣本中有 <span class="math inline">\(K\)</span> 個人身上發生了事件。此時，我們說 <span class="math inline">\(K\)</span> 服從人羣比例爲 <span class="math inline">\(\pi\)</span> 的二項分佈：<span class="math inline">\(K \sim \text{Bin}(n,\pi)\)</span>。</li>
<li>參數，parameters。模型中的參數反映了人羣的某些特徵。在實際應用中，從來沒有“人類”能知道人羣參數的真實值，渺小的我們從人羣中抽取樣本，用於推斷 “上帝才知道的” 這些代表了人羣特徵的參數。<br> 在二項分佈的情境下，有且只有一個人羣參數，人羣中事件的比例 <span class="math inline">\(\pi\)</span>。</li>
<li>參數估計量，parameter estimators。估計量是樣本的統計量，被用來估計未知的總體參數。估計量 estimator，是一個隨機變量，是我們計算估計值的一般形式。估計值 estimate，是每個樣本通過統計模型計算獲得的估計量的真實值，每採樣一次，計算獲得的估計值理論上會略有不同。<br> 二項分佈的上下文中，人羣事件比例 – 這一參數 <span class="math inline">\(\pi\)</span> 的天然估計量是 <span class="math inline">\(\hat\pi = \frac{K}{n}\)</span>，當一個樣本中發現 <span class="math inline">\(K = k\)</span>，該樣本給出的估計值是 <span class="math inline">\(\frac{k}{n}\)</span>。</li>
<li>研究假設，hypotheses。研究假設是實驗前我們提出的要被檢驗的一些關於人羣某些特徵參數的 “陳述 statement”。可以是猜想參數等於某個特定值，或者多個參數大小相同。<br> 二項分佈的數據裏，只有一個人羣參數，<span class="math inline">\(\pi\)</span>。可能提出的零假設和替代假設有很多，<span class="math inline">\(\pi = 0.5 \text{ v.s. } \pi \neq 0.5\)</span> 是其中之一的複合型假設。</li>
</ol>
</div>
<div id="似然" class="section level2">
<h2><span class="header-section-number">43.2</span> 似然</h2>
<p>如果一個模型只有一個參數 <span class="math inline">\(\theta\)</span>，樣本數據已知的話，該參數的似然爲：</p>
<p><span class="math display">\[\text{L}(\theta | \text{data}) = \text{Pr}(\text{data}|\theta)\]</span></p>
<p>其中，<span class="math inline">\(\text{Pr}(\text{data}|\theta)\)</span> 對於離散型變量，是概率方程 probability function；對於連續型變量，則是概率密度方程 probability density function (PDF)。</p>
<p>對數似然，就是上面的似然方程取自然底數的對數方程：</p>
<p><span class="math display">\[\ell(\theta | \text{data}) = \text{ln}\{ \text{L}(\theta | \text{data}) \}\]</span></p>
</div>
<div id="極大似然估計" class="section level2">
<h2><span class="header-section-number">43.3</span> 極大似然估計</h2>
<p>當數據收集完畢，從獲得的數據中計算獲得的能夠使似然方程/或對數似然方程取得極大值的 <span class="math inline">\(\theta\)</span> 的大小，被叫做極大似然估計 <span class="math inline">\(\text{(MLE)}\)</span>，且通常數學標記會在參數上加一頂帽子： <span class="math inline">\(\hat\theta\)</span>。收集不同的樣本，在相同的似然方程或對數似然方程下，極大似然估計不同。</p>
<ol style="list-style-type: decimal">
<li>許多問題，我們獲得極大似然估計的方法是先定義好模型的似然方程，然後求該方程的一階導數之後計算使之等於零的參數值大小就是 <span class="math inline">\(\text{MLE } \hat\theta\)</span>。此時，你還要記得再求一次二階導數，看是否小於零，以確保前一步計算獲得的值給出的似然方程是極大值。</li>
<li>更多的時候我們用對數似然方程以簡化計算過程：</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\left.\frac{\text{d}}{\text{d } \theta}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &amp;= \ell^\prime(\hat\theta) = 0 \\
\left.\frac{\text{d}^2}{\text{d } \theta^2}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &amp;= \ell^{\prime\prime}(\hat\theta) &lt; 0
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>我們只關心似然方程的形狀，所以方程中不包含參數的部分可全部忽略掉。</li>
<li><span class="math inline">\(\text{MLE}\)</span> 的一些關鍵性質：
<ol style="list-style-type: decimal">
<li>漸進無偏 asymptotically unbiased：當 <span class="math inline">\(n\rightarrow \infty\)</span> 時，<span class="math inline">\(E(\hat\theta) \rightarrow \theta\)</span>；</li>
<li>一致性 consistency：隨着樣本量的增加，<span class="math inline">\(\hat\theta\)</span> 收斂於 (converges) 總體參數 <span class="math inline">\(\theta\)</span>；</li>
<li>漸進正態分佈 asymptotically normality：隨着樣本量增加，<span class="math inline">\(\hat\theta\)</span> 的樣本分佈收斂於 (converges) 正態分佈，方差爲 <span class="math display">\[E[-\ell^{\prime\prime}(\theta)]^{-1}=[-\ell^{\prime\prime}(\hat\theta)]^{-1}\]</span></li>
<li>恆定性 invariance：如果 <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(\text{MLE}\)</span>，那麼 <span class="math inline">\(\theta\)</span> 被數學轉換以後 <span class="math inline">\(g(\theta)\)</span> 的方程的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(g(\hat\theta)\)</span></li>
</ol></li>
<li>似然理論可以直接拓展到多個參數的情況。一般地，如果一個模型有 <span class="math inline">\(p\)</span> 個參數 <span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T\)</span>，這些參數在給定數據的條件下的似然方程爲：<span class="math display">\[\text{L}(\mathbf{\theta} | \text{data}) = \text{Pr}(\text{data} | \mathbf{\theta})\]</span> 其中，概率 (密度) 方程在多個參數時變成聯合 (joint) 概率 (密度) 方程。似然，也是各個參數的聯合似然方程。此時，參數向量 <span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T\)</span> 的方差協方差矩陣的估計量爲：</li>
</ol>
<p><span class="math display">\[
\hat{\text{Var}}(\mathbf{\hat\theta}) = - \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} &amp; \frac{\partial^2\ell}{\partial\theta^2_2} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} &amp; \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} &amp; \cdots &amp; \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)^{-1}_{\theta=\hat\theta}
\]</span></p>
<p>Tips: typing <code>vcov(Modelname)</code> command in R will display this estimated variance-covariance matrix for the parameter estimates.</p>
<p>回到二項分佈數據的例子：</p>
<p><span class="math display">\[
K \sim \text{Bin}(n, \pi)
\]</span></p>
<p>如果我們樣本的觀測數據是 <span class="math inline">\(K=k\)</span>，對數似然方程一次微分等於零以後求得的參數 <span class="math inline">\(\pi\)</span> 的 <span class="math inline">\(\text{MLE}\)</span> 是 <span class="math inline">\(\hat\pi = \frac{k}{n}\)</span>。所以參數 <span class="math inline">\(\pi\)</span> 的估計量是 <span class="math inline">\(\frac{K}{n}\)</span>。<span class="math inline">\(\hat\pi\)</span> 的方差估計量是：</p>
<p><span class="math display">\[
\hat{\text{Var}} (\hat\pi) = \frac{\hat\pi(1-\hat\pi)}{n} \text{ for } \hat\pi = \frac{k}{n}
\]</span></p>
</div>
<div id="關於假設檢驗的複習" class="section level2">
<h2><span class="header-section-number">43.4</span> 關於假設檢驗的複習</h2>
<p>極大似然估計可以有三大類檢驗方法：似然比檢驗法 likelihood ratio test；Wald 檢驗 Wald test；Score 檢驗 Score test。</p>
<ul>
<li>似然比檢驗法 likelihood ratio test (LRT) (Section <a href="02-Inference.html#LRT">16.2</a>)：</li>
</ul>
<p><span class="math display">\[
-2llr(\theta_0) = -2\{ \ell(\theta_0) - \ell(\hat\theta) \}
\]</span></p>
<p>零假設條件下 (Under <span class="math inline">\(\text{H}_0\)</span>:)</p>
<p><span class="math display">\[
-2llr(\theta_0) \sim \chi_1^2
\]</span></p>
<p>這個對數似然比的統計量可以和自由度爲 1 的卡方分佈作比較，計算反對零假設的證據的強度大小。如果顯著性水平是 <span class="math inline">\(\alpha\)</span>，那麼下面條件成立時，可以認爲反對零假設的證據強度大到足以拒絕零假設。</p>
<p><span class="math display">\[
-2llr(\theta_0) &gt; \chi^2_{1, 1-\alpha}
\]</span></p>
<ul>
<li>Wald 檢驗 (Section <a href="02-Inference.html#Wald">16.4</a>) 是一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
  (\frac{M-\theta_0}{S})^2 &amp; \sim \chi^2_1 \\
 \text{Where } M  &amp; = \hat\theta \\
              S^2 &amp; = \frac{1}{-\ell^{\prime\prime}(\hat\theta)}
\end{aligned}
\]</span></p>
<ul>
<li>Score 檢驗 (Section <a href="02-Inference.html#Score">16.5</a>) 是另一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\frac{U^2}{V} &amp; \sim \chi^2_1 \\
\text{Where } U  &amp; = \ell^\prime(\theta_0) \\
             V &amp; = -\ell^{\prime\prime}(\theta_0)
\end{aligned}
\]</span></p>
<p>如果對數似然方程本身就是一個二次方程 (數據服從完美正態分佈狀態，且總體方差已知時)，這三大類的檢驗法其實計算獲得完全一樣的 <span class="math inline">\(p\)</span> 值，提供完全一致的證據。多數情況下，三大類檢驗法的結果是近似的。關於三種檢驗法的比較可以參考過去總結的章節 (Section <a href="02-Inference.html#LRTwaldScore-Compare">16.6</a>)</p>
<div id="子集似然函數" class="section level3">
<h3><span class="header-section-number">43.4.1</span> 子集似然函數</h3>
<p>當統計模型中的部分參數是噪音參數 (nuisance parameters) 時，我們需要用到子集似然函數法 (Section <a href="02-Inference.html#profile-log-likelihood">19</a>) 來去除噪音參數的影響,，只檢驗我們感興趣的那部分參數。</p>
</div>
</div>
<div id="線性迴歸複習" class="section level2">
<h2><span class="header-section-number">43.5</span> 線性迴歸複習</h2>
<div id="簡單線性迴歸" class="section level3">
<h3><span class="header-section-number">43.5.1</span> 簡單線性迴歸</h3>
<p>假設對於 <span class="math inline">\(n\)</span> 名研究對象，我們測量個兩個觀測值 <span class="math inline">\((y_i, x_i)\)</span>，那麼用線性迴歸模型來表示這兩個測量值估計的參數之間的關係就是：</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;  = \alpha + \beta x_i + \varepsilon_i \\
\text{Where } &amp; \varepsilon_i \sim \text{NID}(0,1)
\end{aligned}
\]</span></p>
<p>或者用另一個標記法：</p>
<p><span class="math display">\[
Y_i | x_i \sim N(\alpha + \beta x_i, \sigma^2)
\]</span></p>
</div>
<div id="多元線性迴歸" class="section level3">
<h3><span class="header-section-number">43.5.2</span> 多元線性迴歸</h3>
<p>如果預測變量有兩個或者兩個以上 <span class="math inline">\((x_i, \;\&amp;\; z_i)\)</span>，那麼描述這兩個預測變量和因變量之間的多元線性迴歸模型可以寫作：</p>
<p><span class="math display">\[
y_i = \alpha + \beta x_i + \gamma z_i + \varepsilon_i
\]</span></p>
<p>此時， <span class="math inline">\(\beta\)</span> 的含義是，當保持 <span class="math inline">\(z\)</span> 不變時，<span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量。用這個模型，我們默認 <span class="math inline">\(z\)</span> 保持不變的同時無論取值爲多少， <span class="math inline">\(x, y\)</span> 之間的關係是不會變化的，我們用這個模型來調整 (adjust) <span class="math inline">\(z\)</span> 的混雜效應 (confounding effect) (Section <a href="04-Linear-Regression.html#confounding">29.5</a>)。</p>
<p>當然我們也可以考慮當 <span class="math inline">\(z\)</span> 取值不同時， <span class="math inline">\(x, y\)</span> 之間的關係發生改變，只要在上面的多元線性迴歸方程中加入一個交互作用項即可 (Section <a href="04-Linear-Regression.html#interaction">32</a>)。</p>
<p><span class="math display">\[
y_i = \alpha + \beta x_i + \gamma z_i + \delta x_i z_i + \varepsilon_i
\]</span></p>
<p>增加了交互作用項最大的變化是，<span class="math inline">\(x_i\)</span> 的迴歸係數 <span class="math inline">\(\beta\)</span> 的含義發生了改變：當且僅當 <span class="math inline">\(z = 0\)</span> 且保持不變時，<span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量。如果 <span class="math inline">\(z = k \neq 0\)</span> 且保持不變，那麼 <span class="math inline">\(x\)</span> 每增加一個單位，<span class="math inline">\(y\)</span> 的變化量則是 <span class="math inline">\(\beta + k\delta\)</span>。</p>
</div>
<div id="score-equations" class="section level3">
<h3><span class="header-section-number">43.5.3</span> 簡單線性迴歸的統計推斷</h3>
<p>一個給定的樣本 <span class="math inline">\((y_i, x_i), i = 1, \cdots, n\)</span> ，其對數似然方程是</p>
<p><span class="math display">\[
\ell(\alpha, \beta, \sigma^2 | \mathbf{y, x}) = -\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i - \alpha - \beta x_i)^2
\]</span></p>
<p>分別對 <span class="math inline">\(\alpha, \beta\)</span> 求微分之後可以獲得他們各自的 <span class="math inline">\(\text{MLE}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
U(\alpha) &amp; = \ell^\prime(\alpha) = \frac{1}{\sigma^2}\sum_{i=1}^n (y_i - \alpha - \beta x_i) \\
U(\beta)  &amp; = \ell^{\prime}(\beta) = \frac{1}{\sigma^2}\sum_{i=1}^n x_i(y_i - \alpha - \beta x_i) \\
U(\hat\alpha) &amp; = 0 \Rightarrow \hat\alpha = \bar{y} - \hat\beta\bar{x} \\
U(\hat\beta)  &amp; = 0 \Rightarrow \hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2} = \frac{\sum x_iy_i - n\bar{x}\bar{y}}{\sum x_i^2 - n\bar{x}^2}
\end{aligned}
\]</span></p>
<p>注意到和線性迴歸章節中推導的過程不同 (Section <a href="04-Linear-Regression.html#MLEalphabeta">26.4.1</a>)，當時我們用的是最小二乘法，這裏我們用的是光明正大的極大似然法，同時也證明了最小二乘法獲得的 <span class="math inline">\(\hat\alpha,\hat\beta\)</span> 是他們各自的 <span class="math inline">\(\text{MLE}\)</span>。</p>
<p>另外，殘差方差的 <span class="math inline">\(\text{MLE}\)</span> 也可以用上面的方法推導出來，同樣和之前的方法 (Section <a href="04-Linear-Regression.html#ResidualVar">26.5</a>) 做個對比吧：</p>
<p><span class="math display">\[
\begin{aligned}
U(\sigma^2) &amp; = \ell^\prime(\sigma^2) = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n(y_i - \alpha - \beta x_i)^2 \\
U(\hat\sigma^2) = 0 &amp; \Rightarrow \hat\sigma^2 = \frac{\sum_{i=1}^n(y_i - \hat\alpha - \hat\beta x_i)^2}{n}
\end{aligned}
\]</span></p>
<p>這個殘差方差的 <span class="math inline">\(\text{MLE}\)</span> 其實不是一個無偏估計，它只是一個漸進無偏的估計 (需要除以 <span class="math inline">\(\frac{n-2}{n}\)</span>)，所以，當一個線性迴歸模型中有 <span class="math inline">\(p\)</span> 個參數時：</p>
<p><span class="math display">\[
\hat\sigma^2 = \frac{\sum_{i=1}^n(y_i - \hat\alpha - \hat\beta_1 x_{i1} - \hat\beta_2 x_{i2}\cdots)^2}{n - p}
\]</span></p>
<p>線性迴歸時殘差方差的檢驗統計量服從 <span class="math inline">\(F\)</span> 分佈 (Section <a href="04-Linear-Regression.html#lm-Ftest">28.2.6</a>)。</p>
</div>
</div>
<div id="glm-practical-01" class="section level2">
<h2><span class="header-section-number">43.6</span> GLM-Practical 01</h2>
<div id="建立似然方程" class="section level3">
<h3><span class="header-section-number">43.6.1</span> 建立似然方程</h3>
<p>對下列不同的情形，寫下其</p>
<ol style="list-style-type: decimal">
<li>統計學模型</li>
<li>指明模型中的參數</li>
<li>推導該參數的對數似然方程</li>
</ol>
<div id="在-n-名對象中觀察到-k-個事件" class="section level4">
<h4><span class="header-section-number">43.6.1.1</span> 在 <span class="math inline">\(n\)</span> 名對象中觀察到 <span class="math inline">\(k\)</span> 個事件。</h4>
<ol style="list-style-type: decimal">
<li>統計學模型: <span class="math inline">\(K\)</span> 是隨機變量，指代事件的數量，<span class="math inline">\(K \sim \text{Bin}(n, \pi)\)</span>。每個觀察個體中發生事件的概率相互獨立且相同。</li>
<li>模型參數: <span class="math inline">\(\pi\)</span> 是模型參數，指代事件發生的概率。</li>
<li>對數似然的推導</li>
</ol>
<ul>
<li>概率方程 (probability function):</li>
</ul>
<p><span class="math display">\[
\text{Pr}(K = k) = \binom{n}{k}\pi^k(1-\pi)^{n-k}, k = 0,1,\cdots,n
\]</span></p>
<ul>
<li>似然方程 (likelihood function):</li>
</ul>
<p><span class="math display">\[
L(\pi|k) = \binom{n}{k}\pi^k(1-\pi)^{n-k}, 0&lt;\pi&lt;1
\]</span></p>
<ul>
<li>對數似然方程 (log-likelihood function):</li>
</ul>
<p><span class="math display">\[
\ell(\pi|k) = k\log\pi + (n-k)\log(1-\pi) + \text{terms not involving } \pi, 0&lt;\pi&lt;1
\]</span></p>
</div>
<div id="測量-n-名研究對象的總膽固醇濃度-mmoll已知人羣中總膽固醇的測量值呈正態分布且方差爲-4-mmoll2" class="section level4">
<h4><span class="header-section-number">43.6.1.2</span> 測量 <span class="math inline">\(n\)</span> 名研究對象的總膽固醇濃度 (mmol/l)，已知人羣中總膽固醇的測量值呈正態分布且方差爲 <span class="math inline">\(4\)</span> (mmol/l)<sup>2</sup>。</h4>
<ol style="list-style-type: decimal">
<li>統計學模型: 用 <span class="math inline">\(Y_i\)</span> 表示每個個體測量獲得的總膽固醇濃度值。它們是獨立同分布的隨機變量 (independent and indentically distributed, i.i.d. random variables): <span class="math inline">\(Y_i \sim N(\mu, 2^2 = 4)\)</span>。</li>
<li>模型參數: 總體均值 <span class="math inline">\(\mu\)</span>。</li>
<li>對數似然的推導:</li>
</ol>
<ul>
<li>概率密度方程 (probability density function):</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
f(y_1, \cdots, y_n) &amp; = f(\mathbf{y}|\mu) = \prod_{i = 1}^n f(y_i | \mu) \\
                    &amp; = \prod_{i=1}^n \frac{1}{\sqrt{2\pi2^2}}e^{-0.5(\frac{y_i-\mu}{2})^2} \\
                    &amp; = [\frac{1}{\sqrt{2\pi2^2}}]^ne^{-0.5\sum_{i=1}^n(\frac{y_i-\mu}{2})^2} \\
                    &amp; -\infty &lt; y_i &lt; + \infty
\end{aligned}
\]</span></p>
<ul>
<li>對數似然方程 (log-likelihood function):</li>
</ul>
<p><span class="math display">\[
\ell(\mu|\mathbf{y}) = -\frac{1}{2\times2^2}\sum_{i=1}^n(y_i - \mu)^2 + \text{terms not involving } \mu, -\infty &lt; \mu &lt; + \infty
\]</span></p>
</div>
</div>
<div id="建立對數似然方程" class="section level3">
<h3><span class="header-section-number">43.6.2</span> 建立對數似然方程</h3>
<p>對下列不同的情形，寫下其</p>
<ol style="list-style-type: decimal">
<li>參數的對數似然方程</li>
<li>推導極大似然估計</li>
<li>計算極大似然估計量</li>
<li>繪制對數似然方程的示意圖</li>
</ol>
<div id="在-10-名研究對象中觀察到-3-個事件" class="section level4">
<h4><span class="header-section-number">43.6.2.1</span> 在 10 名研究對象中觀察到 3 個事件</h4>
<ol style="list-style-type: decimal">
<li>對數似然方程是</li>
</ol>
<p><span class="math display">\[
\ell(\pi) = k\log\pi + (n-k)\log(1-\pi)
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>極大似然估計的推導</li>
</ol>
<p><span class="math display">\[
\ell^\prime(\pi) = 0 \Rightarrow \frac{k}{\pi} - \frac{n-k}{1-\pi} = 0 \\
\Rightarrow \hat\pi = \frac{k}{n}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>極大似然估計量 <span class="math inline">\(\hat\pi = 3/10 = 0.3\)</span></p></li>
<li><p>繪制對數似然方程的示意圖</p></li>
</ol>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb425-1" title="1">pi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.0001</span>)</a>
<a class="sourceLine" id="cb425-2" title="2">likelihood &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="kw">log</span>(pi) <span class="op">+</span><span class="st"> </span><span class="dv">7</span><span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>pi)</a>
<a class="sourceLine" id="cb425-3" title="3"><span class="kw">plot</span>(pi, likelihood, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">40</span>, <span class="dv">0</span>), <span class="dt">frame.plot =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb425-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;log-likelihood(\U03C0)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03C0&quot;</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:llr-GLM-exe01"></span>
<img src="bookdown_files/figure-html/llr-GLM-exe01-1.png" alt="Log-likelihood for binomial model." width="90%" />
<p class="caption">
圖 43.1: Log-likelihood for binomial model.
</p>
</div>
</div>
<div id="名研究對象測量的總膽固醇濃度分別是-6.0-6.2-6.8-5.3-5.9-6.1-6.0-7.0-5.9-6.3已知人羣中總膽固醇值服從方差爲-4-mmoll2-的正態分布" class="section level4">
<h4><span class="header-section-number">43.6.2.2</span> 10名研究對象測量的總膽固醇濃度分別是 6.0, 6.2, 6.8, 5.3, 5.9, 6.1, 6.0, 7.0, 5.9, 6.3。已知人羣中總膽固醇值服從方差爲 4 (mmol/l)<sup>2</sup> 的正態分布。</h4>
<ol style="list-style-type: decimal">
<li>對數似然方程是:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\ell(\mu) &amp; = -\frac{1}{2\times2^2}\sum_{i=1}^{10} (Y_i - \mu)^2 \\
          &amp; = -\frac{1}{8}\sum_{i=1}^{10} (Y_i - \bar{y} + \bar{y} - \mu)^2 \\
          &amp; = -\frac{1}{8}\sum_{i=1}^{10} (\bar{y} - \mu)^2 \\
          &amp; = -\frac{10}{8}(\bar{y} - \mu)^2
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>極大似然估計，和極大似然估計量是:</li>
</ol>
<p><span class="math display">\[
\ell^\prime(\mu) = 0 \Rightarrow \hat\mu = \bar{y} = 6.15
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>繪制對數似然方程的示意圖</li>
</ol>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb426-1" title="1">mu &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">5</span>,<span class="dv">7</span>, <span class="dt">by =</span> <span class="fl">0.0001</span>)</a>
<a class="sourceLine" id="cb426-2" title="2">likelihood &lt;-<span class="st"> </span><span class="op">-</span>(<span class="dv">5</span><span class="op">/</span><span class="dv">4</span>)<span class="op">*</span>(<span class="fl">6.16</span><span class="op">-</span>mu)<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb426-3" title="3"><span class="kw">plot</span>(mu, likelihood, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">1.8</span>, <span class="dv">0</span>), <span class="dt">frame.plot =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb426-4" title="4">     <span class="dt">ylab =</span> <span class="st">&quot;log-likelihood(\U03BC)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;\U03BC&quot;</span> )</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:llr-GLM-exe02"></span>
<img src="bookdown_files/figure-html/llr-GLM-exe02-1.png" alt="Log-likelihood for normal model" width="90%" />
<p class="caption">
圖 43.2: Log-likelihood for normal model
</p>
</div>
</div>
</div>
<div id="線性回歸模型" class="section level3">
<h3><span class="header-section-number">43.6.3</span> 線性回歸模型</h3>
<p>某項RCT臨牀實驗的目的是比較注射嗎啡和安慰劑哪個對患者的精神醫學指徵的改變更加有效。每個實驗組隨機分配到24名患者，精神醫學指徵使用某種心理調查問卷，問卷有七道題，患者七道題的總得分被用於評價其精神醫學指徵，的分越高，指徵越明顯。下表是這兩組患者在注射相應藥物兩小時之後答題的的分:</p>
<div class="figure" style="text-align: center"><span id="fig:GLMexer1-3"></span>
<img src="img/Selection_122.png" alt="Mental activity scores recorded 2 hours after injection of the drug." width="90%" />
<p class="caption">
圖 43.3: Mental activity scores recorded 2 hours after injection of the drug.
</p>
</div>
<p>下面是 STATA 的計算結果，</p>
<p><img src="img/Selection_123.png" width="90%" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>寫下該模型的數學表達式，陳述該模型中用到的所有假設和前提條件。用手頭的計算器手動計算該簡單線性回歸模型的截距和斜率，確定你的結果和STATA的結果是一樣的。</li>
</ol>
<p><span class="math inline">\(Y_i\)</span> 用來表示第 <span class="math inline">\(i\)</span> 名對象的精神醫學指徵問卷的得分。該模型可以寫作:</p>
<p><span class="math inline">\(Y_1, Y_2, \cdots, Y_{48}\)</span> 是 48 個獨立同分布的隨機變量，且 <span class="math inline">\(Y_i \sim N(\mu, \sigma^2)\)</span>
<span class="math display">\[
y_i = \alpha + \beta x_i \text{ for } x_i = \left\{ \begin{array}{ll}  0 \text{ placebo}\\  1 \text{ morphine}\\ \end{array} \right.
\]</span></p>
<p>從表格數據中可得 <span class="math inline">\(\bar{x} = 0.5, \sum x_i^2 = 24, \bar{y}=4.604, \sum x_iy_i=88\)</span>，利用之前 <a href="09-GLM.html#score-equations">43.5.3</a> 復習的簡單線性回歸公式:</p>
<p><span class="math display">\[
\hat\alpha = 5.542 \\
\hat\beta = -1.875
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>解釋截距和斜率的實際意義:</li>
</ol>
<ul>
<li><span class="math inline">\(\hat\alpha\)</span> 是安慰劑組的平均精神醫學指徵得分;</li>
<li><span class="math inline">\(\hat\beta\)</span> 是注射嗎啡組和安慰劑組兩組之間得分均值之差。</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>實驗研究同時還測量了兩組在注射藥物之前的精神醫學指徵得分，下面是在 STATA 裏對該數據進行擬合的另一個模型。其中 <code>prement</code> 是藥物注射前得分的變量:</li>
</ol>
<p><img src="img/Selection_124.png" width="90%" style="display: block; margin: auto;" /></p>
<ol start="4" style="list-style-type: decimal">
<li>寫下這個模型的數學表達式，並且解釋你會用怎樣的方法求各個參數的 MLE。</li>
</ol>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \beta_2 z_i + \beta_{12}x_iz_i \\
 \text{ for } x_i = \left\{ \begin{array}{ll}  0 \text{ placebo}\\  1 \text{ morphine}\\ \end{array} \right.
\]</span></p>
<p>該模型的對數似然方程是</p>
<p><span class="math display">\[
\ell(\beta_0, \beta_1, \beta_2, \beta_{12} | \mathbf{y, z, x}) = -\frac{1}{2\sigma^2}\sum_{i=1}^{48}(y_i - \beta_0 - \beta_1x_i - \beta_2z_i - \beta_{12}x_iz_i)^2
\]</span></p>
<p>把上面的對數似然方程等於零以後依次對 <span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_{12}\)</span> 求偏微分即可求得各自的 MLE。</p>
<ol start="5" style="list-style-type: decimal">
<li>解釋各參數估計的實際意義</li>
</ol>
<ul>
<li><span class="math inline">\(\hat\beta_0 =\)</span> <code>_cons</code> <span class="math inline">\(=1.978\)</span> 是<strong>當且僅當治療前得分爲零時</strong>，模型對安慰劑組得分均值的估計;</li>
<li><span class="math inline">\(\hat\beta_1 =\)</span> <code>2.treat</code> <span class="math inline">\(=-1.212\)</span> 是<strong>當且僅當治療前得分爲零時</strong>，嗎啡組和安慰劑組之間得分均值之差;</li>
<li><span class="math inline">\(\hat\beta_2 =\)</span> <code>prement</code> <span class="math inline">\(=0.594\)</span> 是<strong>對照組中，治療前得分每增加一個單位</strong>，治療後得分的變化;</li>
<li><span class="math inline">\(\hat\beta_{12} =\)</span> <code>2.treat#c.prement</code> <span class="math inline">\(=-0.0895\)</span> 是嗎啡組和安慰劑組兩組之間回歸斜率之差，也就是說
<span class="math display">\[\hat\beta_2 + \hat\beta_{12} = 0.505\]</span>
是<strong>嗎啡組中，治療錢得分沒增加一個單位</strong>，治療後得分的變化。</li>
</ul>
</div>
<div id="似然比檢驗wald-檢驗score-檢驗" class="section level3">
<h3><span class="header-section-number">43.6.4</span> 似然比檢驗，Wald 檢驗，Score 檢驗</h3>
<p>從服從正態分布 <span class="math inline">\(N(\mu, 1)\)</span> 的總體中抽樣 <span class="math inline">\(n\)</span> 個樣本，他們相互獨立同分布 (i.i.d)。推導用這個模型時的三種檢驗方法的檢驗統計量，證明在此特殊情況下，三種檢驗方法的檢驗統計量完全一致。</p>
<p>該數據的對數似然是</p>
<p><span class="math display">\[
\ell(\mu) = -\frac{1}{2}\sum_{i=1}^n(y_i - \mu)^2
\]</span></p>
<ol style="list-style-type: decimal">
<li>似然比檢驗 likelihood ratio test</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
-2llr &amp; = -2(\ell(\mu_0 - \ell(\hat\mu))) \\
      &amp; = -2(-\frac{1}{2}\sum_{i=1}^n(y_i - \mu_0)^2 + \frac{1}{2}\sum_{i=1}^n(y_i - \bar{y})^2) \\
      &amp; = \sum_{i=1}^n[(y_i - \mu_0)^2 - (y_i - \bar{y})^2] \\
      &amp; = \sum_{i=1}^n(y_i^2 + \mu_0^2 - 2\mu_0y_i - y_i^2 - \bar{y}^2 + 2\bar{y}y_i) \\
      &amp; = n(\mu_0^2 - 2\mu_0\bar{y} + \bar{y}^2) \\
      &amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Wald 檢驗:</li>
</ol>
<p>對數似然的一階導數和二階導數分別是:</p>
<p><span class="math display">\[
\ell^\prime = -\frac{1}{2}\sum_{i=1}^n-2(y_i-\mu) = \sum_{i=1}^n(y_i - \mu) \\
\ell^{\prime\prime} = -n
\]</span></p>
<p>所以，Fisher information <span class="math inline">\(S^2 = n^{-1}\)</span>，<span class="math inline">\(M = \hat\mu = \bar{y}\)</span>，</p>
<p><span class="math display">\[
\begin{aligned}
W^2 &amp; = (\frac{M - \theta_0}{S})^2 \\
    &amp; = (\frac{(\bar{y} - \mu_0)^2}{n^{-1}}) \\
    &amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Score 檢驗</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\frac{\ell^\prime(\mu_0)^2}{-\ell^{\prime\prime}(\mu_0)} &amp; = \frac{(n\bar{y} - n\mu_0)^2}{n}  \\
&amp; = n(\bar{y} - \mu_0)^2
\end{aligned}
\]</span></p>
<p>所以，在方差已知，均值未知，總體服從正態分布的數據條件下，三種檢驗方法獲得的實際檢驗統計量是完全一致的。</p>
</div>
</div>
</div>
<div id="廣義線性迴歸入門" class="section level1">
<h1><span class="header-section-number">第 44 章</span> 廣義線性迴歸入門</h1>
<p>線性迴歸方法是十分強大的建模工具，可惜的是它只能適用與因變量爲連續型變量的情況。廣義線性迴歸模型 (或者叫一般化線性迴歸模型 generalised linear models, GLM) 是一大類將線性迴歸模型拓展到因變量可以使用二分類，計數，分組型變量的建模工具。</p>
<div id="指數分佈家族" class="section level2">
<h2><span class="header-section-number">44.1</span> 指數分佈家族</h2>
<p>一個服從正態分佈的隨機變量 <span class="math inline">\(Y\)</span> 的概率密度方程 (probability density function, PDF) 可以寫作</p>
<p><span class="math display">\[
f(y) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(y-\mu)^2}{2\sigma^2}}
\]</span></p>
<p>給 PDF 的左右兩邊同時取自然底數的對數，方程變形爲</p>
<p><span class="math display" id="eq:glm2-0">\[
\begin{aligned}
\text{ln}\{f(y)\} &amp; = -\frac{y^2}{2\sigma^2} + \frac{y\cdot\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2} -\frac{1}{2}\text{ln}(2\pi\sigma^2) \\
                &amp; = \frac{y\cdot\mu - \frac{\mu^2}{2}}{\sigma^2} - [\frac{y^2}{2\sigma^2} + \frac{1}{2}\text{ln}(2\pi\sigma^2) ]
\end{aligned}
\tag{44.1}
\]</span></p>
<p>如果令</p>
<p><span class="math display">\[
\begin{aligned}
\theta &amp; = \mu  \\
\psi   &amp; = \sigma^2 \\
b(\theta) &amp; = \frac{\mu^2}{2} \\
c(y, \theta) &amp; = \frac{y^2}{2\sigma^2} + \frac{1}{2}\text{ln}(2\pi\sigma^2)
\end{aligned}
\]</span></p>
<p>那麼上面的式子 <a href="09-GLM.html#eq:glm2-0">(44.1)</a> 可以被整理爲：</p>
<p><span class="math display" id="eq:glm2-1">\[
\begin{equation}
\text{ln}\{f(y)\} = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta)
\end{equation}
\tag{44.2}
\]</span></p>
<p><strong>此處有重要結論：</strong> 凡是分佈的概率密度方程的對數方程能夠轉換整理成 <a href="09-GLM.html#eq:glm2-1">(44.2)</a> 形式的分佈，都隸屬於指數分佈家族 (the Exponential Family of distributions)。</p>
<div id="泊松分佈和二項分佈的指數分佈家族屬性" class="section level3">
<h3><span class="header-section-number">44.1.1</span> 泊松分佈和二項分佈的指數分佈家族屬性</h3>
<ul>
<li>泊松分佈 Poisson Distribution</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
     f(y) &amp; = \text{Pr}(Y = y) = \frac{\mu^y e^{-\mu}}{y!}, y = 0,1,2,\cdots \\
\text{ln}\{ f(y) \} &amp; = y\cdot\text{ln}(\mu) - \mu - \text{ln}(y!) \\
\text{Let } &amp;\color{red}{\boxed{\theta = \text{ln}(\mu), \psi = 1, b(\theta) = \mu, c(y,\psi) = \text{ln}(y!)}} \\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta) \\
\end{aligned}
\]</span></p>
<p>所以，<strong>泊松分佈屬於指數分佈家族成員</strong>。</p>
<ul>
<li>二項分佈 Binommial Distribution</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
f(y) &amp; = \text{Pr}(Y = y) = \binom{n}{y}\pi^y(1-\pi)^{n-y}, y = 0,1,2,\cdots\\
\text{ln}\{ f(y) \} &amp; = y\cdot \text{ln}(\pi) + (n - y)\text{ln}(1-\pi) + \text{ln}\{\binom{n}{y}\} \\
                    &amp; = y\cdot \text{ln}(\frac{\pi}{1-\pi}) + n\text{ln}(1-\pi) +  \text{ln}\{\binom{n}{y}\} \\
\text{Let } &amp;\color{red}{\boxed{\theta = \text{ln}(\frac{\pi}{1-\pi}), \psi = 1,}} \\
            &amp;\color{red}{\boxed{b(\theta) = -n\text{ln}(1-\pi), c(y, \psi) = -\text{ln}\{\binom{n}{y}\}}}\\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\psi} - c(y, \theta) \\
\end{aligned}
\]</span></p>
<p>所以，<strong>二項分佈也屬於指數分佈家族成員</strong>。</p>
<p>指數分佈家族成員的數學表達式 <a href="09-GLM.html#eq:glm2-1">(44.2)</a> 中，</p>
<ul>
<li><span class="math inline">\(\theta\)</span> 被叫做標準 (或者叫自然) 參數 (<strong>canonical or natural parameter</strong>)，相關的函數被叫做標準鏈接函數 (canonical link function)，如上面所列舉的例子中：泊松分佈時用的對數函數 <span class="math inline">\(\text{ln}(\mu)\)</span>，二項分佈時用的邏輯函數 (logit function) <span class="math inline">\(\text{ln}(\frac{\pi}{1-\pi})\)</span>，鏈接函數可能還有別的選擇，(例如，二項分佈數據的另一種標準鏈接函數是概率函数 (probit function <span class="math inline">\(\Phi^{-1}(P)\)</span>))，同時它對於條件推斷 conditional inference 至關重要，因爲它還提示我們應該用什麼樣的算法去估計我們苦苦尋找的人羣參數。</li>
<li><span class="math inline">\(\phi\)</span> 被命名爲<strong>尺度參數 (scale or dispersion parameter)</strong>，泊松分佈和二項分佈的尺度參數是 <span class="math inline">\(1\)</span>。但是正態分佈的尺度參數是方差 <span class="math inline">\(\sigma^2\)</span>，且常常是未知的，需要從樣本數據中估計。尺度參數是否需要從樣本中獲取其估計值，對於實際統計推斷或者假設檢驗的過程有重大影響。</li>
</ul>
<p>廣義線性迴歸就是這個指數分佈家族數據共通的一種統計建模過程，所以，在這一“屋檐”下，它衍生出衆多種類的統計模型。</p>
<hr />
</div>
<div id="exercise.-exponential-distribution" class="section level3">
<h3><span class="header-section-number">44.1.2</span> Exercise. Exponential distribution</h3>
<p>證明指數分佈本身也屬於指數分佈家族，定義其標準鏈接函數和標準參數。</p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\begin{aligned}
Y \sim \text{exp}(\lambda) &amp; \rightarrow f(y) = \lambda \text{exp}(-y\lambda), y &gt; 0\\
\Rightarrow \text{ln}\{ f(y) \} &amp; = - y \lambda + \text{ln}(\lambda) \\
\text{Let } &amp; \color{red}{\theta = -\lambda, b(\theta) = - \text{ln}(\lambda), \phi = 1, c(y, \phi) = 0} \\
\Rightarrow \text{ln}\{f(y)\} &amp; = \frac{y\cdot\theta - b(\theta)}{\phi} - c(y, \theta) \\
\text{Because } E(Y) &amp; = \frac{1}{\lambda}, \text{ the canonical link is } g(\lambda) = -\frac{1}{\lambda}\\
\end{aligned}
\]</span></p>
<hr />
</div>
</div>
<div id="defineaGLM" class="section level2">
<h2><span class="header-section-number">44.2</span> 廣義線性迴歸模型之定義</h2>
<p>一個四肢健全的廣義線性模型包括三個部分：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈 (或者叫響應變量分佈，response distribution)：<span class="math inline">\(Y_i, i = 1,\cdots,n\)</span> 可以被認爲是互相獨立且服從指數家族分佈，設其期望值 (均值) <span class="math inline">\(E(Y_i) = \mu_i\)</span>；</li>
<li>線性預測方程 (linear predictor)：<strong>預測變量及其各自的參數以線性迴歸形式進入模型</strong>，其中第 <span class="math inline">\(i\)</span> 個觀測值的線性預測值爲：<br> <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接函數 (link function)：鏈接函數連接的是線性預測方程 <span class="math inline">\(\eta_i\)</span> 和其期待值 (均值) 之間 <span class="math inline">\(\mu_i\)</span> 的關係。<br> <span class="math display">\[g(\mu_i) = \eta_i\]</span></li>
</ol>
<p>簡單線性迴歸模型本身當然也數據廣義線性迴歸模型：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈是正態分佈；</li>
<li>線性預測值也是線性迴歸形式；</li>
<li>鏈接函數是它因變量本身 (the <strong>identity</strong> function)。</li>
</ol>
</div>
<div id="注意" class="section level2">
<h2><span class="header-section-number">44.3</span> 注意</h2>
<ol style="list-style-type: decimal">
<li>廣義線性迴歸的線性預測方程部分的意義，需要澄清的是它指的是 <strong>參數 parameter</strong> 之間呈線性關係，預測變量本身可以有二次方，三次方，多次方，因爲這些多項式線性迴歸本身仍然是<strong>線性的</strong>如： <span class="math display">\[\eta_i = \alpha + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_p x_i^p\]</span> <br> 然而，這樣的形式 <span class="math display">\[\eta_i = \alpha (1- e^{\beta_1 x_{i1}})\]</span> <br> 就不能說是一個線性預測方程。</li>
<li>除了有很少的特例。廣義線性迴歸擬合後的參數估計，推斷，模型評價和比較時使用的原理都一樣，不同的只有各自的分佈和鏈接函數。</li>
<li>通常選用的鏈接方程，要能夠使線性預測方程的取值範圍達到所有實數 <span class="math inline">\(-\infty,+\infty\)</span>。</li>
<li>“模型的似然函數 the log likelihood of the model”，只是我們偷懶縮短了原文 “在給定數據的前提下，當所有參數均爲 <span class="math inline">\(\text{MLE}\)</span> 時模型的對數似然函數 (the log likelihood function of the model for the given data evaluated at the MLE’s of the parameters)”，就是對數似然函數的極大值的意思 (i.e. the maximum of the log likelihood function)。</li>
<li>從本節開始往後的章節中 “模型，model”，“廣義線性模型，generalized linear model”，和 “GLM” 將被視爲同義詞。</li>
</ol>
</div>
<div id="如何在-r-裏擬合-glm" class="section level2">
<h2><span class="header-section-number">44.4</span> 如何在 R 裏擬合 “GLM”</h2>
<p>這裏討論用極大似然法擬合 “GLM” 模型的方法。前面一章節的複習也是在告訴我們，利用極大似然法簡單說就是找到模型參數，使得似然函數能夠取到極大值。對於線性迴歸來說， <span class="math inline">\(\text{MLE}\)</span> 可以用一個封閉式函數來計算；但是廣義線性迴歸模型則必須使用<a href="https://www.youtube.com/watch?v=JZIeX3eVyf4">迭代法計算 (iterative methods)</a>。</p>
<p>在 R 裏面擬合廣義線性模型的命令及其格式是：</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb427-1" title="1"><span class="kw">glm</span>(response variable <span class="op">~</span><span class="st"> </span>explanatory variables to form linear predictor, <span class="dt">family=</span>name of <span class="kw">distribution</span>(<span class="dt">link=</span>link <span class="cf">function</span>), <span class="dt">data=</span>dataset)</a></code></pre></div>
<p>Tips: See <code>help(glm)</code> for other modeling options. See <code>help(family)</code> for other allowable link functions for each family.</p>
<p>下面的數據來自一個心理學臨牀實驗，比較的是和安慰劑組相比，注射嗎啡組，注射海洛因組對象的精神病檢測指數的前後變化。</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb428-1" title="1">Mental &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/MENTAL.DAT&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;treatment&quot;</span>, <span class="st">&quot;Before&quot;</span>, <span class="st">&quot;After&quot;</span>))</a>
<a class="sourceLine" id="cb428-2" title="2">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;placebo&quot;</span></a>
<a class="sourceLine" id="cb428-3" title="3">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>] &lt;-<span class="st"> &quot;morphine&quot;</span></a>
<a class="sourceLine" id="cb428-4" title="4">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>] &lt;-<span class="st"> &quot;heroin&quot;</span></a>
<a class="sourceLine" id="cb428-5" title="5">Mental<span class="op">$</span>treatment &lt;-<span class="st"> </span><span class="kw">factor</span>(Mental<span class="op">$</span>treatment, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;morphine&quot;</span>, <span class="st">&quot;heroin&quot;</span>))</a>
<a class="sourceLine" id="cb428-6" title="6"><span class="kw">head</span>(Mental)</a></code></pre></div>
<pre><code>##   treatment Before After
## 1   placebo      0     7
## 2   placebo      2     1
## 3   placebo     14    10
## 4   placebo      5    10
## 5   placebo      5     6
## 6   placebo      4     2</code></pre>
<p>我們來比較一下簡單線性迴歸的代碼輸出結果和廣義線性迴歸代碼輸出結果是否一致：</p>
<p>用 <code>lm</code> 命令，擬合因變量爲注射後精神病檢測指數，預測變量爲治療方式和注射錢精神病檢測指數，及兩者的交互作用項：</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb430-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(After <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>Before, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb430-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = After ~ treatment * Before, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.82808 -1.93513 -0.51606  1.41607 11.36012 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)               1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine        -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin          -1.461968   1.771855 -0.8251 0.412284   
## Before                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:Before -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:Before   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3329 on 66 degrees of freedom
## Multiple R-squared:  0.34418,    Adjusted R-squared:  0.29449 
## F-statistic: 6.9274 on 5 and 66 DF,  p-value: 0.000029744</code></pre>
<p>同樣的模型也可以用 <code>glm</code> 命令擬合：</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb432-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(After <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>Before, <span class="dt">family =</span> <span class="kw">gaussian</span>(<span class="dt">link =</span> <span class="st">&quot;identity&quot;</span>), <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb432-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = After ~ treatment * Before, family = gaussian(link = &quot;identity&quot;), 
##     data = Mental)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -7.82808  -1.93513  -0.51606   1.41607  11.36012  
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)               1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine        -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin          -1.461968   1.771855 -0.8251 0.412284   
## Before                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:Before -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:Before   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 11.107994)
## 
##     Null deviance: 1117.875  on 71  degrees of freedom
## Residual deviance:  733.128  on 66  degrees of freedom
## AIC: 385.414
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>可以看到，<code>glm</code> 命令的輸出結果略多，但是參數估計的部分是完全相同的。<strong>但是如果你用的是坑爹的 STATA，那裏面的 <code>glm</code> 命令中的統計檢驗量和 <span class="math inline">\(p\)</span> 值用的則是正態分佈近似法。所以在 STATA 裏面簡單線性迴歸模型最好不要使用 <code>glm</code> 命令：</strong></p>
<pre><code> glm After i.treatt##c.Before, family(gaussian) link(identity)

Iteration 0:   log likelihood = -185.70711

Generalized linear models                         No. of obs      =         72
Optimization     : ML                             Residual df     =         66
                                                  Scale parameter =   11.10799
Deviance         =  733.1276068                   (1/df) Deviance =   11.10799
Pearson          =  733.1276068                   (1/df) Pearson  =   11.10799

Variance function: V(u) = 1                       [Gaussian]
Link function    : g(u) = u                       [Identity]

                                                  AIC             =   5.325197
Log likelihood   =  -185.707106                   BIC             =   450.8676

------------------------------------------------------------------------------
             |                 OIM
        After|      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       treat |
          2  |  -1.211742   1.750342    -0.69   0.489    -4.642349    2.218865
          3  |  -1.461968   1.771855    -0.83   0.409    -4.934741    2.010805
             |
      Before |   .5939394   .1834682     3.24   0.001     .2343483    .9535305
             |
 treat#Before|
          2  |  -.0895258   .2483459    -0.36   0.718    -.5762749    .3972233
          3  |  -.3129855   .2503829    -1.25   0.211     -.803727    .1777561
             |
       _cons |    1.97803   1.294069     1.53   0.126    -.5582981    4.514359
------------------------------------------------------------------------------</code></pre>
<p>回到 R 來， 當儲存了一個 <code>Model2</code> 向量在 R 裏之後，你可以用下面的各種命令獲取你想要的各種有用的信息。</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb435-1" title="1"><span class="kw">confint</span>(Model2) <span class="co"># 95% CI for the coefficients</span></a></code></pre></div>
<pre><code>##                                2.5 %     97.5 %
## (Intercept)              -0.55829809 4.51435869
## treatmentmorphine        -4.64234925 2.21886536
## treatmentheroin          -4.93474055 2.01080452
## Before                    0.23434829 0.95353050
## treatmentmorphine:Before -0.57627487 0.39722332
## treatmentheroin:Before   -0.80372697 0.17775605</code></pre>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb437-1" title="1"><span class="kw">exp</span>(<span class="kw">coef</span>(Model2)) <span class="co"># exponentiated coefficients</span></a></code></pre></div>
<pre><code>##              (Intercept)        treatmentmorphine          treatmentheroin                   Before 
##               7.22849102               0.29767829               0.23177968               1.81110905 
## treatmentmorphine:Before   treatmentheroin:Before 
##               0.91436470               0.73126055</code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb439-1" title="1"><span class="kw">exp</span>(<span class="kw">confint</span>(Model2)) <span class="co"># 95% CI for exponentiated coefficients</span></a></code></pre></div>
<pre><code>##                                 2.5 %     97.5 %
## (Intercept)              0.5721820406 91.3189836
## treatmentmorphine        0.0096350359  9.1968898
## treatmentheroin          0.0071923267  7.4693242
## Before                   1.2640846824  2.5948546
## treatmentmorphine:Before 0.5619879499  1.4876881
## treatmentheroin:Before   0.4476574460  1.1945339</code></pre>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb441-1" title="1"><span class="kw">head</span>(<span class="kw">predict</span>(Model2, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)) <span class="co"># predicted values</span></a></code></pre></div>
<pre><code>##          1          2          3          4          5          6 
##  1.9780303  3.1659091 10.2931818  4.9477273  4.9477273  4.3537879</code></pre>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb443-1" title="1"><span class="kw">head</span>(<span class="kw">residuals</span>(Model2, <span class="dt">type=</span><span class="st">&quot;deviance&quot;</span>)) <span class="co"># residuals</span></a></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  5.02196970 -2.16590909 -0.29318182  5.05227273  1.05227273 -2.35378788</code></pre>
<div id="margins-命令" class="section level3">
<h3><span class="header-section-number">44.4.1</span> <code>margins</code> 命令</h3>
<p>一個在 STATA 裏面十分有用的用於<strong>預測</strong>的命令 <code>margins</code>，在 R 裏，下載了 <code>margins</code> 包以後就可以調用和 STATA 的 <code>margins</code> 類似的命令。</p>
<p>假如我們用擬合的模型預測當注射前精神病檢測值分別是 0，6，12 分時三組之間的注射後精神病檢測值差，可以這樣求：</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb445-1" title="1"><span class="kw">summary</span>(<span class="kw">margins</span>(Model2, <span class="dt">at =</span> <span class="kw">list</span>(<span class="dt">Before=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">6</span>,<span class="dv">12</span>))))</a></code></pre></div>
<pre><code>##             factor  Before     AME     SE       z      p   lower   upper
##             Before  0.0000  0.4598 0.1004  4.5797 0.0000  0.2630  0.6565
##             Before  6.0000  0.4598 0.1004  4.5797 0.0000  0.2630  0.6565
##             Before 12.0000  0.4598 0.1004  4.5798 0.0000  0.2630  0.6565
##    treatmentheroin  0.0000 -1.4620 1.7719 -0.8251 0.4093 -4.9347  2.0108
##    treatmentheroin  6.0000 -3.3399 0.9624 -3.4705 0.0005 -5.2261 -1.4537
##    treatmentheroin 12.0000 -5.2178 1.7963 -2.9048 0.0037 -8.7384 -1.6972
##  treatmentmorphine  0.0000 -1.2117 1.7503 -0.6923 0.4888 -4.6423  2.2189
##  treatmentmorphine  6.0000 -1.7489 0.9630 -1.8160 0.0694 -3.6364  0.1386
##  treatmentmorphine 12.0000 -2.2861 1.7977 -1.2716 0.2035 -5.8095  1.2374</code></pre>
<p>對比 STATA 裏的結果：</p>
<pre><code> margins, dydx(trt) at(pre = (0 6 12))

Conditional marginal effects                    Number of obs     =         72
Model VCE    : OIM

Expression   : Predicted mean post, predict()
dy/dx w.r.t. : 2.trt 3.trt

1._at        : pre             =           0

2._at        : pre             =           6

3._at        : pre             =          12

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
1.trt        |  (base outcome)
-------------+----------------------------------------------------------------
2.trt        |
         _at |
          1  |  -1.211742   1.750342    -0.69   0.489    -4.642349    2.218865
          2  |  -1.748897    .963025    -1.82   0.069    -3.636391    .1385977
          3  |  -2.286051   1.797717    -1.27   0.204    -5.809513     1.23741
-------------+----------------------------------------------------------------
3.trt        |
         _at |
          1  |  -1.461968   1.771855    -0.83   0.409    -4.934741    2.010805
          2  |  -3.339881   .9623512    -3.47   0.001    -5.226054   -1.453707
          3  |  -5.217794   1.796264    -2.90   0.004    -8.738406   -1.697181
------------------------------------------------------------------------------
Note: dy/dx for factor levels is the discrete change from the base level.</code></pre>
</div>
<div id="ggplot2geom_smoothmethod-loess-命令" class="section level3">
<h3><span class="header-section-number">44.4.2</span> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</h3>
<p>類似 STATA 作散點圖時的 <code>lowess</code> 命令，在 R 裏，你可以用 <code>ggplot2</code> 包裏自帶的 <code>geom_smooth(method = "loess")</code> 選項命令，給散點圖添加平滑曲線。把觀測數據中變量之間的關係視覺化，用於輔助判斷一個模型是否可以被擬合爲線性關係。全稱是 “locally weighted scatterplot smoothing”，縮寫成 “lowess/loess”。<a href="https://en.wikipedia.org/wiki/Local_regression">LOWESS 的原理</a>簡略說是，通過把預測變量分成幾個部分，分別在各個小區間內擬合迴歸各自的迴歸曲線，如此便可以將<strong>每個觀測值都以各自不同的加權值放入整個模型</strong>中，然而正如我們在簡單線性模型中提到過的，這樣的曲線更加擬合觀測數據，而不能說明觀測值來自的人羣中，兩個變量之間的關係。此方法的靈活性在於，你可以選擇平滑的程度，該平滑程度用 <code>bandwith</code>(STATA) 或者 <code>span</code>(R) 表示，取值範圍是 <span class="math inline">\(0 \sim 1\)</span> 之間的任意值，越靠近 <span class="math inline">\(1\)</span>，Lowess 曲線越接近簡單線性直線，越靠近 <span class="math inline">\(0\)</span>，那麼每個觀測點本身的權重越大，擬合的 Lowess 曲線越接近觀測數據本身。下圖 <a href="09-GLM.html#fig:loess-smoother1">44.1</a> 提示，選用的平滑程度 <span class="math inline">\(= 0.8\)</span> 時，精神病測量分數在 (安慰劑組中) 實驗前後的關係接近線性關係。當我們降低平滑程度，Lowess 曲線接近觀測數據本身，其實是太接近觀測數據本身，反而無法提供太多的信息。</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb448-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(Before, After)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb448-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb448-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess-smoother1"></span>
<img src="bookdown_files/figure-html/loess-smoother1-1.png" alt="Lowess smoother, with bandwith/span set to 0.8, for the mental data" width="100%" />
<p class="caption">
圖 44.1: Lowess smoother, with bandwith/span set to 0.8, for the mental data
</p>
</div>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb449-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(Before, After)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb449-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.4</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb449-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess-smoother2"></span>
<img src="bookdown_files/figure-html/loess-smoother2-1.png" alt="Lowess smoother, with bandwith/span set to 0.4, for the mental data" width="100%" />
<p class="caption">
圖 44.2: Lowess smoother, with bandwith/span set to 0.4, for the mental data
</p>
</div>
</div>
</div>
<div id="glm-practical-02" class="section level2">
<h2><span class="header-section-number">44.5</span> GLM-Practical 02</h2>
<div id="思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證" class="section level3">
<h3><span class="header-section-number">44.5.1</span> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</h3>
<ol style="list-style-type: decimal">
<li><p>MLE <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(b^\prime(\theta) = y\)</span> 的解;</p></li>
<li><p><span class="math inline">\(\theta\)</span> 的 MLE 的方差是 <span class="math inline">\(\frac{\phi}{b^{\prime\prime}(\theta)}\)</span>;</p></li>
<li><p>如果 <span class="math inline">\(Y\sim N(\mu, \sigma^2)\)</span>，試進一步證明 <span class="math inline">\(b^\prime(\theta) = \mu\)</span> 且 <span class="math inline">\(\frac{\phi}{b^{\prime\prime}(\theta)} = \sigma^2\)</span></p></li>
<li><p>當數據來自指數分布家族，它的對數似然可以寫作:</p></li>
</ol>
<p><span class="math display">\[
\frac{y\cdot\theta - b(\theta)}{\phi} - c(y, \phi)
\]</span></p>
<p>對這個對數似然方程取 <span class="math inline">\(\theta\)</span> 的偏微分方程可得:</p>
<p><span class="math display">\[
\frac{\partial}{\partial\theta}\ell(\theta,\phi) = \frac{y - b^\prime(\theta)}{\phi}
\]</span></p>
<p>令此偏微分方程等於零，那麼我們可以知道 <span class="math inline">\(\hat\theta\)</span> 是 <span class="math inline">\(b^\prime(\theta) = y\)</span> 的解。</p>
<ol start="2" style="list-style-type: decimal">
<li>MLE 的方差可以用 Fisher information 來推導。</li>
</ol>
<p><span class="math display">\[
S^2=\left.-\frac{1}{\ell^{\prime\prime}(\theta)}\right\vert_{\theta=\hat{\theta}} \\
\text{Because } \ell^{\prime\prime}(\theta) = -\frac{b^{\prime\prime}(\theta)}{\phi} \\
\Rightarrow  S^2 = \frac{\phi}{b^{\prime\prime}(\theta)}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>如果 <span class="math inline">\(Y\sim N(\mu, \sigma^2)\)</span>, 那麼，根據正態分布數據屬於指數家族的性質，</li>
</ol>
<p><span class="math display">\[
\phi = \sigma^2,\theta = \mu, b(\theta =\mu) = \frac{\mu^2}{2} \\
\Rightarrow b^\prime(\theta) = \mu \\
\Rightarrow S^2 = \frac{\phi}{b^{\prime\prime}(\theta)} = \sigma^2
\]</span></p>
</div>
<div id="r-練習" class="section level3">
<h3><span class="header-section-number">44.5.2</span> R 練習</h3>
<p>數據來自一個RCT臨牀試驗，比較嗎啡，海洛因和安慰劑在患者精神狀態評分上的影響，試分析數據回答下面的問題:</p>
<ol style="list-style-type: decimal">
<li>三組治療組之間注射後的評分均值不同嗎？</li>
<li>調整基線時精神狀態評分對你的模型結果有什麼影響？</li>
<li>基線時精神狀態評分的高低會影響不同藥物的效果嗎？</li>
</ol>
<div id="數據讀入-r作初步分析" class="section level4">
<h4><span class="header-section-number">44.5.2.1</span> 數據讀入 R，作初步分析</h4>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb450-1" title="1">Mental &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/MENTAL.DAT&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;treatment&quot;</span>, <span class="st">&quot;prement&quot;</span>, <span class="st">&quot;mentact&quot;</span>))</a>
<a class="sourceLine" id="cb450-2" title="2">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> &quot;placebo&quot;</span></a>
<a class="sourceLine" id="cb450-3" title="3">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">2</span>] &lt;-<span class="st"> &quot;morphine&quot;</span></a>
<a class="sourceLine" id="cb450-4" title="4">Mental<span class="op">$</span>treatment[Mental<span class="op">$</span>treatment <span class="op">==</span><span class="st"> </span><span class="dv">3</span>] &lt;-<span class="st"> &quot;heroin&quot;</span></a>
<a class="sourceLine" id="cb450-5" title="5">Mental<span class="op">$</span>treatment &lt;-<span class="st"> </span><span class="kw">factor</span>(Mental<span class="op">$</span>treatment, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;morphine&quot;</span>, <span class="st">&quot;heroin&quot;</span>))</a>
<a class="sourceLine" id="cb450-6" title="6"><span class="kw">head</span>(Mental)</a></code></pre></div>
<pre><code>##   treatment prement mentact
## 1   placebo       0       7
## 2   placebo       2       1
## 3   placebo      14      10
## 4   placebo       5      10
## 5   placebo       5       6
## 6   placebo       4       2</code></pre>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb452-1" title="1"><span class="co"># Use hsitograms and plots to look at the distributions of the pre- and post- injection scores.</span></a>
<a class="sourceLine" id="cb452-2" title="2"><span class="co"># with(Mental, hist(prement, breaks = 14, freq = F))</span></a>
<a class="sourceLine" id="cb452-3" title="3"><span class="co"># qplot(prement, data = Mental, binwidth = 1)</span></a>
<a class="sourceLine" id="cb452-4" title="4">hist1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> prement, <span class="dt">y =</span> ..density..)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-5" title="5">hist2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> mentact, <span class="dt">y =</span> ..density..)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-6" title="6">Scatter &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(<span class="dt">x =</span> prement, <span class="dt">y =</span> mentact)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()<span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb452-7" title="7"><span class="kw">grid.arrange</span>(hist1, hist2, Scatter, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pre-score"></span>
<img src="bookdown_files/figure-html/pre-score-1.png" alt="Histogram and plots " width="90%" />
<p class="caption">
圖 44.3: Histogram and plots
</p>
</div>
<p>可以看到柱狀圖暗示我們實驗前後的得分本身都不服從正態分布。但是這並不妨礙我們使用回歸模型來做推斷。畢竟，<strong>線性回歸模型只要求殘差服從正態分布</strong>。另外，散點圖提示實驗前後的得分之間可能呈正相關。</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb453-1" title="1"><span class="kw">ggplot</span>(Mental, <span class="kw">aes</span>(prement, mentact)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb453-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>,  <span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb453-3" title="3"><span class="st">  </span><span class="kw">facet_grid</span>(treatment <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loess1"></span>
<img src="bookdown_files/figure-html/loess1-1.png" alt="Lowess smoother, with bandwith/span set to 0.8, for the mental data" width="100%" />
<p class="caption">
圖 44.4: Lowess smoother, with bandwith/span set to 0.8, for the mental data
</p>
</div>
<p>對於每組實驗組來說，觀測值數量都很少，姑且可以認爲線性模型是合理的。</p>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exer-tab1">表 44.1: </span>Residual sums of squares and degress of freedom from five different models for post-injection mental activity scores (pre-inj = preinjection score)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Terms fitted
</th>
<th style="text-align:left;">
RSS
</th>
<th style="text-align:left;">
Residuals df
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: decimal">
<li>Overall mean
</td>
<td style="text-align:left;">
1117.875
</td>
<td style="text-align:left;">
71
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: decimal">
<li>Drugs
</td>
<td style="text-align:left;">
980.625
</td>
<td style="text-align:left;">
69
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="3" style="list-style-type: decimal">
<li>Pre-inj
</td>
<td style="text-align:left;">
884.328
</td>
<td style="text-align:left;">
70
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="4" style="list-style-type: decimal">
<li>Drugs + Pre-inj
</td>
<td style="text-align:left;">
752.055
</td>
<td style="text-align:left;">
68
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="5" style="list-style-type: decimal">
<li>Drugs + Pre-inj + Drugs×Pre-inj
</td>
<td style="text-align:left;">
733.127
</td>
<td style="text-align:left;">
66
</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol></li>
</ol></li>
</ol></li>
</ol>
</div>
<div id="寫下表格-reftabglm-exer-tab1-中五個線性回歸模型的數學表達式在-r-裏面擬合這5個模型在第二列第三列分別填寫各模型的統計信息-殘差平方和-residuals-sum-of-squares和-殘差自由度-reiduals-degrees-of-freedom利用該表格填寫完整以後的內容用筆和紙正式地比較模型-3-和-4-4-和-5-的擬合優度然後和-r-的輸出結果比較確認你會作出怎樣的結論另外爲什麼相似的比較模型的方法不適用於比較模型-2-和-3" class="section level4">
<h4><span class="header-section-number">44.5.2.2</span> 寫下表格 <a href="09-GLM.html#tab:GLM-exer-tab1">44.1</a> 中五個線性回歸模型的數學表達式，在 R 裏面擬合這5個模型，在第二列第三列分別填寫各模型的統計信息 (殘差平方和 residuals sum of squares，和 殘差自由度 reiduals degrees of freedom)。利用該表格填寫完整以後的內容，用筆和紙正式地比較模型 3 和 4; 4 和 5 的擬合優度。然後和 R 的輸出結果比較確認。你會作出怎樣的結論？另外，爲什麼相似的比較模型的方法不適用於比較模型 2 和 3？</h4>
<p><strong>解</strong></p>
<p>用 <span class="math inline">\(z_i, y_i\)</span> 分別標記第 <span class="math inline">\(i\)</span> 名患者在藥物注射前，後兩次測量的精神醫學指徵評分。使用線性回歸模型的前提假設是 <span class="math inline">\(y_i \sim N(\mu_i, \sigma^2)\)</span> 且互相獨立。另外，預測變量的標記爲:</p>
<p><span class="math display">\[
x_{1i} = \left\{ \begin{array}{ll}  0 \text{ placebo or heroin }\\  1 \text{ morphine}\\ \end{array} \right.
x_{2i} = \left\{ \begin{array}{ll}  0 \text{ placebo or morphine }\\  1 \text{ heroin}\\ \end{array} \right. \\
\]</span></p>
<ol style="list-style-type: decimal">
<li>Overall mean model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0\)</span></p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb454-1" title="1"><span class="co">#1.  Overall mean model</span></a>
<a class="sourceLine" id="cb454-2" title="2">Overall &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb454-3" title="3"><span class="kw">summary</span>(Overall)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ 1, data = Mental)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7917 -3.7917 -1.7917  2.4583 10.2083 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  3.79167    0.46763  8.1083 1.053e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.968 on 71 degrees of freedom</code></pre>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb456-1" title="1"><span class="kw">anova</span>(Overall)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 71 1117.88 15.7447</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Drugs model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}\)</span></p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb458-1" title="1"><span class="co">#2.  Drugs model</span></a>
<a class="sourceLine" id="cb458-2" title="2">Drugs &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb458-3" title="3"><span class="kw">summary</span>(Drugs)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment, data = Mental)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.5417 -2.1667 -1.1667  1.9583 10.8333 
## 
## Coefficients:
##                   Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)        5.54167    0.76952  7.2014 5.732e-10 ***
## treatmentmorphine -1.87500    1.08827 -1.7229  0.089382 .  
## treatmentheroin   -3.37500    1.08827 -3.1013  0.002791 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.7699 on 69 degrees of freedom
## Multiple R-squared:  0.12278,    Adjusted R-squared:  0.097351 
## F-statistic: 4.8287 on 2 and 69 DF,  p-value: 0.010896</code></pre>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb460-1" title="1"><span class="kw">anova</span>(Drugs)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)  
## treatment  2 137.250  68.625 4.82868 0.010896 *
## Residuals 69 980.625  14.212                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Pre-inj model</li>
</ol>
<p>鏈接方程部分 <span class="math inline">\(\eta_i = \beta_0 + \beta_3 z_i\)</span></p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb462-1" title="1"><span class="co">#3.  Pre-inj model</span></a>
<a class="sourceLine" id="cb462-2" title="2">Pre_inj &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb462-3" title="3"><span class="kw">summary</span>(Pre_inj)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.51879 -2.32837 -0.89028  2.25419 10.06844 
## 
## Coefficients:
##             Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)  1.09667    0.75388  1.4547     0.1502    
## prement      0.45872    0.10669  4.2996 0.00005433 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.5543 on 70 degrees of freedom
## Multiple R-squared:  0.20892,    Adjusted R-squared:  0.19762 
## F-statistic: 18.487 on 1 and 70 DF,  p-value: 0.000054335</code></pre>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb464-1" title="1"><span class="kw">anova</span>(Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq  Mean Sq F value      Pr(&gt;F)    
## prement    1 233.547 233.5473 18.4867 0.000054335 ***
## Residuals 70 884.328  12.6333                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Drugs + pre-inj model</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3z_i\)</span></p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb466-1" title="1"><span class="co">#4.  Drugs + Pre-inj model</span></a>
<a class="sourceLine" id="cb466-2" title="2">Drug_Pre_inj &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb466-3" title="3"><span class="kw">summary</span>(Drug_Pre_inj)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment + prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.41185 -2.05478 -0.22877  1.08012 11.68451 
## 
## Coefficients:
##                    Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)        2.817898   0.905424  3.1122  0.0027149 ** 
## treatmentmorphine -1.761510   0.960344 -1.8342  0.0709923 .  
## treatmentheroin   -3.318255   0.960100 -3.4562  0.0009488 ***
## prement            0.453961   0.099857  4.5461 0.00002308 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3256 on 68 degrees of freedom
## Multiple R-squared:  0.32725,    Adjusted R-squared:  0.29757 
## F-statistic: 11.026 on 3 and 68 DF,  p-value: 5.4921e-06</code></pre>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb468-1" title="1"><span class="kw">anova</span>(Drug_Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##           Df  Sum Sq  Mean Sq  F value     Pr(&gt;F)    
## treatment  2 137.250  68.6250  6.20499  0.0033478 ** 
## prement    1 228.570 228.5696 20.66700 0.00002308 ***
## Residuals 68 752.055  11.0596                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Drug + Pre-inj + Drug×Pre-inj</li>
</ol>
<p>鏈接方程部分: <span class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 z_i + \beta_{13}x_{1i}z_i + \beta_{23}x_{2i}z_i\)</span></p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb470-1" title="1"><span class="co">#5.  Drugs + Pre-inj + Drug×Pre-inj model</span></a>
<a class="sourceLine" id="cb470-2" title="2">Model5 &lt;-<span class="st"> </span><span class="kw">lm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>prement, <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb470-3" title="3"><span class="kw">summary</span>(Model5)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mentact ~ treatment * prement, data = Mental)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -7.82808 -1.93513 -0.51606  1.41607 11.36012 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)                1.978030   1.294069  1.5285 0.131158   
## treatmentmorphine         -1.211742   1.750342 -0.6923 0.491185   
## treatmentheroin           -1.461968   1.771855 -0.8251 0.412284   
## prement                    0.593939   0.183468  3.2373 0.001889 **
## treatmentmorphine:prement -0.089526   0.248346 -0.3605 0.719633   
## treatmentheroin:prement   -0.312985   0.250383 -1.2500 0.215704   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.3329 on 66 degrees of freedom
## Multiple R-squared:  0.34418,    Adjusted R-squared:  0.29449 
## F-statistic: 6.9274 on 5 and 66 DF,  p-value: 0.000029744</code></pre>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb472-1" title="1"><span class="kw">anova</span>(Model5)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mentact
##                   Df  Sum Sq  Mean Sq  F value      Pr(&gt;F)    
## treatment          2 137.250  68.6250  6.17798   0.0034719 ** 
## prement            1 228.570 228.5696 20.57704 0.000024811 ***
## treatment:prement  2  18.928   9.4639  0.85199   0.4312025    
## Residuals         66 733.128  11.1080                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>比較模型 3 和 4 可以使用相關的 F 統計量 (Partial F tests)</p>
<p><span class="math display">\[
F=\frac{(844.328 - 752.055)/(70-68)}{752.055/68} = 5.98
\]</span></p>
<p>自由度爲 (2,68) 時 F 統計量爲 5.98 的概率是:</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb474-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pf</span>(<span class="fl">5.98</span>, <span class="dv">2</span>, <span class="dv">68</span>)</a></code></pre></div>
<pre><code>## [1] 0.0040516165</code></pre>
<p>所以我們有極強的證據證明這兩個模型顯著不同，且模型 4 擬合數據更好，且該證據也證明了注射藥物後三組之間的精神醫學指徵的分顯著不同。用 R 進行偏 F 檢驗如下，可見我們的計算是完全正確的:</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb476-1" title="1"><span class="kw">anova</span>(Pre_inj, Drug_Pre_inj)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mentact ~ prement
## Model 2: mentact ~ treatment + prement
##   Res.Df     RSS Df Sum of Sq       F    Pr(&gt;F)   
## 1     70 884.328                                  
## 2     68 752.055  2   132.272 5.97996 0.0040518 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>比較模型 4 和 5:</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb478-1" title="1"><span class="kw">anova</span>(Drug_Pre_inj, Model5)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mentact ~ treatment + prement
## Model 2: mentact ~ treatment * prement
##   Res.Df     RSS Df Sum of Sq       F Pr(&gt;F)
## 1     68 752.055                            
## 2     66 733.128  2   18.9278 0.85199 0.4312</code></pre>
<p>所以，模型 4 和 5 比較的結果告訴我們沒有證據證明實驗前的精神醫學指徵得分和不同治療組之間有交互作用。但是由於模型 2 和 3 本身不是互爲嵌套式結構的，所以他們無法通過相似的偏 F 檢驗來比較模型。</p>
</div>
<div id="用-glm-命令擬合模型-4試比較其輸出結果和-lm-之間的異同" class="section level4">
<h4><span class="header-section-number">44.5.2.3</span> 用 <code>glm</code> 命令擬合模型 4，試比較其輸出結果和 <code>lm</code> 之間的異同:</h4>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb480-1" title="1">Model4 &lt;-<span class="st"> </span><span class="kw">glm</span>(mentact <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>prement, <span class="dt">family =</span> <span class="kw">gaussian</span>(<span class="dt">link =</span> <span class="st">&quot;identity&quot;</span>), <span class="dt">data =</span> Mental)</a>
<a class="sourceLine" id="cb480-2" title="2"><span class="kw">summary</span>(Model4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = mentact ~ treatment + prement, family = gaussian(link = &quot;identity&quot;), 
##     data = Mental)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -7.41185  -2.05478  -0.22877   1.08012  11.68451  
## 
## Coefficients:
##                    Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)        2.817898   0.905424  3.1122  0.0027149 ** 
## treatmentmorphine -1.761510   0.960344 -1.8342  0.0709923 .  
## treatmentheroin   -3.318255   0.960100 -3.4562  0.0009488 ***
## prement            0.453961   0.099857  4.5461 0.00002308 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 11.059638)
## 
##     Null deviance: 1117.875  on 71  degrees of freedom
## Residual deviance:  752.055  on 68  degrees of freedom
## AIC: 383.25
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>可以看出各個參數估計和標準誤估計都是完全相同的。但是當你使用 STATA 的 <code>glm</code> 命令時，它默認的高斯鏈接方程使用的不是 t 檢驗結果而是 z 檢驗結果，所以會給出略微不同的 95% 信賴區間。</p>
</div>
<div id="使用相關模型的結果填寫下列表格" class="section level4">
<h4><span class="header-section-number">44.5.2.4</span> 使用相關模型的結果填寫下列表格</h4>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exer-tab2">表 44.2: </span>Comparison of mean post-injection mental activity scores.
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Mean
</th>
<th style="text-align:center;">
Mean diff with Placebo
</th>
<th style="text-align:center;">
SE
</th>
<th style="text-align:center;">
Adj. mean diff with Placebo
</th>
<th style="text-align:center;">
SE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Placebo
</td>
<td style="text-align:center;">
5.542
</td>
<td style="text-align:center;">
0.000
</td>
<td style="text-align:center;">
–
</td>
<td style="text-align:center;">
0.000
</td>
<td style="text-align:center;">
–
</td>
</tr>
<tr>
<td style="text-align:center;">
Morphine
</td>
<td style="text-align:center;">
3.667
</td>
<td style="text-align:center;">
-1.875
</td>
<td style="text-align:center;">
1.08
</td>
<td style="text-align:center;">
-1.761
</td>
<td style="text-align:center;">
0.96
</td>
</tr>
<tr>
<td style="text-align:center;">
Heroin
</td>
<td style="text-align:center;">
2.167
</td>
<td style="text-align:center;">
-3.375
</td>
<td style="text-align:center;">
1.08
</td>
<td style="text-align:center;">
-3.310
</td>
<td style="text-align:center;">
0.96
</td>
</tr>
</tbody>
</table>
</div>
<div id="對分析的結果做簡短的總結" class="section level4">
<h4><span class="header-section-number">44.5.2.5</span> 對分析的結果做簡短的總結</h4>
<p>在模型 2 (drug model) 中，F 檢驗給出的 p = 0.0109，提供了較爲有力的證據證明每個治療組治療後的精神醫學指徵得分是不同的。但是，觀察每個回歸系數的檢驗結果，發現嗎啡組和安慰劑組之差其實沒有達到 5% 統計學意義 (p = 0.089)，海洛因組和安慰劑組之間的得分差則達到了 5% 的統計學意義 (p = 0.003)。</p>
<p>模型加入對實驗前精神醫學指徵得分的調整之後，組與組之間的估計差發生了些許(但是並不大)的變化。這其實也是我們事先估計的結果，因爲對於RCT來說，沒有混雜因素，之所以調整基線值，主要爲的是提升參數估計的精確度 (減小 SE，從而使95% 信賴區間更小)。</p>
<p>對交互作用實施了偏 F 檢驗得到的結果 (p = 0.43) 提示，沒有證據反對零假設 – 藥物作用效果不因爲實驗前患者的精神醫學指徵得分不同而不同。</p>
<p>最後，<code>glm</code> 和 <code>lm</code> 的模型結果輸出在 R 裏是幾乎完全相同的，在 STATA 裏面則有計算方法的不同導致不同的95%CI。</p>
</div>
</div>
</div>
</div>
<div id="二項分佈數據的廣義線性迴歸模型-logistic-regression-model" class="section level1">
<h1><span class="header-section-number">第 45 章</span> 二項分佈數據的廣義線性迴歸模型 logistic regression model</h1>
<p>二項分佈數據在醫學研究中很常見，例子有千千萬，下面這些只是作爲拋磚引玉：</p>
<ol style="list-style-type: decimal">
<li>心臟搭橋手術和血管成形術兩組病人比較療效時，結果變量可以是：死亡 (是/否)；心肌梗死發作 (是/否)；</li>
<li>機械心臟瓣膜手術結果：成功/失敗；</li>
<li>用小鼠作不同劑量二硫化碳暴露下的毒理學實驗，結果變量是：小鼠死亡 (是/否)；</li>
<li>隊列研究中追蹤對象中出現心肌梗死病例，結果變量是：心肌梗死發作 (是/否)。</li>
</ol>
<div id="彙總後個人-grouped-individual-的二項分佈數據" class="section level2">
<h2><span class="header-section-number">45.1</span> 彙總後/個人 (grouped / individual) 的二項分佈數據</h2>
<p>下面的數據，來自某個毒理學實驗，不同劑量的二硫化碳暴露下小鼠的死亡數和總數的數據：</p>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<p>很容易理解這是一個典型的彙總後二項分佈數據 (grouped binary data)。每組不同的劑量，第二列，第三列分別是死亡數和實驗總數。另外一種個人二項分佈數據 (individual binary data) 的形式是這樣的：</p>
<pre><code>##     dose death
## 1  49.06     1
## 2  49.06     1
## 3  49.06     1
## 4  49.06     1
## 5  49.06     1
## 6  49.06     1
## 7  49.06     0
## 8  49.06     0
## 9  49.06     0
## 10 49.06     0
## 11     .     .
## 12     .     .
## 13     .     .</code></pre>
<p>個人二項分佈數據其實就是把每個觀察對象的事件發生與否的信息都呈現出來。通常個人二項分佈數據又被稱爲<strong>伯努利數據</strong>，分組型的二項分佈數據被稱爲<strong>二項數據</strong>。兩種表達形式，但是存儲的是一樣的數據。</p>
</div>
<div id="二項分佈數據的廣義線性迴歸模型" class="section level2">
<h2><span class="header-section-number">45.2</span> 二項分佈數據的廣義線性迴歸模型</h2>
<p>而所有的 GLM 一樣，二項分佈的 GLM 包括三個部分：</p>
<ol style="list-style-type: decimal">
<li>因變量的分佈 Distribution：因變量應相互獨立，且服從二項分佈 <br> <span class="math display">\[\begin{aligned} Y_i &amp;\sim \text{Bin}(n_i, \pi_i), i = 1, \cdots, n \\ E(Y_i) &amp;= \mu_i = n_i\pi_i\end{aligned}\]</span></li>
<li>線性預測方程 Linear predictor：第 <span class="math inline">\(i\)</span> 名觀測對象的預測變量的線性迴歸模型 <br> <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接方程 Link function：鏈接方程連接的是 <span class="math inline">\(\mu_i = n\pi_i\)</span> 和線性預測方程。一個二項分佈因變量數據，可以有許多種鏈接方程：
<ul>
<li><span class="math inline">\(\mathbf{logit}:\)</span> <span class="math display">\[\text{logit}(\pi) = \text{ln}(\frac{\pi}{1-\pi})\]</span></li>
<li><span class="math inline">\(\mathbf{probit}:\)</span> <span class="math display">\[\text{probit}(\pi) = \Phi^{-1}(\pi)\]</span></li>
<li><span class="math inline">\(\mathbf{complementary\; log-log}:\)</span> <span class="math display">\[\text{cloglog}(\pi) = \text{ln}\{ - \text{ln}(1-\pi) \}\]</span></li>
<li><span class="math inline">\(\mathbf{log:}\)</span> <span class="math display">\[\text{log}(\pi) = \text{ln}(\pi)\]</span></li>
</ul></li>
</ol>
</div>
<div id="logit-or-log" class="section level2">
<h2><span class="header-section-number">45.3</span> 注</h2>
<ol style="list-style-type: decimal">
<li>概率鏈接方程 <span class="math inline">\(\text{probit}\)</span>，<span class="math inline">\(\Phi\)</span> 被定義爲標準正態分佈的累積概率方程 (Section <a href="01-Probability.html#standardNormal">7.3</a>)： <span class="math display">\[\Phi(z) = \text{Pr}(Z \leqslant z), \text{ for } Z\sim N(0,1)\]</span></li>
<li>二項分佈數據的標準參數 (canonical parameter) <span class="math inline">\(\theta_i\)</span> 的標準鏈接方程是 <span class="math inline">\(\theta_i = \text{logit}(\pi_i)\)</span>。</li>
<li><span class="math inline">\(\text{logit, probit, complementary log-log}\)</span> 三種鏈接方程都能達到把閾值僅限於 <span class="math inline">\(0 \sim 1\)</span> 之間的因變量概率映射到線性預測方程的全實數閾值 <span class="math inline">\((-\infty,+\infty)\)</span> 的目的。但是最後一個 <span class="math inline">\(\text{log}\)</span> 鏈接方程只能映射全部的非零負實數 <span class="math inline">\((-\infty,0)\)</span>。</li>
<li><span class="math inline">\(\text{logit, probit}\)</span> 鏈接方程都是以 <span class="math inline">\(\pi= 0.5\)</span> 爲對稱軸左右對稱的。但是 <span class="math inline">\(\text{cloglog}\)</span> 則沒有對稱的性質。</li>
<li>鏈接方程 <span class="math inline">\(\text{log}\)</span> 具有可以直接被解讀爲對數危險度比 (log Risk Ratio) 的優點，所以也常常在應用中見到。對數鏈接方程還有其他的優點 (非塌陷性 non-collapsibility)，但是它的最大缺點是，有時候利用這個鏈接方程的模型無法收斂 (converge)。</li>
<li><span class="math inline">\(\text{logit}\)</span> 鏈接方程是我們最常見的，也最直觀易於理解。利用這個鏈接方程擬合的模型的迴歸係數能夠直接被理解爲對數比值比 (log Odds Ratio)。</li>
<li>如果是個人數據 (individual data)，那麼 <span class="math inline">\(n_i = 1\)</span>，<span class="math inline">\(i\)</span> 是每一個觀測對象的編碼。那麼 <span class="math inline">\(Y_i = 0\text{ or }1\)</span>，代表事件發生或沒發生/成功或者失敗。如果是分組數據 (grouped data)，<span class="math inline">\(i\)</span> 是每個組的編號，<span class="math inline">\(n_i\)</span> 指的是第 <span class="math inline">\(i\)</span> 組中觀測對象的人數，<span class="math inline">\(Y_i\)</span> 是第 <span class="math inline">\(i\)</span> 組的 <span class="math inline">\(n\)</span> 名對象中事件發生的次數/成功的次數。</li>
</ol>
<hr />
<div id="exercise.-link-functions." class="section level3">
<h3><span class="header-section-number">45.3.1</span> Exercise. Link functions.</h3>
<p>推導出鏈接參數分別是</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{log}\)</span></li>
<li><span class="math inline">\(\text{logit}\)</span></li>
<li><span class="math inline">\(\text{complementary log-log}\)</span></li>
</ol>
<p>時，用參數 <span class="math inline">\(\alpha, \beta_1, \cdots, \beta_p\)</span> 表達的參數 <span class="math inline">\(\pi_i=?, E(Y_i)=\mu_i=?\)</span></p>
<p><strong>解</strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\text{log}\)</span>
<span class="math display">\[
\begin{aligned}
\text{ln}(\pi_i) &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i &amp; = e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}} \\
         \mu_i &amp; = n_i\pi_i = n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}
\end{aligned}
\]</span></p></li>
<li><p><span class="math inline">\(\text{logit}\)</span></p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\pi_i) &amp; = \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i   &amp; = \frac{e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
              \mu_i &amp; = \frac{n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\text{complementary log-log}\)</span></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{cloglog}(\pi_i) &amp; = \text{ln}\{ - \text{ln}(1-\pi) \} \\
                      &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i     &amp; = 1 - e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
            \mu_i     &amp; = n_i\pi_i = n_i(1-e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}})
\end{aligned}
\]</span></p>
<hr />
</div>
</div>
<div id="邏輯迴歸模型迴歸係數的實際意義" class="section level2">
<h2><span class="header-section-number">45.4</span> 邏輯迴歸模型迴歸係數的實際意義</h2>
<p>邏輯迴歸 (logistic regression) 的模型可以寫成是</p>
<p><span class="math display">\[
\text{logist}(\pi_i) = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}
\]</span></p>
<p>假如觀察對象 <span class="math inline">\(j\)</span> 和 <span class="math inline">\(i\)</span> 兩人中，其餘的預測變量都相同，二者之間有且僅有最後一個預測變量相差一個單位：</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\pi_j) &amp; = \text{ln}(\frac{\pi_j}{1-\pi_j}) = \alpha + \beta_1 x_{j1} + \beta_2 x_{j2} + \cdots + \beta_p x_{jp} \\
\text{logit}(\pi_i) &amp; = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\text{Because they are} &amp; \text{ in the same model share the same parameters, and } \\
x_{jp} &amp; = x_{ip} + 1\\
\Rightarrow \text{logit}(\pi_j) - \text{logit}(\pi_i) &amp; = \beta_p (x_{jp} + 1 - x_{jp}) = \beta_p \\
\Rightarrow \beta_p &amp; =  \text{ln}(\frac{\pi_j}{1-\pi_j})  -  \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    &amp; = \text{ln}(\frac{\frac{\pi_j}{1-\pi_j}}{\frac{\pi_i}{1-\pi_i}}) \\
                    &amp; = \text{ln}(\text{Odds Ratio})
\end{aligned}
\]</span></p>
<p>所以迴歸係數 <span class="math inline">\(\beta_p\)</span> 可以被理解爲是 <span class="math inline">\(j\)</span> 與 <span class="math inline">\(i\)</span> 相比較時的對數比值比 log Odds Ratio。我們只要對迴歸係數求反函數，即可求得比值比。</p>
</div>
<div id="BSEinfection" class="section level2">
<h2><span class="header-section-number">45.5</span> 邏輯迴歸實際案例</h2>
<p>一組數據如下：</p>
<p>其中，牲畜來自兩大羣 (group)；每羣有五個組的牲畜被飼養五種不同濃度的飼料 (dfactor)；每組牲畜我們記錄了牲畜的總數 (cattle) 以及感染了瘋牛病的牲畜數量 (infect)：</p>
<pre><code>##    group dfactor cattle infect
## 1      1       1     11      8
## 2      1       2     10      7
## 3      1       3     12      5
## 4      1       4     11      3
## 5      1       5     12      2
## 6      2       1     10     10
## 7      2       2     10      9
## 8      2       3     12      8
## 9      2       4     11      6
## 10     2       5     10      4</code></pre>
<div id="分析目的" class="section level3">
<h3><span class="header-section-number">45.5.1</span> 分析目的</h3>
<p>通過對本數據的分析，回答如下的問題：</p>
<ol style="list-style-type: decimal">
<li>考慮了牲畜來自兩羣以後，不同的飼料 (dfactor) 是否和感染瘋牛病有關？</li>
<li>兩羣牲畜之間，飼料和瘋牛病感染之間的關係是否不同？</li>
</ol>
</div>
<div id="模型-1-飼料-羣" class="section level3">
<h3><span class="header-section-number">45.5.2</span> 模型 1 飼料 + 羣</h3>
<p><span class="math display">\[
\begin{aligned}
\text{Assume } Y_i &amp; \sim \text{Bin} (n_i, \pi_i) \\
\text{logit}(\pi_i) &amp; = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2}
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb485-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb485-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + 
##     dfactor, family = binomial(link = logit), data = Cattle)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.60847  -0.17831   0.10110   0.31150   1.16876  
## 
## Coefficients:
##                Estimate Std. Error z value   Pr(&gt;|z|)    
## (Intercept)     2.13104    0.61130  3.4861  0.0004902 ***
## factor(group)2  1.30590    0.46540  2.8060  0.0050163 ** 
## dfactor        -0.78744    0.18135 -4.3422 0.00001411 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.52556  on 9  degrees of freedom
## Residual deviance:  2.45082  on 7  degrees of freedom
## AIC: 32.2537
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb487-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model1)</a></code></pre></div>
<pre><code>##  
##                        OR  lower95ci  upper95ci       Pr(&gt;|Z|)
## factor(group)2 3.69102114 1.48251011 9.18957451 0.005016342395
## dfactor        0.45500721 0.31889988 0.64920551 0.000014109282</code></pre>
<p>於是，我們可以寫下這個邏輯迴歸的數學模型：</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}(\hat\pi_i) &amp; = \text{ln}(\frac{\hat\pi_i}{1-\hat\pi_i})  = \hat\alpha + \hat\beta_1 x_{i1} + \hat\beta_2 x_{i2} \\
                        &amp; = 2.1310 - 0.7874 \times \text{dfactor} + 1.3059 \times \text{group}
\end{aligned}
\]</span></p>
<p><strong>解讀這些參數估計的意義</strong></p>
<ul>
<li>截距 <span class="math inline">\(\hat\alpha = 2.1310\)</span> 的含義是，當 <span class="math inline">\(x_{1}, x_{2}\)</span> 都等於零，i.e. 飼料濃度 0，在第一羣的那些牲畜感染瘋牛病的<strong>對數比值 (log-odds)</strong>；</li>
<li>斜率 <span class="math inline">\(\hat\beta_1 = -0.7874\)</span> 的含義是，當牲畜羣不變時，飼料濃度每增加一個單位，牲畜感染瘋牛病的<strong>對數比值的估計變化量 (estimated increase in log odds of infection)</strong>；</li>
<li>迴歸係數 <span class="math inline">\(\hat\beta_2 = 1.3059\)</span> 的含義是，當飼料濃度不變時，兩羣牲畜之間感染瘋牛病的<strong>對數比值比 (log-Odds Ratio)</strong>，所以第二羣牲畜比第一羣牲畜感染瘋牛病的比值比的估計量，以及 <span class="math inline">\(95\%\text{CI}\)</span> 的計算方法就是：<br> <span class="math display">\[\begin{aligned} \text{exp}(\hat\beta_2) &amp; = \text{exp}(1.3059) = 3.69,\\ \text{ with 95% CI: } &amp; \text{exp}(\hat\beta_2 \pm 1.96\times \text{Std.Error}_{\hat\beta_2}) \\  &amp; = (1.48, 9.19) \end{aligned}\]</span></li>
</ul>
</div>
<div id="模型-2-增加交互作用項-飼料-times-羣" class="section level3">
<h3><span class="header-section-number">45.5.3</span> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</h3>
<p>飼料濃度與瘋牛病感染之間的關係，是否因爲牲畜所在的 “羣” 不同而發生改變？</p>
<p>定義增加了飼料和羣交互作用項的邏輯迴歸模型：</p>
<p><span class="math display">\[
\text{logit}(\pi_i) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1}\times x_{i2}
\]</span></p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb489-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(group)<span class="op">*</span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb489-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + 
##     dfactor + factor(group) * dfactor, family = binomial(link = logit), 
##     data = Cattle)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.71914  -0.16508  -0.02111   0.34451   1.00127  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)             1.89028    0.73584  2.5689 0.010203 * 
## factor(group)2          1.98867    1.34471  1.4789 0.139172   
## dfactor                -0.70508    0.22955 -3.0716 0.002129 **
## factor(group)2:dfactor -0.20583    0.37553 -0.5481 0.583619   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.52556  on 9  degrees of freedom
## Residual deviance:  2.14476  on 6  degrees of freedom
## AIC: 33.9477
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb491-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model2)</a></code></pre></div>
<pre><code>##  
##                                OR  lower95ci    upper95ci     Pr(&gt;|Z|)
## factor(group)2         7.30580425 0.52365757 101.92686809 0.1391720038
## dfactor                0.49406759 0.31506152   0.77477816 0.0021289774
## factor(group)2:dfactor 0.81396890 0.38989883   1.69927508 0.5836187644</code></pre>
<p>從輸出的報告來看，增加了交互作用項以後，在第一羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 是</p>
<p><span class="math display">\[
\text{exp}(-0.7051) = 0.49
\]</span></p>
<p>在第二羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 變成了</p>
<p><span class="math display">\[
\text{exp}(-0.7051 - 0.2058) = 0.40
\]</span></p>
<p>通過對 <span class="math inline">\(\hat\beta_3 = 0\)</span> 的假設檢驗，就可以推斷飼料濃度和感染瘋牛病之間的關係是否因爲不同牲畜 “羣” 而不同。所以上面的報告中也已經有了交互作用項的檢驗結果 <span class="math inline">\(p = 0.584\)</span>，所以，此處可以下的結論是：沒有足夠的證據證明交互作用存在。</p>
</div>
</div>
<div id="glm-practical-03" class="section level2">
<h2><span class="header-section-number">45.6</span> GLM-Practical 03</h2>
<p>數據來自一個毒理學實驗，該實驗中 8 組昆蟲在不同濃度的二硫化碳下暴露四個小時，實驗的目的是研究二硫化碳劑量和昆蟲死亡率之間的關系。</p>
<div id="昆蟲的死亡率" class="section level3">
<h3><span class="header-section-number">45.6.1</span> 昆蟲的死亡率</h3>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb493-1" title="1">Insect &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/INSECT.RAW&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;dose&quot;</span>, <span class="st">&quot;n_deaths&quot;</span>, <span class="st">&quot;n_subjects&quot;</span>))</a>
<a class="sourceLine" id="cb493-2" title="2"><span class="kw">print</span>(Insect)</a></code></pre></div>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<ol style="list-style-type: decimal">
<li>計算每組實驗濃度下死亡昆蟲的比例</li>
</ol>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb495-1" title="1">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb495-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> n_deaths<span class="op">/</span>n_subjects)</a>
<a class="sourceLine" id="cb495-3" title="3"><span class="kw">print</span>(Insect)</a></code></pre></div>
<pre><code>##    dose n_deaths n_subjects          p
## 1 49.06        6         59 0.10169492
## 2 52.99       13         60 0.21666667
## 3 56.91       18         62 0.29032258
## 4 60.84       28         56 0.50000000
## 5 64.76       52         63 0.82539683
## 6 68.69       53         59 0.89830508
## 7 72.61       60         62 0.96774194
## 8 76.54       59         60 0.98333333</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>將濃度和死亡比例做散點圖</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-3"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-3-1.png" alt="Scatter plot of CS2 dose and proportion killed." width="80%" />
<p class="caption">
圖 45.1: Scatter plot of CS2 dose and proportion killed.
</p>
</div>
<p>這裏如果使用<strong>線性回歸模型是不合適的</strong>，這是因爲:</p>
<ul>
<li>散點圖提示濃度和死亡比例之間不是線性關系;</li>
<li>“比例”這一數據被局限在 (0,1) 範圍之內，線性回歸的結果變量不會滿足這個條件;</li>
<li>觀察數據本身的方差不齊，也就是每個觀察點(死亡比例)的變化程度無法保證是相同的。</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>計算死亡比例的對數比值比 (log-odds)，再作相同的散點圖，你會得出什麼樣的結論？</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-4"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-4-1.png" alt="Scatter plot of CS2 dose and log-odds of proportion killed." width="80%" />
<p class="caption">
圖 45.2: Scatter plot of CS2 dose and log-odds of proportion killed.
</p>
</div>
<p>死亡比例的對數比值比和二硫化碳濃度之間更加接近線性關系。</p>
<ol start="4" style="list-style-type: decimal">
<li>寫下此模型的數學表達式，你的表達式必須指明數據的分布，線性預測方程，和鏈接方程三個部分。用 R 擬合你寫下的模型。</li>
</ol>
<p><strong>解</strong></p>
<p>本數據中，隨機變量是每組昆蟲中死亡的個數。用 <span class="math inline">\(Y_i\)</span> 標記第 <span class="math inline">\(i\)</span> 組昆蟲中死亡昆蟲數量，<span class="math inline">\(d_i\)</span> 表示第 <span class="math inline">\(i\)</span> 組昆蟲被暴露的二硫化碳濃度。對於所有的廣義線性回歸模型來說，它都由三個部分組成:
1) 反應量分布 the response distribution; 2) 鏈接方程 link function; 3) 線性預測方程 linear predictor.</p>
<p>反應量分布:</p>
<p><span class="math display">\[
Y_i \sim \text{Bin}(n_i, \pi_i),i = 1, \cdots, 8
\]</span></p>
<p><span class="math inline">\(Y_i\)</span> 的期望值是 <span class="math inline">\(\mu_i\)</span> 的話，鏈接方程是</p>
<p><span class="math display">\[
\eta_i = \log(\frac{\mu_i}{n_i - \mu_i}) = \log(\frac{\pi_i}{1- \pi_i}) = \text{logit}(\pi_i)
\]</span></p>
<p>線性預測方程是</p>
<p><span class="math display">\[
\eta_i = \beta_0 + \beta_1 d_i
\]</span></p>
<p>用 R 來擬合這個模型:</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb497-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb497-2" title="2"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose, 
##     family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.14983  -0.22403   0.25301   0.70846   0.99107  
## 
## Coefficients:
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -14.086403   1.228393 -11.467 &lt; 2.2e-16 ***
## dose          0.236593   0.020303  11.653 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   4.61548  on 6  degrees of freedom
## AIC: 37.394
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol style="list-style-type: decimal">
<li>計算 CS<sub>2</sub> 在 55mg/l 時該模型預測的昆蟲死亡概率是多少。</li>
</ol>
<p><span class="math display">\[
\text{logit}(\hat\pi_i) = -14.09 + 0.2366\times55 \\
\Rightarrow \hat\pi_i = \frac{\exp(-14.09 + 0.2366\times55)}{1+\exp(-14.09 + 0.2366\times55)} = 0.254
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>計算昆蟲死亡比例達到50%的CS<sub>2</sub>濃度(LD50)。</li>
</ol>
<p>當死亡比例達到一半時， <span class="math inline">\(\hat\pi = 0.5 \Rightarrow \text{logit}(\hat\pi) = 0\)</span></p>
<p><span class="math display">\[
0 = -14.09 + 0.2366 \times \text{LD50} \\
\Rightarrow \text{LD50} = 59.5 \text{mg/l}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>有證據證明昆蟲的死亡率隨着 CS<sub>2</sub> 濃度的增加而升高嗎？</li>
</ol>
<p>有極強的證據證明昆蟲死亡率隨着 CS<sub>2</sub> 濃度增加而升高 <span class="math inline">\((z = 11.65, P &lt; 0.001, \text{Wald test})\)</span>。</p>
<ol start="4" style="list-style-type: decimal">
<li>將參數轉換成比值比，並解釋其實際含義。</li>
</ol>
<p>CS<sub>2</sub> 濃每增加 1 個單位 (1 mg/l)，昆蟲死亡率的比值比是 <span class="math inline">\(\exp(0.2366) = 1.27\)</span>，95% 信賴區間下限: <span class="math inline">\(\exp(0.2366 - 1.96\times0.0203) = 1.22\)</span>，上限: <span class="math inline">\(\exp(0.2366 + 1.96\times0.0203) = 1.32\)</span>。</p>
<p>下面是在 R 裏計算的 OR 及其對應的信賴區間:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb499-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(n_deaths, n_subjects - n_deaths) 
##  
##                   OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## dose (cont. var.) 1.27 (1.22,1.32)  &lt; 0.001        &lt; 0.001   
##                                                              
## Log-likelihood = -16.697
## No. of observations = 8
## AIC value = 37.394</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>提取模型中擬合值 fitted value</li>
</ol>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb501-1" title="1"><span class="co"># the fitted values relate to the probability of the deaths in each group</span></a>
<a class="sourceLine" id="cb501-2" title="2">Model1<span class="op">$</span>fitted.values</a></code></pre></div>
<pre><code>##           1           2           3           4           5           6           7           8 
## 0.077332565 0.175181106 0.349349622 0.576375269 0.774754491 0.897077450 0.956586871 0.982405536</code></pre>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb503-1" title="1"><span class="co"># to calculate the counts of numbers of deaths in each group</span></a>
<a class="sourceLine" id="cb503-2" title="2">Model1<span class="op">$</span>fitted.values <span class="op">*</span><span class="st"> </span>Insect<span class="op">$</span>n_subjects</a></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7          8 
##  4.5626213 10.5108663 21.6596766 32.2770151 48.8095329 52.9275695 59.3083860 58.9443322</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>把模型擬合的概率和觀測概率放在同一個散點圖中比較:</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-8"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-8-1.png" alt="Observed (circles) and fitted (triangles) proportions are generally similar, with differences greatest in the third and fourth dose groups." width="80%" />
<p class="caption">
圖 45.3: Observed (circles) and fitted (triangles) proportions are generally similar, with differences greatest in the third and fourth dose groups.
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li>現在計算一個新的濃度值 dose2 = dose<sup>2</sup>。這個新的變量用於分析是否模型中使用濃度平方可以提升模型的擬合優度。1) 用 Wald 檢驗的結果說明濃度平方的回歸系數是否有意義。2) 新模型的擬合值是否有所改善？</li>
</ol>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb505-1" title="1">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb505-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dose2 =</span> dose<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb505-3" title="3">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose <span class="op">+</span><span class="st"> </span>dose2, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb505-4" title="4"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose + 
##     dose2, family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8  
## -0.004545   0.634377  -0.691056  -0.681962   1.223967  -0.154036  -0.029880  -0.561968  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.4881722  9.8677198 -0.2522   0.8009
## dose        -0.1500054  0.3291786 -0.4557   0.6486
## dose2        0.0031871  0.0027273  1.1686   0.2426
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   3.18361  on 5  degrees of freedom
## AIC: 37.9621
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>加入了濃度平方以後，該項本身的 Wald 檢驗結果告訴我們，沒有證據證明濃度和昆蟲死亡比例的對數比值比之間呈拋物線關系。</p>
<div class="figure" style="text-align: center"><span id="fig:GLM-exe-3-10"></span>
<img src="bookdown_files/figure-html/GLM-exe-3-10-1.png" alt="Fitted probabilities for each dose from two models" width="80%" />
<p class="caption">
圖 45.4: Fitted probabilities for each dose from two models
</p>
</div>
<p>加入濃度平方二次項的模型在第三和第四組給出了比一次模型更加接近觀測值的估計。但是這種提升是極爲有限的，且統計學上加入的二次項的回歸系數並無意義。</p>
<p>所以，本數據分析的結論是，有很強的證據證明昆蟲死亡的概率隨着CS<sub>2</sub> 濃度的升高而升高 (P&lt;0.001)。死亡的比值 (odds)，隨着濃度每升高1個單位 (mg/l) 而升高 27% (95% CI: 22%-32%)。</p>
</div>
<div id="哮喘門診數據" class="section level3">
<h3><span class="header-section-number">45.6.2</span> 哮喘門診數據</h3>
<p>在一項橫斷面研究中，訪問哮喘門診連續達到 6 個月以上的全部患者被一一詢問其目前的用藥情況和症狀。下面的表格總結的是這些患者中，目前使用口服類固醇藥物與否，及患者報告夜間由於哮喘症狀而從睡眠中醒來的次數。</p>
<table class="table table-striped table-hover table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:GLM-exe-3-11">表 45.1: </span>Frequency of night waking due to asthma
</caption>
<thead>
<tr>
<th style="text-align:center;">
Corticosteroids
</th>
<th style="text-align:center;">
Never
</th>
<th style="text-align:center;">
Less.than.once.a.week
</th>
<th style="text-align:center;">
More.than.once.a.week
</th>
<th style="text-align:center;">
Every.night
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
User
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
44
</td>
<td style="text-align:center;">
38
</td>
</tr>
<tr>
<td style="text-align:center;">
Non-user
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
22
</td>
</tr>
</tbody>
</table>
<p>下面的 STATA 輸出報告，是對上述數據擬合的邏輯回歸的結果。其中變量 <code>user</code> 和 <code>never</code> 被編碼爲 0/1，1 代表該患者正在使用口服類固醇藥物，或者從未因爲哮喘而在夜間醒來。變量 <code>sev</code> 是患者自己報告的哮喘症狀嚴重程度 (0-3 分，分數越高症狀越嚴重)。</p>
<p><img src="img/Selection_125.png" width="90%" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>用表格的數據實施了一個總體的卡方檢驗還有一個卡方檢驗的傾向性檢驗。這兩個卡方檢驗的統計量分別是 12.87, 和 0.25。請解釋這兩個統計量的實際含義。</li>
</ol>
<p>在零假設 – 使用口服類固醇藥物和夜間因爲哮喘而醒來次數之間沒有關系 – 條件下，表格總體的卡方檢驗服從 <span class="math inline">\(\chi^2_3\)</span> 分布。查表或者在 R 裏使用</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb507-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="fl">12.87</span>, <span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.0049263406</code></pre>
<p>可以知道 p = 0.005。這是極強的反對零假設的證據。</p>
<p>相反，卡方檢驗的傾向性檢驗結果是 p = 0.62，這個結果提示使用類固醇藥物所佔的比例沒有傾向性:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb509-1" title="1"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="fl">0.25</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.61707508</code></pre>
<p>兩個卡方檢驗的顯著不同應是因爲用類固醇藥物的患者比例在 “從不”, “低於每周一次”，“多餘每周一次” 中遞增，但是到了最後一組 “每天” 時又下降。傾向性檢驗比起總體的卡方檢驗在關系是單調遞增或者單調遞減時統計學效能更好，但是當關系變得復雜以後，傾向性卡方檢驗變得不再有優勢。傾向性檢驗其實等同於用一個變量 (用藥與否) 和另一個變量 (夜間因爲哮喘醒來次數) 做線性回歸。對於這個表格的數據來說，這是一個 U 型的關系，所以做線性回歸的結果也是會給出沒有意義的 p 值。</p>
<ol start="2" style="list-style-type: decimal">
<li>利用 STATA 的邏輯回歸報告，能對哮喘的嚴重程度和患者報告夜間從未因爲哮喘醒來(never wake up)之間的關系作出怎樣的結論？</li>
</ol>
<p>從 STATA 計算的結果來看，該數據提供了極強的證據證明哮喘的嚴重程度和報告從未因哮喘而醒來之間呈負相關。特別地，哮喘嚴重程度爲 2 的患者比 1 的患者報告從未醒來的比值比 (odds ratio) 是 0.077 (95% CI: 0.027, 0.224, p &lt; 0.001); 哮喘嚴重程度爲 3 的患者 比 1 的患者報告醒來的比值比是 0.0128 (95% CI: 0.0022, 0.0738, p &lt; 0.001)。所以，哮喘越嚴重，報告夜裏從未醒來的概率越低。</p>
<ol start="3" style="list-style-type: decimal">
<li>利用 STATA 的邏輯回歸報告，能對是否使用口服類固醇藥物和報告從未因哮喘而醒來之間的關系作出怎樣的結論？</li>
</ol>
<p>如果要計算未調整的比值比，我們可以把表格中第2-4列的數據合並，那麼在使用類固醇藥物的患者 (n = 150) 中 27 人報告從未醒來，在不使用類固醇藥物的患者中 (n = 60)，有 20 人報告從未醒來。這樣未調整的比值比就是 <span class="math inline">\(\frac{27 \times 40}{20 \times 123} = 0.44\)</span>。STATA 計算的邏輯回歸模型的結果顯示，這一數字在調整了哮喘症狀之後，發生了本質的變化:
<span class="math inline">\(e^{0.815} = 2.26\)</span>。雖然調整後的比值比並沒有統計學意義。但是它從小於 1 變成了大於 1，方向上發生了轉變。所以，調整了哮喘嚴重程度之後，數據似乎提示使用類固醇藥物和報告從不在夜間因哮喘醒來的概率呈正相關 (用藥者睡得更好)，但是這個相關性沒有統計學意義，其95%信賴區間很寬。</p>
<ol start="4" style="list-style-type: decimal">
<li>從這些分析來看，哮喘嚴重程度和是否口服類固醇藥物之間有什麼樣的關系？</li>
</ol>
<p>因爲用類固醇藥物和報告夜間不曾醒來在調整了哮喘嚴重程度之後從原先的負相關變成了正相關。又因爲哮喘嚴重程度本身和報告夜間不曾醒來之間是負相關，所以，是否口服類固醇藥物和哮喘嚴重程度之間呈正相關，也就是哮喘越嚴重，患者越傾向於使用類固醇藥物。</p>
</div>
</div>
</div>
<div id="模型比較和擬合優度" class="section level1">
<h1><span class="header-section-number">第 46 章</span> 模型比較和擬合優度</h1>
<p>我們用數據擬合廣義線性模型時其實有許多不同的目的和意義：</p>
<ol style="list-style-type: decimal">
<li>估計某些因素的暴露和因變量之間的相關程度，同時調整其餘的混雜因素；</li>
<li>確定能夠強有力的預測因變量變化的因子；</li>
<li>用於預測未來的事件或者病人的預後等等。</li>
</ol>
<p>但是一般情況下，我們拿到數據以後不可能立刻就能構建起來一個完美無缺的模型。我們常常會擬合兩三個甚至許多個模型，探索模型和數據的擬合程度，就成爲了比較哪個模型更優於其他模型的硬指標。本章的目的是介紹 GLM 嵌套式模型之間的兩兩比較方法，其中一個模型的預測變量是另一個模型的預測變量的子集。</p>
<p>對手裡的數據構建一個GLM的過程，其實就是在該數據的條件下(given the data)，對模型參數 <span class="math inline">\(\mathbf{\beta}\)</span> 定義其對數似然 (log-likelihood)，並尋找能給出極大值的那一系列極大似然估計 (maximum likelihood estimates, MLE) <span class="math inline">\(\mathbf{\hat\beta}\)</span> 的過程。每次構建一個模型，我們都會獲得該模型對應的極大對數似然，它其實是極爲依賴構建它的觀察數據的，意味着每次觀察數據發生變化，你即使用了相同的模型來擬合相同的GLM獲得的極大似然都會發生變化。所以其實我們並不會十分關心這個極大似然的絕對值大小。我們關心的其實是，當對相同數據，構建了包含不同變量的模型時，極大似然的<strong>變化量</strong>。因爲這個極大似然(或者常被略稱爲對數似然 log likelihood，甚至直接只叫做似然)的變化量本身確實會反應我們思考的模型，和觀察數據之間的擬合程度。一般來說，模型中變量較少的那個 (通常叫做更加一般化的模型 more general model)獲得的似然值和變量較多的那個模型獲得的似然值相比較都會比較小，我們關心的似然值在增加了新變量之後的複雜模型後獲得的<strong>增量</strong>，是否有價值，是否真的改善了模型的擬合度 (whether the difference in log likelihoods is large enough to indicate that the less general model provides a “real” improvement in fit)。</p>
<div id="嵌套式模型的比較-nested-models" class="section level2">
<h2><span class="header-section-number">46.1</span> 嵌套式模型的比較 nested models</h2>
<p>假如我們用相同的數據擬合兩個 GLM，<span class="math inline">\(\text{Model 1, Model 2}\)</span>。其中，當限制 <span class="math inline">\(\text{Model 2}\)</span> 中部分參數爲零之後會變成 <span class="math inline">\(\text{Model 1}\)</span>時， 我們說 <span class="math inline">\(\text{Model 1}\)</span> 是 <span class="math inline">\(\text{Model 2}\)</span> 的嵌套模型。</p>
<ul>
<li>例1：嵌套式模型 I
<br> 模型 1 的線性預測方程爲 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1}\]</span>
<br> 模型 2 和模型 1 的因變量相同 (分佈相同)，使用相同的鏈接方程 (link function) 和尺度參數 (scale parameter, <span class="math inline">\(\phi\)</span>)，但是它的線性預測方程爲 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i1} + \beta_3 x_{i3}\]</span>
<br> 此時我們說模型 1 是模型 2 的嵌套模型，因爲令 <span class="math inline">\(\beta_2 = \beta_3 = 0\)</span> 時，模型 2 就變成了 模型 1。</li>
<li>例2：嵌套式模型 II
<br> 模型 1 的線性預測方程爲 (此處默認 <span class="math inline">\(x_{i1}\)</span> 是連續型預測變量) <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1}\]</span>
<br> 模型 2 的線性預測方程如果是 <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x^2_{i1}\]</span>
<br> 此時我們依然認爲 模型 1 是模型 2 的嵌套模型， 因爲令 <span class="math inline">\(\beta_2 = 0\)</span> 時，模型 2 就變成了 模型 1。</li>
</ul>
<p>關於嵌套式模型，更加一般性的定義是這樣的：<strong>標記模型 2 的參數向量是 <span class="math inline">\(\mathbf{(\psi, \lambda)}\)</span>，其中，當我們限制了參數向量的一部分例如 <span class="math inline">\(\mathbf{\psi = 0}\)</span>，模型 2 就變成了 模型 1 的話，模型 1 就是嵌套於 模型 2 的</strong>。所以比較嵌套模型之間的擬合度，我們可以比較較爲複雜的 模型 2 相較 模型 1 多出來的複雜的預測變量參數部分 <span class="math inline">\(\mathbf{\psi}\)</span> 是否是必要的。也就是說，比較嵌套模型哪個更優的情況下，零假設是 <span class="math inline">\(\mathbf{\psi = 0}\)</span>。</p>
<p>這是典型的多變量的模型比較，需要用到子集似然比檢驗 <a href="02-Inference.html#profile-log-likelihood">19</a>，log-likelihood ratio test：</p>
<p><span class="math display">\[
\begin{aligned}
-2pllr(\psi = 0) &amp; = -2\{ \ell_p(\psi=0) - \ell_p(\hat\psi) \} \stackrel{\cdot}{\sim} \chi^2_{df}\\
\text{Where } \hat\psi &amp; \text{ denotes the MLE of } \psi \text{ in Model 2} \\
\text{With } df &amp; = \text{ the dimension of } \mathbf{\psi}
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\ell_p(\psi=0)\)</span>，其實是 模型 1 的極大對數似然，記爲 <span class="math inline">\(\ell_1\)</span>。<span class="math inline">\(\ell_p(\hat\psi)\)</span> 其實是 模型 2 的極大對數似然，記爲 <span class="math inline">\(\ell_2\)</span>。所以這個似然比檢驗統計量就變成了：</p>
<p><span class="math display">\[
-2pllr(\psi = 0) = -2(\ell_1-\ell_2)
\]</span></p>
<p>這個統計量在零假設的條件下服從自由度爲兩個模型參數數量之差的卡方分佈。如果 <span class="math inline">\(p\)</span> 值小於提前定義好的顯著性水平，將會提示有足夠證據證明 模型 2 比 模型 1 更好地擬合數據。</p>
</div>
<div id="嵌套式模型比較實例" class="section level2">
<h2><span class="header-section-number">46.2</span> 嵌套式模型比較實例</h2>
<p>回到之前用過的瘋牛病和牲畜羣的數據 <a href="09-GLM.html#BSEinfection">45.5</a>。我們當時成功擬合了兩個 GLM 模型，模型 1 的預測變量只有 “飼料”，“羣”；模型 2 的預測變量在模型 1 的基礎上增加二者的交互作用項。並且我們當時發現交互作用項部分並無實際統計學意義 <span class="math inline">\(p = 0.584\)</span>。現在用對數似然比檢驗來進行類似的假設檢驗。</p>
<p>先用 <code>logLik(Model)</code> 的方式提取兩個模型各自的對數似然，然後計算對數似然比，再去和自由度爲 1 (因爲兩個模型只差了 1 個預測變量) 的卡方分佈做比較：</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb511-1" title="1">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb511-2" title="2">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(infect, cattle <span class="op">-</span><span class="st"> </span>infect) <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(group) <span class="op">+</span><span class="st"> </span>dfactor <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(group)<span class="op">*</span>dfactor, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Cattle)</a>
<a class="sourceLine" id="cb511-3" title="3"><span class="kw">logLik</span>(Model1)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -13.12687 (df=3)</code></pre>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb513-1" title="1"><span class="kw">logLik</span>(Model2)</a></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -12.973836 (df=4)</code></pre>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb515-1" title="1">LLR &lt;-<span class="st"> </span><span class="dv">-2</span><span class="op">*</span>(<span class="kw">logLik</span>(Model1) <span class="op">-</span><span class="st"> </span><span class="kw">logLik</span>(Model2))</a>
<a class="sourceLine" id="cb515-2" title="2"></a>
<a class="sourceLine" id="cb515-3" title="3"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(<span class="kw">as.numeric</span>(LLR), <span class="dt">df=</span><span class="dv">1</span>) <span class="co"># p value for the LLR test</span></a></code></pre></div>
<pre><code>## [1] 0.58010367</code></pre>
<p>再和 <code>lmtest::lrtest</code> 的輸出結果作比較。</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb517-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: cbind(infect, cattle - infect) ~ factor(group) + dfactor
## Model 2: cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group) * 
##     dfactor
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)
## 1   3 -13.1269                      
## 2   4 -12.9738  1 0.30607     0.5801</code></pre>
<p>結果跟我們手計算的結果完全吻合。AWESOME !!!</p>
<p>值得注意的是，此時進行的似然比檢驗結果獲得的 p 值，和模型中 Wald 檢驗結果獲得的 p 值十分接近 (0.5801 v.s. 0.584)，這也充分顯示了這兩個檢驗方法其實是漸進相同的 (asymptotically equivalent)。</p>
</div>
<div id="飽和模型模型的偏差擬合優度" class="section level2">
<h2><span class="header-section-number">46.3</span> 飽和模型，模型的偏差，擬合優度</h2>
<p>在簡單線性迴歸中，殘差平方和提供了模型擬合數據好壞的指標 – 決定係數 <span class="math inline">\(R^2\)</span> (Section <a href="04-Linear-Regression.html#Rsquare">28.2.3</a>)，並且在 偏 F 檢驗 (Section <a href="04-Linear-Regression.html#partialF">30.3.4</a>) 中得到模型比較的應用。</p>
<p>廣義線性迴歸模型中事情雖然沒有這麼簡單，但是思想可以借鑑。先介紹飽和模型 (saturated model) 的概念，再介紹其用於模型偏差 (deviance) 比較的方法。前文中介紹過的嵌套模型之間的對數似然比檢驗，也是測量兩個模型之間偏差大小的方法。</p>
<div id="飽和模型-saturated-model" class="section level3">
<h3><span class="header-section-number">46.3.1</span> 飽和模型 saturated model</h3>
<p>飽和模型 saturated model，是指一個模型中所有可能放入的參數都被放進去的時候，模型達到飽和，自由度爲零。其實就是模型中參數的數量和觀測值個數相等的情況。飽和模型的情況下，所有的擬合值和對應的觀測值相等。所以，對於給定的數據庫，飽和模型提供了所有模型中最 “完美” 的擬合值，因爲擬合值和觀測值完全一致，所以飽和模型的對數似然，比其他所有你建立的模型的對數似然都要大。但是多數情況下，飽和模型並不是合理的模型，不能用來預測也無法拿來解釋數據，因爲它本身就是數據。</p>
</div>
<div id="deviance" class="section level3">
<h3><span class="header-section-number">46.3.2</span> 模型偏差 deviance</h3>
<p>令 <span class="math inline">\(L_c\)</span> 是目前擬合模型的對數似然，<span class="math inline">\(L_s\)</span> 是數據的飽和模型的對數似然，所以兩個模型的對數似然比是 <span class="math inline">\(\frac{L_c}{L_s}\)</span>。那麼尺度化的模型偏差 (scaled deviance) <span class="math inline">\(S\)</span> 被定義爲：</p>
<p><span class="math display">\[
S=-2\text{ln}(\frac{L_c}{L_s}) = -2(\ell_c - \ell_s)
\]</span></p>
<p>值得注意的是，非尺度化偏差 (unscaled deviance) 被定義爲 <span class="math inline">\(\phi S\)</span>，其中的 <span class="math inline">\(\phi\)</span> 是尺度參數，由於泊松分佈和二項分佈的尺度參數都等於 1 (<span class="math inline">\(\phi = 1\)</span>)，所以尺度化偏差和非尺度化偏差才會在數值上相等。</p>
<p>這裏定義的模型偏差大小，可以反應一個模型擬合數據的程度，偏差越大，該模型對數據的擬合越差。“Deviance can be interpreted as Badness of fit”.</p>
<p><strong>但是，模型偏差只適用於彙總後的二項分佈數據(aggregated)。當數據是個人的二分類數據時 (inidividual binary data)，模型的偏差值變得不再適用，無法用來比較模型對數據的擬合程度。</strong> 這是因爲當你的觀測值 (個人數據) 有很多時，擬合飽和模型所需要的參數個數會趨向於無窮大，這違背了子集對數似然比檢驗的條件。</p>
</div>
<div id="彙總型二項分佈數據-aggregatedgrouped-binary-data" class="section level3">
<h3><span class="header-section-number">46.3.3</span> 彙總型二項分佈數據 aggregated/grouped binary data</h3>
<p>假如，觀察數據是互相獨立的，服從二項分佈的 <span class="math inline">\(n\)</span> 個觀測值: <span class="math inline">\(Y_i \sim Bin(n_i, \pi_i), i=1,\dots,n\)</span>。用彙總型的數據表達方法來描述它，那麼獲得的數據就是一個個分類變量在各自組中的人數或者百分比的數據 (如下面的數據所示)。這樣的數據的飽和模型，其實允許了每個分類變量的組中百分比變化 (The saturated model for this data allows the probability of “success” to be different in each group, so that <span class="math inline">\(\tilde{\pi} = \frac{y_i}{n_i}\)</span>)。也就是每組的模型擬合後百分比，等於觀察到的百分比。</p>
<pre><code>##    dose n_deaths n_subjects
## 1 49.06        6         59
## 2 52.99       13         60
## 3 56.91       18         62
## 4 60.84       28         56
## 5 64.76       52         63
## 6 68.69       53         59
## 7 72.61       60         62
## 8 76.54       59         60</code></pre>
<p>那麼彙總型二項分佈數據，其飽和模型的對數似然其實就是</p>
<p><span class="math display">\[
\ell_s = \sum_{i = 1}^n\{ \log\binom{n_i}{y_i} + y_i\log(\tilde{\pi_i}) + (n_i - y_i)\log(1 - \tilde{\pi_i}) \}
\]</span></p>
<p>假設此時我們給這個數據擬合一個非飽和模型，該模型告訴我們每個分類組中的預測百分比是 <span class="math inline">\(\hat\pi_i, i = 1, \dots, n\)</span>，那麼這個非飽和模型的對數似然其實是</p>
<p><span class="math display">\[
\ell_c = \sum_{i = 1}^n\{ \binom{n_i}{y_i} + y_i\log(\hat\pi_i) + (n_i - y_i)\log(1-\hat\pi_i)\}
\]</span></p>
<p>那麼這個非飽和模型的模型偏差 (deviance) 就等於</p>
<p><span class="math display">\[
\begin{aligned}
S &amp; = -2(\ell_c - \ell_s) \\
  &amp; = 2\sum_{i = 1}^n\{ y_i\log(\frac{\tilde{\pi_i}}{\hat\pi_i}) + (n_i - y_i)\log(\frac{1-\tilde{\pi_i}}{1-\hat\pi_i}) \}
\end{aligned}
\]</span></p>
<p>從上面這個表達式不難看出，模型偏差值的大小，將會隨着模型預測值的變化而變化，如果它更加接近飽和模型的預測值 (飽和模型的預測值其實就等於觀測值)，那麼模型的偏差就會比較小。如果你的彙總型數據擬合了你認爲合適的模型以後，你發現它的模型偏差值很大，那麼就意味着你的模型預測值其實和觀測值相去甚遠，模型和觀測值的擬合度應該不理想。對於彙總型數據來說，模型偏差值，其實等價於將你擬合的模型和飽和模型之間做子集對數似然比檢驗 (profile log-likelihood ratio test)。漸進來說 (asymptotically)，這個子集對數似然比檢驗的結果，會服從自由度爲 <span class="math inline">\(n-p\)</span> 的 <span class="math inline">\(\chi^2\)</span> 分佈，其中 <span class="math inline">\(n, p\)</span> 分別是飽和模型和你擬合的模型中被估計參數的個數。</p>
</div>
</div>
<div id="gof" class="section level2">
<h2><span class="header-section-number">46.4</span> 個人數據擬合模型的優度檢驗</h2>
<p>在上文中已經提到了，當你的數據不再是彙總型二項分佈數據，而是個人二項分佈數據 (individual binary data) 時，模型偏差 (deviance) 無法用來評價你建立的模型。這樣的數據其實比彙總型二項分佈數據更加常見，當模型中一旦需要加入一個連續型變量時，數據就只能被表達爲個人二項分佈數據。對於個人二項分佈數據模型擬合度比較，最常用的方法是 <span class="citation">(Hosmer and Lemesbow <a href="#ref-hosmer1980goodness" role="doc-biblioref">1980</a>)</span> 提出的模型擬合優度檢驗法 (goodness of fit)。該方法的主要思想是，把個人二項分佈數據模型獲得的個人預測值 (model predicted probabilities) <span class="math inline">\(\hat\pi_i\)</span> 進行人爲的分組，把預測值數據強行變成彙總型二項分佈數據，那麼觀測值的樣本量即使增加到無窮大，也不會使得模型中組別增加到無窮大，從而可以規避</p>
<p>在 R 裏面，進行邏輯迴歸模型的擬合優度檢驗的自定義方程如下，參考<a href="http://data.princeton.edu/wws509/r/c3s8.html">網站</a>：</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb520-1" title="1">hosmer &lt;-<span class="st"> </span><span class="cf">function</span>(y, fv, <span class="dt">groups=</span><span class="dv">10</span>, <span class="dt">table=</span><span class="ot">TRUE</span>, <span class="dt">type=</span><span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb520-2" title="2"> <span class="co"># A simple implementation of the Hosmer-Lemeshow test</span></a>
<a class="sourceLine" id="cb520-3" title="3">   q &lt;-<span class="st"> </span><span class="kw">quantile</span>(fv, <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span><span class="op">/</span>groups), <span class="dt">type=</span>type)</a>
<a class="sourceLine" id="cb520-4" title="4">   fv.g &lt;-<span class="st"> </span><span class="kw">cut</span>(fv, <span class="dt">breaks=</span>q, <span class="dt">include.lowest=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb520-5" title="5">   obs &lt;-<span class="st"> </span><span class="kw">xtabs</span>( <span class="op">~</span><span class="st"> </span>fv.g <span class="op">+</span><span class="st"> </span>y)</a>
<a class="sourceLine" id="cb520-6" title="6">   fit &lt;-<span class="st"> </span><span class="kw">cbind</span>( <span class="dt">e.0 =</span> <span class="kw">tapply</span>(<span class="dv">1</span><span class="op">-</span>fv, fv.g, sum), <span class="dt">e.1 =</span> <span class="kw">tapply</span>(fv, fv.g, sum))</a>
<a class="sourceLine" id="cb520-7" title="7">   <span class="cf">if</span>(table) <span class="kw">print</span>(<span class="kw">cbind</span>(obs,fit))</a>
<a class="sourceLine" id="cb520-8" title="8">   chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((obs<span class="op">-</span>fit)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>fit)</a>
<a class="sourceLine" id="cb520-9" title="9">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, groups<span class="dv">-2</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb520-10" title="10">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Hosmer-Lemeshow&quot;</span>,<span class="dt">groups=</span>groups,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a>
<a class="sourceLine" id="cb520-11" title="11"> }</a></code></pre></div>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb521-1" title="1"><span class="co"># lbw &lt;- read_dta(&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;)</span></a>
<a class="sourceLine" id="cb521-2" title="2">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="dt">file =</span> <span class="st">&quot;backupfiles/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb521-3" title="3">lbw<span class="op">$</span>race &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>race)</a>
<a class="sourceLine" id="cb521-4" title="4">lbw<span class="op">$</span>smoke &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>smoke)</a>
<a class="sourceLine" id="cb521-5" title="5">lbw<span class="op">$</span>ht &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>ht)</a>
<a class="sourceLine" id="cb521-6" title="6">Modelgof &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>lwt <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>ptl <span class="op">+</span><span class="st"> </span>ht <span class="op">+</span><span class="st"> </span>ui, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</a>
<a class="sourceLine" id="cb521-7" title="7"><span class="kw">hosmer</span>(lbw<span class="op">$</span>low, <span class="kw">fitted</span>(Modelgof))</a></code></pre></div>
<pre><code>##                  0  1        e.0        e.1
## [0.0273,0.0827] 19  0 17.8222227  1.1777773
## (0.0827,0.128]  17  2 16.9739017  2.0260983
## (0.128,0.201]   13  6 15.8285445  3.1714555
## (0.201,0.243]   18  1 14.6957098  4.3042902
## (0.243,0.279]   12  7 14.1062047  4.8937953
## (0.279,0.314]   12  7 13.3601242  5.6398758
## (0.314,0.387]   13  6 12.4628053  6.5371947
## (0.387,0.483]   12  7 10.8241660  8.1758340
## (0.483,0.594]    9 10  8.6901416 10.3098584
## (0.594,0.839]    5 13  5.2361795 12.7638205</code></pre>
<pre><code>##              test groups    chi.sq     pvalue
## 1 Hosmer-Lemeshow     10 9.6506834 0.29040407</code></pre>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb524-1" title="1"><span class="kw">hosmer</span>(lbw<span class="op">$</span>low, <span class="kw">fitted</span>(Modelgof), <span class="dt">group=</span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>##                 0  1       e.0        e.1
## [0.0273,0.128] 36  2 34.796124  3.2038756
## (0.128,0.243]  31  7 30.524254  7.4757458
## (0.243,0.314]  24 14 27.466329 10.5336711
## (0.314,0.483]  25 13 23.286971 14.7130287
## (0.483,0.839]  14 23 13.926321 23.0736789</code></pre>
<pre><code>##              test groups   chi.sq     pvalue
## 1 Hosmer-Lemeshow      5 2.435921 0.48698297</code></pre>
</div>
<div id="glm-practical-04" class="section level2">
<h2><span class="header-section-number">46.5</span> GLM Practical 04</h2>
<div id="回到之前的昆蟲數據嘗試評價該模型的擬合優度" class="section level3">
<h3><span class="header-section-number">46.5.1</span> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</h3>
<ol style="list-style-type: decimal">
<li>重新讀入昆蟲數據，擬合前一個練習中擬合過的模型，使用 <code>glm()</code> 命令。</li>
</ol>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb527-1" title="1">Insect &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;backupfiles/INSECT.RAW&quot;</span>, <span class="dt">header =</span>  <span class="ot">FALSE</span>, <span class="dt">sep =</span><span class="st">&quot;&quot;</span>, <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;dose&quot;</span>, <span class="st">&quot;n_deaths&quot;</span>, <span class="st">&quot;n_subjects&quot;</span>))</a>
<a class="sourceLine" id="cb527-2" title="2"><span class="co"># print(Insect)</span></a>
<a class="sourceLine" id="cb527-3" title="3">Insect &lt;-<span class="st"> </span>Insect <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb527-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> n_deaths<span class="op">/</span>n_subjects)</a>
<a class="sourceLine" id="cb527-5" title="5"></a>
<a class="sourceLine" id="cb527-6" title="6">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb527-7" title="7"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose, 
##     family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.14983  -0.22403   0.25301   0.70846   0.99107  
## 
## Coefficients:
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -14.086403   1.228393 -11.467 &lt; 2.2e-16 ***
## dose          0.236593   0.020303  11.653 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   4.61548  on 6  degrees of freedom
## AIC: 37.394
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>根據上面模型輸出的結果，檢驗是否有證據證明該模型對數據的擬合不佳。</li>
</ol>
<p>上面模型擬合的輸出結果中，可以找到最下面的模型偏差值的大小和相應的自由度： <code>Residual deviance:   4.6155  on 6  degrees of freedom</code>。如果我們要檢驗該模型中假設的前提條件之一–昆蟲死亡的對數比值 (on a log-odds scale) 和藥物濃度 (dose) 之間是線性關係（或者你也可以說，檢驗是否有證據證明該模型對數據擬合不佳），我們可以比較計算獲得的模型偏差值在自由度為 6 的卡方分布 (<span class="math inline">\(\chi^2_6\)</span>) 中出現的概率。這裡自由度 6 是由 <span class="math inline">\(n - p = 8 - 2\)</span> 計算獲得，其中 <span class="math inline">\(n\)</span> 是數據中觀察值個數，<span class="math inline">\(p\)</span> 是模型中估計的參數的個數。檢驗方法很簡單：</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb529-1" title="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">4.6155</span>, <span class="dt">df =</span> <span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.59398469</code></pre>
<p>所以，檢驗的結果，P 值就是 0.594，沒有任何證據反對零假設（模型擬合數據合理）。</p>
<ol start="3" style="list-style-type: decimal">
<li>試比較兩個模型對數據的擬合效果孰優孰劣：模型1，上面的模型；模型2，加入劑量的平方 (dose<sup>2</sup>)，作為新增的模型解釋變量。嵌套式模型之間的比較使用的是似然比檢驗法 (profile likelihood ratio test)，試着解釋這個比較方法和 Wald 檢驗之間的區別。</li>
</ol>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb531-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(n_deaths, n_subjects <span class="op">-</span><span class="st"> </span>n_deaths) <span class="op">~</span><span class="st"> </span>dose <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(dose<span class="op">^</span><span class="dv">2</span>), <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Insect)</a>
<a class="sourceLine" id="cb531-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(n_deaths, n_subjects - n_deaths) ~ dose + 
##     I(dose^2), family = binomial(link = logit), data = Insect)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8  
## -0.004545   0.634377  -0.691056  -0.681962   1.223967  -0.154036  -0.029880  -0.561968  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.4881722  9.8677198 -0.2522   0.8009
## dose        -0.1500054  0.3291786 -0.4557   0.6486
## I(dose^2)    0.0031871  0.0027273  1.1686   0.2426
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.26829  on 7  degrees of freedom
## Residual deviance:   3.18361  on 5  degrees of freedom
## AIC: 37.9621
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb533-1" title="1"><span class="kw">anova</span>(Model1, Model2)</a></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cbind(n_deaths, n_subjects - n_deaths) ~ dose
## Model 2: cbind(n_deaths, n_subjects - n_deaths) ~ dose + I(dose^2)
##   Resid. Df Resid. Dev Df Deviance
## 1         6    4.61548            
## 2         5    3.18361  1  1.43188</code></pre>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb535-1" title="1"><span class="co"># P-value for model comparison</span></a>
<a class="sourceLine" id="cb535-2" title="2"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(<span class="fl">1.43</span>, <span class="dt">df =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.23176444</code></pre>
<p>兩個模型比較的結果表明，無證據反對零假設（只用線性關係擬合數據是合理的），也就是說增加劑量的平方這一新的解釋變量並不能提升模型對數據的擬合程度。仔細觀察模型2的輸出結果中，可以發現 <code>I(dose^2)</code> 項的 Wald 檢驗結果是 <code>p = 0.24</code>，十分接近似然比檢驗的結果。因為它們兩者是漸近相同的 (asymptotically equivalent)。</p>
</div>
<div id="低出生體重數據" class="section level3">
<h3><span class="header-section-number">46.5.2</span> 低出生體重數據</h3>
<ol style="list-style-type: decimal">
<li>讀入該數據，試分析數據中和低出生體重可能相關的變量：</li>
</ol>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb537-1" title="1">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb537-2" title="2"><span class="kw">head</span>(lbw)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 11
##      id   low   age   lwt      race         smoke   ptl    ht    ui   ftv   bwt
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    85     0    19   182 2 [black] 0 [nonsmoker]     0     0     1     0  2523
## 2    86     0    33   155 3 [other] 0 [nonsmoker]     0     0     0     3  2551
## 3    87     0    20   105 1 [white] 1 [smoker]        0     0     0     1  2557
## 4    88     0    21   108 1 [white] 1 [smoker]        0     0     1     2  2594
## 5    89     0    18   107 1 [white] 1 [smoker]        0     0     1     0  2600
## 6    91     0    21   124 3 [other] 0 [nonsmoker]     0     0     0     0  2622</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>擬合一個這樣的邏輯回歸模型：結果變量使用低出生體重與否 <code>low</code>，解釋變量使用母親最後一次月經時體重 <code>lwt</code> (磅)。</li>
</ol>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb539-1" title="1">M &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</a>
<a class="sourceLine" id="cb539-2" title="2"><span class="kw">summary</span>(M)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ lwt, family = binomial(link = logit), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.09482  -0.90217  -0.80197   1.36105   1.98141  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  0.9957634  0.7852434  1.2681  0.20476  
## lwt         -0.0140371  0.0061685 -2.2756  0.02287 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 228.708  on 187  degrees of freedom
## AIC: 232.708
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb541-1" title="1"><span class="kw">logistic.display</span>(M)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## lwt (cont. var.) 0.99 (0.97,1)  0.023          0.015     
##                                                          
## Log-likelihood = -114.354
## No. of observations = 189
## AIC value = 232.7081</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>利用 <code>lowess</code> 平滑曲線作圖，評價在 logit 單位上，<code>lwt</code> 和 <code>low</code> 之間是否可以認為是線性關係。</li>
</ol>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb543-1" title="1">pi &lt;-<span class="st"> </span>M<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb543-2" title="2"></a>
<a class="sourceLine" id="cb543-3" title="3"><span class="co"># with(lbw, scatter.smooth(lwt, pi, pch = 20, span = 0.4, lpars =</span></a>
<a class="sourceLine" id="cb543-4" title="4"><span class="co">#                  list(col = &quot;blue&quot;, lwd = 3, lty = 1), col=rgb(0,0,0,0.004),</span></a>
<a class="sourceLine" id="cb543-5" title="5"><span class="co">#                  xlab = &quot;Mother&#39;s weight at last menstural period (lbs)&quot;,</span></a>
<a class="sourceLine" id="cb543-6" title="6"><span class="co">#                  ylab = &quot;Logit(probability) of being low birth weight&quot;,</span></a>
<a class="sourceLine" id="cb543-7" title="7"><span class="co">#                  frame = FALSE))</span></a>
<a class="sourceLine" id="cb543-8" title="8"></a>
<a class="sourceLine" id="cb543-9" title="9"><span class="kw">plot</span>(lbw<span class="op">$</span>lwt, lbw<span class="op">$</span>low, <span class="dt">main=</span><span class="st">&quot;Lowess smoother plot</span><span class="ch">\n</span><span class="st"> of the prob of having a low brith weight baby&quot;</span>, </a>
<a class="sourceLine" id="cb543-10" title="10">     <span class="dt">xlab =</span> <span class="st">&quot;Weight at at last menstural period (lbs)&quot;</span>, </a>
<a class="sourceLine" id="cb543-11" title="11">     <span class="dt">ylab =</span> <span class="st">&quot;Probability&quot;</span>)</a>
<a class="sourceLine" id="cb543-12" title="12"><span class="kw">lines</span>(<span class="kw">lowess</span>(lbw<span class="op">$</span>lwt, lbw<span class="op">$</span>low, <span class="dt">f =</span> <span class="fl">0.7</span>), <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb543-13" title="13"><span class="kw">points</span>(lbw<span class="op">$</span>lwt, pi)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:GLM-prac04-06"></span>
<img src="bookdown_files/figure-html/GLM-prac04-06-1.png" alt="The loess plot of the observed proportion with low birth weight against mother's weight at last menstural period. Span = 0.6" width="100%" />
<p class="caption">
圖 46.1: The loess plot of the observed proportion with low birth weight against mother’s weight at last menstural period. Span = 0.6
</p>
</div>
<p>Lowess 平滑曲線提示模型的擬合值(<code>fitted.values</code>)有一些變動，由於樣本採樣方法等原因，這是無法避免的。但是總體來說，擬合值和平滑曲線基本在同一個步調上，從該圖來看，認為母親的最後一次月經時體重和是否生下低出生體重兒的概率的 logit 之間的關係是線性的應該不是太大的問題。</p>
</div>
</div>
</div>
<div id="計數型因變量-poisson-regression" class="section level1">
<h1><span class="header-section-number">第 47 章</span> 計數型因變量 Poisson regression</h1>
<p>計數型變量在醫學研究中也十分常見，下面是一些例子：</p>
<ol style="list-style-type: decimal">
<li>某個呼吸科診所的患者中，每個人在過去一個月中哮喘發作的次數；</li>
<li>癲癇患者在過去一年中癲癇發作次數；</li>
<li>接受腦部 CT 掃描的患者中，每個人被診斷出顱內腫瘤個數。</li>
</ol>
<div id="泊松-glm" class="section level2">
<h2><span class="header-section-number">47.1</span> 泊松 GLM</h2>
<p>一個計數型的隨機變量，只能取大於等於零的正整數，<span class="math inline">\(0,1,\cdots\)</span>。泊松模型可以用於計數型數據的迴歸模型的構建：</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;\sim \text{Po}(\mu) \\
\text{P} (Y = y) &amp; = \frac{\mu^y e^{-\mu}}{y!}
\end{aligned}
\]</span></p>
<p>所以，一個泊松迴歸，默認的前提是因變量 <span class="math inline">\(Y\)</span> 服從一個以預測變量 <span class="math inline">\(x_1, \cdots, x_p\)</span> 爲條件的泊松分佈。其標準鏈接方程是 <span class="math inline">\(\theta=\text{log}(\mu)\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp; \sim \text{Po}(\mu_i) \\
\text{log}(\mu_i) &amp; = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>觀測對象 1，用模型中全部的預測變量 <span class="math inline">\(\mathbf{x_1}=(x_{11},\cdots,x_{1p})\)</span> 計算獲得的擬合值，和另一個觀測對象 0 的擬合值之比爲：</p>
<p><span class="math display">\[
\begin{aligned}
  &amp; \frac{\text{exp}(\alpha + \beta_1 x_{11} + \cdots + \beta_p x_{1p})}{\text{exp}(\alpha + \beta_1 x_{01} + \cdots + \beta_p x_{0p})} \\
= &amp; exp(\beta_1(x_{11}-x_{01}) + \cdots + \beta_p(x_{1p} - x_{0p}))
\end{aligned}
\]</span></p>
<p>其中，</p>
<ul>
<li>線性預測方程 linear predictor 中的截距 <span class="math inline">\(\alpha\)</span> 的含義是，<strong>當所有的預測變量均等於零 <span class="math inline">\(\mathbf{x_1} = 0\)</span></strong> 時，<strong>因變量 <span class="math inline">\(Y\)</span> 的均值之對數</strong>。</li>
<li><span class="math inline">\(\beta_1\)</span> 的含義是，<strong>其餘預測變量保持不變時，預測變量 <span class="math inline">\(x_1\)</span> 每增加一個單位時，因變量變化量的對數</strong>。</li>
<li>迴歸係數的指數 (自然底數) 大小，可以被理解爲是<strong>率比 (rate ratio)</strong> (詳見下一章率的 GLM)。</li>
</ul>
</div>
<div id="泊松迴歸實例" class="section level2">
<h2><span class="header-section-number">47.2</span> 泊松迴歸實例</h2>
<p>下列數據來自 <a href="https://stats.idre.ucla.edu/r/dae/poisson-regression/">UCLA 的統計學網站</a>。數據內容是某高中全部學生，獲獎的次數。預測變量包括，1) 獲獎種類 “一般 General”，“學術類 Academic”，“技能類 Vocational”；和所有學生期末數學考試分數。</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb544-1" title="1">p &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;backupfiles/poisson_sim.csv&quot;</span>)</a></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   id = col_double(),
##   num_awards = col_double(),
##   prog = col_double(),
##   math = col_double()
## )</code></pre>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb546-1" title="1">p &lt;-<span class="st"> </span><span class="kw">within</span>(p, {</a>
<a class="sourceLine" id="cb546-2" title="2">  prog &lt;-<span class="st"> </span><span class="kw">factor</span>(prog, <span class="dt">levels=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;General&quot;</span>, <span class="st">&quot;Academic&quot;</span>,</a>
<a class="sourceLine" id="cb546-3" title="3">                                                     <span class="st">&quot;Vocational&quot;</span>))</a>
<a class="sourceLine" id="cb546-4" title="4">  id &lt;-<span class="st"> </span><span class="kw">factor</span>(id)</a>
<a class="sourceLine" id="cb546-5" title="5">})</a>
<a class="sourceLine" id="cb546-6" title="6"><span class="kw">summary</span>(p)</a></code></pre></div>
<pre><code>##        id        num_awards           prog          math       
##  1      :  1   Min.   :0.00   General   : 45   Min.   :33.000  
##  2      :  1   1st Qu.:0.00   Academic  :105   1st Qu.:45.000  
##  3      :  1   Median :0.00   Vocational: 50   Median :52.000  
##  4      :  1   Mean   :0.63                    Mean   :52.645  
##  5      :  1   3rd Qu.:1.00                    3rd Qu.:59.000  
##  6      :  1   Max.   :6.00                    Max.   :75.000  
##  (Other):194</code></pre>
<p>下面的代碼擬合因變量爲獲獎次數，預測變量爲獲獎種類 (分類) 和數學成績 (連續) 的泊松分佈，泊松分佈默認的鏈接方程就是 <span class="math inline">\(\text{log}\)</span>，所以你可以像第一行那樣把鏈接方程部分省略。結果也是一樣的。</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb548-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>, <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb548-2" title="2">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb548-3" title="3"><span class="kw">summary</span>(m1); <span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = &quot;poisson&quot;, data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = poisson(link = log), 
##     data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>輸出結果的迴歸係數部分，</p>
<ul>
<li>該學校學生獲得學術類獎項的平均次數和獲得一般獎項的平均次數的比值是 <span class="math inline">\(\text{exp}(1.6094) = 4.999\)</span>，所以獲得的學術類獎平均次數要高於一般獎次數 <span class="math inline">\(390\%\)</span>；</li>
<li>獲得技能類獎的平均次數和一般獎平均次數的比值是 <span class="math inline">\(\text{exp}(0.1823) = 1.199\)</span>，也就是高出了 <span class="math inline">\(19.9\%\)</span>；</li>
<li>該校學生獲得一般類獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094) = 0.20\)</span> 次；</li>
<li>該校學生獲得學術獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094 + 1.6094) = 1\)</span> 次；(一人一次夠流弊)</li>
<li>該校學生獲得技能類獎的次數平均每人是 <span class="math inline">\(\text{exp}(-1.6094 + 0.182) = 0.24\)</span> 次。</li>
</ul>
<p>看來該校師生很重視學術。</p>
<p>當然也可以用下面定義的函數來幫助我們計算上面這些數值，及其信賴區間。</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb551-1" title="1">glm.RR &lt;-<span class="st"> </span><span class="cf">function</span>(GLM.RESULT, <span class="dt">digits =</span> <span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb551-2" title="2"></a>
<a class="sourceLine" id="cb551-3" title="3">    <span class="cf">if</span> (GLM.RESULT<span class="op">$</span>family<span class="op">$</span>family <span class="op">==</span><span class="st"> &quot;binomial&quot;</span>) {</a>
<a class="sourceLine" id="cb551-4" title="4">        LABEL &lt;-<span class="st"> &quot;OR&quot;</span></a>
<a class="sourceLine" id="cb551-5" title="5">    } <span class="cf">else</span> <span class="cf">if</span> (GLM.RESULT<span class="op">$</span>family<span class="op">$</span>family <span class="op">==</span><span class="st"> &quot;poisson&quot;</span>) {</a>
<a class="sourceLine" id="cb551-6" title="6">        LABEL &lt;-<span class="st"> &quot;RR&quot;</span></a>
<a class="sourceLine" id="cb551-7" title="7">    } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb551-8" title="8">        <span class="kw">stop</span>(<span class="st">&quot;Not logistic or Poisson model&quot;</span>)</a>
<a class="sourceLine" id="cb551-9" title="9">    }</a>
<a class="sourceLine" id="cb551-10" title="10"></a>
<a class="sourceLine" id="cb551-11" title="11">    COEF      &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw">coef</span>(GLM.RESULT)</a>
<a class="sourceLine" id="cb551-12" title="12">    CONFINT   &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw">confint</span>(GLM.RESULT)</a>
<a class="sourceLine" id="cb551-13" title="13">    TABLE     &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">coef=</span>COEF, CONFINT)</a>
<a class="sourceLine" id="cb551-14" title="14">    TABLE.EXP &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">exp</span>(TABLE), digits)</a>
<a class="sourceLine" id="cb551-15" title="15"></a>
<a class="sourceLine" id="cb551-16" title="16">    <span class="kw">colnames</span>(TABLE.EXP)[<span class="dv">1</span>] &lt;-<span class="st"> </span>LABEL</a>
<a class="sourceLine" id="cb551-17" title="17"></a>
<a class="sourceLine" id="cb551-18" title="18">    TABLE.EXP</a>
<a class="sourceLine" id="cb551-19" title="19">}</a></code></pre></div>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb552-1" title="1"><span class="kw">glm.RR</span>(m1)</a></code></pre></div>
<pre><code>##                 RR 2.5 % 97.5 %
## (Intercept)    0.2  0.10   0.36
## progAcademic   5.0  2.68  10.63
## progVocational 1.2  0.51   2.94</code></pre>
</div>
<div id="過度離散-overdispersion" class="section level2">
<h2><span class="header-section-number">47.3</span> 過度離散 overdispersion</h2>
<p>泊松分佈的前提條件之一是，方差和均值相等。這是一個<strong>非常強的假設</strong>，很多計數型數據其實是無法滿足這個條件的。許多時候 (包括上面的例子也是) 方差要大於或者小於均值：</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb554-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;Academic&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  105  1      1       1.279  0      6</code></pre>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb556-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;General&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  45   0.2    0       0.405  0      1</code></pre>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb558-1" title="1">epiDisplay<span class="op">::</span><span class="kw">summ</span>(p<span class="op">$</span>num_awards[p<span class="op">$</span>prog <span class="op">==</span><span class="st"> &quot;Vocational&quot;</span>], <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>##  obs. mean   median  s.d.   min.   max.  
##  50   0.24   0       0.517  0      2</code></pre>
<p>試想一下，實際的數據中其實是經常出現這樣的違反泊松分佈前提的計數型數據的。例如某兩個觀測對象，如果他們二者的線性預測方程給出相等的結果 (他們各自的預測變量可以完全不同)，會被認爲服從相同均值，相同方差的泊松分佈，這顯然是不合理的。例如本章用到的學校學生獲獎的例子，有的學生成績好，那麼獲得學術類獎的平均次數 (及其方差) 自然和成績排在後面的學生不同，強制這樣的兩個學生服從相同均值，相同方差的泊松分佈顯然是不合情理的。手工好的學生，可能更傾向於獲得更多得技能類獎。實際情況下，還有許許多多其他的未知因素會影響學生獲獎的次數，例如家庭教育背景的不同，有些學生鋼琴獲獎多，因爲他每天都去練習彈鋼琴等等，這些都是沒有被收集到的數據。</p>
<p>真實情況應該是這樣的，當有其他的我們不知道的因素存在時，這些因素會導致某些人的均值高於其他人。如果對象 <span class="math inline">\(i\)</span> 的因變量 <span class="math inline">\(Y_i\)</span> 服從均值爲 <span class="math inline">\(\mu_i\)</span> 的泊松分佈，那麼對於所有的 <span class="math inline">\(\mu_i\)</span>，其均值 (overall mean) 是 <span class="math inline">\(\mu\)</span>，方差 (overall variance) 是 <span class="math inline">\(\sigma^2\)</span>。這是一個典型的隨機效應模型 random effect model，我們會在後面的 hierarchical data analysis 再深入討論，但是這裏的重點是，每個觀測對象自己的均值 <span class="math inline">\(\mu_i\)</span>，是我們在普通泊松迴歸中忽略掉的隨機共變量 (the effects of omitted covariates)。</p>
<p>所以樣本數據來自的人羣如果共同均值 (或者叫邊際效應均值，marginal mean) 爲 <span class="math inline">\(\mu\)</span>：</p>
<p><span class="math display">\[
E(Y_i) = E(E(Y_i | \mu_i)) = E(\mu_i) = \mu
\]</span></p>
<p>和共同方差 (邊際效應方差) ，需要用到 <a href="https://en.wikipedia.org/wiki/Law_of_total_variance">總體方差法則 (Law of total variance)</a> 概念：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(Y_i) &amp; = E(\text{Var}(Y_i | \mu_i)) + \text{Var}(E(Y_i | \mu_i)) \\
                &amp; = E(\mu_i) + \text{Var}(\mu_i) \\
                &amp; = \mu + \sigma^2
\end{aligned}
\]</span></p>
<div id="過度離散怎麼查" class="section level3">
<h3><span class="header-section-number">47.3.1</span> 過度離散怎麼查？</h3>
<p>如果，我們的泊松回歸模型中的共變量全部都是分類型變量，我們可以把觀測值 <span class="math inline">\(Y\)</span> 對每一個分類變量分別作簡單的數據總結，觀察其均值和方差是否可以認為大致相同。但是許多時候模型中不會只有分類型變量。</p>
<p>R 輸出的結果中的 模型偏差 deviance，可以用來初步判斷整體模型的擬合優度。如果模型偏差除以殘差獲得的殘差偏差 (residual deviance) 足夠小，說明擬合的模型跟數據本身比較接近，也就是模型和數據擬合程度較好，反之則提示模型本身具有較高的過度離散 overdispersion。另外，模型偏差由於在個人數據 (individual data) 情況下不適用 (因為模型偏差值就不再服從卡方分佈了)，下面的檢驗結果僅僅只能作為極為微弱的參考證據。此時應該推薦使用 Pearson 的模型擬合檢驗。如果 Pearson 統計量，除以殘差的自由度獲得的值遠大於 1，就提示存在過度離散。</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb560-1" title="1"><span class="kw">with</span>(m1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb560-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df           p
## [1,]    234.45997 197 0.034961171</code></pre>
<p>Goodness of fit 檢驗結果 提示本模型<strong>可能存在過度離散</strong>，數據擬合度不理想。值得注意的是如果樣本很大時，模型偏差的檢驗統計量<strong>將不再服從卡方分佈</strong>，應用的時候一定要慎重。</p>
</div>
<div id="負二項式分佈模型-negative-binomial-model" class="section level3">
<h3><span class="header-section-number">47.3.2</span> 負二項式分佈模型 negative binomial model</h3>
<p>如果普通泊松迴歸模型擬合數據時，發現數據本身有過度離散的嫌疑，那麼建議使用負二項式分佈模型來重新擬合數據。負二項式分佈模型其實是泊松分佈的擴展版本，即考慮了個體的方差和均值的隨機效應 subject-specific random effect。如果設每個觀測對象的隨機效應部分爲 <span class="math inline">\(a_i\)</span>，預測變量爲向量 <span class="math inline">\(\mathbf{x_i} = (x_{i1}, \cdots, x_{ip})\)</span>，那麼因變量 <span class="math inline">\(Y_i\)</span> 服從均值爲 <span class="math inline">\(\text{exp}(\beta^T\mathbf{x_i}+a_i)\)</span> 泊松分佈。在負二項式分佈中，個體的隨機效應部分的自然底數的指數 <span class="math inline">\(e^{a_i}\)</span> 其實是服從均值爲 1， 方差爲 <span class="math inline">\(\alpha\)</span> 的<a href="https://cosx.org/2013/01/lda-math-gamma-function/">伽馬分佈 (gamma distribution)</a>。<span class="math inline">\(\alpha\)</span> 越大，说明过度离散越明显。</p>
<p>接下來用相同的數據，使用負二項式分佈模型在 R 裏作模型的擬合，你就會看到差別：</p>
<p>R 裏擬合負二項式分佈模型的函數 <code>glm.nb</code> 在基本包 <code>MASS</code> 裏。</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb562-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">glm.nb</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">data =</span> p)</a>
<a class="sourceLine" id="cb562-2" title="2">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb562-3" title="3"><span class="kw">summary</span>(m1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm.nb(formula = num_awards ~ prog, data = p, init.theta = 1.72267107, 
##     link = log)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.25581  -0.67036  -0.61517   0.00000   2.32349  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.35215 -4.5703 4.87e-06 ***
## progAcademic    1.60944    0.37291  4.3159 1.59e-05 ***
## progVocational  0.18232    0.46793  0.3896   0.6968    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(1.7227) family taken to be 1)
## 
##     Null deviance: 211.264  on 199  degrees of freedom
## Residual deviance: 171.066  on 197  degrees of freedom
## AIC: 406.532
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  1.723 
##           Std. Err.:  0.717 
## 
##  2 x log-likelihood:  -398.532</code></pre>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb564-1" title="1"><span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = num_awards ~ prog, family = poisson(link = log), 
##     data = p)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.41421  -0.69282  -0.63246   0.00000   3.39133  
## 
## Coefficients:
##                Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)    -1.60944    0.33333 -4.8283 1.377e-06 ***
## progAcademic    1.60944    0.34733  4.6338 3.590e-06 ***
## progVocational  0.18232    0.44096  0.4135    0.6793    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 287.672  on 199  degrees of freedom
## Residual deviance: 234.460  on 197  degrees of freedom
## AIC: 416.515
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>仔細比較普通泊松分佈迴歸和負二項式分佈迴歸的輸出結果，你會發現</p>
<ol style="list-style-type: decimal">
<li>迴歸係數的計算是完全相同的 (由於我們只放了一個簡單的分類型變量作爲預測變量，一般來說泊松迴歸和負二項式分佈迴歸計算的迴歸係數會有些許不同)；</li>
<li>另外一個變化是標準誤的估計量在負二項式分佈模型中明顯變大了，這就是我們放寬了前提條件，允許模型考慮個體的隨機效應的體現。如果泊松模型被數據本身的過度離散影響顯著，那麼泊松迴歸計算獲得的參數標準無是偏低的；</li>
<li>負二項式分佈迴歸的結果最底下出現的 <code>Theta:  1.723</code> 部分，它的倒數是前面提到的歌廳效應部分 <span class="math inline">\(a_i\)</span> 服從的伽馬分佈的方差 <span class="math inline">\(\alpha\)</span>。它是關鍵的離散程度參數 (dispersion parameter)。在 STATA 裏，如果用 <code>nbreg</code> 擬合負二項式分佈迴歸的模型，輸出的結果最底下會有 <span class="math inline">\(\alpha\)</span> 值的報告，注意它和 R 輸出的 <code>Theta</code> 結果互爲倒數。另外，STATA 的輸出結果還會對 <span class="math inline">\(\alpha = 0\)</span> 直接進行檢驗。在 R 裏面則需要給兩個模型分別進行擬合優度檢驗，多數情況下你會發現負二項式分佈迴歸的模型更加擬合數據：</li>
</ol>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb566-1" title="1"><span class="kw">with</span>(m1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb566-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df          p
## [1,]    171.06608 197 0.90901874</code></pre>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb568-1" title="1"><span class="kw">with</span>(m2, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb568-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance  df           p
## [1,]    234.45997 197 0.034961171</code></pre>
<p>另一種獲取沒有被低估的迴歸係數的標準誤的方法來自穩健統計學手段。在 R 裏，擬合完普通泊松迴歸以後，用 <code>sandwich</code> 包裏的 <code>vcovHC()</code> 命令進行穩健的參數誤差估計 (具體說是夾心方差矩陣估計 sandwich estimator of variance)：</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb570-1" title="1">m2 &lt;-<span class="st"> </span><span class="kw">glm</span>(num_awards <span class="op">~</span><span class="st"> </span>prog, <span class="dt">family=</span><span class="kw">poisson</span>(<span class="dt">link =</span> log), <span class="dt">data=</span>p)</a>
<a class="sourceLine" id="cb570-2" title="2">cov.m2 &lt;-<span class="st"> </span><span class="kw">vcovHC</span>(m2, <span class="dt">type =</span> <span class="st">&quot;HC0&quot;</span>)</a>
<a class="sourceLine" id="cb570-3" title="3">std.err &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(cov.m2))</a>
<a class="sourceLine" id="cb570-4" title="4">robust.est &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">Estimate=</span> <span class="kw">coef</span>(m2), <span class="st">&quot;Robust SE&quot;</span> =<span class="st"> </span>std.err,</a>
<a class="sourceLine" id="cb570-5" title="5"><span class="st">&quot;Pr(&gt;|z|)&quot;</span> =<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(<span class="kw">coef</span>(m2)<span class="op">/</span>std.err), <span class="dt">lower.tail=</span><span class="ot">FALSE</span>),</a>
<a class="sourceLine" id="cb570-6" title="6"><span class="dt">LL =</span> <span class="kw">coef</span>(m1) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.err,</a>
<a class="sourceLine" id="cb570-7" title="7"><span class="dt">UL =</span> <span class="kw">coef</span>(m1) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.err)</a>
<a class="sourceLine" id="cb570-8" title="8">robust.est</a></code></pre></div>
<pre><code>##                   Estimate  Robust SE      Pr(&gt;|z|)          LL         UL
## (Intercept)    -1.60943791 0.29814240 6.7305731e-08 -2.19379701 -1.0250788
## progAcademic    1.60943791 0.32296809 6.2517920e-07  0.97642045  2.2424554
## progVocational  0.18232156 0.42426407 6.6738767e-01 -0.64923602  1.0138791</code></pre>
</div>
</div>
</div>
<div id="率的廣義線性迴歸-poisson-glm-for-rates" class="section level1">
<h1><span class="header-section-number">第 48 章</span> 率的廣義線性迴歸 Poisson GLM for rates</h1>
<div id="醫學中的率" class="section level2">
<h2><span class="header-section-number">48.1</span> 醫學中的率</h2>
<p>前章介紹的事件發生次數，使用的是泊松迴歸。本章介紹同樣利用泊松迴歸，對事件發生率類型數據的泊松迴歸模型。常見的率的數據例如：</p>
<ul>
<li>肺癌發病率</li>
<li>工廠職工的死亡率</li>
<li>術後後遺症的發生率</li>
</ul>
<p>下列數據來自英國醫生調查 (British doctors study)，研究的是男性醫生中吸菸與否和冠心病死亡之間的關係。最後一列是每組觀測對象被追蹤的人年 (person-year)。</p>
<pre><code>##    agegrp     smokes deaths  pyrs
## 1   35-44     Smoker     32 52407
## 2   45-54     Smoker    104 43248
## 3   55-64     Smoker    206 28612
## 4   65-74     Smoker    186 12663
## 5     75+     Smoker    102  5317
## 6   35-44 Non-smoker      2 18790
## 7   45-54 Non-smoker     12 10673
## 8   55-64 Non-smoker     28  5710
## 9   65-74 Non-smoker     28  2585
## 10    75+ Non-smoker     31  1462</code></pre>
<p>這是一個已經被整理過的數據，我們沒有辦法從這樣的數據還原到每個觀察對象的個人水平數據。冠心病的粗死亡率 (crude death rate) 可以被計算如下表 (忽略年齡分組)，此時默認的前提是死亡事件在追蹤的過程中發生的概率不發生改變。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:PoissonRates">表 48.1: </span>Death rates due to CHD in smokers and non-smokers, collapsed over age group
</caption>
<thead>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Person-years of follow-up
</th>
<th style="text-align:center;">
CHD deaths
</th>
<th style="text-align:center;">
Death Rate per 1000 person-years
</th>
<th style="text-align:center;">
Rate Ratios
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Non-smokers
</td>
<td style="text-align:center;">
39220
</td>
<td style="text-align:center;">
101
</td>
<td style="text-align:center;">
2.58
</td>
<td style="text-align:center;">
1.00
</td>
</tr>
<tr>
<td style="text-align:center;">
Smokers
</td>
<td style="text-align:center;">
142247
</td>
<td style="text-align:center;">
630
</td>
<td style="text-align:center;">
4.43
</td>
<td style="text-align:center;">
1.72
</td>
</tr>
</tbody>
</table>
</div>
<div id="泊松過程" class="section level2">
<h2><span class="header-section-number">48.2</span> 泊松過程</h2>
<p>設 <span class="math inline">\(Y\)</span> 是代表某段時間 <span class="math inline">\(t\)</span> 內<strong>事件發生次數 (死亡)</strong> 的隨機變量。如果可以假設：</p>
<ul>
<li>每次事件的發生，是互相獨立的，即在沒有重疊的時間線上，每個事件的發生是隨機的。</li>
<li>在一個無限小的時間段 <span class="math inline">\(\delta t\)</span> 內，事件發生的概率是 <span class="math inline">\(\lambda\times\delta t\)</span>，其中 <span class="math inline">\(\delta t \rightarrow 0\)</span>。</li>
</ul>
<p>那麼根據泊松分佈 (Section <a href="01-Probability.html#poisson">6</a>) 的定義，在這個時間段內，隨機變量 <span class="math inline">\(Y\)</span> 事件發生次數服從泊松分佈：</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp; \sim \text{Po}(\mu) \\
\text{Where } \mu &amp; = \lambda t, \text{ and } \lambda \text{ is the Rate}
\end{aligned}
\]</span></p>
<p>所以，從泊松過程可以看到，我們關心的參數是事件發生率 <span class="math inline">\(\lambda\)</span>。</p>
</div>
<div id="率的模型" class="section level2">
<h2><span class="header-section-number">48.3</span> 率的模型</h2>
<p>既然關心的參數只是發生率，且我們已知泊松分佈是指數分佈的家族成員，可以用廣義線性模型的概念來建模。</p>
<ol style="list-style-type: decimal">
<li>因變量分佈，distribution of dependent variable <span class="math display">\[Y_i \sim \text{Po}(\mu_i), \text{ where } \mu_i = \lambda_i t_i\]</span></li>
<li>線性預測方程，linear predictor <span class="math display">\[\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>標準鏈接方程，canonical link function <span class="math display">\[\text{log}(\lambda_i) = \text{log}(\frac{\mu_i}{t_i})\]</span></li>
</ol>
<p>所以，將率的模型整理一下，就變成了</p>
<p><span class="math display">\[
\begin{aligned}
\text{log}(\mu_i) - \text{log}(t_i) &amp; = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip} \\
\text{log}(\mu_i) &amp; = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>你可以看到，時間項的對數部分 <span class="math inline">\(\text{log}(t_i)\)</span> 其實是被移到線性預測方程的右邊跟參數放在一起的，只是<strong>它的迴歸係數被強制爲 <span class="math inline">\(1\)</span></strong>。這個時間項被叫做 <strong>補償項 (offset)</strong>。這樣我們就成功地擬合了用於求事件發生率的一個泊松迴歸模型。在 R 裏，你可以用 <code>glm()</code> 命令的 <code>offset =</code> 選項功能，也可以把 <code>offset(log(Person-year))</code> 作爲線性預測方程的一部分把時間項取對數以後放進模型裏面。</p>
</div>
<div id="率的-glm" class="section level2">
<h2><span class="header-section-number">48.4</span> 率的 GLM</h2>
<p>所以我們一起來把率的 GLM 正式定義一下，它包含三個部分：</p>
<ol style="list-style-type: decimal">
<li>可被認爲互相獨立的因變量觀測值的分佈服從泊松分佈 <span class="math display">\[Y_i \sim \text{Po}(\mu_i)\]</span> <br> 其中 <span class="math inline">\(E(Y_i) = \mu_i = \lambda_i t_i\)</span>，<span class="math inline">\(t_i\)</span> 是第 <span class="math inline">\(i\)</span> 個觀察對象 (或者觀察組) 的追蹤人年 (person-time)。</li>
<li>線性預測方程 <span class="math display">\[\eta_i = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}\]</span></li>
<li>鏈接方程是均值的對數方程 <span class="math display">\[\text{log}(\mu_i) = \eta_i\]</span></li>
</ol>
<p>和分組型二項分佈數據相似，如果泊松 GLM 擬合的數據也是分組型數據，如本章開頭的英國醫生隊列數據。那麼模型偏差值 (deviance) 可以用來衡量模型擬合的好壞。在零假設條件下，模型偏差值服從自由度爲 <span class="math inline">\(n-p\)</span> 的卡方分佈 (這裏的 <span class="math inline">\(n\)</span> 是分組型數據中的“組的數量”，也就是飽和模型中參數的數量，<span class="math inline">\(p\)</span> 是擬合的線性預測方程中參數的數量)。</p>
</div>
<div id="實戰演練" class="section level2">
<h2><span class="header-section-number">48.5</span> 實戰演練</h2>
<p>數據是本章開頭使用的英國醫生隊列</p>
<pre><code>##    agegrp     smokes deaths  pyrs
## 1   35-44     Smoker     32 52407
## 2   45-54     Smoker    104 43248
## 3   55-64     Smoker    206 28612
## 4   65-74     Smoker    186 12663
## 5     75+     Smoker    102  5317
## 6   35-44 Non-smoker      2 18790
## 7   45-54 Non-smoker     12 10673
## 8   55-64 Non-smoker     28  5710
## 9   65-74 Non-smoker     28  2585
## 10    75+ Non-smoker     31  1462</code></pre>
<ul>
<li>每組的死亡人數用 <span class="math inline">\(y_i, i=1,\cdots,10\)</span> 標記；</li>
<li>每組追蹤的人年用 <span class="math inline">\(t_i\)</span> 標記；</li>
<li><span class="math inline">\(x_{i1} = 0\)</span> 時對象是吸菸者，<span class="math inline">\(x_{i1} = 1\)</span> 時對象是非吸菸者；</li>
<li><span class="math inline">\(x_{i2}, x_{i3}, x_{i4}, x_{i5}\)</span> 作爲5個年齡組的啞變量。</li>
</ul>
<p>分析目的是：</p>
<ol style="list-style-type: decimal">
<li>調查吸菸與冠心病死亡率的關係 (不調整年齡)；</li>
<li>調查吸菸與冠心病死亡率的年齡調整後關係；</li>
<li>調查年齡是否對吸菸與冠心病死亡率的關係起到交互作用。</li>
</ol>
<div id="模型-1" class="section level3">
<h3><span class="header-section-number">48.5.1</span> 模型 1</h3>
<p>第一個模型可以用下面的數學表達式：</p>
<p><span class="math display">\[
\text{log}(\mu_i)  = \text{log}(t_i) + \alpha + \beta_1 x_{i1}
\]</span></p>
<p>在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb574-1" title="1"><span class="co"># the following 2 models are equivalent</span></a>
<a class="sourceLine" id="cb574-2" title="2">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb574-3" title="3">Model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes, <span class="dt">offset =</span> <span class="kw">log</span>(pyrs), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb574-4" title="4"><span class="kw">summary</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes, family = poisson(link = &quot;log&quot;), 
##     data = BritishD, offset = log(pyrs))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -16.5348   -6.0313    4.6116    8.1617   13.6441  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -5.961822   0.099504 -59.9157 &lt; 2.2e-16 ***
## smokesSmoker  0.542221   0.107183   5.0588 4.219e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 935.067  on 9  degrees of freedom
## Residual deviance: 905.976  on 8  degrees of freedom
## AIC: 965.044
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>輸出報告中的參數估計部分 <code>Estimate</code> 就是我們擬合模型中參數的估計 <span class="math inline">\(\hat\alpha, \hat\beta_1\)</span>，他們各自的含義是：</p>
<ul>
<li><span class="math inline">\(\hat\alpha = -5.96\)</span>：非吸菸者的冠心病估計死亡率的對數 (the estimated log rate for non-smokers)；</li>
<li><span class="math inline">\(\hat\beta_1 = 0.547\)</span>：非吸菸者和吸菸者兩組之間冠心病死亡率對數之差 (the estimated difference in log rate between non-smokers and smokers)。</li>
</ul>
<p>注意看報告中間部分模型偏差部分的數字 <code>Residual deviance: 905.98  on 8  degrees of freedom</code>，如果對 模型 1 進行擬合優度檢驗：</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb576-1" title="1"><span class="kw">with</span>(Model1, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb576-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance df              p
## [1,]    905.97619  8 2.9024145e-190</code></pre>
<p>擬合優度檢驗結果提示，這個模型對數據的擬合非常差 (poor fit)。可能的原因是，模型 1 中忽略了“年齡”這一重要的因素，使得當僅僅使用 吸菸與否 的信息擬合的泊松迴歸模型的擬合值和觀察值之間的差異的波動非常大，大到很可能無法滿足泊松分佈的前提假設。</p>
</div>
<div id="模型-2" class="section level3">
<h3><span class="header-section-number">48.5.2</span> 模型 2</h3>
<p>第二個模型的線性預測方程可以寫作：</p>
<p><span class="math display">\[
\text{log}(\mu_i) = \text{ln}(t_i) + \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5}
\]</span></p>
<p>在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb578-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes <span class="op">+</span><span class="st"> </span>agegrp <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb578-2" title="2"><span class="kw">summary</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes + agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), 
##     data = BritishD)
## 
## Deviance Residuals: 
##         1          2          3          4          5          6          7          8          9  
##  0.901600   0.510379   0.051347  -0.087318  -0.912369  -2.179780  -1.308000  -0.137907   0.228819  
##        10  
##  1.919020  
## 
## Coefficients:
##              Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -7.91933    0.19176 -41.2978 &lt; 2.2e-16 ***
## smokesSmoker  0.35454    0.10737   3.3019 0.0009604 ***
## agegrp45-54   1.48401    0.19510   7.6063 2.821e-14 ***
## agegrp55-64   2.62751    0.18373  14.3012 &lt; 2.2e-16 ***
## agegrp65-74   3.35049    0.18480  18.1305 &lt; 2.2e-16 ***
## agegrp75+     3.70010    0.19222  19.2494 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 935.0673  on 9  degrees of freedom
## Residual deviance:  12.1324  on 4  degrees of freedom
## AIC: 79.2003
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>此時可以計算吸菸者與非吸菸者相比時，年齡調整後冠心病死亡率的比爲：</p>
<p><span class="math display">\[
\begin{aligned}
e^{0.3545} &amp; = 1.43 \text{ with } 95\% \text{ CI: } \\
(e^{0.3545 - 1.96\times0.1074}, &amp; e^{0.3545 + 1.96\times0.1074}) = (1.16, 1.76)
\end{aligned}
\]</span></p>
<p>報告中還包含了對吸菸項迴歸係數的 Wald 檢驗結果 <code>smokesSmoker   0.3545     0.1074   3.302  0.00096 ***</code>，從這一結果來看，數據提供了強有力的證據證明了年齡調整以後，吸菸會引起冠心病死亡率的顯著升高。再利用模型擬合報告中模型偏差部分的數據 <code>Residual deviance: 905.98  on 8  degrees of freedom</code>，模型的擬合優度檢驗結果爲：</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb580-1" title="1"><span class="kw">with</span>(Model2, <span class="kw">cbind</span>(<span class="dt">res.deviance =</span> deviance, <span class="dt">df =</span> df.residual,</a>
<a class="sourceLine" id="cb580-2" title="2">  <span class="dt">p =</span> <span class="kw">pchisq</span>(deviance, df.residual, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)))</a></code></pre></div>
<pre><code>##      res.deviance df           p
## [1,]    12.132366  4 0.016393625</code></pre>
<p>結果依然提示，即使把年齡組放入這個泊松迴歸，模型對數據的擬合程度依然非常的不好。所以，到這裏，在即使調整了年齡之後模型擬合度依然不理想的情況下 (這是需要加交互作用項的證據)，我們需要在模型中加入年齡和吸菸的交互作用項 (結果是加入交互作用項的模型就變成了飽和模型)。</p>
</div>
<div id="模型-3" class="section level3">
<h3><span class="header-section-number">48.5.3</span> 模型 3</h3>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb582-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">glm</span>(deaths <span class="op">~</span><span class="st"> </span>smokes<span class="op">*</span>agegrp <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(pyrs)), <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>), <span class="dt">data =</span> BritishD)</a>
<a class="sourceLine" id="cb582-2" title="2"><span class="kw">summary</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = deaths ~ smokes * agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), 
##     data = BritishD)
## 
## Deviance Residuals: 
##  [1]  0  0  0  0  0  0  0  0  0  0
## 
## Coefficients:
##                          Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)              -9.14793    0.70711 -12.9371 &lt; 2.2e-16 ***
## smokesSmoker              1.74687    0.72887   2.3967  0.016544 *  
## agegrp45-54               2.35737    0.76376   3.0865  0.002025 ** 
## agegrp55-64               3.83016    0.73192   5.2330 1.668e-07 ***
## agegrp65-74               4.62266    0.73192   6.3158 2.688e-10 ***
## agegrp75+                 5.29436    0.72956   7.2569 3.960e-13 ***
## smokesSmoker:agegrp45-54 -0.98662    0.79006  -1.2488  0.211741    
## smokesSmoker:agegrp55-64 -1.36281    0.75619  -1.8022  0.071512 .  
## smokesSmoker:agegrp65-74 -1.44229    0.75653  -1.9065  0.056592 .  
## smokesSmoker:agegrp75+   -1.84699    0.75717  -2.4393  0.014715 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 9.35067e+02  on 9  degrees of freedom
## Residual deviance: 4.44089e-15  on 0  degrees of freedom
## AIC: 75.0679
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>此時你會看到模型的偏差已經幾乎接近於零，因爲這已經是一個飽和模型。</p>
</div>
</div>
</div>
<div id="混雜的調整交互作用和模型的可壓縮性" class="section level1">
<h1><span class="header-section-number">第 49 章</span> 混雜的調整，交互作用，和模型的可壓縮性</h1>
<p>臨牀醫學，流行病學研究的許多問題，需要我們通過數據來評估某些結果變量 (outcome) 和某些預測變量 (predictors/exposures) 之間的關係 (甚至是因果關係)。這些問題的最佳解決方法應該說是隨機臨牀試驗 (ramdomized clinical trial, RCT)。但是有更多的時候 (由於違反醫學倫理，或者現狀所困，甚至是知識有限) 我們無法設計 RCT 來解決這些問題，就只能藉助於觀察性研究 (observational study)。觀察性研究最大的侷限性在於無法像 RCT 那樣從實驗設計階段把混雜因素排除或者降到最低，所以觀察數據在分析的時候，混雜 (confounding) 是必須要加以考慮的一大要因。在簡單線性迴歸章節 (Section <a href="04-Linear-Regression.html#confounding">29.5</a>)，詳細討論過混雜因素的定義及條件：</p>
<blockquote>
<p>對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件：</p>
<ul>
<li>與關心的預測變量相關 (i.e. <span class="math inline">\(\delta_1 \neq 0\)</span>)；</li>
<li>與因變量相關 (當關心的預測變量不變時，<span class="math inline">\(\beta_2\neq0\)</span> )；</li>
<li>不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable.</li>
</ul>
</blockquote>
<p>下面的統計數據來自一個比較手術和超聲碎石術對於腎結石治療結果的評價。已知大多數醫生都公認，腎結石的直徑小於 2 公分時治療成功的概率較高。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Lithotripsy">表 49.1: </span>Lithotripsy
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
&lt; 2cm Diameter
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
&gt;= 2cm Diameter
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81.00
</td>
<td style="text-align:center;">
234
</td>
<td style="text-align:center;">
192.00
</td>
<td style="text-align:center;">
55
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6.00
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
71.00
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87.00
</td>
<td style="text-align:center;">
270
</td>
<td style="text-align:center;">
263.00
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
2.08
</td>
<td style="text-align:center;">
NA
</td>
<td style="text-align:center;">
1.23
</td>
<td style="text-align:center;">
NA
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.1: Lithotripsy data
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(&lt;2\)</span> cm Diameter
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(\geqslant2\)</span> cm Diameter
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Group
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81
</td>
<td style="text-align:center;">
234
</td>
<td style="text-align:center;">
192
</td>
<td style="text-align:center;">
55
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
71
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87
</td>
<td style="text-align:center;">
270
</td>
<td style="text-align:center;">
263
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
2.08
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
1.23
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>可以看到，在上面的分組表格中，左右兩邊的四格表分別統計了腎結石尺寸小於 2 cm 和大於 2 cm 時，手術摘除腎結石的成功/失敗次數，以及超聲碎石術的成功/失敗次數。這個表格告訴我們，無論腎結石的尺寸是大於還是小於 2 cm，手術的成功的比值比都大於超聲碎石術。但是如果我們沒有把數據按照腎結石尺寸區分時，數據就被壓縮 (collapsed) 成了下面表格總結的樣子：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:Lithotripsy-collapsed">表 49.2: </span>Lithotripsy collapsed
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
273 (78%)
</td>
<td style="text-align:center;">
289 (83%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
61
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
0.75
</td>
<td style="text-align:center;">
<ul>
<li></td>
</tr>
</tbody>
</table></li>
</ul>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.2: Lithotripsy data collapsed
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
273 (78%)
</td>
<td style="text-align:center;">
289 (83%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
61
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
0.75
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>當腎結石尺寸被忽略時，數據卻顯示超聲碎石術的成功比值比要高於手術，和之前的結果是矛盾的，你會信哪個？</p>
<p>不要慌，數據不會撒謊，撒謊的永遠是人類。我們來把手術次數，超聲碎石術次數，以及腎結石尺寸之間的關係再列個表格：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.3: Association between treatment and the size of the stone.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Size of the Stone
</th>
<th style="text-align:center;">
Surgery
</th>
<th style="text-align:center;">
Lithotripsy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</td>
<td style="text-align:center;">
87 (33%)
</td>
<td style="text-align:center;">
270 (77%)
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</td>
<td style="text-align:center;">
263
</td>
<td style="text-align:center;">
80
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
350
</td>
<td style="text-align:center;">
350
</td>
</tr>
</tbody>
</table>
<p>可見醫生也都不是傻子，明明腎結石尺寸很大還要用超聲碎石術的人很少，有 77% 的腎結石尺寸小的患者選擇了超聲碎石術。然後我們再列一個表格來看看<strong>腎結石的尺寸大小和超聲碎石術</strong>成功與否有沒有關係：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.4: Among the <strong>lithotripsy patients</strong> higher percentage of success was observed when stones were small.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</th>
<th style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
234 (87%)
</td>
<td style="text-align:center;">
55 (69%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
370
</td>
<td style="text-align:center;">
80
</td>
</tr>
</tbody>
</table>
<p>可見結石尺寸較大時，超聲碎石術的成功率 (69%)，明顯低於尺寸小的時候的成功率 (87%)。在選擇做外科手術的患者中，大多數人的結石尺寸大於 2 cm，成功率仍然達到了 73%。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.5: Among the <strong>surgery patients</strong> higher percentage of success in both stones compared with lithotripsy
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
<span class="math inline">\(&lt; 2\)</span> cm
</th>
<th style="text-align:center;">
<span class="math inline">\(\geqslant 2\)</span> cm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
81 (93%)
</td>
<td style="text-align:center;">
192 (73%)
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
71
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
87
</td>
<td style="text-align:center;">
263
</td>
</tr>
</tbody>
</table>
<p>看到這裏，你是否也發現了，腎結石尺寸大小，同時和手術類型的選擇有關 (尺寸小的傾向於選擇超聲碎石術)，尺寸大小，同樣也和手術結果的成功與否，高度相關 (結石小的人成功率高)。所以，分析手術類型和結石手術的成功率的關係的時候，患者體內結石尺寸的大小，對這個關係是產生了混雜效應的。他們三者之間的關係，可以用下面的圖 <a href="09-GLM.html#fig:confounding-kidney">49.1</a> 來理解：</p>
<div class="figure" style="text-align: center"><span id="fig:confounding-kidney"></span>
<img src="img/Selection_113.png" alt="Confounding in kidney stones example" width="90%" />
<p class="caption">
圖 49.1: Confounding in kidney stones example
</p>
</div>
<p>當數據被壓縮 (忽略了腎結石尺寸時)，比較兩種手術類型的成功率的時候，接受外科手術患者的尺寸大多數都較大的事實被“<strong>人爲的掩蓋住了</strong>”，但是當數據按照結石大小分層以後，你會看見外科手術不論是對付大的結石，還是小的結石，成功率都高於超聲碎石術。這個例子是混雜效應直接逆轉真實相關關係的極佳的實例。同時也提示我們，總體的比值比 (overall odds ratio) 不能通過簡單地把分層表格直接壓縮 (collapsed table) 獲得的數字來計算。</p>
<div id="混雜因素的調整" class="section level2">
<h2><span class="header-section-number">49.1</span> 混雜因素的調整</h2>
<p>在前面的腎結石手術的例子中，我們利用已有的背景知識 (小尺寸結石的成功率高)，和初步的統計分析 (變量之間兩兩列表分析其內在關係) 發現了混雜因素 (結石尺寸)，並且其結果也讓我們認定了要暴露因素和結果變量之間的關係，混雜因素必須被調整 (adjusted)。</p>
<p>如腎結石數據這樣簡單的情境下 (被認爲是混雜因素的變量和預測變量/暴露變量都只是一個二分類變量)，我們可以把變量兩兩捉對列表分析其相互關係，確定了混雜效應以後把暴露變量和結果變量按照混雜因素的有無列表之後，就可以求得混雜因素被<strong>調整後的分層的比值比</strong>。這些分層比值比，在暴露變量與結果變量的關係保持混雜因素的層之間保持不變的前提下，可以被“平均化”(簡單地說)以後求得總體/合併的比值比 (overall/pooled odds ratio)。這就是 Mantel-Haenszel 法或者 Woolf 法的合併比值比的思想出發點。我們來回顧一下 Woolf 法的全部計算過程：</p>
<p>現在假設我們關心的是某種疾病的患病與否 (是/否)，和某個暴露變量 (是/否) 之間的關係，但是同時想要調整另一個具有 <span class="math inline">\(k\)</span> 個分層的混雜因素變量。</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.6: Woolf Method for estimating the stratified and pooled odds ratio
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Group
</div>
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(D=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
</tbody>
</table>
<div id="woolf-法估算合併比值比" class="section level3">
<h3><span class="header-section-number">49.1.1</span> Woolf 法估算合併比值比</h3>
<p>對想要調整的一個 <span class="math inline">\(k\)</span> 組的混雜因素，把數據按照它的分組分層整理以後，可以得到上面的 <span class="math inline">\(k\)</span> 個四格表 (每個分層四格表都是暴露變量和結果變量結合的四個觀察值 <span class="math inline">\(a_i, b_i, c_i, d_i, i=1,\cdots, k\)</span>)。每個分層四格表的觀測比值比爲 <span class="math inline">\(\hat\Psi_i = \frac{a_id_i}{c_ib_i}\)</span>，且可以證明方差爲</p>
<p><span class="math display">\[
\text{Var}(\text{log}\hat\Psi_i) \approx \frac{1}{a_i} + \frac{1}{b_i} + \frac{1}{c_i} + \frac{1}{d_i} = \frac{1}{w_i}
\]</span></p>
<p>合併比值比的對數 <span class="math inline">\(\text{log}\hat\Psi_w\)</span> 的 Woolf 的計算方法就是</p>
<p><span class="math display">\[
\text{log}\hat\Psi_w = \frac{\sum w_i\text{log}\hat\Psi_i}{\sum w_i}
\]</span></p>
<p>所以，每個分層的對數比值比乘以自己的<strong>方差的倒數</strong> (權重 weights) 之後求和，再除以所有權重之和，獲得的是合併後的對數比值比，然後再逆運算回來就是 Woolf 法計算合併比值比的原理是。</p>
<p>這個合併比值比的對數的方差是</p>
<p><span class="math display">\[
\text{Var}(\text{log}\hat\Psi_w) = \frac{1}{\sum w_i}
\]</span></p>
<p>有了加權後的合併比值比，和方差，就可以求加權後的合併比值比的信賴區間了。值得注意的是，分層之後每個分層四格表中的四個數字 (四個樣本量) 都不能太小。腎結石手術數據滿足這些條件，那麼不妨跟我一起手算一下結石尺寸調整後的手術與超聲碎石術成功與否的比值比：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\Psi_1 = 2.08 ;&amp;\; \hat\Psi_2 = 1.23 \\
\text{Var}(\text{log}\hat\Psi_1) = \frac{1}{81} &amp; + \frac{1}{234} + \frac{1}{6} + \frac{1}{36} = 0.2111 \\
\text{Var}(\text{log}\hat\Psi_2) = \frac{1}{192} &amp; + \frac{1}{55} + \frac{1}{71} + \frac{1}{25} = 0.0775 \\
w_1 = \frac{1}{\text{Var}(\text{log}\hat\Psi_1)} = 4.74 ; \;&amp; w_2 = \frac{1}{\text{Var}(\text{log}\hat\Psi_2)} = 12.91 \\
\text{log}\hat\Psi_w = &amp; \frac{4.74\times\text{log(2.08)} + 12.91\times\text{log(1.23)}}{4.74 + 12.91} \\
                     = &amp; 0.3481 \\
\Rightarrow \hat\Psi_w =&amp; e^{0.3481} = 1.42\\
\text{Var}(\hat\Psi_w) =&amp; \frac{1}{4.74+12.91} = 0.0567 \\
\Rightarrow 95\% \text{ CI} = &amp; e^{0.3481 \pm 1.96\times\sqrt{0.0567}} \\
                            = &amp; (0.89, 2.26)
\end{aligned}
\]</span></p>
<p>Woolf 的計算調整後的合併比值比的方法是<strong>在線性迴歸和廣義線性迴歸被發現之前誕生的</strong>，但是其想法之精妙，確實令人感嘆。可惜其最大的缺陷是無法用這樣的方法進行連續型變量的調整，也很難同時進行多個變量的調整，所以現在這一算法已經逐漸被淘汰。現在我們有了廣義線性迴歸模型這一更強大的工具，只要把變量加入廣義線性模型進行調整就可以計算曾經難以計算和擴展的調整後的合併比值比。從下面的代碼計算獲得的調整後比值比 <span class="math inline">\(1.43 (0.91, 2.34)\)</span> 也可以看出，Woolf 方法的計算結果也是足夠令人滿意的。</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb584-1" title="1">size &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;&lt; 2cm&quot;</span>, <span class="st">&quot;&lt; 2cm&quot;</span>, <span class="st">&quot;&gt;= 2cm&quot;</span>, <span class="st">&quot;&gt;= 2cm&quot;</span>)</a>
<a class="sourceLine" id="cb584-2" title="2">treatment &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Surgery&quot;</span>,<span class="st">&quot;Lithotripsy&quot;</span>,<span class="st">&quot;Surgery&quot;</span>,<span class="st">&quot;Lithotripsy&quot;</span>)</a>
<a class="sourceLine" id="cb584-3" title="3">n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">87</span>, <span class="dv">270</span>, <span class="dv">263</span>, <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb584-4" title="4">Success &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">81</span>, <span class="dv">234</span>, <span class="dv">192</span>, <span class="dv">55</span>)</a>
<a class="sourceLine" id="cb584-5" title="5">Stone &lt;-<span class="st"> </span><span class="kw">data.frame</span>(size, treatment, n, Success)</a>
<a class="sourceLine" id="cb584-6" title="6">ModelStone &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(Success, n <span class="op">-</span><span class="st"> </span>Success) <span class="op">~</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>size, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Stone)</a>
<a class="sourceLine" id="cb584-7" title="7"><span class="kw">summary</span>(ModelStone)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Success, n - Success) ~ treatment + size, 
##     family = binomial(link = logit), data = Stone)
## 
## Deviance Residuals: 
##        1         2         3         4  
##  0.76357  -0.35881  -0.27563   0.46948  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       1.93655    0.17045 11.3614 &lt; 2.2e-16 ***
## treatmentSurgery  0.35723    0.22908  1.5594    0.1189    
## size&gt;= 2cm       -1.26057    0.23900 -5.2742 1.333e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 33.12395  on 3  degrees of freedom
## Residual deviance:  1.00816  on 1  degrees of freedom
## AIC: 26.3554
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb586-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(ModelStone)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(Success, n - Success) 
##  
##                                   crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09)  1.43 (0.91,2.24)  0.119          &lt; 0.001   
##                                                                                                
## size: &gt;= 2cm vs &lt; 2cm             0.34 (0.23,0.51)  0.28 (0.18,0.45)  &lt; 0.001        &lt; 0.001   
##                                                                                                
## Log-likelihood = -10.1777
## No. of observations = 4
## AIC value = 26.3554</code></pre>
<p>所以，此次分析的結論是，在 5% 的顯著性水平下，數據無法提供有效證據證明，當調整了結石尺寸之後，外科手術和超聲碎石術治療腎結石有差別。
We can conclude that there is no evidence at the 5% level for an effect of surgery, adjusted for stone size.</p>
</div>
</div>
<div id="交互作用" class="section level2">
<h2><span class="header-section-number">49.2</span> 交互作用</h2>
<p>我們決定調整一個混雜因素的時候，其實同時包含了 “在不同混雜因素的程度下，暴露變量和結果變量之間的關係不變/This implicitly assumes that the effect of the exposure is the same irrespective of the levels of the confounder.” 的假設。但是，一個混雜因素，它可能同時還扮演了改變暴露變量和結果變量之間關係的角色 (effect modifier/交互作用效應)。另外還有的情況下，某變量可能改變了暴露變量和結果變量之間的關係，卻不一定是一個混雜因素。此時我們說這個起到改變關係的變量和暴露變量之間發生了交互作用。</p>
<p>如果暴露變量在某個分組變量的不同層 (strata) 之間是不同質的 (hetergeneous, not constant)，我們建議<strong>要分析且報告不同層各自的</strong>比值比。惟一的例外是 RCT 臨牀試驗的時候，我們更加關心調整後合併比值比。因爲一項治療藥物對不同的 “個體” 有不同的療效是必然的，但是，RCT 的目的是要評價的其實是這個藥物或者新療法在整個人羣中的療效是怎樣的。</p>
<p>我們給腎結石數據加上治療方案和結石尺寸大小的交互作用項，結果如下：</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb588-1" title="1">ModelStone2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">cbind</span>(Success, n <span class="op">-</span><span class="st"> </span>Success) <span class="op">~</span><span class="st"> </span>treatment<span class="op">*</span>size, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> Stone)</a>
<a class="sourceLine" id="cb588-2" title="2"><span class="kw">summary</span>(ModelStone2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(Success, n - Success) ~ treatment * size, 
##     family = binomial(link = logit), data = Stone)
## 
## Deviance Residuals: 
## [1]  0  0  0  0
## 
## Coefficients:
##                             Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                  1.87180    0.17903 10.4553 &lt; 2.2e-16 ***
## treatmentSurgery             0.73089    0.45942  1.5909 0.1116310    
## size&gt;= 2cm                  -1.08334    0.30039 -3.6065 0.0003104 ***
## treatmentSurgery:size&gt;= 2cm -0.52453    0.53716 -0.9765 0.3288211    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 3.31239e+01  on 3  degrees of freedom
## Residual deviance: 3.66374e-14  on 0  degrees of freedom
## AIC: 27.3472
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb590-1" title="1">epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(ModelStone2)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting cbind(Success, n - Success) 
##  
##                                   crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09)  2.08 (0.84,5.11)  0.112          &lt; 0.001   
##                                                                                                
## size: &gt;= 2cm vs &lt; 2cm             0.34 (0.23,0.51)  0.34 (0.19,0.61)  &lt; 0.001        &lt; 0.001   
##                                                                                                
## treatmentSurgery:size&gt;= 2cm       -                 0.59 (0.21,1.7)   0.329          &lt; 0.001   
##                                                                                                
## Log-likelihood = -9.6736
## No. of observations = 4
## AIC value = 27.3472</code></pre>
<p>交互作用項的迴歸係數是否爲零的檢驗結果是 <span class="math inline">\(p = 0.329\)</span>，提示數據無法提供足夠的證據證明結石尺寸對治療方案和手術成功與否之間的關係造成有意義的交互作用 (There is no evidence of an interaction between stone size and surgery)。所以此次的數據分析我們可以報告結石尺寸調整後的手術成功比值比就可以了。其中，交互作用項的迴歸係數 <span class="math inline">\(-0.5245 = \text{log}(0.59)\)</span>，的含義是當結石尺寸 <span class="math inline">\(\geqslant 2 \text{cm}\)</span> 時，外科手術和超聲碎石術成功<strong>比值比的對數的差</strong>。我們可以看到一開始我們計算的分層比值比的比值 <span class="math inline">\(\frac{1.23}{2.08} = 0.59\)</span>。還注意到這已經是一個飽和模型 (模型偏差爲零)，模型的擬合值和我們的觀測值是完全相同的。</p>
<p>另外一點不得不提的是，交互作用項的迴歸係數的點估計 <span class="math inline">\(0.59\)</span> 其實低於零假設時的 <span class="math inline">\(1\)</span> 挺多的，它的 <span class="math inline">\(95\%\)</span> 信賴區間也相當的寬 <span class="math inline">\((0.21,1.70)\)</span>，所以其實這裏我們沒有獲得足夠的證據證明替代假設 (有交互作用)，很難說不是因爲樣本量不足導致的統計效能較低，所以我們沒有辦法從這個數據完全排除結石尺寸對治療方案的選擇和手術成功的關係之間的交互作用。(We really cannot be sure that there is no interaction in truth - the data are consistent with quite large interactions between size and surgery effect.) 因此，<strong>有些統計學家可能會傾向於報告分層的比值比，因爲我們沒有辦法從這個樣本數據排除有較強交互作用存在的可能性</strong>。</p>
</div>
<div id="可壓縮性-collapsibility" class="section level2">
<h2><span class="header-section-number">49.3</span> 可壓縮性 collapsibility</h2>
<p>模型可壓縮性的概念可以這樣來理解：</p>
<p>當我們把一個 <strong>我們認爲很重要的混雜因子</strong> 加到模型中去時，自然而然我們會期待其對結果變量的 <strong>效果估計 (effect estimate)</strong> (迴歸係數)在調整前後發生變化。如果是反過來，當我們把一個 <strong>我們認爲不重要的非混雜因子</strong> 加到模型中去時，我們也會自然而然地期待其對結果變量的 <strong>效果估計 (effect estimate)</strong> 在調整前後不會發生改變才是。不幸的是，我們這種理想中的想當然，僅僅在某些情境下成立，其中之一是簡單線性迴歸 (Section <a href="04-Linear-Regression.html#lm">26</a>)。</p>
<div id="線性迴歸的可壓縮性" class="section level3">
<h3><span class="header-section-number">49.3.1</span> 線性迴歸的可壓縮性</h3>
<p><strong>證明</strong></p>
<p>令 <span class="math inline">\(Y\)</span> 標記結果變量，<span class="math inline">\(X\)</span> 標記暴露變量，<span class="math inline">\(Z\)</span> 則標記我們想要調整的莫個混雜因子：</p>
<p><span class="math display">\[
Y = \alpha + \beta_X X + \beta_Z Z + \varepsilon, \text{ where } \varepsilon \sim N(0, \sigma^2)
\]</span></p>
<p>然後把等式兩邊同時取以暴露變量 <span class="math inline">\(X\)</span> 爲條件的期待值：</p>
<p><span class="math display">\[
E(Y | X) = \alpha + \beta_X X + \beta_Z E(Z|X)
\]</span></p>
<p>如果 <span class="math inline">\(Z\)</span> 和 <span class="math inline">\(X\)</span> 是相互獨立的 (即，不是 <span class="math inline">\(X, Y\)</span> 之間關係的混淆因子)，那麼 <span class="math inline">\(E(Z|X) = E(Z) = \mu_Z\)</span>，因爲 <span class="math inline">\(X\)</span> 不能提供任何 <span class="math inline">\(Z\)</span> 的有效信息。所以，等式就變爲：</p>
<p><span class="math display">\[
E(Y|X) = \alpha + \beta_Z \mu_Z + \beta_X X
\]</span></p>
<p>所以，當我們用簡單線性迴歸來擬合 <span class="math inline">\(X,Y\)</span> 之間的關係時，如果 <span class="math inline">\(Z,X\)</span> 是相互獨立的，模型中增加了 <span class="math inline">\(Z\)</span>，不會影響 <span class="math inline">\(X\)</span> 的迴歸係數。線性迴歸的這個性質被定義爲模型的可壓縮性 (linear regression models are collapsible)。</p>
</div>
<div id="collapsibility" class="section level3">
<h3><span class="header-section-number">49.3.2</span> 邏輯鏈接方程時的不可壓縮性</h3>
<p>使用對數鏈接方程 (<span class="math inline">\(\text{log link}\)</span>) 的迴歸模型，同樣具有和線性迴歸類似的可壓縮性。但是，邏輯鏈接方程 (<span class="math inline">\(\text{logit link}\)</span>) 的迴歸模型則不具有可壓縮性。下面舉例的分層表格和壓縮表格，證明了邏輯鏈接方程不具有可壓縮性：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.7: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(stratified data)</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 1
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 2
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
90
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
10
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
90
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>從表格的數據計算可知，要被調整的分組變量的兩層數據中，暴露變量和結果變量的關係相同，比值比都是 <span class="math inline">\(9\)</span>，沒有交互作用，也沒有混雜效應 (每一層中暴露與非暴露均佔相同的 <span class="math inline">\(50\%\)</span>)。但是，你如果把這個觀測數據合併：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 49.8: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(collapsed data)</strong>
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(+\)</span>
</th>
<th style="text-align:center;">
Exposure <span class="math inline">\(-\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
140
</td>
<td style="text-align:center;">
60
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
140
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
200
</td>
<td style="text-align:center;">
200
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
5.4
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>既然已知我們拿來分層的變量對暴露和結果的關係既沒有交互作用，也沒有混雜效應，那麼壓縮數據以後的合併比值比應該和分層比值比一樣才說的通，可惜我們獲得了截然不同的合併比值比 (非調整的)。所以在應用邏輯鏈接方程建立廣義線性迴歸模型的時候，一定不能忘記其不可壓縮性的特徵。所以，<strong>即使加入一個非混淆因子，暴露變量的邏輯迴歸的效應估計 (係數) 也會發生改變</strong>。調整了 <span class="math inline">\(Z\)</span> 以後的比值比被叫做條件 (或直接使用分層) 比值比。如同表格中實例所示，條件比值比會比邊緣比值比 (非調整) 看起來要大一些。</p>
<p>邏輯迴歸的不可壓縮性給我們的啓示是，加入某個變量進入邏輯迴歸模型前後，其他預測變量的迴歸係數發生的變化可能僅僅是由於模型的不可壓縮性導致的變化，而非由於新加入的變量對原先變量與結果之間的關係起到了交互作用或者混雜效應。所以，<strong>擬合迴歸模型的時候，如果你要考慮對莫個因素進行調整，必須做的一件事是，先分析它和其他模型中已有的預測變量之間的關係，從而有助於分析，當把要調整的變量放進模型前後的迴歸係數變化是否是真的來自於交互作用或者混雜效應。</strong></p>
</div>
</div>
<div id="interaction-depend-scale" class="section level2">
<h2><span class="header-section-number">49.4</span> 交互作用對尺度的依賴性</h2>
<p>GLM 模型中的交互作用檢驗，對選用的尺度 (比值比 OR，還是危險度比 RR) 依賴性極高。用模型可壓縮性的數據例子也可以說明交互作用對尺度的依賴性。上文書說到，兩個分層中的比值比都是 9，該分層變量既沒有交互作用，也不是混淆因子 (當使用比值比的時候)。如果我們改用危險度比 (risk ratio, RR)，在分類變量的第一層 (Strata 1) 中，暴露的危險度比是 <span class="math inline">\(\frac{90/100}{50/100} = 1.8\)</span>；分類變量的第二層 (Strata 2) 中，暴露的危險度比是 <span class="math inline">\(\frac{50/100}{10/100} = 5\)</span>。所以使用危險度比作爲評價指標的時候，被調整的分類變量就突然搖身一變變成了有交互作用的因子。這裏，我們用數據，證明了交互作用的存在與否，對尺度的選用依賴性極高。<strong>這就導致我們在描述一個變量是否對我們關心的暴露和結果之間的關係有交互作用時，必須明確指出所使用的是比值比，還是危險度比進行的交互作用評價。</strong></p>
</div>
</div>
<div id="流行病學中的邏輯迴歸" class="section level1">
<h1><span class="header-section-number">第 50 章</span> 流行病學中的邏輯迴歸</h1>
<div id="流行病學研究最常用的實驗設計" class="section level2">
<h2><span class="header-section-number">50.1</span> 流行病學研究最常用的實驗設計</h2>
<p>在流行病學研究中，我們最關心的無非是 暴露變量 (治療方案的選用，或者一些對象的某些特徵如吸菸或飲酒等生活習慣) 與結果變量 (罹患某種我們關心的疾病與否，或者死亡與否) 之間的相關關係。爲了方便解釋本章暫且只考慮 <strong>單一的結果變量 (univariate)</strong> 的情況，不過不要忘了真實世界中的數據和實驗，我們常要 <strong>同時處理多個不同的結果變量 (multivariate)</strong>。</p>
<p>流行病學最常用的兩種研究設計是：</p>
<ul>
<li>隊列研究/前瞻性研究 cohort or prospective studies；</li>
<li>病例對照/回顧性研究 case-control or retrospective studies。</li>
</ul>
<p>無論是這兩種研究中的哪一種，都要從定義研究的人羣開始 (start by defining some population we wish to study)。例如某個年齡段的男性或者女性；某個特定時間段內，在某特定地區範圍內生活的所有人等。這被定義爲 <strong>潛在研究人羣 (underlying population of interest)</strong>。</p>
<p>如果是<strong>隊列研究</strong>，我們需要對這個潛在研究人羣取樣，選取具 <strong>有代表性的，且有足夠樣本量</strong> 的一羣個體 (隊列) 參與研究。那些我們要研究的 <strong>暴露變量 <span class="math inline">\((\mathbf{X})\)</span></strong> 被提前定義好，然後在開始研究的時候收集整理成數據庫。之後這個隊列的參與者不斷被隨訪，這個時間段可以是先定義好的 (一年，五年，十年…)，也可以因人而異，最終直至每個個體的結果變量被觀測到 <span class="math inline">\((D=1 \text{ or } D=0)\)</span>。更一般地，如果我們要研究的暴露因素是二分類的，甚至是多分類的，我們可能會使用一些取樣的技巧，從而保證取樣構成的隊列能夠真實地反應該暴露因子在人羣中的分佈情況，保證隊列的代表性。</p>
<p>如果是<strong>病例對照研究</strong>，從它的別名 – 回顧性研究 – 也可以看出，它的研究起點和隊列研究相反，是從收集到的病例開始的 <span class="math inline">\((D=1)\)</span>。有了病例以後，我們從人羣中沒有該結果變量 <span class="math inline">\((D=0)\)</span> 的人羣中，取適合樣本量的人作爲對照組。然後再分別對病例和對照組用採訪或者問卷，或者調取過去的病例記錄/數據庫記錄等等尋找他們是否接觸過我們要研究的暴露變量。</p>
<p>到這裏，如果你還沒暈，恭喜你應該能理解爲什麼說<strong>病例對照研究研究的是 “結果的原因/causes of effect”</strong>；<strong>隊列研究研究的是 “原因導致的結果/effect of causes”</strong>。二者的終極目標卻是一致的 – 尋找暴露和結果二者之間的關係/To investigate the association between exposures and the outcomes – 只是手段不同而已。</p>
<p>觀察性研究 (不論是隊列還是病例對照研究)，除了我們一定會測量並收集的暴露變量數據，在分析過程中還不可避免地需要把混雜效應考慮進來，也就是我們還必須測量並收集那些潛在的混雜因子的數據 <span class="math inline">\((W)\)</span>。圖 <a href="09-GLM.html#fig:cohort-case-control">50.1</a> 用簡單示意圖總結了 <span class="math inline">\(W (\text{ confounders }), X (\text{ exposures }), D (\text{ outcomes })\)</span> 之間，在不同實驗設計下的關係。</p>
<div class="figure" style="text-align: center"><span id="fig:cohort-case-control"></span>
<img src="img/Selection_114.png" alt="Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study." width="90%" />
<p class="caption">
圖 50.1: Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study.
</p>
</div>
</div>
<div id="GLM8-3" class="section level2">
<h2><span class="header-section-number">50.2</span> 以簡單二分類暴露變量爲例</h2>
<div id="先決條件" class="section level3">
<h3><span class="header-section-number">50.2.1</span> 先決條件</h3>
<p>我們以一個最簡單的二分類暴露變量 <span class="math inline">\((X)\)</span>，和一個二分類結果變量 <span class="math inline">\((D)\)</span> 爲例展開：</p>
<ul>
<li>觀察對象樣本量爲 <span class="math inline">\(n, i = 1,\cdots,n\)</span>；</li>
<li><span class="math inline">\(X_i\)</span> 爲一個二分類暴露變量 (是否接觸了某種化學試劑，<span class="math inline">\(1=\)</span>是，<span class="math inline">\(0=\)</span>否)；</li>
<li><span class="math inline">\(D_i\)</span> 爲一個二分類結果變量 (是否有食道癌，<span class="math inline">\(1=\)</span>是，<span class="math inline">\(0=\)</span>否)。</li>
</ul>
<p>所以，該研究的潛在研究人羣可以被分成四組：<span class="math inline">\((X=1,D=1),(X=1,D=0),(X=0,D=1),(X=0,D=0)\)</span>。如果用 <span class="math inline">\(\pi_{11}, \pi_{10}, \pi_{01}, \pi_{00}\)</span> 標記每組人在該潛在研究人羣中所佔的比例，那麼有：</p>
<p><span class="math display" id="eq:GLM8-123">\[
\begin{aligned}
\pi_{xd} &amp; = \text{Pr}(X=x, D=d) \\
\pi_{11} &amp;+ \pi_{10} + \pi_{01} + \pi_{00}  = 1
\end{aligned}
\tag{50.1}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.1: Probabilities associated with binary explanatory and binary response variables <strong>in the underlying population structure</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
</tr>
</tbody>
</table>
<p>應用概率標記法來輔助理解隊列研究：我們從潛在研究人羣中抽樣，觀察其暴露情況，再追蹤其結果變量。所以實際上，<strong>隊列研究的樣本，來自與對暴露與否 <span class="math inline">\((X=0, X=1)\)</span> 兩組人的抽樣</strong>，所以我們實際求的是，</p>
<p><span class="math display">\[
\begin{equation}
\text{Pr}(D=d|X=x) = \frac{\pi_{xd}}{\pi_{x0} + \pi_{x1}}
\end{equation}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.2: Probabilities associated with binary explanatory and binary response variables <strong>in a cohort study</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(D\)</span>
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; <span class="math inline">\(\text{Pr}(D=d|X=x)\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
<span class="math inline">\(X\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{01}}{\pi_{01} + \pi_{00}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{11}}{\pi_{10} + \pi_{11}}\)</span>
</td>
</tr>
</tbody>
</table>
<p>相反地，病例對照研究中我們從已有的病例 <span class="math inline">\((D=1)\)</span> 出發，這樣做的理由有很多，通常可能由於病例可能十分稀少，如果建立隊列研究可能需要龐大的樣本量 (即便如此也不一定能夠收集到足夠分析的數據，可能還要花費相當長的隨訪時間，吃力不討好)。所以，在病例對照研究的設計中，我們其實是獨立地從兩個人羣 (病例組，<span class="math inline">\(D=1\)</span>，對照組，<span class="math inline">\(D=0\)</span>) 中抽取樣本。所以，<strong>病例對照研究獲得的數據，只能用於計算暴露在病例組和對照組中的條件概率</strong>：</p>
<p><span class="math display">\[
\text{Pr}(X=x|D=d) = \frac{\pi_{xd}}{\pi_{0d}+\pi_{1d}}
\]</span></p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 50.3: Separate samples from subpopulations <span class="math inline">\(D=0,1\)</span> with relavant conditional probabilities <strong>in a case-control study</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{Pr}(X=x|D=d)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{10}}{\pi_{10}+\pi_{00}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{11}}{\pi_{11}+\pi_{01}}\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="比值比-odds-ratios" class="section level3">
<h3><span class="header-section-number">50.2.2</span> 比值比 Odds ratios</h3>
<p>一項研究 二分類暴露變量 <span class="math inline">\(X\)</span>，和 二分類結果變量 <span class="math inline">\(D\)</span> 之間的關係的研究，我們其實最關心的問題是：結果變量的兩個分類 <span class="math inline">\(D=0, D=1\)</span>，在暴露變量 <span class="math inline">\(X=0, X=1\)</span> 兩組中到底個佔多少比例。用吸菸與肺癌的例子來解釋就是，我們最關心的是，在吸菸人羣中，發生肺癌的人的比例，是否顯著地高於非吸菸人羣中發生肺癌的人的比例，僅此而已。這句話用概率論的標記法來寫的話，則是兩個條件概率：<span class="math inline">\(\text{Pr}(D=1|X=1), \text{Pr}(D=1|X=0)\)</span>。此處，可以定義暴露變量 <span class="math inline">\(X=1\)</span> 的條件下，結果變量 <span class="math inline">\(D=1\)</span> 的概率的比值 (Odds)：</p>
<p><span class="math display">\[
\text{Odds}_1 = \frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)} = \frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}
\]</span></p>
<p>類似地，暴露變量 <span class="math inline">\(X=0\)</span> 的條件下，結果變量 <span class="math inline">\(D=1\)</span> 的概率的比值 (Odds)：</p>
<p><span class="math display">\[
\text{Odds}_2 = \frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)} = \frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}
\]</span></p>
<p>故，從隊列研究中，可以很自然的計算暴露變量和結果變量的比值比：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Odds Ratio}_{\text{cohort}} = \frac{\text{Odds}_1}{\text{Odds}_2} &amp; = \frac{\frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)}}{\frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)}}\\
 &amp; = \frac{\frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}}{\frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}} \\
 &amp; = \frac{\frac{\pi_{11}/(\pi_{10}+\pi_{11})}{\pi_{10}/(\pi_{10}+\pi_{11})}}{\frac{\pi_{01}/(\pi_{01}+\pi_{00})}{\pi_{00}/(\pi_{01}+\pi_{00})}} \\
 &amp; = \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
\]</span></p>
<p>從病例對照研究中，推算的暴露變量和結果變量的比值比是另外一個過程：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Odds Ratio}_{\text{case-control}} = \frac{\text{Odds}^\prime_1}{\text{Odds}^\prime_2} &amp; = \frac{\frac{\text{Pr}(X=1|D=1)}{1-\text{Pr}(X=1|D=1)}}{\frac{\text{Pr}(X=0|D=0)}{1-\text{Pr}(X=0|D=0)}} \\
&amp; = \frac{\frac{\pi_{11}/(\pi_{11} + \pi_{01})}{1-\pi_{11}/(\pi_{11} + \pi_{01})}}{\frac{\pi_{10}/(\pi_{10} + \pi_{00})}{1-\pi_{10}/(\pi_{10} + \pi_{00})}} \\
&amp; = \frac{\frac{\pi_{11}/(\pi_{11}+\pi_{01})}{\pi_{01}/(\pi_{11}+\pi_{01})}}{\frac{\pi_{10}/(\pi_{10}+\pi_{00})}{\pi_{00}/(\pi_{10}+\pi_{00})}} \\
&amp; =  \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
\]</span></p>
<p>經過上面的推演，我們發現用病例對照研究的數據，<strong>雖然不能像隊列研究一樣直接推算正確的暴露條件下的比值 (conditional odds given exposure)</strong>，<strong>卻能用較少的樣本量中獲得真實的比值比 (OR) </strong>。</p>
</div>
<div id="GLM8-3-4" class="section level3">
<h3><span class="header-section-number">50.2.3</span> 邏輯迴歸應用於病例對照研究的合理性</h3>
<p>在一個<strong>隊列研究</strong>中，當我們有不止一個暴露變量時，顯然就需要更加複雜的模型來輔助分析 (迴歸型分析法) 暴露變量和結果變量之間的關係。估計比值比最佳的模型是邏輯迴歸。如果 <span class="math inline">\(D\)</span>，表示一個隨機型結果變量，其中每個觀察對象的結果變量服從暴露變量的條件二項分佈 (繼續用單一的<strong>二分類暴露變量</strong> <span class="math inline">\(x_i\)</span>)：</p>
<p><span class="math display">\[
(D_i|X_i = x_i) \sim \text{Binomial}(1, \pi_i)
\]</span></p>
<p>所以，可以用邏輯迴歸來擬合：</p>
<p><span class="math display">\[
\text{logit}(\pi_i) = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta x_i
\]</span></p>
<p>把這個邏輯迴歸方程重新整理：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(D=1|X=1) &amp; = \frac{e^{\alpha + \beta}}{1 + e^{\alpha + \beta}} \\
\text{Pr}(D=1|X=0) &amp; = \frac{e^\alpha}{1 + e^\alpha} \\
\text{Where, }\alpha &amp; =  \text{log}{\frac{\pi_{01}}{\pi_{00}}} \\
\beta &amp; = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
\]</span></p>
<p>在一個<strong>病例對照研究</strong>中，結果變量 <span class="math inline">\(D_i\)</span> 被鎖死，暴露變量成了服從結果變量的條件二項分佈的隨機變量：</p>
<p><span class="math display">\[
(X_i | D_i = d_i) \sim \text{Binomial}(1,\pi_i^*)
\]</span></p>
<p>繼續任性地用邏輯迴歸擬合的話：</p>
<p><span class="math display">\[
\text{logit}(\pi_i^*) = \text{log}(\frac{\pi_i^*}{1-\pi_i^*}) = \alpha^* + \beta d_i
\]</span></p>
<p>同樣整理成概率方程：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(X=1|D=1) &amp; = \frac{e^{\alpha^* + \beta}}{1 + e^{\alpha^* + \beta}} \\
\text{Pr}(X=1|D=0) &amp; = \frac{e^{\alpha^*}}{1 + e^{\alpha^*}} \\
\text{Where, }\alpha &amp; =  \text{log}{\frac{\pi_{10}}{\pi_{00}}} \\
\beta &amp; = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
\]</span></p>
<p>所以，用邏輯迴歸擬合病例對照研究的數據，同樣可以得到和隊列研究一樣正確的比值比估計。但是這個截距 <span class="math inline">\(\alpha\)</span>，<strong>在隊列研究中指的是，非暴露組中患病的比值的對數 (log odds of disease in the unexposed)</strong>；<strong>在病例對照研究中指的是，對照組中暴露的比值的對數 (log odds of exposure in the controls)</strong>。是兩個完全不同含義的估計量。</p>
<p>綜上所述，從一個<strong>隊列研究獲得的似然方程</strong>是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{cohort}} &amp; = \prod_{i=1}^n(\frac{e^{\alpha + \beta x_i}}{1+e^{\alpha + \beta x_i}})^{d_i}(\frac{1}{e^{\alpha + \beta x_i}})^{1-d_i} \\
\text{Where } d_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
\]</span></p>
<p>從一個<strong>病例對照研究獲得的似然方程</strong>是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{case-control}} &amp; = \prod_{i=1}^n(\frac{e^{\alpha + \beta d_i}}{1+e^{\alpha + \beta d_i}})^{x_i}(\frac{1}{e^{\alpha + \beta d_i}})^{1-x_i} \\
\text{Where } d_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i &amp; = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
\]</span></p>
</div>
</div>
<div id="拓展到多個暴露變量的邏輯迴歸模型" class="section level2">
<h2><span class="header-section-number">50.3</span> 拓展到多個暴露變量的邏輯迴歸模型</h2>
<p>現在來考慮 <span class="math inline">\(p\)</span> 個暴露變量的情況：<span class="math inline">\(X_1, \cdots, X_p\)</span>，這些暴露變量可以是分類型變量，也可以是連續型變量，例如，</p>
<ul>
<li><span class="math inline">\(D_i = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象觀察到有 <span class="math inline">\((=1)\)</span>，或沒有 <span class="math inline">\((=0)\)</span> 結果變量 (如發生胰腺癌)；</li>
<li><span class="math inline">\(X_{i1} = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象有 <span class="math inline">\((=1)\)</span>，或沒有 <span class="math inline">\((=0)\)</span> 暴露變量 (如吸菸)；</li>
<li><span class="math inline">\(X_{i2} = 0 \text{ or } 1\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象是男性 <span class="math inline">\((=1)\)</span>，或女性 <span class="math inline">\((=0)\)</span>；</li>
<li><span class="math inline">\(X_{i3}\)</span>，第 <span class="math inline">\(i\)</span> 名研究對象的年齡 (years)。</li>
</ul>
<div id="mantel-haenszel-法" class="section level3">
<h3><span class="header-section-number">50.3.1</span> Mantel Haenszel 法</h3>
<p>如果數據有且只有兩個暴露變量，<span class="math inline">\(X_1, X_2\)</span>，其中 <span class="math inline">\(X_1\)</span> 是一個二分類變量，<span class="math inline">\(X_2\)</span> 是一個可以分成 <span class="math inline">\(C\)</span> 組的分類變量。那麼如果樣本量足夠大，可以把數據整理成 <span class="math inline">\(C\)</span> 個四格表用於分析每一個 <span class="math inline">\(X_2\)</span> 的分層中 <span class="math inline">\(X_1\)</span> 和結果變量 <span class="math inline">\(D\)</span> 之間的關係。多層數據的合併比值比可以用 <a href="https://en.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics">Mantel Haenszel 法</a>。此法在兩個分類暴露變量的情況下還能適用，當某個(或兩個)分類變量的層數越來越多時，你會發現最終落到小格子裏的樣本量急劇下降，侷限性就體現了出來。另外，此法亦不能應用於連續型變量的調整，用處簡直就是捉襟見肘。迫切地我們需要有更加一般的 (藉助於迴歸的威力的) 方法來對多個暴露變量進行調整。</p>
</div>
<div id="隊列研究和病例對照研究的似然" class="section level3">
<h3><span class="header-section-number">50.3.2</span> 隊列研究和病例對照研究的似然</h3>
<p>一個<strong>隊列研究</strong>，用邏輯迴歸擬合其結果變量 (因變量) <span class="math inline">\(D\)</span> 和暴露變量 <span class="math inline">\(X_1, \cdots, X_p\)</span> 之間的關係時，可以寫作：</p>
<p><span class="math display">\[
\begin{aligned}
D_i=1 | (X_{i1} &amp; = x_{i1}, \cdots, X_{ip} = x_{ip}) \sim \text{Binomial}(1, \pi_i) \\
\text{logit} (\pi_i) &amp; = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
\]</span></p>
<p>將這個迴歸方程重新整理成爲概率方程：</p>
<p><span class="math display">\[
\text{Pr}(D_i = 1 | X_{i1}  = x_{i1}, \cdots, X_{ip} = x_{ip}) = \frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}
\]</span></p>
<ul>
<li>截距 <span class="math inline">\(\alpha\)</span> 的含義是，當所有的暴露變量都取 <span class="math inline">\(0\)</span> 時，研究對象觀察到結果變量爲 <span class="math inline">\(1\)</span> 的對數比值 <span class="math inline">\((\text{log odds})\)</span>；</li>
<li>迴歸係數 <span class="math inline">\(\beta_k\)</span> 的含義是，當其餘的暴露變量保持不變時，<span class="math inline">\(x_k\)</span> 每增加一個單位，結果變量爲 <span class="math inline">\(1\)</span> 的對數比值比 <span class="math inline">\((\text{log odds-ratio})\)</span> (即，調整了其餘所有變量之後，<span class="math inline">\(x_k\)</span> 和結果變量之間的對數比值比)。</li>
</ul>
<p>所以，隊列研究的數據，其似然方程是：</p>
<p><span class="math display">\[
\begin{aligned}
L_{\text{cohort}} &amp; = \prod_{i=1}^n\text{Pr}(D_i = d_i |  X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip}) \\
                  &amp; = \prod_{i=1}^n\text{Pr}(\frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
\end{aligned}
\]</span></p>
<p>當數據變成了<strong>病例對照研究</strong>，其似然方程會變成怎樣呢？</p>
<p><span class="math display">\[
L_{\text{case-control}} = \prod_{i=1}^n\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = d_i)
\]</span></p>
<p>這裏，我們很難看出這到底是怎樣的一個條件概率，如果預測變量中同時包括了連續型變量和分類變量，情況就更加複雜，剪不斷理還亂。</p>
</div>
<div id="病例對照研究中的邏輯迴歸" class="section level3">
<h3><span class="header-section-number">50.3.3</span> 病例對照研究中的邏輯迴歸</h3>
<p>用 <span class="math inline">\(\text{Pr}(S_i=1 \text{ or } 0)\)</span> 表示在潛在研究人羣 (underlying study population) 中，被抽樣 (或者沒有被抽樣) 進入該隊列研究的概率。那麼，理想情況下，可認爲實施病例對照研究時，病例是稀少的，即我們收集到的病例，幾乎等價於我們關心的潛在研究人羣中全部的病例，且可以被證明：</p>
<p><span class="math display" id="eq:GLM8-2526">\[
\begin{aligned}
 &amp; \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1) \\
=&amp; \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1, S_i=1) \\
=&amp; \frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}  \\
 &amp; \;\;\;\; \times \frac{\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)}{\text{Pr}(D_i = 1 | S_i = 1)} \\
\text{Where } \alpha^* &amp; =  \alpha + \text{log}(\frac{\text{Pr}(D_i = 0)}{\text{Pr}(D_i = 1)}) + \text{log}(\frac{\text{Pr}(D_i = 1|S_i=1)}{\text{Pr}(D_i = 0|S_i=1)})
\end{aligned}
\tag{50.2}
\]</span></p>
<p>概率方程 <a href="09-GLM.html#eq:GLM8-2526">(50.2)</a> 中，可以看出第一部分 <span class="math inline">\(\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}\)</span> 是一個邏輯迴歸模型。跟隊列研究的邏輯迴歸模型相比較，差別只是截距不同 <span class="math inline">\(\alpha \neq \alpha^*\)</span>。其餘的部分如 <span class="math inline">\(\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)\)</span> 的含義是潛在人羣中被取樣放入該隊列研究，且預測變量各自不同的隨機概率分佈，其實和我們尋找的參數 <span class="math inline">\(\beta_1,\cdots,\beta_p\)</span>，是沒有什麼關係的。最後一部分分母的 <span class="math inline">\(\text{Pr}(D_i = 1 | S_i = 1)\)</span> 的意思是，結果變量爲 <span class="math inline">\(1\)</span> 的人被選入本項病例對照研究的概率，理想的實驗設計下這被認爲是接近於 <span class="math inline">\(1\)</span> 的，即使不是，它也是一個固定不變的常數。所以，病例對照研究的似然方程中，我們關心的只有第一部分，邏輯迴歸模型：</p>
<p><span class="math display">\[
L_{\text{case-control}} \propto \prod_{i=1}^n(\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
\]</span></p>
<p>這裏必須明確的一點是，病例對照研究擬合的邏輯迴歸，其截距是 <span class="math inline">\(\alpha^*\)</span>，並非 <span class="math inline">\(\alpha\)</span>。這個 <span class="math inline">\(\alpha^*\)</span> 其實是包含了 <span class="math inline">\(\text{Pr}(D_i=1),\text{Pr}(D_i=0)\)</span> 的，可惜這些概率也無法用病例對照研究設計獲得。所以，<strong>病例對照研究數據擬合了邏輯迴歸模型以後的截距，其實沒有太多實際的含義</strong>。</p>
</div>
</div>
<div id="流行病學研究中變量的調整策略" class="section level2">
<h2><span class="header-section-number">50.4</span> 流行病學研究中變量的調整策略</h2>
<div class="figure" style="text-align: center"><span id="fig:epi-adjustment"></span>
<img src="img/Selection_115.png" alt="relationships between three variables in an underlying population of interest" width="90%" />
<p class="caption">
圖 50.2: relationships between three variables in an underlying population of interest
</p>
</div>
<p>圖 <a href="09-GLM.html#fig:epi-adjustment">50.2</a> 展示的是在潛在研究人羣中 <span class="math inline">\(W (\text{potential confounder}),X (\text{exposure}),D (\text{outcome})\)</span> 三者之間可能存在的四種關係。</p>
<ul>
<li>圖 <a href="09-GLM.html#fig:epi-adjustment">50.2</a> - (a) <span class="math inline">\(W\)</span> 和 <span class="math inline">\(X, D\)</span> 都沒有關係，那麼我們研究 <span class="math inline">\(X,D\)</span> 之間的關係時，完全可以忽略掉 <span class="math inline">\(W\)</span>，不用調整。<br> 但是，如果在邏輯迴歸模型中調整了一個和暴露變量結果變量之間無關的變量，獲得的比值比估計幾乎不會有太大改變，但是代價是會獲得較大的對數比值比的<strong>標準誤 (standard error)，降低了對比值比估計的精確程度</strong>。</li>
<li>圖 <a href="09-GLM.html#fig:epi-adjustment">50.2</a> - (b) <span class="math inline">\(W\)</span> 和 <span class="math inline">\(X, D\)</span> 同時都相關，且不在 <span class="math inline">\(X\rightarrow D\)</span> 的因果關係通路上，此種情況下，必須對 <span class="math inline">\(W\)</span> 進行調整，否則獲得的比值比估計是帶有嚴重偏倚的。</li>
<li>圖 <a href="09-GLM.html#fig:epi-adjustment">50.2</a> - (c) <span class="math inline">\(W\)</span> 僅僅和 <span class="math inline">\(X\)</span> 有關係，和結果變量 <span class="math inline">\(D\)</span> 沒有相關性。此時研究 <span class="math inline">\(X,D\)</span> 之間的關係時，忽略掉 <span class="math inline">\(W\)</span>，不需要對之進行任何調整。和 (a) 一樣，如果此時調整了 <span class="math inline">\(W\)</span>，估計的比值比不會發生質變，但是會損失估計的精確度。</li>
<li>圖 <a href="09-GLM.html#fig:epi-adjustment">50.2</a> - (d) <span class="math inline">\(W\)</span> 僅僅和結果變量 <span class="math inline">\(D\)</span> 有關係，和暴露變量 <span class="math inline">\(X\)</span> 無關時，如果模型對 <span class="math inline">\(W\)</span> 進行調整，我們會獲得完全不同的比值比估計，因爲這種情況下其實調整 <span class="math inline">\(W\)</span> 前後的比值比估計的是具有不同含義的，二者都具有實際意義。調整前的估計量，是總體估計，有助於作總體的決策；調整後的估計量，是帶有某些特徵的部分人羣估計，有助於評價個人水平的 <span class="math inline">\(X,D\)</span> 之間的關係。</li>
</ul>
</div>
</div>
<div id="分析策略" class="section level1">
<h1><span class="header-section-number">第 51 章</span> 分析策略</h1>
<div id="明確分析目的" class="section level2">
<h2><span class="header-section-number">51.1</span> 明確分析目的</h2>
<p>作爲統計學家，着手分析數據之前，千萬記得，必須要制定一個儘可能詳盡的分析計劃。即使你的分析，可能並不一定受到第三方的監管或者調控，因爲同行評審的專家們，喜歡看到你分析的目的明確，假設檢驗的過程是經過仔細推敲的。同時，也可以避免陷入 “<a href="https://en.wikipedia.org/wiki/Data_dredging">玩弄數據 (data dredging)</a>” 指控的危險。</p>
<p>數據分析的目的，可以分成三大類：</p>
<ol style="list-style-type: decimal">
<li>估計一個或者幾個暴露變量，對結果變量的影響。以此目的的數據分析過程，需要我們有<a href="https://en.wikipedia.org/wiki/John_Snow">醫學偵探</a>一樣的眼光和見解，從數據中判斷那些需要被調整和控制的混雜因子，從而提高你的分析效率。最常見的例子是分析隨機對照臨牀實驗 (RCT) 中，療效的差異；或者流行病學研究中，分析某種生活習慣，和疾病的發生或者死亡之間的關係。</li>
<li>在現有的數據庫中，尋找並且建立 “最佳” 模型。以此目的的數據分析，需要我們對模型中的結果變量有極爲深入的瞭解，把與之相關的<strong>所有要因</strong>，儘可能多的納入你的分析模型。常見的例子如，在某個特定人羣的數據庫中尋找並確定能夠決定自殺這一結果變量的決定性因素，之所以有這樣的目的，背後可能有決策者希望尋找這些決定性因素後採取一些對策從而達到改善現狀的最終目的。所以找到和結果變量相關的因素，是此類研究的重中之重。</li>
<li>建立預測模型。例如，某項研究的目的是爲了能夠建立一個能夠預測孕期胎兒患有唐氏綜合症的預測模型，用能夠測量的一些指標(如血液指標，或者母親的一些健康指標)，通過模型的算法，去計算胎兒患病的概率是多大。這樣的模型，對與診斷醫學有重大意義。所以，此類研究的目的，不是爲了尋找確定和胎兒患病相關的全部要因，而是<strong>怎樣才能提高模型預測的準確度</strong>，提高診斷的效率，減少錯誤診斷，拯救生命。</li>
</ol>
<p>當然，上述目的中的 2 和 3 有時候易讓人混淆，因爲我們可能建立最佳模型，除了想要找到和 “自殺” 這一結果相關的所有要因，還可能希望通過該模型做出預測，尋找可能自殺的高危人羣，進行干預。這並不矛盾。</p>
</div>
<div id="分析目的-1.1-估計-rct-中治療效果-treatment-effect" class="section level2">
<h2><span class="header-section-number">51.2</span> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</h2>
<p>先揀最軟的柿子捏，RCT 的療效比較作爲數據分析的目的時，情況要比其他的目的相對簡單些。RCT 的隨機過程，確保了臨牀試驗不會受到混雜因素的影響。但是我們還會出於爲了<strong>提高統計分析效能</strong>，<strong>改善估計的精確度</strong>的目的，對參與臨牀試驗的受試者最初測量的一些特徵進行調整。當然，不是所有的數據專家，也不是所有的 RCT 實施者都同意進行這一調整的。如果確定要調整，放入模型中的變量，可能常常是一開始隨機分配時用到的那些用於將受試者分層歸類或者最小化 (minimisation) 的那些變量。</p>
<p>基線值調整 (baseline adjustment)，在結果變量爲<strong>連續型，同時模型是線性迴歸模型</strong>時，能夠顯著提高統計效能 (statistical efficiency)，降低估計值的標準誤。理論上，一個基線測量時的連續型變量，如果它和實驗後測量的連續型結果變量之間的 <strong>皮爾森相關係數 Pearson correlation coefficient</strong> 是 <span class="math inline">\(r\)</span>，那麼如果你用 ANCOVA 模型調整了這個基線值的話，療效差異估計值的標準誤會是沒有調整時的 <span class="math inline">\(\sqrt{1-r^2}\)</span> 倍 (也就是永遠比不調整時要小，大大提高精確度，縮小療效差異估計值的 95% 信賴區間)。</p>
<p>但是，但是，但是！如果一個 RCT 測量的結果變量是一個二分類變量 (死亡/存活)，線性迴歸模型不適用，只能使用邏輯迴歸時，模型中加入和結果變量相關 (和暴露變量無關) 的基線值的做法对分析效能的提高顯得十分有限，相反還会受到邏輯迴歸的不可壓縮性較大的影響 (Section <a href="09-GLM.html#collapsibility">49.3.2</a>)。</p>
<p>再把之前講邏輯迴歸不可壓縮性時用过的例子拿过来这里解释这个现象：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 51.1: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(stratified data)</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 1
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;&gt; Strata 2
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
90
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
10
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
90
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds Ratios
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>上面的數據表示，分層變量 (Strata 1-2) 本身和使用藥物和安慰劑無交互作用，也和藥物使用與臨牀試驗結果之間的關係無關。但是，即使這個分類變量無關，壓縮後的數據計算獲得的比值比和分層時的比值比差異巨大：</p>
<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>
表 51.2: <strong>Non-collapsibility</strong> of logit link in GLM <strong>(collapsed data)</strong>
</caption>
<thead>
<tr>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Drug
</th>
<th style="text-align:center;">
Placebo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Success
</td>
<td style="text-align:center;">
140
</td>
<td style="text-align:center;">
60
</td>
</tr>
<tr>
<td style="text-align:center;">
Failure
</td>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
140
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
200
</td>
<td style="text-align:center;">
200
</td>
</tr>
<tr>
<td style="text-align:center;">
Odds ratio
</td>
<td style="text-align:center;">
5.4
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
<p>實際在 R 裏擬合邏輯迴歸模型的結果如下：</p>
<pre><code>## 
## Call:
## glm(formula = Result ~ Treatment, family = binomial(link = logit), 
##     data = RCT)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5518  -0.8446   0.0000   0.8446   1.5518  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       0.84730    0.15430  5.4911 3.994e-08 ***
## TreatmentPlacebo -1.69460    0.21822 -7.7656 8.125e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 554.518  on 399  degrees of freedom
## Residual deviance: 488.691  on 398  degrees of freedom
## AIC: 492.691
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Call:
## glm(formula = Result ~ Treatment + Strata, family = binomial(link = logit), 
##     data = RCT)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1460  -1.1774   0.0000   1.1774   2.1460  
## 
## Coefficients:
##                  Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)       2.19722    0.26505  8.2898 &lt; 2.2e-16 ***
## TreatmentPlacebo -2.19722    0.27486 -7.9941 1.306e-15 ***
## Strata2          -2.19722    0.27486 -7.9941 1.306e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 554.518  on 399  degrees of freedom
## Residual deviance: 407.292  on 397  degrees of freedom
## AIC: 413.292
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>從結果的迴歸係數估計和計算的標準誤來看，調整了其他的變量會引起：</p>
<ol style="list-style-type: decimal">
<li>使對數比值比的估計量升高 (這是由於模型的不可壓縮性) <span class="math inline">\(1.69 \rightarrow 2.19\)</span>；</li>
<li>對數比值比的標準誤估計升高 (非但不能增加估計精確度，反而起到了反作用) <span class="math inline">\(0.22\rightarrow0.27\)</span>；</li>
<li>對數比值比的統計檢驗量升高 (由於對數比值比的升高比標準誤升高的更多一些) <span class="math inline">\(7.77\rightarrow7.99\)</span>。</li>
</ol>
<p>事實上，上面的現象在使用邏輯迴歸的時候基本上都會呈現。在經典論文 <span class="citation">(Robinson and Jewell <a href="#ref-Robinson1991" role="doc-biblioref">1991</a>)</span> 中給出了詳細的論證。所以其實使用邏輯迴歸擬合數據的 RCT 臨牀試驗，我們可以推論，<strong>當模型中加入第三個僅和結果變量有關的基線共變量</strong> (baseline covariates)，如果模型估計的對數比值比在調整前後變化不大 (即，不可壓縮性造成的影響很小)，那這樣的調整對於改善分析的統計效能上幾乎也沒有貢獻。(跟使用線性迴歸的 RCT 完全不同！)</p>
<p>由於邏輯迴歸受使用 <span class="math inline">\(\text{logit}\)</span> 鏈接方程時不可壓縮性的侷限，同時還由於使用 <span class="math inline">\(\text{log}\)</span> 鏈接方程時獲得的危險度比 (risk ratios) 比比值比 (odds ratios) 更加容易讓人理解，結果變量爲二分類的 RCT 臨牀試驗常常會選用 <span class="math inline">\(\text{log}\)</span> 鏈接方程的廣義線性迴歸模型 (見 Section <a href="09-GLM.html#logit-or-log">45.3</a> 第 5 條討論)。選用 <span class="math inline">\(\text{log}\)</span> 鏈接方程的 GLM 最大的問題在於，當模型中<strong>加入過多的預測變量</strong>時，會導致模型<strong>無法收斂 (converge)–無法找到極大似然估計</strong>。</p>
<p>至於使用泊松迴歸模型的時候，預測變量如果放入不合理，那麼很容易違反泊松分佈的前提 (方差和均值相同)。對於違反了泊松分佈前提，模型變得過度離散 (over-dispersed) 的 GLM，加入適當的基線共變量 (baseline covariates) 則有助於減少模型的過度離散，減小參數估計的標準誤 (使之變得更精確些)。和線性迴歸相同的是，泊松迴歸模型不受不可壓縮性 (non-collapsibility) 的影響。</p>
<div id="rct-數據分析的一些不成熟的小建議" class="section level3">
<h3><span class="header-section-number">51.2.1</span> RCT 數據分析的一些不成熟的小建議</h3>
<ol style="list-style-type: decimal">
<li>RCT 臨牀試驗通常都有嚴格的數據管理和監控，且統計分析計劃 (statistical analysis plan, SAP) 在任何一個 RCT 都已經是必須條件。除此之外，還要在試驗進行前就制訂所有詳細的計劃，並寫成實驗實施計劃文件，以供參與的所有人及倫理審查委員會等各種第三方機構的監督。所以，RCT 的統計分析計劃必須儘量考慮到所有的可能情況，因爲一旦開始了試驗，分析計劃是很難改動的。</li>
<li>SAP 必須詳細記錄哪些共變量需要被調整，常見的是實驗設計階段用於實施隨機化過程的那些特徵變量。對於連續型結果變量，(還有過度離散的計數型變量)，基線共變量的調整許多時候會有助於改善參數估計的精確度，提高統計效能。對於使用邏輯迴歸模型的試驗，調整基線共變量則沒有太多的好處，且調整後的比值比的含義會發生較大的改變，需慎重。</li>
<li>有些統計學家支持調整基線共變量，認爲這樣做有助於減少萬一隨機化不徹底造成的治療組和對照組之間隨機產生的殘差偏倚 (residual bias)，但是你無法提前欲知那些變量可能會產生隨機的殘差偏倚，這樣便無法在事先需要準備的SAP計劃文件中明確到底哪些基線變量需要被調整。</li>
<li>另有許多研究者喜歡在 RCT 中尋找交互作用的存在，但是他們常常忽略掉的一點是，一個 RCT 本身的檢驗效能是 80%-90%，其用於檢驗交互作用的效能會更低。建議在 RCT 中儘量少 (甚至不建議) 進行任何交互作用的統計檢驗。</li>
</ol>
</div>
</div>
<div id="分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect" class="section level2">
<h2><span class="header-section-number">51.3</span> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</h2>
<p>前文討論的關於調整僅僅和結果變量相關 (與暴露變量無關) 的基線共變量的內容，同樣適用與一般的流行病學研究。流行病學研究中另一個 (應該是更加) 重要的點是，混雜因子的排查和調整。</p>
<p>實例：</p>
<ul>
<li><span class="math inline">\(Y\)</span> 標記結果變量，如嬰兒的出生體重；</li>
<li><span class="math inline">\(X_1\)</span> 標記最主要的 (想要分析其與結果變量之間的關係的) 預測變量，如母親孕期高血壓 (是/否)；</li>
<li><span class="math inline">\(X_2, X_3, \cdots, X_Q\)</span> 標記其他非主要預測變量，但是可能是 <span class="math inline">\(X_1, Y\)</span> 之間關係中重要的潛在混雜因子，如嬰兒的性別/母親孕前體重/嬰兒胎齡等等。</li>
</ul>
<p>在這個簡單流行病學研究實例中，我們關心的問題包括：</p>
<ol style="list-style-type: decimal">
<li>主要暴露變量–孕期高血壓，和結果變量–嬰兒出生體重二者的未调整前 (粗) 關係 (crude/before adjustment association) 是什麼樣的？</li>
<li>主要暴露變量和結果變量之間的關係是否被其他因素影響 (例如胎齡)？如果有，那麼調整後的關係會發生怎樣的變化？</li>
<li>有沒有其他的變量會改變 (modify) 主要暴露變量和結果變量之間的關係？也就是，有沒有那個變量和主要暴露變量有交互作用？</li>
<li>有沒有其他的變量和主要暴露變量無關，卻可能和結果變量有關係呢？如果存在這樣的變量，模型中調整它在一些情況下可能會改善擬合的結果提高模型的統計效能 (statistical power)。</li>
<li>收集的變量中，有沒有哪個變量可能是在主要暴露變量和結果變量之間因果關係 (如果存在因果關係的話) 的通路上 (on the causal pathway) 的呢？如果有，這樣的變量應該被認爲是媒介因子 (mediator)。</li>
</ol>
<div id="不成熟的小策略" class="section level3">
<h3><span class="header-section-number">51.3.1</span> 不成熟的小策略</h3>
<p>這是很常見的簡單流行病學數據分析。可以按照 (但不一定非要按照) 下面建議的步驟實施統計分析：</p>
<ol style="list-style-type: decimal">
<li>第一步，分析主要暴露變量和結果變量之間的未調整前 (粗) 關係： <br> <span class="math display">\[g\{ E(Y|X_1) \} = \alpha + \beta_1 X_1\]</span></li>
<li>第二步，逐個分析<strong>其餘的變量和主要暴露變量之間的關係</strong>，以及這些<strong>潛在的混雜因子和結果變量之間的關係</strong>。注意，這一步可能耗時較長，但是它並不是決定模型中是否要加入某個或某些非主要暴露變量的步驟，通過<strong>這一步過程有助於我們分析和理解，進一步分析中調整前後的參數估計變化</strong>。</li>
<li>第三步，建立主要暴露變量和這些潛在混雜因子同時放入模型中的 GLM，逐步放入，<strong>一次放入一個 (one at a time) 潛在混雜因子</strong>，和上一步分析的三者之間的關係相結合，分析調整該潛在混雜因子前後，主要暴露變量的迴歸係數的參數估計變化的原因。<br> <span class="math display">\[g\{ E(Y|X_1, X_k) \} = \alpha^* + \beta_1^*X_1 + \beta_kX_k,\; k= 1,\cdots,Q\]</span></li>
</ol>
<p>我們來分析這個可以從 <a href="http://www.stata-press.com/data/r12/lbw.dta">Stata 網站上下載的數據</a>：</p>
<ul>
<li>第一步，先看看暴露變量和結果變量之間的關係</li>
</ul>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb594-1" title="1">lbw &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;</span>)</a>
<a class="sourceLine" id="cb594-2" title="2">lbw<span class="op">$</span>race &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>race)</a>
<a class="sourceLine" id="cb594-3" title="3">lbw<span class="op">$</span>smoke &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>smoke)</a>
<a class="sourceLine" id="cb594-4" title="4">lbw<span class="op">$</span>ht &lt;-<span class="st"> </span><span class="kw">factor</span>(lbw<span class="op">$</span>ht)</a>
<a class="sourceLine" id="cb594-5" title="5">a &lt;-<span class="st"> </span>Epi<span class="op">::</span><span class="kw">stat.table</span>(<span class="kw">list</span>(<span class="st">&quot;Birthweight &lt;2500g&quot;</span> =<span class="st"> </span>low, <span class="st">&quot;History of hypertension&quot;</span>=ht), <span class="kw">list</span>(<span class="kw">count</span>(),<span class="kw">percent</span>(low)), <span class="dt">data =</span> lbw, <span class="dt">margins =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb594-6" title="6"><span class="co"># We first tabulate the data</span></a>
<a class="sourceLine" id="cb594-7" title="7"><span class="kw">print</span>(a, <span class="dt">digits =</span> <span class="kw">c</span>(<span class="dt">percent =</span> <span class="dv">2</span>))</a></code></pre></div>
<pre><code>##  -------------------------------------- 
##               -History of hypertension- 
##  Birthweight         0       1   Total  
##  &lt;2500g                                 
##  -------------------------------------- 
##  0                 125       5     130  
##                  70.62   41.67   68.78  
##                                         
##  1                  52       7      59  
##                  29.38   58.33   31.22  
##                                         
##                                         
##  Total             177      12     189  
##                 100.00  100.00  100.00  
##  --------------------------------------</code></pre>
<ul>
<li>第二步，分析母親高血壓病史和嬰兒低出生體重之間的調整前 (粗) 關係。</li>
</ul>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb596-1" title="1">Model0 &lt;-<span class="st"> </span><span class="kw">glm</span>(low<span class="op">~</span>ht, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb596-2" title="2"><span class="kw">summary</span>(Model0); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model0)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht, family = binomial(link = &quot;logit&quot;), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.32323  -0.83407  -0.83407   1.56519   1.56519  
## 
## Coefficients:
##             Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -0.87707    0.16502 -5.3150 1.066e-07 ***
## ht1          1.21354    0.60835  1.9948   0.04606 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 230.650  on 187  degrees of freedom
## AIC: 234.65
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##            OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0 3.37 (1.02,11.09)  0.046          0.045     
##                                                        
## Log-likelihood = -115.3249
## No. of observations = 189
## AIC value = 234.6499</code></pre>
<p>所以，數據提供了一些證據證明母親的高血壓病史和嬰兒低出生體重之間可能存在正關係，這個調整前的關係是，粗比值比 (crude odds ratio) 爲 3.37 (1.02, 11.09)。</p>
<ul>
<li>接下來，分析潛在的混雜因子是否和主要暴露變量相關：</li>
</ul>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb599-1" title="1"><span class="co"># lwt is the last weight of mothers before pregnancy</span></a>
<a class="sourceLine" id="cb599-2" title="2">Model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(lwt <span class="op">~</span><span class="st"> </span>ht, <span class="dt">data =</span> lbw)</a>
<a class="sourceLine" id="cb599-3" title="3"><span class="kw">summary</span>(Model1); epiDisplay<span class="op">::</span><span class="kw">regress.display</span>(Model1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lwt ~ ht, data = lbw)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -62.5000 -17.9435  -7.9435  10.0565 122.0565 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 127.9435     2.2390 57.1426  &lt; 2e-16 ***
## ht1          29.5565     8.8858  3.3262  0.00106 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29.788 on 187 degrees of freedom
## Multiple R-squared:  0.05586,    Adjusted R-squared:  0.050811 
## F-statistic: 11.064 on 1 and 187 DF,  p-value: 0.0010596</code></pre>
<pre><code>## Linear regression predicting lwt
##  
##            Coeff.(95%CI)        P(t-test) P(F-test)
## ht: 1 vs 0 29.56 (12.03,47.09)  0.001     0.001    
##                                                    
## No. of observations = 189</code></pre>
<p>可見，有高血壓病史的母親，孕前體重較高。再看其與結果變量是否有關係：</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb602-1" title="1">Model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb602-2" title="2"><span class="kw">summary</span>(Model2); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model2)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ lwt, family = binomial(link = &quot;logit&quot;), data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.09482  -0.90217  -0.80197   1.36105   1.98141  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  0.9957634  0.7852434  1.2681  0.20476  
## lwt         -0.0140371  0.0061685 -2.2756  0.02287 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 228.708  on 187  degrees of freedom
## AIC: 232.708
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## lwt (cont. var.) 0.99 (0.97,1)  0.023          0.015     
##                                                          
## Log-likelihood = -114.354
## No. of observations = 189
## AIC value = 232.7081</code></pre>
<p>由此知，母親孕前體重較高的人，有較低的可能剩下低出生體重的嬰兒。這兩個單獨的關係，各自看都具有 5% 的統計學意義，但是這 (或者其他變量分析的結果沒有統計學意義時) 並不是決定模型中是否加入母親孕前體重這一潛在的混雜因子的理由。接下來，我們通過模型中加入母親孕前體重這一變量前後模型的參數估計變化來分析：</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb605-1" title="1">Model3 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>ht <span class="op">+</span><span class="st"> </span>lwt, <span class="dt">data =</span> lbw, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb605-2" title="2"><span class="kw">summary</span>(Model3);epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model3)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht + lwt, family = binomial(link = &quot;logit&quot;), 
##     data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.85912  -0.87274  -0.73845   1.29224   2.17964  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  1.4478621  0.8208975  1.7638 0.077773 . 
## ht1          1.8544773  0.7008245  2.6461 0.008142 **
## lwt         -0.0186285  0.0065928 -2.8256 0.004720 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 221.165  on 186  degrees of freedom
## AIC: 227.165
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  crude OR(95%CI)    adj. OR(95%CI)     P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0       3.37 (1.02,11.09)  6.39 (1.62,25.23)  0.008          0.006     
##                                                                                 
## lwt (cont. var.) 0.99 (0.97,1)      0.98 (0.97,0.99)   0.005          0.002     
##                                                                                 
## Log-likelihood = -110.5827
## No. of observations = 189
## AIC value = 227.1654</code></pre>
<p>加入了孕前體重的模型給出的母親是否有高血壓病史對嬰兒的低出生體重關係的比值比估計爲 <span class="math inline">\(6.39\)</span>，這很明顯比調整孕前體重前的粗比值比 <span class="math inline">\((3.37)\)</span> 大了很多。這個比值比估計的變化有兩個原因：</p>
<ol style="list-style-type: decimal">
<li>(常被忽略的) 邏輯迴歸模型的不可壓縮性導致的；</li>
<li>母親孕前體重對高血壓病史和嬰兒的低出生體重之間的關係造成了混雜效應。</li>
</ol>
<p>上面的分析結果，告訴我們，數據提供了足夠的證據證明母親孕前體重和是否有高血壓病史，在調整了彼此之後，仍然獨立地和嬰兒低出生體重的發生有相關性。這裏，我們可以下結論認爲，模型中加入母親孕前體重作爲混雜因子，是合情合理的。</p>
<p>完成了目前爲止的初步分析和混雜因子的判斷以後，下一階段的分析側重於尋找有沒有任何第三方的預測變量，會對主要暴露變量 <span class="math inline">\(X_1\)</span> (孕期高血壓) 與結果變量 <span class="math inline">\(Y\)</span> (嬰兒出生體重過低) 之間的關係產生交互作用。如果數據中的預測變量有多個，那可能導致需要分析潛在的交互作用有許多對，通常建議在遇到多個預測變量之間的複雜關係需要討論的時候，建議不要一股腦全部作交互作用的分析，而是限定一個或者幾個最有可能有交互作用的變量就可以了。否則模型過於複雜，反而不利於理解。一般生物醫學的統計分析中考慮的重要交互作用分析，需要有重要的生物學意義，常見的例子是年齡，性別等。</p>
<p>本節使用的例子中，令人感興趣的是，母親的孕前體重，會不會對妊娠高血壓的有無與嬰兒出生體重過低之間的關係造成交互作用：</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb608-1" title="1">Model4 &lt;-<span class="st"> </span><span class="kw">glm</span>(low <span class="op">~</span><span class="st"> </span>ht<span class="op">*</span>lwt, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), <span class="dt">data =</span> lbw)</a>
<a class="sourceLine" id="cb608-2" title="2"><span class="kw">summary</span>(Model4); epiDisplay<span class="op">::</span><span class="kw">logistic.display</span>(Model4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = low ~ ht * lwt, family = binomial(link = &quot;logit&quot;), 
##     data = lbw)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.77338  -0.87349  -0.74658   1.28246   2.20403  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  1.5393115  0.9174755  1.6778 0.093392 . 
## ht1          1.2869895  2.5493528  0.5048 0.613678   
## lwt         -0.0193796  0.0074129 -2.6143 0.008941 **
## ht1:lwt      0.0037324  0.0161735  0.2308 0.817490   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 234.672  on 188  degrees of freedom
## Residual deviance: 221.113  on 185  degrees of freedom
## AIC: 229.113
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre><code>## 
## Logistic regression predicting low 
##  
##                  crude OR(95%CI)    adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ht: 1 vs 0       3.37 (1.02,11.09)  3.62 (0.02,535.73)      0.614          0.605     
##                                                                                      
## lwt (cont. var.) 0.99 (0.97,1)      0.98 (0.97,1)           0.009          1         
##                                                                                      
## ht1:lwt          -                  1.0037 (0.9724,1.0361)  0.817          0.819     
##                                                                                      
## Log-likelihood = -110.5567
## No. of observations = 189
## AIC value = 229.1133</code></pre>
<p>由於交互作用項結果爲 <code>ht1:lwt      0.003732   0.016173   0.231  0.81749</code>，無足夠的證據證明孕前體重會對妊娠高血壓和嬰兒出生體重過低之間的關係造成交互作用。</p>
<p>如果確認沒有交互作用，建立本例最終模型前的幾個建議：</p>
<ol style="list-style-type: decimal">
<li>最終分析 <span class="math inline">\(X_1, Y\)</span> 之間關係的模型，需要加入我們逐一甄別之後確認過的混淆因子，此時稱爲<strong>模型 1</strong>；</li>
<li>對於確認不是 <span class="math inline">\(X_1, Y\)</span> 之間關係的混淆因子的那些剩餘變量，逐一加入<strong>模型 1</strong>，比較前後是否模型中各個混淆因子的參數估計是否發生了變化 (有沒有混淆因子的混淆因子？)；</li>
<li>最終模型中的變量，需要包含前兩步確認過的全部混淆因子；</li>
<li>在報告中把調整前後的參數估計整理成表格。</li>
</ol>
<p>如果在分析過程中發現了有重要意義的交互作用，那麼除了包含全部的混淆因子之外，你的最終模型中還需加入重要的交互作用項。此時需要報告的參數估計是有交互作用項部分的分層比值比/其他指標。</p>
</div>
<div id="補充" class="section level3">
<h3><span class="header-section-number">51.3.2</span> 補充</h3>
<p>除了使用二項分佈的邏輯迴歸之外，當結果變量是連續型或者計數型，也就是分析模型使用線性迴歸 (ANCOVA)，或者 (可能過度離散的) 泊松迴歸時，爲了提高模型的統計效能，減小參數估計的標準誤，模型可以選擇進一步調整一個或幾個<strong>只和結果變量有關的基線變量</strong>。此時，在你寫論文或者報告時，<strong>必須把這些變量和確認是混雜因子的變量加以區分</strong>，因爲加它們進入模型的目的不同。</p>
</div>
</div>
<div id="分析目的-2-和-3-建立預測模型-predictive-models" class="section level2">
<h2><span class="header-section-number">51.4</span> 分析目的 2 和 3 – 建立預測模型 (predictive models)</h2>
<p>建立預測模型的過程，其實就是選擇哪個或者那些變量進入模型的過程。方法有很多，可惜的是，沒有哪種是公認完美的。這裏只介紹兩種最常見，也最常被批評的方法 – 前/後 逐步選擇法 (forward stepwise selection/backward elimination)。強調一下，逐步法本身並不是神奇法術，不同的算法選擇的變量自然會有不同，如果你用了逐步選擇法，選出來的模型變量僅僅只能作爲參考，而不能作爲最終結論。</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb611-1" title="1">vitc &lt;-<span class="st"> </span>haven<span class="op">::</span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/vitC.dta&quot;</span>)</a>
<a class="sourceLine" id="cb611-2" title="2">vitc<span class="op">$</span>ctakers &lt;-<span class="st"> </span><span class="kw">factor</span>(vitc<span class="op">$</span>ctakers)</a>
<a class="sourceLine" id="cb611-3" title="3">vitc<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">factor</span>(vitc<span class="op">$</span>sex)</a>
<a class="sourceLine" id="cb611-4" title="4"></a>
<a class="sourceLine" id="cb611-5" title="5">stats<span class="op">::</span><span class="kw">step</span>(<span class="kw">lm</span>(seruvitc<span class="op">~</span><span class="dv">1</span>,<span class="dt">data=</span>vitc[<span class="kw">complete.cases</span>(vitc),]),<span class="dt">direction=</span><span class="st">&quot;forward&quot;</span>,<span class="dt">scope=</span><span class="op">~</span>age<span class="op">+</span>height<span class="op">+</span>weight<span class="op">+</span>sex<span class="op">+</span>cigs<span class="op">+</span>ctakers)</a></code></pre></div>
<pre><code>## Start:  AIC=575.43
## seruvitc ~ 1
## 
##           Df Sum of Sq     RSS     AIC
## + ctakers  1   6967.43 42659.6 563.663
## + sex      1   3688.53 45938.5 570.402
## + cigs     1   2470.90 47156.1 572.783
## + height   1   1243.73 48383.3 575.121
## &lt;none&gt;                 49627.0 575.430
## + age      1    273.59 49353.4 576.927
## + weight   1      1.53 49625.5 577.427
## 
## Step:  AIC=563.66
## seruvitc ~ ctakers
## 
##          Df Sum of Sq     RSS     AIC
## + sex     1  2713.526 39946.0 559.683
## + cigs    1  2150.581 40509.0 560.956
## + height  1  1049.000 41610.6 563.398
## &lt;none&gt;                42659.6 563.663
## + age     1   247.944 42411.6 565.133
## + weight  1    18.227 42641.3 565.625
## 
## Step:  AIC=559.68
## seruvitc ~ ctakers + sex
## 
##          Df Sum of Sq     RSS     AIC
## + cigs    1  1527.704 38418.3 558.134
## &lt;none&gt;                39946.0 559.683
## + weight  1   445.296 39500.7 560.663
## + age     1   183.277 39762.8 561.264
## + height  1   131.722 39814.3 561.382
## 
## Step:  AIC=558.13
## seruvitc ~ ctakers + sex + cigs
## 
##          Df Sum of Sq     RSS     AIC
## &lt;none&gt;                38418.3 558.134
## + weight  1  257.1523 38161.2 559.523
## + age     1  205.2889 38213.0 559.647
## + height  1   58.2745 38360.1 559.996</code></pre>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ ctakers + sex + cigs, data = vitc[complete.cases(vitc), 
##     ])
## 
## Coefficients:
## (Intercept)     ctakers1         sex1         cigs  
##     46.0283      19.8317       9.7642     -12.2550</code></pre>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb614-1" title="1">stats<span class="op">::</span><span class="kw">step</span>(<span class="kw">lm</span>(seruvitc<span class="op">~</span>.,<span class="dt">data=</span>vitc[<span class="kw">complete.cases</span>(vitc),]),<span class="dt">direction=</span><span class="st">&quot;backward&quot;</span>)</a></code></pre></div>
<pre><code>## Start:  AIC=563.38
## seruvitc ~ serial + age + height + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - height   1      1.48 37272.5 561.379
## - age      1     64.18 37335.2 561.532
## - weight   1    174.65 37445.7 561.801
## - serial   1    808.36 38079.4 563.328
## &lt;none&gt;                 37271.1 563.375
## - cigs     1    979.26 38250.3 563.735
## - sex      1   1123.50 38394.6 564.078
## - ctakers  1   6407.24 43678.3 575.811
## 
## Step:  AIC=561.38
## seruvitc ~ serial + age + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - age      1     65.27 37337.8 559.538
## - weight   1    217.51 37490.0 559.908
## - serial   1    807.51 38080.1 561.329
## &lt;none&gt;                 37272.5 561.379
## - cigs     1    977.97 38250.5 561.736
## - sex      1   2584.37 39856.9 565.479
## - ctakers  1   6442.37 43714.9 573.887
## 
## Step:  AIC=559.54
## seruvitc ~ serial + cigs + weight + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - weight   1    366.60 37704.4 558.427
## - serial   1    823.37 38161.2 559.523
## &lt;none&gt;                 37337.8 559.538
## - cigs     1    944.21 38282.0 559.811
## - sex      1   2816.28 40154.1 564.155
## - ctakers  1   6462.15 43800.0 572.064
## 
## Step:  AIC=558.43
## seruvitc ~ serial + cigs + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## - serial   1    713.92 38418.3 558.134
## &lt;none&gt;                 37704.4 558.427
## - cigs     1   1156.10 38860.5 559.176
## - sex      1   2451.95 40156.4 562.161
## - ctakers  1   6385.14 44089.5 570.664
## 
## Step:  AIC=558.13
## seruvitc ~ cigs + sex + ctakers
## 
##           Df Sum of Sq     RSS     AIC
## &lt;none&gt;                 38418.3 558.134
## - cigs     1   1527.70 39946.0 559.683
## - sex      1   2090.65 40509.0 560.956
## - ctakers  1   5841.01 44259.3 569.014</code></pre>
<pre><code>## 
## Call:
## lm(formula = seruvitc ~ cigs + sex + ctakers, data = vitc[complete.cases(vitc), 
##     ])
## 
## Coefficients:
## (Intercept)         cigs         sex1     ctakers1  
##     46.0283     -12.2550       9.7642      19.8317</code></pre>
</div>
</div>
<div id="檢查你的模型-model-checking---glm" class="section level1">
<h1><span class="header-section-number">第 52 章</span> 檢查你的模型 Model Checking - GLM</h1>
<p>每次定義一個 GLM 模型的時候 (Section <a href="09-GLM.html#defineaGLM">44.2</a>)，均分三步走，所以一個模型會出錯的部分，就在這三步驟中的任何一步：</p>
<ol style="list-style-type: decimal">
<li>因變量分佈定義錯誤 (或者分佈的假設不成立) mis-specified distribution: 因變量之間<strong>是否相互獨立</strong>，且<strong>服從某個已知的分佈</strong>，這兩個條件中的任意一個不能滿足，第一步都無法成立。例如，最常見的是我們用泊松迴歸模型來擬合計數型數據時，因爲缺乏一些關鍵變量，導致模型遇到過度離散的問題 (over-dispersed for a Poisson distribution due to an omitted covariate)；</li>
<li>線性預測方程定義錯誤 mis-specified linear predictor: 線性預測方程中放入的變量，有的可能需要被轉換 (連續型轉換成分類型，或者是需要數學轉換)。或者是應該加入的交互作用項被我們粗心忽略了；</li>
<li>鏈接方程錯誤 mis-specified link function: 對前一步定義好的線性預測方程，第三步的鏈接方程指定很可能出現錯誤。或者是，我們可以考慮選用別的鏈接方程 (<span class="math inline">\(\text{log instead of logit}\)</span>)，改變了鏈接方程之後，很可能原先認爲有交互作用的變量之間交互作用就消失了 (Section <a href="09-GLM.html#interaction-depend-scale">49.4</a>)。</li>
</ol>
<p>本章介紹一些廣義線性迴歸模型診斷的方法，這些手段雖然偶爾有一些檢驗方法，但更多的診斷方法需要繪圖通過視覺判斷。介紹邏輯迴歸時解釋過模型比較時使用的模型偏差 (deviance) 概念 (Section <a href="09-GLM.html#deviance">46.3.2</a>) Pearson 的擬合優度檢驗，以及使用 Hosmer-Lemeshow 檢驗法檢驗個人二分類變量數據的邏輯迴歸擬合優度 (Section <a href="09-GLM.html#gof">46.4</a>) 法。值得注意的是，這些方法是一種整體檢驗 (global test)，其零假設是 “<strong>模型可以擬合數據</strong>”，如果擬合優度檢驗的結果是拒絕這個零假設，那麼可以認爲模型建立的不佳，即<strong>接受 “模型不能擬合數據” 的替代假設</strong>。如果擬合優度檢驗的結果是無法拒絕零假設，那麼我們僅僅只能認爲<strong>無證據證明 “模型不可以擬合數據”</strong>，而<strong>不能證明設計的模型可以良好的擬合數據</strong>。所以，擬合優度的檢驗結果可以警告我們模型擬合有沒有錯誤，卻不能證明這個模型到底是不是一個良好的模型 (個人感覺應把擬合優度檢驗 goodness of fit 的名稱改爲 <strong>擬合劣度檢驗 badness of fit</strong>)。</p>
<div id="線性預測方程的定義" class="section level2">
<h2><span class="header-section-number">52.1</span> 線性預測方程的定義</h2>
<p>線性預測方程定義錯誤的最常見的就是“忽略了不該忽略的交互作用”，及<strong>連續型變量可能被以不恰當的方式加入預測方程中</strong>。當然，你可以通過把一個變量放入模型前後，該變量本身的迴歸係數是否有意義 (Wald test) 或者你關心的<strong>預測變量的迴歸係數的變化程度</strong> (magnitude of the corresponding parameter estimate) 來判斷是否保留這個變量在你的模型裏。這麼做的時候，你要當心自己陷入多重比較 (multiple testing) 的陷阱 (某次或者某幾次出現的統計學有意義的結果，可以僅僅是由於偶然，而不是因爲它真的有意義)。</p>
<div id="殘差-1" class="section level3">
<h3><span class="header-section-number">52.1.1</span> 殘差</h3>
<p>觀測值跟擬合值之間的差距，就是我們常說的殘差。</p>
<p>以二項分佈數據爲例，</p>
<p><span class="math display">\[Y_i\sim\text{Bin}(n_i, \pi_i), \\
\text{where n is the number of subjects in one group} \\
\text{logit}(\pi_i) = \eta_i\]</span></p>
<p>其第 <span class="math inline">\(i\)</span> 個觀測值的原始殘差 (raw residual)，是</p>
<p><span class="math display">\[
\begin{aligned}
r_i &amp; = y_i - \hat\mu_i \\
    &amp; = y_i - n_i\hat\pi_i
\end{aligned}
\]</span></p>
<p>觀測值 <span class="math inline">\(Y_i\)</span> 的變化程度 (variability) 本身並不是一成不變的 (會根據模型中加入的共變量而改變)，其變化程度可能是觀測值 <span class="math inline">\(Y_i\)</span> 的方差導致的。二項分佈數據的方差已知是 <span class="math inline">\(\text{Var}(Y_i) = n_i\pi_i(1-\pi_i)\)</span>。舉個栗子，如果 <span class="math inline">\(n_i = 10, \hat\pi_i = 0.01, Y_i = 10\)</span>，那麼 <span class="math inline">\(r_i \approx 10\)</span>，這是一個很差的擬合效果。如果，<span class="math inline">\(n_i = 100000, \hat\pi_i = 0.5, Y_i = 5010\)</span>，那麼 <span class="math inline">\(r_i = 10\)</span>，此時的殘差也是 <span class="math inline">\(10\)</span> 又證明了這是一個擬合效果良好的模型。相同的殘差，由於方差不同，判斷則不一樣，所以我們需要有一個類似簡單線性迴歸中標準化殘差 (Section <a href="04-Linear-Regression.html#standardres">31.6.1</a>) 的過程 – <strong>Pearson 殘差</strong>:</p>
<p><span class="math display">\[
p_i = \frac{r_i}{\sqrt{\hat{\text{Var}}}(Y_i)}
\]</span></p>
<p>所以，二項分佈數據的 Pearson 殘差公式爲</p>
<p><span class="math display">\[
p_i = \frac{r_i}{\sqrt{n_i\hat\pi_i(1-\hat\pi_i)}}
\]</span></p>
<p>Pearson 殘差的平方和，就是 Pearson 卡方統計量，在只有分類變量的邏輯迴歸模型中可以用於擬合度診斷 (Section <a href="09-GLM.html#calibration">53.1</a>)，自由度爲 <span class="math inline">\(1\)</span>：</p>
<p><span class="math display">\[
\sum_i^Np^2_i = \text{Pearson&#39;s } \chi^2 \text{ statistic}
\]</span></p>
<p>和標準化 Pearson 殘差相似地，另一個選項是使用<strong>偏差殘差 (deviance residual)</strong>。只要使偏差殘差 <span class="math inline">\(d_i\)</span> 和原始殘差 <span class="math inline">\(r_i\)</span> 保持相同的符號，偏差殘差也可以被標準化用於模型診斷。</p>
<p>用二項分佈數據的例子，</p>
<p><span class="math display">\[
\begin{aligned}
d_i &amp; = \text{sign}(r_i)\sqrt{2\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i-y_i}{n_i - \hat\mu_i})\}} \\
\sum_{i=1}^n d^2 = D &amp; = 2\sum_{i=1}^N\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i - y_i}{n_i - \hat\mu_i}) \}
\end{aligned}
\]</span></p>
</div>
<div id="glm-在-r-裏獲取殘差" class="section level3">
<h3><span class="header-section-number">52.1.2</span> GLM 在 R 裏獲取殘差</h3>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb617-1" title="1">boot<span class="op">::</span><span class="kw">glm.diag</span>(modelname)<span class="op">$</span>rp       <span class="co">## 可以獲取 standardized Pearson residuals</span></a>
<a class="sourceLine" id="cb617-2" title="2"><span class="kw">resid</span>(modelname, <span class="dt">type =</span> <span class="st">&quot;pearson&quot;</span>) <span class="co">## 可以獲取 Pearson residuals</span></a>
<a class="sourceLine" id="cb617-3" title="3"><span class="kw">rstandard</span>(modelname)               <span class="co">## 可以獲取 standardized deviance residuals</span></a>
<a class="sourceLine" id="cb617-4" title="4"><span class="kw">resid</span>(modelname)                   <span class="co">## 可以獲取 deviance residuals</span></a></code></pre></div>
</div>
<div id="如何利用獲得的殘差" class="section level3">
<h3><span class="header-section-number">52.1.3</span> 如何利用獲得的殘差</h3>
<ol style="list-style-type: decimal">
<li>將殘差和觀測值的排序作散點圖–查看是否有觀測值擁有過大的標準化殘差；</li>
<li>作殘差和線性預測方程值的散點圖–如果模型合理的話，這兩者之間視覺上可以判斷是沒有關係的 (no systematic relationship)；</li>
<li>作殘差和模型中任意一個連續型變量 (如果有的話) – 可以判定該連續型變量的放入方式是否合理；</li>
<li>作殘差和數據中尚未加入模型的新變量之間的散點圖 (甚至是已有變量的二次/三次方值)–如果二者之間有明顯的相關性，需要考慮是否加入這個新變量到模型中去。</li>
</ol>
<p>做這些散點圖時，推薦都加上 <code>lowess</code> 的非線性平滑曲線，用於輔助判斷是否變量之間存在特殊關係。</p>
</div>
</div>
<div id="共變量模式殘差-covariate-pattern-residuals" class="section level2">
<h2><span class="header-section-number">52.2</span> 共變量模式殘差 covariate pattern residuals</h2>
</div>
<div id="鏈接方程" class="section level2">
<h2><span class="header-section-number">52.3</span> 鏈接方程</h2>
</div>
<div id="NHANESdrinker" class="section level2">
<h2><span class="header-section-number">52.4</span> NHANES 飲酒量數據實例</h2>
<p>數據的變量和每個變量的解釋如下表，總樣本量是 2548 人，飲酒量大於 5 杯每日者被定義爲重度飲酒者。</p>
<table>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>gender</code></td>
<td align="left">1=male, 2=female</td>
</tr>
<tr class="even">
<td align="left"><code>ageyrs</code></td>
<td align="left">Age in years at survey</td>
</tr>
<tr class="odd">
<td align="left"><code>bmi</code></td>
<td align="left">Body mass index <span class="math inline">\((\text{kg/m}^2)\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>sbp</code></td>
<td align="left">Systolic blood pressure <span class="math inline">\((\text{mmHg})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>ALQ130</code></td>
<td align="left">Reported average number of drinks per day</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb618-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb618-2" title="2">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb618-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb618-4" title="4"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb618-5" title="5"><span class="kw">with</span>(NHANES, <span class="kw">table</span>(gender))</a></code></pre></div>
<pre><code>## gender
##    1    2 
## 1391 1157</code></pre>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb620-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">Heavydrinker =</span> ALQ130 <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>)</a>
<a class="sourceLine" id="cb620-2" title="2">Model_NH &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb620-3" title="3"><span class="kw">logistic.display</span>(Model_NH);<span class="kw">summary</span>(Model_NH)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)  0.16 (0.11,0.23)  &lt; 0.001        &lt; 0.001   
##                                                                                  
## ageyrs (cont. var.) 0.97 (0.97,0.98)  0.97 (0.96,0.98)  &lt; 0.001        &lt; 0.001   
##                                                                                  
## Log-likelihood = -801.292
## No. of observations = 2548
## AIC value = 1608.5839</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.86408  -0.57154  -0.34828  -0.22281   2.85177  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  1.6410885  0.2755315   5.9561 2.584e-09 ***
## gender      -1.8249474  0.1736041 -10.5121 &lt; 2.2e-16 ***
## ageyrs      -0.0304506  0.0039882  -7.6351 2.257e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1602.58  on 2545  degrees of freedom
## AIC: 1608.58
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>當用邏輯迴歸模型擬合數據，線性迴歸方程加入年齡和性別時，數據給出了極強的證據證明性別和年齡和是否爲重度飲酒者都有很大的關係。但是，擬合完這樣一個邏輯迴歸模型之後，我們最大的擔心是，模型中的年齡變量和 <span class="math inline">\(\text{logit}(\text{P}(Y=1))\)</span> 之間的關係，用簡單線性是不是恰當？要檢驗這樣的擔憂，最好的方法是追加一個非線性轉換後的年齡值，去看看模型的擬合程度是否得到改善：</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb623-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">age2 =</span> ageyrs<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb623-2" title="2">Model_NH2 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>age2, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb623-3" title="3"><span class="kw">logistic.display</span>(Model_NH2) ; <span class="kw">summary</span>(Model_NH2)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)      P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.16 (0.11,0.23)    &lt; 0.001        &lt; 0.001   
##                                                                                          
## ageyrs (cont. var.) 0.9726 (0.9652,0.9801)  1.01 (0.966,1.056)  0.663          0.662     
##                                                                                          
## age2 (cont. var.)   0.9997 (0.9996,0.9998)  0.9996 (0.9991,1)   0.073          0.067     
##                                                                                          
## Log-likelihood = -799.6124
## No. of observations = 2548
## AIC value = 1607.2249</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + age2, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.80207  -0.60342  -0.32980  -0.23312   2.87272  
## 
## Coefficients:
##                Estimate  Std. Error  z value Pr(&gt;|z|)    
## (Intercept)  0.83418082  0.52440600   1.5907  0.11167    
## gender      -1.82748612  0.17346142 -10.5354  &lt; 2e-16 ***
## ageyrs       0.00991164  0.02272523   0.4362  0.66273    
## age2        -0.00043512  0.00024311  -1.7898  0.07348 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1599.22  on 2544  degrees of freedom
## AIC: 1607.22
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>擬合了年齡的平方 (<code>age2</code>) 進入邏輯迴歸模型中之後，<code>age2</code> 的迴歸係數的 Wald 檢驗結果是 <span class="math inline">\(p = 0.073\)</span>，這證明用簡單的線性關係把年齡放在模型裏<strong>並不算不妥當 (not unreasonable)</strong>。</p>
<p>另外，可以提取 <code>Model_NH</code> 的標準化 Pearson 殘差和年齡作如下的散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:stPearsonAge"></span>
<img src="bookdown_files/figure-html/stPearsonAge-1.png" alt="Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates" width="80%" />
<p class="caption">
圖 52.1: Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates
</p>
</div>
<p>圖 <a href="09-GLM.html#fig:stPearsonAge">52.1</a> 中靠近橫軸的藍色實線是 LOWESS 平滑曲線，它十分接近平直的橫線，也證明了 Pearson 標準化殘差值和年齡本身並無關聯。這同時也佐證了，將年齡以連續型共變量的形式放入本次邏輯迴歸模型中<strong>並非不合理 (not unreasonable)</strong>。</p>
<p>下一步，我們再來考慮，模型中加入 <code>bmi</code> 是否合理 (能改善模型的擬合度)：</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb626-1" title="1">Model_NH3 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>bmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb626-2" title="2"><span class="kw">logistic.display</span>(Model_NH3) ; <span class="kw">summary</span>(Model_NH3)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.16 (0.11,0.23)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## ageyrs (cont. var.) 0.97 (0.97,0.98)        0.97 (0.96,0.98)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## bmi (cont. var.)    0.9965 (0.9756,1.0179)  1.0084 (0.9855,1.0318)  0.477          0.479     
##                                                                                              
## Log-likelihood = -801.0412
## No. of observations = 2548
## AIC value = 1610.0825</code></pre>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + bmi, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.93712  -0.57479  -0.34466  -0.22359   2.82847  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  1.4251178  0.4096026   3.4793 0.0005028 ***
## gender      -1.8299784  0.1738183 -10.5281 &lt; 2.2e-16 ***
## ageyrs      -0.0306880  0.0040105  -7.6518 1.982e-14 ***
## bmi          0.0083460  0.0117336   0.7113 0.4769053    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1602.08  on 2544  degrees of freedom
## AIC: 1610.08
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>BMI的迴歸係數是否爲零的 Wald 檢驗 <span class="math inline">\(p=0.477\)</span>，提示數據無法提供證據去反對零假設：“調整了年齡和性別之後，BMI 和是否是重度飲酒者的概率的對數比值 <span class="math inline">\(\text{log-odds}\)</span> 之間無線性關係”，也就是二者之間可能有非線性關係。如果把 Pearson 標準化殘差和 BMI 作殘差散點圖，如下所示：</p>
<div class="figure" style="text-align: center"><span id="fig:stPearsonBMI"></span>
<img src="bookdown_files/figure-html/stPearsonBMI-1.png" alt="Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates" width="80%" />
<p class="caption">
圖 52.2: Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates
</p>
</div>
<p>此殘差圖 <a href="09-GLM.html#fig:stPearsonBMI">52.2</a> 的 LOWESS 平滑曲線卻提示我們，BMI 和殘差之間不完全是毫無關係的 (應該是非線性的，拋物線關係？)。如果我們把 BMI 取平方放入模型中再看其結果：</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb629-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">bmi2 =</span> bmi<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb629-2" title="2">Model_NH4 &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>bmi2, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb629-3" title="3"><span class="kw">summary</span>(Model_NH4)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Heavydrinker ~ gender + ageyrs + bmi + bmi2, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.93349  -0.57566  -0.34335  -0.21636   2.85524  
## 
## Coefficients:
##               Estimate Std. Error  z value  Pr(&gt;|z|)    
## (Intercept) -2.1277529  1.4806329  -1.4371   0.15070    
## gender      -1.7784430  0.1745978 -10.1859 &lt; 2.2e-16 ***
## ageyrs      -0.0323786  0.0040936  -7.9096 2.583e-15 ***
## bmi          0.2551992  0.1003287   2.5436   0.01097 *  
## bmi2        -0.0041230  0.0016854  -2.4464   0.01443 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1810.21  on 2547  degrees of freedom
## Residual deviance: 1594.91  on 2543  degrees of freedom
## AIC: 1604.91
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb631-1" title="1"><span class="kw">logistic.display</span>(Model_NH4)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## gender (cont. var.) 0.17 (0.12,0.24)        0.17 (0.12,0.24)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## ageyrs (cont. var.) 0.97 (0.97,0.98)        0.97 (0.96,0.98)        &lt; 0.001        &lt; 0.001   
##                                                                                              
## bmi (cont. var.)    1 (0.98,1.02)           1.29 (1.06,1.57)        0.011          0.006     
##                                                                                              
## bmi2 (cont. var.)   0.9999 (0.9995,1.0002)  0.9959 (0.9926,0.9992)  0.014          0.007     
##                                                                                              
## Log-likelihood = -797.4554
## No. of observations = 2548
## AIC value = 1604.9108</code></pre>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb633-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH, Model_NH4)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: Heavydrinker ~ gender + ageyrs
## Model 2: Heavydrinker ~ gender + ageyrs + bmi + bmi2
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)  
## 1   3 -801.292                        
## 2   5 -797.455  2 7.67309   0.021568 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>通過似然比檢驗比較加了 <code>bmi, bmi2</code> 兩個共變量的模型和只有 <code>gender, ageyrs</code> 兩個共變量的模型 <span class="math inline">\((p=0.022)\)</span>，提示我們 BMI 和是否是重度飲酒者 (概率的對數比值 <span class="math inline">\(\text{log-odds}\)</span>) 之間的關係並非簡單的線性關係。不過這樣的關係似乎並不是特別的明顯，圖 <a href="09-GLM.html#fig:stPearsonBMI">52.2</a> 的平滑曲線的彎曲程度也沒有特別明顯。所以，在這樣的情況下，有的統計學家可能還是會選擇不放 BMI 進入模型裏。</p>
</div>
<div id="practical-10" class="section level2">
<h2><span class="header-section-number">52.5</span> Practical 10</h2>
<p>繼續沿用 NHANES 數據，此次練習我們把重點放在收集到的收縮期血壓數據上。定義收縮期血壓大於 140 <span class="math inline">\(\text{mmHg}\)</span> 者爲高血壓患者。</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb635-1" title="1"><span class="co"># 1. load the data and define a binary variable indicating whether</span></a>
<a class="sourceLine" id="cb635-2" title="2"><span class="co">#    each observation has hypertension (1) or not (0)</span></a>
<a class="sourceLine" id="cb635-3" title="3">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb635-4" title="4">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb635-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb635-6" title="6"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb635-7" title="7">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">hypertension =</span> sbp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">140</span>)</a>
<a class="sourceLine" id="cb635-8" title="8"><span class="kw">tab1</span>(NHANES<span class="op">$</span>hypertension, <span class="dt">graph =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## NHANES$hypertension : 
##         Frequency Percent Cum. percent
## FALSE        2116      83           83
## TRUE          432      17          100
##   Total      2548     100          100</code></pre>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb637-1" title="1"><span class="co"># 2. Bearing in mind that we know blood pressure increases with age</span></a>
<a class="sourceLine" id="cb637-2" title="2"><span class="co">#    we begin by including age into a logistic regression for the</span></a>
<a class="sourceLine" id="cb637-3" title="3"><span class="co">#    the binary hypertension variable. We can use a lowess smoother</span></a>
<a class="sourceLine" id="cb637-4" title="4"><span class="co">#    plot to examine how the probability of hypertension varies with</span></a>
<a class="sourceLine" id="cb637-5" title="5"><span class="co">#    age.</span></a>
<a class="sourceLine" id="cb637-6" title="6">pi &lt;-<span class="st"> </span><span class="kw">with</span>(NHANES, <span class="kw">predict</span>(<span class="kw">loess</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs)))</a>
<a class="sourceLine" id="cb637-7" title="7"></a>
<a class="sourceLine" id="cb637-8" title="8"><span class="kw">with</span>(NHANES, <span class="kw">scatter.smooth</span>(ageyrs, <span class="kw">logit</span>(pi), <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">span =</span> <span class="fl">0.6</span>, <span class="dt">lpars =</span></a>
<a class="sourceLine" id="cb637-9" title="9">                 <span class="kw">list</span>(<span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>), <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.004</span>),</a>
<a class="sourceLine" id="cb637-10" title="10">                 <span class="dt">xlab =</span> <span class="st">&quot;Age in years&quot;</span>,</a>
<a class="sourceLine" id="cb637-11" title="11">                 <span class="dt">ylab =</span> <span class="st">&quot;Logit(probability) of Hypertension&quot;</span>,</a>
<a class="sourceLine" id="cb637-12" title="12">                 <span class="dt">frame =</span> <span class="ot">FALSE</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:loesslogit"></span>
<img src="bookdown_files/figure-html/loesslogit-1.png" alt="The loess plot of the observed proportin with hypertension against age. Span = 0.6" width="100%" />
<p class="caption">
圖 52.3: The loess plot of the observed proportin with hypertension against age. Span = 0.6
</p>
</div>
<p>Lowess 平滑曲線圖提示，高血壓患病的可能性的 <span class="math inline">\(\text{logit}\)</span>，和年齡之間的關係似乎不是簡單直線關係。我們可能需要把<strong>年齡本身</strong>和<strong>年齡的平方</strong>放入邏輯迴歸模型中去看看。</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb638-1" title="1"><span class="co"># 3. Include age into the logistic regression in the way suggested by the lowess plot.</span></a>
<a class="sourceLine" id="cb638-2" title="2"><span class="co">#    do your results support your findings from the previous graph?</span></a>
<a class="sourceLine" id="cb638-3" title="3">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">agesq =</span> ageyrs<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb638-4" title="4">Model_NH5 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb638-5" title="5"><span class="kw">logistic.display</span>(Model_NH5) ; <span class="kw">summary</span>(Model_NH5)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)          P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.) 1.07 (1.06,1.07)        1.15 (1.1,1.21)         &lt; 0.001        &lt; 0.001   
##                                                                                              
## agesq (cont. var.)  1.0005 (1.0005,1.0006)  0.9993 (0.9989,0.9997)  0.001          &lt; 0.001   
##                                                                                              
## Log-likelihood = -943.7811
## No. of observations = 2548
## AIC value = 1893.5622</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.20772  -0.61574  -0.33152  -0.18319   2.97415  
## 
## Coefficients:
##                Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -6.92931228  0.67205641 -10.311 &lt; 2.2e-16 ***
## ageyrs       0.13933661  0.02419897   5.758 8.514e-09 ***
## agesq       -0.00067035  0.00020870  -3.212  0.001318 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1887.56  on 2545  degrees of freedom
## AIC: 1893.56
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>正如同 Lowess 平滑曲線建議的那樣，數據提供了極強的證據證明年齡和患有高血壓概率的對數比值 <span class="math inline">\((\text{log-odds})\)</span> 之間呈現的是拋物線關係。</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb641-1" title="1"><span class="co"># 4. Generate Pearson residuals and investigate whether the way in</span></a>
<a class="sourceLine" id="cb641-2" title="2"><span class="co">#    which you have included age in the logistic regression in the</span></a>
<a class="sourceLine" id="cb641-3" title="3"><span class="co">#    previous part is correct.</span></a>
<a class="sourceLine" id="cb641-4" title="4"></a>
<a class="sourceLine" id="cb641-5" title="5"><span class="co"># obtain the standardized Pearson residuals by covariate pattern</span></a>
<a class="sourceLine" id="cb641-6" title="6">Diag &lt;-<span class="st"> </span>LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_NH5)</a>
<a class="sourceLine" id="cb641-7" title="7"><span class="kw">ggplot</span>(Diag, <span class="kw">aes</span>(<span class="dt">x =</span> ageyrs, <span class="dt">y =</span> sPr)) <span class="op">+</span><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb641-8" title="8"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">span =</span> <span class="fl">0.9</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st">  </span><span class="kw">theme_bw</span>()  <span class="op">+</span></a>
<a class="sourceLine" id="cb641-9" title="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb641-10" title="10">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb641-11" title="11">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb641-12" title="12"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age in years&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;standardised Pearson residual&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb641-13" title="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb641-14" title="14">        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb641-15" title="15">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb641-16" title="16">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt2"></span>
<img src="bookdown_files/figure-html/NHANEhyt2-1.png" alt="Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates." width="100%" />
<p class="caption">
圖 52.4: Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates.
</p>
</div>
<p>標準化 Pearson 殘差 (共變量模式) 和年齡之間的散點圖 <a href="09-GLM.html#fig:NHANEhyt2">52.4</a> 提示此時的殘差和年齡之間再無明顯的關係。也就是說，年齡作爲連續變量和高血壓患病概率的對數比值之間的關係，用拋物線 (二次方程) 擬合<strong>並非不合理 (not unreasonable)</strong>。</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb642-1" title="1"><span class="co"># 5. Next, use individual level residuals to examine whether BMI ought to be</span></a>
<a class="sourceLine" id="cb642-2" title="2"><span class="co">#    included in the model, and depending on what you find, continue with you</span></a>
<a class="sourceLine" id="cb642-3" title="3"><span class="co">#    previous model or add BMI. In the latter case, generate new residuals and</span></a>
<a class="sourceLine" id="cb642-4" title="4"><span class="co">#    assess if you have included BMI using the most appropriate functional form.</span></a>
<a class="sourceLine" id="cb642-5" title="5">NHANES<span class="op">$</span>stresPearson &lt;-<span class="st"> </span>boot<span class="op">::</span><span class="kw">glm.diag</span>(Model_NH5)<span class="op">$</span>rp</a>
<a class="sourceLine" id="cb642-6" title="6"><span class="kw">ggplot</span>(NHANES, <span class="kw">aes</span>(<span class="dt">x =</span> bmi, <span class="dt">y =</span> stresPearson)) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb642-8" title="8"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb642-9" title="9"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">span =</span> <span class="fl">0.8</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-10" title="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb642-11" title="11">  <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb642-12" title="12">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb642-13" title="13"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Body Mass Index&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Standardized Pearson residual&quot;</span>)  <span class="op">+</span></a>
<a class="sourceLine" id="cb642-14" title="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>), <span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb642-15" title="15">        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>),</a>
<a class="sourceLine" id="cb642-16" title="16">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb642-17" title="17">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt3"></span>
<img src="bookdown_files/figure-html/NHANEhyt3-1.png" alt="Standardized Pearson residuals vs. BMI. Logistic mdoel with **just** linear and quadratic age as covariates." width="100%" />
<p class="caption">
圖 52.5: Standardized Pearson residuals vs. BMI. Logistic mdoel with <strong>just</strong> linear and quadratic age as covariates.
</p>
</div>
<p>圖 <a href="09-GLM.html#fig:NHANEhyt3">52.5</a>，提示，標準化 Pearson 殘差和連續型 BMI 值之間應該存在相關性，也就是該圖提示需要加入連續型變量 BMI 進入邏輯迴歸模型中去！</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb643-1" title="1">Model_NH6 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb643-2" title="2"><span class="kw">logistic.display</span>(Model_NH6) ; <span class="kw">summary</span>(Model_NH6)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                     crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.) 1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                             
## agesq (cont. var.)  1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.005          0.004     
##                                                                                             
## bmi (cont. var.)    1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.007          0.007     
##                                                                                             
## Log-likelihood = -940.1583
## No. of observations = 2548
## AIC value = 1888.3166</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq + bmi, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.32095  -0.61276  -0.33033  -0.18260   2.85207  
## 
## Coefficients:
##                Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept) -7.54111034  0.71010300 -10.6197 &lt; 2.2e-16 ***
## ageyrs       0.13107997  0.02430813   5.3924 6.951e-08 ***
## agesq       -0.00059168  0.00021030  -2.8135  0.004900 ** 
## bmi          0.02840320  0.01046359   2.7145  0.006638 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1880.32  on 2544  degrees of freedom
## AIC: 1888.32
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>加入連續型變量 BMI 進入模型後，<code>bmi</code> 項的 Wald 檢驗結果果然證實了 之前殘差圖提示的 BMI 和高血壓患病概率之間存在相關性。再對 <code>Model_NH6</code> 的殘差和 <code>bmi</code> 作殘差散點圖：</p>
<div class="figure" style="text-align: center"><span id="fig:NHANEhyt5"></span>
<img src="bookdown_files/figure-html/NHANEhyt5-1.png" alt="Standardized Pearson residuals vs. BMI. Logistic mdoel with **linear and quadratic age and BMI** as covariates." width="100%" />
<p class="caption">
圖 52.6: Standardized Pearson residuals vs. BMI. Logistic mdoel with <strong>linear and quadratic age and BMI</strong> as covariates.
</p>
</div>
<p>現在的殘差散點圖提示殘差和 <code>bmi</code> 之間不再有關係，所以之前把 <code>bmi</code> 加入邏輯迴歸模型是個<strong>並非不合理 (not unreasonable)</strong>的選擇。</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb646-1" title="1"><span class="co"># 6. So far we have ingored gender. Explore whether gender should be included</span></a>
<a class="sourceLine" id="cb646-2" title="2"><span class="co">#    in the model. including whether or not the other covariates included</span></a>
<a class="sourceLine" id="cb646-3" title="3"><span class="co">#    already interact with gender with their effects on hypertension.</span></a>
<a class="sourceLine" id="cb646-4" title="4">Model_NH7 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>Gender,</a>
<a class="sourceLine" id="cb646-5" title="5">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb646-6" title="6"><span class="kw">logistic.display</span>(Model_NH7) ; <span class="kw">summary</span>(Model_NH7)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.005          0.004     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.009          0.009     
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          1.24 (0.98,1.56)       0.07           0.07      
##                                                                                                
## Log-likelihood = -938.5164
## No. of observations = 2548
## AIC value = 1887.0328</code></pre>
<pre><code>## 
## Call:
## glm(formula = hypertension ~ ageyrs + agesq + bmi + Gender, family = binomial(link = &quot;logit&quot;), 
##     data = NHANES)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.37006  -0.61503  -0.33044  -0.18099   2.89593  
## 
## Coefficients:
##                 Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)  -7.64411420  0.71405324 -10.7052 &lt; 2.2e-16 ***
## ageyrs        0.13206361  0.02435967   5.4214 5.913e-08 ***
## agesq        -0.00059709  0.00021066  -2.8344  0.004592 ** 
## bmi           0.02730943  0.01043204   2.6178  0.008849 ** 
## GenderFemale  0.21213190  0.11703954   1.8125  0.069912 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2319.51  on 2547  degrees of freedom
## Residual deviance: 1877.03  on 2543  degrees of freedom
## AIC: 1887.03
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb649-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH6, Model_NH7)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi
## Model 2: hypertension ~ ageyrs + agesq + bmi + Gender
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)  
## 1   4 -940.158                        
## 2   5 -938.516  1 3.28378   0.069967 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb651-1" title="1"><span class="co"># some evidence of an effect of gender.</span></a>
<a class="sourceLine" id="cb651-2" title="2"><span class="co"># the Wald test and the likelihood ratio test are both borderline</span></a>
<a class="sourceLine" id="cb651-3" title="3"><span class="co"># statistically significant.</span></a>
<a class="sourceLine" id="cb651-4" title="4">Model_NH8 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi<span class="op">*</span>Gender,</a>
<a class="sourceLine" id="cb651-5" title="5">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb651-6" title="6"><span class="kw">logistic.display</span>(Model_NH8)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.14 (1.09,1.2)        &lt; 0.001        &lt; 0.001   
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.006          0.005     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.05 (1.01,1.08)       0.005          1         
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          3.01 (0.9,10)          0.072          0.072     
##                                                                                                
## bmi:GenderFemale       -                       0.97 (0.93,1.01)       0.139          0.139     
##                                                                                                
## Log-likelihood = -937.423
## No. of observations = 2548
## AIC value = 1886.846</code></pre>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb653-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH7, Model_NH8)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender
## Model 2: hypertension ~ ageyrs + agesq + bmi * Gender
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)
## 1   5 -938.516                      
## 2   6 -937.423  1 2.18675     0.1392</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb655-1" title="1"><span class="co"># no strong evidence of an interaction between BMI and gender</span></a>
<a class="sourceLine" id="cb655-2" title="2"><span class="co"># from both wald test and likelihood ratio test.</span></a>
<a class="sourceLine" id="cb655-3" title="3">Model_NH9 &lt;-<span class="st"> </span><span class="kw">glm</span>(hypertension <span class="op">~</span><span class="st"> </span>ageyrs<span class="op">*</span>Gender <span class="op">+</span><span class="st"> </span>agesq <span class="op">+</span><span class="st"> </span>bmi,</a>
<a class="sourceLine" id="cb655-4" title="4">                 <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb655-5" title="5"><span class="kw">logistic.display</span>(Model_NH9)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting hypertension 
##  
##                        crude OR(95%CI)         adj. OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## ageyrs (cont. var.)    1.07 (1.06,1.07)        1.13 (1.08,1.19)       &lt; 0.001        1         
##                                                                                                
## Gender: Female vs Male 1.1 (0.9,1.36)          0.34 (0.14,0.84)       0.02           0.018     
##                                                                                                
## agesq (cont. var.)     1.0005 (1.0005,1.0006)  0.9994 (0.999,0.9998)  0.004          0.003     
##                                                                                                
## bmi (cont. var.)       1.02 (1.01,1.04)        1.03 (1.01,1.05)       0.008          0.009     
##                                                                                                
## ageyrs:GenderFemale    -                       1.02 (1.01,1.04)       0.004          0.004     
##                                                                                                
## Log-likelihood = -934.2658
## No. of observations = 2548
## AIC value = 1880.5315</code></pre>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb657-1" title="1">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH7, Model_NH9)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender
## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)   
## 1   5 -938.516                         
## 2   6 -934.266  1 8.50127   0.003549 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb659-1" title="1"><span class="co"># strong evidence of an interaction between gender and age</span></a>
<a class="sourceLine" id="cb659-2" title="2">lmtest<span class="op">::</span><span class="kw">lrtest</span>(Model_NH6, Model_NH9)</a></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: hypertension ~ ageyrs + agesq + bmi
## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi
##   #Df   LogLik Df   Chisq Pr(&gt;Chisq)   
## 1   4 -940.158                         
## 2   6 -934.266  2 11.7851    0.00276 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb661-1" title="1"><span class="co"># joint test of gender and its interaction with age is also significant</span></a></code></pre></div>
<p>增加性別項進入邏輯迴歸模型以後，數據提供了臨界有意義證據 <span class="math inline">\((p = 0.070)\)</span> 證明了調整了年齡和 BMI 以後，高血壓的患病概率依然和性別有關係。增加了 BMI 和性別的交互作用項之後發現，無證據證明性別和 BMI 之間存在有意義的交互作用 <span class="math inline">\((p=0.139)\)</span>。但是，增加了年齡和性別的交互作用項以後，發現了有很強的證據證明性別和年齡之間存在交互作用 <span class="math inline">\((p=0.004)\)</span>。增加性別以及性別和年齡的交互作用項，顯著提升了模型對數據的擬合度 <span class="math inline">\((p = 0.0028)\)</span>。此處，我們可以下結論認爲，雖然加入年齡本身，對模型擬合程度提升有有限的幫助，但是當模型考慮了年齡和性別的交互作用之後，擬合數據的程度得到極爲顯著的改善。</p>
<p>當然，想要繼續下去也是可以的，例如 <code>Model_NH9</code> 的前提下，再加入年齡平方與性別的交互作用項，會發現其 Wald 檢驗結果提示年齡平方，和性別的交互作用是沒有意義的 <span class="math inline">\((p=0.58)\)</span>。</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb662-1" title="1"><span class="co"># 7. Based on your final model, calculate fitted probabilities for an individual</span></a>
<a class="sourceLine" id="cb662-2" title="2"><span class="co">#    aged 60 years, at BMI values from 20 to 40 in increments of 5, separately</span></a>
<a class="sourceLine" id="cb662-3" title="3"><span class="co">#    for men and women, and plot the resulting values.</span></a>
<a class="sourceLine" id="cb662-4" title="4"></a>
<a class="sourceLine" id="cb662-5" title="5">a &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">bmi =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">5</span>), <span class="dt">ageyrs =</span> <span class="kw">rep</span>(<span class="dv">60</span>, <span class="dv">5</span>), <span class="dt">agesq =</span> <span class="kw">rep</span>(<span class="dv">3600</span>, <span class="dv">5</span>), <span class="dt">Gender =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="st">&quot;Male&quot;</span>, <span class="dv">5</span>)))</a>
<a class="sourceLine" id="cb662-6" title="6">b &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">bmi =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">5</span>), <span class="dt">ageyrs =</span> <span class="kw">rep</span>(<span class="dv">60</span>, <span class="dv">5</span>), <span class="dt">agesq =</span> <span class="kw">rep</span>(<span class="dv">3600</span>, <span class="dv">5</span>), <span class="dt">Gender =</span> <span class="kw">factor</span>(<span class="kw">rep</span>(<span class="st">&quot;Female&quot;</span>, <span class="dv">5</span>)))</a>
<a class="sourceLine" id="cb662-7" title="7"></a>
<a class="sourceLine" id="cb662-8" title="8">Predict_men &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, a, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>fit</a>
<a class="sourceLine" id="cb662-9" title="9">Predict_men_se &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, a, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>se.fit</a>
<a class="sourceLine" id="cb662-10" title="10">Point_pred_men &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men))</a>
<a class="sourceLine" id="cb662-11" title="11">PredictCI_men_L &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men<span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se))</a>
<a class="sourceLine" id="cb662-12" title="12">PredictCI_men_U &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_men <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_men<span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_men_se))</a>
<a class="sourceLine" id="cb662-13" title="13"><span class="kw">cbind</span>(Point_pred_men, PredictCI_men_L, PredictCI_men_U)</a></code></pre></div>
<pre><code>##   Point_pred_men PredictCI_men_L PredictCI_men_U
## 1     0.20999989      0.16990237      0.25663492
## 2     0.23409879      0.19980473      0.27227618
## 3     0.26005285      0.22575914      0.29755387
## 4     0.28780311      0.24411252      0.33583907
## 5     0.31724500      0.25701542      0.38428866</code></pre>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb664-1" title="1">Predict_women &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, b, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>fit</a>
<a class="sourceLine" id="cb664-2" title="2">Predict_women_se &lt;-<span class="st"> </span><span class="kw">predict</span>(Model_NH9, b, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)<span class="op">$</span>se.fit</a>
<a class="sourceLine" id="cb664-3" title="3">Point_pred_women &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women))</a>
<a class="sourceLine" id="cb664-4" title="4">PredictCI_women_L &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women<span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se))</a>
<a class="sourceLine" id="cb664-5" title="5">PredictCI_women_U &lt;-<span class="st"> </span><span class="kw">exp</span>(Predict_women <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(Predict_women<span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>Predict_women_se))</a>
<a class="sourceLine" id="cb664-6" title="6"><span class="kw">cbind</span>(Point_pred_women, PredictCI_women_L, PredictCI_women_U)</a></code></pre></div>
<pre><code>##   Point_pred_women PredictCI_women_L PredictCI_women_U
## 1       0.24913421        0.20076523        0.30471354
## 2       0.27615418        0.23478059        0.32175308
## 3       0.30491460        0.26477267        0.34825967
## 4       0.33528289        0.28659479        0.38774675
## 5       0.36707847        0.30191960        0.43748678</code></pre>
</div>
</div>
<div id="評價模型的表現-assessing-model-performance" class="section level1">
<h1><span class="header-section-number">第 53 章</span> 評價模型的表現 Assessing model performance</h1>
<p>在廣義線性迴歸的模型表現中，還有幾個重要的概念，<strong>精準度 (calibration)，變異度 (variation)，和分辨能力 (descrimination)</strong>，本章繼續用二分類結果變量和多個共變量的廣義線性迴歸模型來理解這幾個概念。本章使用邏輯迴歸，也就是 <span class="math inline">\(\text{logit}\)</span> 鏈接方程的 GLM 來解釋，但是實際上使用其他鏈接方程時，這些概念也是一樣通用的。</p>
<p>當用邏輯迴歸模型擬合了觀測數據。我們可以通過擬合的模型來計算每個觀測對象的預測“成功”概率 (the predicted probability of “success” for each subject)。當使用 <span class="math inline">\(\text{logit}\)</span> 作鏈接方程時，每個人的預測概率 (predicted probability) 爲：</p>
<p><span class="math display">\[
\hat\pi_i = \frac{\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}{1+\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}
\]</span></p>
<div id="calibration" class="section level2">
<h2><span class="header-section-number">53.1</span> 精準度 calibration</h2>
<p>模型具有良好的精準度時，其計算獲得的每個觀測對象的預測概率，和每個觀測對象本身“成功”的<strong>概率期望值</strong>保持一致。</p>
<p><span class="math display">\[
E(Y|\hat\pi = p) = p
\]</span></p>
<p>當一個 GLM 具有良好精準度時，我們可以利用它在臨牀醫學中發揮重要的作用 (如預測患者死亡，發病或療效等)。如果模型的精準度不佳，那可能導致的嚴重後果有：治療不必要治療的“健康人”，或者漏掉應該治療的“患者”。當一個模型的預測變量只包含了分類型變量，比較觀測概率和預測概率的過程較爲簡單，比較各個分類變量的排列組合後，不同共變量類型 (covariate pattern) 的患者的觀測值和預測值即可。</p>
<p>這裏再沿用之前 NHANES 的重度飲酒相關的數據 (Section <a href="09-GLM.html#NHANESdrinker">52.4</a>)來繼續下面對精準度的說明，先擬合一個只有性別作爲預測變量的邏輯迴歸模型：</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb666-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/nhanesglm.dta&quot;</span>)</a>
<a class="sourceLine" id="cb666-2" title="2">NHANES &lt;-<span class="st"> </span>NHANES <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb666-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">ifelse</span>(gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb666-4" title="4"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Gender =</span> <span class="kw">factor</span>(Gender, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)))</a>
<a class="sourceLine" id="cb666-5" title="5"><span class="kw">with</span>(NHANES, <span class="kw">table</span>(Gender))</a></code></pre></div>
<pre><code>## Gender
##   Male Female 
##   1391   1157</code></pre>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb668-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">Heavydrinker =</span> ALQ130 <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>)</a>
<a class="sourceLine" id="cb668-2" title="2">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</a>
<a class="sourceLine" id="cb668-3" title="3"><span class="kw">logistic.display</span>(Model_perf)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                        OR(95%CI)         P(Wald&#39;s test) P(LR-test)
## Gender: Female vs Male 0.17 (0.12,0.24)  &lt; 0.001        &lt; 0.001   
##                                                                   
## Log-likelihood = -834.1079
## No. of observations = 2548
## AIC value = 1672.2158</code></pre>
<p>完成這個模型之後，在 STATA 裏可以用簡便的 <code>estat gof, table</code> 命令獲取模型擬合的觀測值和期待值表格，然而 R 裏面需要用到 <a href="https://cran.r-project.org/web/packages/LogisticDx/index.html"><code>LogisticDx</code></a> 包裏的診斷命令 <code>dx</code> 獲取 <del>(我花了好幾個小時才找到這個命令，不得不說 STATA 對於流行病的傳統計算真的是比較方便)</del>：</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb670-1" title="1">LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)[, <span class="dv">2</span><span class="op">:</span><span class="dv">6</span>]</a></code></pre></div>
<pre><code>##    GenderFemale   y           P    n yhat
## 1:            0 249 0.179007908 1391  249
## 2:            1  42 0.036300778 1157   42</code></pre>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb672-1" title="1"><span class="co"># obtain Pearson&#39;s test statistics</span></a>
<a class="sourceLine" id="cb672-2" title="2">chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)<span class="op">$</span>sPr)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb672-3" title="3">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb672-4" title="4">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Pearson chi2(1)&quot;</span>,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a></code></pre></div>
<pre><code>##              test        chi.sq pvalue
## 1 Pearson chi2(1) 7.5334682e-25      1</code></pre>
<p>在這個只有性別作預測變量的邏輯迴歸模型裏，當然只有男，女，兩種共變量模式 (covariate patterns)。此時，模型的精準度100% (<code>y</code> 是觀測值， <code>yhat</code> 是期待值)。接下來，再在模型中加入一個是否體重超重的二分類變量。再獲取其觀測值和期待值表格如下：</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb674-1" title="1">NHANES &lt;-<span class="st"> </span><span class="kw">mutate</span>(NHANES, <span class="dt">highbmi =</span> bmi <span class="op">&gt;</span><span class="st"> </span><span class="dv">25</span>)</a>
<a class="sourceLine" id="cb674-2" title="2">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>highbmi, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> binomial)</a>
<a class="sourceLine" id="cb674-3" title="3"><span class="kw">logistic.display</span>(Model_perf)</a></code></pre></div>
<pre><code>## 
## Logistic regression predicting Heavydrinker 
##  
##                        crude OR(95%CI)   adj. OR(95%CI)    P(Wald&#39;s test) P(LR-test)
## Gender: Female vs Male 0.17 (0.12,0.24)  0.17 (0.12,0.24)  &lt; 0.001        &lt; 0.001   
##                                                                                     
## highbmi                1.21 (0.93,1.58)  1.11 (0.84,1.46)  0.456          0.453     
##                                                                                     
## Log-likelihood = -833.8269
## No. of observations = 2548
## AIC value = 1673.6539</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb676-1" title="1">LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)[,<span class="dv">2</span><span class="op">:</span><span class="dv">7</span>]</a></code></pre></div>
<pre><code>##    GenderFemale highbmiTRUE   y           P   n       yhat
## 1:            0           1 175 0.183662501 961 176.499664
## 2:            0           0  74 0.168605433 430  72.500336
## 3:            1           1  29 0.037620159 731  27.500336
## 4:            1           0  13 0.034036770 426  14.499664</code></pre>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb678-1" title="1"><span class="co"># obtain Pearson&#39;s test statistics</span></a>
<a class="sourceLine" id="cb678-2" title="2">chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((LogisticDx<span class="op">::</span><span class="kw">dx</span>(Model_perf)<span class="op">$</span>sPr)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb678-3" title="3">   pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb678-4" title="4">   <span class="kw">data.frame</span>(<span class="dt">test=</span><span class="st">&quot;Pearson chi2(1)&quot;</span>,<span class="dt">chi.sq=</span>chi2,<span class="dt">pvalue=</span>pval)</a></code></pre></div>
<pre><code>##              test     chi.sq     pvalue
## 1 Pearson chi2(1) 0.29881856 0.58462403</code></pre>
<p>此時的模型有 4 種共變量模式 (covariate patterns)，其實就是性別和超重與否的四種排列組合。這裏報告的 <code>Pearson's test statisitics</code>
我們在前一章講邏輯迴歸殘差的部分有講過，它就是 Pearson 標準化殘差的平方和。此處它的卡方檢驗，檢驗零假設是“模型制定正確”。所以，我們無足夠的證據 <span class="math inline">\((p=0.58)\)</span> 來反對零假設，數據觀測值和模型的期待值似乎也較爲吻合。</p>
<p>但是一旦模型裏加入了新的連續型變量，整個模型的共變量模式 (covariate patterns)，將會變得很難進行上面的觀測值和期待值的比較，由於加入的連續型變量會導致模型的共變量模式變得越來越多，甚至接近與樣本量個數 <span class="math inline">\(n\)</span>，也就是每個共變量模式的樣本越來越小，直至等於 <span class="math inline">\(1\)</span>。連續型變量的模型中我們 Hosmer-Lemeshow 檢驗 (Section <a href="09-GLM.html#gof">46.4</a>) 而不是 Pearson 統計檢驗量。</p>
</div>
<div id="可解釋因變量的變異度及-r2-決定係數" class="section level2">
<h2><span class="header-section-number">53.2</span> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</h2>
<p>精準度的確重要，但是模型精準度好，只代表它和過去擬合它的觀測數據之間關係接近，不代表它能準確地預測其他的個體的概率。前文中只有性別作爲預測變量的邏輯迴歸模型就是實例，它和擬合的觀測數據做到了 100% 完美擬合，但是不用大腦思考也知道，除了性別還有其他更多的能預測一個人是否是重度飲酒者的變量，且擁有能提升模型的擬合程度的潛質。只有性別作預測變量的邏輯迴歸模型，最大的問題在於，它只能解釋個體之間<strong>重度飲酒者概率</strong>的<strong>變異度(variation)</strong>中極少的部分。事實上，它<strong>只能解釋能夠用性別解釋的個體之間重度飲酒者概率的變異度</strong>。所以，此處打算引伸出的概念就是類似簡單線性迴歸中的 <span class="math inline">\(R^2\)</span> 決定係數 (Section <a href="04-Linear-Regression.html#Rsquare">28.2.3</a>) 的定義。</p>
<p>你應該還能記得，在簡單線性迴歸中決定係數 <span class="math inline">\(R^2\)</span> 的含義是因變量的平方和 (平方和) 中能被模型解釋的部分：</p>
<p><span class="math display">\[
R^2 = \frac{SS_{REG}}{SS_{yy}} = \frac{\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\]</span></p>
<p>許多前人嘗試過試圖將線性迴歸的決定係數概念擴展到廣義線性迴歸模型中來，但是目前爲止的嘗試都不太成功。所以，只有一些借鑑了簡單線性迴歸的的決定係數思想的概念，得到了擴展，但是要注意，他們本身和決定係數是有區別的。</p>
<p><strong>“假決定係數 (pseudo-R2)”</strong>，別名 McFadden 的似然比係數 (McFadden’s likelihood ratio index) <br> <span class="math display">\[R^r_{\text{McFadden}} = 1 - \frac{\ell_c}{\ell_\text{null}}\]</span> <br> 其中 <span class="math inline">\(\ell_c, \ell_{\text{null}}\)</span> 分別是模型的極大似然值 和零模型時的極大似然值。<br> 假決定係數，之所以被冠名“假”，因爲這個係數你也可以在簡單線性迴歸下計算，但是其大小常常和一般我們熟知的決定係數結果有些差距。所以，常有人質疑其到底是否可用 (因爲它在現實生活中根本不可能取到 <span class="math inline">\(0\)</span> 或 <span class="math inline">\(1\)</span>)。</p>
<p>在 R 裏，擬合了邏輯迴歸以後通常也不會報告假決定係數值的大小。所以想要獲得它，需要 <code>DescTools::PseudoR2()</code> 命令來獲取：</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb680-1" title="1"><span class="kw">PseudoR2</span>(Model_perf)</a></code></pre></div>
<pre><code>##    McFadden 
## 0.078752188</code></pre>
<p>上文中包含了性別和是否超重的模型的假決定係數只有區區 <span class="math inline">\(0.0785\)</span>，可見，只有性別和是否超重兩個變量只能解釋結果變量變異度中極少的部分。</p>
</div>
<div id="分辨能力-descrimination" class="section level2">
<h2><span class="header-section-number">53.3</span> 分辨能力 descrimination</h2>
<div id="敏感度和特異度" class="section level3">
<h3><span class="header-section-number">53.3.1</span> 敏感度和特異度</h3>
<p>評價一個邏輯迴歸的表現，最後的一個手段是，看這個模型對觀測對象的分辨能力。也就是，當我們人爲地指定一個概率值 <span class="math inline">\(p\)</span> 作爲是否患病的閾值，那麼，觀測對象通過模型計算獲得的概率，已經觀測對象本身的觀測概率之間，其實可以用診斷學的敏感度和特異度的概念來評價模型對於觀測對象的分別能力到底如何。所以邏輯迴歸模型的敏感度就是，病例中通過模型計算被判斷爲陽性的概率；特異度是，非病例中，通過模型計算本判斷爲陰性的概率。這個敏感度特異度當然會隨着我們選擇的閾值而變化。</p>
<p>圖 <a href="09-GLM.html#fig:ROClogistic">53.1</a> 所示的是，將性別， BMI，和年齡三個變量放入邏輯迴歸模型之後，模型對於觀察對象的分辨能力的 ROC 示意圖。計算所得的 ROC 曲線下面積爲 0.7484。如果一個模型是失敗的，那麼其曲線下面積爲 (接近) 0.5。也就是會十分貼近 <span class="math inline">\(y=x\)</span> 的直線。</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb682-1" title="1">Model_perf &lt;-<span class="st"> </span><span class="kw">glm</span>(Heavydrinker <span class="op">~</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>ageyrs, <span class="dt">data =</span> NHANES, <span class="dt">family =</span> binomial)</a>
<a class="sourceLine" id="cb682-2" title="2">ROC_graph &lt;-<span class="st"> </span><span class="kw">lroc</span>(Model_perf, <span class="dt">grid.col =</span> <span class="st">&quot;grey&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">frame =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ROClogistic"></span>
<img src="bookdown_files/figure-html/ROClogistic-1.png" alt="Receiver operating curve for model for heavy drinking with gender, age, and BMI" width="100%" />
<p class="caption">
圖 53.1: Receiver operating curve for model for heavy drinking with gender, age, and BMI
</p>
</div>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb683-1" title="1">ROC_graph<span class="op">$</span>auc</a></code></pre></div>
<pre><code>## [1] 0.74835297</code></pre>
<p>曲線下面積，AUC 的另一個有用的意義是，從觀測對象中任意選取兩個人，一個是病例 <span class="math inline">\((y_i = 1)\)</span>，一個是非病例 <span class="math inline">\((y_j = 0)\)</span>，那麼曲線下面積就是模型能夠正確將這兩個對象按照是否患病的可能性進行排序的概率。 <span class="math inline">\(\text{AUC} = \text{Pr}(\pi_i &gt; \pi_j | y_i = 1 \&amp; y_j = 0)\)</span></p>
<p>ROC 曲線本身有自己的優點，也有許多侷限性。最近有另外一個用於診斷的新型曲線–預測曲線<span class="citation">(Pepe et al. <a href="#ref-Pepe2007" role="doc-biblioref">2007</a>)</span>。預測曲線繪製的是，觀測對象的擬合後概率 <span class="math inline">\(\hat\pi_i\)</span> 和這個概率在所有觀察對象的擬合後概率的百分位數 (percentile) 之間的曲線。一個模型，如果給許多對象相似的概率，那麼不能說這個模型的分辨能力足夠好。同時，此圖也能一目瞭然讓人看到大概多少對象的患病概率是大於一定水平的。</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb685-1" title="1">Predictive &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">fitted</span>(Model_perf), <span class="kw">rank</span>(<span class="kw">fitted</span>(Model_perf))<span class="op">/</span><span class="dv">2548</span>)</a>
<a class="sourceLine" id="cb685-2" title="2"><span class="kw">names</span>(Predictive) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;hatpi&quot;</span>, <span class="st">&quot;percentile&quot;</span>)</a>
<a class="sourceLine" id="cb685-3" title="3"><span class="kw">ggplot</span>(Predictive, <span class="kw">aes</span>(<span class="dt">x =</span> percentile, <span class="dt">y =</span> hatpi)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb685-4" title="4"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="fl">0.4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb685-5" title="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Risk percentile&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Heavy drinker risk&quot;</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb685-6" title="6"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">17</span>),</a>
<a class="sourceLine" id="cb685-7" title="7">       <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>),</a>
<a class="sourceLine" id="cb685-8" title="8">  <span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:predictiveness"></span>
<img src="bookdown_files/figure-html/predictiveness-1.png" alt="Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate" width="100%" />
<p class="caption">
圖 53.2: Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate
</p>
</div>
<p>圖 <a href="09-GLM.html#fig:predictiveness">53.2</a> 所示的是，性別，年齡，BMI作爲共變量的邏輯迴歸模型的預測變量，預測重度飲酒概率的模型給出的預測曲線。從圖中可見，大多數人的概率值各不相同。而且，圖中也能告訴我們大約 20% 的觀測對象其重度飲酒的概率大於 0.2。</p>
</div>
</div>
</div>
<div id="配對實驗數據的分析法" class="section level1">
<h1><span class="header-section-number">第 54 章</span> 配對實驗數據的分析法</h1>
<p>配對實驗是指觀察對象中的一個以上 (通常是2-3個) 以事先確定的條件進行配對 (matched under conditions)。配對實驗中根據條件配對後的觀察對象常常被稱爲一個個區塊 (block)。</p>
<p><strong>例1：</strong> 配對交叉設計實驗，結果變量爲連續型。</p>
<p>給予五十名實驗對象抗高血壓藥物用於降低其舒張期血壓 (diastolic blood pressure)。舒張期血壓在實驗前 <span class="math inline">\((y_{i1})\)</span> 和實驗後 <span class="math inline">\((y_{i2})\)</span> 分別測量。此時的實驗區塊是每個患者的自身前後對照數據。</p>
<p><strong>例2：</strong> 干預實驗，結果變量爲二分類型。</p>
<p>77名已經有眼底病變的糖尿病患者被選爲實驗對象，每人隨機選取一隻眼睛接受最新的雷射激光治療，另一隻眼睛使用標準治療法。經過五年的隨訪，觀察患者的兩隻眼睛是病變爲全盲 (是/否)。此時的實驗區塊是每個患者自己，左右眼互爲對照。</p>
<p><strong>例3：</strong> 隊列研究中的配對設計，結果變量爲二分類型。</p>
<p>100 名觀察對像根據性別年齡和 100 名服他汀類藥物 (statin) 的患者，以高膽固醇血癥的有無作爲對照變量 (病例對照同時患病，或同時無病) 一一對應。這 200 名對象被追蹤隨訪 3 年，記錄他們是否罹患心血管疾病。此時的實驗區塊，是 100 個成對的實驗對象。</p>
<p><strong>例4：</strong> 配對病例對照實驗。</p>
<p>20 名肺癌患者，和另外 20 名沒有肺癌的對照以同年齡，同性別爲條件配對。研究人員詢問每個實驗參與者過去的吸菸史。本實驗的結果變量爲對象是否吸過香菸。此時的實驗區塊是一名肺癌患者和一名同年齡，同性別的對照。</p>
<p>配對實驗中，我們通常認爲在每個區塊裏的個人，或者他們的測量值應該比不同一區塊裏的觀察對象的測量值更加相似。</p>
<ul>
<li><strong>例1</strong> 中，每個個體實驗前後的血壓值，理論上會比另外一個個體的血壓值相比更加接近，無論他是否接受抗高血壓治療，故每個個體本身，構成了“完美”的病例 (實驗前) 和對照 (實驗後)。</li>
<li><strong>例3</strong> 中，無論一個人是否服用他汀類藥物，兩個同時都是高膽固醇血癥的人理論上會比無此症狀的人更加有可能罹患心血管疾病。</li>
<li><strong>例4</strong> 中，年齡和性別可能既和一個人是否患有肺癌有關係，也和一個人是否吸菸有關。所以，在考察吸菸和肺癌關係的時候，需要在相同年齡，性別的條件下才是公平的。</li>
</ul>
<div id="配對的原理" class="section level2">
<h2><span class="header-section-number">54.1</span> 配對的原理</h2>
<p>不同的實驗，配對的設計可能有不同的理由：</p>
<ul>
<li>在 RCT 設計中，配對實驗是爲了提升實驗數據對治療的真實效果的估計 (to improve the precision of the estimated effect of the treatment on the outcome)；</li>
<li>隊列研究和病例對照研究中，使用配對實驗設計 <strong>主要是爲了在實驗設計階段就控制已知的混雜因素</strong>。當然有時也有人使用配對設計去提升差異估計的精確度。</li>
</ul>
<div id="爲了提升估計的精確度" class="section level3">
<h3><span class="header-section-number">54.1.1</span> 爲了提升估計的精確度</h3>
<p>使用配對實驗設計，獲得數據以後就應使用相應的統計手法，從而達到提高差異估計的精確度的目的。因爲配對實驗設計允許我們在分析階段去除掉 “區塊差異 block variability”：</p>
<p><span class="math display">\[
\begin{aligned}
             Y_{ij} &amp; = C_j + P_i + O_{ij} \\
\text{Where } Y_{ij} &amp; = \text{outcome for block } i \text{ under treatment } j\\
                C_j &amp; = \text{component of outcome due to treatment } j \\
                P_i &amp; = \text{component of outcome due to characteristics of block } i\\
             O_{ij} &amp; = \text{residual component of outcome}
\end{aligned}
\]</span></p>
<p>在上述式子描述的配對實驗設計下，如果成對的觀察值是 <span class="math inline">\(Y_{i1}, Y_{i2} (i = 1,\cdots, n)\)</span>，那麼可以把二者的差用於估計治療效果：</p>
<p><span class="math display" id="eq:GLM12-1">\[
\begin{equation}
Y_{i2} - Y_{i1} = C_2 - C_1 + O_{i2} - O_{i1}
\end{equation}
\tag{54.1}
\]</span></p>
<p>所以，配對實驗中，由於區塊 <span class="math inline">\((P_i)\)</span> 造成的估計的方差被從隨機變異 (random variation) 中去除掉，<span class="math inline">\(C_j\)</span> 之間的差異的估計精確度得到提高。這一結論在結果變量是連續型或是二分類型中同樣適用。</p>
</div>
<div id="控制混雜因素" class="section level3">
<h3><span class="header-section-number">54.1.2</span> 控制混雜因素</h3>
<p>在病例對照實驗中，常常用配對設計來控制已知的混雜。但是必須強調的是，如果實驗設計中用了配對，那麼統計分析時，也必須用配對實驗的分析方法。</p>
<p><strong>隊列研究中</strong>： 暴露組對象和非暴露組對象之間的配對根據一些已知的混雜變量，常見的如年齡和性別配對。</p>
<p><strong>病例對照研究中</strong>：病例和對照之間通過某些特徵配對，從而控制這些特徵的混雜，常見的也是年齡和性別。另外還有的病例會從他/她居住的區域附近中尋找相似的對照，或者從他/她的家庭醫生的患者中尋找相似的對象，這時配對設計爲的是控制那些可能無法精確測量的如社會經濟條件，或環境因子。有些研究會尋找病例同一家族中的非患病者作爲對照，從而達到控制 “遺傳因素” 這一混雜因子的效果。</p>
</div>
</div>
<div id="結果變量爲連續型變量的配對實驗" class="section level2">
<h2><span class="header-section-number">54.2</span> 結果變量爲連續型變量的配對實驗</h2>
<p>用 <span class="math inline">\(Y_{i1}, Y_{i2}, (i = 1,\cdots, n)\)</span> 標記 <span class="math inline">\(n\)</span> 組配對實驗對象的結果變量的測量值。所以每對實驗對象中的兩個成員，分別被給予不同的實驗條件 (治療或安慰劑，暴露或非暴露)，用數字 <span class="math inline">\(1,2\)</span> 表示。所以，分析此種數據的策略是，計算每個實驗區塊的結果變量之差：</p>
<p><span class="math display" id="eq:GLM12-2">\[
\begin{equation}
Y_{i2} - Y_{i1}, (i = 1, \cdots, n)
\end{equation}
\tag{54.2}
\]</span></p>
<p>那麼，配對實驗的結果變量是連續型變量時，等同於單樣本的假設檢驗，零假設是結果變量在不同實驗條件下的差等於零。</p>
<div id="一般檢驗方法" class="section level3">
<h3><span class="header-section-number">54.2.1</span> 一般檢驗方法</h3>
<p>常用的有：</p>
<ol style="list-style-type: decimal">
<li>均值的配對 <span class="math inline">\(t\)</span> 檢驗。其實就是和 <span class="math inline">\(0\)</span> 作比較的單樣本 <span class="math inline">\(t\)</span> 檢驗 (Section <a href="03-Analytic-Technique.html#OneSampleT">22.6</a>)；</li>
<li>Wilcoxon 配對檢驗 (Wilcoxon matched pairs test)。此法其實是 Wilcoxon 符號秩和檢驗 (Wilcoxon signed rank test)，在零假設是兩組數據中位數之差等於零的條件下的假設檢驗 (Section <a href="06-RobustStatistic.html#Wilcoxon-signed-rank-test">36.2</a>)。</li>
<li>符號檢驗 (Sign test) (Section <a href="06-RobustStatistic.html#sign-test">36.1</a>)。</li>
</ol>
<p>例：17名實驗對象同時給予抗高血壓治療，數據記錄了實驗前後收縮壓的測量值：</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb686-1" title="1"><span class="kw">library</span>(haven)</a>
<a class="sourceLine" id="cb686-2" title="2">sbp &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/sbp.dta&quot;</span>)</a>
<a class="sourceLine" id="cb686-3" title="3">sbp</a></code></pre></div>
<pre><code>## # A tibble: 17 x 4
##     ptid sbp_A sbp_B diff_AB
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1     1   148   132      16
##  2     2   128   120       8
##  3     3   152   148       4
##  4     4   135   134       1
##  5     5   150   128      22
##  6     6   165   140      25
##  7     7   155   138      17
##  8     8   132   136      -4
##  9     9   140   135       5
## 10    10   165   144      21
## 11    11   145   115      30
## 12    12   140   126      14
## 13    13   135   140      -5
## 14    14   135   130       5
## 15    15   122   132     -10
## 16    16   144   118      26
## 17    17   158   115      43</code></pre>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb688-1" title="1"><span class="co">## Wilcoxon signed-rank test</span></a>
<a class="sourceLine" id="cb688-2" title="2"><span class="kw">wilcox.test</span>(sbp<span class="op">$</span>sbp_A, sbp<span class="op">$</span>sbp_B, <span class="dt">paired =</span> <span class="ot">TRUE</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  sbp$sbp_A and sbp$sbp_B
## V = 137.5, p-value = 0.0038567
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb690-1" title="1"><span class="co">## 秩和檢驗結果提示，數據提供了顯著性水平低於 1% (0.0038567) 的證據</span></a>
<a class="sourceLine" id="cb690-2" title="2"><span class="co">## 證明實驗前後收縮期血壓值的變化的中位數不等於零。</span></a>
<a class="sourceLine" id="cb690-3" title="3"><span class="co">## 由此可以下結論，數據能夠提供足夠的證據證明實驗前後的收縮期血壓的</span></a>
<a class="sourceLine" id="cb690-4" title="4"><span class="co">## 分佈，是不同的。</span></a>
<a class="sourceLine" id="cb690-5" title="5"><span class="co">## 注意，這不是一個 RCT，所以，這樣的不同不一定是由於抗高血壓治療。</span></a>
<a class="sourceLine" id="cb690-6" title="6"></a>
<a class="sourceLine" id="cb690-7" title="7"><span class="co">## 3 different methods to conduct sign test</span></a>
<a class="sourceLine" id="cb690-8" title="8"></a>
<a class="sourceLine" id="cb690-9" title="9">Positive_n &lt;-<span class="st"> </span><span class="kw">sum</span>(sbp<span class="op">$</span>diff_AB <span class="op">&gt;</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb690-10" title="10">total_n &lt;-<span class="st"> </span><span class="kw">length</span>(sbp<span class="op">$</span>diff_AB)</a>
<a class="sourceLine" id="cb690-11" title="11"><span class="dv">2</span><span class="op">*</span><span class="kw">pbinom</span>(total_n<span class="op">-</span>Positive_n, total_n, <span class="fl">0.5</span>) <span class="co">## sign test -- just p-value</span></a></code></pre></div>
<pre><code>## [1] 0.01272583</code></pre>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb692-1" title="1"><span class="kw">binom.test</span>(Positive_n, total_n,<span class="fl">0.5</span>) <span class="co">## sign test through binomial test</span></a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  Positive_n and total_n
## number of successes = 14, number of trials = 17, p-value = 0.012726
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.56568213 0.96201493
## sample estimates:
## probability of success 
##             0.82352941</code></pre>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb694-1" title="1">BSDA<span class="op">::</span><span class="kw">SIGN.test</span>(sbp<span class="op">$</span>sbp_A, sbp<span class="op">$</span>sbp_B) <span class="co">## sign-test from BSDA package</span></a></code></pre></div>
<pre><code>## 
##  Dependent-samples Sign-Test
## 
## data:  sbp$sbp_A and sbp$sbp_B
## S = 14, p-value = 0.012726
## alternative hypothesis: true median difference is not equal to 0
## 95 percent confidence interval:
##   4.0101487 21.9898513
## sample estimates:
## median of x-y 
##            14 
## 
## Achieved and Interpolated Confidence Intervals: 
## 
##                   Conf.Level L.E.pt  U.E.pt
## Lower Achieved CI     0.8565 5.0000 21.0000
## Interpolated CI       0.9500 4.0101 21.9899
## Upper Achieved CI     0.9510 4.0000 22.0000</code></pre>
<p>符號檢驗的結果，相比 Wilcoxon 秩和檢驗的結果來說， P 值稍大，由於符號檢驗需要的假設前提比 Wilcoxon 秩和檢驗更少，更穩健 (檢驗效能更低, lacks power)。即便如此，數據依然提供足夠的證據 (p = 0.01273) 證明，實驗前後的收縮期血壓的中位數之差不等於零。</p>
<p>下面是 STATA 中同一數據的 Wilcoxon 秩和檢驗和符號檢驗的結果，和上面的 R 輸出結果作比較：</p>
<pre><code>. signrank sbp_A = sbp_B

Wilcoxon signed-rank test

        sign |      obs   sum ranks    expected
-------------+---------------------------------
    positive |       14       137.5        76.5
    negative |        3        15.5        76.5
        zero |        0           0           0
-------------+---------------------------------
         all |       17         153         153

unadjusted variance      446.25
adjustment for ties       -0.63
adjustment for zeros       0.00
                     ----------
adjusted variance        445.63

Ho: sbp_A = sbp_B
             z =   2.890
    Prob &gt; |z| =   0.0039

. signtest sbp_A = sbp_B

Sign test

        sign |    observed    expected
-------------+------------------------
    positive |          14         8.5
    negative |           3         8.5
        zero |           0           0
-------------+------------------------
         all |          17          17

One-sided tests:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B &gt; 0
      Pr(#positive &gt;= 14) =
         Binomial(n = 17, x &gt;= 14, p = 0.5) =  0.0064

  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B &lt; 0
      Pr(#negative &gt;= 3) =
         Binomial(n = 17, x &gt;= 3, p = 0.5) =  0.9988

Two-sided test:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B != 0
      Pr(#positive &gt;= 14 or #negative &gt;= 14) =
         min(1, 2*Binomial(n = 17, x &gt;= 14, p = 0.5)) =  0.0127</code></pre>
</div>
<div id="用迴歸法分析" class="section level3">
<h3><span class="header-section-number">54.2.2</span> 用迴歸法分析</h3>
<p>配對實驗數據還可以使用迴歸手段分析。使用迴歸分析時，需要考慮兩種不同的情形：</p>
<ol style="list-style-type: decimal">
<li>配對使用的特徵具有唯一性，即有且只有一個對照。
<ul>
<li>自己作自己的對照，如實驗前實驗後的觀測值變化；</li>
<li>同一個實驗對象，左右兩眼隨機抽取一隻作病例，一隻作對照；</li>
<li>病例和自己的配偶配對。</li>
</ul></li>
<li>配對使用的特徵不具有唯一性，病例可以有多個潛在對照。
<ul>
<li>病例和性別相同，年齡相近的對照；</li>
</ul></li>
</ol>
<p><strong>第 1 種情況：配對使用的特徵具有唯一性</strong></p>
<p>用 <span class="math inline">\(Y_{ij}\)</span> 標記第 <span class="math inline">\(j\)</span> 個配對實驗區塊中第 <span class="math inline">\(i\)</span> 個對象的觀測結果。我們可以使用下面的迴歸模型：</p>
<p><span class="math display" id="eq:GLM12-3">\[
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 X_{ij} + \gamma_j + \varepsilon_{ij}
\end{equation}
\tag{54.3}
\]</span></p>
<p>其中， <span class="math inline">\(\gamma_j\)</span> 是第 <span class="math inline">\(j\)</span> 個<strong>配對實驗區塊的固定效應</strong> (fixed effect)；<span class="math inline">\(\varepsilon_{ij}\)</span> 是殘差。這個模型可以在簡單線性迴歸中直接加入一個代表不同配對實驗區塊的變量 (分類型) 進行調整即可。用簡單線性迴歸擬合 <a href="09-GLM.html#eq:GLM12-3">(54.3)</a> 是一個等同於配對 <span class="math inline">\(t\)</span> 檢驗的迴歸方程。</p>
<p>注意：在迴歸模型中加入代表實驗區塊的分類型變量調整<strong>僅適用</strong>與簡單線性迴歸。<strong>非線性迴歸例如邏輯迴歸，方程中試圖加入區塊變量作爲固定效應是不合適的。</strong></p>
<p>在模型中加入隨機效應 (random effect)，作爲另一種迴歸手段，則可以同時應用於線性迴歸和非線性迴歸。這種模型被叫做分層迴歸模型 (hierarchical models)，或混合效應模型 (mixed effect model)，或隨機效應模型 (random effect model)。這將會在等級線性回歸 (Section <a href="10-Hierarchical-models.html#Hierarchical">58</a>) 這一章節中詳細討論，此處且先按下不表。</p>
<p><strong>第 2 種情況：配對使用的特徵不具有唯一性</strong></p>
<p>用 <span class="math inline">\(Y_i\)</span> 標記第 <span class="math inline">\(i\)</span> 個個體的觀測結果， <span class="math inline">\(X_i\)</span> 標記主要關心的暴露變量，<span class="math inline">\(W_i\)</span> 標記用於配對的一系列變量的向量。那麼我們可以擬合兩種迴歸模型，差別在於是否調整配對變量向量：</p>
<p><span class="math display" id="eq:GLM12-4">\[
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i
\end{equation}
\tag{54.4}
\]</span></p>
<p><span class="math display" id="eq:GLM12-5">\[
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \beta_2^TW_i + \delta_i
\end{equation}
\tag{54.5}
\]</span></p>
<p>需要指出的是，這兩個模型，都是合理有效的迴歸模型，理論上會給出相同或者十分近似的 <span class="math inline">\(\beta_1\)</span> 估計。因爲配對，意味着在該樣本中，<span class="math inline">\(X_i\)</span> 和 <span class="math inline">\(W_i\)</span> 是無關的，所以加入 <span class="math inline">\(W_i\)</span> 不會影響 <span class="math inline">\(\beta_1\)</span> 的估計值。即使，實驗樣本所來自的潛在人羣 (the unerlying population) 中，<span class="math inline">\(X_i, W_i\)</span> 是相關的 (也是最主要的要拿 <span class="math inline">\(W_i\)</span> 進行配對的動機所在)，兩個模型給出的 <span class="math inline">\(\beta_1\)</span> 估計理論上也不會有太大差距。但是，如果說配對是爲了控制混雜 (即人羣中 <span class="math inline">\(X_i, W_i\)</span> 是相關的)，建議應該使用模型 <a href="09-GLM.html#eq:GLM12-5">(54.5)</a>。因爲模型 <a href="09-GLM.html#eq:GLM12-5">(54.5)</a> 給出的 <span class="math inline">\(\beta_1\)</span> 的標準誤估計會比較小 (更小的信賴區間，更精確)。</p>
<p>前一節提到的一般檢驗法，是直接把“配對”這個條件放在檢驗過程中，它們只關心差異大小是否有意義。本小節討論的迴歸方法，則需要一些前提假設 (參考簡單線性迴歸的前提和邏輯迴歸的前提)。當前提條件可以滿足時，我們會更推薦使用迴歸方法對配對數據進行檢驗。因爲通常除了拿來配對的變量，我們對觀察對象還收集了其他的潛在混雜因子數據，使用迴歸方法可以進一步對其餘未用於配對的變量進行調整。</p>
</div>
</div>
<div id="結果變量是二分類變量的配對實驗" class="section level2">
<h2><span class="header-section-number">54.3</span> 結果變量是二分類變量的配對實驗</h2>
<p>用 <span class="math inline">\(Y_{i1}, Y_{i2} (i = 1,\cdots,n)\)</span> 標記 <span class="math inline">\(n\)</span> 個配對的二分類型的結果變量，其對應的暴露變量是 <span class="math inline">\(X_{i1}, X_{i2}\)</span>。</p>
<p>這樣的數據，有兩種方法來分析暴露和結果之間是否相關：</p>
<ol style="list-style-type: decimal">
<li>McNemar’s test;</li>
<li>Odds ratio.</li>
</ol>
<p>用前文中糖尿病患者眼底病變和是否變盲的例子來說明就是：第 <span class="math inline">\(i\)</span> 個實驗對象，他/她接受標準治療的眼睛是否變盲，決定了 <span class="math inline">\(Y_{i1} = 1 \text{ or } 0\)</span>；他/她接受新的治療的那隻眼睛是否變盲決定了 <span class="math inline">\(Y_{i2} = 1 \text{ or } 0\)</span>。</p>
<p>但是，用病例對照實驗 (肺癌例) 來解釋時，20 名肺癌患者被一一和同性別，年齡相近的 20 名非肺癌對象配對，每個實驗對象都被詢問其吸菸史。這樣的配對病例對照實驗的設計，決定了其實際上是把我們關心的問題 (吸菸是否導致肺癌) 逆轉了的 (肺癌患者中吸菸的比例是否大於沒有患肺癌的人)。此時應當使用 <strong>比值比 Odds ratio</strong> 來評價吸菸和肺癌之間的關係。</p>
<div id="第一步-對數據作表格" class="section level3">
<h3><span class="header-section-number">54.3.1</span> 第一步 對數據作表格</h3>
<p>有兩種方式對結果變量是二分類變量的實驗數據作表格歸納。其一，配對與否的信息被忽略掉 (表格 <a href="09-GLM.html#tab:unmatchedGLM12-1a">54.1</a>)；其二，包含配對信息 (表格 <a href="09-GLM.html#tab:matchedGLM12-1b">54.2</a>)。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unmatchedGLM12-1a">表 54.1: </span>Unmatched presentation of data from a study with binary outcome and binary treatment
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
New treatment
</th>
<th style="text-align:center;">
Standard treatment
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Blind
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;">
Not blind
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
43
</td>
</tr>
<tr>
<td style="text-align:center;">
Total
</td>
<td style="text-align:center;">
77
</td>
<td style="text-align:center;">
77
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:matchedGLM12-1b">表 54.2: </span>Matched presentation of data from a study with binary outcome and binary treatment
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
New treatment
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Not blind
</th>
<th style="text-align:center;">
Blind
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Standard treatment
</td>
<td style="text-align:center;font-weight: bold;">
Not blind
</td>
<td style="text-align:center;">
39
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
43
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
Blind
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;font-weight: bold;">
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
77
</td>
</tr>
</tbody>
</table>
</div>
<div id="mcnemars-test" class="section level3">
<h3><span class="header-section-number">54.3.2</span> McNemar’s test</h3>
<p>下面的表格，是前面表格 <a href="09-GLM.html#tab:matchedGLM12-1b">54.2</a> 的一般化形式。可以用於 McNemar 檢驗。在暴露對象中，結果變量等於 <span class="math inline">\(Y_{i1} = 1\)</span> 的配對數量的比例是 <span class="math inline">\(p_1 = (n_{10} + n_{11})/n\)</span>；在非暴露對象中，結果變量等於 <span class="math inline">\(Y_{i2} = 2\)</span> 的配對數量的比例是 <span class="math inline">\(p_2 = (n_{01} + n_{11})/n\)</span>。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 54.3 General arrangement of data for McNemar’s test
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Exposed <span class="math inline">\((j = 1)\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Failure <br> <span class="math inline">\((Y_{i1} = 0)\)</span>
</th>
<th style="text-align:center;">
Success <br> <span class="math inline">\((Y_{i1} = 1)\)</span>
</th>
<th style="text-align:center;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3">
Unexposed <br><span class="math inline">\((j = 2)\)</span>
</td>
<td style="text-align:center;">
Failure <br> <span class="math inline">\((Y_{i2} = 0)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}+n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Success <br> <span class="math inline">\((Y_{i2} = 1)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}+n_{11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}+n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}+n_{11}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n\)</span>
</td>
</tr>
</tbody>
</table>
<p>McNemar 檢驗的零假設是，<span class="math inline">\(p_2 - p_1 = 0\)</span>，其實這等價於比較表格中 <span class="math inline">\(n_{10}, n_{01}\)</span> 是否相等。所以，在零假設條件下：</p>
<p><span class="math display">\[
n_{10} \sim \text{Binomial}(n_{10} + n_{01}, 0.5)
\]</span></p>
<p>此時既可以選用精確的二項分佈檢驗，也可以用正態分佈近似法進行假設檢驗。用表格 <a href="09-GLM.html#tab:matchedGLM12-1b">54.2</a> 的數據進行的檢驗結果如下：</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb697-1" title="1"><span class="kw">binom.test</span>(<span class="dv">28</span>, <span class="dv">32</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  28 and 32
## number of successes = 28, number of trials = 32, p-value = 0.000019301
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.71005158 0.96486935
## sample estimates:
## probability of success 
##                  0.875</code></pre>
</div>
<div id="二分類型結果變量配對實驗的比值比" class="section level3">
<h3><span class="header-section-number">54.3.3</span> 二分類型結果變量配對實驗的比值比</h3>
<p>McNemar 檢驗只能用於判斷暴露和結果之間是否有關係。衡量這個關係的大小，還需要用比值比 (odds ratio)。我們已知可以用 Mantel Haenszel 方法來總結以某個分類變量爲條件的分層/合併比值比。同樣的方法也可以用於配對實驗數據的分析。此時的分層變量使用的是配對的實驗區塊 (blocks)。每個實驗區塊的數據可以歸納成下面的表格：</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 54.4 Example of matched data in stratum <span class="math inline">\(i\)</span>: numbers of individuals in stratum <span class="math inline">\(i\)</span> with each combination
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Unexposed (0)
</th>
<th style="text-align:center;">
Exposed (1)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Outcome 0
</td>
<td style="text-align:center;">
<span class="math inline">\(a_i\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b_i\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Outcome 1
</td>
<td style="text-align:center;">
<span class="math inline">\(c_i\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(d_i\)</span>
</td>
</tr>
</tbody>
</table>
<p>實驗區塊 <span class="math inline">\(i\)</span> 的比值比 OR 是：</p>
<p><span class="math display">\[
\text{OR} = \frac{a_id_i}{b_ic_i}
\]</span></p>
<p>Mantel Haenszel 合併 OR 是：</p>
<p><span class="math display">\[
\Psi = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
\text{where } n_i = 2
\]</span></p>
<p>可以繼續推導：</p>
<p><span class="math display">\[
\begin{aligned}
\Psi &amp; = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
     &amp; = \frac{\text{number of blocks with } Y_{i1} = 1 \;\&amp;\; Y_{i2} = 0}{\text{number of blocks with } Y_{i1} = 0 \;\&amp;\; Y_{i2} = 1} \\
     &amp; = \frac{n_{10}}{n_{01}}
\end{aligned}
\]</span></p>
<p>所以，從上述推導可知，在配對實驗中，比值比只取決於那些配對中出現了不同結果的數據。這些結果不一致的配對被命名爲<strong>不一致配對 (discordant pairs)</strong>。那些結果變量相同的配對對最終的比值比估計毫無用處。</p>
</div>
<div id="配對實驗比值比的信賴區間" class="section level3">
<h3><span class="header-section-number">54.3.4</span> 配對實驗比值比的信賴區間</h3>
<p>配對實驗比值比信賴區間的精確計算步驟如下：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\pi\)</span> 標記暴露對象中，結果變量等於 <span class="math inline">\(Y_{i1} = 1\)</span>，且非暴露對象中，結果變量等於 <span class="math inline">\(Y_{i2} = 0\)</span> 的配對數在全部不一致配對數中所佔的比例：<span class="math display">\[\hat\pi = \frac{n_{10}}{n_{10} + n_{01}}\]</span></li>
<li><span class="math inline">\(\Psi\)</span> 爲不一致配對的比值比：<span class="math display">\[\hat\Psi = \frac{n_{10}}{n_{01}}\]</span></li>
<li><span class="math inline">\(\pi, \Psi\)</span> 之間的關係是：<span class="math display">\[\Psi = \frac{\pi}{1-\pi}\]</span></li>
<li><span class="math inline">\(n_{10}\)</span> 服從二項分佈：<span class="math display">\[n_{10}\sim \text{Binomial}(n_{10} + n_{01}, \pi)\]</span></li>
<li>根據二項分佈的性質計算 <span class="math inline">\(\pi\)</span> 的信賴區間： <span class="math display">\[\pi_L, \pi_U\]</span></li>
<li>所以 <span class="math inline">\(\Psi\)</span> 的信賴區間就可以計算爲：<span class="math display">\[(\frac{\pi_L}{1-\pi_L},\frac{\pi_U}{1-\pi_U})\]</span></li>
</ol>
<p>用表格<a href="09-GLM.html#tab:matchedGLM12-1b">54.2</a> 的數據計算其比值比估計：</p>
<p><span class="math display">\[\hat{\text{OR}} = \frac{n_{10}}{n_{01}} = \frac{4}{28} = 0.14\]</span></p>
<p><span class="math inline">\(n_{10} = 4 \sim \text{Binomial}(32, \pi = 4/32 = 0.125)\)</span></p>
<p>所以 <span class="math inline">\(\pi\)</span> 的 95% 信賴區間爲：</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb699-1" title="1">FSA<span class="op">::</span><span class="kw">binCI</span>(<span class="dv">4</span>, <span class="dv">32</span>)</a></code></pre></div>
<pre><code>##                95% LCI    95% UCI
## Exact      0.035130653 0.28994842
## Wilson     0.049701344 0.28068305
## Asymptotic 0.010413848 0.23958615</code></pre>
<p>那麼該比值比的精確 95% 信賴區間爲：</p>
<p><span class="math display">\[
\begin{aligned}
 &amp; (\frac{0.03513065}{1-0.03513065},\frac{0.2899484}{1-0.2899484}) \\
=&amp; (0.036, 0.408)
\end{aligned}
\]</span></p>
<p>精確計算的結果和 R 裏獲得的結果一致：</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb701-1" title="1"><span class="kw">library</span>(exact2x2)</a>
<a class="sourceLine" id="cb701-2" title="2"><span class="kw">mcnemar.exact</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">39</span>, <span class="dv">28</span>, <span class="dv">4</span>, <span class="dv">6</span>),<span class="dv">2</span>,<span class="dv">2</span>))</a></code></pre></div>
<pre><code>## 
##  Exact McNemar test (with central confidence intervals)
## 
## data:  matrix(c(39, 28, 4, 6), 2, 2)
## b = 4, c = 28, p-value = 0.000019301
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.036409751 0.408348391
## sample estimates:
## odds ratio 
## 0.14285714</code></pre>
</div>
</div>
<div id="條件-conditional-比值比和邊際-marginal-比值比" class="section level2">
<h2><span class="header-section-number">54.4</span> 條件 (conditional) 比值比和邊際 (marginal) 比值比</h2>
<p>從配對實驗獲得的比值比是<strong>條件比值比 (conditional odds ratio)</strong>，所謂條件比值比，意思就是從配對實驗獲得的比值比是以配對的試驗區塊爲條件的。</p>
<p>用表格 <a href="09-GLM.html#tab:matchedGLM12-1b">54.2</a> 的糖尿病患者眼底病變的數據來進一步解釋：該實驗獲得的條件比值比爲 0.143，實驗區塊是每位眼底發生病變的糖尿病患者本身。這個條件比值比應被正確解讀爲：<strong>每位眼底發生病變的患者中</strong>的兩隻眼睛中接受新療法的眼睛最終失明的機率 (odds)，和另一隻接受標準療法的眼睛最終失明的機率的比值是 0.143。數學表達式標記爲：</p>
<p><span class="math display">\[
\text{Conditional OR} = \frac{\frac{\text{Pr(Blind|new, individual) } i}{\text{Pr(Not Blind|new, individual) } i}}{\frac{\text{Pr(Blind|standard, individual) } i}{\text{Pr(Not blind|standard, individual) } i}}
\]</span></p>
<p>此<strong>條件比值比</strong>被認爲在<strong>不同的發生眼底病變的糖尿病患者<span class="math inline">\((i)\)</span>中保持不變</strong>。需要指出的是這個條件比值比<strong>不等同於認爲在糖尿病人羣中</strong>接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比爲 0.134 (邊際比值比 marginal odds ratio)。邊際比值比的數學表達式爲：</p>
<p><span class="math display">\[
\text{Marginal OR} = \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}}
\]</span></p>
<p>如果要估計上式的邊際比值比，我們需要有糖尿病人羣中失明的危險度 (the risk of blindness in the population)，以及失明高危人羣，低危人羣各自接受標準療法的失明概率。假如已知如下的信息：</p>
<ul>
<li>糖尿病人羣中有 50% 的人可以被歸類爲失明高危人羣 (high risk, HR)，另 50% 可以被歸類會失明低危人羣 (low risk, LR)；</li>
<li>接受標準療法時，高危人羣失明的概率是 90%，低危人羣失明的概率是 10%。</li>
</ul>
<p>上述信息告訴我們，總體糖尿病人羣中接受標準療法失明的概率 <span class="math inline">\(\text{Pr(Blind|standard)}\)</span> 是：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr(Blind|standard)}  &amp; = \text{Pr(Blind|standard,HR)Pr(HR)} \\
                           &amp; \;\;\;+ \text{Pr(Blind|standard, LR)Pr(LR)} \\
                           &amp; = 0.9\times0.5 + 0.1\times0.5 = 0.5
\end{aligned}
\]</span></p>
<p>再利用條件比值比 <span class="math inline">\(0.143\)</span> 我們可以計算糖尿病人羣中接受新療法失明的概率 <span class="math inline">\(\text{Pr(Blind | new)}\)</span> 是：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\text{Pr(Blind|new, HR)}}{\text{PR(Not blind | new, HR)}} &amp; = 0.143 \times \frac{\text{Pr(Blind|standard, HR)}}{\text{Pr(Not blind|standard, HR)}}  \\
 &amp; = 0.143 \times \frac{0.9}{0.1} = 1.287  \\
\frac{\text{Pr(Blind|new, LR)}}{\text{PR(Not blind | new, LR)}} &amp; = 0.143 \times \frac{\text{Pr(Blind|standard, LR)}}{\text{Pr(Not blind|standard, LR)}}  \\
 &amp; = 0.143 \times \frac{0.1}{0.9} = 0.016  \\
\Rightarrow \text{Pr(Blind|new, HR)} &amp; = 1.287/(1+1.287) = 0.563 \\
            \text{Pr(Blind|new, LR)} &amp; = 0/016/(1+0.016) = 0.016 \\
\Rightarrow\;\;\; \text{Pr(Blind | new)}   &amp; = \text{Pr(Blind|new, HR)Pr(HR)} + \text{Pr(Blind|new, LR)PR(LR)} \\
                                     &amp; = 0.563\times0.5 + 0.016\times0.5 =  0.290
\end{aligned}
\]</span></p>
<p>獲得了 <span class="math inline">\(\text{Pr(Blind|standard), Pr(Blind | new)}\)</span> 之後，邊際比值比 (糖尿病人羣中接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比)：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Marginal OR} &amp; =  \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}} \\
                   &amp; = \frac{0.5/(1-0.5)}{0.290/(1-0.290)} = 0.408
\end{aligned}
\]</span></p>
<p>比起條件比值比 (0.143)，邊際比值比 (0.408) 要大出許多來。</p>
</div>
</div>
<div id="條件邏輯迴歸-conditional-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 55 章</span> 條件邏輯迴歸 Conditional logistic regression</h1>
<p>配對實驗設計可以用於 RCT，隊列研究，病例對照研究：</p>
<ul>
<li>RCT實驗設計中，接受治療方案 A 的患者，和接受治療方案 B 的患者，以 1:1 的比例按照他們的某種醫學特徵配對。這種配對可以是同一個患者在交叉設計RCT 實驗中的觀測值，也可以是同一個患者接受治療的前後測量值，當然還可以是同一個患者的左右兩隻眼睛 (手臂，腿，等等)；</li>
<li>隊列研究裏，<strong>暴露和非暴露</strong>對象根據事先決定的配對原則配對 (相同性別，年齡接近，或者居住在同一社區，或者是同一家庭中暴露和非暴露的兩個個體)；</li>
<li>病例對照研究裏，<strong>病例和非病例</strong>按照事先決定的配對原則配對，一個病例可能和一個或者多個對照相匹配。</li>
</ul>
<p>本章節着重討論病例對照研究中，條件邏輯迴歸模型的使用。在病例對照研究中，配對設計極爲常見。如同前面提到的那樣，在病例對照研究的設計階段，研究者可能設計一個病例和一個或者多個對照進行配對。要研究的暴露因素變量可以是多種多樣的 (二分類，或連續型)，且可以考慮對多個不同的暴露進行觀察和分析時的調整。相反，隊列研究中能夠進行配對的暴露就只能僅限於二分類變量。所以，病例對照研究中<strong>對某個特徵進行的配對</strong>，其實是對病例-對照這樣的實驗設計本身與生俱來的特質進行了合理的利用。隊列研究則沒有了這樣的優勢，所以隊列研究中使用配對設計的其實不太常見。</p>
<p>配對病例對照研究中，研究者常用一些最常見的混雜因素作爲配對的變量 (如性別年齡)，且這些配對所使用的變量本身不是該實驗主要探討的話題。有些研究者還認爲配對是一個方便地尋找對照組的手段。當然，選取對照組的原則，可以是具有唯一性的配對原則 (使對照有且僅有1-2個)，或者是無唯一性的配對原則 (病例可以有多個潛在的對照)。<strong>唯一性配對原則導致的最大問題是，你可能根本找不到合適的對照</strong>，所以研究者會更傾向於把配對原則放寬一些，以獲取足夠的對照組樣本量，但是這也會帶來別的附加問題，那就是需要用匹配的數學模型來控制殘差之間的依賴性 (residual dependency)。在考慮了生存時間的一些病例對照研究中，原則上還會考慮選取和病例存活相同時間 (年齡) 的人作對照，詳細會繼續在生存分析中深入探討。</p>
<div id="配對實驗的邏輯迴歸模型" class="section level2">
<h2><span class="header-section-number">55.1</span> 配對實驗的邏輯迴歸模型</h2>
<p>定義 <span class="math inline">\(X_u\)</span> 是一個簡單的二分類暴露變量，<span class="math inline">\(D_u\)</span> 是一個簡單的二分類結果變量，<span class="math inline">\(u = 1, \cdots, n\)</span> 是配對的個數。第 <span class="math inline">\(u\text{th}\)</span> 組中的研究對象，互爲配對。在某些特殊場合，每組配對只有2個研究對象 (例如糖尿病患者的左右兩隻眼睛)。</p>
<p>用概率標記法定義每個患者的概率：</p>
<p><span class="math display" id="eq:GLM13-1">\[
\begin{equation}
\pi_{u;xd} = \text{Pr}(X_u = x, D_u = d)
\end{equation}
\tag{55.1}
\]</span></p>
<p>用 (Section <a href="09-GLM.html#GLM8-3">50.2</a>) 中相似的表格來理解，第 <span class="math inline">\(u\)</span> 組 <span class="math inline">\((u = 1, \cdots, n)\)</span> 配對中的研究對象可以用下表來歸納其概率。</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 55.1: Separate samples from subpopulations <span class="math inline">\(D=0,1\)</span> with relavant conditional probabilities <strong>in a matched case-control study within each pair</strong>
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(X\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;01}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;10}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pi_{u;11}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(\text{Pr}(X_u=x|D_u=d)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{u;10}}{\pi_{u;10}+\pi_{u;00}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{\pi_{u;11}}{\pi_{u;11}+\pi_{u;01}}\)</span>
</td>
</tr>
</tbody>
</table>
<p>那麼第 <span class="math inline">\(u\)</span> 組配對中，暴露和結果之間真實的比值比 (odds ratio)是：</p>
<p><span class="math display" id="eq:GLM13-2">\[
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}}
\end{equation}
\tag{55.2}
\]</span></p>
<p>所以，在配對病例對照研究中，<strong>我們假設這樣的前提得到滿足：每個配對中的比值比是不變的 (we assume that the true log odds ratio relating exposure to disease is the same for all pairs)</strong>：</p>
<p><span class="math display" id="eq:GLM13-3">\[
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}} = e^\beta
\end{equation}
\tag{55.3}
\]</span></p>
<div id="配對病例對照研究" class="section level3">
<h3><span class="header-section-number">55.1.1</span> 配對病例對照研究</h3>
<p>在探討<strong>非配對的病例對照研究</strong>時，我們給二分類型暴露變量定義過下列邏輯迴歸模型 (Section <a href="09-GLM.html#GLM8-3-4">50.2.3</a>)：</p>
<p><span class="math display" id="eq:GLM13-4">\[
\begin{equation}
\text{Pr}(X_i = 1 | D_i = d_i) = \frac{e^{\lambda^*+\beta d_i}}{1+e^{\lambda^*+\beta d_i}}\\
\text{Where } i \text{ refers to an individual}
\end{equation}
\tag{55.4}
\]</span></p>
<p>接下來，我們來把這個邏輯回歸模型擴展到配對實驗數據: 每對實驗數據包含一個病例，一個對照。用 <span class="math inline">\(X_{u;0}\)</span> 標記第 <span class="math inline">\(u\)</span> 對配對數據中，對照的某二分類解釋變量的值 (the binary explanatory variable <span class="math inline">\(X\)</span> for the control in the <span class="math inline">\(u\)</span>th matched pair)。<span class="math inline">\(X_{u;1}\)</span> 表示該對照的病例的相應二分類解釋變量的值。如此，一個包含了配對的病例和對照二者的邏輯回歸模型可以寫爲:</p>
<p><span class="math display" id="eq:GLM13-5">\[
\begin{equation}
\text{Pr}(X_{u;0} = 1) = \frac{e^{\lambda^*_u}}{1+e^{\lambda^*_u}} ; \text{Pr}(X_{u;1} = 1) = \frac{e^{\lambda^*_u + \beta}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
\tag{55.5}
\]</span></p>
<p>或者你如果願意，可以把它改寫成:</p>
<p><span class="math display" id="eq:GLM13-6">\[
\begin{equation}
\text{Pr}(X_{u;d} = 1)  = \frac{e^{\lambda^*_u + d\beta}}{1+e^{\lambda^*_u + d\beta}}, \;d = 0,1
\end{equation}
\tag{55.6}
\]</span></p>
<p>該模型的參數 <span class="math inline">\(\beta\)</span> 是第 <span class="math inline">\(u\)</span> 配對中的對數比值比 (log-odds ratio)。可是，我們使用它的前提是，默認這個對數比值比在所有的配對數據 <span class="math inline">\(u = 1, \cdots, n\)</span> 中都是相同的。另一個參數 <span class="math inline">\(\lambda^*_u\)</span> 是第 <span class="math inline">\(u\)</span> 組的特徵值。被定義爲第 <span class="math inline">\(u\)</span> 組配對中對照的暴露 <span class="math inline">\((X = 1)\)</span> 的對數幾率 (log odds of exposure for the exposure in the <span class="math inline">\(u\)</span>th pair):</p>
<p><span class="math display">\[
\lambda^*_u = \log(\frac{\pi_{u;10}}{\pi_{u;00}})
\]</span></p>
<p>在第 <span class="math inline">\(u\)</span> 組配對中，有且只有4種 <span class="math inline">\((x_{u;1},x_{u;0})\)</span> 結果: 也就是 <span class="math inline">\((0,0), (1,0), (0,1), (1,1)\)</span>。該對數據的似然方程是:</p>
<p><span class="math display" id="eq:GLM13-8">\[
\begin{equation}
\frac{e^{\lambda^*_ux_{u;0}}}{1+e^{\lambda^*_u}}\cdot\frac{e^{(\lambda^*_u + \beta)x_{u;1}}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
\tag{55.7}
\]</span></p>
<p>所以把所有配對的似然相乘可得整個數據的似然方程:</p>
<p><span class="math display" id="eq:GLM13-9">\[
\begin{equation}
\frac{\exp(\sum\lambda^*_ux_{u;0})}{\prod(1+e^{\lambda^*_u})}\cdot\frac{\exp(\sum(\lambda^*_u + \beta)x_{u;1})}{\prod(1+e^{\lambda^*_u+\beta})}
\end{equation}
\tag{55.8}
\]</span></p>
<p>整體數據的似然方程 <a href="09-GLM.html#eq:GLM13-9">(55.8)</a> 中的和 <span class="math inline">\(\sum\)</span> 與積 <span class="math inline">\(\prod\)</span> 分別對應相加與相乘所有的病例與對照的 <span class="math inline">\(n\)</span> 組配對。對於第 <span class="math inline">\(u\)</span> 組來說，它對似然方程的貢獻的部分只是式子 <a href="09-GLM.html#eq:GLM13-8">(55.7)</a> 中包含 <span class="math inline">\(\lambda_u^*\)</span> 的部分。該信息其實就是第 <span class="math inline">\(u\)</span> 組配對自有/特有的信息。但其實每組配對中的病例和對照又與其他組略微不同，他們各自提供的信息其實對於整體的似然來說雖然微小，但是當配對數量越來越多，就變得不可忽略。此時對 <a href="09-GLM.html#eq:GLM13-9">(55.8)</a> 直接進行粗暴的取參數 <span class="math inline">\(\beta\)</span> 的極大值是錯誤的，其導致的後果會在下文中繼續討論。我們需要用另一種新的途徑來求參數 <span class="math inline">\(\beta\)</span>。</p>
</div>
<div id="配對隊列研究" class="section level3">
<h3><span class="header-section-number">55.1.2</span> 配對隊列研究</h3>
<p>這裏簡略地分析一下配對隊列研究中會遇見的和配對病例對照研究相似問題的過程。在配對隊列研究中，一個<strong>接受暴露的研究對象</strong>被配對給另一個<strong>沒有接受暴露的研究對象</strong> (注意在配對病例對照研究中，是一個病例和一個對照做配對)。在第 <span class="math inline">\(u\)</span> 組隊列配對中，用 <span class="math inline">\(D_{u;1}\)</span> 標記暴露對象的追蹤結果 (發病/死亡/事件發生的有無)，用 <span class="math inline">\(D_{u;0}\)</span> 標記非暴露對象的追蹤結果 (發病/死亡/事件發生的有無)。</p>
<p>隊列研究中已知暴露 <span class="math inline">\(X\)</span> 有無的前提下，結果 <span class="math inline">\(D\)</span> 發生的有無的邏輯回歸模型，加入對配對設計的考量是:</p>
<p><span class="math display" id="eq:GLM13-10">\[
\begin{equation}
\text{Pr}(D_{u;0} = 1) = \frac{e^{\lambda_u}}{1+e^{\lambda_u}}\;; \; \text{Pr}(D_{u;1} = 1) = \frac{e^{\lambda_u + \beta}}{1+e^{\lambda_u+\beta}}
\end{equation}
\tag{55.9}
\]</span></p>
<p>正如之前在無配對條件下的隊列研究和病例對照研究中的推導過的那樣 <a href="09-GLM.html#GLM8-3-4">50.2.3</a>，<span class="math inline">\(\lambda_u\)</span> 和 <span class="math inline">\(\lambda_u^*\)</span> 是有<strong>不同涵義</strong>的，但是配對隊列研究和配對病例對照研究則具有相同的對數比值比–參數 <span class="math inline">\((\beta)\)</span>。這是基於一個重要的前提–相同人羣，相同暴露和相同疾病的結果在不同實驗設計 (病例對照和隊列研究) 時使用相同的配對變量。</p>
<p>在配對病例對照研究中，某對暴露和非暴露對象其實驗結果的可能性也只有四種 <span class="math inline">\((d_{u;1}, d_{u;0})\)</span>，該配對的似然是:</p>
<p><span class="math display" id="eq:GLM13-11">\[
\begin{equation}
\frac{e^{\lambda_ud_{u;0}}}{(1+e^{\lambda_ud_{u;0}})}\cdot\frac{e^{(\lambda_u+\beta)d_{u;1}}}{(1+e^{\lambda_u+\beta})}
\end{equation}
\tag{55.10}
\]</span></p>
<p>整體數據的似然方程就是和配對病例對照研究一樣的，將每對這樣的似然相乘。所以，我們就又遇見了和配對病例對照研究相似的問題，此時如果直接對整體似然方程中求極大似然獲得的 <span class="math inline">\(\beta\)</span> 將會是錯誤的。</p>
</div>
</div>
<div id="條件邏輯回歸-二分類暴露變量" class="section level2">
<h2><span class="header-section-number">55.2</span> 條件邏輯回歸 – 二分類暴露變量</h2>
<p>我們再回到簡單的一對一配對病例對照實驗設計，且研究的實驗暴露是一個簡單的二分類變量。這一節的目的是克服前面遇見的困難 (繞過不需要的 <span class="math inline">\(\lambda_u^*, u = 1, 2, \cdots, n\)</span>) ，找到能夠準確估計參數 <span class="math inline">\(\beta\)</span> 的數學方法。</p>
<div id="充分統計量-sufficient-statistics" class="section level3">
<h3><span class="header-section-number">55.2.1</span> 充分統計量 sufficient statistics</h3>
<p>繞過雜音變量(不需要的變量)，直接估計我們感興趣的參數的過程，需要利用<strong>充分統計量 (sufficient statistics)</strong> 的概念。這裏，噪音變量就是 <span class="math inline">\(\lambda_u^*, u = 1, 2, \cdots, n\)</span>。下面是對充分統計量的定義:</p>
<p>假設隨機變量 <span class="math inline">\(\mathbf{y}\)</span> 的概率(密度)方程中含有其他的雜音變量 <span class="math inline">\(\theta_1, \cdots, \theta_p\)</span>:</p>
<p><span class="math display">\[
f(\mathbf{y}|\theta_1, \cdots, \theta_9)
\]</span></p>
<p>如果統計量 <span class="math inline">\(T_k\)</span>，是實驗數據中得到的某方程，且 <span class="math inline">\(\mathbf{y}\)</span> 基於 <span class="math inline">\(T_k\)</span> 的條件分布與 <span class="math inline">\(\theta_k\)</span> 無關 (獨立)，那麼該方程被稱作參數 <span class="math inline">\(\theta_k\)</span> 的充分統計量。其實就是，如果 <span class="math inline">\(T_k\)</span> 可以給我們足夠估計 <span class="math inline">\(\theta_k\)</span> 的信息量，我們就稱 <span class="math inline">\(T_k\)</span> 是 <span class="math inline">\(\theta_k\)</span> 的充分統計量。</p>
<p>舉例來說，假設我們手頭的樣本數據 <span class="math inline">\(y_1, y_2, \cdots, y_n\)</span> 可以被認爲從正態分布的人羣中採集，我們希望通過這個樣本來估計總體人羣的均值 <span class="math inline">\(\mu\)</span>。此時常常(不自覺地)做總體方差已知的假設。該數據的似然方程是:</p>
<p><span class="math display">\[
\prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{ -\frac{(y_i-\mu)^2}{2\sigma^2} \}
\]</span></p>
<p>此時，估計要總體均值 <span class="math inline">\(\mu\)</span> 我們僅需要 <span class="math inline">\(\sum_i y_i\)</span> (或者只要 <span class="math inline">\(\bar{y}\)</span>) 就足夠了。這裏我們說 <span class="math inline">\(\sum_i y_i\)</span> 是參數總體均值 <span class="math inline">\(\mu\)</span> 的充分統計量。</p>
</div>
<div id="條件邏輯回歸的推導" class="section level3">
<h3><span class="header-section-number">55.2.2</span> 條件邏輯回歸的推導</h3>
<p>在簡單配對病例對照研究的實驗設定下，可以被證明的是，第 <span class="math inline">\(u\)</span> 對配對的暴露變量 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span> 是雜音變量 <span class="math inline">\(\lambda_u^*\)</span> 的充分統計量。值得注意的是，我們其實不需要知道 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span> 這一對暴露數據中哪個來自病例，哪個來自對照。對於一個二分類暴露變量，如果我們已知 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，那麼我們就知道了每個病例對照配對中暴露的個數。所以，我們完全可以用 <span class="math inline">\(T_u = x_{u;0} + x_{u;1}\)</span> 來替代 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，因爲它只有三種取值的可能:</p>
<ul>
<li>0: 病例對照都沒有暴露;</li>
<li>1: 病例或者對照其中之一有暴露;</li>
<li>2: 病例和對照均有暴露。</li>
</ul>
<p>利用已知的關於充分統計量的概念，在尋找第 <span class="math inline">\(u\)</span> 對配對對總體似然的貢獻時我們把 <span class="math inline">\(T_u = x_{u;0} + x_{u;1}\)</span> 作條件 (condition on)。有了這個條件，剩下的隨機現象就是暴露在病例和對照中的分布，也就是:</p>
<p><span class="math display" id="eq:GLM13-13">\[
\begin{equation}
\text{Pr}(X_{u;0} = x_{u;0}, X_{u;1} = x_{u;1} | T_u = x_{u;0} + x_{u;1})
\end{equation}
\tag{55.11}
\]</span></p>
<p>如果 <span class="math inline">\(x_{u;0}=x_{u;1}\)</span>，也就是當病例和對照同時爲暴露或非暴露時，我們有 100% 的把握對他們的暴露信息加以區分:</p>
<p><span class="math display" id="eq:GLM13-14">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 0| T_u = 0) =  1,\\
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 1| T_u = 2) =  1
\end{aligned}
\tag{55.12}
\]</span></p>
<p>如果 <span class="math inline">\(x_{u;0} \neq x_{u;1}\)</span>，也就是 <span class="math inline">\(T_u = 1\)</span>，那只有兩種可能性，要麼病例是暴露，對照非暴露，要麼病例是非暴露，對照是暴露:</p>
<p><span class="math display" id="eq:GLM13-15">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1),\\
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1)
\end{aligned}
\tag{55.13}
\]</span></p>
<p>這兩個概率可以被計算爲:</p>
<p><span class="math display" id="eq:GLM13-16">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) \\ &amp; =  \frac{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
\tag{55.14}
\]</span></p>
<p><span class="math display" id="eq:GLM13-17">\[
\begin{aligned}
&amp; \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) \\ &amp; = \frac{\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
\tag{55.15}
\]</span></p>
<p>用前面推導過的邏輯回歸模型公式 <a href="09-GLM.html#eq:GLM13-5">(55.5)</a> 可以推導出:</p>
<p><span class="math display" id="eq:GLM13-18">\[
\begin{aligned}
\text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) &amp; = \frac{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}}{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})} + \frac{e^{\lambda^*_u + \beta}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}} \\
 &amp; = \frac{1}{1+e^\beta}
\end{aligned}
\tag{55.16}
\]</span></p>
<p>類似地:</p>
<p><span class="math display" id="eq:GLM13-19">\[
\begin{aligned}
\text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) = \frac{e^\beta}{1+e^\beta}
\end{aligned}
\tag{55.17}
\]</span></p>
</div>
<div id="條件似然-conditional-likelihood" class="section level3">
<h3><span class="header-section-number">55.2.3</span> 條件似然 conditional likelihood</h3>
<p>一個簡單設計，暴露變量爲二分類變量的配對病例對照研究，可以用下面的四格表歸納收集的數據:</p>
<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
表 55.2: Data from a matched case control study with a single binary
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
<span class="math inline">\(D = 1\)</span>
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(D=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(X=0\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{00}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(X=1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{01}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n_{10}\)</span>
</td>
</tr>
</tbody>
</table>
<p>用上之前推導的結論，和上面表格的總結，我們可以知道，對於 1:1 的配對病例對照研究，且暴露爲二分類變量來說，它的似然是:</p>
<p><span class="math display" id="eq:GLM13-20">\[
\begin{equation}
L = (\frac{e^\beta}{1+e^\beta})^{n_{10}}(\frac{1}{1+e^\beta})^{n_{01}}
\end{equation}
\tag{55.18}
\]</span></p>
<p>接下來用我們熟悉的極大似然法就可以推導出 <span class="math inline">\(\beta\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
\ell &amp; = n_{10}\beta - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \frac{\text{d}\ell}{\text{d}\beta} &amp; = n_{10} - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \hat\beta  &amp; = \log\frac{n_{10}}{n_{01}}
\end{aligned}
\]</span></p>
</div>
<div id="進一步擴展" class="section level3">
<h3><span class="header-section-number">55.2.4</span> 進一步擴展</h3>
<p>目前為止推導的條件邏輯回歸模型雖然只是簡單的一對一配對病例對照研究實驗設計，且暴露變量也只是二分類變量。但是經驗告訴我們，這樣的理論基礎可以被進一步擴展到更加復雜的實驗設計:</p>
<ul>
<li><p>上述理論很容易地可以擴展到一對一配對隊列研究和RCT實驗。我們需要做的只是修改 <span class="math inline">\(X_{u;d}\)</span> 成 <span class="math inline">\(D_{u;x}\)</span> 即可，推導獲得的條件似然是完全相同的。唯一不同的是 <span class="math inline">\(n_{10}, n_{01}\)</span> 在隊列研究和RCT臨牀試驗中的含義從<strong>病例中暴露和對照中非暴露的對數</strong>變成了<strong>暴露中病例和非暴露中對照</strong>的對數。(<span class="math inline">\(n_{10}\)</span> becomes the number of pairs in which the exposed individual becomse a case and the unexposed becomes a control, and vice versa for <span class="math inline">\(n_{01}\)</span>)。</p></li>
<li><p>配對病例對照研究常見的可以一個病例配對1-5個對照。</p></li>
<li><p>也可以在配對病例對照研究中研究(比二分類變量)更加復雜的暴露因素，既可以是非類型變量，也可以是連續型變量。</p></li>
</ul>
</div>
</div>
<div id="條件邏輯回歸模型的一般化" class="section level2">
<h2><span class="header-section-number">55.3</span> 條件邏輯回歸模型的一般化</h2>
<p>現在我們拋棄簡單實驗設計思維，考慮在配對實驗中需要研究一個一般的暴露變量 (可以是二分類，多分類，連續型)，或者是一個多種不同變量組成的預測變量的向量。此時我們關心的主要是這些預測變量在病例或者對照的條件下分布 (conditional distribution): <span class="math inline">\(P(X_{u;0} = x), P(X_{u;1} = x)\)</span>。假設，某對病例和對照對象中，對照被觀測到有預測變量 <span class="math inline">\(x_{u;0}\)</span>，病例則被觀察到的是 <span class="math inline">\(x_{u;1}\)</span>，那麼我們關心的條件概率其實是研究對象被觀測到預測變量 <span class="math inline">\(x_{u;0}\)</span> 且他/她本身正好是對照，且同時他/她的病例被觀測到預測變量 <span class="math inline">\(x_{u;1}\)</span> 的概率。此時，充分統計量就是 <span class="math inline">\((x_{u;0}, x_{u;1})\)</span>，且聯合條件分布 (joint conditional distribution) 是:</p>
<p><span class="math display" id="eq:GLM13-24">\[
\begin{aligned}
&amp; \text{P}(X_{u;0} = x_{u;0}, X_{u; 1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
=&amp;  \frac{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1})}{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1}) + \text{P}(X_{u;0} = x_{u;1})\text{P}(X_{u;1} = x_{u;0})}
\end{aligned}
\tag{55.19}
\]</span></p>
<p>其實，當且僅當我們在研究<strong>一個簡單二分類預測變量</strong>時，一樣。這裏當我們需要把它一般化的時候，需要來點不太一樣的方法。先用 <span class="math inline">\(D_{u;x}\)</span> 標記第 <span class="math inline">\(u\)</span> 對配對中觀測到預測變量 <span class="math inline">\(x\)</span> 的研究對象的病例/對照狀態。那麼 <span class="math inline">\(D_{u;x}\)</span> 的邏輯回歸模型是:</p>
<p><span class="math display" id="eq:GLM13-25">\[
\begin{aligned}
\text{Pr}(D_{u;x} =1) &amp; = \frac{e^{\lambda_u+\beta^Tx}}{1+e^{\lambda_u+\beta^Tx}} \\
\text{Pr}(D_{u;x} =0) &amp; = \frac{1}{1+e^{\lambda_u+\beta^Tx}}
\end{aligned}
\tag{55.20}
\]</span></p>
<p>應用貝葉斯定理:</p>
<p><span class="math display" id="eq:GLM13-26">\[
\begin{equation}
\text{Pr}(X_{u;1} = x) = \frac{\text{Pr}(D_{u;x} = 1)\times\text{Pr}(X_{u;\cdot} = x)}{\text{Pr}(D_{u;\cdot} = 1)}
\end{equation}
\tag{55.21}
\]</span></p>
<p>其中,</p>
<ul>
<li><span class="math inline">\(\text{Pr}(X_{u;\cdot} = x)\)</span> 指的是預測變量 <span class="math inline">\(X\)</span> 在產生第 <span class="math inline">\(u\)</span> 對病例對照配對的人羣 (subpopulation which generates the <span class="math inline">\(u\)</span>th matched set) 中的邊際分布 (marginal distribution，或者叫做非條件分布 unconditional distribution);</li>
<li><span class="math inline">\(\text{Pr}(D_{u;\cdot} = 1)\)</span> 指的是在產生第 <span class="math inline">\(u\)</span> 對病例對照配對的人羣中，成爲病例的概率 (unconditional probability of being a case in that sub-population)。</li>
</ul>
<p>那麼將 <a href="09-GLM.html#eq:GLM13-26">(55.21)</a> 代入 <a href="09-GLM.html#eq:GLM13-24">(55.19)</a> 經過推導和精簡可以得到:</p>
<p><span class="math display" id="eq:GLM13-27">\[
\begin{aligned}
&amp; \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= &amp; \frac{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1)}{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1) + \text{Pr}(D_{u;x_{u;0}} = 1)\text{Pr}(D_{u;x_{u;1}} = 0)}
\end{aligned}
\tag{55.22}
\]</span></p>
<p>此時再帶入 <a href="09-GLM.html#eq:GLM13-25">(55.20)</a>，推導精簡之後可以獲得:</p>
<p><span class="math display" id="eq:GLM13-28">\[
\begin{aligned}
  &amp; \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= &amp; \frac{e^{\beta^{T}x_{u;1}}}{e^{\beta^{T}x_{u;1}} + e^{\beta^{T}x_{u;0}}}
\end{aligned}
\tag{55.23}
\]</span></p>
<p>這就是第 <span class="math inline">\(u\)</span> 組病例對照配對數據對條件似然 (conditional likelihood) 的貢獻。那麼對於完整的整套數據來說，整體似然就是把所有的病例對照配對的似然相乘:</p>
<p><span class="math display" id="eq:GLM13-29">\[
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \exp{(\beta^{T}x_{u;0})}}
\end{equation}
\tag{55.24}
\]</span></p>
<p>這樣的一對一病例對照研究的似然可以擴展到 1:c 的情況，也就是一個病例和 c 個對照相配對的情況，其條件邏輯回歸的似然是:</p>
<p><span class="math display">\[
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \sum_{k=1}^c\exp{(\beta^{T}x_{u;0k})}}
\end{equation}
\]</span></p>
</div>
</div>
<div id="multinomial-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 56 章</span> Multinomial Logistic Regression</h1>
</div>
<div id="ordinal-logistic-regression" class="section level1">
<h1><span class="header-section-number">第 57 章</span> Ordinal Logistic Regression</h1>

</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-hosmer1980goodness">
<p>Hosmer, David W, and Stanley Lemesbow. 1980. “Goodness of Fit Tests for the Multiple Logistic Regression Model.” <em>Communications in Statistics-Theory and Methods</em> 9 (10): 1043–69.</p>
</div>
<div id="ref-Pepe2007">
<p>Pepe, Margaret S, Ziding Feng, Ying Huang, Gary Longton, Ross Prentice, Ian M Thompson, and Yingye Zheng. 2007. “Integrating the Predictiveness of a Marker with Its Performance as a Classifier.” <em>American Journal of Epidemiology</em> 167 (3): 362–68.</p>
</div>
<div id="ref-Robinson1991">
<p>Robinson, Laurence D, and Nicholas P Jewell. 1991. “Some Surprising Results About Covariate Adjustment in Logistic Regression Models.” <em>International Statistical Review</em>, 227–40.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="08-Intro-to-Bayes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="10-Hierarchical-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook/js/app.min.js"></script>
<script src="assets/gitbook/js/lunr.js"></script>
<script src="assets/gitbook/js/clipboard.min.js"></script>
<script src="assets/gitbook/js/plugin-search.js"></script>
<script src="assets/gitbook/js/plugin-sharing.js"></script>
<script src="assets/gitbook/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook/js/plugin-bookdown.js"></script>
<script src="assets/gitbook/js/jquery.highlight.js"></script>
<script src="assets/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/09-GLM.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
